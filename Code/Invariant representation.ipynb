{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import data_loader\n",
    "from vae_classifier_attacks import test_attack, fgsm_attack\n",
    "import pickle\n",
    "from utils.viewer import show_batch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.mmd import MMD_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = data_loader.get_data()\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_channels = 8\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(1, num_channels, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(num_channels, eps=1e-05, momentum=0.5, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_channels, eps=1e-05, momentum=0.5, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(num_channels, num_channels, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(num_channels, eps=1e-05, momentum=0.5, affine=True),\n",
    "            nn.ReLU(inplace=True)\n",
    "\n",
    "        )\n",
    "        self.fc1 = nn.Linear(num_channels * 4 ** 2, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        convolved = self.conv(x)\n",
    "        after_fc1 = self.fc1(convolved.view(convolved.size(0), -1))\n",
    "        output = self.fc2(after_fc1)\n",
    "        return output\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \n",
    "        convolved = self.conv(x)\n",
    "        code = self.fc1(convolved.view(convolved.size(0), -1))\n",
    "        \n",
    "        return code\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=512)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=512)\n",
    "\n",
    "first_batch = next(iter(train_loader))\n",
    "first_images, first_labels = first_batch \n",
    "\n",
    "print(first_images.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = NeuralModel()\n",
    "#train_model(model, train_loader)\n",
    "#test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = torch.utils.data.DataLoader(test_set, batch_size=1)\n",
    "# train_loader = torch.utils.data.DataLoader(train_set, batch_size=1)\n",
    "# #acc, adv_examples = test_attack(model, device, train_loader, epsilon=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(adv_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('models/train_adv_examples.pkl', 'wb') as f:\n",
    "#     pickle.dump(adv_examples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/train_adv_examples.pkl', 'rb') as f:\n",
    "    adv_examples = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels =[]\n",
    "adv_labels = [] \n",
    "adv_images =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in adv_examples:\n",
    "    true_l, adv_l, adv_img = example\n",
    "    \n",
    "    true_labels.append(true_l)\n",
    "    adv_labels.append(adv_l)\n",
    "    adv_images.append(adv_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = torch.Tensor(true_labels).long()\n",
    "adv_images = torch.Tensor(adv_images).reshape(-1,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "b_size = 60\n",
    "training_data = []\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=b_size)\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_iter = iter(train_loader)\n",
    "\n",
    "for b in range (0, len(train_loader)*b_size, b_size):\n",
    "    batch_images, batch_labels = next(train_loader_iter)\n",
    "    training_data.append((batch_images, adv_images[b: b+b_size], true_labels[b: b+b_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "60\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 0, 2, 7, 1, 8, 6, 4, 1, 6, 3, 4, 1, 9, 1, 3, 3, 8, 5, 4, 7, 7, 4, 2,\n",
      "        8, 5, 8, 6, 9, 3, 4, 6, 1, 9, 9, 6, 0, 3, 7, 2, 8, 2, 9, 4, 4, 6, 4, 9,\n",
      "        7, 0, 9, 2, 7, 5, 1, 5, 9, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "training_data_iter = iter(training_data)\n",
    "b1 = next(training_data_iter)\n",
    "b1 = next(training_data_iter)\n",
    "b1 = next(training_data_iter)\n",
    "a,b,c = b1\n",
    "\n",
    "print(len(a))\n",
    "print(len(b))\n",
    "print(len(c))\n",
    "\n",
    "show_batch(a)\n",
    "show_batch(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    n_epochs = 10\n",
    "    model.train()\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    print(\"training ...\")\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch in train_data:\n",
    "            batch_images, adv_images, batch_labels = batch\n",
    "\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            adv_images = adv_images.to(device)\n",
    "            \n",
    "            batch_output = model(batch_images)\n",
    "            \n",
    "            latent_1 = model.encode(batch_images)\n",
    "            latent_2 = model.encode(adv_images)\n",
    "            \n",
    "            down_stream_loss = criterion(batch_output, batch_labels)\n",
    "            representation_loss = MMD_Loss(latent_1, latent_2)\n",
    "            \n",
    "            total_loss = down_stream_loss + 100*representation_loss\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(\"The classification loss after processing this batch is: \", down_stream_loss.item())\n",
    "            print(\"The representation loss after processing this batch is: \", representation_loss.item())\n",
    "            print(\"\")\n",
    "            \n",
    "    print(\"Done training..\")\n",
    "    print(\"=*=\"*20)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MMD_Loss(x, y):\n",
    "    \n",
    "    alpha =1\n",
    "    B=b_size\n",
    "\n",
    "    x = x.view(x.size(0), x.size(1) * 1)\n",
    "    y = y.view(y.size(0), y.size(1) * 1)\n",
    "\n",
    "    xx, yy, zz = torch.mm(x,x.t()), torch.mm(y,y.t()), torch.mm(x,y.t())\n",
    "\n",
    "    rx = (xx.diag().unsqueeze(0).expand_as(xx))\n",
    "    ry = (yy.diag().unsqueeze(0).expand_as(yy))\n",
    "\n",
    "    K = torch.exp(- alpha * (rx.t() + rx - 2*xx))\n",
    "    L = torch.exp(- alpha * (ry.t() + ry - 2*yy))\n",
    "    P = torch.exp(- alpha * (rx.t() + ry - 2*zz))\n",
    "\n",
    "    beta = (1./(B*(B-1)))\n",
    "    gamma = (2./(B*B)) \n",
    "\n",
    "    return beta * (torch.sum(K)+torch.sum(L)) - gamma * torch.sum(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ...\n",
      "The classification loss after processing this batch is:  2.319800853729248\n",
      "The representation loss after processing this batch is:  0.03756791353225708\n",
      "\n",
      "The classification loss after processing this batch is:  2.3250112533569336\n",
      "The representation loss after processing this batch is:  0.03828895092010498\n",
      "\n",
      "The classification loss after processing this batch is:  2.3251535892486572\n",
      "The representation loss after processing this batch is:  0.031454771757125854\n",
      "\n",
      "The classification loss after processing this batch is:  2.315671682357788\n",
      "The representation loss after processing this batch is:  0.02934589982032776\n",
      "\n",
      "The classification loss after processing this batch is:  2.319268226623535\n",
      "The representation loss after processing this batch is:  0.03258591890335083\n",
      "\n",
      "The classification loss after processing this batch is:  2.3162291049957275\n",
      "The representation loss after processing this batch is:  0.03440070152282715\n",
      "\n",
      "The classification loss after processing this batch is:  2.2978813648223877\n",
      "The representation loss after processing this batch is:  0.03063148260116577\n",
      "\n",
      "The classification loss after processing this batch is:  2.305689573287964\n",
      "The representation loss after processing this batch is:  0.03009098768234253\n",
      "\n",
      "The classification loss after processing this batch is:  2.3024656772613525\n",
      "The representation loss after processing this batch is:  0.028609037399291992\n",
      "\n",
      "The classification loss after processing this batch is:  2.3139331340789795\n",
      "The representation loss after processing this batch is:  0.029845595359802246\n",
      "\n",
      "The classification loss after processing this batch is:  2.2967300415039062\n",
      "The representation loss after processing this batch is:  0.028760403394699097\n",
      "\n",
      "The classification loss after processing this batch is:  2.3122034072875977\n",
      "The representation loss after processing this batch is:  0.03095144033432007\n",
      "\n",
      "The classification loss after processing this batch is:  2.280947685241699\n",
      "The representation loss after processing this batch is:  0.027131497859954834\n",
      "\n",
      "The classification loss after processing this batch is:  2.2587177753448486\n",
      "The representation loss after processing this batch is:  0.02885735034942627\n",
      "\n",
      "The classification loss after processing this batch is:  2.3187716007232666\n",
      "The representation loss after processing this batch is:  0.02886885404586792\n",
      "\n",
      "The classification loss after processing this batch is:  2.2964231967926025\n",
      "The representation loss after processing this batch is:  0.026578396558761597\n",
      "\n",
      "The classification loss after processing this batch is:  2.296020746231079\n",
      "The representation loss after processing this batch is:  0.02603432536125183\n",
      "\n",
      "The classification loss after processing this batch is:  2.2796342372894287\n",
      "The representation loss after processing this batch is:  0.02852591872215271\n",
      "\n",
      "The classification loss after processing this batch is:  2.2290658950805664\n",
      "The representation loss after processing this batch is:  0.03255516290664673\n",
      "\n",
      "The classification loss after processing this batch is:  2.2791354656219482\n",
      "The representation loss after processing this batch is:  0.03325268626213074\n",
      "\n",
      "The classification loss after processing this batch is:  2.2753846645355225\n",
      "The representation loss after processing this batch is:  0.02454841136932373\n",
      "\n",
      "The classification loss after processing this batch is:  2.2659225463867188\n",
      "The representation loss after processing this batch is:  0.0266762375831604\n",
      "\n",
      "The classification loss after processing this batch is:  2.2649874687194824\n",
      "The representation loss after processing this batch is:  0.029362231492996216\n",
      "\n",
      "The classification loss after processing this batch is:  2.302698850631714\n",
      "The representation loss after processing this batch is:  0.025489360094070435\n",
      "\n",
      "The classification loss after processing this batch is:  2.2814409732818604\n",
      "The representation loss after processing this batch is:  0.02374890446662903\n",
      "\n",
      "The classification loss after processing this batch is:  2.220604181289673\n",
      "The representation loss after processing this batch is:  0.02968856692314148\n",
      "\n",
      "The classification loss after processing this batch is:  2.2950141429901123\n",
      "The representation loss after processing this batch is:  0.023171037435531616\n",
      "\n",
      "The classification loss after processing this batch is:  2.2595856189727783\n",
      "The representation loss after processing this batch is:  0.030263572931289673\n",
      "\n",
      "The classification loss after processing this batch is:  2.2267158031463623\n",
      "The representation loss after processing this batch is:  0.02650630474090576\n",
      "\n",
      "The classification loss after processing this batch is:  2.226334810256958\n",
      "The representation loss after processing this batch is:  0.028751760721206665\n",
      "\n",
      "The classification loss after processing this batch is:  2.2240819931030273\n",
      "The representation loss after processing this batch is:  0.02422654628753662\n",
      "\n",
      "The classification loss after processing this batch is:  2.2376108169555664\n",
      "The representation loss after processing this batch is:  0.0269758403301239\n",
      "\n",
      "The classification loss after processing this batch is:  2.2394347190856934\n",
      "The representation loss after processing this batch is:  0.028451532125473022\n",
      "\n",
      "The classification loss after processing this batch is:  2.246549129486084\n",
      "The representation loss after processing this batch is:  0.02294495701789856\n",
      "\n",
      "The classification loss after processing this batch is:  2.209606409072876\n",
      "The representation loss after processing this batch is:  0.023673713207244873\n",
      "\n",
      "The classification loss after processing this batch is:  2.2108521461486816\n",
      "The representation loss after processing this batch is:  0.025087088346481323\n",
      "\n",
      "The classification loss after processing this batch is:  2.222728729248047\n",
      "The representation loss after processing this batch is:  0.023206323385238647\n",
      "\n",
      "The classification loss after processing this batch is:  2.2314374446868896\n",
      "The representation loss after processing this batch is:  0.023176640272140503\n",
      "\n",
      "The classification loss after processing this batch is:  2.1818339824676514\n",
      "The representation loss after processing this batch is:  0.02516523003578186\n",
      "\n",
      "The classification loss after processing this batch is:  2.2010793685913086\n",
      "The representation loss after processing this batch is:  0.02126210927963257\n",
      "\n",
      "The classification loss after processing this batch is:  2.2420756816864014\n",
      "The representation loss after processing this batch is:  0.024810791015625\n",
      "\n",
      "The classification loss after processing this batch is:  2.1795003414154053\n",
      "The representation loss after processing this batch is:  0.022051900625228882\n",
      "\n",
      "The classification loss after processing this batch is:  2.177807569503784\n",
      "The representation loss after processing this batch is:  0.022704124450683594\n",
      "\n",
      "The classification loss after processing this batch is:  2.1860971450805664\n",
      "The representation loss after processing this batch is:  0.02151980996131897\n",
      "\n",
      "The classification loss after processing this batch is:  2.186072826385498\n",
      "The representation loss after processing this batch is:  0.0225771963596344\n",
      "\n",
      "The classification loss after processing this batch is:  2.1937711238861084\n",
      "The representation loss after processing this batch is:  0.02087286114692688\n",
      "\n",
      "The classification loss after processing this batch is:  2.2157275676727295\n",
      "The representation loss after processing this batch is:  0.019996553659439087\n",
      "\n",
      "The classification loss after processing this batch is:  2.2059686183929443\n",
      "The representation loss after processing this batch is:  0.01839745044708252\n",
      "\n",
      "The classification loss after processing this batch is:  2.1702446937561035\n",
      "The representation loss after processing this batch is:  0.01957225799560547\n",
      "\n",
      "The classification loss after processing this batch is:  2.1633875370025635\n",
      "The representation loss after processing this batch is:  0.019809961318969727\n",
      "\n",
      "The classification loss after processing this batch is:  2.1846306324005127\n",
      "The representation loss after processing this batch is:  0.020632117986679077\n",
      "\n",
      "The classification loss after processing this batch is:  2.1345858573913574\n",
      "The representation loss after processing this batch is:  0.02053120732307434\n",
      "\n",
      "The classification loss after processing this batch is:  2.173407554626465\n",
      "The representation loss after processing this batch is:  0.019339710474014282\n",
      "\n",
      "The classification loss after processing this batch is:  2.1795239448547363\n",
      "The representation loss after processing this batch is:  0.018929868936538696\n",
      "\n",
      "The classification loss after processing this batch is:  2.1670761108398438\n",
      "The representation loss after processing this batch is:  0.017651110887527466\n",
      "\n",
      "The classification loss after processing this batch is:  2.186202049255371\n",
      "The representation loss after processing this batch is:  0.01844993233680725\n",
      "\n",
      "The classification loss after processing this batch is:  2.150639533996582\n",
      "The representation loss after processing this batch is:  0.017388910055160522\n",
      "\n",
      "The classification loss after processing this batch is:  2.1493682861328125\n",
      "The representation loss after processing this batch is:  0.021301329135894775\n",
      "\n",
      "The classification loss after processing this batch is:  2.194749116897583\n",
      "The representation loss after processing this batch is:  0.020547598600387573\n",
      "\n",
      "The classification loss after processing this batch is:  2.1510543823242188\n",
      "The representation loss after processing this batch is:  0.016239792108535767\n",
      "\n",
      "The classification loss after processing this batch is:  2.1430113315582275\n",
      "The representation loss after processing this batch is:  0.016907066106796265\n",
      "\n",
      "The classification loss after processing this batch is:  2.1488122940063477\n",
      "The representation loss after processing this batch is:  0.016881555318832397\n",
      "\n",
      "The classification loss after processing this batch is:  2.1592190265655518\n",
      "The representation loss after processing this batch is:  0.020490199327468872\n",
      "\n",
      "The classification loss after processing this batch is:  2.151406764984131\n",
      "The representation loss after processing this batch is:  0.016321957111358643\n",
      "\n",
      "The classification loss after processing this batch is:  2.1655688285827637\n",
      "The representation loss after processing this batch is:  0.016184359788894653\n",
      "\n",
      "The classification loss after processing this batch is:  2.1350746154785156\n",
      "The representation loss after processing this batch is:  0.018776297569274902\n",
      "\n",
      "The classification loss after processing this batch is:  2.1553337574005127\n",
      "The representation loss after processing this batch is:  0.018633604049682617\n",
      "\n",
      "The classification loss after processing this batch is:  2.1535398960113525\n",
      "The representation loss after processing this batch is:  0.015899688005447388\n",
      "\n",
      "The classification loss after processing this batch is:  2.1278910636901855\n",
      "The representation loss after processing this batch is:  0.016467124223709106\n",
      "\n",
      "The classification loss after processing this batch is:  2.1568832397460938\n",
      "The representation loss after processing this batch is:  0.01722903549671173\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  2.1354401111602783\n",
      "The representation loss after processing this batch is:  0.014337092638015747\n",
      "\n",
      "The classification loss after processing this batch is:  2.098585367202759\n",
      "The representation loss after processing this batch is:  0.017018407583236694\n",
      "\n",
      "The classification loss after processing this batch is:  2.136108636856079\n",
      "The representation loss after processing this batch is:  0.016084909439086914\n",
      "\n",
      "The classification loss after processing this batch is:  2.0768964290618896\n",
      "The representation loss after processing this batch is:  0.017725318670272827\n",
      "\n",
      "The classification loss after processing this batch is:  2.1157777309417725\n",
      "The representation loss after processing this batch is:  0.014912158250808716\n",
      "\n",
      "The classification loss after processing this batch is:  2.084702491760254\n",
      "The representation loss after processing this batch is:  0.01344558596611023\n",
      "\n",
      "The classification loss after processing this batch is:  2.0803029537200928\n",
      "The representation loss after processing this batch is:  0.015794098377227783\n",
      "\n",
      "The classification loss after processing this batch is:  2.1253700256347656\n",
      "The representation loss after processing this batch is:  0.012679129838943481\n",
      "\n",
      "The classification loss after processing this batch is:  2.096719264984131\n",
      "The representation loss after processing this batch is:  0.012658238410949707\n",
      "\n",
      "The classification loss after processing this batch is:  2.095073938369751\n",
      "The representation loss after processing this batch is:  0.014605298638343811\n",
      "\n",
      "The classification loss after processing this batch is:  2.132722854614258\n",
      "The representation loss after processing this batch is:  0.014645248651504517\n",
      "\n",
      "The classification loss after processing this batch is:  2.1011345386505127\n",
      "The representation loss after processing this batch is:  0.014023900032043457\n",
      "\n",
      "The classification loss after processing this batch is:  2.0419352054595947\n",
      "The representation loss after processing this batch is:  0.014393612742424011\n",
      "\n",
      "The classification loss after processing this batch is:  2.0316109657287598\n",
      "The representation loss after processing this batch is:  0.016150817275047302\n",
      "\n",
      "The classification loss after processing this batch is:  2.061772584915161\n",
      "The representation loss after processing this batch is:  0.013941064476966858\n",
      "\n",
      "The classification loss after processing this batch is:  2.0297341346740723\n",
      "The representation loss after processing this batch is:  0.012826591730117798\n",
      "\n",
      "The classification loss after processing this batch is:  2.074429988861084\n",
      "The representation loss after processing this batch is:  0.013326823711395264\n",
      "\n",
      "The classification loss after processing this batch is:  2.011556625366211\n",
      "The representation loss after processing this batch is:  0.011362671852111816\n",
      "\n",
      "The classification loss after processing this batch is:  2.0423059463500977\n",
      "The representation loss after processing this batch is:  0.011917322874069214\n",
      "\n",
      "The classification loss after processing this batch is:  2.0320725440979004\n",
      "The representation loss after processing this batch is:  0.012539505958557129\n",
      "\n",
      "The classification loss after processing this batch is:  2.0874171257019043\n",
      "The representation loss after processing this batch is:  0.013375058770179749\n",
      "\n",
      "The classification loss after processing this batch is:  1.9968091249465942\n",
      "The representation loss after processing this batch is:  0.011595726013183594\n",
      "\n",
      "The classification loss after processing this batch is:  2.0457684993743896\n",
      "The representation loss after processing this batch is:  0.013647347688674927\n",
      "\n",
      "The classification loss after processing this batch is:  2.0092928409576416\n",
      "The representation loss after processing this batch is:  0.011494725942611694\n",
      "\n",
      "The classification loss after processing this batch is:  1.9939520359039307\n",
      "The representation loss after processing this batch is:  0.012453600764274597\n",
      "\n",
      "The classification loss after processing this batch is:  2.037543296813965\n",
      "The representation loss after processing this batch is:  0.01152084767818451\n",
      "\n",
      "The classification loss after processing this batch is:  1.9930355548858643\n",
      "The representation loss after processing this batch is:  0.013737678527832031\n",
      "\n",
      "The classification loss after processing this batch is:  2.013547420501709\n",
      "The representation loss after processing this batch is:  0.01291397213935852\n",
      "\n",
      "The classification loss after processing this batch is:  2.0009191036224365\n",
      "The representation loss after processing this batch is:  0.013522431254386902\n",
      "\n",
      "The classification loss after processing this batch is:  2.029283285140991\n",
      "The representation loss after processing this batch is:  0.011324301362037659\n",
      "\n",
      "The classification loss after processing this batch is:  2.0020482540130615\n",
      "The representation loss after processing this batch is:  0.010408326983451843\n",
      "\n",
      "The classification loss after processing this batch is:  2.010287284851074\n",
      "The representation loss after processing this batch is:  0.01013725996017456\n",
      "\n",
      "The classification loss after processing this batch is:  2.013559103012085\n",
      "The representation loss after processing this batch is:  0.010932624340057373\n",
      "\n",
      "The classification loss after processing this batch is:  2.00038743019104\n",
      "The representation loss after processing this batch is:  0.010572865605354309\n",
      "\n",
      "The classification loss after processing this batch is:  2.043372392654419\n",
      "The representation loss after processing this batch is:  0.011535421013832092\n",
      "\n",
      "The classification loss after processing this batch is:  1.9913591146469116\n",
      "The representation loss after processing this batch is:  0.011448770761489868\n",
      "\n",
      "The classification loss after processing this batch is:  1.9761216640472412\n",
      "The representation loss after processing this batch is:  0.011018335819244385\n",
      "\n",
      "The classification loss after processing this batch is:  1.9635939598083496\n",
      "The representation loss after processing this batch is:  0.01177273690700531\n",
      "\n",
      "The classification loss after processing this batch is:  1.9875272512435913\n",
      "The representation loss after processing this batch is:  0.012228026986122131\n",
      "\n",
      "The classification loss after processing this batch is:  1.9190409183502197\n",
      "The representation loss after processing this batch is:  0.01125192642211914\n",
      "\n",
      "The classification loss after processing this batch is:  1.8778305053710938\n",
      "The representation loss after processing this batch is:  0.010401472449302673\n",
      "\n",
      "The classification loss after processing this batch is:  1.910306692123413\n",
      "The representation loss after processing this batch is:  0.013498082756996155\n",
      "\n",
      "The classification loss after processing this batch is:  1.9379088878631592\n",
      "The representation loss after processing this batch is:  0.01470974087715149\n",
      "\n",
      "The classification loss after processing this batch is:  1.9894050359725952\n",
      "The representation loss after processing this batch is:  0.012306198477745056\n",
      "\n",
      "The classification loss after processing this batch is:  1.9885692596435547\n",
      "The representation loss after processing this batch is:  0.010511130094528198\n",
      "\n",
      "The classification loss after processing this batch is:  1.9515132904052734\n",
      "The representation loss after processing this batch is:  0.010705530643463135\n",
      "\n",
      "The classification loss after processing this batch is:  1.8744605779647827\n",
      "The representation loss after processing this batch is:  0.010617643594741821\n",
      "\n",
      "The classification loss after processing this batch is:  1.9136216640472412\n",
      "The representation loss after processing this batch is:  0.01243610680103302\n",
      "\n",
      "The classification loss after processing this batch is:  1.9217190742492676\n",
      "The representation loss after processing this batch is:  0.011677369475364685\n",
      "\n",
      "The classification loss after processing this batch is:  1.960768461227417\n",
      "The representation loss after processing this batch is:  0.011260747909545898\n",
      "\n",
      "The classification loss after processing this batch is:  2.0183210372924805\n",
      "The representation loss after processing this batch is:  0.011524423956871033\n",
      "\n",
      "The classification loss after processing this batch is:  1.9970142841339111\n",
      "The representation loss after processing this batch is:  0.013002008199691772\n",
      "\n",
      "The classification loss after processing this batch is:  1.942984700202942\n",
      "The representation loss after processing this batch is:  0.01560521125793457\n",
      "\n",
      "The classification loss after processing this batch is:  1.9683459997177124\n",
      "The representation loss after processing this batch is:  0.010559767484664917\n",
      "\n",
      "The classification loss after processing this batch is:  1.9384198188781738\n",
      "The representation loss after processing this batch is:  0.014804840087890625\n",
      "\n",
      "The classification loss after processing this batch is:  1.8992186784744263\n",
      "The representation loss after processing this batch is:  0.013037621974945068\n",
      "\n",
      "The classification loss after processing this batch is:  1.947083592414856\n",
      "The representation loss after processing this batch is:  0.01097080111503601\n",
      "\n",
      "The classification loss after processing this batch is:  1.9475305080413818\n",
      "The representation loss after processing this batch is:  0.009920701384544373\n",
      "\n",
      "The classification loss after processing this batch is:  1.903077244758606\n",
      "The representation loss after processing this batch is:  0.011631712317466736\n",
      "\n",
      "The classification loss after processing this batch is:  1.9286607503890991\n",
      "The representation loss after processing this batch is:  0.010476306080818176\n",
      "\n",
      "The classification loss after processing this batch is:  1.842599630355835\n",
      "The representation loss after processing this batch is:  0.009702667593955994\n",
      "\n",
      "The classification loss after processing this batch is:  1.8827502727508545\n",
      "The representation loss after processing this batch is:  0.009117498993873596\n",
      "\n",
      "The classification loss after processing this batch is:  1.8744032382965088\n",
      "The representation loss after processing this batch is:  0.008638247847557068\n",
      "\n",
      "The classification loss after processing this batch is:  1.8864109516143799\n",
      "The representation loss after processing this batch is:  0.009143009781837463\n",
      "\n",
      "The classification loss after processing this batch is:  1.8142074346542358\n",
      "The representation loss after processing this batch is:  0.00837661325931549\n",
      "\n",
      "The classification loss after processing this batch is:  1.8271690607070923\n",
      "The representation loss after processing this batch is:  0.012407690286636353\n",
      "\n",
      "The classification loss after processing this batch is:  1.8869203329086304\n",
      "The representation loss after processing this batch is:  0.011434465646743774\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  1.920264482498169\n",
      "The representation loss after processing this batch is:  0.010343819856643677\n",
      "\n",
      "The classification loss after processing this batch is:  1.87166428565979\n",
      "The representation loss after processing this batch is:  0.010343357920646667\n",
      "\n",
      "The classification loss after processing this batch is:  1.8795208930969238\n",
      "The representation loss after processing this batch is:  0.009350091218948364\n",
      "\n",
      "The classification loss after processing this batch is:  1.9562705755233765\n",
      "The representation loss after processing this batch is:  0.009449213743209839\n",
      "\n",
      "The classification loss after processing this batch is:  1.868042230606079\n",
      "The representation loss after processing this batch is:  0.008636385202407837\n",
      "\n",
      "The classification loss after processing this batch is:  1.7994238138198853\n",
      "The representation loss after processing this batch is:  0.008538365364074707\n",
      "\n",
      "The classification loss after processing this batch is:  1.869121789932251\n",
      "The representation loss after processing this batch is:  0.007862180471420288\n",
      "\n",
      "The classification loss after processing this batch is:  1.8568426370620728\n",
      "The representation loss after processing this batch is:  0.009240567684173584\n",
      "\n",
      "The classification loss after processing this batch is:  1.8696953058242798\n",
      "The representation loss after processing this batch is:  0.008440598845481873\n",
      "\n",
      "The classification loss after processing this batch is:  1.8352243900299072\n",
      "The representation loss after processing this batch is:  0.008662089705467224\n",
      "\n",
      "The classification loss after processing this batch is:  1.8834177255630493\n",
      "The representation loss after processing this batch is:  0.010011836886405945\n",
      "\n",
      "The classification loss after processing this batch is:  1.7849559783935547\n",
      "The representation loss after processing this batch is:  0.008427083492279053\n",
      "\n",
      "The classification loss after processing this batch is:  1.7620590925216675\n",
      "The representation loss after processing this batch is:  0.00964316725730896\n",
      "\n",
      "The classification loss after processing this batch is:  1.7026679515838623\n",
      "The representation loss after processing this batch is:  0.00879301130771637\n",
      "\n",
      "The classification loss after processing this batch is:  1.806328296661377\n",
      "The representation loss after processing this batch is:  0.009721383452415466\n",
      "\n",
      "The classification loss after processing this batch is:  1.764216661453247\n",
      "The representation loss after processing this batch is:  0.012182950973510742\n",
      "\n",
      "The classification loss after processing this batch is:  1.6901730298995972\n",
      "The representation loss after processing this batch is:  0.009428352117538452\n",
      "\n",
      "The classification loss after processing this batch is:  1.7626529932022095\n",
      "The representation loss after processing this batch is:  0.010690480470657349\n",
      "\n",
      "The classification loss after processing this batch is:  1.7920440435409546\n",
      "The representation loss after processing this batch is:  0.009326621890068054\n",
      "\n",
      "The classification loss after processing this batch is:  1.8431031703948975\n",
      "The representation loss after processing this batch is:  0.008990690112113953\n",
      "\n",
      "The classification loss after processing this batch is:  1.6926742792129517\n",
      "The representation loss after processing this batch is:  0.010207071900367737\n",
      "\n",
      "The classification loss after processing this batch is:  1.7872931957244873\n",
      "The representation loss after processing this batch is:  0.009739771485328674\n",
      "\n",
      "The classification loss after processing this batch is:  1.7955766916275024\n",
      "The representation loss after processing this batch is:  0.011375024914741516\n",
      "\n",
      "The classification loss after processing this batch is:  1.8034894466400146\n",
      "The representation loss after processing this batch is:  0.01052778959274292\n",
      "\n",
      "The classification loss after processing this batch is:  1.6701524257659912\n",
      "The representation loss after processing this batch is:  0.010354503989219666\n",
      "\n",
      "The classification loss after processing this batch is:  1.7621055841445923\n",
      "The representation loss after processing this batch is:  0.00756971538066864\n",
      "\n",
      "The classification loss after processing this batch is:  1.7315154075622559\n",
      "The representation loss after processing this batch is:  0.008698821067810059\n",
      "\n",
      "The classification loss after processing this batch is:  1.7085367441177368\n",
      "The representation loss after processing this batch is:  0.008553087711334229\n",
      "\n",
      "The classification loss after processing this batch is:  1.7099307775497437\n",
      "The representation loss after processing this batch is:  0.010852202773094177\n",
      "\n",
      "The classification loss after processing this batch is:  1.6899821758270264\n",
      "The representation loss after processing this batch is:  0.007316768169403076\n",
      "\n",
      "The classification loss after processing this batch is:  1.7536025047302246\n",
      "The representation loss after processing this batch is:  0.00851084291934967\n",
      "\n",
      "The classification loss after processing this batch is:  1.631839394569397\n",
      "The representation loss after processing this batch is:  0.009335622191429138\n",
      "\n",
      "The classification loss after processing this batch is:  1.7164804935455322\n",
      "The representation loss after processing this batch is:  0.009227797389030457\n",
      "\n",
      "The classification loss after processing this batch is:  1.8227717876434326\n",
      "The representation loss after processing this batch is:  0.007395729422569275\n",
      "\n",
      "The classification loss after processing this batch is:  1.772221326828003\n",
      "The representation loss after processing this batch is:  0.007998660206794739\n",
      "\n",
      "The classification loss after processing this batch is:  1.5700600147247314\n",
      "The representation loss after processing this batch is:  0.008120253682136536\n",
      "\n",
      "The classification loss after processing this batch is:  1.719378113746643\n",
      "The representation loss after processing this batch is:  0.007935822010040283\n",
      "\n",
      "The classification loss after processing this batch is:  1.7268588542938232\n",
      "The representation loss after processing this batch is:  0.008260130882263184\n",
      "\n",
      "The classification loss after processing this batch is:  1.6696518659591675\n",
      "The representation loss after processing this batch is:  0.007477611303329468\n",
      "\n",
      "The classification loss after processing this batch is:  1.643191933631897\n",
      "The representation loss after processing this batch is:  0.00974862277507782\n",
      "\n",
      "The classification loss after processing this batch is:  1.6754425764083862\n",
      "The representation loss after processing this batch is:  0.009659543633460999\n",
      "\n",
      "The classification loss after processing this batch is:  1.677628755569458\n",
      "The representation loss after processing this batch is:  0.011807665228843689\n",
      "\n",
      "The classification loss after processing this batch is:  1.7880488634109497\n",
      "The representation loss after processing this batch is:  0.008464142680168152\n",
      "\n",
      "The classification loss after processing this batch is:  1.5739021301269531\n",
      "The representation loss after processing this batch is:  0.007143065333366394\n",
      "\n",
      "The classification loss after processing this batch is:  1.6245096921920776\n",
      "The representation loss after processing this batch is:  0.00759182870388031\n",
      "\n",
      "The classification loss after processing this batch is:  1.6197139024734497\n",
      "The representation loss after processing this batch is:  0.007352083921432495\n",
      "\n",
      "The classification loss after processing this batch is:  1.7199530601501465\n",
      "The representation loss after processing this batch is:  0.007904782891273499\n",
      "\n",
      "The classification loss after processing this batch is:  1.5659193992614746\n",
      "The representation loss after processing this batch is:  0.007468476891517639\n",
      "\n",
      "The classification loss after processing this batch is:  1.6259610652923584\n",
      "The representation loss after processing this batch is:  0.008337438106536865\n",
      "\n",
      "The classification loss after processing this batch is:  1.7165405750274658\n",
      "The representation loss after processing this batch is:  0.008217588067054749\n",
      "\n",
      "The classification loss after processing this batch is:  1.5801974534988403\n",
      "The representation loss after processing this batch is:  0.007866188883781433\n",
      "\n",
      "The classification loss after processing this batch is:  1.5313770771026611\n",
      "The representation loss after processing this batch is:  0.007947593927383423\n",
      "\n",
      "The classification loss after processing this batch is:  1.6637990474700928\n",
      "The representation loss after processing this batch is:  0.007633015513420105\n",
      "\n",
      "The classification loss after processing this batch is:  1.505915880203247\n",
      "The representation loss after processing this batch is:  0.00828416645526886\n",
      "\n",
      "The classification loss after processing this batch is:  1.6374320983886719\n",
      "The representation loss after processing this batch is:  0.007615536451339722\n",
      "\n",
      "The classification loss after processing this batch is:  1.6486815214157104\n",
      "The representation loss after processing this batch is:  0.008438855409622192\n",
      "\n",
      "The classification loss after processing this batch is:  1.6877163648605347\n",
      "The representation loss after processing this batch is:  0.007295593619346619\n",
      "\n",
      "The classification loss after processing this batch is:  1.630198359489441\n",
      "The representation loss after processing this batch is:  0.007674567401409149\n",
      "\n",
      "The classification loss after processing this batch is:  1.7019336223602295\n",
      "The representation loss after processing this batch is:  0.007466152310371399\n",
      "\n",
      "The classification loss after processing this batch is:  1.6133426427841187\n",
      "The representation loss after processing this batch is:  0.009159065783023834\n",
      "\n",
      "The classification loss after processing this batch is:  1.607585072517395\n",
      "The representation loss after processing this batch is:  0.007536560297012329\n",
      "\n",
      "The classification loss after processing this batch is:  1.590152621269226\n",
      "The representation loss after processing this batch is:  0.008038043975830078\n",
      "\n",
      "The classification loss after processing this batch is:  1.6387985944747925\n",
      "The representation loss after processing this batch is:  0.007985599339008331\n",
      "\n",
      "The classification loss after processing this batch is:  1.5698833465576172\n",
      "The representation loss after processing this batch is:  0.008484721183776855\n",
      "\n",
      "The classification loss after processing this batch is:  1.6209464073181152\n",
      "The representation loss after processing this batch is:  0.008002549409866333\n",
      "\n",
      "The classification loss after processing this batch is:  1.4537845849990845\n",
      "The representation loss after processing this batch is:  0.00835912674665451\n",
      "\n",
      "The classification loss after processing this batch is:  1.611686110496521\n",
      "The representation loss after processing this batch is:  0.008054539561271667\n",
      "\n",
      "The classification loss after processing this batch is:  1.7293275594711304\n",
      "The representation loss after processing this batch is:  0.008284792304039001\n",
      "\n",
      "The classification loss after processing this batch is:  1.6861941814422607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.00855591893196106\n",
      "\n",
      "The classification loss after processing this batch is:  1.5752123594284058\n",
      "The representation loss after processing this batch is:  0.00755879282951355\n",
      "\n",
      "The classification loss after processing this batch is:  1.6637749671936035\n",
      "The representation loss after processing this batch is:  0.007704630494117737\n",
      "\n",
      "The classification loss after processing this batch is:  1.6456717252731323\n",
      "The representation loss after processing this batch is:  0.006956204771995544\n",
      "\n",
      "The classification loss after processing this batch is:  1.6030638217926025\n",
      "The representation loss after processing this batch is:  0.008535295724868774\n",
      "\n",
      "The classification loss after processing this batch is:  1.6609052419662476\n",
      "The representation loss after processing this batch is:  0.006873533129692078\n",
      "\n",
      "The classification loss after processing this batch is:  1.5692542791366577\n",
      "The representation loss after processing this batch is:  0.008014723658561707\n",
      "\n",
      "The classification loss after processing this batch is:  1.5141348838806152\n",
      "The representation loss after processing this batch is:  0.008193597197532654\n",
      "\n",
      "The classification loss after processing this batch is:  1.5145385265350342\n",
      "The representation loss after processing this batch is:  0.00730162113904953\n",
      "\n",
      "The classification loss after processing this batch is:  1.5027143955230713\n",
      "The representation loss after processing this batch is:  0.0075345635414123535\n",
      "\n",
      "The classification loss after processing this batch is:  1.7347888946533203\n",
      "The representation loss after processing this batch is:  0.007038332521915436\n",
      "\n",
      "The classification loss after processing this batch is:  1.726285457611084\n",
      "The representation loss after processing this batch is:  0.008152320981025696\n",
      "\n",
      "The classification loss after processing this batch is:  1.6732001304626465\n",
      "The representation loss after processing this batch is:  0.006750963628292084\n",
      "\n",
      "The classification loss after processing this batch is:  1.6169339418411255\n",
      "The representation loss after processing this batch is:  0.006668895483016968\n",
      "\n",
      "The classification loss after processing this batch is:  1.6597903966903687\n",
      "The representation loss after processing this batch is:  0.0074165090918540955\n",
      "\n",
      "The classification loss after processing this batch is:  1.5928343534469604\n",
      "The representation loss after processing this batch is:  0.0070933327078819275\n",
      "\n",
      "The classification loss after processing this batch is:  1.5532807111740112\n",
      "The representation loss after processing this batch is:  0.007005646824836731\n",
      "\n",
      "The classification loss after processing this batch is:  1.626973032951355\n",
      "The representation loss after processing this batch is:  0.007519960403442383\n",
      "\n",
      "The classification loss after processing this batch is:  1.454114317893982\n",
      "The representation loss after processing this batch is:  0.00780554860830307\n",
      "\n",
      "The classification loss after processing this batch is:  1.3749428987503052\n",
      "The representation loss after processing this batch is:  0.006508208811283112\n",
      "\n",
      "The classification loss after processing this batch is:  1.4572374820709229\n",
      "The representation loss after processing this batch is:  0.006402336061000824\n",
      "\n",
      "The classification loss after processing this batch is:  1.4867912530899048\n",
      "The representation loss after processing this batch is:  0.0072365254163742065\n",
      "\n",
      "The classification loss after processing this batch is:  1.5230695009231567\n",
      "The representation loss after processing this batch is:  0.008181579411029816\n",
      "\n",
      "The classification loss after processing this batch is:  1.4874558448791504\n",
      "The representation loss after processing this batch is:  0.008640177547931671\n",
      "\n",
      "The classification loss after processing this batch is:  1.4882922172546387\n",
      "The representation loss after processing this batch is:  0.0077107250690460205\n",
      "\n",
      "The classification loss after processing this batch is:  1.4503166675567627\n",
      "The representation loss after processing this batch is:  0.0077357664704322815\n",
      "\n",
      "The classification loss after processing this batch is:  1.5153346061706543\n",
      "The representation loss after processing this batch is:  0.008970528841018677\n",
      "\n",
      "The classification loss after processing this batch is:  1.582882046699524\n",
      "The representation loss after processing this batch is:  0.007973939180374146\n",
      "\n",
      "The classification loss after processing this batch is:  1.5659656524658203\n",
      "The representation loss after processing this batch is:  0.007148735225200653\n",
      "\n",
      "The classification loss after processing this batch is:  1.4520072937011719\n",
      "The representation loss after processing this batch is:  0.005905017256736755\n",
      "\n",
      "The classification loss after processing this batch is:  1.4419316053390503\n",
      "The representation loss after processing this batch is:  0.006571874022483826\n",
      "\n",
      "The classification loss after processing this batch is:  1.5609537363052368\n",
      "The representation loss after processing this batch is:  0.007324308156967163\n",
      "\n",
      "The classification loss after processing this batch is:  1.4804707765579224\n",
      "The representation loss after processing this batch is:  0.006713353097438812\n",
      "\n",
      "The classification loss after processing this batch is:  1.507012963294983\n",
      "The representation loss after processing this batch is:  0.006821736693382263\n",
      "\n",
      "The classification loss after processing this batch is:  1.6388695240020752\n",
      "The representation loss after processing this batch is:  0.007944777607917786\n",
      "\n",
      "The classification loss after processing this batch is:  1.4365073442459106\n",
      "The representation loss after processing this batch is:  0.007259592413902283\n",
      "\n",
      "The classification loss after processing this batch is:  1.3352049589157104\n",
      "The representation loss after processing this batch is:  0.008038744330406189\n",
      "\n",
      "The classification loss after processing this batch is:  1.5609050989151\n",
      "The representation loss after processing this batch is:  0.008881114423274994\n",
      "\n",
      "The classification loss after processing this batch is:  1.5250189304351807\n",
      "The representation loss after processing this batch is:  0.008729323744773865\n",
      "\n",
      "The classification loss after processing this batch is:  1.622546911239624\n",
      "The representation loss after processing this batch is:  0.009049810469150543\n",
      "\n",
      "The classification loss after processing this batch is:  1.4806383848190308\n",
      "The representation loss after processing this batch is:  0.007551558315753937\n",
      "\n",
      "The classification loss after processing this batch is:  1.5036544799804688\n",
      "The representation loss after processing this batch is:  0.009037628769874573\n",
      "\n",
      "The classification loss after processing this batch is:  1.40733003616333\n",
      "The representation loss after processing this batch is:  0.006650857627391815\n",
      "\n",
      "The classification loss after processing this batch is:  1.3534541130065918\n",
      "The representation loss after processing this batch is:  0.006209857761859894\n",
      "\n",
      "The classification loss after processing this batch is:  1.268473505973816\n",
      "The representation loss after processing this batch is:  0.008014887571334839\n",
      "\n",
      "The classification loss after processing this batch is:  1.3024767637252808\n",
      "The representation loss after processing this batch is:  0.008101820945739746\n",
      "\n",
      "The classification loss after processing this batch is:  1.4536526203155518\n",
      "The representation loss after processing this batch is:  0.007518552243709564\n",
      "\n",
      "The classification loss after processing this batch is:  1.3719465732574463\n",
      "The representation loss after processing this batch is:  0.0070992931723594666\n",
      "\n",
      "The classification loss after processing this batch is:  1.3882498741149902\n",
      "The representation loss after processing this batch is:  0.007730215787887573\n",
      "\n",
      "The classification loss after processing this batch is:  1.2837575674057007\n",
      "The representation loss after processing this batch is:  0.007877446711063385\n",
      "\n",
      "The classification loss after processing this batch is:  1.277779459953308\n",
      "The representation loss after processing this batch is:  0.009039126336574554\n",
      "\n",
      "The classification loss after processing this batch is:  1.4226065874099731\n",
      "The representation loss after processing this batch is:  0.00869811326265335\n",
      "\n",
      "The classification loss after processing this batch is:  1.2796690464019775\n",
      "The representation loss after processing this batch is:  0.00717674195766449\n",
      "\n",
      "The classification loss after processing this batch is:  1.3468854427337646\n",
      "The representation loss after processing this batch is:  0.008510097861289978\n",
      "\n",
      "The classification loss after processing this batch is:  1.2652583122253418\n",
      "The representation loss after processing this batch is:  0.00749429315328598\n",
      "\n",
      "The classification loss after processing this batch is:  1.3237782716751099\n",
      "The representation loss after processing this batch is:  0.00720900297164917\n",
      "\n",
      "The classification loss after processing this batch is:  1.3248565196990967\n",
      "The representation loss after processing this batch is:  0.00832781195640564\n",
      "\n",
      "The classification loss after processing this batch is:  1.6094324588775635\n",
      "The representation loss after processing this batch is:  0.008070096373558044\n",
      "\n",
      "The classification loss after processing this batch is:  1.445562720298767\n",
      "The representation loss after processing this batch is:  0.00940065085887909\n",
      "\n",
      "The classification loss after processing this batch is:  1.4593771696090698\n",
      "The representation loss after processing this batch is:  0.007329411804676056\n",
      "\n",
      "The classification loss after processing this batch is:  1.3993637561798096\n",
      "The representation loss after processing this batch is:  0.0056371018290519714\n",
      "\n",
      "The classification loss after processing this batch is:  1.3642765283584595\n",
      "The representation loss after processing this batch is:  0.006413869559764862\n",
      "\n",
      "The classification loss after processing this batch is:  1.6188305616378784\n",
      "The representation loss after processing this batch is:  0.006375297904014587\n",
      "\n",
      "The classification loss after processing this batch is:  1.3159598112106323\n",
      "The representation loss after processing this batch is:  0.0069690123200416565\n",
      "\n",
      "The classification loss after processing this batch is:  1.4773831367492676\n",
      "The representation loss after processing this batch is:  0.006995663046836853\n",
      "\n",
      "The classification loss after processing this batch is:  1.2749308347702026\n",
      "The representation loss after processing this batch is:  0.0062418729066848755\n",
      "\n",
      "The classification loss after processing this batch is:  1.2335796356201172\n",
      "The representation loss after processing this batch is:  0.007105663418769836\n",
      "\n",
      "The classification loss after processing this batch is:  1.3192620277404785\n",
      "The representation loss after processing this batch is:  0.008630208671092987\n",
      "\n",
      "The classification loss after processing this batch is:  1.2406275272369385\n",
      "The representation loss after processing this batch is:  0.008013762533664703\n",
      "\n",
      "The classification loss after processing this batch is:  1.2693763971328735\n",
      "The representation loss after processing this batch is:  0.007271304726600647\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  1.2145925760269165\n",
      "The representation loss after processing this batch is:  0.00673520565032959\n",
      "\n",
      "The classification loss after processing this batch is:  1.1593966484069824\n",
      "The representation loss after processing this batch is:  0.007650889456272125\n",
      "\n",
      "The classification loss after processing this batch is:  1.2576487064361572\n",
      "The representation loss after processing this batch is:  0.00726751983165741\n",
      "\n",
      "The classification loss after processing this batch is:  1.224829912185669\n",
      "The representation loss after processing this batch is:  0.008306607604026794\n",
      "\n",
      "The classification loss after processing this batch is:  1.42558753490448\n",
      "The representation loss after processing this batch is:  0.007785633206367493\n",
      "\n",
      "The classification loss after processing this batch is:  1.472212314605713\n",
      "The representation loss after processing this batch is:  0.009179383516311646\n",
      "\n",
      "The classification loss after processing this batch is:  1.2930431365966797\n",
      "The representation loss after processing this batch is:  0.008458562195301056\n",
      "\n",
      "The classification loss after processing this batch is:  1.3622310161590576\n",
      "The representation loss after processing this batch is:  0.007779322564601898\n",
      "\n",
      "The classification loss after processing this batch is:  1.316997766494751\n",
      "The representation loss after processing this batch is:  0.007246091961860657\n",
      "\n",
      "The classification loss after processing this batch is:  1.3890501260757446\n",
      "The representation loss after processing this batch is:  0.007382594048976898\n",
      "\n",
      "The classification loss after processing this batch is:  1.2988879680633545\n",
      "The representation loss after processing this batch is:  0.006121799349784851\n",
      "\n",
      "The classification loss after processing this batch is:  1.4628819227218628\n",
      "The representation loss after processing this batch is:  0.007130704820156097\n",
      "\n",
      "The classification loss after processing this batch is:  1.299452543258667\n",
      "The representation loss after processing this batch is:  0.0062759071588516235\n",
      "\n",
      "The classification loss after processing this batch is:  1.314256191253662\n",
      "The representation loss after processing this batch is:  0.007312461733818054\n",
      "\n",
      "The classification loss after processing this batch is:  1.3359659910202026\n",
      "The representation loss after processing this batch is:  0.007412441074848175\n",
      "\n",
      "The classification loss after processing this batch is:  1.232627511024475\n",
      "The representation loss after processing this batch is:  0.007343396544456482\n",
      "\n",
      "The classification loss after processing this batch is:  1.3542065620422363\n",
      "The representation loss after processing this batch is:  0.0077423229813575745\n",
      "\n",
      "The classification loss after processing this batch is:  1.3917022943496704\n",
      "The representation loss after processing this batch is:  0.011010520160198212\n",
      "\n",
      "The classification loss after processing this batch is:  1.235406517982483\n",
      "The representation loss after processing this batch is:  0.007925570011138916\n",
      "\n",
      "The classification loss after processing this batch is:  1.3977344036102295\n",
      "The representation loss after processing this batch is:  0.008814290165901184\n",
      "\n",
      "The classification loss after processing this batch is:  1.3907744884490967\n",
      "The representation loss after processing this batch is:  0.007124572992324829\n",
      "\n",
      "The classification loss after processing this batch is:  1.3084784746170044\n",
      "The representation loss after processing this batch is:  0.006996117532253265\n",
      "\n",
      "The classification loss after processing this batch is:  1.230936884880066\n",
      "The representation loss after processing this batch is:  0.008241944015026093\n",
      "\n",
      "The classification loss after processing this batch is:  1.1957231760025024\n",
      "The representation loss after processing this batch is:  0.006328001618385315\n",
      "\n",
      "The classification loss after processing this batch is:  1.2075345516204834\n",
      "The representation loss after processing this batch is:  0.006193891167640686\n",
      "\n",
      "The classification loss after processing this batch is:  1.2629806995391846\n",
      "The representation loss after processing this batch is:  0.006158523261547089\n",
      "\n",
      "The classification loss after processing this batch is:  1.1255608797073364\n",
      "The representation loss after processing this batch is:  0.006757631897926331\n",
      "\n",
      "The classification loss after processing this batch is:  1.1075019836425781\n",
      "The representation loss after processing this batch is:  0.006205998361110687\n",
      "\n",
      "The classification loss after processing this batch is:  1.1482181549072266\n",
      "The representation loss after processing this batch is:  0.006745375692844391\n",
      "\n",
      "The classification loss after processing this batch is:  1.137580394744873\n",
      "The representation loss after processing this batch is:  0.00564323365688324\n",
      "\n",
      "The classification loss after processing this batch is:  1.1795190572738647\n",
      "The representation loss after processing this batch is:  0.006930798292160034\n",
      "\n",
      "The classification loss after processing this batch is:  1.2871994972229004\n",
      "The representation loss after processing this batch is:  0.006124503910541534\n",
      "\n",
      "The classification loss after processing this batch is:  1.2702383995056152\n",
      "The representation loss after processing this batch is:  0.0076895058155059814\n",
      "\n",
      "The classification loss after processing this batch is:  1.3095746040344238\n",
      "The representation loss after processing this batch is:  0.0057264938950538635\n",
      "\n",
      "The classification loss after processing this batch is:  1.0632294416427612\n",
      "The representation loss after processing this batch is:  0.0076454877853393555\n",
      "\n",
      "The classification loss after processing this batch is:  1.1484276056289673\n",
      "The representation loss after processing this batch is:  0.007602892816066742\n",
      "\n",
      "The classification loss after processing this batch is:  1.1908090114593506\n",
      "The representation loss after processing this batch is:  0.006850078701972961\n",
      "\n",
      "The classification loss after processing this batch is:  1.1598718166351318\n",
      "The representation loss after processing this batch is:  0.006791256368160248\n",
      "\n",
      "The classification loss after processing this batch is:  1.241194486618042\n",
      "The representation loss after processing this batch is:  0.00684085488319397\n",
      "\n",
      "The classification loss after processing this batch is:  1.1045899391174316\n",
      "The representation loss after processing this batch is:  0.005902126431465149\n",
      "\n",
      "The classification loss after processing this batch is:  1.1206284761428833\n",
      "The representation loss after processing this batch is:  0.006593629717826843\n",
      "\n",
      "The classification loss after processing this batch is:  1.2142633199691772\n",
      "The representation loss after processing this batch is:  0.006568893790245056\n",
      "\n",
      "The classification loss after processing this batch is:  1.2593992948532104\n",
      "The representation loss after processing this batch is:  0.0073544979095458984\n",
      "\n",
      "The classification loss after processing this batch is:  1.1538259983062744\n",
      "The representation loss after processing this batch is:  0.006422579288482666\n",
      "\n",
      "The classification loss after processing this batch is:  1.2277172803878784\n",
      "The representation loss after processing this batch is:  0.007024705410003662\n",
      "\n",
      "The classification loss after processing this batch is:  1.273300051689148\n",
      "The representation loss after processing this batch is:  0.0070456042885780334\n",
      "\n",
      "The classification loss after processing this batch is:  1.1177479028701782\n",
      "The representation loss after processing this batch is:  0.006096936762332916\n",
      "\n",
      "The classification loss after processing this batch is:  1.2652114629745483\n",
      "The representation loss after processing this batch is:  0.006591513752937317\n",
      "\n",
      "The classification loss after processing this batch is:  1.0505346059799194\n",
      "The representation loss after processing this batch is:  0.005961388349533081\n",
      "\n",
      "The classification loss after processing this batch is:  1.1121501922607422\n",
      "The representation loss after processing this batch is:  0.006130233407020569\n",
      "\n",
      "The classification loss after processing this batch is:  1.1946830749511719\n",
      "The representation loss after processing this batch is:  0.00557757169008255\n",
      "\n",
      "The classification loss after processing this batch is:  1.2340770959854126\n",
      "The representation loss after processing this batch is:  0.005257919430732727\n",
      "\n",
      "The classification loss after processing this batch is:  0.9885455965995789\n",
      "The representation loss after processing this batch is:  0.005543135106563568\n",
      "\n",
      "The classification loss after processing this batch is:  1.0821653604507446\n",
      "The representation loss after processing this batch is:  0.0061065927147865295\n",
      "\n",
      "The classification loss after processing this batch is:  0.9830443859100342\n",
      "The representation loss after processing this batch is:  0.004963099956512451\n",
      "\n",
      "The classification loss after processing this batch is:  1.1039481163024902\n",
      "The representation loss after processing this batch is:  0.007066085934638977\n",
      "\n",
      "The classification loss after processing this batch is:  1.1233408451080322\n",
      "The representation loss after processing this batch is:  0.005591399967670441\n",
      "\n",
      "The classification loss after processing this batch is:  1.2500795125961304\n",
      "The representation loss after processing this batch is:  0.009539812803268433\n",
      "\n",
      "The classification loss after processing this batch is:  1.3211935758590698\n",
      "The representation loss after processing this batch is:  0.007498115301132202\n",
      "\n",
      "The classification loss after processing this batch is:  1.1356662511825562\n",
      "The representation loss after processing this batch is:  0.005382247269153595\n",
      "\n",
      "The classification loss after processing this batch is:  1.098202109336853\n",
      "The representation loss after processing this batch is:  0.006406523287296295\n",
      "\n",
      "The classification loss after processing this batch is:  1.303483247756958\n",
      "The representation loss after processing this batch is:  0.006416626274585724\n",
      "\n",
      "The classification loss after processing this batch is:  1.114382266998291\n",
      "The representation loss after processing this batch is:  0.005470864474773407\n",
      "\n",
      "The classification loss after processing this batch is:  1.1771600246429443\n",
      "The representation loss after processing this batch is:  0.006745636463165283\n",
      "\n",
      "The classification loss after processing this batch is:  1.033737301826477\n",
      "The representation loss after processing this batch is:  0.005998097360134125\n",
      "\n",
      "The classification loss after processing this batch is:  1.0581332445144653\n",
      "The representation loss after processing this batch is:  0.006254062056541443\n",
      "\n",
      "The classification loss after processing this batch is:  1.0259218215942383\n",
      "The representation loss after processing this batch is:  0.006617635488510132\n",
      "\n",
      "The classification loss after processing this batch is:  1.2784894704818726\n",
      "The representation loss after processing this batch is:  0.00711783766746521\n",
      "\n",
      "The classification loss after processing this batch is:  1.0713268518447876\n",
      "The representation loss after processing this batch is:  0.005560852587223053\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.9711796045303345\n",
      "The representation loss after processing this batch is:  0.0065604448318481445\n",
      "\n",
      "The classification loss after processing this batch is:  1.1254234313964844\n",
      "The representation loss after processing this batch is:  0.005835697054862976\n",
      "\n",
      "The classification loss after processing this batch is:  1.074142575263977\n",
      "The representation loss after processing this batch is:  0.006791949272155762\n",
      "\n",
      "The classification loss after processing this batch is:  1.2126059532165527\n",
      "The representation loss after processing this batch is:  0.005660459399223328\n",
      "\n",
      "The classification loss after processing this batch is:  1.198702335357666\n",
      "The representation loss after processing this batch is:  0.006512239575386047\n",
      "\n",
      "The classification loss after processing this batch is:  1.215194821357727\n",
      "The representation loss after processing this batch is:  0.006140194833278656\n",
      "\n",
      "The classification loss after processing this batch is:  1.163514494895935\n",
      "The representation loss after processing this batch is:  0.0069930776953697205\n",
      "\n",
      "The classification loss after processing this batch is:  0.8881599307060242\n",
      "The representation loss after processing this batch is:  0.007283590734004974\n",
      "\n",
      "The classification loss after processing this batch is:  0.9850379824638367\n",
      "The representation loss after processing this batch is:  0.006496593356132507\n",
      "\n",
      "The classification loss after processing this batch is:  0.9733321666717529\n",
      "The representation loss after processing this batch is:  0.0071787238121032715\n",
      "\n",
      "The classification loss after processing this batch is:  0.9468697905540466\n",
      "The representation loss after processing this batch is:  0.00603465735912323\n",
      "\n",
      "The classification loss after processing this batch is:  1.0720105171203613\n",
      "The representation loss after processing this batch is:  0.0073839277029037476\n",
      "\n",
      "The classification loss after processing this batch is:  1.07021164894104\n",
      "The representation loss after processing this batch is:  0.006420433521270752\n",
      "\n",
      "The classification loss after processing this batch is:  1.1292675733566284\n",
      "The representation loss after processing this batch is:  0.006247498095035553\n",
      "\n",
      "The classification loss after processing this batch is:  1.0560070276260376\n",
      "The representation loss after processing this batch is:  0.006490379571914673\n",
      "\n",
      "The classification loss after processing this batch is:  1.013851284980774\n",
      "The representation loss after processing this batch is:  0.006627991795539856\n",
      "\n",
      "The classification loss after processing this batch is:  0.9705013036727905\n",
      "The representation loss after processing this batch is:  0.00843251496553421\n",
      "\n",
      "The classification loss after processing this batch is:  1.0708470344543457\n",
      "The representation loss after processing this batch is:  0.006185412406921387\n",
      "\n",
      "The classification loss after processing this batch is:  0.9243444800376892\n",
      "The representation loss after processing this batch is:  0.005631931126117706\n",
      "\n",
      "The classification loss after processing this batch is:  0.9449487328529358\n",
      "The representation loss after processing this batch is:  0.006254531443119049\n",
      "\n",
      "The classification loss after processing this batch is:  0.9968166351318359\n",
      "The representation loss after processing this batch is:  0.00724724680185318\n",
      "\n",
      "The classification loss after processing this batch is:  0.8892878890037537\n",
      "The representation loss after processing this batch is:  0.005249828100204468\n",
      "\n",
      "The classification loss after processing this batch is:  0.9270631074905396\n",
      "The representation loss after processing this batch is:  0.006088040769100189\n",
      "\n",
      "The classification loss after processing this batch is:  0.979206383228302\n",
      "The representation loss after processing this batch is:  0.0069060251116752625\n",
      "\n",
      "The classification loss after processing this batch is:  1.1145066022872925\n",
      "The representation loss after processing this batch is:  0.00775841623544693\n",
      "\n",
      "The classification loss after processing this batch is:  1.0295474529266357\n",
      "The representation loss after processing this batch is:  0.007573656737804413\n",
      "\n",
      "The classification loss after processing this batch is:  1.0544418096542358\n",
      "The representation loss after processing this batch is:  0.0062978193163871765\n",
      "\n",
      "The classification loss after processing this batch is:  1.204890489578247\n",
      "The representation loss after processing this batch is:  0.0075865089893341064\n",
      "\n",
      "The classification loss after processing this batch is:  0.8930221796035767\n",
      "The representation loss after processing this batch is:  0.00695984810590744\n",
      "\n",
      "The classification loss after processing this batch is:  1.0106494426727295\n",
      "The representation loss after processing this batch is:  0.006396286189556122\n",
      "\n",
      "The classification loss after processing this batch is:  1.198968768119812\n",
      "The representation loss after processing this batch is:  0.0071573033928871155\n",
      "\n",
      "The classification loss after processing this batch is:  1.3386863470077515\n",
      "The representation loss after processing this batch is:  0.00737491250038147\n",
      "\n",
      "The classification loss after processing this batch is:  1.2031590938568115\n",
      "The representation loss after processing this batch is:  0.006554946303367615\n",
      "\n",
      "The classification loss after processing this batch is:  1.1654865741729736\n",
      "The representation loss after processing this batch is:  0.005865179002285004\n",
      "\n",
      "The classification loss after processing this batch is:  1.023993730545044\n",
      "The representation loss after processing this batch is:  0.004909411072731018\n",
      "\n",
      "The classification loss after processing this batch is:  1.0538090467453003\n",
      "The representation loss after processing this batch is:  0.0047097280621528625\n",
      "\n",
      "The classification loss after processing this batch is:  1.0943289995193481\n",
      "The representation loss after processing this batch is:  0.005965597927570343\n",
      "\n",
      "The classification loss after processing this batch is:  1.0360310077667236\n",
      "The representation loss after processing this batch is:  0.005411967635154724\n",
      "\n",
      "The classification loss after processing this batch is:  0.9848682284355164\n",
      "The representation loss after processing this batch is:  0.006326362490653992\n",
      "\n",
      "The classification loss after processing this batch is:  1.031935453414917\n",
      "The representation loss after processing this batch is:  0.006352290511131287\n",
      "\n",
      "The classification loss after processing this batch is:  1.0362714529037476\n",
      "The representation loss after processing this batch is:  0.006179474294185638\n",
      "\n",
      "The classification loss after processing this batch is:  0.9446084499359131\n",
      "The representation loss after processing this batch is:  0.006197281181812286\n",
      "\n",
      "The classification loss after processing this batch is:  0.9689807295799255\n",
      "The representation loss after processing this batch is:  0.006220705807209015\n",
      "\n",
      "The classification loss after processing this batch is:  0.9040089249610901\n",
      "The representation loss after processing this batch is:  0.005986012518405914\n",
      "\n",
      "The classification loss after processing this batch is:  0.8653728365898132\n",
      "The representation loss after processing this batch is:  0.005600638687610626\n",
      "\n",
      "The classification loss after processing this batch is:  0.8909590244293213\n",
      "The representation loss after processing this batch is:  0.006173528730869293\n",
      "\n",
      "The classification loss after processing this batch is:  1.0280301570892334\n",
      "The representation loss after processing this batch is:  0.006024248898029327\n",
      "\n",
      "The classification loss after processing this batch is:  0.8922720551490784\n",
      "The representation loss after processing this batch is:  0.007037647068500519\n",
      "\n",
      "The classification loss after processing this batch is:  0.9553312063217163\n",
      "The representation loss after processing this batch is:  0.005531683564186096\n",
      "\n",
      "The classification loss after processing this batch is:  0.9818207025527954\n",
      "The representation loss after processing this batch is:  0.007486164569854736\n",
      "\n",
      "The classification loss after processing this batch is:  1.0799626111984253\n",
      "The representation loss after processing this batch is:  0.007218196988105774\n",
      "\n",
      "The classification loss after processing this batch is:  1.0571954250335693\n",
      "The representation loss after processing this batch is:  0.008111931383609772\n",
      "\n",
      "The classification loss after processing this batch is:  0.9592909216880798\n",
      "The representation loss after processing this batch is:  0.0062050484120845795\n",
      "\n",
      "The classification loss after processing this batch is:  0.9467605948448181\n",
      "The representation loss after processing this batch is:  0.0063848793506622314\n",
      "\n",
      "The classification loss after processing this batch is:  0.9177000522613525\n",
      "The representation loss after processing this batch is:  0.006311282515525818\n",
      "\n",
      "The classification loss after processing this batch is:  0.9048275351524353\n",
      "The representation loss after processing this batch is:  0.006106279790401459\n",
      "\n",
      "The classification loss after processing this batch is:  0.9760138988494873\n",
      "The representation loss after processing this batch is:  0.005822673439979553\n",
      "\n",
      "The classification loss after processing this batch is:  0.9270157217979431\n",
      "The representation loss after processing this batch is:  0.0061802938580513\n",
      "\n",
      "The classification loss after processing this batch is:  0.7826398015022278\n",
      "The representation loss after processing this batch is:  0.005533963441848755\n",
      "\n",
      "The classification loss after processing this batch is:  0.9734658598899841\n",
      "The representation loss after processing this batch is:  0.005794346332550049\n",
      "\n",
      "The classification loss after processing this batch is:  1.1244518756866455\n",
      "The representation loss after processing this batch is:  0.0060582831501960754\n",
      "\n",
      "The classification loss after processing this batch is:  0.9409508109092712\n",
      "The representation loss after processing this batch is:  0.006407931447029114\n",
      "\n",
      "The classification loss after processing this batch is:  1.0004124641418457\n",
      "The representation loss after processing this batch is:  0.006182022392749786\n",
      "\n",
      "The classification loss after processing this batch is:  0.9386528730392456\n",
      "The representation loss after processing this batch is:  0.00613083690404892\n",
      "\n",
      "The classification loss after processing this batch is:  0.979631245136261\n",
      "The representation loss after processing this batch is:  0.006234399974346161\n",
      "\n",
      "The classification loss after processing this batch is:  0.86360764503479\n",
      "The representation loss after processing this batch is:  0.006237223744392395\n",
      "\n",
      "The classification loss after processing this batch is:  0.9865804314613342\n",
      "The representation loss after processing this batch is:  0.005044713616371155\n",
      "\n",
      "The classification loss after processing this batch is:  1.054306983947754\n",
      "The representation loss after processing this batch is:  0.005828924477100372\n",
      "\n",
      "The classification loss after processing this batch is:  1.104135513305664\n",
      "The representation loss after processing this batch is:  0.006375059485435486\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.9689480066299438\n",
      "The representation loss after processing this batch is:  0.006605528295040131\n",
      "\n",
      "The classification loss after processing this batch is:  0.9171541929244995\n",
      "The representation loss after processing this batch is:  0.006029855459928513\n",
      "\n",
      "The classification loss after processing this batch is:  0.8475178480148315\n",
      "The representation loss after processing this batch is:  0.006571829319000244\n",
      "\n",
      "The classification loss after processing this batch is:  0.859370768070221\n",
      "The representation loss after processing this batch is:  0.005405552685260773\n",
      "\n",
      "The classification loss after processing this batch is:  0.7967987656593323\n",
      "The representation loss after processing this batch is:  0.0057340338826179504\n",
      "\n",
      "The classification loss after processing this batch is:  0.8246837854385376\n",
      "The representation loss after processing this batch is:  0.006485573947429657\n",
      "\n",
      "The classification loss after processing this batch is:  0.8470079898834229\n",
      "The representation loss after processing this batch is:  0.00662463903427124\n",
      "\n",
      "The classification loss after processing this batch is:  0.7845144271850586\n",
      "The representation loss after processing this batch is:  0.006583742797374725\n",
      "\n",
      "The classification loss after processing this batch is:  0.9317730665206909\n",
      "The representation loss after processing this batch is:  0.0056791752576828\n",
      "\n",
      "The classification loss after processing this batch is:  0.8730047941207886\n",
      "The representation loss after processing this batch is:  0.005653344094753265\n",
      "\n",
      "The classification loss after processing this batch is:  0.7659889459609985\n",
      "The representation loss after processing this batch is:  0.005652248859405518\n",
      "\n",
      "The classification loss after processing this batch is:  0.8282915949821472\n",
      "The representation loss after processing this batch is:  0.0063569918274879456\n",
      "\n",
      "The classification loss after processing this batch is:  0.7038299441337585\n",
      "The representation loss after processing this batch is:  0.00600123405456543\n",
      "\n",
      "The classification loss after processing this batch is:  0.796573281288147\n",
      "The representation loss after processing this batch is:  0.006583370268344879\n",
      "\n",
      "The classification loss after processing this batch is:  0.8816332221031189\n",
      "The representation loss after processing this batch is:  0.0062063708901405334\n",
      "\n",
      "The classification loss after processing this batch is:  0.6565930843353271\n",
      "The representation loss after processing this batch is:  0.006357051432132721\n",
      "\n",
      "The classification loss after processing this batch is:  0.7759746313095093\n",
      "The representation loss after processing this batch is:  0.0056806281208992004\n",
      "\n",
      "The classification loss after processing this batch is:  0.8549737334251404\n",
      "The representation loss after processing this batch is:  0.007628440856933594\n",
      "\n",
      "The classification loss after processing this batch is:  0.8411476612091064\n",
      "The representation loss after processing this batch is:  0.00783500075340271\n",
      "\n",
      "The classification loss after processing this batch is:  0.8757351636886597\n",
      "The representation loss after processing this batch is:  0.006082609295845032\n",
      "\n",
      "The classification loss after processing this batch is:  0.790147602558136\n",
      "The representation loss after processing this batch is:  0.005733750760555267\n",
      "\n",
      "The classification loss after processing this batch is:  0.7141650319099426\n",
      "The representation loss after processing this batch is:  0.005394794046878815\n",
      "\n",
      "The classification loss after processing this batch is:  0.8065208196640015\n",
      "The representation loss after processing this batch is:  0.005602747201919556\n",
      "\n",
      "The classification loss after processing this batch is:  0.7921286225318909\n",
      "The representation loss after processing this batch is:  0.0055114105343818665\n",
      "\n",
      "The classification loss after processing this batch is:  0.775514543056488\n",
      "The representation loss after processing this batch is:  0.006169259548187256\n",
      "\n",
      "The classification loss after processing this batch is:  0.8371300101280212\n",
      "The representation loss after processing this batch is:  0.0060539208352565765\n",
      "\n",
      "The classification loss after processing this batch is:  0.9403648972511292\n",
      "The representation loss after processing this batch is:  0.006676636636257172\n",
      "\n",
      "The classification loss after processing this batch is:  0.8955560922622681\n",
      "The representation loss after processing this batch is:  0.006837226450443268\n",
      "\n",
      "The classification loss after processing this batch is:  0.7729291319847107\n",
      "The representation loss after processing this batch is:  0.006543517112731934\n",
      "\n",
      "The classification loss after processing this batch is:  0.8177662491798401\n",
      "The representation loss after processing this batch is:  0.0075529515743255615\n",
      "\n",
      "The classification loss after processing this batch is:  0.9044151306152344\n",
      "The representation loss after processing this batch is:  0.006328519433736801\n",
      "\n",
      "The classification loss after processing this batch is:  0.819625198841095\n",
      "The representation loss after processing this batch is:  0.006917189806699753\n",
      "\n",
      "The classification loss after processing this batch is:  0.9951216578483582\n",
      "The representation loss after processing this batch is:  0.007045097649097443\n",
      "\n",
      "The classification loss after processing this batch is:  0.8657904863357544\n",
      "The representation loss after processing this batch is:  0.006383121013641357\n",
      "\n",
      "The classification loss after processing this batch is:  0.9558064341545105\n",
      "The representation loss after processing this batch is:  0.007496796548366547\n",
      "\n",
      "The classification loss after processing this batch is:  0.807505190372467\n",
      "The representation loss after processing this batch is:  0.006336994469165802\n",
      "\n",
      "The classification loss after processing this batch is:  0.7535971403121948\n",
      "The representation loss after processing this batch is:  0.005712956190109253\n",
      "\n",
      "The classification loss after processing this batch is:  0.7672303915023804\n",
      "The representation loss after processing this batch is:  0.005495525896549225\n",
      "\n",
      "The classification loss after processing this batch is:  0.9501859545707703\n",
      "The representation loss after processing this batch is:  0.006735101342201233\n",
      "\n",
      "The classification loss after processing this batch is:  1.013395071029663\n",
      "The representation loss after processing this batch is:  0.006044432520866394\n",
      "\n",
      "The classification loss after processing this batch is:  1.102324366569519\n",
      "The representation loss after processing this batch is:  0.006307072937488556\n",
      "\n",
      "The classification loss after processing this batch is:  0.8317638635635376\n",
      "The representation loss after processing this batch is:  0.0060272738337516785\n",
      "\n",
      "The classification loss after processing this batch is:  0.8094741106033325\n",
      "The representation loss after processing this batch is:  0.005676820874214172\n",
      "\n",
      "The classification loss after processing this batch is:  0.7382720708847046\n",
      "The representation loss after processing this batch is:  0.006249342113733292\n",
      "\n",
      "The classification loss after processing this batch is:  0.7621334195137024\n",
      "The representation loss after processing this batch is:  0.0068273283541202545\n",
      "\n",
      "The classification loss after processing this batch is:  0.7331588864326477\n",
      "The representation loss after processing this batch is:  0.005483753979206085\n",
      "\n",
      "The classification loss after processing this batch is:  0.6227798461914062\n",
      "The representation loss after processing this batch is:  0.006068341434001923\n",
      "\n",
      "The classification loss after processing this batch is:  0.8139623403549194\n",
      "The representation loss after processing this batch is:  0.004866376519203186\n",
      "\n",
      "The classification loss after processing this batch is:  0.8583443760871887\n",
      "The representation loss after processing this batch is:  0.006483733654022217\n",
      "\n",
      "The classification loss after processing this batch is:  0.8547775745391846\n",
      "The representation loss after processing this batch is:  0.006011854857206345\n",
      "\n",
      "The classification loss after processing this batch is:  0.8219243884086609\n",
      "The representation loss after processing this batch is:  0.0070644281804561615\n",
      "\n",
      "The classification loss after processing this batch is:  0.7416674494743347\n",
      "The representation loss after processing this batch is:  0.006680391728878021\n",
      "\n",
      "The classification loss after processing this batch is:  0.7093554139137268\n",
      "The representation loss after processing this batch is:  0.005379617214202881\n",
      "\n",
      "The classification loss after processing this batch is:  0.7194749712944031\n",
      "The representation loss after processing this batch is:  0.006118416786193848\n",
      "\n",
      "The classification loss after processing this batch is:  0.6473382115364075\n",
      "The representation loss after processing this batch is:  0.0052325427532196045\n",
      "\n",
      "The classification loss after processing this batch is:  0.6861611604690552\n",
      "The representation loss after processing this batch is:  0.004752784967422485\n",
      "\n",
      "The classification loss after processing this batch is:  0.8351953029632568\n",
      "The representation loss after processing this batch is:  0.0051824599504470825\n",
      "\n",
      "The classification loss after processing this batch is:  0.6518757939338684\n",
      "The representation loss after processing this batch is:  0.005529813468456268\n",
      "\n",
      "The classification loss after processing this batch is:  0.8354586958885193\n",
      "The representation loss after processing this batch is:  0.005156189203262329\n",
      "\n",
      "The classification loss after processing this batch is:  0.8741340637207031\n",
      "The representation loss after processing this batch is:  0.005762502551078796\n",
      "\n",
      "The classification loss after processing this batch is:  0.6435568332672119\n",
      "The representation loss after processing this batch is:  0.005351163446903229\n",
      "\n",
      "The classification loss after processing this batch is:  0.6604967713356018\n",
      "The representation loss after processing this batch is:  0.0054382383823394775\n",
      "\n",
      "The classification loss after processing this batch is:  0.746141791343689\n",
      "The representation loss after processing this batch is:  0.0053234100341796875\n",
      "\n",
      "The classification loss after processing this batch is:  0.7798948884010315\n",
      "The representation loss after processing this batch is:  0.0056476593017578125\n",
      "\n",
      "The classification loss after processing this batch is:  0.9598567485809326\n",
      "The representation loss after processing this batch is:  0.005250498652458191\n",
      "\n",
      "The classification loss after processing this batch is:  0.8520603775978088\n",
      "The representation loss after processing this batch is:  0.006046108901500702\n",
      "\n",
      "The classification loss after processing this batch is:  0.8260014057159424\n",
      "The representation loss after processing this batch is:  0.005313090980052948\n",
      "\n",
      "The classification loss after processing this batch is:  0.7444350123405457\n",
      "The representation loss after processing this batch is:  0.005913570523262024\n",
      "\n",
      "The classification loss after processing this batch is:  0.8620744347572327\n",
      "The representation loss after processing this batch is:  0.006190143525600433\n",
      "\n",
      "The classification loss after processing this batch is:  0.8444375395774841\n",
      "The representation loss after processing this batch is:  0.005434833467006683\n",
      "\n",
      "The classification loss after processing this batch is:  0.9006213545799255\n",
      "The representation loss after processing this batch is:  0.006382878869771957\n",
      "\n",
      "The classification loss after processing this batch is:  0.7312294244766235\n",
      "The representation loss after processing this batch is:  0.006552174687385559\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.9698308110237122\n",
      "The representation loss after processing this batch is:  0.008210241794586182\n",
      "\n",
      "The classification loss after processing this batch is:  0.8082716464996338\n",
      "The representation loss after processing this batch is:  0.007566813379526138\n",
      "\n",
      "The classification loss after processing this batch is:  0.6831615567207336\n",
      "The representation loss after processing this batch is:  0.005384698510169983\n",
      "\n",
      "The classification loss after processing this batch is:  0.8860825300216675\n",
      "The representation loss after processing this batch is:  0.005989100784063339\n",
      "\n",
      "The classification loss after processing this batch is:  0.7643291354179382\n",
      "The representation loss after processing this batch is:  0.004569090902805328\n",
      "\n",
      "The classification loss after processing this batch is:  0.6138018369674683\n",
      "The representation loss after processing this batch is:  0.005693189799785614\n",
      "\n",
      "The classification loss after processing this batch is:  0.6633186936378479\n",
      "The representation loss after processing this batch is:  0.005678839981555939\n",
      "\n",
      "The classification loss after processing this batch is:  0.7012773156166077\n",
      "The representation loss after processing this batch is:  0.0063661858439445496\n",
      "\n",
      "The classification loss after processing this batch is:  0.7109196186065674\n",
      "The representation loss after processing this batch is:  0.006348378956317902\n",
      "\n",
      "The classification loss after processing this batch is:  0.8041676878929138\n",
      "The representation loss after processing this batch is:  0.005233444273471832\n",
      "\n",
      "The classification loss after processing this batch is:  1.0816936492919922\n",
      "The representation loss after processing this batch is:  0.0057350993156433105\n",
      "\n",
      "The classification loss after processing this batch is:  0.783338189125061\n",
      "The representation loss after processing this batch is:  0.0065796151757240295\n",
      "\n",
      "The classification loss after processing this batch is:  0.9233924150466919\n",
      "The representation loss after processing this batch is:  0.006359472870826721\n",
      "\n",
      "The classification loss after processing this batch is:  0.968578040599823\n",
      "The representation loss after processing this batch is:  0.006083443760871887\n",
      "\n",
      "The classification loss after processing this batch is:  0.8233516216278076\n",
      "The representation loss after processing this batch is:  0.007336996495723724\n",
      "\n",
      "The classification loss after processing this batch is:  0.738806426525116\n",
      "The representation loss after processing this batch is:  0.005977053195238113\n",
      "\n",
      "The classification loss after processing this batch is:  1.0475178956985474\n",
      "The representation loss after processing this batch is:  0.006635360419750214\n",
      "\n",
      "The classification loss after processing this batch is:  1.061604619026184\n",
      "The representation loss after processing this batch is:  0.006193533539772034\n",
      "\n",
      "The classification loss after processing this batch is:  0.8078540563583374\n",
      "The representation loss after processing this batch is:  0.007058054208755493\n",
      "\n",
      "The classification loss after processing this batch is:  0.6154952645301819\n",
      "The representation loss after processing this batch is:  0.005586467683315277\n",
      "\n",
      "The classification loss after processing this batch is:  0.722247302532196\n",
      "The representation loss after processing this batch is:  0.006448335945606232\n",
      "\n",
      "The classification loss after processing this batch is:  0.8092272281646729\n",
      "The representation loss after processing this batch is:  0.006963133811950684\n",
      "\n",
      "The classification loss after processing this batch is:  0.8273811340332031\n",
      "The representation loss after processing this batch is:  0.005284685641527176\n",
      "\n",
      "The classification loss after processing this batch is:  0.8739185929298401\n",
      "The representation loss after processing this batch is:  0.0055288150906562805\n",
      "\n",
      "The classification loss after processing this batch is:  0.765004575252533\n",
      "The representation loss after processing this batch is:  0.005575135350227356\n",
      "\n",
      "The classification loss after processing this batch is:  0.8336798548698425\n",
      "The representation loss after processing this batch is:  0.008033320307731628\n",
      "\n",
      "The classification loss after processing this batch is:  0.846964418888092\n",
      "The representation loss after processing this batch is:  0.00881534069776535\n",
      "\n",
      "The classification loss after processing this batch is:  0.7454685568809509\n",
      "The representation loss after processing this batch is:  0.0077191852033138275\n",
      "\n",
      "The classification loss after processing this batch is:  0.7350580096244812\n",
      "The representation loss after processing this batch is:  0.0061140283942222595\n",
      "\n",
      "The classification loss after processing this batch is:  0.9424642324447632\n",
      "The representation loss after processing this batch is:  0.005854792892932892\n",
      "\n",
      "The classification loss after processing this batch is:  0.7811392545700073\n",
      "The representation loss after processing this batch is:  0.005833327770233154\n",
      "\n",
      "The classification loss after processing this batch is:  0.7028299570083618\n",
      "The representation loss after processing this batch is:  0.005785241723060608\n",
      "\n",
      "The classification loss after processing this batch is:  0.7205554246902466\n",
      "The representation loss after processing this batch is:  0.005543913692235947\n",
      "\n",
      "The classification loss after processing this batch is:  0.6396539807319641\n",
      "The representation loss after processing this batch is:  0.005418553948402405\n",
      "\n",
      "The classification loss after processing this batch is:  0.5762265920639038\n",
      "The representation loss after processing this batch is:  0.005778968334197998\n",
      "\n",
      "The classification loss after processing this batch is:  0.7257359027862549\n",
      "The representation loss after processing this batch is:  0.006342802196741104\n",
      "\n",
      "The classification loss after processing this batch is:  0.9941491484642029\n",
      "The representation loss after processing this batch is:  0.006257437169551849\n",
      "\n",
      "The classification loss after processing this batch is:  0.8562732934951782\n",
      "The representation loss after processing this batch is:  0.0059937164187431335\n",
      "\n",
      "The classification loss after processing this batch is:  0.8508182764053345\n",
      "The representation loss after processing this batch is:  0.006003879010677338\n",
      "\n",
      "The classification loss after processing this batch is:  0.7670027613639832\n",
      "The representation loss after processing this batch is:  0.0060604289174079895\n",
      "\n",
      "The classification loss after processing this batch is:  0.7160071134567261\n",
      "The representation loss after processing this batch is:  0.005775734782218933\n",
      "\n",
      "The classification loss after processing this batch is:  0.7602716088294983\n",
      "The representation loss after processing this batch is:  0.006612814962863922\n",
      "\n",
      "The classification loss after processing this batch is:  0.8418091535568237\n",
      "The representation loss after processing this batch is:  0.006125845015048981\n",
      "\n",
      "The classification loss after processing this batch is:  0.8274165391921997\n",
      "The representation loss after processing this batch is:  0.005842927843332291\n",
      "\n",
      "The classification loss after processing this batch is:  0.8523930311203003\n",
      "The representation loss after processing this batch is:  0.0053565651178359985\n",
      "\n",
      "The classification loss after processing this batch is:  0.7459907531738281\n",
      "The representation loss after processing this batch is:  0.005567930638790131\n",
      "\n",
      "The classification loss after processing this batch is:  0.5821449756622314\n",
      "The representation loss after processing this batch is:  0.005958087742328644\n",
      "\n",
      "The classification loss after processing this batch is:  0.8210267424583435\n",
      "The representation loss after processing this batch is:  0.00538056343793869\n",
      "\n",
      "The classification loss after processing this batch is:  0.6949416995048523\n",
      "The representation loss after processing this batch is:  0.005958102643489838\n",
      "\n",
      "The classification loss after processing this batch is:  0.8988675475120544\n",
      "The representation loss after processing this batch is:  0.005697079002857208\n",
      "\n",
      "The classification loss after processing this batch is:  0.959786593914032\n",
      "The representation loss after processing this batch is:  0.005108565092086792\n",
      "\n",
      "The classification loss after processing this batch is:  0.9835492372512817\n",
      "The representation loss after processing this batch is:  0.005273289978504181\n",
      "\n",
      "The classification loss after processing this batch is:  1.007515788078308\n",
      "The representation loss after processing this batch is:  0.005177915096282959\n",
      "\n",
      "The classification loss after processing this batch is:  0.9309102892875671\n",
      "The representation loss after processing this batch is:  0.004746034741401672\n",
      "\n",
      "The classification loss after processing this batch is:  0.9539716243743896\n",
      "The representation loss after processing this batch is:  0.004700809717178345\n",
      "\n",
      "The classification loss after processing this batch is:  0.9912940859794617\n",
      "The representation loss after processing this batch is:  0.004359990358352661\n",
      "\n",
      "The classification loss after processing this batch is:  0.957634687423706\n",
      "The representation loss after processing this batch is:  0.0045874714851379395\n",
      "\n",
      "The classification loss after processing this batch is:  0.741571307182312\n",
      "The representation loss after processing this batch is:  0.006060555577278137\n",
      "\n",
      "The classification loss after processing this batch is:  0.61178058385849\n",
      "The representation loss after processing this batch is:  0.0064965784549713135\n",
      "\n",
      "The classification loss after processing this batch is:  0.7404242157936096\n",
      "The representation loss after processing this batch is:  0.006509765982627869\n",
      "\n",
      "The classification loss after processing this batch is:  0.6925943493843079\n",
      "The representation loss after processing this batch is:  0.00868174433708191\n",
      "\n",
      "The classification loss after processing this batch is:  0.7281399965286255\n",
      "The representation loss after processing this batch is:  0.006945669651031494\n",
      "\n",
      "The classification loss after processing this batch is:  0.5978509783744812\n",
      "The representation loss after processing this batch is:  0.0057349056005477905\n",
      "\n",
      "The classification loss after processing this batch is:  0.766342282295227\n",
      "The representation loss after processing this batch is:  0.006125584244728088\n",
      "\n",
      "The classification loss after processing this batch is:  0.5281617045402527\n",
      "The representation loss after processing this batch is:  0.005933485925197601\n",
      "\n",
      "The classification loss after processing this batch is:  0.879352331161499\n",
      "The representation loss after processing this batch is:  0.0058246515691280365\n",
      "\n",
      "The classification loss after processing this batch is:  0.6855794787406921\n",
      "The representation loss after processing this batch is:  0.005257129669189453\n",
      "\n",
      "The classification loss after processing this batch is:  0.7893572449684143\n",
      "The representation loss after processing this batch is:  0.006166562438011169\n",
      "\n",
      "The classification loss after processing this batch is:  0.8457318544387817\n",
      "The representation loss after processing this batch is:  0.006326496601104736\n",
      "\n",
      "The classification loss after processing this batch is:  0.6775124669075012\n",
      "The representation loss after processing this batch is:  0.005361046642065048\n",
      "\n",
      "The classification loss after processing this batch is:  0.6651250720024109\n",
      "The representation loss after processing this batch is:  0.004943884909152985\n",
      "\n",
      "The classification loss after processing this batch is:  0.7348543405532837\n",
      "The representation loss after processing this batch is:  0.006138436496257782\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.7438240051269531\n",
      "The representation loss after processing this batch is:  0.00512261688709259\n",
      "\n",
      "The classification loss after processing this batch is:  0.5746616721153259\n",
      "The representation loss after processing this batch is:  0.005364805459976196\n",
      "\n",
      "The classification loss after processing this batch is:  0.6020199656486511\n",
      "The representation loss after processing this batch is:  0.006261102855205536\n",
      "\n",
      "The classification loss after processing this batch is:  0.5379897356033325\n",
      "The representation loss after processing this batch is:  0.005498230457305908\n",
      "\n",
      "The classification loss after processing this batch is:  0.5682657957077026\n",
      "The representation loss after processing this batch is:  0.005823850631713867\n",
      "\n",
      "The classification loss after processing this batch is:  0.5916964411735535\n",
      "The representation loss after processing this batch is:  0.005948506295681\n",
      "\n",
      "The classification loss after processing this batch is:  0.7766914963722229\n",
      "The representation loss after processing this batch is:  0.0055655017495155334\n",
      "\n",
      "The classification loss after processing this batch is:  0.548429548740387\n",
      "The representation loss after processing this batch is:  0.004962354898452759\n",
      "\n",
      "The classification loss after processing this batch is:  0.5849986672401428\n",
      "The representation loss after processing this batch is:  0.005921699106693268\n",
      "\n",
      "The classification loss after processing this batch is:  0.6855804920196533\n",
      "The representation loss after processing this batch is:  0.006018243730068207\n",
      "\n",
      "The classification loss after processing this batch is:  0.7390648722648621\n",
      "The representation loss after processing this batch is:  0.005480721592903137\n",
      "\n",
      "The classification loss after processing this batch is:  0.7975219488143921\n",
      "The representation loss after processing this batch is:  0.0057635679841041565\n",
      "\n",
      "The classification loss after processing this batch is:  0.6083450317382812\n",
      "The representation loss after processing this batch is:  0.005391441285610199\n",
      "\n",
      "The classification loss after processing this batch is:  0.49631109833717346\n",
      "The representation loss after processing this batch is:  0.00538548082113266\n",
      "\n",
      "The classification loss after processing this batch is:  0.5675403475761414\n",
      "The representation loss after processing this batch is:  0.00537998229265213\n",
      "\n",
      "The classification loss after processing this batch is:  0.6402345299720764\n",
      "The representation loss after processing this batch is:  0.0053637027740478516\n",
      "\n",
      "The classification loss after processing this batch is:  0.7055756449699402\n",
      "The representation loss after processing this batch is:  0.005824834108352661\n",
      "\n",
      "The classification loss after processing this batch is:  0.5721874237060547\n",
      "The representation loss after processing this batch is:  0.005700424313545227\n",
      "\n",
      "The classification loss after processing this batch is:  0.7115020751953125\n",
      "The representation loss after processing this batch is:  0.005554020404815674\n",
      "\n",
      "The classification loss after processing this batch is:  0.663583517074585\n",
      "The representation loss after processing this batch is:  0.004618652164936066\n",
      "\n",
      "The classification loss after processing this batch is:  0.6835812330245972\n",
      "The representation loss after processing this batch is:  0.005307972431182861\n",
      "\n",
      "The classification loss after processing this batch is:  0.7408268451690674\n",
      "The representation loss after processing this batch is:  0.006218958646059036\n",
      "\n",
      "The classification loss after processing this batch is:  0.6264485716819763\n",
      "The representation loss after processing this batch is:  0.005951941013336182\n",
      "\n",
      "The classification loss after processing this batch is:  0.9259448647499084\n",
      "The representation loss after processing this batch is:  0.00601581484079361\n",
      "\n",
      "The classification loss after processing this batch is:  0.8246210813522339\n",
      "The representation loss after processing this batch is:  0.0054378509521484375\n",
      "\n",
      "The classification loss after processing this batch is:  0.7275444865226746\n",
      "The representation loss after processing this batch is:  0.006143674254417419\n",
      "\n",
      "The classification loss after processing this batch is:  0.635256826877594\n",
      "The representation loss after processing this batch is:  0.005098402500152588\n",
      "\n",
      "The classification loss after processing this batch is:  0.733108401298523\n",
      "The representation loss after processing this batch is:  0.006875425577163696\n",
      "\n",
      "The classification loss after processing this batch is:  0.7108325362205505\n",
      "The representation loss after processing this batch is:  0.005405869334936142\n",
      "\n",
      "The classification loss after processing this batch is:  0.6981658935546875\n",
      "The representation loss after processing this batch is:  0.005835875868797302\n",
      "\n",
      "The classification loss after processing this batch is:  0.7398344874382019\n",
      "The representation loss after processing this batch is:  0.005528829991817474\n",
      "\n",
      "The classification loss after processing this batch is:  0.6180132031440735\n",
      "The representation loss after processing this batch is:  0.005515947937965393\n",
      "\n",
      "The classification loss after processing this batch is:  0.6282323002815247\n",
      "The representation loss after processing this batch is:  0.005138121545314789\n",
      "\n",
      "The classification loss after processing this batch is:  0.6449130773544312\n",
      "The representation loss after processing this batch is:  0.005056113004684448\n",
      "\n",
      "The classification loss after processing this batch is:  0.7126312255859375\n",
      "The representation loss after processing this batch is:  0.0046859122812747955\n",
      "\n",
      "The classification loss after processing this batch is:  0.6486243605613708\n",
      "The representation loss after processing this batch is:  0.005622208118438721\n",
      "\n",
      "The classification loss after processing this batch is:  0.7724864482879639\n",
      "The representation loss after processing this batch is:  0.006152234971523285\n",
      "\n",
      "The classification loss after processing this batch is:  0.651502251625061\n",
      "The representation loss after processing this batch is:  0.005182214081287384\n",
      "\n",
      "The classification loss after processing this batch is:  0.5019242167472839\n",
      "The representation loss after processing this batch is:  0.006198547780513763\n",
      "\n",
      "The classification loss after processing this batch is:  0.5536290407180786\n",
      "The representation loss after processing this batch is:  0.005728267133235931\n",
      "\n",
      "The classification loss after processing this batch is:  0.590496838092804\n",
      "The representation loss after processing this batch is:  0.005930379033088684\n",
      "\n",
      "The classification loss after processing this batch is:  0.5452011823654175\n",
      "The representation loss after processing this batch is:  0.0063102878630161285\n",
      "\n",
      "The classification loss after processing this batch is:  0.6526458859443665\n",
      "The representation loss after processing this batch is:  0.0060889460146427155\n",
      "\n",
      "The classification loss after processing this batch is:  0.6302114725112915\n",
      "The representation loss after processing this batch is:  0.00644206628203392\n",
      "\n",
      "The classification loss after processing this batch is:  0.595147967338562\n",
      "The representation loss after processing this batch is:  0.006079234182834625\n",
      "\n",
      "The classification loss after processing this batch is:  0.6175668239593506\n",
      "The representation loss after processing this batch is:  0.004611603915691376\n",
      "\n",
      "The classification loss after processing this batch is:  0.6102604269981384\n",
      "The representation loss after processing this batch is:  0.00539003312587738\n",
      "\n",
      "The classification loss after processing this batch is:  0.4612172245979309\n",
      "The representation loss after processing this batch is:  0.005891457200050354\n",
      "\n",
      "The classification loss after processing this batch is:  0.6061935424804688\n",
      "The representation loss after processing this batch is:  0.005331285297870636\n",
      "\n",
      "The classification loss after processing this batch is:  0.6041526198387146\n",
      "The representation loss after processing this batch is:  0.005507990717887878\n",
      "\n",
      "The classification loss after processing this batch is:  0.6236864328384399\n",
      "The representation loss after processing this batch is:  0.005970194935798645\n",
      "\n",
      "The classification loss after processing this batch is:  0.6301406621932983\n",
      "The representation loss after processing this batch is:  0.0067024752497673035\n",
      "\n",
      "The classification loss after processing this batch is:  0.6540380716323853\n",
      "The representation loss after processing this batch is:  0.006084851920604706\n",
      "\n",
      "The classification loss after processing this batch is:  0.6318318247795105\n",
      "The representation loss after processing this batch is:  0.00579022616147995\n",
      "\n",
      "The classification loss after processing this batch is:  0.583315908908844\n",
      "The representation loss after processing this batch is:  0.006412774324417114\n",
      "\n",
      "The classification loss after processing this batch is:  0.7100399732589722\n",
      "The representation loss after processing this batch is:  0.005475237965583801\n",
      "\n",
      "The classification loss after processing this batch is:  0.6388089656829834\n",
      "The representation loss after processing this batch is:  0.004733450710773468\n",
      "\n",
      "The classification loss after processing this batch is:  0.6460198163986206\n",
      "The representation loss after processing this batch is:  0.0056143999099731445\n",
      "\n",
      "The classification loss after processing this batch is:  0.5106717348098755\n",
      "The representation loss after processing this batch is:  0.005725428462028503\n",
      "\n",
      "The classification loss after processing this batch is:  0.5311076641082764\n",
      "The representation loss after processing this batch is:  0.00573837012052536\n",
      "\n",
      "The classification loss after processing this batch is:  0.6944547891616821\n",
      "The representation loss after processing this batch is:  0.005468495190143585\n",
      "\n",
      "The classification loss after processing this batch is:  0.7711535096168518\n",
      "The representation loss after processing this batch is:  0.005269240587949753\n",
      "\n",
      "The classification loss after processing this batch is:  0.7256239056587219\n",
      "The representation loss after processing this batch is:  0.005090087652206421\n",
      "\n",
      "The classification loss after processing this batch is:  0.6631718873977661\n",
      "The representation loss after processing this batch is:  0.005958147346973419\n",
      "\n",
      "The classification loss after processing this batch is:  0.7188293933868408\n",
      "The representation loss after processing this batch is:  0.00594189390540123\n",
      "\n",
      "The classification loss after processing this batch is:  0.7361413240432739\n",
      "The representation loss after processing this batch is:  0.004762955009937286\n",
      "\n",
      "The classification loss after processing this batch is:  0.7821542024612427\n",
      "The representation loss after processing this batch is:  0.005616653710603714\n",
      "\n",
      "The classification loss after processing this batch is:  0.7551202774047852\n",
      "The representation loss after processing this batch is:  0.004995107650756836\n",
      "\n",
      "The classification loss after processing this batch is:  0.7005758881568909\n",
      "The representation loss after processing this batch is:  0.005825139582157135\n",
      "\n",
      "The classification loss after processing this batch is:  0.6549168229103088\n",
      "The representation loss after processing this batch is:  0.006171718239784241\n",
      "\n",
      "The classification loss after processing this batch is:  0.39507046341896057\n",
      "The representation loss after processing this batch is:  0.00602489709854126\n",
      "\n",
      "The classification loss after processing this batch is:  0.5440259575843811\n",
      "The representation loss after processing this batch is:  0.005847800523042679\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.6050278544425964\n",
      "The representation loss after processing this batch is:  0.004898961633443832\n",
      "\n",
      "The classification loss after processing this batch is:  0.5831270813941956\n",
      "The representation loss after processing this batch is:  0.004876170307397842\n",
      "\n",
      "The classification loss after processing this batch is:  0.6581094264984131\n",
      "The representation loss after processing this batch is:  0.005616530776023865\n",
      "\n",
      "The classification loss after processing this batch is:  0.587952733039856\n",
      "The representation loss after processing this batch is:  0.005774170160293579\n",
      "\n",
      "The classification loss after processing this batch is:  0.5952185988426208\n",
      "The representation loss after processing this batch is:  0.005523018538951874\n",
      "\n",
      "The classification loss after processing this batch is:  0.6080309152603149\n",
      "The representation loss after processing this batch is:  0.006714373826980591\n",
      "\n",
      "The classification loss after processing this batch is:  0.6078130006790161\n",
      "The representation loss after processing this batch is:  0.004911839962005615\n",
      "\n",
      "The classification loss after processing this batch is:  0.5906679034233093\n",
      "The representation loss after processing this batch is:  0.005407832562923431\n",
      "\n",
      "The classification loss after processing this batch is:  0.7185162901878357\n",
      "The representation loss after processing this batch is:  0.005124285817146301\n",
      "\n",
      "The classification loss after processing this batch is:  0.7220479249954224\n",
      "The representation loss after processing this batch is:  0.005495693534612656\n",
      "\n",
      "The classification loss after processing this batch is:  0.5544658303260803\n",
      "The representation loss after processing this batch is:  0.007834844291210175\n",
      "\n",
      "The classification loss after processing this batch is:  0.5327765345573425\n",
      "The representation loss after processing this batch is:  0.005505822598934174\n",
      "\n",
      "The classification loss after processing this batch is:  0.5468814969062805\n",
      "The representation loss after processing this batch is:  0.0055120959877967834\n",
      "\n",
      "The classification loss after processing this batch is:  0.6544177532196045\n",
      "The representation loss after processing this batch is:  0.0044381022453308105\n",
      "\n",
      "The classification loss after processing this batch is:  0.7456021904945374\n",
      "The representation loss after processing this batch is:  0.004329510033130646\n",
      "\n",
      "The classification loss after processing this batch is:  0.5587488412857056\n",
      "The representation loss after processing this batch is:  0.005321674048900604\n",
      "\n",
      "The classification loss after processing this batch is:  0.43053585290908813\n",
      "The representation loss after processing this batch is:  0.005146093666553497\n",
      "\n",
      "The classification loss after processing this batch is:  0.610298216342926\n",
      "The representation loss after processing this batch is:  0.005129311233758926\n",
      "\n",
      "The classification loss after processing this batch is:  0.46613866090774536\n",
      "The representation loss after processing this batch is:  0.0054614245891571045\n",
      "\n",
      "The classification loss after processing this batch is:  0.5353556871414185\n",
      "The representation loss after processing this batch is:  0.004515618085861206\n",
      "\n",
      "The classification loss after processing this batch is:  0.4756630063056946\n",
      "The representation loss after processing this batch is:  0.006072349846363068\n",
      "\n",
      "The classification loss after processing this batch is:  0.42026418447494507\n",
      "The representation loss after processing this batch is:  0.0051853954792022705\n",
      "\n",
      "The classification loss after processing this batch is:  0.4340943694114685\n",
      "The representation loss after processing this batch is:  0.00494607537984848\n",
      "\n",
      "The classification loss after processing this batch is:  0.5575836300849915\n",
      "The representation loss after processing this batch is:  0.005144469439983368\n",
      "\n",
      "The classification loss after processing this batch is:  0.4600689709186554\n",
      "The representation loss after processing this batch is:  0.005613312125205994\n",
      "\n",
      "The classification loss after processing this batch is:  0.7145663499832153\n",
      "The representation loss after processing this batch is:  0.005157172679901123\n",
      "\n",
      "The classification loss after processing this batch is:  0.802315890789032\n",
      "The representation loss after processing this batch is:  0.005051802843809128\n",
      "\n",
      "The classification loss after processing this batch is:  0.6514244079589844\n",
      "The representation loss after processing this batch is:  0.006098031997680664\n",
      "\n",
      "The classification loss after processing this batch is:  0.7613419890403748\n",
      "The representation loss after processing this batch is:  0.006134718656539917\n",
      "\n",
      "The classification loss after processing this batch is:  0.6382461190223694\n",
      "The representation loss after processing this batch is:  0.0054665058851242065\n",
      "\n",
      "The classification loss after processing this batch is:  0.6014013886451721\n",
      "The representation loss after processing this batch is:  0.005055546760559082\n",
      "\n",
      "The classification loss after processing this batch is:  0.6317495107650757\n",
      "The representation loss after processing this batch is:  0.004925258457660675\n",
      "\n",
      "The classification loss after processing this batch is:  0.523141086101532\n",
      "The representation loss after processing this batch is:  0.0057931020855903625\n",
      "\n",
      "The classification loss after processing this batch is:  0.722798228263855\n",
      "The representation loss after processing this batch is:  0.006608642637729645\n",
      "\n",
      "The classification loss after processing this batch is:  0.6264054179191589\n",
      "The representation loss after processing this batch is:  0.006025344133377075\n",
      "\n",
      "The classification loss after processing this batch is:  0.5810254216194153\n",
      "The representation loss after processing this batch is:  0.005507953464984894\n",
      "\n",
      "The classification loss after processing this batch is:  0.7338998317718506\n",
      "The representation loss after processing this batch is:  0.005339372903108597\n",
      "\n",
      "The classification loss after processing this batch is:  0.6395784020423889\n",
      "The representation loss after processing this batch is:  0.0049725547432899475\n",
      "\n",
      "The classification loss after processing this batch is:  0.6434282660484314\n",
      "The representation loss after processing this batch is:  0.004769749939441681\n",
      "\n",
      "The classification loss after processing this batch is:  0.5265102386474609\n",
      "The representation loss after processing this batch is:  0.005828380584716797\n",
      "\n",
      "The classification loss after processing this batch is:  0.49664145708084106\n",
      "The representation loss after processing this batch is:  0.00484880805015564\n",
      "\n",
      "The classification loss after processing this batch is:  0.552121102809906\n",
      "The representation loss after processing this batch is:  0.004929885268211365\n",
      "\n",
      "The classification loss after processing this batch is:  0.5575354099273682\n",
      "The representation loss after processing this batch is:  0.005998432636260986\n",
      "\n",
      "The classification loss after processing this batch is:  0.41252055764198303\n",
      "The representation loss after processing this batch is:  0.005278438329696655\n",
      "\n",
      "The classification loss after processing this batch is:  0.5500370860099792\n",
      "The representation loss after processing this batch is:  0.00493963435292244\n",
      "\n",
      "The classification loss after processing this batch is:  0.6799764037132263\n",
      "The representation loss after processing this batch is:  0.004914291203022003\n",
      "\n",
      "The classification loss after processing this batch is:  0.5485798120498657\n",
      "The representation loss after processing this batch is:  0.004929050803184509\n",
      "\n",
      "The classification loss after processing this batch is:  0.5982610583305359\n",
      "The representation loss after processing this batch is:  0.005310773849487305\n",
      "\n",
      "The classification loss after processing this batch is:  0.7424891591072083\n",
      "The representation loss after processing this batch is:  0.005158096551895142\n",
      "\n",
      "The classification loss after processing this batch is:  0.503633975982666\n",
      "The representation loss after processing this batch is:  0.005836352705955505\n",
      "\n",
      "The classification loss after processing this batch is:  0.4717904031276703\n",
      "The representation loss after processing this batch is:  0.005816616117954254\n",
      "\n",
      "The classification loss after processing this batch is:  0.45935070514678955\n",
      "The representation loss after processing this batch is:  0.005829192698001862\n",
      "\n",
      "The classification loss after processing this batch is:  0.44727465510368347\n",
      "The representation loss after processing this batch is:  0.005458422005176544\n",
      "\n",
      "The classification loss after processing this batch is:  0.5382758378982544\n",
      "The representation loss after processing this batch is:  0.005081631243228912\n",
      "\n",
      "The classification loss after processing this batch is:  0.5397237539291382\n",
      "The representation loss after processing this batch is:  0.005297422409057617\n",
      "\n",
      "The classification loss after processing this batch is:  0.5432124733924866\n",
      "The representation loss after processing this batch is:  0.005891844630241394\n",
      "\n",
      "The classification loss after processing this batch is:  0.6278661489486694\n",
      "The representation loss after processing this batch is:  0.006218872964382172\n",
      "\n",
      "The classification loss after processing this batch is:  0.5383517146110535\n",
      "The representation loss after processing this batch is:  0.005442578345537186\n",
      "\n",
      "The classification loss after processing this batch is:  0.5784119963645935\n",
      "The representation loss after processing this batch is:  0.005932219326496124\n",
      "\n",
      "The classification loss after processing this batch is:  0.7769103646278381\n",
      "The representation loss after processing this batch is:  0.005797889083623886\n",
      "\n",
      "The classification loss after processing this batch is:  0.7277567982673645\n",
      "The representation loss after processing this batch is:  0.005936466157436371\n",
      "\n",
      "The classification loss after processing this batch is:  0.7109163403511047\n",
      "The representation loss after processing this batch is:  0.004948057234287262\n",
      "\n",
      "The classification loss after processing this batch is:  0.7180135846138\n",
      "The representation loss after processing this batch is:  0.0050080642104148865\n",
      "\n",
      "The classification loss after processing this batch is:  0.7133979797363281\n",
      "The representation loss after processing this batch is:  0.006113648414611816\n",
      "\n",
      "The classification loss after processing this batch is:  0.6384946703910828\n",
      "The representation loss after processing this batch is:  0.005052104592323303\n",
      "\n",
      "The classification loss after processing this batch is:  0.37686246633529663\n",
      "The representation loss after processing this batch is:  0.006102107465267181\n",
      "\n",
      "The classification loss after processing this batch is:  0.5668514966964722\n",
      "The representation loss after processing this batch is:  0.006999090313911438\n",
      "\n",
      "The classification loss after processing this batch is:  0.5572177767753601\n",
      "The representation loss after processing this batch is:  0.006910547614097595\n",
      "\n",
      "The classification loss after processing this batch is:  0.48841509222984314\n",
      "The representation loss after processing this batch is:  0.005423262715339661\n",
      "\n",
      "The classification loss after processing this batch is:  0.6114346981048584\n",
      "The representation loss after processing this batch is:  0.004275016486644745\n",
      "\n",
      "The classification loss after processing this batch is:  0.6312902569770813\n",
      "The representation loss after processing this batch is:  0.00556684285402298\n",
      "\n",
      "The classification loss after processing this batch is:  0.5675659775733948\n",
      "The representation loss after processing this batch is:  0.004996791481971741\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.6610720157623291\n",
      "The representation loss after processing this batch is:  0.0047695934772491455\n",
      "\n",
      "The classification loss after processing this batch is:  0.6773338913917542\n",
      "The representation loss after processing this batch is:  0.005244165658950806\n",
      "\n",
      "The classification loss after processing this batch is:  0.815255343914032\n",
      "The representation loss after processing this batch is:  0.005447253584861755\n",
      "\n",
      "The classification loss after processing this batch is:  0.659800112247467\n",
      "The representation loss after processing this batch is:  0.0053192079067230225\n",
      "\n",
      "The classification loss after processing this batch is:  0.7003529667854309\n",
      "The representation loss after processing this batch is:  0.0045744627714157104\n",
      "\n",
      "The classification loss after processing this batch is:  0.6015040874481201\n",
      "The representation loss after processing this batch is:  0.0049385130405426025\n",
      "\n",
      "The classification loss after processing this batch is:  0.5864226222038269\n",
      "The representation loss after processing this batch is:  0.005647961050271988\n",
      "\n",
      "The classification loss after processing this batch is:  0.6462298035621643\n",
      "The representation loss after processing this batch is:  0.005218595266342163\n",
      "\n",
      "The classification loss after processing this batch is:  0.4216863214969635\n",
      "The representation loss after processing this batch is:  0.004544980823993683\n",
      "\n",
      "The classification loss after processing this batch is:  0.45581409335136414\n",
      "The representation loss after processing this batch is:  0.005105812102556229\n",
      "\n",
      "The classification loss after processing this batch is:  0.755316972732544\n",
      "The representation loss after processing this batch is:  0.004671812057495117\n",
      "\n",
      "The classification loss after processing this batch is:  0.43857377767562866\n",
      "The representation loss after processing this batch is:  0.005355283617973328\n",
      "\n",
      "The classification loss after processing this batch is:  0.5521994829177856\n",
      "The representation loss after processing this batch is:  0.00505492091178894\n",
      "\n",
      "The classification loss after processing this batch is:  0.554517388343811\n",
      "The representation loss after processing this batch is:  0.0052026063203811646\n",
      "\n",
      "The classification loss after processing this batch is:  0.5575646758079529\n",
      "The representation loss after processing this batch is:  0.005214430391788483\n",
      "\n",
      "The classification loss after processing this batch is:  0.7628329992294312\n",
      "The representation loss after processing this batch is:  0.006111800670623779\n",
      "\n",
      "The classification loss after processing this batch is:  0.7384325861930847\n",
      "The representation loss after processing this batch is:  0.005858764052391052\n",
      "\n",
      "The classification loss after processing this batch is:  0.6617832183837891\n",
      "The representation loss after processing this batch is:  0.005604222416877747\n",
      "\n",
      "The classification loss after processing this batch is:  0.4942358732223511\n",
      "The representation loss after processing this batch is:  0.004799500107765198\n",
      "\n",
      "The classification loss after processing this batch is:  0.5781412720680237\n",
      "The representation loss after processing this batch is:  0.004798620939254761\n",
      "\n",
      "The classification loss after processing this batch is:  0.42330047488212585\n",
      "The representation loss after processing this batch is:  0.004652656614780426\n",
      "\n",
      "The classification loss after processing this batch is:  0.4451974332332611\n",
      "The representation loss after processing this batch is:  0.004576936364173889\n",
      "\n",
      "The classification loss after processing this batch is:  0.4492127299308777\n",
      "The representation loss after processing this batch is:  0.004693135619163513\n",
      "\n",
      "The classification loss after processing this batch is:  0.3647523522377014\n",
      "The representation loss after processing this batch is:  0.0047238171100616455\n",
      "\n",
      "The classification loss after processing this batch is:  0.5416250228881836\n",
      "The representation loss after processing this batch is:  0.005610696971416473\n",
      "\n",
      "The classification loss after processing this batch is:  0.39962467551231384\n",
      "The representation loss after processing this batch is:  0.004552245140075684\n",
      "\n",
      "The classification loss after processing this batch is:  0.4709535539150238\n",
      "The representation loss after processing this batch is:  0.004611052572727203\n",
      "\n",
      "The classification loss after processing this batch is:  0.5040061473846436\n",
      "The representation loss after processing this batch is:  0.0050545744597911835\n",
      "\n",
      "The classification loss after processing this batch is:  0.5430225729942322\n",
      "The representation loss after processing this batch is:  0.006343923509120941\n",
      "\n",
      "The classification loss after processing this batch is:  0.6351786255836487\n",
      "The representation loss after processing this batch is:  0.004708684980869293\n",
      "\n",
      "The classification loss after processing this batch is:  0.48065072298049927\n",
      "The representation loss after processing this batch is:  0.006231822073459625\n",
      "\n",
      "The classification loss after processing this batch is:  0.5720880627632141\n",
      "The representation loss after processing this batch is:  0.005534108728170395\n",
      "\n",
      "The classification loss after processing this batch is:  0.5158267021179199\n",
      "The representation loss after processing this batch is:  0.005079738795757294\n",
      "\n",
      "The classification loss after processing this batch is:  0.5195016264915466\n",
      "The representation loss after processing this batch is:  0.005650170147418976\n",
      "\n",
      "The classification loss after processing this batch is:  0.7039858102798462\n",
      "The representation loss after processing this batch is:  0.005908951163291931\n",
      "\n",
      "The classification loss after processing this batch is:  0.5695663094520569\n",
      "The representation loss after processing this batch is:  0.004701495170593262\n",
      "\n",
      "The classification loss after processing this batch is:  0.6218418478965759\n",
      "The representation loss after processing this batch is:  0.004619598388671875\n",
      "\n",
      "The classification loss after processing this batch is:  0.5912097692489624\n",
      "The representation loss after processing this batch is:  0.004955843091011047\n",
      "\n",
      "The classification loss after processing this batch is:  0.6370806097984314\n",
      "The representation loss after processing this batch is:  0.004774753004312515\n",
      "\n",
      "The classification loss after processing this batch is:  0.5462719202041626\n",
      "The representation loss after processing this batch is:  0.005806431174278259\n",
      "\n",
      "The classification loss after processing this batch is:  0.411645770072937\n",
      "The representation loss after processing this batch is:  0.004958122968673706\n",
      "\n",
      "The classification loss after processing this batch is:  0.36732327938079834\n",
      "The representation loss after processing this batch is:  0.004765987396240234\n",
      "\n",
      "The classification loss after processing this batch is:  0.4405682384967804\n",
      "The representation loss after processing this batch is:  0.005253821611404419\n",
      "\n",
      "The classification loss after processing this batch is:  0.3918539881706238\n",
      "The representation loss after processing this batch is:  0.005240015685558319\n",
      "\n",
      "The classification loss after processing this batch is:  0.5374547839164734\n",
      "The representation loss after processing this batch is:  0.005561612546443939\n",
      "\n",
      "The classification loss after processing this batch is:  0.5035452842712402\n",
      "The representation loss after processing this batch is:  0.005732938647270203\n",
      "\n",
      "The classification loss after processing this batch is:  0.6720200777053833\n",
      "The representation loss after processing this batch is:  0.005593717098236084\n",
      "\n",
      "The classification loss after processing this batch is:  0.5275377035140991\n",
      "The representation loss after processing this batch is:  0.004965677857398987\n",
      "\n",
      "The classification loss after processing this batch is:  0.45200029015541077\n",
      "The representation loss after processing this batch is:  0.005272343754768372\n",
      "\n",
      "The classification loss after processing this batch is:  0.6892624497413635\n",
      "The representation loss after processing this batch is:  0.005032077431678772\n",
      "\n",
      "The classification loss after processing this batch is:  0.5642756223678589\n",
      "The representation loss after processing this batch is:  0.0042190104722976685\n",
      "\n",
      "The classification loss after processing this batch is:  0.4990459382534027\n",
      "The representation loss after processing this batch is:  0.0052408017218112946\n",
      "\n",
      "The classification loss after processing this batch is:  0.3795841634273529\n",
      "The representation loss after processing this batch is:  0.005369260907173157\n",
      "\n",
      "The classification loss after processing this batch is:  0.4096831679344177\n",
      "The representation loss after processing this batch is:  0.005239374935626984\n",
      "\n",
      "The classification loss after processing this batch is:  0.4120573103427887\n",
      "The representation loss after processing this batch is:  0.005456589162349701\n",
      "\n",
      "The classification loss after processing this batch is:  0.4828273355960846\n",
      "The representation loss after processing this batch is:  0.004834212362766266\n",
      "\n",
      "The classification loss after processing this batch is:  0.6620343923568726\n",
      "The representation loss after processing this batch is:  0.005670800805091858\n",
      "\n",
      "The classification loss after processing this batch is:  0.6934072375297546\n",
      "The representation loss after processing this batch is:  0.005861412733793259\n",
      "\n",
      "The classification loss after processing this batch is:  0.41879892349243164\n",
      "The representation loss after processing this batch is:  0.005239710211753845\n",
      "\n",
      "The classification loss after processing this batch is:  0.5851988196372986\n",
      "The representation loss after processing this batch is:  0.005338691174983978\n",
      "\n",
      "The classification loss after processing this batch is:  0.3813999593257904\n",
      "The representation loss after processing this batch is:  0.004797354340553284\n",
      "\n",
      "The classification loss after processing this batch is:  0.46108487248420715\n",
      "The representation loss after processing this batch is:  0.006025504320859909\n",
      "\n",
      "The classification loss after processing this batch is:  0.64483243227005\n",
      "The representation loss after processing this batch is:  0.004904013127088547\n",
      "\n",
      "The classification loss after processing this batch is:  0.5385048985481262\n",
      "The representation loss after processing this batch is:  0.007266081869602203\n",
      "\n",
      "The classification loss after processing this batch is:  0.5080414414405823\n",
      "The representation loss after processing this batch is:  0.006678476929664612\n",
      "\n",
      "The classification loss after processing this batch is:  0.5129663348197937\n",
      "The representation loss after processing this batch is:  0.006823152303695679\n",
      "\n",
      "The classification loss after processing this batch is:  0.605258584022522\n",
      "The representation loss after processing this batch is:  0.006578385829925537\n",
      "\n",
      "The classification loss after processing this batch is:  0.542534589767456\n",
      "The representation loss after processing this batch is:  0.006610851734876633\n",
      "\n",
      "The classification loss after processing this batch is:  0.5116892457008362\n",
      "The representation loss after processing this batch is:  0.005118861794471741\n",
      "\n",
      "The classification loss after processing this batch is:  0.4955466687679291\n",
      "The representation loss after processing this batch is:  0.00478728860616684\n",
      "\n",
      "The classification loss after processing this batch is:  0.5903251767158508\n",
      "The representation loss after processing this batch is:  0.0046988315880298615\n",
      "\n",
      "The classification loss after processing this batch is:  0.6493040323257446\n",
      "The representation loss after processing this batch is:  0.004316672682762146\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.5176793336868286\n",
      "The representation loss after processing this batch is:  0.005013063549995422\n",
      "\n",
      "The classification loss after processing this batch is:  0.42261311411857605\n",
      "The representation loss after processing this batch is:  0.005269952118396759\n",
      "\n",
      "The classification loss after processing this batch is:  0.3383726477622986\n",
      "The representation loss after processing this batch is:  0.005317695438861847\n",
      "\n",
      "The classification loss after processing this batch is:  0.5105560421943665\n",
      "The representation loss after processing this batch is:  0.005814515054225922\n",
      "\n",
      "The classification loss after processing this batch is:  0.4966897666454315\n",
      "The representation loss after processing this batch is:  0.004570186138153076\n",
      "\n",
      "The classification loss after processing this batch is:  0.5746561884880066\n",
      "The representation loss after processing this batch is:  0.004297226667404175\n",
      "\n",
      "The classification loss after processing this batch is:  0.4176875054836273\n",
      "The representation loss after processing this batch is:  0.005759142339229584\n",
      "\n",
      "The classification loss after processing this batch is:  0.44895318150520325\n",
      "The representation loss after processing this batch is:  0.005349017679691315\n",
      "\n",
      "The classification loss after processing this batch is:  0.5463669300079346\n",
      "The representation loss after processing this batch is:  0.005158700048923492\n",
      "\n",
      "The classification loss after processing this batch is:  0.4181435704231262\n",
      "The representation loss after processing this batch is:  0.004320055246353149\n",
      "\n",
      "The classification loss after processing this batch is:  0.5582931041717529\n",
      "The representation loss after processing this batch is:  0.005094394087791443\n",
      "\n",
      "The classification loss after processing this batch is:  0.37181681394577026\n",
      "The representation loss after processing this batch is:  0.004285156726837158\n",
      "\n",
      "The classification loss after processing this batch is:  0.47538408637046814\n",
      "The representation loss after processing this batch is:  0.004904933273792267\n",
      "\n",
      "The classification loss after processing this batch is:  0.43025267124176025\n",
      "The representation loss after processing this batch is:  0.005360700190067291\n",
      "\n",
      "The classification loss after processing this batch is:  0.5643342733383179\n",
      "The representation loss after processing this batch is:  0.0057433247566223145\n",
      "\n",
      "The classification loss after processing this batch is:  0.5184975862503052\n",
      "The representation loss after processing this batch is:  0.00551261380314827\n",
      "\n",
      "The classification loss after processing this batch is:  0.5579059720039368\n",
      "The representation loss after processing this batch is:  0.004765592515468597\n",
      "\n",
      "The classification loss after processing this batch is:  0.6326602697372437\n",
      "The representation loss after processing this batch is:  0.005312055349349976\n",
      "\n",
      "The classification loss after processing this batch is:  0.6706043481826782\n",
      "The representation loss after processing this batch is:  0.004835803061723709\n",
      "\n",
      "The classification loss after processing this batch is:  0.5343448519706726\n",
      "The representation loss after processing this batch is:  0.005808502435684204\n",
      "\n",
      "The classification loss after processing this batch is:  0.6225224733352661\n",
      "The representation loss after processing this batch is:  0.004674583673477173\n",
      "\n",
      "The classification loss after processing this batch is:  0.5282929539680481\n",
      "The representation loss after processing this batch is:  0.004693113267421722\n",
      "\n",
      "The classification loss after processing this batch is:  0.418415904045105\n",
      "The representation loss after processing this batch is:  0.004649370908737183\n",
      "\n",
      "The classification loss after processing this batch is:  0.36931946873664856\n",
      "The representation loss after processing this batch is:  0.004789456725120544\n",
      "\n",
      "The classification loss after processing this batch is:  0.4387332499027252\n",
      "The representation loss after processing this batch is:  0.004605822265148163\n",
      "\n",
      "The classification loss after processing this batch is:  0.6850920915603638\n",
      "The representation loss after processing this batch is:  0.005381591618061066\n",
      "\n",
      "The classification loss after processing this batch is:  0.5422785878181458\n",
      "The representation loss after processing this batch is:  0.0048656165599823\n",
      "\n",
      "The classification loss after processing this batch is:  0.4810745418071747\n",
      "The representation loss after processing this batch is:  0.004659287631511688\n",
      "\n",
      "The classification loss after processing this batch is:  0.45153695344924927\n",
      "The representation loss after processing this batch is:  0.004829719662666321\n",
      "\n",
      "The classification loss after processing this batch is:  0.43728774785995483\n",
      "The representation loss after processing this batch is:  0.005072992295026779\n",
      "\n",
      "The classification loss after processing this batch is:  0.3821749985218048\n",
      "The representation loss after processing this batch is:  0.004685662686824799\n",
      "\n",
      "The classification loss after processing this batch is:  0.417111337184906\n",
      "The representation loss after processing this batch is:  0.00468609482049942\n",
      "\n",
      "The classification loss after processing this batch is:  0.4543059766292572\n",
      "The representation loss after processing this batch is:  0.0043992698192596436\n",
      "\n",
      "The classification loss after processing this batch is:  0.5696640014648438\n",
      "The representation loss after processing this batch is:  0.004744179546833038\n",
      "\n",
      "The classification loss after processing this batch is:  0.3600406050682068\n",
      "The representation loss after processing this batch is:  0.003982044756412506\n",
      "\n",
      "The classification loss after processing this batch is:  0.5273526906967163\n",
      "The representation loss after processing this batch is:  0.004253372550010681\n",
      "\n",
      "The classification loss after processing this batch is:  0.46276384592056274\n",
      "The representation loss after processing this batch is:  0.004125379025936127\n",
      "\n",
      "The classification loss after processing this batch is:  0.4376688301563263\n",
      "The representation loss after processing this batch is:  0.004500295966863632\n",
      "\n",
      "The classification loss after processing this batch is:  0.422070175409317\n",
      "The representation loss after processing this batch is:  0.005206793546676636\n",
      "\n",
      "The classification loss after processing this batch is:  0.4034634828567505\n",
      "The representation loss after processing this batch is:  0.004808761179447174\n",
      "\n",
      "The classification loss after processing this batch is:  0.41889747977256775\n",
      "The representation loss after processing this batch is:  0.005222216248512268\n",
      "\n",
      "The classification loss after processing this batch is:  0.4509696960449219\n",
      "The representation loss after processing this batch is:  0.0050535425543785095\n",
      "\n",
      "The classification loss after processing this batch is:  0.6035944819450378\n",
      "The representation loss after processing this batch is:  0.0058242082595825195\n",
      "\n",
      "The classification loss after processing this batch is:  0.7380324602127075\n",
      "The representation loss after processing this batch is:  0.00606180727481842\n",
      "\n",
      "The classification loss after processing this batch is:  0.6649190187454224\n",
      "The representation loss after processing this batch is:  0.005723416805267334\n",
      "\n",
      "The classification loss after processing this batch is:  0.5649469494819641\n",
      "The representation loss after processing this batch is:  0.005629099905490875\n",
      "\n",
      "The classification loss after processing this batch is:  0.5205735564231873\n",
      "The representation loss after processing this batch is:  0.006071664392948151\n",
      "\n",
      "The classification loss after processing this batch is:  0.6441468596458435\n",
      "The representation loss after processing this batch is:  0.004849106073379517\n",
      "\n",
      "The classification loss after processing this batch is:  0.44755449891090393\n",
      "The representation loss after processing this batch is:  0.004904843866825104\n",
      "\n",
      "The classification loss after processing this batch is:  0.3144576847553253\n",
      "The representation loss after processing this batch is:  0.005000129342079163\n",
      "\n",
      "The classification loss after processing this batch is:  0.41682636737823486\n",
      "The representation loss after processing this batch is:  0.004642609506845474\n",
      "\n",
      "The classification loss after processing this batch is:  0.7283139824867249\n",
      "The representation loss after processing this batch is:  0.005482956767082214\n",
      "\n",
      "The classification loss after processing this batch is:  0.7778416275978088\n",
      "The representation loss after processing this batch is:  0.005282461643218994\n",
      "\n",
      "The classification loss after processing this batch is:  0.6813872456550598\n",
      "The representation loss after processing this batch is:  0.004807315766811371\n",
      "\n",
      "The classification loss after processing this batch is:  0.5308231115341187\n",
      "The representation loss after processing this batch is:  0.005433030426502228\n",
      "\n",
      "The classification loss after processing this batch is:  0.4485122859477997\n",
      "The representation loss after processing this batch is:  0.00504356250166893\n",
      "\n",
      "The classification loss after processing this batch is:  0.4337368905544281\n",
      "The representation loss after processing this batch is:  0.004957646131515503\n",
      "\n",
      "The classification loss after processing this batch is:  0.4981049597263336\n",
      "The representation loss after processing this batch is:  0.005319640040397644\n",
      "\n",
      "The classification loss after processing this batch is:  0.5367940664291382\n",
      "The representation loss after processing this batch is:  0.005354598164558411\n",
      "\n",
      "The classification loss after processing this batch is:  0.47172263264656067\n",
      "The representation loss after processing this batch is:  0.005378901958465576\n",
      "\n",
      "The classification loss after processing this batch is:  0.5582707524299622\n",
      "The representation loss after processing this batch is:  0.0065996646881103516\n",
      "\n",
      "The classification loss after processing this batch is:  0.5286517143249512\n",
      "The representation loss after processing this batch is:  0.005584642291069031\n",
      "\n",
      "The classification loss after processing this batch is:  0.45664823055267334\n",
      "The representation loss after processing this batch is:  0.004763297736644745\n",
      "\n",
      "The classification loss after processing this batch is:  0.46851158142089844\n",
      "The representation loss after processing this batch is:  0.005422048270702362\n",
      "\n",
      "The classification loss after processing this batch is:  0.5031261444091797\n",
      "The representation loss after processing this batch is:  0.00494268536567688\n",
      "\n",
      "The classification loss after processing this batch is:  0.4404965043067932\n",
      "The representation loss after processing this batch is:  0.00430278480052948\n",
      "\n",
      "The classification loss after processing this batch is:  0.6825991272926331\n",
      "The representation loss after processing this batch is:  0.005162276327610016\n",
      "\n",
      "The classification loss after processing this batch is:  0.6431458592414856\n",
      "The representation loss after processing this batch is:  0.0058101266622543335\n",
      "\n",
      "The classification loss after processing this batch is:  0.48455938696861267\n",
      "The representation loss after processing this batch is:  0.00599294900894165\n",
      "\n",
      "The classification loss after processing this batch is:  0.490858256816864\n",
      "The representation loss after processing this batch is:  0.004731312394142151\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.43439409136772156\n",
      "The representation loss after processing this batch is:  0.005492553114891052\n",
      "\n",
      "The classification loss after processing this batch is:  0.39597728848457336\n",
      "The representation loss after processing this batch is:  0.004947654902935028\n",
      "\n",
      "The classification loss after processing this batch is:  0.5872427821159363\n",
      "The representation loss after processing this batch is:  0.005702860653400421\n",
      "\n",
      "The classification loss after processing this batch is:  0.44374048709869385\n",
      "The representation loss after processing this batch is:  0.004634328186511993\n",
      "\n",
      "The classification loss after processing this batch is:  0.4051796793937683\n",
      "The representation loss after processing this batch is:  0.005434289574623108\n",
      "\n",
      "The classification loss after processing this batch is:  0.505027174949646\n",
      "The representation loss after processing this batch is:  0.004464864730834961\n",
      "\n",
      "The classification loss after processing this batch is:  0.35546866059303284\n",
      "The representation loss after processing this batch is:  0.004641320556402206\n",
      "\n",
      "The classification loss after processing this batch is:  0.39725998044013977\n",
      "The representation loss after processing this batch is:  0.004883341491222382\n",
      "\n",
      "The classification loss after processing this batch is:  0.4925301671028137\n",
      "The representation loss after processing this batch is:  0.004604704678058624\n",
      "\n",
      "The classification loss after processing this batch is:  0.596307098865509\n",
      "The representation loss after processing this batch is:  0.004522435367107391\n",
      "\n",
      "The classification loss after processing this batch is:  0.6107069253921509\n",
      "The representation loss after processing this batch is:  0.004550471901893616\n",
      "\n",
      "The classification loss after processing this batch is:  0.5255367159843445\n",
      "The representation loss after processing this batch is:  0.0047365352511405945\n",
      "\n",
      "The classification loss after processing this batch is:  0.5004904866218567\n",
      "The representation loss after processing this batch is:  0.005124174058437347\n",
      "\n",
      "The classification loss after processing this batch is:  0.3709926903247833\n",
      "The representation loss after processing this batch is:  0.003948614001274109\n",
      "\n",
      "The classification loss after processing this batch is:  0.3805142343044281\n",
      "The representation loss after processing this batch is:  0.004492677748203278\n",
      "\n",
      "The classification loss after processing this batch is:  0.35524681210517883\n",
      "The representation loss after processing this batch is:  0.0045465752482414246\n",
      "\n",
      "The classification loss after processing this batch is:  0.39076945185661316\n",
      "The representation loss after processing this batch is:  0.004383645951747894\n",
      "\n",
      "The classification loss after processing this batch is:  0.46338802576065063\n",
      "The representation loss after processing this batch is:  0.004884935915470123\n",
      "\n",
      "The classification loss after processing this batch is:  0.41865384578704834\n",
      "The representation loss after processing this batch is:  0.004558861255645752\n",
      "\n",
      "The classification loss after processing this batch is:  0.496372789144516\n",
      "The representation loss after processing this batch is:  0.0052398815751075745\n",
      "\n",
      "The classification loss after processing this batch is:  0.31807515025138855\n",
      "The representation loss after processing this batch is:  0.004566479474306107\n",
      "\n",
      "The classification loss after processing this batch is:  0.38715189695358276\n",
      "The representation loss after processing this batch is:  0.0049840547144412994\n",
      "\n",
      "The classification loss after processing this batch is:  0.3846973776817322\n",
      "The representation loss after processing this batch is:  0.005519844591617584\n",
      "\n",
      "The classification loss after processing this batch is:  0.5346195101737976\n",
      "The representation loss after processing this batch is:  0.005178347229957581\n",
      "\n",
      "The classification loss after processing this batch is:  0.35106563568115234\n",
      "The representation loss after processing this batch is:  0.005830921232700348\n",
      "\n",
      "The classification loss after processing this batch is:  0.7296998500823975\n",
      "The representation loss after processing this batch is:  0.005755618214607239\n",
      "\n",
      "The classification loss after processing this batch is:  0.597366452217102\n",
      "The representation loss after processing this batch is:  0.006065551191568375\n",
      "\n",
      "The classification loss after processing this batch is:  0.5696519017219543\n",
      "The representation loss after processing this batch is:  0.004993639886379242\n",
      "\n",
      "The classification loss after processing this batch is:  0.47675496339797974\n",
      "The representation loss after processing this batch is:  0.005141213536262512\n",
      "\n",
      "The classification loss after processing this batch is:  0.3488885760307312\n",
      "The representation loss after processing this batch is:  0.005191631615161896\n",
      "\n",
      "The classification loss after processing this batch is:  0.44541260600090027\n",
      "The representation loss after processing this batch is:  0.004365555942058563\n",
      "\n",
      "The classification loss after processing this batch is:  0.4174404442310333\n",
      "The representation loss after processing this batch is:  0.005262784659862518\n",
      "\n",
      "The classification loss after processing this batch is:  0.37828341126441956\n",
      "The representation loss after processing this batch is:  0.004485607147216797\n",
      "\n",
      "The classification loss after processing this batch is:  0.2612258195877075\n",
      "The representation loss after processing this batch is:  0.004301898181438446\n",
      "\n",
      "The classification loss after processing this batch is:  0.4968441128730774\n",
      "The representation loss after processing this batch is:  0.004783131182193756\n",
      "\n",
      "The classification loss after processing this batch is:  0.5801898837089539\n",
      "The representation loss after processing this batch is:  0.004507787525653839\n",
      "\n",
      "The classification loss after processing this batch is:  0.542812705039978\n",
      "The representation loss after processing this batch is:  0.0043919384479522705\n",
      "\n",
      "The classification loss after processing this batch is:  0.478323757648468\n",
      "The representation loss after processing this batch is:  0.004466533660888672\n",
      "\n",
      "The classification loss after processing this batch is:  0.6651567220687866\n",
      "The representation loss after processing this batch is:  0.0051794275641441345\n",
      "\n",
      "The classification loss after processing this batch is:  0.7591090798377991\n",
      "The representation loss after processing this batch is:  0.004744216799736023\n",
      "\n",
      "The classification loss after processing this batch is:  0.5013473629951477\n",
      "The representation loss after processing this batch is:  0.004518844187259674\n",
      "\n",
      "The classification loss after processing this batch is:  0.4058155119419098\n",
      "The representation loss after processing this batch is:  0.00483279675245285\n",
      "\n",
      "The classification loss after processing this batch is:  0.5470908284187317\n",
      "The representation loss after processing this batch is:  0.0048577263951301575\n",
      "\n",
      "The classification loss after processing this batch is:  0.4992569088935852\n",
      "The representation loss after processing this batch is:  0.005150608718395233\n",
      "\n",
      "The classification loss after processing this batch is:  0.474335640668869\n",
      "The representation loss after processing this batch is:  0.004499368369579315\n",
      "\n",
      "The classification loss after processing this batch is:  0.3513183295726776\n",
      "The representation loss after processing this batch is:  0.004847772419452667\n",
      "\n",
      "The classification loss after processing this batch is:  0.3202448785305023\n",
      "The representation loss after processing this batch is:  0.004207581281661987\n",
      "\n",
      "The classification loss after processing this batch is:  0.30699965357780457\n",
      "The representation loss after processing this batch is:  0.0048565492033958435\n",
      "\n",
      "The classification loss after processing this batch is:  0.5066791772842407\n",
      "The representation loss after processing this batch is:  0.004557915031909943\n",
      "\n",
      "The classification loss after processing this batch is:  0.5208848714828491\n",
      "The representation loss after processing this batch is:  0.004445284605026245\n",
      "\n",
      "The classification loss after processing this batch is:  0.38035982847213745\n",
      "The representation loss after processing this batch is:  0.005226165056228638\n",
      "\n",
      "The classification loss after processing this batch is:  0.4195142090320587\n",
      "The representation loss after processing this batch is:  0.005243506282567978\n",
      "\n",
      "The classification loss after processing this batch is:  0.4370252192020416\n",
      "The representation loss after processing this batch is:  0.004712320864200592\n",
      "\n",
      "The classification loss after processing this batch is:  0.2677156329154968\n",
      "The representation loss after processing this batch is:  0.004899382591247559\n",
      "\n",
      "The classification loss after processing this batch is:  0.4923017621040344\n",
      "The representation loss after processing this batch is:  0.004463203251361847\n",
      "\n",
      "The classification loss after processing this batch is:  0.442500501871109\n",
      "The representation loss after processing this batch is:  0.004743531346321106\n",
      "\n",
      "The classification loss after processing this batch is:  0.5547953248023987\n",
      "The representation loss after processing this batch is:  0.004497028887271881\n",
      "\n",
      "The classification loss after processing this batch is:  0.5677896738052368\n",
      "The representation loss after processing this batch is:  0.005654819309711456\n",
      "\n",
      "The classification loss after processing this batch is:  0.5696952939033508\n",
      "The representation loss after processing this batch is:  0.004906751215457916\n",
      "\n",
      "The classification loss after processing this batch is:  0.28138479590415955\n",
      "The representation loss after processing this batch is:  0.004872899502515793\n",
      "\n",
      "The classification loss after processing this batch is:  0.28643128275871277\n",
      "The representation loss after processing this batch is:  0.004300378262996674\n",
      "\n",
      "The classification loss after processing this batch is:  0.41789260506629944\n",
      "The representation loss after processing this batch is:  0.004804063588380814\n",
      "\n",
      "The classification loss after processing this batch is:  0.29773107171058655\n",
      "The representation loss after processing this batch is:  0.004882872104644775\n",
      "\n",
      "The classification loss after processing this batch is:  0.5308718085289001\n",
      "The representation loss after processing this batch is:  0.004908449947834015\n",
      "\n",
      "The classification loss after processing this batch is:  0.3912167549133301\n",
      "The representation loss after processing this batch is:  0.005112968385219574\n",
      "\n",
      "The classification loss after processing this batch is:  0.5098263025283813\n",
      "The representation loss after processing this batch is:  0.004821624606847763\n",
      "\n",
      "The classification loss after processing this batch is:  0.5264647603034973\n",
      "The representation loss after processing this batch is:  0.004767611622810364\n",
      "\n",
      "The classification loss after processing this batch is:  0.41445666551589966\n",
      "The representation loss after processing this batch is:  0.004318401217460632\n",
      "\n",
      "The classification loss after processing this batch is:  0.38521847128868103\n",
      "The representation loss after processing this batch is:  0.0054306089878082275\n",
      "\n",
      "The classification loss after processing this batch is:  0.43670666217803955\n",
      "The representation loss after processing this batch is:  0.005376048386096954\n",
      "\n",
      "The classification loss after processing this batch is:  0.45506349205970764\n",
      "The representation loss after processing this batch is:  0.004650332033634186\n",
      "\n",
      "The classification loss after processing this batch is:  0.633441150188446\n",
      "The representation loss after processing this batch is:  0.005907364189624786\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.6890037655830383\n",
      "The representation loss after processing this batch is:  0.005165651440620422\n",
      "\n",
      "The classification loss after processing this batch is:  0.6065201163291931\n",
      "The representation loss after processing this batch is:  0.004409469664096832\n",
      "\n",
      "The classification loss after processing this batch is:  0.39771080017089844\n",
      "The representation loss after processing this batch is:  0.004424974322319031\n",
      "\n",
      "The classification loss after processing this batch is:  0.3377018868923187\n",
      "The representation loss after processing this batch is:  0.004681341350078583\n",
      "\n",
      "The classification loss after processing this batch is:  0.3381550908088684\n",
      "The representation loss after processing this batch is:  0.0045365020632743835\n",
      "\n",
      "The classification loss after processing this batch is:  0.3532212972640991\n",
      "The representation loss after processing this batch is:  0.004500746726989746\n",
      "\n",
      "The classification loss after processing this batch is:  0.472189337015152\n",
      "The representation loss after processing this batch is:  0.004047174006700516\n",
      "\n",
      "The classification loss after processing this batch is:  0.4000856280326843\n",
      "The representation loss after processing this batch is:  0.005257345736026764\n",
      "\n",
      "The classification loss after processing this batch is:  0.41454172134399414\n",
      "The representation loss after processing this batch is:  0.004938080906867981\n",
      "\n",
      "The classification loss after processing this batch is:  0.35686737298965454\n",
      "The representation loss after processing this batch is:  0.004694655537605286\n",
      "\n",
      "The classification loss after processing this batch is:  0.40409597754478455\n",
      "The representation loss after processing this batch is:  0.005018189549446106\n",
      "\n",
      "The classification loss after processing this batch is:  0.392647385597229\n",
      "The representation loss after processing this batch is:  0.004435285925865173\n",
      "\n",
      "The classification loss after processing this batch is:  0.4612722098827362\n",
      "The representation loss after processing this batch is:  0.003950715065002441\n",
      "\n",
      "The classification loss after processing this batch is:  0.39239057898521423\n",
      "The representation loss after processing this batch is:  0.004664942622184753\n",
      "\n",
      "The classification loss after processing this batch is:  0.40129145979881287\n",
      "The representation loss after processing this batch is:  0.0048094019293785095\n",
      "\n",
      "The classification loss after processing this batch is:  0.410434752702713\n",
      "The representation loss after processing this batch is:  0.004836626350879669\n",
      "\n",
      "The classification loss after processing this batch is:  0.5112259387969971\n",
      "The representation loss after processing this batch is:  0.004950381815433502\n",
      "\n",
      "The classification loss after processing this batch is:  0.3384779691696167\n",
      "The representation loss after processing this batch is:  0.004542522132396698\n",
      "\n",
      "The classification loss after processing this batch is:  0.3243269920349121\n",
      "The representation loss after processing this batch is:  0.0040984079241752625\n",
      "\n",
      "The classification loss after processing this batch is:  0.44683992862701416\n",
      "The representation loss after processing this batch is:  0.00530734658241272\n",
      "\n",
      "The classification loss after processing this batch is:  0.3973366916179657\n",
      "The representation loss after processing this batch is:  0.004176728427410126\n",
      "\n",
      "The classification loss after processing this batch is:  0.5479052066802979\n",
      "The representation loss after processing this batch is:  0.004350252449512482\n",
      "\n",
      "The classification loss after processing this batch is:  0.4491710662841797\n",
      "The representation loss after processing this batch is:  0.004791565239429474\n",
      "\n",
      "The classification loss after processing this batch is:  0.38426637649536133\n",
      "The representation loss after processing this batch is:  0.005336940288543701\n",
      "\n",
      "The classification loss after processing this batch is:  0.3797129988670349\n",
      "The representation loss after processing this batch is:  0.0048140063881874084\n",
      "\n",
      "The classification loss after processing this batch is:  0.37440547347068787\n",
      "The representation loss after processing this batch is:  0.005424566566944122\n",
      "\n",
      "The classification loss after processing this batch is:  0.5496931076049805\n",
      "The representation loss after processing this batch is:  0.004494823515415192\n",
      "\n",
      "The classification loss after processing this batch is:  0.29646751284599304\n",
      "The representation loss after processing this batch is:  0.0054113417863845825\n",
      "\n",
      "The classification loss after processing this batch is:  0.36236685514450073\n",
      "The representation loss after processing this batch is:  0.005708083510398865\n",
      "\n",
      "The classification loss after processing this batch is:  0.38784754276275635\n",
      "The representation loss after processing this batch is:  0.004213109612464905\n",
      "\n",
      "The classification loss after processing this batch is:  0.6000354886054993\n",
      "The representation loss after processing this batch is:  0.004947181791067123\n",
      "\n",
      "The classification loss after processing this batch is:  0.36214640736579895\n",
      "The representation loss after processing this batch is:  0.004527345299720764\n",
      "\n",
      "The classification loss after processing this batch is:  0.39937666058540344\n",
      "The representation loss after processing this batch is:  0.004434235394001007\n",
      "\n",
      "The classification loss after processing this batch is:  0.3236899971961975\n",
      "The representation loss after processing this batch is:  0.004803963005542755\n",
      "\n",
      "The classification loss after processing this batch is:  0.3040260970592499\n",
      "The representation loss after processing this batch is:  0.004606582224369049\n",
      "\n",
      "The classification loss after processing this batch is:  0.43158218264579773\n",
      "The representation loss after processing this batch is:  0.005545921623706818\n",
      "\n",
      "The classification loss after processing this batch is:  0.3543703854084015\n",
      "The representation loss after processing this batch is:  0.0066862404346466064\n",
      "\n",
      "The classification loss after processing this batch is:  0.29192930459976196\n",
      "The representation loss after processing this batch is:  0.005615167319774628\n",
      "\n",
      "The classification loss after processing this batch is:  0.3996361196041107\n",
      "The representation loss after processing this batch is:  0.004766538739204407\n",
      "\n",
      "The classification loss after processing this batch is:  0.5064616799354553\n",
      "The representation loss after processing this batch is:  0.00450906902551651\n",
      "\n",
      "The classification loss after processing this batch is:  0.4607013761997223\n",
      "The representation loss after processing this batch is:  0.005285818129777908\n",
      "\n",
      "The classification loss after processing this batch is:  0.3513118624687195\n",
      "The representation loss after processing this batch is:  0.004983082413673401\n",
      "\n",
      "The classification loss after processing this batch is:  0.44163310527801514\n",
      "The representation loss after processing this batch is:  0.004956632852554321\n",
      "\n",
      "The classification loss after processing this batch is:  0.5305871367454529\n",
      "The representation loss after processing this batch is:  0.0045926496386528015\n",
      "\n",
      "The classification loss after processing this batch is:  0.48284614086151123\n",
      "The representation loss after processing this batch is:  0.005139373242855072\n",
      "\n",
      "The classification loss after processing this batch is:  0.46072155237197876\n",
      "The representation loss after processing this batch is:  0.0044784098863601685\n",
      "\n",
      "The classification loss after processing this batch is:  0.4732969403266907\n",
      "The representation loss after processing this batch is:  0.005017079412937164\n",
      "\n",
      "The classification loss after processing this batch is:  0.5665430426597595\n",
      "The representation loss after processing this batch is:  0.004504121840000153\n",
      "\n",
      "The classification loss after processing this batch is:  0.34133440256118774\n",
      "The representation loss after processing this batch is:  0.00498836487531662\n",
      "\n",
      "The classification loss after processing this batch is:  0.32812929153442383\n",
      "The representation loss after processing this batch is:  0.0053153932094573975\n",
      "\n",
      "The classification loss after processing this batch is:  0.3286689519882202\n",
      "The representation loss after processing this batch is:  0.004677623510360718\n",
      "\n",
      "The classification loss after processing this batch is:  0.3422946333885193\n",
      "The representation loss after processing this batch is:  0.004247158765792847\n",
      "\n",
      "The classification loss after processing this batch is:  0.4282228350639343\n",
      "The representation loss after processing this batch is:  0.0050525963306427\n",
      "\n",
      "The classification loss after processing this batch is:  0.37941500544548035\n",
      "The representation loss after processing this batch is:  0.005462527275085449\n",
      "\n",
      "The classification loss after processing this batch is:  0.2561275362968445\n",
      "The representation loss after processing this batch is:  0.005145154893398285\n",
      "\n",
      "The classification loss after processing this batch is:  0.2282731682062149\n",
      "The representation loss after processing this batch is:  0.005126602947711945\n",
      "\n",
      "The classification loss after processing this batch is:  0.34527111053466797\n",
      "The representation loss after processing this batch is:  0.005155511200428009\n",
      "\n",
      "The classification loss after processing this batch is:  0.38962751626968384\n",
      "The representation loss after processing this batch is:  0.005653396248817444\n",
      "\n",
      "The classification loss after processing this batch is:  0.45711496472358704\n",
      "The representation loss after processing this batch is:  0.004767365753650665\n",
      "\n",
      "The classification loss after processing this batch is:  0.3085504174232483\n",
      "The representation loss after processing this batch is:  0.004389643669128418\n",
      "\n",
      "The classification loss after processing this batch is:  0.27281200885772705\n",
      "The representation loss after processing this batch is:  0.004948921501636505\n",
      "\n",
      "The classification loss after processing this batch is:  0.32954397797584534\n",
      "The representation loss after processing this batch is:  0.005259595811367035\n",
      "\n",
      "The classification loss after processing this batch is:  0.2959364950656891\n",
      "The representation loss after processing this batch is:  0.007148072123527527\n",
      "\n",
      "The classification loss after processing this batch is:  0.22689883410930634\n",
      "The representation loss after processing this batch is:  0.00653935968875885\n",
      "\n",
      "The classification loss after processing this batch is:  0.2679433226585388\n",
      "The representation loss after processing this batch is:  0.006429776549339294\n",
      "\n",
      "The classification loss after processing this batch is:  0.41663992404937744\n",
      "The representation loss after processing this batch is:  0.004933491349220276\n",
      "\n",
      "The classification loss after processing this batch is:  0.23986177146434784\n",
      "The representation loss after processing this batch is:  0.005281426012516022\n",
      "\n",
      "The classification loss after processing this batch is:  0.19872716069221497\n",
      "The representation loss after processing this batch is:  0.004801042377948761\n",
      "\n",
      "The classification loss after processing this batch is:  0.27108338475227356\n",
      "The representation loss after processing this batch is:  0.004682376980781555\n",
      "\n",
      "The classification loss after processing this batch is:  0.2842092216014862\n",
      "The representation loss after processing this batch is:  0.00545337051153183\n",
      "\n",
      "The classification loss after processing this batch is:  0.21667398512363434\n",
      "The representation loss after processing this batch is:  0.004423990845680237\n",
      "\n",
      "The classification loss after processing this batch is:  0.2930445671081543\n",
      "The representation loss after processing this batch is:  0.005089014768600464\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.25018492341041565\n",
      "The representation loss after processing this batch is:  0.005889378488063812\n",
      "\n",
      "The classification loss after processing this batch is:  0.6601131558418274\n",
      "The representation loss after processing this batch is:  0.005667954683303833\n",
      "\n",
      "The classification loss after processing this batch is:  0.6207292079925537\n",
      "The representation loss after processing this batch is:  0.00515630841255188\n",
      "\n",
      "The classification loss after processing this batch is:  0.4802708923816681\n",
      "The representation loss after processing this batch is:  0.005741387605667114\n",
      "\n",
      "The classification loss after processing this batch is:  0.24922701716423035\n",
      "The representation loss after processing this batch is:  0.0047830864787101746\n",
      "\n",
      "The classification loss after processing this batch is:  0.22682085633277893\n",
      "The representation loss after processing this batch is:  0.005721554160118103\n",
      "\n",
      "The classification loss after processing this batch is:  0.24621371924877167\n",
      "The representation loss after processing this batch is:  0.003998354077339172\n",
      "\n",
      "The classification loss after processing this batch is:  0.31455621123313904\n",
      "The representation loss after processing this batch is:  0.00407777726650238\n",
      "\n",
      "The classification loss after processing this batch is:  0.6289845108985901\n",
      "The representation loss after processing this batch is:  0.004905857145786285\n",
      "\n",
      "The classification loss after processing this batch is:  0.2905021607875824\n",
      "The representation loss after processing this batch is:  0.004788786172866821\n",
      "\n",
      "The classification loss after processing this batch is:  0.20231205224990845\n",
      "The representation loss after processing this batch is:  0.005350947380065918\n",
      "\n",
      "The classification loss after processing this batch is:  0.3299174904823303\n",
      "The representation loss after processing this batch is:  0.005254685878753662\n",
      "\n",
      "The classification loss after processing this batch is:  0.3034479022026062\n",
      "The representation loss after processing this batch is:  0.006986856460571289\n",
      "\n",
      "The classification loss after processing this batch is:  0.4234120547771454\n",
      "The representation loss after processing this batch is:  0.004503101110458374\n",
      "\n",
      "The classification loss after processing this batch is:  0.2630314528942108\n",
      "The representation loss after processing this batch is:  0.004250809550285339\n",
      "\n",
      "The classification loss after processing this batch is:  0.4259588122367859\n",
      "The representation loss after processing this batch is:  0.004373505711555481\n",
      "\n",
      "The classification loss after processing this batch is:  0.3316355347633362\n",
      "The representation loss after processing this batch is:  0.004751507192850113\n",
      "\n",
      "The classification loss after processing this batch is:  0.38899460434913635\n",
      "The representation loss after processing this batch is:  0.004226908087730408\n",
      "\n",
      "The classification loss after processing this batch is:  0.2851252853870392\n",
      "The representation loss after processing this batch is:  0.0046286433935165405\n",
      "\n",
      "The classification loss after processing this batch is:  0.37945157289505005\n",
      "The representation loss after processing this batch is:  0.005728386342525482\n",
      "\n",
      "The classification loss after processing this batch is:  0.34243980050086975\n",
      "The representation loss after processing this batch is:  0.004489973187446594\n",
      "\n",
      "The classification loss after processing this batch is:  0.44528552889823914\n",
      "The representation loss after processing this batch is:  0.004737988114356995\n",
      "\n",
      "The classification loss after processing this batch is:  0.4337824583053589\n",
      "The representation loss after processing this batch is:  0.004806704819202423\n",
      "\n",
      "The classification loss after processing this batch is:  0.5193269848823547\n",
      "The representation loss after processing this batch is:  0.004552990198135376\n",
      "\n",
      "The classification loss after processing this batch is:  0.3549441397190094\n",
      "The representation loss after processing this batch is:  0.0043614692986011505\n",
      "\n",
      "The classification loss after processing this batch is:  0.4436537027359009\n",
      "The representation loss after processing this batch is:  0.0044681355357170105\n",
      "\n",
      "The classification loss after processing this batch is:  0.28890231251716614\n",
      "The representation loss after processing this batch is:  0.00366026908159256\n",
      "\n",
      "The classification loss after processing this batch is:  0.6557877659797668\n",
      "The representation loss after processing this batch is:  0.004669263958930969\n",
      "\n",
      "The classification loss after processing this batch is:  0.48341795802116394\n",
      "The representation loss after processing this batch is:  0.004792205989360809\n",
      "\n",
      "The classification loss after processing this batch is:  0.4358596205711365\n",
      "The representation loss after processing this batch is:  0.004884887486696243\n",
      "\n",
      "The classification loss after processing this batch is:  0.5874537825584412\n",
      "The representation loss after processing this batch is:  0.005313824862241745\n",
      "\n",
      "The classification loss after processing this batch is:  0.5359101891517639\n",
      "The representation loss after processing this batch is:  0.005070380866527557\n",
      "\n",
      "The classification loss after processing this batch is:  0.34262731671333313\n",
      "The representation loss after processing this batch is:  0.005687549710273743\n",
      "\n",
      "The classification loss after processing this batch is:  0.5497224926948547\n",
      "The representation loss after processing this batch is:  0.005385994911193848\n",
      "\n",
      "The classification loss after processing this batch is:  0.4600037932395935\n",
      "The representation loss after processing this batch is:  0.005244344472885132\n",
      "\n",
      "The classification loss after processing this batch is:  0.5512226819992065\n",
      "The representation loss after processing this batch is:  0.004582345485687256\n",
      "\n",
      "The classification loss after processing this batch is:  0.3979351222515106\n",
      "The representation loss after processing this batch is:  0.003725629299879074\n",
      "\n",
      "The classification loss after processing this batch is:  0.3507082760334015\n",
      "The representation loss after processing this batch is:  0.004244491457939148\n",
      "\n",
      "The classification loss after processing this batch is:  0.35600990056991577\n",
      "The representation loss after processing this batch is:  0.0046136341989040375\n",
      "\n",
      "The classification loss after processing this batch is:  0.46883299946784973\n",
      "The representation loss after processing this batch is:  0.004449889063835144\n",
      "\n",
      "The classification loss after processing this batch is:  0.32133612036705017\n",
      "The representation loss after processing this batch is:  0.004466436803340912\n",
      "\n",
      "The classification loss after processing this batch is:  0.24716132879257202\n",
      "The representation loss after processing this batch is:  0.004263199865818024\n",
      "\n",
      "The classification loss after processing this batch is:  0.24872566759586334\n",
      "The representation loss after processing this batch is:  0.004852138459682465\n",
      "\n",
      "The classification loss after processing this batch is:  0.30648273229599\n",
      "The representation loss after processing this batch is:  0.004486501216888428\n",
      "\n",
      "The classification loss after processing this batch is:  0.33163243532180786\n",
      "The representation loss after processing this batch is:  0.005023933947086334\n",
      "\n",
      "The classification loss after processing this batch is:  0.41606956720352173\n",
      "The representation loss after processing this batch is:  0.0048824697732925415\n",
      "\n",
      "The classification loss after processing this batch is:  0.3934057652950287\n",
      "The representation loss after processing this batch is:  0.005419351160526276\n",
      "\n",
      "The classification loss after processing this batch is:  0.3149503171443939\n",
      "The representation loss after processing this batch is:  0.00497480109333992\n",
      "\n",
      "The classification loss after processing this batch is:  0.23992274701595306\n",
      "The representation loss after processing this batch is:  0.004803232848644257\n",
      "\n",
      "The classification loss after processing this batch is:  0.3662794530391693\n",
      "The representation loss after processing this batch is:  0.004767224192619324\n",
      "\n",
      "The classification loss after processing this batch is:  0.37062737345695496\n",
      "The representation loss after processing this batch is:  0.0043553560972213745\n",
      "\n",
      "The classification loss after processing this batch is:  0.2635025382041931\n",
      "The representation loss after processing this batch is:  0.004659056663513184\n",
      "\n",
      "The classification loss after processing this batch is:  0.3457295596599579\n",
      "The representation loss after processing this batch is:  0.004503093659877777\n",
      "\n",
      "The classification loss after processing this batch is:  0.5090197324752808\n",
      "The representation loss after processing this batch is:  0.005111277103424072\n",
      "\n",
      "The classification loss after processing this batch is:  0.3195604979991913\n",
      "The representation loss after processing this batch is:  0.004553802311420441\n",
      "\n",
      "The classification loss after processing this batch is:  0.37186089158058167\n",
      "The representation loss after processing this batch is:  0.0041668713092803955\n",
      "\n",
      "The classification loss after processing this batch is:  0.3412950932979584\n",
      "The representation loss after processing this batch is:  0.0043473318219184875\n",
      "\n",
      "The classification loss after processing this batch is:  0.3001900315284729\n",
      "The representation loss after processing this batch is:  0.003924846649169922\n",
      "\n",
      "The classification loss after processing this batch is:  0.3842223882675171\n",
      "The representation loss after processing this batch is:  0.0036465078592300415\n",
      "\n",
      "The classification loss after processing this batch is:  0.4182174801826477\n",
      "The representation loss after processing this batch is:  0.00459626317024231\n",
      "\n",
      "The classification loss after processing this batch is:  0.2562713623046875\n",
      "The representation loss after processing this batch is:  0.004213578999042511\n",
      "\n",
      "The classification loss after processing this batch is:  0.34393393993377686\n",
      "The representation loss after processing this batch is:  0.003958284854888916\n",
      "\n",
      "The classification loss after processing this batch is:  0.329435259103775\n",
      "The representation loss after processing this batch is:  0.004836924374103546\n",
      "\n",
      "The classification loss after processing this batch is:  0.374421089887619\n",
      "The representation loss after processing this batch is:  0.00456291064620018\n",
      "\n",
      "The classification loss after processing this batch is:  0.3898136019706726\n",
      "The representation loss after processing this batch is:  0.004865139722824097\n",
      "\n",
      "The classification loss after processing this batch is:  0.3283850848674774\n",
      "The representation loss after processing this batch is:  0.004308223724365234\n",
      "\n",
      "The classification loss after processing this batch is:  0.3103046417236328\n",
      "The representation loss after processing this batch is:  0.005076497793197632\n",
      "\n",
      "The classification loss after processing this batch is:  0.37456533312797546\n",
      "The representation loss after processing this batch is:  0.004929967224597931\n",
      "\n",
      "The classification loss after processing this batch is:  0.37884795665740967\n",
      "The representation loss after processing this batch is:  0.004493311047554016\n",
      "\n",
      "The classification loss after processing this batch is:  0.42450669407844543\n",
      "The representation loss after processing this batch is:  0.00427883118391037\n",
      "\n",
      "The classification loss after processing this batch is:  0.2966177761554718\n",
      "The representation loss after processing this batch is:  0.004869244992733002\n",
      "\n",
      "The classification loss after processing this batch is:  0.420667439699173\n",
      "The representation loss after processing this batch is:  0.005004845559597015\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.28498607873916626\n",
      "The representation loss after processing this batch is:  0.0037676170468330383\n",
      "\n",
      "The classification loss after processing this batch is:  0.2863256633281708\n",
      "The representation loss after processing this batch is:  0.004691660404205322\n",
      "\n",
      "The classification loss after processing this batch is:  0.35265466570854187\n",
      "The representation loss after processing this batch is:  0.004488419741392136\n",
      "\n",
      "The classification loss after processing this batch is:  0.38844138383865356\n",
      "The representation loss after processing this batch is:  0.004156298935413361\n",
      "\n",
      "The classification loss after processing this batch is:  0.32687288522720337\n",
      "The representation loss after processing this batch is:  0.00481172651052475\n",
      "\n",
      "The classification loss after processing this batch is:  0.33461421728134155\n",
      "The representation loss after processing this batch is:  0.004204601049423218\n",
      "\n",
      "The classification loss after processing this batch is:  0.3519802689552307\n",
      "The representation loss after processing this batch is:  0.0039749667048454285\n",
      "\n",
      "The classification loss after processing this batch is:  0.43807798624038696\n",
      "The representation loss after processing this batch is:  0.005009263753890991\n",
      "\n",
      "The classification loss after processing this batch is:  0.36731433868408203\n",
      "The representation loss after processing this batch is:  0.004282746464014053\n",
      "\n",
      "The classification loss after processing this batch is:  0.24814017117023468\n",
      "The representation loss after processing this batch is:  0.004598550498485565\n",
      "\n",
      "The classification loss after processing this batch is:  0.48338043689727783\n",
      "The representation loss after processing this batch is:  0.004549793899059296\n",
      "\n",
      "The classification loss after processing this batch is:  0.33728426694869995\n",
      "The representation loss after processing this batch is:  0.004582647234201431\n",
      "\n",
      "The classification loss after processing this batch is:  0.41463449597358704\n",
      "The representation loss after processing this batch is:  0.004715263843536377\n",
      "\n",
      "The classification loss after processing this batch is:  0.4093893766403198\n",
      "The representation loss after processing this batch is:  0.004048332571983337\n",
      "\n",
      "The classification loss after processing this batch is:  0.27949628233909607\n",
      "The representation loss after processing this batch is:  0.0043462663888931274\n",
      "\n",
      "The classification loss after processing this batch is:  0.3467133343219757\n",
      "The representation loss after processing this batch is:  0.004079714417457581\n",
      "\n",
      "The classification loss after processing this batch is:  0.33592528104782104\n",
      "The representation loss after processing this batch is:  0.003764227032661438\n",
      "\n",
      "The classification loss after processing this batch is:  0.3139719069004059\n",
      "The representation loss after processing this batch is:  0.004049330949783325\n",
      "\n",
      "The classification loss after processing this batch is:  0.49063917994499207\n",
      "The representation loss after processing this batch is:  0.0041489675641059875\n",
      "\n",
      "The classification loss after processing this batch is:  0.35546207427978516\n",
      "The representation loss after processing this batch is:  0.003953792154788971\n",
      "\n",
      "The classification loss after processing this batch is:  0.3156513571739197\n",
      "The representation loss after processing this batch is:  0.004776105284690857\n",
      "\n",
      "The classification loss after processing this batch is:  0.4464947581291199\n",
      "The representation loss after processing this batch is:  0.0045437291264534\n",
      "\n",
      "The classification loss after processing this batch is:  0.3525131344795227\n",
      "The representation loss after processing this batch is:  0.004701204597949982\n",
      "\n",
      "The classification loss after processing this batch is:  0.4706149399280548\n",
      "The representation loss after processing this batch is:  0.005351215600967407\n",
      "\n",
      "The classification loss after processing this batch is:  0.33631280064582825\n",
      "The representation loss after processing this batch is:  0.004831045866012573\n",
      "\n",
      "The classification loss after processing this batch is:  0.37970301508903503\n",
      "The representation loss after processing this batch is:  0.003802478313446045\n",
      "\n",
      "The classification loss after processing this batch is:  0.5981662273406982\n",
      "The representation loss after processing this batch is:  0.004458911716938019\n",
      "\n",
      "The classification loss after processing this batch is:  0.41028258204460144\n",
      "The representation loss after processing this batch is:  0.004041101783514023\n",
      "\n",
      "The classification loss after processing this batch is:  0.31313052773475647\n",
      "The representation loss after processing this batch is:  0.004731006920337677\n",
      "\n",
      "The classification loss after processing this batch is:  0.47801473736763\n",
      "The representation loss after processing this batch is:  0.003993958234786987\n",
      "\n",
      "The classification loss after processing this batch is:  0.3888345956802368\n",
      "The representation loss after processing this batch is:  0.0038774237036705017\n",
      "\n",
      "The classification loss after processing this batch is:  0.3411538898944855\n",
      "The representation loss after processing this batch is:  0.004523422569036484\n",
      "\n",
      "The classification loss after processing this batch is:  0.28671392798423767\n",
      "The representation loss after processing this batch is:  0.004153110086917877\n",
      "\n",
      "The classification loss after processing this batch is:  0.365649551153183\n",
      "The representation loss after processing this batch is:  0.004223749041557312\n",
      "\n",
      "The classification loss after processing this batch is:  0.39201509952545166\n",
      "The representation loss after processing this batch is:  0.004375025629997253\n",
      "\n",
      "The classification loss after processing this batch is:  0.33434218168258667\n",
      "The representation loss after processing this batch is:  0.0051043033599853516\n",
      "\n",
      "The classification loss after processing this batch is:  0.4615562856197357\n",
      "The representation loss after processing this batch is:  0.004217095673084259\n",
      "\n",
      "The classification loss after processing this batch is:  0.4029083847999573\n",
      "The representation loss after processing this batch is:  0.004198543727397919\n",
      "\n",
      "The classification loss after processing this batch is:  0.4844770133495331\n",
      "The representation loss after processing this batch is:  0.005151174962520599\n",
      "\n",
      "The classification loss after processing this batch is:  0.33710190653800964\n",
      "The representation loss after processing this batch is:  0.004857689142227173\n",
      "\n",
      "The classification loss after processing this batch is:  0.2954035997390747\n",
      "The representation loss after processing this batch is:  0.004342421889305115\n",
      "\n",
      "The classification loss after processing this batch is:  0.2453380972146988\n",
      "The representation loss after processing this batch is:  0.004609547555446625\n",
      "\n",
      "The classification loss after processing this batch is:  0.32723650336265564\n",
      "The representation loss after processing this batch is:  0.004608139395713806\n",
      "\n",
      "The classification loss after processing this batch is:  0.257445365190506\n",
      "The representation loss after processing this batch is:  0.0042320191860198975\n",
      "\n",
      "The classification loss after processing this batch is:  0.44582805037498474\n",
      "The representation loss after processing this batch is:  0.004721060395240784\n",
      "\n",
      "The classification loss after processing this batch is:  0.5222933888435364\n",
      "The representation loss after processing this batch is:  0.005025357007980347\n",
      "\n",
      "The classification loss after processing this batch is:  0.3426752984523773\n",
      "The representation loss after processing this batch is:  0.0045710280537605286\n",
      "\n",
      "The classification loss after processing this batch is:  0.2755277454853058\n",
      "The representation loss after processing this batch is:  0.004957646131515503\n",
      "\n",
      "The classification loss after processing this batch is:  0.34254616498947144\n",
      "The representation loss after processing this batch is:  0.00421549379825592\n",
      "\n",
      "The classification loss after processing this batch is:  0.26930153369903564\n",
      "The representation loss after processing this batch is:  0.005455620586872101\n",
      "\n",
      "The classification loss after processing this batch is:  0.20728185772895813\n",
      "The representation loss after processing this batch is:  0.004294365644454956\n",
      "\n",
      "The classification loss after processing this batch is:  0.3732493221759796\n",
      "The representation loss after processing this batch is:  0.003893442451953888\n",
      "\n",
      "The classification loss after processing this batch is:  0.33370116353034973\n",
      "The representation loss after processing this batch is:  0.006688542664051056\n",
      "\n",
      "The classification loss after processing this batch is:  0.2886066734790802\n",
      "The representation loss after processing this batch is:  0.004818543791770935\n",
      "\n",
      "The classification loss after processing this batch is:  0.520500898361206\n",
      "The representation loss after processing this batch is:  0.006335459649562836\n",
      "\n",
      "The classification loss after processing this batch is:  0.4437536895275116\n",
      "The representation loss after processing this batch is:  0.0037687867879867554\n",
      "\n",
      "The classification loss after processing this batch is:  0.4077005386352539\n",
      "The representation loss after processing this batch is:  0.0047711655497550964\n",
      "\n",
      "The classification loss after processing this batch is:  0.49524158239364624\n",
      "The representation loss after processing this batch is:  0.0041738152503967285\n",
      "\n",
      "The classification loss after processing this batch is:  0.3921128511428833\n",
      "The representation loss after processing this batch is:  0.004071496427059174\n",
      "\n",
      "The classification loss after processing this batch is:  0.2520599067211151\n",
      "The representation loss after processing this batch is:  0.004990924149751663\n",
      "\n",
      "The classification loss after processing this batch is:  0.4313153028488159\n",
      "The representation loss after processing this batch is:  0.004450641572475433\n",
      "\n",
      "The classification loss after processing this batch is:  0.6518983244895935\n",
      "The representation loss after processing this batch is:  0.0069003477692604065\n",
      "\n",
      "The classification loss after processing this batch is:  0.4806134104728699\n",
      "The representation loss after processing this batch is:  0.006048165261745453\n",
      "\n",
      "The classification loss after processing this batch is:  0.3627515137195587\n",
      "The representation loss after processing this batch is:  0.005827188491821289\n",
      "\n",
      "The classification loss after processing this batch is:  0.36711761355400085\n",
      "The representation loss after processing this batch is:  0.0046431273221969604\n",
      "\n",
      "The classification loss after processing this batch is:  0.35662925243377686\n",
      "The representation loss after processing this batch is:  0.006284043192863464\n",
      "\n",
      "The classification loss after processing this batch is:  0.3927207887172699\n",
      "The representation loss after processing this batch is:  0.004473850131034851\n",
      "\n",
      "The classification loss after processing this batch is:  0.29143768548965454\n",
      "The representation loss after processing this batch is:  0.00489392876625061\n",
      "\n",
      "The classification loss after processing this batch is:  0.4248439371585846\n",
      "The representation loss after processing this batch is:  0.004783399403095245\n",
      "\n",
      "The classification loss after processing this batch is:  0.3476939797401428\n",
      "The representation loss after processing this batch is:  0.004574097692966461\n",
      "\n",
      "The classification loss after processing this batch is:  0.49501001834869385\n",
      "The representation loss after processing this batch is:  0.004726603627204895\n",
      "\n",
      "The classification loss after processing this batch is:  0.3367525041103363\n",
      "The representation loss after processing this batch is:  0.004131991416215897\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.35691720247268677\n",
      "The representation loss after processing this batch is:  0.0037936903536319733\n",
      "\n",
      "The classification loss after processing this batch is:  0.37504270672798157\n",
      "The representation loss after processing this batch is:  0.0035352520644664764\n",
      "\n",
      "The classification loss after processing this batch is:  0.3976905941963196\n",
      "The representation loss after processing this batch is:  0.004499394446611404\n",
      "\n",
      "The classification loss after processing this batch is:  0.2726227641105652\n",
      "The representation loss after processing this batch is:  0.004551805555820465\n",
      "\n",
      "The classification loss after processing this batch is:  0.3930634558200836\n",
      "The representation loss after processing this batch is:  0.0043359920382499695\n",
      "\n",
      "The classification loss after processing this batch is:  0.39252060651779175\n",
      "The representation loss after processing this batch is:  0.004430606961250305\n",
      "\n",
      "The classification loss after processing this batch is:  0.45158860087394714\n",
      "The representation loss after processing this batch is:  0.004277780652046204\n",
      "\n",
      "The classification loss after processing this batch is:  0.40639469027519226\n",
      "The representation loss after processing this batch is:  0.0042461007833480835\n",
      "\n",
      "The classification loss after processing this batch is:  0.33494922518730164\n",
      "The representation loss after processing this batch is:  0.0046241506934165955\n",
      "\n",
      "The classification loss after processing this batch is:  0.48322799801826477\n",
      "The representation loss after processing this batch is:  0.004546660929918289\n",
      "\n",
      "The classification loss after processing this batch is:  0.4223884046077728\n",
      "The representation loss after processing this batch is:  0.004437386989593506\n",
      "\n",
      "The classification loss after processing this batch is:  0.26322266459465027\n",
      "The representation loss after processing this batch is:  0.004486896097660065\n",
      "\n",
      "The classification loss after processing this batch is:  0.3728354275226593\n",
      "The representation loss after processing this batch is:  0.004296168684959412\n",
      "\n",
      "The classification loss after processing this batch is:  0.551200270652771\n",
      "The representation loss after processing this batch is:  0.004029318690299988\n",
      "\n",
      "The classification loss after processing this batch is:  0.4750900864601135\n",
      "The representation loss after processing this batch is:  0.003904443234205246\n",
      "\n",
      "The classification loss after processing this batch is:  0.45363128185272217\n",
      "The representation loss after processing this batch is:  0.004490282386541367\n",
      "\n",
      "The classification loss after processing this batch is:  0.6189180016517639\n",
      "The representation loss after processing this batch is:  0.0040300264954566956\n",
      "\n",
      "The classification loss after processing this batch is:  0.4990635812282562\n",
      "The representation loss after processing this batch is:  0.003637567162513733\n",
      "\n",
      "The classification loss after processing this batch is:  0.26569584012031555\n",
      "The representation loss after processing this batch is:  0.0035069286823272705\n",
      "\n",
      "The classification loss after processing this batch is:  0.25454485416412354\n",
      "The representation loss after processing this batch is:  0.00442834198474884\n",
      "\n",
      "The classification loss after processing this batch is:  0.2982141673564911\n",
      "The representation loss after processing this batch is:  0.005060300230979919\n",
      "\n",
      "The classification loss after processing this batch is:  0.3581184148788452\n",
      "The representation loss after processing this batch is:  0.005785539746284485\n",
      "\n",
      "The classification loss after processing this batch is:  0.20480704307556152\n",
      "The representation loss after processing this batch is:  0.0046387165784835815\n",
      "\n",
      "The classification loss after processing this batch is:  0.428044855594635\n",
      "The representation loss after processing this batch is:  0.005324222147464752\n",
      "\n",
      "The classification loss after processing this batch is:  0.3015218675136566\n",
      "The representation loss after processing this batch is:  0.004903681576251984\n",
      "\n",
      "The classification loss after processing this batch is:  0.2950098216533661\n",
      "The representation loss after processing this batch is:  0.0038468390703201294\n",
      "\n",
      "The classification loss after processing this batch is:  0.4306376874446869\n",
      "The representation loss after processing this batch is:  0.004023253917694092\n",
      "\n",
      "The classification loss after processing this batch is:  0.30266273021698\n",
      "The representation loss after processing this batch is:  0.004594616591930389\n",
      "\n",
      "The classification loss after processing this batch is:  0.43218547105789185\n",
      "The representation loss after processing this batch is:  0.005071625113487244\n",
      "\n",
      "The classification loss after processing this batch is:  0.3752588629722595\n",
      "The representation loss after processing this batch is:  0.005665294826030731\n",
      "\n",
      "The classification loss after processing this batch is:  0.29995402693748474\n",
      "The representation loss after processing this batch is:  0.004638195037841797\n",
      "\n",
      "The classification loss after processing this batch is:  0.35599979758262634\n",
      "The representation loss after processing this batch is:  0.003973707556724548\n",
      "\n",
      "The classification loss after processing this batch is:  0.3361075222492218\n",
      "The representation loss after processing this batch is:  0.004053711891174316\n",
      "\n",
      "The classification loss after processing this batch is:  0.25143033266067505\n",
      "The representation loss after processing this batch is:  0.004316776990890503\n",
      "\n",
      "The classification loss after processing this batch is:  0.25905027985572815\n",
      "The representation loss after processing this batch is:  0.004342630505561829\n",
      "\n",
      "The classification loss after processing this batch is:  0.2905471920967102\n",
      "The representation loss after processing this batch is:  0.00409480556845665\n",
      "\n",
      "The classification loss after processing this batch is:  0.3436097502708435\n",
      "The representation loss after processing this batch is:  0.0034755393862724304\n",
      "\n",
      "The classification loss after processing this batch is:  0.28517797589302063\n",
      "The representation loss after processing this batch is:  0.0039525628089904785\n",
      "\n",
      "The classification loss after processing this batch is:  0.38896557688713074\n",
      "The representation loss after processing this batch is:  0.004683457314968109\n",
      "\n",
      "The classification loss after processing this batch is:  0.5985168814659119\n",
      "The representation loss after processing this batch is:  0.004530169069766998\n",
      "\n",
      "The classification loss after processing this batch is:  0.47013065218925476\n",
      "The representation loss after processing this batch is:  0.004610203206539154\n",
      "\n",
      "The classification loss after processing this batch is:  0.23639625310897827\n",
      "The representation loss after processing this batch is:  0.00440303236246109\n",
      "\n",
      "The classification loss after processing this batch is:  0.2990143895149231\n",
      "The representation loss after processing this batch is:  0.004845842719078064\n",
      "\n",
      "The classification loss after processing this batch is:  0.31824323534965515\n",
      "The representation loss after processing this batch is:  0.004370443522930145\n",
      "\n",
      "The classification loss after processing this batch is:  0.29982268810272217\n",
      "The representation loss after processing this batch is:  0.004101566970348358\n",
      "\n",
      "The classification loss after processing this batch is:  0.25468137860298157\n",
      "The representation loss after processing this batch is:  0.004563368856906891\n",
      "\n",
      "The classification loss after processing this batch is:  0.3288012146949768\n",
      "The representation loss after processing this batch is:  0.005062505602836609\n",
      "\n",
      "The classification loss after processing this batch is:  0.3891240656375885\n",
      "The representation loss after processing this batch is:  0.004343844950199127\n",
      "\n",
      "The classification loss after processing this batch is:  0.465431272983551\n",
      "The representation loss after processing this batch is:  0.004738103598356247\n",
      "\n",
      "The classification loss after processing this batch is:  0.2606765925884247\n",
      "The representation loss after processing this batch is:  0.0041183605790138245\n",
      "\n",
      "The classification loss after processing this batch is:  0.2575012147426605\n",
      "The representation loss after processing this batch is:  0.0036168619990348816\n",
      "\n",
      "The classification loss after processing this batch is:  0.2691129744052887\n",
      "The representation loss after processing this batch is:  0.003826916217803955\n",
      "\n",
      "The classification loss after processing this batch is:  0.4407137334346771\n",
      "The representation loss after processing this batch is:  0.004506468772888184\n",
      "\n",
      "The classification loss after processing this batch is:  0.281149297952652\n",
      "The representation loss after processing this batch is:  0.004192627966403961\n",
      "\n",
      "The classification loss after processing this batch is:  0.2471274882555008\n",
      "The representation loss after processing this batch is:  0.004336051642894745\n",
      "\n",
      "The classification loss after processing this batch is:  0.42102447152137756\n",
      "The representation loss after processing this batch is:  0.004332520067691803\n",
      "\n",
      "The classification loss after processing this batch is:  0.3026629686355591\n",
      "The representation loss after processing this batch is:  0.003817148506641388\n",
      "\n",
      "The classification loss after processing this batch is:  0.28673142194747925\n",
      "The representation loss after processing this batch is:  0.004581719636917114\n",
      "\n",
      "The classification loss after processing this batch is:  0.37240856885910034\n",
      "The representation loss after processing this batch is:  0.0041150860488414764\n",
      "\n",
      "The classification loss after processing this batch is:  0.24741119146347046\n",
      "The representation loss after processing this batch is:  0.004126846790313721\n",
      "\n",
      "The classification loss after processing this batch is:  0.32527491450309753\n",
      "The representation loss after processing this batch is:  0.004056621342897415\n",
      "\n",
      "The classification loss after processing this batch is:  0.4371325373649597\n",
      "The representation loss after processing this batch is:  0.004225492477416992\n",
      "\n",
      "The classification loss after processing this batch is:  0.4584980309009552\n",
      "The representation loss after processing this batch is:  0.004038073122501373\n",
      "\n",
      "The classification loss after processing this batch is:  0.3674912750720978\n",
      "The representation loss after processing this batch is:  0.004535935819149017\n",
      "\n",
      "The classification loss after processing this batch is:  0.48301658034324646\n",
      "The representation loss after processing this batch is:  0.004209548234939575\n",
      "\n",
      "The classification loss after processing this batch is:  0.3268275260925293\n",
      "The representation loss after processing this batch is:  0.004415687173604965\n",
      "\n",
      "The classification loss after processing this batch is:  0.37767085433006287\n",
      "The representation loss after processing this batch is:  0.004557989537715912\n",
      "\n",
      "The classification loss after processing this batch is:  0.3089270293712616\n",
      "The representation loss after processing this batch is:  0.004867464303970337\n",
      "\n",
      "The classification loss after processing this batch is:  0.38703277707099915\n",
      "The representation loss after processing this batch is:  0.0043473802506923676\n",
      "\n",
      "The classification loss after processing this batch is:  0.27996930480003357\n",
      "The representation loss after processing this batch is:  0.004180930554866791\n",
      "\n",
      "The classification loss after processing this batch is:  0.32183101773262024\n",
      "The representation loss after processing this batch is:  0.00400204211473465\n",
      "\n",
      "The classification loss after processing this batch is:  0.2400418370962143\n",
      "The representation loss after processing this batch is:  0.0044119879603385925\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.34183967113494873\n",
      "The representation loss after processing this batch is:  0.004322823137044907\n",
      "\n",
      "The classification loss after processing this batch is:  0.3397722840309143\n",
      "The representation loss after processing this batch is:  0.003884732723236084\n",
      "\n",
      "The classification loss after processing this batch is:  0.3514677584171295\n",
      "The representation loss after processing this batch is:  0.0047483667731285095\n",
      "\n",
      "The classification loss after processing this batch is:  0.37827837467193604\n",
      "The representation loss after processing this batch is:  0.0039133355021476746\n",
      "\n",
      "The classification loss after processing this batch is:  0.4563814699649811\n",
      "The representation loss after processing this batch is:  0.0041282884776592255\n",
      "\n",
      "The classification loss after processing this batch is:  0.4276729226112366\n",
      "The representation loss after processing this batch is:  0.004081033170223236\n",
      "\n",
      "The classification loss after processing this batch is:  0.4901072680950165\n",
      "The representation loss after processing this batch is:  0.004374593496322632\n",
      "\n",
      "The classification loss after processing this batch is:  0.542779266834259\n",
      "The representation loss after processing this batch is:  0.003832932561635971\n",
      "\n",
      "The classification loss after processing this batch is:  0.4515666961669922\n",
      "The representation loss after processing this batch is:  0.003565531224012375\n",
      "\n",
      "The classification loss after processing this batch is:  0.2670517563819885\n",
      "The representation loss after processing this batch is:  0.004346035420894623\n",
      "\n",
      "The classification loss after processing this batch is:  0.35909873247146606\n",
      "The representation loss after processing this batch is:  0.004540883004665375\n",
      "\n",
      "The classification loss after processing this batch is:  0.21589605510234833\n",
      "The representation loss after processing this batch is:  0.004103370010852814\n",
      "\n",
      "The classification loss after processing this batch is:  0.39664897322654724\n",
      "The representation loss after processing this batch is:  0.004845187067985535\n",
      "\n",
      "The classification loss after processing this batch is:  0.5054463148117065\n",
      "The representation loss after processing this batch is:  0.005060635507106781\n",
      "\n",
      "The classification loss after processing this batch is:  0.546867311000824\n",
      "The representation loss after processing this batch is:  0.004280515015125275\n",
      "\n",
      "The classification loss after processing this batch is:  0.6046215295791626\n",
      "The representation loss after processing this batch is:  0.004168123006820679\n",
      "\n",
      "The classification loss after processing this batch is:  0.4250231385231018\n",
      "The representation loss after processing this batch is:  0.0043455734848976135\n",
      "\n",
      "The classification loss after processing this batch is:  0.30255433917045593\n",
      "The representation loss after processing this batch is:  0.0039768218994140625\n",
      "\n",
      "The classification loss after processing this batch is:  0.2993697226047516\n",
      "The representation loss after processing this batch is:  0.004455648362636566\n",
      "\n",
      "The classification loss after processing this batch is:  0.45852038264274597\n",
      "The representation loss after processing this batch is:  0.003756023943424225\n",
      "\n",
      "The classification loss after processing this batch is:  0.2581600844860077\n",
      "The representation loss after processing this batch is:  0.004355631768703461\n",
      "\n",
      "The classification loss after processing this batch is:  0.23705774545669556\n",
      "The representation loss after processing this batch is:  0.004246041178703308\n",
      "\n",
      "The classification loss after processing this batch is:  0.256553053855896\n",
      "The representation loss after processing this batch is:  0.004193335771560669\n",
      "\n",
      "The classification loss after processing this batch is:  0.17055663466453552\n",
      "The representation loss after processing this batch is:  0.004706911742687225\n",
      "\n",
      "The classification loss after processing this batch is:  0.3618212640285492\n",
      "The representation loss after processing this batch is:  0.004468105733394623\n",
      "\n",
      "The classification loss after processing this batch is:  0.2960616946220398\n",
      "The representation loss after processing this batch is:  0.00461888313293457\n",
      "\n",
      "The classification loss after processing this batch is:  0.38036733865737915\n",
      "The representation loss after processing this batch is:  0.004262257367372513\n",
      "\n",
      "The classification loss after processing this batch is:  0.3430933654308319\n",
      "The representation loss after processing this batch is:  0.004077985882759094\n",
      "\n",
      "The classification loss after processing this batch is:  0.35072606801986694\n",
      "The representation loss after processing this batch is:  0.00446753203868866\n",
      "\n",
      "The classification loss after processing this batch is:  0.3967103660106659\n",
      "The representation loss after processing this batch is:  0.004591464996337891\n",
      "\n",
      "The classification loss after processing this batch is:  0.33880308270454407\n",
      "The representation loss after processing this batch is:  0.004697989672422409\n",
      "\n",
      "The classification loss after processing this batch is:  0.32474997639656067\n",
      "The representation loss after processing this batch is:  0.004743896424770355\n",
      "\n",
      "The classification loss after processing this batch is:  0.3878289461135864\n",
      "The representation loss after processing this batch is:  0.004300311207771301\n",
      "\n",
      "The classification loss after processing this batch is:  0.40556854009628296\n",
      "The representation loss after processing this batch is:  0.004388481378555298\n",
      "\n",
      "The classification loss after processing this batch is:  0.3037125766277313\n",
      "The representation loss after processing this batch is:  0.003909476101398468\n",
      "\n",
      "The classification loss after processing this batch is:  0.4226874113082886\n",
      "The representation loss after processing this batch is:  0.0048220232129096985\n",
      "\n",
      "The classification loss after processing this batch is:  0.5054800510406494\n",
      "The representation loss after processing this batch is:  0.004762880504131317\n",
      "\n",
      "The classification loss after processing this batch is:  0.2825959026813507\n",
      "The representation loss after processing this batch is:  0.0038159415125846863\n",
      "\n",
      "The classification loss after processing this batch is:  0.2913720905780792\n",
      "The representation loss after processing this batch is:  0.004533432424068451\n",
      "\n",
      "The classification loss after processing this batch is:  0.38578078150749207\n",
      "The representation loss after processing this batch is:  0.004597757011651993\n",
      "\n",
      "The classification loss after processing this batch is:  0.3889227509498596\n",
      "The representation loss after processing this batch is:  0.004708919674158096\n",
      "\n",
      "The classification loss after processing this batch is:  0.5376640558242798\n",
      "The representation loss after processing this batch is:  0.004627399146556854\n",
      "\n",
      "The classification loss after processing this batch is:  0.4654889404773712\n",
      "The representation loss after processing this batch is:  0.004979953169822693\n",
      "\n",
      "The classification loss after processing this batch is:  0.46114444732666016\n",
      "The representation loss after processing this batch is:  0.005065701901912689\n",
      "\n",
      "The classification loss after processing this batch is:  0.4634554982185364\n",
      "The representation loss after processing this batch is:  0.004948817193508148\n",
      "\n",
      "The classification loss after processing this batch is:  0.3340887427330017\n",
      "The representation loss after processing this batch is:  0.00373116135597229\n",
      "\n",
      "The classification loss after processing this batch is:  0.34379202127456665\n",
      "The representation loss after processing this batch is:  0.004876911640167236\n",
      "\n",
      "The classification loss after processing this batch is:  0.2790108621120453\n",
      "The representation loss after processing this batch is:  0.00460437685251236\n",
      "\n",
      "The classification loss after processing this batch is:  0.398527055978775\n",
      "The representation loss after processing this batch is:  0.004361104220151901\n",
      "\n",
      "The classification loss after processing this batch is:  0.3530851900577545\n",
      "The representation loss after processing this batch is:  0.003871738910675049\n",
      "\n",
      "The classification loss after processing this batch is:  0.29758161306381226\n",
      "The representation loss after processing this batch is:  0.00414615124464035\n",
      "\n",
      "The classification loss after processing this batch is:  0.29793107509613037\n",
      "The representation loss after processing this batch is:  0.0041372328996658325\n",
      "\n",
      "The classification loss after processing this batch is:  0.25343528389930725\n",
      "The representation loss after processing this batch is:  0.00519639253616333\n",
      "\n",
      "The classification loss after processing this batch is:  0.30808722972869873\n",
      "The representation loss after processing this batch is:  0.004154738038778305\n",
      "\n",
      "The classification loss after processing this batch is:  0.2591699957847595\n",
      "The representation loss after processing this batch is:  0.004206366837024689\n",
      "\n",
      "The classification loss after processing this batch is:  0.3521011471748352\n",
      "The representation loss after processing this batch is:  0.004155285656452179\n",
      "\n",
      "The classification loss after processing this batch is:  0.2617383897304535\n",
      "The representation loss after processing this batch is:  0.003696657717227936\n",
      "\n",
      "The classification loss after processing this batch is:  0.2784794867038727\n",
      "The representation loss after processing this batch is:  0.0037612318992614746\n",
      "\n",
      "The classification loss after processing this batch is:  0.29280224442481995\n",
      "The representation loss after processing this batch is:  0.003840506076812744\n",
      "\n",
      "The classification loss after processing this batch is:  0.7983750700950623\n",
      "The representation loss after processing this batch is:  0.004930168390274048\n",
      "\n",
      "The classification loss after processing this batch is:  0.3542638123035431\n",
      "The representation loss after processing this batch is:  0.003985844552516937\n",
      "\n",
      "The classification loss after processing this batch is:  0.5107442736625671\n",
      "The representation loss after processing this batch is:  0.004138033837080002\n",
      "\n",
      "The classification loss after processing this batch is:  0.46546223759651184\n",
      "The representation loss after processing this batch is:  0.004273552447557449\n",
      "\n",
      "The classification loss after processing this batch is:  0.36153003573417664\n",
      "The representation loss after processing this batch is:  0.004401199519634247\n",
      "\n",
      "The classification loss after processing this batch is:  0.617242693901062\n",
      "The representation loss after processing this batch is:  0.004224434494972229\n",
      "\n",
      "The classification loss after processing this batch is:  0.34907153248786926\n",
      "The representation loss after processing this batch is:  0.0041954852640628815\n",
      "\n",
      "The classification loss after processing this batch is:  0.4626496136188507\n",
      "The representation loss after processing this batch is:  0.003982312977313995\n",
      "\n",
      "The classification loss after processing this batch is:  0.2332112342119217\n",
      "The representation loss after processing this batch is:  0.0043886080384254456\n",
      "\n",
      "The classification loss after processing this batch is:  0.2460489720106125\n",
      "The representation loss after processing this batch is:  0.0038070902228355408\n",
      "\n",
      "The classification loss after processing this batch is:  0.24320730566978455\n",
      "The representation loss after processing this batch is:  0.00458410382270813\n",
      "\n",
      "The classification loss after processing this batch is:  0.20726720988750458\n",
      "The representation loss after processing this batch is:  0.004554383456707001\n",
      "\n",
      "The classification loss after processing this batch is:  0.30078327655792236\n",
      "The representation loss after processing this batch is:  0.003840804100036621\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.22234807908535004\n",
      "The representation loss after processing this batch is:  0.0040376558899879456\n",
      "\n",
      "The classification loss after processing this batch is:  0.271830677986145\n",
      "The representation loss after processing this batch is:  0.004063256084918976\n",
      "\n",
      "The classification loss after processing this batch is:  0.28345730900764465\n",
      "The representation loss after processing this batch is:  0.004334747791290283\n",
      "\n",
      "The classification loss after processing this batch is:  0.2797875702381134\n",
      "The representation loss after processing this batch is:  0.004249878227710724\n",
      "\n",
      "The classification loss after processing this batch is:  0.35463032126426697\n",
      "The representation loss after processing this batch is:  0.003799818456172943\n",
      "\n",
      "The classification loss after processing this batch is:  0.29134857654571533\n",
      "The representation loss after processing this batch is:  0.004667617380619049\n",
      "\n",
      "The classification loss after processing this batch is:  0.3378817141056061\n",
      "The representation loss after processing this batch is:  0.004126019775867462\n",
      "\n",
      "The classification loss after processing this batch is:  0.32173070311546326\n",
      "The representation loss after processing this batch is:  0.004251949489116669\n",
      "\n",
      "The classification loss after processing this batch is:  0.37921804189682007\n",
      "The representation loss after processing this batch is:  0.004376895725727081\n",
      "\n",
      "The classification loss after processing this batch is:  0.3706274628639221\n",
      "The representation loss after processing this batch is:  0.004251956939697266\n",
      "\n",
      "The classification loss after processing this batch is:  0.27909624576568604\n",
      "The representation loss after processing this batch is:  0.004002172499895096\n",
      "\n",
      "The classification loss after processing this batch is:  0.44691821932792664\n",
      "The representation loss after processing this batch is:  0.004936344921588898\n",
      "\n",
      "The classification loss after processing this batch is:  0.3887101411819458\n",
      "The representation loss after processing this batch is:  0.004189357161521912\n",
      "\n",
      "The classification loss after processing this batch is:  0.3376656472682953\n",
      "The representation loss after processing this batch is:  0.003971874713897705\n",
      "\n",
      "The classification loss after processing this batch is:  0.26178786158561707\n",
      "The representation loss after processing this batch is:  0.004450388252735138\n",
      "\n",
      "The classification loss after processing this batch is:  0.2957741916179657\n",
      "The representation loss after processing this batch is:  0.004414372146129608\n",
      "\n",
      "The classification loss after processing this batch is:  0.3789759576320648\n",
      "The representation loss after processing this batch is:  0.0044351741671562195\n",
      "\n",
      "The classification loss after processing this batch is:  0.3365762531757355\n",
      "The representation loss after processing this batch is:  0.00579468160867691\n",
      "\n",
      "The classification loss after processing this batch is:  0.2763180732727051\n",
      "The representation loss after processing this batch is:  0.004947349429130554\n",
      "\n",
      "The classification loss after processing this batch is:  0.35916662216186523\n",
      "The representation loss after processing this batch is:  0.006357021629810333\n",
      "\n",
      "The classification loss after processing this batch is:  0.407194584608078\n",
      "The representation loss after processing this batch is:  0.00444108247756958\n",
      "\n",
      "The classification loss after processing this batch is:  0.4926111102104187\n",
      "The representation loss after processing this batch is:  0.0038263387978076935\n",
      "\n",
      "The classification loss after processing this batch is:  0.3854999542236328\n",
      "The representation loss after processing this batch is:  0.005261503159999847\n",
      "\n",
      "The classification loss after processing this batch is:  0.332669198513031\n",
      "The representation loss after processing this batch is:  0.003873199224472046\n",
      "\n",
      "The classification loss after processing this batch is:  0.2605866491794586\n",
      "The representation loss after processing this batch is:  0.003949321806430817\n",
      "\n",
      "The classification loss after processing this batch is:  0.40855151414871216\n",
      "The representation loss after processing this batch is:  0.003858111798763275\n",
      "\n",
      "The classification loss after processing this batch is:  0.24060644209384918\n",
      "The representation loss after processing this batch is:  0.0041419267654418945\n",
      "\n",
      "The classification loss after processing this batch is:  0.27688995003700256\n",
      "The representation loss after processing this batch is:  0.004655413329601288\n",
      "\n",
      "The classification loss after processing this batch is:  0.2633076012134552\n",
      "The representation loss after processing this batch is:  0.004687517881393433\n",
      "\n",
      "The classification loss after processing this batch is:  0.25836440920829773\n",
      "The representation loss after processing this batch is:  0.004468634724617004\n",
      "\n",
      "The classification loss after processing this batch is:  0.2586551010608673\n",
      "The representation loss after processing this batch is:  0.004711993038654327\n",
      "\n",
      "The classification loss after processing this batch is:  0.41139283776283264\n",
      "The representation loss after processing this batch is:  0.004355616867542267\n",
      "\n",
      "The classification loss after processing this batch is:  0.3411549925804138\n",
      "The representation loss after processing this batch is:  0.004817739129066467\n",
      "\n",
      "The classification loss after processing this batch is:  0.36390721797943115\n",
      "The representation loss after processing this batch is:  0.004100777208805084\n",
      "\n",
      "The classification loss after processing this batch is:  0.29466214776039124\n",
      "The representation loss after processing this batch is:  0.004650384187698364\n",
      "\n",
      "The classification loss after processing this batch is:  0.29461848735809326\n",
      "The representation loss after processing this batch is:  0.00460495799779892\n",
      "\n",
      "The classification loss after processing this batch is:  0.24903272092342377\n",
      "The representation loss after processing this batch is:  0.0037029609084129333\n",
      "\n",
      "The classification loss after processing this batch is:  0.30270442366600037\n",
      "The representation loss after processing this batch is:  0.004206173121929169\n",
      "\n",
      "The classification loss after processing this batch is:  0.2934121787548065\n",
      "The representation loss after processing this batch is:  0.00422205775976181\n",
      "\n",
      "The classification loss after processing this batch is:  0.22090451419353485\n",
      "The representation loss after processing this batch is:  0.0038480237126350403\n",
      "\n",
      "The classification loss after processing this batch is:  0.2051907479763031\n",
      "The representation loss after processing this batch is:  0.0039458610117435455\n",
      "\n",
      "The classification loss after processing this batch is:  0.3134709596633911\n",
      "The representation loss after processing this batch is:  0.004484593868255615\n",
      "\n",
      "The classification loss after processing this batch is:  0.24270911514759064\n",
      "The representation loss after processing this batch is:  0.004309564828872681\n",
      "\n",
      "The classification loss after processing this batch is:  0.38021916151046753\n",
      "The representation loss after processing this batch is:  0.004683174192905426\n",
      "\n",
      "The classification loss after processing this batch is:  0.317208856344223\n",
      "The representation loss after processing this batch is:  0.003586895763874054\n",
      "\n",
      "The classification loss after processing this batch is:  0.3583812117576599\n",
      "The representation loss after processing this batch is:  0.004112761467695236\n",
      "\n",
      "The classification loss after processing this batch is:  0.24423837661743164\n",
      "The representation loss after processing this batch is:  0.004416622221469879\n",
      "\n",
      "The classification loss after processing this batch is:  0.39970606565475464\n",
      "The representation loss after processing this batch is:  0.004222791641950607\n",
      "\n",
      "The classification loss after processing this batch is:  0.30336853861808777\n",
      "The representation loss after processing this batch is:  0.003542080521583557\n",
      "\n",
      "The classification loss after processing this batch is:  0.25314852595329285\n",
      "The representation loss after processing this batch is:  0.004003643989562988\n",
      "\n",
      "The classification loss after processing this batch is:  0.40762144327163696\n",
      "The representation loss after processing this batch is:  0.004263758659362793\n",
      "\n",
      "The classification loss after processing this batch is:  0.35975077748298645\n",
      "The representation loss after processing this batch is:  0.004198111593723297\n",
      "\n",
      "The classification loss after processing this batch is:  0.18338896334171295\n",
      "The representation loss after processing this batch is:  0.003830365836620331\n",
      "\n",
      "The classification loss after processing this batch is:  0.23630453646183014\n",
      "The representation loss after processing this batch is:  0.0041902512311935425\n",
      "\n",
      "The classification loss after processing this batch is:  0.25418514013290405\n",
      "The representation loss after processing this batch is:  0.0033677443861961365\n",
      "\n",
      "The classification loss after processing this batch is:  0.3431965112686157\n",
      "The representation loss after processing this batch is:  0.004282951354980469\n",
      "\n",
      "The classification loss after processing this batch is:  0.32585009932518005\n",
      "The representation loss after processing this batch is:  0.003960616886615753\n",
      "\n",
      "The classification loss after processing this batch is:  0.33279356360435486\n",
      "The representation loss after processing this batch is:  0.005246385931968689\n",
      "\n",
      "The classification loss after processing this batch is:  0.4495886266231537\n",
      "The representation loss after processing this batch is:  0.004118137061595917\n",
      "\n",
      "The classification loss after processing this batch is:  0.4074919819831848\n",
      "The representation loss after processing this batch is:  0.0038262680172920227\n",
      "\n",
      "The classification loss after processing this batch is:  0.3276296555995941\n",
      "The representation loss after processing this batch is:  0.003940477967262268\n",
      "\n",
      "The classification loss after processing this batch is:  0.5384169220924377\n",
      "The representation loss after processing this batch is:  0.003934942185878754\n",
      "\n",
      "The classification loss after processing this batch is:  0.395773321390152\n",
      "The representation loss after processing this batch is:  0.003765299916267395\n",
      "\n",
      "The classification loss after processing this batch is:  0.3529486358165741\n",
      "The representation loss after processing this batch is:  0.003781154751777649\n",
      "\n",
      "The classification loss after processing this batch is:  0.26298460364341736\n",
      "The representation loss after processing this batch is:  0.0034927353262901306\n",
      "\n",
      "The classification loss after processing this batch is:  0.24245122075080872\n",
      "The representation loss after processing this batch is:  0.0036170855164527893\n",
      "\n",
      "The classification loss after processing this batch is:  0.23305971920490265\n",
      "The representation loss after processing this batch is:  0.0038252174854278564\n",
      "\n",
      "The classification loss after processing this batch is:  0.37216490507125854\n",
      "The representation loss after processing this batch is:  0.005142048001289368\n",
      "\n",
      "The classification loss after processing this batch is:  0.28197070956230164\n",
      "The representation loss after processing this batch is:  0.0035349950194358826\n",
      "\n",
      "The classification loss after processing this batch is:  0.2710227370262146\n",
      "The representation loss after processing this batch is:  0.004043802618980408\n",
      "\n",
      "The classification loss after processing this batch is:  0.3575040102005005\n",
      "The representation loss after processing this batch is:  0.0038115158677101135\n",
      "\n",
      "The classification loss after processing this batch is:  0.2952732741832733\n",
      "The representation loss after processing this batch is:  0.004537619650363922\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.42359456419944763\n",
      "The representation loss after processing this batch is:  0.003907695412635803\n",
      "\n",
      "The classification loss after processing this batch is:  0.319124311208725\n",
      "The representation loss after processing this batch is:  0.004180997610092163\n",
      "\n",
      "The classification loss after processing this batch is:  0.4128306210041046\n",
      "The representation loss after processing this batch is:  0.004113372415304184\n",
      "\n",
      "The classification loss after processing this batch is:  0.36404818296432495\n",
      "The representation loss after processing this batch is:  0.004174955189228058\n",
      "\n",
      "The classification loss after processing this batch is:  0.21472541987895966\n",
      "The representation loss after processing this batch is:  0.00408017635345459\n",
      "\n",
      "The classification loss after processing this batch is:  0.3531538248062134\n",
      "The representation loss after processing this batch is:  0.0039505138993263245\n",
      "\n",
      "The classification loss after processing this batch is:  0.20909158885478973\n",
      "The representation loss after processing this batch is:  0.0038651973009109497\n",
      "\n",
      "The classification loss after processing this batch is:  0.21183906495571136\n",
      "The representation loss after processing this batch is:  0.0037278905510902405\n",
      "\n",
      "The classification loss after processing this batch is:  0.2663792371749878\n",
      "The representation loss after processing this batch is:  0.004571884870529175\n",
      "\n",
      "The classification loss after processing this batch is:  0.34154337644577026\n",
      "The representation loss after processing this batch is:  0.003742203116416931\n",
      "\n",
      "The classification loss after processing this batch is:  0.37881115078926086\n",
      "The representation loss after processing this batch is:  0.0042206645011901855\n",
      "\n",
      "The classification loss after processing this batch is:  0.25565749406814575\n",
      "The representation loss after processing this batch is:  0.003693781793117523\n",
      "\n",
      "The classification loss after processing this batch is:  0.31897714734077454\n",
      "The representation loss after processing this batch is:  0.004922062158584595\n",
      "\n",
      "The classification loss after processing this batch is:  0.2149631530046463\n",
      "The representation loss after processing this batch is:  0.0040056705474853516\n",
      "\n",
      "The classification loss after processing this batch is:  0.36397600173950195\n",
      "The representation loss after processing this batch is:  0.004124723374843597\n",
      "\n",
      "The classification loss after processing this batch is:  0.22650839388370514\n",
      "The representation loss after processing this batch is:  0.003370136022567749\n",
      "\n",
      "The classification loss after processing this batch is:  0.1864859014749527\n",
      "The representation loss after processing this batch is:  0.0042849332094192505\n",
      "\n",
      "The classification loss after processing this batch is:  0.2649858295917511\n",
      "The representation loss after processing this batch is:  0.0048027560114860535\n",
      "\n",
      "The classification loss after processing this batch is:  0.24964068830013275\n",
      "The representation loss after processing this batch is:  0.0041460394859313965\n",
      "\n",
      "The classification loss after processing this batch is:  0.2388121336698532\n",
      "The representation loss after processing this batch is:  0.004187919199466705\n",
      "\n",
      "The classification loss after processing this batch is:  0.23314426839351654\n",
      "The representation loss after processing this batch is:  0.0037776604294776917\n",
      "\n",
      "The classification loss after processing this batch is:  0.3489439785480499\n",
      "The representation loss after processing this batch is:  0.0044756606221199036\n",
      "\n",
      "The classification loss after processing this batch is:  0.3945426940917969\n",
      "The representation loss after processing this batch is:  0.004477322101593018\n",
      "\n",
      "The classification loss after processing this batch is:  0.41006991267204285\n",
      "The representation loss after processing this batch is:  0.004434037953615189\n",
      "\n",
      "The classification loss after processing this batch is:  0.3892473876476288\n",
      "The representation loss after processing this batch is:  0.004791140556335449\n",
      "\n",
      "The classification loss after processing this batch is:  0.21697841584682465\n",
      "The representation loss after processing this batch is:  0.004200540482997894\n",
      "\n",
      "The classification loss after processing this batch is:  0.2649579346179962\n",
      "The representation loss after processing this batch is:  0.0038178488612174988\n",
      "\n",
      "The classification loss after processing this batch is:  0.4432023763656616\n",
      "The representation loss after processing this batch is:  0.0045127272605896\n",
      "\n",
      "The classification loss after processing this batch is:  0.49715372920036316\n",
      "The representation loss after processing this batch is:  0.005224049091339111\n",
      "\n",
      "The classification loss after processing this batch is:  0.432623028755188\n",
      "The representation loss after processing this batch is:  0.00477314367890358\n",
      "\n",
      "The classification loss after processing this batch is:  0.4962005019187927\n",
      "The representation loss after processing this batch is:  0.004555270075798035\n",
      "\n",
      "The classification loss after processing this batch is:  0.32710087299346924\n",
      "The representation loss after processing this batch is:  0.0035294219851493835\n",
      "\n",
      "The classification loss after processing this batch is:  0.41640201210975647\n",
      "The representation loss after processing this batch is:  0.003976687788963318\n",
      "\n",
      "The classification loss after processing this batch is:  0.36106356978416443\n",
      "The representation loss after processing this batch is:  0.004005424678325653\n",
      "\n",
      "The classification loss after processing this batch is:  0.3088178336620331\n",
      "The representation loss after processing this batch is:  0.003947071731090546\n",
      "\n",
      "The classification loss after processing this batch is:  0.25404122471809387\n",
      "The representation loss after processing this batch is:  0.0041686296463012695\n",
      "\n",
      "The classification loss after processing this batch is:  0.3093566298484802\n",
      "The representation loss after processing this batch is:  0.004331633448600769\n",
      "\n",
      "The classification loss after processing this batch is:  0.3178103566169739\n",
      "The representation loss after processing this batch is:  0.004709623754024506\n",
      "\n",
      "The classification loss after processing this batch is:  0.31103938817977905\n",
      "The representation loss after processing this batch is:  0.004131760448217392\n",
      "\n",
      "The classification loss after processing this batch is:  0.3276706039905548\n",
      "The representation loss after processing this batch is:  0.0041504353284835815\n",
      "\n",
      "The classification loss after processing this batch is:  0.2270004153251648\n",
      "The representation loss after processing this batch is:  0.00477224588394165\n",
      "\n",
      "The classification loss after processing this batch is:  0.25310373306274414\n",
      "The representation loss after processing this batch is:  0.004215054214000702\n",
      "\n",
      "The classification loss after processing this batch is:  0.2623194754123688\n",
      "The representation loss after processing this batch is:  0.004729829728603363\n",
      "\n",
      "The classification loss after processing this batch is:  0.2757628858089447\n",
      "The representation loss after processing this batch is:  0.004342205822467804\n",
      "\n",
      "The classification loss after processing this batch is:  0.24208615720272064\n",
      "The representation loss after processing this batch is:  0.004790805280208588\n",
      "\n",
      "The classification loss after processing this batch is:  0.2618548274040222\n",
      "The representation loss after processing this batch is:  0.0035272501409053802\n",
      "\n",
      "The classification loss after processing this batch is:  0.29379934072494507\n",
      "The representation loss after processing this batch is:  0.004585690796375275\n",
      "\n",
      "The classification loss after processing this batch is:  0.36763542890548706\n",
      "The representation loss after processing this batch is:  0.004539325833320618\n",
      "\n",
      "The classification loss after processing this batch is:  0.3537447154521942\n",
      "The representation loss after processing this batch is:  0.0037842392921447754\n",
      "\n",
      "The classification loss after processing this batch is:  0.27074840664863586\n",
      "The representation loss after processing this batch is:  0.004130057990550995\n",
      "\n",
      "The classification loss after processing this batch is:  0.24238170683383942\n",
      "The representation loss after processing this batch is:  0.004362046718597412\n",
      "\n",
      "The classification loss after processing this batch is:  0.20163780450820923\n",
      "The representation loss after processing this batch is:  0.0037961602210998535\n",
      "\n",
      "The classification loss after processing this batch is:  0.28187066316604614\n",
      "The representation loss after processing this batch is:  0.004693135619163513\n",
      "\n",
      "The classification loss after processing this batch is:  0.35623666644096375\n",
      "The representation loss after processing this batch is:  0.00417734682559967\n",
      "\n",
      "The classification loss after processing this batch is:  0.3431328535079956\n",
      "The representation loss after processing this batch is:  0.004112958908081055\n",
      "\n",
      "The classification loss after processing this batch is:  0.23884734511375427\n",
      "The representation loss after processing this batch is:  0.003964856266975403\n",
      "\n",
      "The classification loss after processing this batch is:  0.360224187374115\n",
      "The representation loss after processing this batch is:  0.004044774919748306\n",
      "\n",
      "The classification loss after processing this batch is:  0.4527563154697418\n",
      "The representation loss after processing this batch is:  0.004161074757575989\n",
      "\n",
      "The classification loss after processing this batch is:  0.2206733375787735\n",
      "The representation loss after processing this batch is:  0.004093430936336517\n",
      "\n",
      "The classification loss after processing this batch is:  0.2665277421474457\n",
      "The representation loss after processing this batch is:  0.0037826895713806152\n",
      "\n",
      "The classification loss after processing this batch is:  0.3722805082798004\n",
      "The representation loss after processing this batch is:  0.003797963261604309\n",
      "\n",
      "The classification loss after processing this batch is:  0.35954126715660095\n",
      "The representation loss after processing this batch is:  0.0036650970578193665\n",
      "\n",
      "The classification loss after processing this batch is:  0.2358682006597519\n",
      "The representation loss after processing this batch is:  0.003788173198699951\n",
      "\n",
      "The classification loss after processing this batch is:  0.5231741070747375\n",
      "The representation loss after processing this batch is:  0.0036056339740753174\n",
      "\n",
      "The classification loss after processing this batch is:  0.36812344193458557\n",
      "The representation loss after processing this batch is:  0.004419296979904175\n",
      "\n",
      "The classification loss after processing this batch is:  0.45157644152641296\n",
      "The representation loss after processing this batch is:  0.004205755889415741\n",
      "\n",
      "The classification loss after processing this batch is:  0.3135972023010254\n",
      "The representation loss after processing this batch is:  0.004553481936454773\n",
      "\n",
      "The classification loss after processing this batch is:  0.38615989685058594\n",
      "The representation loss after processing this batch is:  0.004218608140945435\n",
      "\n",
      "The classification loss after processing this batch is:  0.2641204595565796\n",
      "The representation loss after processing this batch is:  0.005254834890365601\n",
      "\n",
      "The classification loss after processing this batch is:  0.2928552031517029\n",
      "The representation loss after processing this batch is:  0.004001684486865997\n",
      "\n",
      "The classification loss after processing this batch is:  0.2861993908882141\n",
      "The representation loss after processing this batch is:  0.0037561804056167603\n",
      "\n",
      "The classification loss after processing this batch is:  0.30969128012657166\n",
      "The representation loss after processing this batch is:  0.0038561299443244934\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2981313467025757\n",
      "The representation loss after processing this batch is:  0.004192769527435303\n",
      "\n",
      "The classification loss after processing this batch is:  0.2654053270816803\n",
      "The representation loss after processing this batch is:  0.003943294286727905\n",
      "\n",
      "The classification loss after processing this batch is:  0.33820030093193054\n",
      "The representation loss after processing this batch is:  0.004312235862016678\n",
      "\n",
      "The classification loss after processing this batch is:  0.2570157051086426\n",
      "The representation loss after processing this batch is:  0.004411101341247559\n",
      "\n",
      "The classification loss after processing this batch is:  0.23828966915607452\n",
      "The representation loss after processing this batch is:  0.004467308521270752\n",
      "\n",
      "The classification loss after processing this batch is:  0.3163190484046936\n",
      "The representation loss after processing this batch is:  0.004866085946559906\n",
      "\n",
      "The classification loss after processing this batch is:  0.20733729004859924\n",
      "The representation loss after processing this batch is:  0.0040211305022239685\n",
      "\n",
      "The classification loss after processing this batch is:  0.2679036557674408\n",
      "The representation loss after processing this batch is:  0.003808937966823578\n",
      "\n",
      "The classification loss after processing this batch is:  0.2093210518360138\n",
      "The representation loss after processing this batch is:  0.004220321774482727\n",
      "\n",
      "The classification loss after processing this batch is:  0.17373409867286682\n",
      "The representation loss after processing this batch is:  0.003801576793193817\n",
      "\n",
      "The classification loss after processing this batch is:  0.26576241850852966\n",
      "The representation loss after processing this batch is:  0.004631660878658295\n",
      "\n",
      "The classification loss after processing this batch is:  0.33271080255508423\n",
      "The representation loss after processing this batch is:  0.004968129098415375\n",
      "\n",
      "The classification loss after processing this batch is:  0.30055472254753113\n",
      "The representation loss after processing this batch is:  0.005205415189266205\n",
      "\n",
      "The classification loss after processing this batch is:  0.28956595063209534\n",
      "The representation loss after processing this batch is:  0.004143640398979187\n",
      "\n",
      "The classification loss after processing this batch is:  0.24467076361179352\n",
      "The representation loss after processing this batch is:  0.003921404480934143\n",
      "\n",
      "The classification loss after processing this batch is:  0.2068638652563095\n",
      "The representation loss after processing this batch is:  0.0034519657492637634\n",
      "\n",
      "The classification loss after processing this batch is:  0.24775972962379456\n",
      "The representation loss after processing this batch is:  0.003993555903434753\n",
      "\n",
      "The classification loss after processing this batch is:  0.24286898970603943\n",
      "The representation loss after processing this batch is:  0.0037806034088134766\n",
      "\n",
      "The classification loss after processing this batch is:  0.24655494093894958\n",
      "The representation loss after processing this batch is:  0.004154883325099945\n",
      "\n",
      "The classification loss after processing this batch is:  0.31900179386138916\n",
      "The representation loss after processing this batch is:  0.004611000418663025\n",
      "\n",
      "The classification loss after processing this batch is:  0.34398987889289856\n",
      "The representation loss after processing this batch is:  0.004121996462345123\n",
      "\n",
      "The classification loss after processing this batch is:  0.2970103323459625\n",
      "The representation loss after processing this batch is:  0.004715755581855774\n",
      "\n",
      "The classification loss after processing this batch is:  0.22879794239997864\n",
      "The representation loss after processing this batch is:  0.004663683474063873\n",
      "\n",
      "The classification loss after processing this batch is:  0.27222347259521484\n",
      "The representation loss after processing this batch is:  0.004816807806491852\n",
      "\n",
      "The classification loss after processing this batch is:  0.3782929480075836\n",
      "The representation loss after processing this batch is:  0.003915954381227493\n",
      "\n",
      "The classification loss after processing this batch is:  0.28236204385757446\n",
      "The representation loss after processing this batch is:  0.004313722252845764\n",
      "\n",
      "The classification loss after processing this batch is:  0.5246514081954956\n",
      "The representation loss after processing this batch is:  0.004046790301799774\n",
      "\n",
      "The classification loss after processing this batch is:  0.349691778421402\n",
      "The representation loss after processing this batch is:  0.00421520322561264\n",
      "\n",
      "The classification loss after processing this batch is:  0.383724570274353\n",
      "The representation loss after processing this batch is:  0.005204543471336365\n",
      "\n",
      "The classification loss after processing this batch is:  0.2900783121585846\n",
      "The representation loss after processing this batch is:  0.0037461668252944946\n",
      "\n",
      "The classification loss after processing this batch is:  0.2671738862991333\n",
      "The representation loss after processing this batch is:  0.00399363785982132\n",
      "\n",
      "The classification loss after processing this batch is:  0.2733372151851654\n",
      "The representation loss after processing this batch is:  0.0035888850688934326\n",
      "\n",
      "The classification loss after processing this batch is:  0.3522002398967743\n",
      "The representation loss after processing this batch is:  0.004510968923568726\n",
      "\n",
      "The classification loss after processing this batch is:  0.45462191104888916\n",
      "The representation loss after processing this batch is:  0.003980115056037903\n",
      "\n",
      "The classification loss after processing this batch is:  0.4621935486793518\n",
      "The representation loss after processing this batch is:  0.0045798346400260925\n",
      "\n",
      "The classification loss after processing this batch is:  0.33693504333496094\n",
      "The representation loss after processing this batch is:  0.004649102687835693\n",
      "\n",
      "The classification loss after processing this batch is:  0.31891143321990967\n",
      "The representation loss after processing this batch is:  0.003895409405231476\n",
      "\n",
      "The classification loss after processing this batch is:  0.19353342056274414\n",
      "The representation loss after processing this batch is:  0.004458233714103699\n",
      "\n",
      "The classification loss after processing this batch is:  0.2649732530117035\n",
      "The representation loss after processing this batch is:  0.004400968551635742\n",
      "\n",
      "The classification loss after processing this batch is:  0.2322993278503418\n",
      "The representation loss after processing this batch is:  0.00373879075050354\n",
      "\n",
      "The classification loss after processing this batch is:  0.19800488650798798\n",
      "The representation loss after processing this batch is:  0.004075266420841217\n",
      "\n",
      "The classification loss after processing this batch is:  0.27057307958602905\n",
      "The representation loss after processing this batch is:  0.003530070185661316\n",
      "\n",
      "The classification loss after processing this batch is:  0.37127071619033813\n",
      "The representation loss after processing this batch is:  0.0039390698075294495\n",
      "\n",
      "The classification loss after processing this batch is:  0.33131736516952515\n",
      "The representation loss after processing this batch is:  0.0034959279000759125\n",
      "\n",
      "The classification loss after processing this batch is:  0.30909284949302673\n",
      "The representation loss after processing this batch is:  0.004904143512248993\n",
      "\n",
      "The classification loss after processing this batch is:  0.28361281752586365\n",
      "The representation loss after processing this batch is:  0.004601284861564636\n",
      "\n",
      "The classification loss after processing this batch is:  0.21170498430728912\n",
      "The representation loss after processing this batch is:  0.0042412057518959045\n",
      "\n",
      "The classification loss after processing this batch is:  0.26219016313552856\n",
      "The representation loss after processing this batch is:  0.004952467978000641\n",
      "\n",
      "The classification loss after processing this batch is:  0.18843011558055878\n",
      "The representation loss after processing this batch is:  0.003938421607017517\n",
      "\n",
      "The classification loss after processing this batch is:  0.2745679020881653\n",
      "The representation loss after processing this batch is:  0.003638729453086853\n",
      "\n",
      "The classification loss after processing this batch is:  0.33038899302482605\n",
      "The representation loss after processing this batch is:  0.0038986653089523315\n",
      "\n",
      "The classification loss after processing this batch is:  0.21575094759464264\n",
      "The representation loss after processing this batch is:  0.003623880445957184\n",
      "\n",
      "The classification loss after processing this batch is:  0.3520506024360657\n",
      "The representation loss after processing this batch is:  0.0033942312002182007\n",
      "\n",
      "The classification loss after processing this batch is:  0.3092813789844513\n",
      "The representation loss after processing this batch is:  0.0040763989090919495\n",
      "\n",
      "The classification loss after processing this batch is:  0.19882002472877502\n",
      "The representation loss after processing this batch is:  0.004127375781536102\n",
      "\n",
      "The classification loss after processing this batch is:  0.2106350213289261\n",
      "The representation loss after processing this batch is:  0.003963388502597809\n",
      "\n",
      "The classification loss after processing this batch is:  0.2867020070552826\n",
      "The representation loss after processing this batch is:  0.004197351634502411\n",
      "\n",
      "The classification loss after processing this batch is:  0.25926053524017334\n",
      "The representation loss after processing this batch is:  0.003976546227931976\n",
      "\n",
      "The classification loss after processing this batch is:  0.4990769028663635\n",
      "The representation loss after processing this batch is:  0.0037872716784477234\n",
      "\n",
      "The classification loss after processing this batch is:  0.3444361388683319\n",
      "The representation loss after processing this batch is:  0.00426163524389267\n",
      "\n",
      "The classification loss after processing this batch is:  0.31636330485343933\n",
      "The representation loss after processing this batch is:  0.0037521719932556152\n",
      "\n",
      "The classification loss after processing this batch is:  0.3054470121860504\n",
      "The representation loss after processing this batch is:  0.0035749152302742004\n",
      "\n",
      "The classification loss after processing this batch is:  0.3294006586074829\n",
      "The representation loss after processing this batch is:  0.004700507968664169\n",
      "\n",
      "The classification loss after processing this batch is:  0.29153284430503845\n",
      "The representation loss after processing this batch is:  0.0034675225615501404\n",
      "\n",
      "The classification loss after processing this batch is:  0.347618043422699\n",
      "The representation loss after processing this batch is:  0.004481621086597443\n",
      "\n",
      "The classification loss after processing this batch is:  0.3359956741333008\n",
      "The representation loss after processing this batch is:  0.004494138062000275\n",
      "\n",
      "The classification loss after processing this batch is:  0.3541880249977112\n",
      "The representation loss after processing this batch is:  0.005023933947086334\n",
      "\n",
      "The classification loss after processing this batch is:  0.30830177664756775\n",
      "The representation loss after processing this batch is:  0.0046243853867053986\n",
      "\n",
      "The classification loss after processing this batch is:  0.28390949964523315\n",
      "The representation loss after processing this batch is:  0.003824867308139801\n",
      "\n",
      "The classification loss after processing this batch is:  0.37496551871299744\n",
      "The representation loss after processing this batch is:  0.003846682608127594\n",
      "\n",
      "The classification loss after processing this batch is:  0.2816133499145508\n",
      "The representation loss after processing this batch is:  0.003602154552936554\n",
      "\n",
      "The classification loss after processing this batch is:  0.2966679632663727\n",
      "The representation loss after processing this batch is:  0.0035570263862609863\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.29447534680366516\n",
      "The representation loss after processing this batch is:  0.003932565450668335\n",
      "\n",
      "The classification loss after processing this batch is:  0.27725949883461\n",
      "The representation loss after processing this batch is:  0.004256486892700195\n",
      "\n",
      "The classification loss after processing this batch is:  0.23598922789096832\n",
      "The representation loss after processing this batch is:  0.0045800358057022095\n",
      "\n",
      "The classification loss after processing this batch is:  0.3740083873271942\n",
      "The representation loss after processing this batch is:  0.0035874247550964355\n",
      "\n",
      "The classification loss after processing this batch is:  0.5537524819374084\n",
      "The representation loss after processing this batch is:  0.003934845328330994\n",
      "\n",
      "The classification loss after processing this batch is:  0.27766433358192444\n",
      "The representation loss after processing this batch is:  0.004237540066242218\n",
      "\n",
      "The classification loss after processing this batch is:  0.4846504032611847\n",
      "The representation loss after processing this batch is:  0.004312768578529358\n",
      "\n",
      "The classification loss after processing this batch is:  0.41453489661216736\n",
      "The representation loss after processing this batch is:  0.004220552742481232\n",
      "\n",
      "The classification loss after processing this batch is:  0.3712233901023865\n",
      "The representation loss after processing this batch is:  0.004492796957492828\n",
      "\n",
      "The classification loss after processing this batch is:  0.23366671800613403\n",
      "The representation loss after processing this batch is:  0.004343844950199127\n",
      "\n",
      "The classification loss after processing this batch is:  0.40644100308418274\n",
      "The representation loss after processing this batch is:  0.0037698298692703247\n",
      "\n",
      "The classification loss after processing this batch is:  0.4354667663574219\n",
      "The representation loss after processing this batch is:  0.00453253835439682\n",
      "\n",
      "The classification loss after processing this batch is:  0.321492463350296\n",
      "The representation loss after processing this batch is:  0.004470109939575195\n",
      "\n",
      "The classification loss after processing this batch is:  0.1787085235118866\n",
      "The representation loss after processing this batch is:  0.0041482895612716675\n",
      "\n",
      "The classification loss after processing this batch is:  0.2819576561450958\n",
      "The representation loss after processing this batch is:  0.00412391871213913\n",
      "\n",
      "The classification loss after processing this batch is:  0.3303165137767792\n",
      "The representation loss after processing this batch is:  0.004489488899707794\n",
      "\n",
      "The classification loss after processing this batch is:  0.3356732726097107\n",
      "The representation loss after processing this batch is:  0.00354592502117157\n",
      "\n",
      "The classification loss after processing this batch is:  0.38319694995880127\n",
      "The representation loss after processing this batch is:  0.003940079361200333\n",
      "\n",
      "The classification loss after processing this batch is:  0.27999597787857056\n",
      "The representation loss after processing this batch is:  0.0036480724811553955\n",
      "\n",
      "The classification loss after processing this batch is:  0.30935969948768616\n",
      "The representation loss after processing this batch is:  0.0054965391755104065\n",
      "\n",
      "The classification loss after processing this batch is:  0.3834722638130188\n",
      "The representation loss after processing this batch is:  0.004733633249998093\n",
      "\n",
      "The classification loss after processing this batch is:  0.2921296954154968\n",
      "The representation loss after processing this batch is:  0.005068980157375336\n",
      "\n",
      "The classification loss after processing this batch is:  0.2516922354698181\n",
      "The representation loss after processing this batch is:  0.004093043506145477\n",
      "\n",
      "The classification loss after processing this batch is:  0.5337508320808411\n",
      "The representation loss after processing this batch is:  0.004280909895896912\n",
      "\n",
      "The classification loss after processing this batch is:  0.3881568908691406\n",
      "The representation loss after processing this batch is:  0.004479169845581055\n",
      "\n",
      "The classification loss after processing this batch is:  0.3231382966041565\n",
      "The representation loss after processing this batch is:  0.003940790891647339\n",
      "\n",
      "The classification loss after processing this batch is:  0.26562631130218506\n",
      "The representation loss after processing this batch is:  0.003925006836652756\n",
      "\n",
      "The classification loss after processing this batch is:  0.23831263184547424\n",
      "The representation loss after processing this batch is:  0.003384806215763092\n",
      "\n",
      "The classification loss after processing this batch is:  0.24029269814491272\n",
      "The representation loss after processing this batch is:  0.003885619342327118\n",
      "\n",
      "The classification loss after processing this batch is:  0.2731821835041046\n",
      "The representation loss after processing this batch is:  0.0040064118802547455\n",
      "\n",
      "The classification loss after processing this batch is:  0.5418469309806824\n",
      "The representation loss after processing this batch is:  0.004124827682971954\n",
      "\n",
      "The classification loss after processing this batch is:  0.43383029103279114\n",
      "The representation loss after processing this batch is:  0.004326775670051575\n",
      "\n",
      "The classification loss after processing this batch is:  0.3119634687900543\n",
      "The representation loss after processing this batch is:  0.004080910235643387\n",
      "\n",
      "The classification loss after processing this batch is:  0.29723623394966125\n",
      "The representation loss after processing this batch is:  0.004172861576080322\n",
      "\n",
      "The classification loss after processing this batch is:  0.27436313033103943\n",
      "The representation loss after processing this batch is:  0.0036128610372543335\n",
      "\n",
      "The classification loss after processing this batch is:  0.3156530261039734\n",
      "The representation loss after processing this batch is:  0.0037456005811691284\n",
      "\n",
      "The classification loss after processing this batch is:  0.42520561814308167\n",
      "The representation loss after processing this batch is:  0.004342552274465561\n",
      "\n",
      "The classification loss after processing this batch is:  0.34605005383491516\n",
      "The representation loss after processing this batch is:  0.0032283663749694824\n",
      "\n",
      "The classification loss after processing this batch is:  0.4031435251235962\n",
      "The representation loss after processing this batch is:  0.00423634797334671\n",
      "\n",
      "The classification loss after processing this batch is:  0.3072079122066498\n",
      "The representation loss after processing this batch is:  0.0036735758185386658\n",
      "\n",
      "The classification loss after processing this batch is:  0.1728963702917099\n",
      "The representation loss after processing this batch is:  0.003934614360332489\n",
      "\n",
      "The classification loss after processing this batch is:  0.3400260806083679\n",
      "The representation loss after processing this batch is:  0.0038988590240478516\n",
      "\n",
      "The classification loss after processing this batch is:  0.2614870071411133\n",
      "The representation loss after processing this batch is:  0.004007205367088318\n",
      "\n",
      "The classification loss after processing this batch is:  0.35127609968185425\n",
      "The representation loss after processing this batch is:  0.0041012242436409\n",
      "\n",
      "The classification loss after processing this batch is:  0.36147767305374146\n",
      "The representation loss after processing this batch is:  0.00337383896112442\n",
      "\n",
      "The classification loss after processing this batch is:  0.3897477984428406\n",
      "The representation loss after processing this batch is:  0.0037773624062538147\n",
      "\n",
      "The classification loss after processing this batch is:  0.36228880286216736\n",
      "The representation loss after processing this batch is:  0.003821432590484619\n",
      "\n",
      "The classification loss after processing this batch is:  0.3768000900745392\n",
      "The representation loss after processing this batch is:  0.0037403330206871033\n",
      "\n",
      "The classification loss after processing this batch is:  0.441507488489151\n",
      "The representation loss after processing this batch is:  0.003606356680393219\n",
      "\n",
      "The classification loss after processing this batch is:  0.46936213970184326\n",
      "The representation loss after processing this batch is:  0.00328633189201355\n",
      "\n",
      "The classification loss after processing this batch is:  0.37042585015296936\n",
      "The representation loss after processing this batch is:  0.003953881561756134\n",
      "\n",
      "The classification loss after processing this batch is:  0.21694937348365784\n",
      "The representation loss after processing this batch is:  0.004208296537399292\n",
      "\n",
      "The classification loss after processing this batch is:  0.1532435119152069\n",
      "The representation loss after processing this batch is:  0.004076175391674042\n",
      "\n",
      "The classification loss after processing this batch is:  0.28942108154296875\n",
      "The representation loss after processing this batch is:  0.004519864916801453\n",
      "\n",
      "The classification loss after processing this batch is:  0.22168470919132233\n",
      "The representation loss after processing this batch is:  0.006087765097618103\n",
      "\n",
      "The classification loss after processing this batch is:  0.3559318780899048\n",
      "The representation loss after processing this batch is:  0.0037022829055786133\n",
      "\n",
      "The classification loss after processing this batch is:  0.21188999712467194\n",
      "The representation loss after processing this batch is:  0.0041794851422309875\n",
      "\n",
      "The classification loss after processing this batch is:  0.3521498739719391\n",
      "The representation loss after processing this batch is:  0.004066728055477142\n",
      "\n",
      "The classification loss after processing this batch is:  0.14296366274356842\n",
      "The representation loss after processing this batch is:  0.004262886941432953\n",
      "\n",
      "The classification loss after processing this batch is:  0.3221813142299652\n",
      "The representation loss after processing this batch is:  0.004307687282562256\n",
      "\n",
      "The classification loss after processing this batch is:  0.28113678097724915\n",
      "The representation loss after processing this batch is:  0.004193000495433807\n",
      "\n",
      "The classification loss after processing this batch is:  0.3197588324546814\n",
      "The representation loss after processing this batch is:  0.005086399614810944\n",
      "\n",
      "The classification loss after processing this batch is:  0.3200293183326721\n",
      "The representation loss after processing this batch is:  0.004051625728607178\n",
      "\n",
      "The classification loss after processing this batch is:  0.2076387256383896\n",
      "The representation loss after processing this batch is:  0.0035240761935710907\n",
      "\n",
      "The classification loss after processing this batch is:  0.27376100420951843\n",
      "The representation loss after processing this batch is:  0.0038571208715438843\n",
      "\n",
      "The classification loss after processing this batch is:  0.31439724564552307\n",
      "The representation loss after processing this batch is:  0.0036573484539985657\n",
      "\n",
      "The classification loss after processing this batch is:  0.3119411766529083\n",
      "The representation loss after processing this batch is:  0.0036772489547729492\n",
      "\n",
      "The classification loss after processing this batch is:  0.20704132318496704\n",
      "The representation loss after processing this batch is:  0.003651171922683716\n",
      "\n",
      "The classification loss after processing this batch is:  0.2141464352607727\n",
      "The representation loss after processing this batch is:  0.004059210419654846\n",
      "\n",
      "The classification loss after processing this batch is:  0.1472724974155426\n",
      "The representation loss after processing this batch is:  0.004135921597480774\n",
      "\n",
      "The classification loss after processing this batch is:  0.18997055292129517\n",
      "The representation loss after processing this batch is:  0.004389055073261261\n",
      "\n",
      "The classification loss after processing this batch is:  0.18379172682762146\n",
      "The representation loss after processing this batch is:  0.004034273326396942\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.3238828778266907\n",
      "The representation loss after processing this batch is:  0.0038304775953292847\n",
      "\n",
      "The classification loss after processing this batch is:  0.1866198480129242\n",
      "The representation loss after processing this batch is:  0.003621138632297516\n",
      "\n",
      "The classification loss after processing this batch is:  0.17817085981369019\n",
      "The representation loss after processing this batch is:  0.003864087164402008\n",
      "\n",
      "The classification loss after processing this batch is:  0.26798883080482483\n",
      "The representation loss after processing this batch is:  0.003962039947509766\n",
      "\n",
      "The classification loss after processing this batch is:  0.28809547424316406\n",
      "The representation loss after processing this batch is:  0.004447735846042633\n",
      "\n",
      "The classification loss after processing this batch is:  0.25459566712379456\n",
      "The representation loss after processing this batch is:  0.004049248993396759\n",
      "\n",
      "The classification loss after processing this batch is:  0.2274080216884613\n",
      "The representation loss after processing this batch is:  0.004079319536685944\n",
      "\n",
      "The classification loss after processing this batch is:  0.17184805870056152\n",
      "The representation loss after processing this batch is:  0.0038191676139831543\n",
      "\n",
      "The classification loss after processing this batch is:  0.20006714761257172\n",
      "The representation loss after processing this batch is:  0.004244856536388397\n",
      "\n",
      "The classification loss after processing this batch is:  0.262022465467453\n",
      "The representation loss after processing this batch is:  0.004448920488357544\n",
      "\n",
      "The classification loss after processing this batch is:  0.2862366735935211\n",
      "The representation loss after processing this batch is:  0.004182115197181702\n",
      "\n",
      "The classification loss after processing this batch is:  0.1983601301908493\n",
      "The representation loss after processing this batch is:  0.0040885210037231445\n",
      "\n",
      "The classification loss after processing this batch is:  0.3270430862903595\n",
      "The representation loss after processing this batch is:  0.00394776463508606\n",
      "\n",
      "The classification loss after processing this batch is:  0.23467345535755157\n",
      "The representation loss after processing this batch is:  0.003630422055721283\n",
      "\n",
      "The classification loss after processing this batch is:  0.2944281995296478\n",
      "The representation loss after processing this batch is:  0.003982052206993103\n",
      "\n",
      "The classification loss after processing this batch is:  0.3285304605960846\n",
      "The representation loss after processing this batch is:  0.0045126937329769135\n",
      "\n",
      "The classification loss after processing this batch is:  0.23903784155845642\n",
      "The representation loss after processing this batch is:  0.004304468631744385\n",
      "\n",
      "The classification loss after processing this batch is:  0.3921632766723633\n",
      "The representation loss after processing this batch is:  0.004265010356903076\n",
      "\n",
      "The classification loss after processing this batch is:  0.30780282616615295\n",
      "The representation loss after processing this batch is:  0.0034029632806777954\n",
      "\n",
      "The classification loss after processing this batch is:  0.24167975783348083\n",
      "The representation loss after processing this batch is:  0.004097975790500641\n",
      "\n",
      "The classification loss after processing this batch is:  0.2696666121482849\n",
      "The representation loss after processing this batch is:  0.003985181450843811\n",
      "\n",
      "The classification loss after processing this batch is:  0.283567875623703\n",
      "The representation loss after processing this batch is:  0.004407033324241638\n",
      "\n",
      "The classification loss after processing this batch is:  0.28502407670021057\n",
      "The representation loss after processing this batch is:  0.0033218376338481903\n",
      "\n",
      "The classification loss after processing this batch is:  0.27776509523391724\n",
      "The representation loss after processing this batch is:  0.003903903067111969\n",
      "\n",
      "The classification loss after processing this batch is:  0.33307310938835144\n",
      "The representation loss after processing this batch is:  0.0038252025842666626\n",
      "\n",
      "The classification loss after processing this batch is:  0.298082172870636\n",
      "The representation loss after processing this batch is:  0.004085473716259003\n",
      "\n",
      "The classification loss after processing this batch is:  0.19708435237407684\n",
      "The representation loss after processing this batch is:  0.003423266112804413\n",
      "\n",
      "The classification loss after processing this batch is:  0.2544173300266266\n",
      "The representation loss after processing this batch is:  0.003696359694004059\n",
      "\n",
      "The classification loss after processing this batch is:  0.3389839231967926\n",
      "The representation loss after processing this batch is:  0.0035056062042713165\n",
      "\n",
      "The classification loss after processing this batch is:  0.21571268141269684\n",
      "The representation loss after processing this batch is:  0.0035907402634620667\n",
      "\n",
      "The classification loss after processing this batch is:  0.3098371624946594\n",
      "The representation loss after processing this batch is:  0.004167251288890839\n",
      "\n",
      "The classification loss after processing this batch is:  0.3085416853427887\n",
      "The representation loss after processing this batch is:  0.003877706825733185\n",
      "\n",
      "The classification loss after processing this batch is:  0.1824655383825302\n",
      "The representation loss after processing this batch is:  0.004385322332382202\n",
      "\n",
      "The classification loss after processing this batch is:  0.20189222693443298\n",
      "The representation loss after processing this batch is:  0.0038100332021713257\n",
      "\n",
      "The classification loss after processing this batch is:  0.2532988488674164\n",
      "The representation loss after processing this batch is:  0.004041746258735657\n",
      "\n",
      "The classification loss after processing this batch is:  0.23130837082862854\n",
      "The representation loss after processing this batch is:  0.00435856357216835\n",
      "\n",
      "The classification loss after processing this batch is:  0.2708587944507599\n",
      "The representation loss after processing this batch is:  0.0041697025299072266\n",
      "\n",
      "The classification loss after processing this batch is:  0.26808032393455505\n",
      "The representation loss after processing this batch is:  0.004648003727197647\n",
      "\n",
      "The classification loss after processing this batch is:  0.22719138860702515\n",
      "The representation loss after processing this batch is:  0.003931984305381775\n",
      "\n",
      "The classification loss after processing this batch is:  0.2915300726890564\n",
      "The representation loss after processing this batch is:  0.0032316744327545166\n",
      "\n",
      "The classification loss after processing this batch is:  0.29125356674194336\n",
      "The representation loss after processing this batch is:  0.004085421562194824\n",
      "\n",
      "The classification loss after processing this batch is:  0.14537903666496277\n",
      "The representation loss after processing this batch is:  0.004513725638389587\n",
      "\n",
      "The classification loss after processing this batch is:  0.2153514176607132\n",
      "The representation loss after processing this batch is:  0.00367765873670578\n",
      "\n",
      "The classification loss after processing this batch is:  0.2457508146762848\n",
      "The representation loss after processing this batch is:  0.0038557276129722595\n",
      "\n",
      "The classification loss after processing this batch is:  0.23091083765029907\n",
      "The representation loss after processing this batch is:  0.004146754741668701\n",
      "\n",
      "The classification loss after processing this batch is:  0.24682821333408356\n",
      "The representation loss after processing this batch is:  0.004087373614311218\n",
      "\n",
      "The classification loss after processing this batch is:  0.2981916069984436\n",
      "The representation loss after processing this batch is:  0.004177398979663849\n",
      "\n",
      "The classification loss after processing this batch is:  0.25214242935180664\n",
      "The representation loss after processing this batch is:  0.005042277276515961\n",
      "\n",
      "The classification loss after processing this batch is:  0.21022114157676697\n",
      "The representation loss after processing this batch is:  0.004464074969291687\n",
      "\n",
      "The classification loss after processing this batch is:  0.34511128067970276\n",
      "The representation loss after processing this batch is:  0.003954567015171051\n",
      "\n",
      "The classification loss after processing this batch is:  0.3262171149253845\n",
      "The representation loss after processing this batch is:  0.003683321177959442\n",
      "\n",
      "The classification loss after processing this batch is:  0.29963356256484985\n",
      "The representation loss after processing this batch is:  0.004112951457500458\n",
      "\n",
      "The classification loss after processing this batch is:  0.21358944475650787\n",
      "The representation loss after processing this batch is:  0.0040411800146102905\n",
      "\n",
      "The classification loss after processing this batch is:  0.18825508654117584\n",
      "The representation loss after processing this batch is:  0.003907017409801483\n",
      "\n",
      "The classification loss after processing this batch is:  0.3561939001083374\n",
      "The representation loss after processing this batch is:  0.0036510154604911804\n",
      "\n",
      "The classification loss after processing this batch is:  0.36637961864471436\n",
      "The representation loss after processing this batch is:  0.0036076009273529053\n",
      "\n",
      "The classification loss after processing this batch is:  0.3576365113258362\n",
      "The representation loss after processing this batch is:  0.003701239824295044\n",
      "\n",
      "The classification loss after processing this batch is:  0.3033730685710907\n",
      "The representation loss after processing this batch is:  0.004053689539432526\n",
      "\n",
      "The classification loss after processing this batch is:  0.3401050269603729\n",
      "The representation loss after processing this batch is:  0.0038978904485702515\n",
      "\n",
      "The classification loss after processing this batch is:  0.3671332001686096\n",
      "The representation loss after processing this batch is:  0.003394700586795807\n",
      "\n",
      "The classification loss after processing this batch is:  0.35819900035858154\n",
      "The representation loss after processing this batch is:  0.0036769285798072815\n",
      "\n",
      "The classification loss after processing this batch is:  0.3919793963432312\n",
      "The representation loss after processing this batch is:  0.003818996250629425\n",
      "\n",
      "The classification loss after processing this batch is:  0.3799210786819458\n",
      "The representation loss after processing this batch is:  0.00396467000246048\n",
      "\n",
      "The classification loss after processing this batch is:  0.2629287838935852\n",
      "The representation loss after processing this batch is:  0.003913253545761108\n",
      "\n",
      "The classification loss after processing this batch is:  0.14281216263771057\n",
      "The representation loss after processing this batch is:  0.003945969045162201\n",
      "\n",
      "The classification loss after processing this batch is:  0.2642117142677307\n",
      "The representation loss after processing this batch is:  0.004480525851249695\n",
      "\n",
      "The classification loss after processing this batch is:  0.26138219237327576\n",
      "The representation loss after processing this batch is:  0.003649294376373291\n",
      "\n",
      "The classification loss after processing this batch is:  0.20090661942958832\n",
      "The representation loss after processing this batch is:  0.003716692328453064\n",
      "\n",
      "The classification loss after processing this batch is:  0.27585554122924805\n",
      "The representation loss after processing this batch is:  0.0037032626569271088\n",
      "\n",
      "The classification loss after processing this batch is:  0.2540312707424164\n",
      "The representation loss after processing this batch is:  0.003401458263397217\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.24647535383701324\n",
      "The representation loss after processing this batch is:  0.0038891062140464783\n",
      "\n",
      "The classification loss after processing this batch is:  0.25411897897720337\n",
      "The representation loss after processing this batch is:  0.004128977656364441\n",
      "\n",
      "The classification loss after processing this batch is:  0.24582165479660034\n",
      "The representation loss after processing this batch is:  0.0034016743302345276\n",
      "\n",
      "The classification loss after processing this batch is:  0.24102789163589478\n",
      "The representation loss after processing this batch is:  0.0036438480019569397\n",
      "\n",
      "The classification loss after processing this batch is:  0.2938254177570343\n",
      "The representation loss after processing this batch is:  0.004047617316246033\n",
      "\n",
      "The classification loss after processing this batch is:  0.3032855689525604\n",
      "The representation loss after processing this batch is:  0.003986235707998276\n",
      "\n",
      "The classification loss after processing this batch is:  0.2915169298648834\n",
      "The representation loss after processing this batch is:  0.004973113536834717\n",
      "\n",
      "The classification loss after processing this batch is:  0.23483866453170776\n",
      "The representation loss after processing this batch is:  0.003679722547531128\n",
      "\n",
      "The classification loss after processing this batch is:  0.19713278114795685\n",
      "The representation loss after processing this batch is:  0.00395665317773819\n",
      "\n",
      "The classification loss after processing this batch is:  0.2821267545223236\n",
      "The representation loss after processing this batch is:  0.003443390130996704\n",
      "\n",
      "The classification loss after processing this batch is:  0.40864071249961853\n",
      "The representation loss after processing this batch is:  0.0033305883407592773\n",
      "\n",
      "The classification loss after processing this batch is:  0.26053598523139954\n",
      "The representation loss after processing this batch is:  0.0036228373646736145\n",
      "\n",
      "The classification loss after processing this batch is:  0.16068877279758453\n",
      "The representation loss after processing this batch is:  0.003938533365726471\n",
      "\n",
      "The classification loss after processing this batch is:  0.2937764525413513\n",
      "The representation loss after processing this batch is:  0.0035895593464374542\n",
      "\n",
      "The classification loss after processing this batch is:  0.13332685828208923\n",
      "The representation loss after processing this batch is:  0.0038217678666114807\n",
      "\n",
      "The classification loss after processing this batch is:  0.2557162642478943\n",
      "The representation loss after processing this batch is:  0.003613688051700592\n",
      "\n",
      "The classification loss after processing this batch is:  0.23159565031528473\n",
      "The representation loss after processing this batch is:  0.004413522779941559\n",
      "\n",
      "The classification loss after processing this batch is:  0.16092106699943542\n",
      "The representation loss after processing this batch is:  0.0037982091307640076\n",
      "\n",
      "The classification loss after processing this batch is:  0.19488659501075745\n",
      "The representation loss after processing this batch is:  0.004076994955539703\n",
      "\n",
      "The classification loss after processing this batch is:  0.20984958112239838\n",
      "The representation loss after processing this batch is:  0.0034924447536468506\n",
      "\n",
      "The classification loss after processing this batch is:  0.15631230175495148\n",
      "The representation loss after processing this batch is:  0.00380900502204895\n",
      "\n",
      "The classification loss after processing this batch is:  0.41229048371315\n",
      "The representation loss after processing this batch is:  0.003413178026676178\n",
      "\n",
      "The classification loss after processing this batch is:  0.43145453929901123\n",
      "The representation loss after processing this batch is:  0.004087287932634354\n",
      "\n",
      "The classification loss after processing this batch is:  0.32296377420425415\n",
      "The representation loss after processing this batch is:  0.004092540591955185\n",
      "\n",
      "The classification loss after processing this batch is:  0.38280484080314636\n",
      "The representation loss after processing this batch is:  0.003687102347612381\n",
      "\n",
      "The classification loss after processing this batch is:  0.2702387571334839\n",
      "The representation loss after processing this batch is:  0.004134725779294968\n",
      "\n",
      "The classification loss after processing this batch is:  0.25857076048851013\n",
      "The representation loss after processing this batch is:  0.0037815868854522705\n",
      "\n",
      "The classification loss after processing this batch is:  0.36597850918769836\n",
      "The representation loss after processing this batch is:  0.0037229210138320923\n",
      "\n",
      "The classification loss after processing this batch is:  0.22127509117126465\n",
      "The representation loss after processing this batch is:  0.003901224583387375\n",
      "\n",
      "The classification loss after processing this batch is:  0.3301050364971161\n",
      "The representation loss after processing this batch is:  0.004028979688882828\n",
      "\n",
      "The classification loss after processing this batch is:  0.25615614652633667\n",
      "The representation loss after processing this batch is:  0.004582434892654419\n",
      "\n",
      "The classification loss after processing this batch is:  0.3038477599620819\n",
      "The representation loss after processing this batch is:  0.0035190992057323456\n",
      "\n",
      "The classification loss after processing this batch is:  0.30092179775238037\n",
      "The representation loss after processing this batch is:  0.003615889698266983\n",
      "\n",
      "The classification loss after processing this batch is:  0.24657005071640015\n",
      "The representation loss after processing this batch is:  0.0036675557494163513\n",
      "\n",
      "The classification loss after processing this batch is:  0.31038764119148254\n",
      "The representation loss after processing this batch is:  0.0036233365535736084\n",
      "\n",
      "The classification loss after processing this batch is:  0.20555634796619415\n",
      "The representation loss after processing this batch is:  0.004276596009731293\n",
      "\n",
      "The classification loss after processing this batch is:  0.18560943007469177\n",
      "The representation loss after processing this batch is:  0.0034810081124305725\n",
      "\n",
      "The classification loss after processing this batch is:  0.2539981007575989\n",
      "The representation loss after processing this batch is:  0.0038228556513786316\n",
      "\n",
      "The classification loss after processing this batch is:  0.29302820563316345\n",
      "The representation loss after processing this batch is:  0.004232518374919891\n",
      "\n",
      "The classification loss after processing this batch is:  0.15744152665138245\n",
      "The representation loss after processing this batch is:  0.0037661120295524597\n",
      "\n",
      "The classification loss after processing this batch is:  0.1883659064769745\n",
      "The representation loss after processing this batch is:  0.0034217946231365204\n",
      "\n",
      "The classification loss after processing this batch is:  0.33233165740966797\n",
      "The representation loss after processing this batch is:  0.004137203097343445\n",
      "\n",
      "The classification loss after processing this batch is:  0.2501813471317291\n",
      "The representation loss after processing this batch is:  0.0035944506525993347\n",
      "\n",
      "The classification loss after processing this batch is:  0.2869791090488434\n",
      "The representation loss after processing this batch is:  0.003996469080448151\n",
      "\n",
      "The classification loss after processing this batch is:  0.4052310287952423\n",
      "The representation loss after processing this batch is:  0.003311537206172943\n",
      "\n",
      "The classification loss after processing this batch is:  0.20134519040584564\n",
      "The representation loss after processing this batch is:  0.004239514470100403\n",
      "\n",
      "The classification loss after processing this batch is:  0.15818196535110474\n",
      "The representation loss after processing this batch is:  0.0035591870546340942\n",
      "\n",
      "The classification loss after processing this batch is:  0.1805364191532135\n",
      "The representation loss after processing this batch is:  0.004079744219779968\n",
      "\n",
      "The classification loss after processing this batch is:  0.2562144100666046\n",
      "The representation loss after processing this batch is:  0.004427753388881683\n",
      "\n",
      "The classification loss after processing this batch is:  0.2713537812232971\n",
      "The representation loss after processing this batch is:  0.0037822797894477844\n",
      "\n",
      "The classification loss after processing this batch is:  0.2266278862953186\n",
      "The representation loss after processing this batch is:  0.004074610769748688\n",
      "\n",
      "The classification loss after processing this batch is:  0.2561601400375366\n",
      "The representation loss after processing this batch is:  0.003631994128227234\n",
      "\n",
      "The classification loss after processing this batch is:  0.23375800251960754\n",
      "The representation loss after processing this batch is:  0.003721170127391815\n",
      "\n",
      "The classification loss after processing this batch is:  0.23815135657787323\n",
      "The representation loss after processing this batch is:  0.004041068255901337\n",
      "\n",
      "The classification loss after processing this batch is:  0.24481147527694702\n",
      "The representation loss after processing this batch is:  0.0038871057331562042\n",
      "\n",
      "The classification loss after processing this batch is:  0.35944822430610657\n",
      "The representation loss after processing this batch is:  0.004063863307237625\n",
      "\n",
      "The classification loss after processing this batch is:  0.31325623393058777\n",
      "The representation loss after processing this batch is:  0.0044332221150398254\n",
      "\n",
      "The classification loss after processing this batch is:  0.3924316465854645\n",
      "The representation loss after processing this batch is:  0.003665253520011902\n",
      "\n",
      "The classification loss after processing this batch is:  0.3483964800834656\n",
      "The representation loss after processing this batch is:  0.003635760396718979\n",
      "\n",
      "The classification loss after processing this batch is:  0.35125017166137695\n",
      "The representation loss after processing this batch is:  0.004011467099189758\n",
      "\n",
      "The classification loss after processing this batch is:  0.35181981325149536\n",
      "The representation loss after processing this batch is:  0.0038384422659873962\n",
      "\n",
      "The classification loss after processing this batch is:  0.12351420521736145\n",
      "The representation loss after processing this batch is:  0.0036978796124458313\n",
      "\n",
      "The classification loss after processing this batch is:  0.25258034467697144\n",
      "The representation loss after processing this batch is:  0.005029842257499695\n",
      "\n",
      "The classification loss after processing this batch is:  0.24434611201286316\n",
      "The representation loss after processing this batch is:  0.004628010094165802\n",
      "\n",
      "The classification loss after processing this batch is:  0.22238454222679138\n",
      "The representation loss after processing this batch is:  0.004143893718719482\n",
      "\n",
      "The classification loss after processing this batch is:  0.32284605503082275\n",
      "The representation loss after processing this batch is:  0.003276623785495758\n",
      "\n",
      "The classification loss after processing this batch is:  0.25126948952674866\n",
      "The representation loss after processing this batch is:  0.0036262087523937225\n",
      "\n",
      "The classification loss after processing this batch is:  0.29369401931762695\n",
      "The representation loss after processing this batch is:  0.0034599900245666504\n",
      "\n",
      "The classification loss after processing this batch is:  0.3285890519618988\n",
      "The representation loss after processing this batch is:  0.003414653241634369\n",
      "\n",
      "The classification loss after processing this batch is:  0.32084178924560547\n",
      "The representation loss after processing this batch is:  0.004008442163467407\n",
      "\n",
      "The classification loss after processing this batch is:  0.3992879092693329\n",
      "The representation loss after processing this batch is:  0.003790542483329773\n",
      "\n",
      "The classification loss after processing this batch is:  0.2815881073474884\n",
      "The representation loss after processing this batch is:  0.0037539079785346985\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.33947545289993286\n",
      "The representation loss after processing this batch is:  0.0035604089498519897\n",
      "\n",
      "The classification loss after processing this batch is:  0.23590412735939026\n",
      "The representation loss after processing this batch is:  0.0041786134243011475\n",
      "\n",
      "The classification loss after processing this batch is:  0.38268500566482544\n",
      "The representation loss after processing this batch is:  0.003829341381788254\n",
      "\n",
      "The classification loss after processing this batch is:  0.39420977234840393\n",
      "The representation loss after processing this batch is:  0.004084691405296326\n",
      "\n",
      "The classification loss after processing this batch is:  0.14567089080810547\n",
      "The representation loss after processing this batch is:  0.0032309219241142273\n",
      "\n",
      "The classification loss after processing this batch is:  0.18277835845947266\n",
      "The representation loss after processing this batch is:  0.003779679536819458\n",
      "\n",
      "The classification loss after processing this batch is:  0.37442895770072937\n",
      "The representation loss after processing this batch is:  0.003436323255300522\n",
      "\n",
      "The classification loss after processing this batch is:  0.14167353510856628\n",
      "The representation loss after processing this batch is:  0.0040898397564888\n",
      "\n",
      "The classification loss after processing this batch is:  0.2782841920852661\n",
      "The representation loss after processing this batch is:  0.0032820701599121094\n",
      "\n",
      "The classification loss after processing this batch is:  0.2956659495830536\n",
      "The representation loss after processing this batch is:  0.0038550421595573425\n",
      "\n",
      "The classification loss after processing this batch is:  0.260458379983902\n",
      "The representation loss after processing this batch is:  0.0039059892296791077\n",
      "\n",
      "The classification loss after processing this batch is:  0.39957600831985474\n",
      "The representation loss after processing this batch is:  0.0044048503041267395\n",
      "\n",
      "The classification loss after processing this batch is:  0.3191107213497162\n",
      "The representation loss after processing this batch is:  0.0041847676038742065\n",
      "\n",
      "The classification loss after processing this batch is:  0.31754034757614136\n",
      "The representation loss after processing this batch is:  0.004173807799816132\n",
      "\n",
      "The classification loss after processing this batch is:  0.22180846333503723\n",
      "The representation loss after processing this batch is:  0.0033293962478637695\n",
      "\n",
      "The classification loss after processing this batch is:  0.31394582986831665\n",
      "The representation loss after processing this batch is:  0.0035230182111263275\n",
      "\n",
      "The classification loss after processing this batch is:  0.16684111952781677\n",
      "The representation loss after processing this batch is:  0.0033954381942749023\n",
      "\n",
      "The classification loss after processing this batch is:  0.15483175218105316\n",
      "The representation loss after processing this batch is:  0.0033058226108551025\n",
      "\n",
      "The classification loss after processing this batch is:  0.1595531851053238\n",
      "The representation loss after processing this batch is:  0.0033447518944740295\n",
      "\n",
      "The classification loss after processing this batch is:  0.1489802747964859\n",
      "The representation loss after processing this batch is:  0.003534160554409027\n",
      "\n",
      "The classification loss after processing this batch is:  0.2416546642780304\n",
      "The representation loss after processing this batch is:  0.003946378827095032\n",
      "\n",
      "The classification loss after processing this batch is:  0.16115815937519073\n",
      "The representation loss after processing this batch is:  0.0035542845726013184\n",
      "\n",
      "The classification loss after processing this batch is:  0.20285078883171082\n",
      "The representation loss after processing this batch is:  0.0035155154764652252\n",
      "\n",
      "The classification loss after processing this batch is:  0.23534581065177917\n",
      "The representation loss after processing this batch is:  0.0038222745060920715\n",
      "\n",
      "The classification loss after processing this batch is:  0.3157796859741211\n",
      "The representation loss after processing this batch is:  0.004245847463607788\n",
      "\n",
      "The classification loss after processing this batch is:  0.33384430408477783\n",
      "The representation loss after processing this batch is:  0.003701545298099518\n",
      "\n",
      "The classification loss after processing this batch is:  0.2409389466047287\n",
      "The representation loss after processing this batch is:  0.0040704235434532166\n",
      "\n",
      "The classification loss after processing this batch is:  0.3238711655139923\n",
      "The representation loss after processing this batch is:  0.003770347684621811\n",
      "\n",
      "The classification loss after processing this batch is:  0.22427186369895935\n",
      "The representation loss after processing this batch is:  0.003864660859107971\n",
      "\n",
      "The classification loss after processing this batch is:  0.26621803641319275\n",
      "The representation loss after processing this batch is:  0.003916501998901367\n",
      "\n",
      "The classification loss after processing this batch is:  0.4198741018772125\n",
      "The representation loss after processing this batch is:  0.004031658172607422\n",
      "\n",
      "The classification loss after processing this batch is:  0.24821525812149048\n",
      "The representation loss after processing this batch is:  0.0034096166491508484\n",
      "\n",
      "The classification loss after processing this batch is:  0.38371941447257996\n",
      "The representation loss after processing this batch is:  0.0033432282507419586\n",
      "\n",
      "The classification loss after processing this batch is:  0.32460683584213257\n",
      "The representation loss after processing this batch is:  0.0036274418234825134\n",
      "\n",
      "The classification loss after processing this batch is:  0.3077187240123749\n",
      "The representation loss after processing this batch is:  0.0035689398646354675\n",
      "\n",
      "The classification loss after processing this batch is:  0.2521403431892395\n",
      "The representation loss after processing this batch is:  0.004051730036735535\n",
      "\n",
      "The classification loss after processing this batch is:  0.1743122935295105\n",
      "The representation loss after processing this batch is:  0.003426477313041687\n",
      "\n",
      "The classification loss after processing this batch is:  0.1829840987920761\n",
      "The representation loss after processing this batch is:  0.00326363742351532\n",
      "\n",
      "The classification loss after processing this batch is:  0.18574517965316772\n",
      "The representation loss after processing this batch is:  0.003695271909236908\n",
      "\n",
      "The classification loss after processing this batch is:  0.16162827610969543\n",
      "The representation loss after processing this batch is:  0.0035911574959754944\n",
      "\n",
      "The classification loss after processing this batch is:  0.30902454257011414\n",
      "The representation loss after processing this batch is:  0.0038929954171180725\n",
      "\n",
      "The classification loss after processing this batch is:  0.18822555243968964\n",
      "The representation loss after processing this batch is:  0.0039844810962677\n",
      "\n",
      "The classification loss after processing this batch is:  0.3640303909778595\n",
      "The representation loss after processing this batch is:  0.0041403137147426605\n",
      "\n",
      "The classification loss after processing this batch is:  0.22207756340503693\n",
      "The representation loss after processing this batch is:  0.004015028476715088\n",
      "\n",
      "The classification loss after processing this batch is:  0.2816091477870941\n",
      "The representation loss after processing this batch is:  0.0036343857645988464\n",
      "\n",
      "The classification loss after processing this batch is:  0.4384814500808716\n",
      "The representation loss after processing this batch is:  0.003564409911632538\n",
      "\n",
      "The classification loss after processing this batch is:  0.29564613103866577\n",
      "The representation loss after processing this batch is:  0.003133535385131836\n",
      "\n",
      "The classification loss after processing this batch is:  0.17823639512062073\n",
      "The representation loss after processing this batch is:  0.0037375837564468384\n",
      "\n",
      "The classification loss after processing this batch is:  0.1694984883069992\n",
      "The representation loss after processing this batch is:  0.004033312201499939\n",
      "\n",
      "The classification loss after processing this batch is:  0.1681937873363495\n",
      "The representation loss after processing this batch is:  0.004148043692111969\n",
      "\n",
      "The classification loss after processing this batch is:  0.20261014997959137\n",
      "The representation loss after processing this batch is:  0.0037511736154556274\n",
      "\n",
      "The classification loss after processing this batch is:  0.1974198967218399\n",
      "The representation loss after processing this batch is:  0.0035255402326583862\n",
      "\n",
      "The classification loss after processing this batch is:  0.4000643491744995\n",
      "The representation loss after processing this batch is:  0.003934182226657867\n",
      "\n",
      "The classification loss after processing this batch is:  0.36550503969192505\n",
      "The representation loss after processing this batch is:  0.003939252346754074\n",
      "\n",
      "The classification loss after processing this batch is:  0.23829717934131622\n",
      "The representation loss after processing this batch is:  0.003766871988773346\n",
      "\n",
      "The classification loss after processing this batch is:  0.3801506757736206\n",
      "The representation loss after processing this batch is:  0.004086889326572418\n",
      "\n",
      "The classification loss after processing this batch is:  0.19891977310180664\n",
      "The representation loss after processing this batch is:  0.003677859902381897\n",
      "\n",
      "The classification loss after processing this batch is:  0.24666675925254822\n",
      "The representation loss after processing this batch is:  0.003796197474002838\n",
      "\n",
      "The classification loss after processing this batch is:  0.37714508175849915\n",
      "The representation loss after processing this batch is:  0.0036755353212356567\n",
      "\n",
      "The classification loss after processing this batch is:  0.25533899664878845\n",
      "The representation loss after processing this batch is:  0.005231868475675583\n",
      "\n",
      "The classification loss after processing this batch is:  0.2608063519001007\n",
      "The representation loss after processing this batch is:  0.005256146192550659\n",
      "\n",
      "The classification loss after processing this batch is:  0.20713476836681366\n",
      "The representation loss after processing this batch is:  0.005437169224023819\n",
      "\n",
      "The classification loss after processing this batch is:  0.3268287479877472\n",
      "The representation loss after processing this batch is:  0.0047994330525398254\n",
      "\n",
      "The classification loss after processing this batch is:  0.320637583732605\n",
      "The representation loss after processing this batch is:  0.004891648888587952\n",
      "\n",
      "The classification loss after processing this batch is:  0.2387336641550064\n",
      "The representation loss after processing this batch is:  0.004018276929855347\n",
      "\n",
      "The classification loss after processing this batch is:  0.24787263572216034\n",
      "The representation loss after processing this batch is:  0.003971293568611145\n",
      "\n",
      "The classification loss after processing this batch is:  0.31285813450813293\n",
      "The representation loss after processing this batch is:  0.0038116201758384705\n",
      "\n",
      "The classification loss after processing this batch is:  0.3303340971469879\n",
      "The representation loss after processing this batch is:  0.0029277950525283813\n",
      "\n",
      "The classification loss after processing this batch is:  0.2817574143409729\n",
      "The representation loss after processing this batch is:  0.003402523696422577\n",
      "\n",
      "The classification loss after processing this batch is:  0.19199196994304657\n",
      "The representation loss after processing this batch is:  0.004454754292964935\n",
      "\n",
      "The classification loss after processing this batch is:  0.12264963239431381\n",
      "The representation loss after processing this batch is:  0.00381634384393692\n",
      "\n",
      "The classification loss after processing this batch is:  0.27152708172798157\n",
      "The representation loss after processing this batch is:  0.003959000110626221\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2015213668346405\n",
      "The representation loss after processing this batch is:  0.0038957297801971436\n",
      "\n",
      "The classification loss after processing this batch is:  0.3433596193790436\n",
      "The representation loss after processing this batch is:  0.003085523843765259\n",
      "\n",
      "The classification loss after processing this batch is:  0.17604531347751617\n",
      "The representation loss after processing this batch is:  0.003907114267349243\n",
      "\n",
      "The classification loss after processing this batch is:  0.2141633778810501\n",
      "The representation loss after processing this batch is:  0.003440171480178833\n",
      "\n",
      "The classification loss after processing this batch is:  0.2771992087364197\n",
      "The representation loss after processing this batch is:  0.0040198564529418945\n",
      "\n",
      "The classification loss after processing this batch is:  0.22274088859558105\n",
      "The representation loss after processing this batch is:  0.0032498762011528015\n",
      "\n",
      "The classification loss after processing this batch is:  0.3129597306251526\n",
      "The representation loss after processing this batch is:  0.0036815404891967773\n",
      "\n",
      "The classification loss after processing this batch is:  0.18096882104873657\n",
      "The representation loss after processing this batch is:  0.0034958571195602417\n",
      "\n",
      "The classification loss after processing this batch is:  0.22885602712631226\n",
      "The representation loss after processing this batch is:  0.0032684728503227234\n",
      "\n",
      "The classification loss after processing this batch is:  0.2166193574666977\n",
      "The representation loss after processing this batch is:  0.003705635666847229\n",
      "\n",
      "The classification loss after processing this batch is:  0.31023073196411133\n",
      "The representation loss after processing this batch is:  0.004420801997184753\n",
      "\n",
      "The classification loss after processing this batch is:  0.2932370603084564\n",
      "The representation loss after processing this batch is:  0.004004478454589844\n",
      "\n",
      "The classification loss after processing this batch is:  0.3023402988910675\n",
      "The representation loss after processing this batch is:  0.0036263130605220795\n",
      "\n",
      "The classification loss after processing this batch is:  0.3380211591720581\n",
      "The representation loss after processing this batch is:  0.0039882659912109375\n",
      "\n",
      "The classification loss after processing this batch is:  0.4054916799068451\n",
      "The representation loss after processing this batch is:  0.003718547523021698\n",
      "\n",
      "The classification loss after processing this batch is:  0.272256463766098\n",
      "The representation loss after processing this batch is:  0.004262842237949371\n",
      "\n",
      "The classification loss after processing this batch is:  0.38588905334472656\n",
      "The representation loss after processing this batch is:  0.0034476369619369507\n",
      "\n",
      "The classification loss after processing this batch is:  0.2627529501914978\n",
      "The representation loss after processing this batch is:  0.0036133751273155212\n",
      "\n",
      "The classification loss after processing this batch is:  0.17977739870548248\n",
      "The representation loss after processing this batch is:  0.0037729963660240173\n",
      "\n",
      "The classification loss after processing this batch is:  0.13217522203922272\n",
      "The representation loss after processing this batch is:  0.003162562847137451\n",
      "\n",
      "The classification loss after processing this batch is:  0.1734474152326584\n",
      "The representation loss after processing this batch is:  0.0037476643919944763\n",
      "\n",
      "The classification loss after processing this batch is:  0.3724938929080963\n",
      "The representation loss after processing this batch is:  0.0035625994205474854\n",
      "\n",
      "The classification loss after processing this batch is:  0.23758551478385925\n",
      "The representation loss after processing this batch is:  0.00359257310628891\n",
      "\n",
      "The classification loss after processing this batch is:  0.22517140209674835\n",
      "The representation loss after processing this batch is:  0.0036958083510398865\n",
      "\n",
      "The classification loss after processing this batch is:  0.25496765971183777\n",
      "The representation loss after processing this batch is:  0.0038311928510665894\n",
      "\n",
      "The classification loss after processing this batch is:  0.23474416136741638\n",
      "The representation loss after processing this batch is:  0.00366172194480896\n",
      "\n",
      "The classification loss after processing this batch is:  0.1774030178785324\n",
      "The representation loss after processing this batch is:  0.0033849626779556274\n",
      "\n",
      "The classification loss after processing this batch is:  0.2519592046737671\n",
      "The representation loss after processing this batch is:  0.0032314881682395935\n",
      "\n",
      "The classification loss after processing this batch is:  0.29112708568573\n",
      "The representation loss after processing this batch is:  0.0035917088389396667\n",
      "\n",
      "The classification loss after processing this batch is:  0.342695415019989\n",
      "The representation loss after processing this batch is:  0.003611534833908081\n",
      "\n",
      "The classification loss after processing this batch is:  0.17183910310268402\n",
      "The representation loss after processing this batch is:  0.003358803689479828\n",
      "\n",
      "The classification loss after processing this batch is:  0.36484402418136597\n",
      "The representation loss after processing this batch is:  0.003511689603328705\n",
      "\n",
      "The classification loss after processing this batch is:  0.22222445905208588\n",
      "The representation loss after processing this batch is:  0.0031439512968063354\n",
      "\n",
      "The classification loss after processing this batch is:  0.267762690782547\n",
      "The representation loss after processing this batch is:  0.0031437575817108154\n",
      "\n",
      "The classification loss after processing this batch is:  0.2264462560415268\n",
      "The representation loss after processing this batch is:  0.003796316683292389\n",
      "\n",
      "The classification loss after processing this batch is:  0.17297275364398956\n",
      "The representation loss after processing this batch is:  0.003636308014392853\n",
      "\n",
      "The classification loss after processing this batch is:  0.21191145479679108\n",
      "The representation loss after processing this batch is:  0.00403662770986557\n",
      "\n",
      "The classification loss after processing this batch is:  0.22722625732421875\n",
      "The representation loss after processing this batch is:  0.003818891942501068\n",
      "\n",
      "The classification loss after processing this batch is:  0.334139883518219\n",
      "The representation loss after processing this batch is:  0.004112672060728073\n",
      "\n",
      "The classification loss after processing this batch is:  0.40613582730293274\n",
      "The representation loss after processing this batch is:  0.004329755902290344\n",
      "\n",
      "The classification loss after processing this batch is:  0.3588261306285858\n",
      "The representation loss after processing this batch is:  0.003767266869544983\n",
      "\n",
      "The classification loss after processing this batch is:  0.29665079712867737\n",
      "The representation loss after processing this batch is:  0.00419418141245842\n",
      "\n",
      "The classification loss after processing this batch is:  0.22966426610946655\n",
      "The representation loss after processing this batch is:  0.004388898611068726\n",
      "\n",
      "The classification loss after processing this batch is:  0.33812424540519714\n",
      "The representation loss after processing this batch is:  0.003238830715417862\n",
      "\n",
      "The classification loss after processing this batch is:  0.2632147967815399\n",
      "The representation loss after processing this batch is:  0.003618381917476654\n",
      "\n",
      "The classification loss after processing this batch is:  0.1251893937587738\n",
      "The representation loss after processing this batch is:  0.00358707457780838\n",
      "\n",
      "The classification loss after processing this batch is:  0.21528670191764832\n",
      "The representation loss after processing this batch is:  0.0035166852176189423\n",
      "\n",
      "The classification loss after processing this batch is:  0.4701104164123535\n",
      "The representation loss after processing this batch is:  0.004251420497894287\n",
      "\n",
      "The classification loss after processing this batch is:  0.52320396900177\n",
      "The representation loss after processing this batch is:  0.004027850925922394\n",
      "\n",
      "The classification loss after processing this batch is:  0.4477499723434448\n",
      "The representation loss after processing this batch is:  0.003655802458524704\n",
      "\n",
      "The classification loss after processing this batch is:  0.2959210276603699\n",
      "The representation loss after processing this batch is:  0.003832392394542694\n",
      "\n",
      "The classification loss after processing this batch is:  0.20503607392311096\n",
      "The representation loss after processing this batch is:  0.0035600773990154266\n",
      "\n",
      "The classification loss after processing this batch is:  0.22319738566875458\n",
      "The representation loss after processing this batch is:  0.003370031714439392\n",
      "\n",
      "The classification loss after processing this batch is:  0.24095214903354645\n",
      "The representation loss after processing this batch is:  0.004075042903423309\n",
      "\n",
      "The classification loss after processing this batch is:  0.335086464881897\n",
      "The representation loss after processing this batch is:  0.0038474053144454956\n",
      "\n",
      "The classification loss after processing this batch is:  0.27006056904792786\n",
      "The representation loss after processing this batch is:  0.0038719698786735535\n",
      "\n",
      "The classification loss after processing this batch is:  0.283117413520813\n",
      "The representation loss after processing this batch is:  0.004426136612892151\n",
      "\n",
      "The classification loss after processing this batch is:  0.2519988715648651\n",
      "The representation loss after processing this batch is:  0.003935717046260834\n",
      "\n",
      "The classification loss after processing this batch is:  0.2176724523305893\n",
      "The representation loss after processing this batch is:  0.003969945013523102\n",
      "\n",
      "The classification loss after processing this batch is:  0.2847968339920044\n",
      "The representation loss after processing this batch is:  0.004054360091686249\n",
      "\n",
      "The classification loss after processing this batch is:  0.2897758185863495\n",
      "The representation loss after processing this batch is:  0.003321520984172821\n",
      "\n",
      "The classification loss after processing this batch is:  0.2523577809333801\n",
      "The representation loss after processing this batch is:  0.003377459943294525\n",
      "\n",
      "The classification loss after processing this batch is:  0.4215750992298126\n",
      "The representation loss after processing this batch is:  0.004044432193040848\n",
      "\n",
      "The classification loss after processing this batch is:  0.4485045373439789\n",
      "The representation loss after processing this batch is:  0.004037745296955109\n",
      "\n",
      "The classification loss after processing this batch is:  0.30464786291122437\n",
      "The representation loss after processing this batch is:  0.004714973270893097\n",
      "\n",
      "The classification loss after processing this batch is:  0.2614343762397766\n",
      "The representation loss after processing this batch is:  0.003885813057422638\n",
      "\n",
      "The classification loss after processing this batch is:  0.20630070567131042\n",
      "The representation loss after processing this batch is:  0.003956645727157593\n",
      "\n",
      "The classification loss after processing this batch is:  0.1882517784833908\n",
      "The representation loss after processing this batch is:  0.0035306736826896667\n",
      "\n",
      "The classification loss after processing this batch is:  0.35925185680389404\n",
      "The representation loss after processing this batch is:  0.004269629716873169\n",
      "\n",
      "The classification loss after processing this batch is:  0.2582891285419464\n",
      "The representation loss after processing this batch is:  0.0038319602608680725\n",
      "\n",
      "The classification loss after processing this batch is:  0.21760740876197815\n",
      "The representation loss after processing this batch is:  0.003949359059333801\n",
      "\n",
      "The classification loss after processing this batch is:  0.35826823115348816\n",
      "The representation loss after processing this batch is:  0.003330923616886139\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1446932852268219\n",
      "The representation loss after processing this batch is:  0.003491811454296112\n",
      "\n",
      "The classification loss after processing this batch is:  0.20308643579483032\n",
      "The representation loss after processing this batch is:  0.003702796995639801\n",
      "\n",
      "The classification loss after processing this batch is:  0.25409990549087524\n",
      "The representation loss after processing this batch is:  0.0036123692989349365\n",
      "\n",
      "The classification loss after processing this batch is:  0.32180365920066833\n",
      "The representation loss after processing this batch is:  0.0032575465738773346\n",
      "\n",
      "The classification loss after processing this batch is:  0.3558451235294342\n",
      "The representation loss after processing this batch is:  0.0037468746304512024\n",
      "\n",
      "The classification loss after processing this batch is:  0.22374960780143738\n",
      "The representation loss after processing this batch is:  0.0035656318068504333\n",
      "\n",
      "The classification loss after processing this batch is:  0.2485010176897049\n",
      "The representation loss after processing this batch is:  0.0037757903337478638\n",
      "\n",
      "The classification loss after processing this batch is:  0.15172748267650604\n",
      "The representation loss after processing this batch is:  0.003207176923751831\n",
      "\n",
      "The classification loss after processing this batch is:  0.19254134595394135\n",
      "The representation loss after processing this batch is:  0.003330916166305542\n",
      "\n",
      "The classification loss after processing this batch is:  0.17137381434440613\n",
      "The representation loss after processing this batch is:  0.0034638121724128723\n",
      "\n",
      "The classification loss after processing this batch is:  0.18507924675941467\n",
      "The representation loss after processing this batch is:  0.0033879876136779785\n",
      "\n",
      "The classification loss after processing this batch is:  0.23056666553020477\n",
      "The representation loss after processing this batch is:  0.00334935262799263\n",
      "\n",
      "The classification loss after processing this batch is:  0.24393317103385925\n",
      "The representation loss after processing this batch is:  0.003633923828601837\n",
      "\n",
      "The classification loss after processing this batch is:  0.3076544404029846\n",
      "The representation loss after processing this batch is:  0.003936648368835449\n",
      "\n",
      "The classification loss after processing this batch is:  0.12206530570983887\n",
      "The representation loss after processing this batch is:  0.0034955590963363647\n",
      "\n",
      "The classification loss after processing this batch is:  0.1771404892206192\n",
      "The representation loss after processing this batch is:  0.0035077258944511414\n",
      "\n",
      "The classification loss after processing this batch is:  0.182193785905838\n",
      "The representation loss after processing this batch is:  0.004467561841011047\n",
      "\n",
      "The classification loss after processing this batch is:  0.2945135831832886\n",
      "The representation loss after processing this batch is:  0.003620769828557968\n",
      "\n",
      "The classification loss after processing this batch is:  0.1823367476463318\n",
      "The representation loss after processing this batch is:  0.004513256251811981\n",
      "\n",
      "The classification loss after processing this batch is:  0.42732352018356323\n",
      "The representation loss after processing this batch is:  0.00406695157289505\n",
      "\n",
      "The classification loss after processing this batch is:  0.3744233250617981\n",
      "The representation loss after processing this batch is:  0.0037013739347457886\n",
      "\n",
      "The classification loss after processing this batch is:  0.33930474519729614\n",
      "The representation loss after processing this batch is:  0.003799065947532654\n",
      "\n",
      "The classification loss after processing this batch is:  0.2844794690608978\n",
      "The representation loss after processing this batch is:  0.0036450326442718506\n",
      "\n",
      "The classification loss after processing this batch is:  0.1831493377685547\n",
      "The representation loss after processing this batch is:  0.0036705881357192993\n",
      "\n",
      "The classification loss after processing this batch is:  0.24640557169914246\n",
      "The representation loss after processing this batch is:  0.003314696252346039\n",
      "\n",
      "The classification loss after processing this batch is:  0.25668394565582275\n",
      "The representation loss after processing this batch is:  0.003610469400882721\n",
      "\n",
      "The classification loss after processing this batch is:  0.21732088923454285\n",
      "The representation loss after processing this batch is:  0.0037420988082885742\n",
      "\n",
      "The classification loss after processing this batch is:  0.10763748735189438\n",
      "The representation loss after processing this batch is:  0.003293849527835846\n",
      "\n",
      "The classification loss after processing this batch is:  0.30500757694244385\n",
      "The representation loss after processing this batch is:  0.0037917867302894592\n",
      "\n",
      "The classification loss after processing this batch is:  0.360292911529541\n",
      "The representation loss after processing this batch is:  0.0033618248999118805\n",
      "\n",
      "The classification loss after processing this batch is:  0.26430848240852356\n",
      "The representation loss after processing this batch is:  0.003622189164161682\n",
      "\n",
      "The classification loss after processing this batch is:  0.3126223385334015\n",
      "The representation loss after processing this batch is:  0.003514312207698822\n",
      "\n",
      "The classification loss after processing this batch is:  0.41545477509498596\n",
      "The representation loss after processing this batch is:  0.004046589136123657\n",
      "\n",
      "The classification loss after processing this batch is:  0.5675216913223267\n",
      "The representation loss after processing this batch is:  0.0036326199769973755\n",
      "\n",
      "The classification loss after processing this batch is:  0.31320667266845703\n",
      "The representation loss after processing this batch is:  0.003092952072620392\n",
      "\n",
      "The classification loss after processing this batch is:  0.22977454960346222\n",
      "The representation loss after processing this batch is:  0.003641866147518158\n",
      "\n",
      "The classification loss after processing this batch is:  0.31318676471710205\n",
      "The representation loss after processing this batch is:  0.0036649107933044434\n",
      "\n",
      "The classification loss after processing this batch is:  0.22489385306835175\n",
      "The representation loss after processing this batch is:  0.0038196444511413574\n",
      "\n",
      "The classification loss after processing this batch is:  0.20117956399917603\n",
      "The representation loss after processing this batch is:  0.0036913827061653137\n",
      "\n",
      "The classification loss after processing this batch is:  0.17592103779315948\n",
      "The representation loss after processing this batch is:  0.003564789891242981\n",
      "\n",
      "The classification loss after processing this batch is:  0.16069689393043518\n",
      "The representation loss after processing this batch is:  0.003433443605899811\n",
      "\n",
      "The classification loss after processing this batch is:  0.13279156386852264\n",
      "The representation loss after processing this batch is:  0.004044808447360992\n",
      "\n",
      "The classification loss after processing this batch is:  0.3166502118110657\n",
      "The representation loss after processing this batch is:  0.0033791586756706238\n",
      "\n",
      "The classification loss after processing this batch is:  0.32462042570114136\n",
      "The representation loss after processing this batch is:  0.003265000879764557\n",
      "\n",
      "The classification loss after processing this batch is:  0.1904001235961914\n",
      "The representation loss after processing this batch is:  0.003863781690597534\n",
      "\n",
      "The classification loss after processing this batch is:  0.22053085267543793\n",
      "The representation loss after processing this batch is:  0.0035218149423599243\n",
      "\n",
      "The classification loss after processing this batch is:  0.25707560777664185\n",
      "The representation loss after processing this batch is:  0.003643222153186798\n",
      "\n",
      "The classification loss after processing this batch is:  0.11637808382511139\n",
      "The representation loss after processing this batch is:  0.003720901906490326\n",
      "\n",
      "The classification loss after processing this batch is:  0.31841087341308594\n",
      "The representation loss after processing this batch is:  0.0036947280168533325\n",
      "\n",
      "The classification loss after processing this batch is:  0.2181200236082077\n",
      "The representation loss after processing this batch is:  0.003401517868041992\n",
      "\n",
      "The classification loss after processing this batch is:  0.34612905979156494\n",
      "The representation loss after processing this batch is:  0.0034332573413848877\n",
      "\n",
      "The classification loss after processing this batch is:  0.29155102372169495\n",
      "The representation loss after processing this batch is:  0.004114478826522827\n",
      "\n",
      "The classification loss after processing this batch is:  0.3380109965801239\n",
      "The representation loss after processing this batch is:  0.0033292099833488464\n",
      "\n",
      "The classification loss after processing this batch is:  0.12617066502571106\n",
      "The representation loss after processing this batch is:  0.0031799674034118652\n",
      "\n",
      "The classification loss after processing this batch is:  0.13866952061653137\n",
      "The representation loss after processing this batch is:  0.0033490732312202454\n",
      "\n",
      "The classification loss after processing this batch is:  0.2507520914077759\n",
      "The representation loss after processing this batch is:  0.0037399232387542725\n",
      "\n",
      "The classification loss after processing this batch is:  0.14015483856201172\n",
      "The representation loss after processing this batch is:  0.004168674349784851\n",
      "\n",
      "The classification loss after processing this batch is:  0.30711233615875244\n",
      "The representation loss after processing this batch is:  0.0037526488304138184\n",
      "\n",
      "The classification loss after processing this batch is:  0.17599137127399445\n",
      "The representation loss after processing this batch is:  0.0036333277821540833\n",
      "\n",
      "The classification loss after processing this batch is:  0.2665400803089142\n",
      "The representation loss after processing this batch is:  0.0038163140416145325\n",
      "\n",
      "The classification loss after processing this batch is:  0.2946699559688568\n",
      "The representation loss after processing this batch is:  0.003595709800720215\n",
      "\n",
      "The classification loss after processing this batch is:  0.24774105846881866\n",
      "The representation loss after processing this batch is:  0.0034365206956863403\n",
      "\n",
      "The classification loss after processing this batch is:  0.2244781106710434\n",
      "The representation loss after processing this batch is:  0.003986328840255737\n",
      "\n",
      "The classification loss after processing this batch is:  0.25863364338874817\n",
      "The representation loss after processing this batch is:  0.0038855895400047302\n",
      "\n",
      "The classification loss after processing this batch is:  0.2905481457710266\n",
      "The representation loss after processing this batch is:  0.0036050304770469666\n",
      "\n",
      "The classification loss after processing this batch is:  0.3767954111099243\n",
      "The representation loss after processing this batch is:  0.004191242158412933\n",
      "\n",
      "The classification loss after processing this batch is:  0.4309346377849579\n",
      "The representation loss after processing this batch is:  0.00397057831287384\n",
      "\n",
      "The classification loss after processing this batch is:  0.3367067575454712\n",
      "The representation loss after processing this batch is:  0.00315132737159729\n",
      "\n",
      "The classification loss after processing this batch is:  0.21219474077224731\n",
      "The representation loss after processing this batch is:  0.003403604030609131\n",
      "\n",
      "The classification loss after processing this batch is:  0.19053424894809723\n",
      "The representation loss after processing this batch is:  0.0033154338598251343\n",
      "\n",
      "The classification loss after processing this batch is:  0.18171390891075134\n",
      "The representation loss after processing this batch is:  0.0036648735404014587\n",
      "\n",
      "The classification loss after processing this batch is:  0.17906062304973602\n",
      "The representation loss after processing this batch is:  0.003771774470806122\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2618565261363983\n",
      "The representation loss after processing this batch is:  0.0029413923621177673\n",
      "\n",
      "The classification loss after processing this batch is:  0.20245574414730072\n",
      "The representation loss after processing this batch is:  0.0039008408784866333\n",
      "\n",
      "The classification loss after processing this batch is:  0.24475394189357758\n",
      "The representation loss after processing this batch is:  0.0038340911269187927\n",
      "\n",
      "The classification loss after processing this batch is:  0.17030054330825806\n",
      "The representation loss after processing this batch is:  0.0036236420273780823\n",
      "\n",
      "The classification loss after processing this batch is:  0.2712622284889221\n",
      "The representation loss after processing this batch is:  0.003422968089580536\n",
      "\n",
      "The classification loss after processing this batch is:  0.21329504251480103\n",
      "The representation loss after processing this batch is:  0.0036314204335212708\n",
      "\n",
      "The classification loss after processing this batch is:  0.28983262181282043\n",
      "The representation loss after processing this batch is:  0.003231830894947052\n",
      "\n",
      "The classification loss after processing this batch is:  0.2557894289493561\n",
      "The representation loss after processing this batch is:  0.003988109529018402\n",
      "\n",
      "The classification loss after processing this batch is:  0.22648270428180695\n",
      "The representation loss after processing this batch is:  0.004084110260009766\n",
      "\n",
      "The classification loss after processing this batch is:  0.21644645929336548\n",
      "The representation loss after processing this batch is:  0.0037541985511779785\n",
      "\n",
      "The classification loss after processing this batch is:  0.31276044249534607\n",
      "The representation loss after processing this batch is:  0.003992743790149689\n",
      "\n",
      "The classification loss after processing this batch is:  0.1729624718427658\n",
      "The representation loss after processing this batch is:  0.003539569675922394\n",
      "\n",
      "The classification loss after processing this batch is:  0.1523120254278183\n",
      "The representation loss after processing this batch is:  0.003331996500492096\n",
      "\n",
      "The classification loss after processing this batch is:  0.22965770959854126\n",
      "The representation loss after processing this batch is:  0.0036017373204231262\n",
      "\n",
      "The classification loss after processing this batch is:  0.20275256037712097\n",
      "The representation loss after processing this batch is:  0.003025956451892853\n",
      "\n",
      "The classification loss after processing this batch is:  0.3040677011013031\n",
      "The representation loss after processing this batch is:  0.003404095768928528\n",
      "\n",
      "The classification loss after processing this batch is:  0.2860832214355469\n",
      "The representation loss after processing this batch is:  0.004042871296405792\n",
      "\n",
      "The classification loss after processing this batch is:  0.23318110406398773\n",
      "The representation loss after processing this batch is:  0.0044716596603393555\n",
      "\n",
      "The classification loss after processing this batch is:  0.1871420294046402\n",
      "The representation loss after processing this batch is:  0.0036784932017326355\n",
      "\n",
      "The classification loss after processing this batch is:  0.2097708135843277\n",
      "The representation loss after processing this batch is:  0.0036789774894714355\n",
      "\n",
      "The classification loss after processing this batch is:  0.3599920868873596\n",
      "The representation loss after processing this batch is:  0.0036517679691314697\n",
      "\n",
      "The classification loss after processing this batch is:  0.12859362363815308\n",
      "The representation loss after processing this batch is:  0.004037164151668549\n",
      "\n",
      "The classification loss after processing this batch is:  0.19388103485107422\n",
      "The representation loss after processing this batch is:  0.004021093249320984\n",
      "\n",
      "The classification loss after processing this batch is:  0.24654318392276764\n",
      "The representation loss after processing this batch is:  0.0034590736031532288\n",
      "\n",
      "The classification loss after processing this batch is:  0.4423314034938812\n",
      "The representation loss after processing this batch is:  0.0041050538420677185\n",
      "\n",
      "The classification loss after processing this batch is:  0.18795619904994965\n",
      "The representation loss after processing this batch is:  0.003273382782936096\n",
      "\n",
      "The classification loss after processing this batch is:  0.2615509331226349\n",
      "The representation loss after processing this batch is:  0.00320492684841156\n",
      "\n",
      "The classification loss after processing this batch is:  0.170623779296875\n",
      "The representation loss after processing this batch is:  0.0035699084401130676\n",
      "\n",
      "The classification loss after processing this batch is:  0.1312897801399231\n",
      "The representation loss after processing this batch is:  0.00348750501871109\n",
      "\n",
      "The classification loss after processing this batch is:  0.23480600118637085\n",
      "The representation loss after processing this batch is:  0.004205226898193359\n",
      "\n",
      "The classification loss after processing this batch is:  0.1932552009820938\n",
      "The representation loss after processing this batch is:  0.004821300506591797\n",
      "\n",
      "The classification loss after processing this batch is:  0.1370045691728592\n",
      "The representation loss after processing this batch is:  0.00433368980884552\n",
      "\n",
      "The classification loss after processing this batch is:  0.16762828826904297\n",
      "The representation loss after processing this batch is:  0.0035704076290130615\n",
      "\n",
      "The classification loss after processing this batch is:  0.28200557827949524\n",
      "The representation loss after processing this batch is:  0.00366944819688797\n",
      "\n",
      "The classification loss after processing this batch is:  0.25285306572914124\n",
      "The representation loss after processing this batch is:  0.003552667796611786\n",
      "\n",
      "The classification loss after processing this batch is:  0.17491133511066437\n",
      "The representation loss after processing this batch is:  0.0033728182315826416\n",
      "\n",
      "The classification loss after processing this batch is:  0.23411886394023895\n",
      "The representation loss after processing this batch is:  0.0036525577306747437\n",
      "\n",
      "The classification loss after processing this batch is:  0.29373231530189514\n",
      "The representation loss after processing this batch is:  0.003346174955368042\n",
      "\n",
      "The classification loss after processing this batch is:  0.3145957589149475\n",
      "The representation loss after processing this batch is:  0.0036660507321357727\n",
      "\n",
      "The classification loss after processing this batch is:  0.290191650390625\n",
      "The representation loss after processing this batch is:  0.003235727548599243\n",
      "\n",
      "The classification loss after processing this batch is:  0.2693788409233093\n",
      "The representation loss after processing this batch is:  0.0037001073360443115\n",
      "\n",
      "The classification loss after processing this batch is:  0.42676645517349243\n",
      "The representation loss after processing this batch is:  0.00348605215549469\n",
      "\n",
      "The classification loss after processing this batch is:  0.19412797689437866\n",
      "The representation loss after processing this batch is:  0.0037574470043182373\n",
      "\n",
      "The classification loss after processing this batch is:  0.1692640632390976\n",
      "The representation loss after processing this batch is:  0.003759227693080902\n",
      "\n",
      "The classification loss after processing this batch is:  0.16519390046596527\n",
      "The representation loss after processing this batch is:  0.00324171781539917\n",
      "\n",
      "The classification loss after processing this batch is:  0.17075467109680176\n",
      "The representation loss after processing this batch is:  0.0033077821135520935\n",
      "\n",
      "The classification loss after processing this batch is:  0.2669491171836853\n",
      "The representation loss after processing this batch is:  0.0036909878253936768\n",
      "\n",
      "The classification loss after processing this batch is:  0.191482812166214\n",
      "The representation loss after processing this batch is:  0.004066206514835358\n",
      "\n",
      "The classification loss after processing this batch is:  0.12519125640392303\n",
      "The representation loss after processing this batch is:  0.003775201737880707\n",
      "\n",
      "The classification loss after processing this batch is:  0.12464892864227295\n",
      "The representation loss after processing this batch is:  0.0038936957716941833\n",
      "\n",
      "The classification loss after processing this batch is:  0.13038675487041473\n",
      "The representation loss after processing this batch is:  0.003993265330791473\n",
      "\n",
      "The classification loss after processing this batch is:  0.175132617354393\n",
      "The representation loss after processing this batch is:  0.00454770028591156\n",
      "\n",
      "The classification loss after processing this batch is:  0.2285638004541397\n",
      "The representation loss after processing this batch is:  0.0037549957633018494\n",
      "\n",
      "The classification loss after processing this batch is:  0.15277238190174103\n",
      "The representation loss after processing this batch is:  0.003544352948665619\n",
      "\n",
      "The classification loss after processing this batch is:  0.11909946799278259\n",
      "The representation loss after processing this batch is:  0.0040545836091041565\n",
      "\n",
      "The classification loss after processing this batch is:  0.16661697626113892\n",
      "The representation loss after processing this batch is:  0.004106014966964722\n",
      "\n",
      "The classification loss after processing this batch is:  0.14057204127311707\n",
      "The representation loss after processing this batch is:  0.004972189664840698\n",
      "\n",
      "The classification loss after processing this batch is:  0.08258874714374542\n",
      "The representation loss after processing this batch is:  0.004946917295455933\n",
      "\n",
      "The classification loss after processing this batch is:  0.11137504130601883\n",
      "The representation loss after processing this batch is:  0.004589833319187164\n",
      "\n",
      "The classification loss after processing this batch is:  0.26162007451057434\n",
      "The representation loss after processing this batch is:  0.003761887550354004\n",
      "\n",
      "The classification loss after processing this batch is:  0.12812598049640656\n",
      "The representation loss after processing this batch is:  0.0042371004819869995\n",
      "\n",
      "The classification loss after processing this batch is:  0.06425145268440247\n",
      "The representation loss after processing this batch is:  0.0035267919301986694\n",
      "\n",
      "The classification loss after processing this batch is:  0.13276246190071106\n",
      "The representation loss after processing this batch is:  0.004104964435100555\n",
      "\n",
      "The classification loss after processing this batch is:  0.12143198400735855\n",
      "The representation loss after processing this batch is:  0.004163205623626709\n",
      "\n",
      "The classification loss after processing this batch is:  0.09218395501375198\n",
      "The representation loss after processing this batch is:  0.003494858741760254\n",
      "\n",
      "The classification loss after processing this batch is:  0.09868515282869339\n",
      "The representation loss after processing this batch is:  0.004243083298206329\n",
      "\n",
      "The classification loss after processing this batch is:  0.09332117438316345\n",
      "The representation loss after processing this batch is:  0.004647605121135712\n",
      "\n",
      "The classification loss after processing this batch is:  0.4321273863315582\n",
      "The representation loss after processing this batch is:  0.0049004629254341125\n",
      "\n",
      "The classification loss after processing this batch is:  0.4778214693069458\n",
      "The representation loss after processing this batch is:  0.004450082778930664\n",
      "\n",
      "The classification loss after processing this batch is:  0.3451211750507355\n",
      "The representation loss after processing this batch is:  0.004712224006652832\n",
      "\n",
      "The classification loss after processing this batch is:  0.12772271037101746\n",
      "The representation loss after processing this batch is:  0.0037060976028442383\n",
      "\n",
      "The classification loss after processing this batch is:  0.09797313809394836\n",
      "The representation loss after processing this batch is:  0.004645034670829773\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.09311224520206451\n",
      "The representation loss after processing this batch is:  0.0030804798007011414\n",
      "\n",
      "The classification loss after processing this batch is:  0.17313037812709808\n",
      "The representation loss after processing this batch is:  0.00305803120136261\n",
      "\n",
      "The classification loss after processing this batch is:  0.45796194672584534\n",
      "The representation loss after processing this batch is:  0.0036351680755615234\n",
      "\n",
      "The classification loss after processing this batch is:  0.15185880661010742\n",
      "The representation loss after processing this batch is:  0.0036932453513145447\n",
      "\n",
      "The classification loss after processing this batch is:  0.10067962855100632\n",
      "The representation loss after processing this batch is:  0.004327163100242615\n",
      "\n",
      "The classification loss after processing this batch is:  0.1554676741361618\n",
      "The representation loss after processing this batch is:  0.0042533427476882935\n",
      "\n",
      "The classification loss after processing this batch is:  0.12872202694416046\n",
      "The representation loss after processing this batch is:  0.005480341613292694\n",
      "\n",
      "The classification loss after processing this batch is:  0.2372964322566986\n",
      "The representation loss after processing this batch is:  0.003595776855945587\n",
      "\n",
      "The classification loss after processing this batch is:  0.13939371705055237\n",
      "The representation loss after processing this batch is:  0.0033233091235160828\n",
      "\n",
      "The classification loss after processing this batch is:  0.23771347105503082\n",
      "The representation loss after processing this batch is:  0.0033276155591011047\n",
      "\n",
      "The classification loss after processing this batch is:  0.18317320942878723\n",
      "The representation loss after processing this batch is:  0.0033641867339611053\n",
      "\n",
      "The classification loss after processing this batch is:  0.25019949674606323\n",
      "The representation loss after processing this batch is:  0.0030731260776519775\n",
      "\n",
      "The classification loss after processing this batch is:  0.16079489886760712\n",
      "The representation loss after processing this batch is:  0.00370585173368454\n",
      "\n",
      "The classification loss after processing this batch is:  0.23180335760116577\n",
      "The representation loss after processing this batch is:  0.0042406171560287476\n",
      "\n",
      "The classification loss after processing this batch is:  0.1929258406162262\n",
      "The representation loss after processing this batch is:  0.0034031495451927185\n",
      "\n",
      "The classification loss after processing this batch is:  0.2545868158340454\n",
      "The representation loss after processing this batch is:  0.003512471914291382\n",
      "\n",
      "The classification loss after processing this batch is:  0.23945783078670502\n",
      "The representation loss after processing this batch is:  0.003479205071926117\n",
      "\n",
      "The classification loss after processing this batch is:  0.31522464752197266\n",
      "The representation loss after processing this batch is:  0.003425832837820053\n",
      "\n",
      "The classification loss after processing this batch is:  0.1721372902393341\n",
      "The representation loss after processing this batch is:  0.003181636333465576\n",
      "\n",
      "The classification loss after processing this batch is:  0.2687673568725586\n",
      "The representation loss after processing this batch is:  0.003586098551750183\n",
      "\n",
      "The classification loss after processing this batch is:  0.14419743418693542\n",
      "The representation loss after processing this batch is:  0.0030871257185935974\n",
      "\n",
      "The classification loss after processing this batch is:  0.4709170162677765\n",
      "The representation loss after processing this batch is:  0.0035477466881275177\n",
      "\n",
      "The classification loss after processing this batch is:  0.2682233154773712\n",
      "The representation loss after processing this batch is:  0.0034173056483268738\n",
      "\n",
      "The classification loss after processing this batch is:  0.2667778730392456\n",
      "The representation loss after processing this batch is:  0.0036475397646427155\n",
      "\n",
      "The classification loss after processing this batch is:  0.40444090962409973\n",
      "The representation loss after processing this batch is:  0.004496544599533081\n",
      "\n",
      "The classification loss after processing this batch is:  0.32813647389411926\n",
      "The representation loss after processing this batch is:  0.003714829683303833\n",
      "\n",
      "The classification loss after processing this batch is:  0.1448686420917511\n",
      "The representation loss after processing this batch is:  0.004149500280618668\n",
      "\n",
      "The classification loss after processing this batch is:  0.39140284061431885\n",
      "The representation loss after processing this batch is:  0.004655018448829651\n",
      "\n",
      "The classification loss after processing this batch is:  0.2926662862300873\n",
      "The representation loss after processing this batch is:  0.003803566098213196\n",
      "\n",
      "The classification loss after processing this batch is:  0.4179137945175171\n",
      "The representation loss after processing this batch is:  0.0034771114587783813\n",
      "\n",
      "The classification loss after processing this batch is:  0.20789499580860138\n",
      "The representation loss after processing this batch is:  0.002979312092065811\n",
      "\n",
      "The classification loss after processing this batch is:  0.16322952508926392\n",
      "The representation loss after processing this batch is:  0.003587000072002411\n",
      "\n",
      "The classification loss after processing this batch is:  0.19287624955177307\n",
      "The representation loss after processing this batch is:  0.0033604279160499573\n",
      "\n",
      "The classification loss after processing this batch is:  0.26959341764450073\n",
      "The representation loss after processing this batch is:  0.003235429525375366\n",
      "\n",
      "The classification loss after processing this batch is:  0.18790750205516815\n",
      "The representation loss after processing this batch is:  0.0031967461109161377\n",
      "\n",
      "The classification loss after processing this batch is:  0.13770240545272827\n",
      "The representation loss after processing this batch is:  0.003193005919456482\n",
      "\n",
      "The classification loss after processing this batch is:  0.1058826595544815\n",
      "The representation loss after processing this batch is:  0.003859885036945343\n",
      "\n",
      "The classification loss after processing this batch is:  0.15046657621860504\n",
      "The representation loss after processing this batch is:  0.0032559633255004883\n",
      "\n",
      "The classification loss after processing this batch is:  0.15694785118103027\n",
      "The representation loss after processing this batch is:  0.003702916204929352\n",
      "\n",
      "The classification loss after processing this batch is:  0.2700182795524597\n",
      "The representation loss after processing this batch is:  0.003631085157394409\n",
      "\n",
      "The classification loss after processing this batch is:  0.23067449033260345\n",
      "The representation loss after processing this batch is:  0.004110418260097504\n",
      "\n",
      "The classification loss after processing this batch is:  0.18932701647281647\n",
      "The representation loss after processing this batch is:  0.0037326589226722717\n",
      "\n",
      "The classification loss after processing this batch is:  0.1280127465724945\n",
      "The representation loss after processing this batch is:  0.003493092954158783\n",
      "\n",
      "The classification loss after processing this batch is:  0.179588183760643\n",
      "The representation loss after processing this batch is:  0.0037376731634140015\n",
      "\n",
      "The classification loss after processing this batch is:  0.23296381533145905\n",
      "The representation loss after processing this batch is:  0.0035431236028671265\n",
      "\n",
      "The classification loss after processing this batch is:  0.11937462538480759\n",
      "The representation loss after processing this batch is:  0.0038326308131217957\n",
      "\n",
      "The classification loss after processing this batch is:  0.1932552009820938\n",
      "The representation loss after processing this batch is:  0.0034811124205589294\n",
      "\n",
      "The classification loss after processing this batch is:  0.31766512989997864\n",
      "The representation loss after processing this batch is:  0.004121355712413788\n",
      "\n",
      "The classification loss after processing this batch is:  0.18536879122257233\n",
      "The representation loss after processing this batch is:  0.003348805010318756\n",
      "\n",
      "The classification loss after processing this batch is:  0.21921347081661224\n",
      "The representation loss after processing this batch is:  0.00343182310461998\n",
      "\n",
      "The classification loss after processing this batch is:  0.206833153963089\n",
      "The representation loss after processing this batch is:  0.0034211575984954834\n",
      "\n",
      "The classification loss after processing this batch is:  0.18791097402572632\n",
      "The representation loss after processing this batch is:  0.0032232701778411865\n",
      "\n",
      "The classification loss after processing this batch is:  0.22903195023536682\n",
      "The representation loss after processing this batch is:  0.003109566867351532\n",
      "\n",
      "The classification loss after processing this batch is:  0.26057374477386475\n",
      "The representation loss after processing this batch is:  0.003697015345096588\n",
      "\n",
      "The classification loss after processing this batch is:  0.12870781123638153\n",
      "The representation loss after processing this batch is:  0.0033978447318077087\n",
      "\n",
      "The classification loss after processing this batch is:  0.24417616426944733\n",
      "The representation loss after processing this batch is:  0.0032955408096313477\n",
      "\n",
      "The classification loss after processing this batch is:  0.1945534646511078\n",
      "The representation loss after processing this batch is:  0.0035039037466049194\n",
      "\n",
      "The classification loss after processing this batch is:  0.2179456502199173\n",
      "The representation loss after processing this batch is:  0.0033519379794597626\n",
      "\n",
      "The classification loss after processing this batch is:  0.21636123955249786\n",
      "The representation loss after processing this batch is:  0.0036718323826789856\n",
      "\n",
      "The classification loss after processing this batch is:  0.18933282792568207\n",
      "The representation loss after processing this batch is:  0.003634430468082428\n",
      "\n",
      "The classification loss after processing this batch is:  0.17455345392227173\n",
      "The representation loss after processing this batch is:  0.004027031362056732\n",
      "\n",
      "The classification loss after processing this batch is:  0.2061251848936081\n",
      "The representation loss after processing this batch is:  0.0038145557045936584\n",
      "\n",
      "The classification loss after processing this batch is:  0.2288546860218048\n",
      "The representation loss after processing this batch is:  0.0033944323658943176\n",
      "\n",
      "The classification loss after processing this batch is:  0.2362157702445984\n",
      "The representation loss after processing this batch is:  0.0032214224338531494\n",
      "\n",
      "The classification loss after processing this batch is:  0.15399856865406036\n",
      "The representation loss after processing this batch is:  0.003853633999824524\n",
      "\n",
      "The classification loss after processing this batch is:  0.24213165044784546\n",
      "The representation loss after processing this batch is:  0.0038285404443740845\n",
      "\n",
      "The classification loss after processing this batch is:  0.14026600122451782\n",
      "The representation loss after processing this batch is:  0.003286421298980713\n",
      "\n",
      "The classification loss after processing this batch is:  0.14813044667243958\n",
      "The representation loss after processing this batch is:  0.0033653415739536285\n",
      "\n",
      "The classification loss after processing this batch is:  0.24329982697963715\n",
      "The representation loss after processing this batch is:  0.0032104700803756714\n",
      "\n",
      "The classification loss after processing this batch is:  0.24012069404125214\n",
      "The representation loss after processing this batch is:  0.003340400755405426\n",
      "\n",
      "The classification loss after processing this batch is:  0.18636462092399597\n",
      "The representation loss after processing this batch is:  0.0033457353711128235\n",
      "\n",
      "The classification loss after processing this batch is:  0.20088644325733185\n",
      "The representation loss after processing this batch is:  0.003220006823539734\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.18441197276115417\n",
      "The representation loss after processing this batch is:  0.0032200589776039124\n",
      "\n",
      "The classification loss after processing this batch is:  0.26057830452919006\n",
      "The representation loss after processing this batch is:  0.003911033272743225\n",
      "\n",
      "The classification loss after processing this batch is:  0.24766260385513306\n",
      "The representation loss after processing this batch is:  0.0029482170939445496\n",
      "\n",
      "The classification loss after processing this batch is:  0.12445354461669922\n",
      "The representation loss after processing this batch is:  0.003308728337287903\n",
      "\n",
      "The classification loss after processing this batch is:  0.33186060190200806\n",
      "The representation loss after processing this batch is:  0.003521241247653961\n",
      "\n",
      "The classification loss after processing this batch is:  0.20131660997867584\n",
      "The representation loss after processing this batch is:  0.003657262772321701\n",
      "\n",
      "The classification loss after processing this batch is:  0.23201636970043182\n",
      "The representation loss after processing this batch is:  0.003654859960079193\n",
      "\n",
      "The classification loss after processing this batch is:  0.21256017684936523\n",
      "The representation loss after processing this batch is:  0.0029490068554878235\n",
      "\n",
      "The classification loss after processing this batch is:  0.16076864302158356\n",
      "The representation loss after processing this batch is:  0.0033095404505729675\n",
      "\n",
      "The classification loss after processing this batch is:  0.18439814448356628\n",
      "The representation loss after processing this batch is:  0.0032502412796020508\n",
      "\n",
      "The classification loss after processing this batch is:  0.2354671210050583\n",
      "The representation loss after processing this batch is:  0.0032059773802757263\n",
      "\n",
      "The classification loss after processing this batch is:  0.18283894658088684\n",
      "The representation loss after processing this batch is:  0.0032430291175842285\n",
      "\n",
      "The classification loss after processing this batch is:  0.3671720325946808\n",
      "The representation loss after processing this batch is:  0.0031732767820358276\n",
      "\n",
      "The classification loss after processing this batch is:  0.2225511223077774\n",
      "The representation loss after processing this batch is:  0.0030801966786384583\n",
      "\n",
      "The classification loss after processing this batch is:  0.17266099154949188\n",
      "The representation loss after processing this batch is:  0.0038747638463974\n",
      "\n",
      "The classification loss after processing this batch is:  0.2695308327674866\n",
      "The representation loss after processing this batch is:  0.0034850984811782837\n",
      "\n",
      "The classification loss after processing this batch is:  0.20503021776676178\n",
      "The representation loss after processing this batch is:  0.003670409321784973\n",
      "\n",
      "The classification loss after processing this batch is:  0.3695557713508606\n",
      "The representation loss after processing this batch is:  0.0037811696529388428\n",
      "\n",
      "The classification loss after processing this batch is:  0.20734195411205292\n",
      "The representation loss after processing this batch is:  0.00369291752576828\n",
      "\n",
      "The classification loss after processing this batch is:  0.24130266904830933\n",
      "The representation loss after processing this batch is:  0.0031290650367736816\n",
      "\n",
      "The classification loss after processing this batch is:  0.4197206199169159\n",
      "The representation loss after processing this batch is:  0.0034062787890434265\n",
      "\n",
      "The classification loss after processing this batch is:  0.2568429112434387\n",
      "The representation loss after processing this batch is:  0.0032874196767807007\n",
      "\n",
      "The classification loss after processing this batch is:  0.15989753603935242\n",
      "The representation loss after processing this batch is:  0.0036401450634002686\n",
      "\n",
      "The classification loss after processing this batch is:  0.301260381937027\n",
      "The representation loss after processing this batch is:  0.0031766630709171295\n",
      "\n",
      "The classification loss after processing this batch is:  0.27376028895378113\n",
      "The representation loss after processing this batch is:  0.0029354989528656006\n",
      "\n",
      "The classification loss after processing this batch is:  0.21202455461025238\n",
      "The representation loss after processing this batch is:  0.0034966692328453064\n",
      "\n",
      "The classification loss after processing this batch is:  0.15595334768295288\n",
      "The representation loss after processing this batch is:  0.0032162144780158997\n",
      "\n",
      "The classification loss after processing this batch is:  0.234378382563591\n",
      "The representation loss after processing this batch is:  0.003103204071521759\n",
      "\n",
      "The classification loss after processing this batch is:  0.26202255487442017\n",
      "The representation loss after processing this batch is:  0.003288544714450836\n",
      "\n",
      "The classification loss after processing this batch is:  0.21126359701156616\n",
      "The representation loss after processing this batch is:  0.0037872344255447388\n",
      "\n",
      "The classification loss after processing this batch is:  0.30202826857566833\n",
      "The representation loss after processing this batch is:  0.003195144236087799\n",
      "\n",
      "The classification loss after processing this batch is:  0.25175222754478455\n",
      "The representation loss after processing this batch is:  0.0037136003375053406\n",
      "\n",
      "The classification loss after processing this batch is:  0.2806241810321808\n",
      "The representation loss after processing this batch is:  0.0039363279938697815\n",
      "\n",
      "The classification loss after processing this batch is:  0.16613207757472992\n",
      "The representation loss after processing this batch is:  0.004142992198467255\n",
      "\n",
      "The classification loss after processing this batch is:  0.1757814884185791\n",
      "The representation loss after processing this batch is:  0.0032363049685955048\n",
      "\n",
      "The classification loss after processing this batch is:  0.12189594656229019\n",
      "The representation loss after processing this batch is:  0.0035494863986968994\n",
      "\n",
      "The classification loss after processing this batch is:  0.21214519441127777\n",
      "The representation loss after processing this batch is:  0.003569655120372772\n",
      "\n",
      "The classification loss after processing this batch is:  0.14872077107429504\n",
      "The representation loss after processing this batch is:  0.0034471675753593445\n",
      "\n",
      "The classification loss after processing this batch is:  0.37686601281166077\n",
      "The representation loss after processing this batch is:  0.003599688410758972\n",
      "\n",
      "The classification loss after processing this batch is:  0.39289724826812744\n",
      "The representation loss after processing this batch is:  0.0037738755345344543\n",
      "\n",
      "The classification loss after processing this batch is:  0.20582975447177887\n",
      "The representation loss after processing this batch is:  0.0035156607627868652\n",
      "\n",
      "The classification loss after processing this batch is:  0.17167586088180542\n",
      "The representation loss after processing this batch is:  0.0037844479084014893\n",
      "\n",
      "The classification loss after processing this batch is:  0.21023713052272797\n",
      "The representation loss after processing this batch is:  0.0029665492475032806\n",
      "\n",
      "The classification loss after processing this batch is:  0.14144521951675415\n",
      "The representation loss after processing this batch is:  0.004053644835948944\n",
      "\n",
      "The classification loss after processing this batch is:  0.12356662005186081\n",
      "The representation loss after processing this batch is:  0.0032993629574775696\n",
      "\n",
      "The classification loss after processing this batch is:  0.25749266147613525\n",
      "The representation loss after processing this batch is:  0.0031189173460006714\n",
      "\n",
      "The classification loss after processing this batch is:  0.18617597222328186\n",
      "The representation loss after processing this batch is:  0.004774957895278931\n",
      "\n",
      "The classification loss after processing this batch is:  0.1621493697166443\n",
      "The representation loss after processing this batch is:  0.003580912947654724\n",
      "\n",
      "The classification loss after processing this batch is:  0.3502739667892456\n",
      "The representation loss after processing this batch is:  0.004596292972564697\n",
      "\n",
      "The classification loss after processing this batch is:  0.3183239996433258\n",
      "The representation loss after processing this batch is:  0.0028109028935432434\n",
      "\n",
      "The classification loss after processing this batch is:  0.269307017326355\n",
      "The representation loss after processing this batch is:  0.0037949606776237488\n",
      "\n",
      "The classification loss after processing this batch is:  0.3337027430534363\n",
      "The representation loss after processing this batch is:  0.0032239630818367004\n",
      "\n",
      "The classification loss after processing this batch is:  0.24313774704933167\n",
      "The representation loss after processing this batch is:  0.0030609741806983948\n",
      "\n",
      "The classification loss after processing this batch is:  0.14446376264095306\n",
      "The representation loss after processing this batch is:  0.0035818517208099365\n",
      "\n",
      "The classification loss after processing this batch is:  0.29247063398361206\n",
      "The representation loss after processing this batch is:  0.0035050436854362488\n",
      "\n",
      "The classification loss after processing this batch is:  0.47619640827178955\n",
      "The representation loss after processing this batch is:  0.004581660032272339\n",
      "\n",
      "The classification loss after processing this batch is:  0.30277976393699646\n",
      "The representation loss after processing this batch is:  0.004788387566804886\n",
      "\n",
      "The classification loss after processing this batch is:  0.218123659491539\n",
      "The representation loss after processing this batch is:  0.004551216959953308\n",
      "\n",
      "The classification loss after processing this batch is:  0.22596709430217743\n",
      "The representation loss after processing this batch is:  0.0038291290402412415\n",
      "\n",
      "The classification loss after processing this batch is:  0.17239700257778168\n",
      "The representation loss after processing this batch is:  0.004057049751281738\n",
      "\n",
      "The classification loss after processing this batch is:  0.22264601290225983\n",
      "The representation loss after processing this batch is:  0.003412194550037384\n",
      "\n",
      "The classification loss after processing this batch is:  0.16124515235424042\n",
      "The representation loss after processing this batch is:  0.0037936195731163025\n",
      "\n",
      "The classification loss after processing this batch is:  0.24315659701824188\n",
      "The representation loss after processing this batch is:  0.003403790295124054\n",
      "\n",
      "The classification loss after processing this batch is:  0.20652557909488678\n",
      "The representation loss after processing this batch is:  0.003483019769191742\n",
      "\n",
      "The classification loss after processing this batch is:  0.3479960262775421\n",
      "The representation loss after processing this batch is:  0.003530345857143402\n",
      "\n",
      "The classification loss after processing this batch is:  0.19365015625953674\n",
      "The representation loss after processing this batch is:  0.0034218207001686096\n",
      "\n",
      "The classification loss after processing this batch is:  0.20434612035751343\n",
      "The representation loss after processing this batch is:  0.0029604583978652954\n",
      "\n",
      "The classification loss after processing this batch is:  0.22508026659488678\n",
      "The representation loss after processing this batch is:  0.0029590874910354614\n",
      "\n",
      "The classification loss after processing this batch is:  0.2253570258617401\n",
      "The representation loss after processing this batch is:  0.0034892410039901733\n",
      "\n",
      "The classification loss after processing this batch is:  0.16277456283569336\n",
      "The representation loss after processing this batch is:  0.0034942030906677246\n",
      "\n",
      "The classification loss after processing this batch is:  0.2621175944805145\n",
      "The representation loss after processing this batch is:  0.0031951069831848145\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2768785059452057\n",
      "The representation loss after processing this batch is:  0.0031182169914245605\n",
      "\n",
      "The classification loss after processing this batch is:  0.32267239689826965\n",
      "The representation loss after processing this batch is:  0.0031978413462638855\n",
      "\n",
      "The classification loss after processing this batch is:  0.2310318946838379\n",
      "The representation loss after processing this batch is:  0.0031481608748435974\n",
      "\n",
      "The classification loss after processing this batch is:  0.23694077134132385\n",
      "The representation loss after processing this batch is:  0.0035320445895195007\n",
      "\n",
      "The classification loss after processing this batch is:  0.30695581436157227\n",
      "The representation loss after processing this batch is:  0.003403604030609131\n",
      "\n",
      "The classification loss after processing this batch is:  0.25742101669311523\n",
      "The representation loss after processing this batch is:  0.003273308277130127\n",
      "\n",
      "The classification loss after processing this batch is:  0.14954446256160736\n",
      "The representation loss after processing this batch is:  0.0037383437156677246\n",
      "\n",
      "The classification loss after processing this batch is:  0.24447740614414215\n",
      "The representation loss after processing this batch is:  0.003696642816066742\n",
      "\n",
      "The classification loss after processing this batch is:  0.40498730540275574\n",
      "The representation loss after processing this batch is:  0.0034658461809158325\n",
      "\n",
      "The classification loss after processing this batch is:  0.33199751377105713\n",
      "The representation loss after processing this batch is:  0.0033682771027088165\n",
      "\n",
      "The classification loss after processing this batch is:  0.3321664035320282\n",
      "The representation loss after processing this batch is:  0.0036781206727027893\n",
      "\n",
      "The classification loss after processing this batch is:  0.4601958692073822\n",
      "The representation loss after processing this batch is:  0.003225848078727722\n",
      "\n",
      "The classification loss after processing this batch is:  0.3331795334815979\n",
      "The representation loss after processing this batch is:  0.0032241418957710266\n",
      "\n",
      "The classification loss after processing this batch is:  0.15589171648025513\n",
      "The representation loss after processing this batch is:  0.0031123608350753784\n",
      "\n",
      "The classification loss after processing this batch is:  0.15305845439434052\n",
      "The representation loss after processing this batch is:  0.0034819766879081726\n",
      "\n",
      "The classification loss after processing this batch is:  0.19325946271419525\n",
      "The representation loss after processing this batch is:  0.0041017085313797\n",
      "\n",
      "The classification loss after processing this batch is:  0.24306993186473846\n",
      "The representation loss after processing this batch is:  0.004268720746040344\n",
      "\n",
      "The classification loss after processing this batch is:  0.1070193499326706\n",
      "The representation loss after processing this batch is:  0.0036226511001586914\n",
      "\n",
      "The classification loss after processing this batch is:  0.2936957776546478\n",
      "The representation loss after processing this batch is:  0.004200667142868042\n",
      "\n",
      "The classification loss after processing this batch is:  0.21783657371997833\n",
      "The representation loss after processing this batch is:  0.003367319703102112\n",
      "\n",
      "The classification loss after processing this batch is:  0.1897529661655426\n",
      "The representation loss after processing this batch is:  0.002992965281009674\n",
      "\n",
      "The classification loss after processing this batch is:  0.33113613724708557\n",
      "The representation loss after processing this batch is:  0.0033018216490745544\n",
      "\n",
      "The classification loss after processing this batch is:  0.17449015378952026\n",
      "The representation loss after processing this batch is:  0.003939345479011536\n",
      "\n",
      "The classification loss after processing this batch is:  0.2882142663002014\n",
      "The representation loss after processing this batch is:  0.004183389246463776\n",
      "\n",
      "The classification loss after processing this batch is:  0.27264708280563354\n",
      "The representation loss after processing this batch is:  0.003932736814022064\n",
      "\n",
      "The classification loss after processing this batch is:  0.18977013230323792\n",
      "The representation loss after processing this batch is:  0.003837965428829193\n",
      "\n",
      "The classification loss after processing this batch is:  0.23599809408187866\n",
      "The representation loss after processing this batch is:  0.0029058530926704407\n",
      "\n",
      "The classification loss after processing this batch is:  0.17652848362922668\n",
      "The representation loss after processing this batch is:  0.0035492107272148132\n",
      "\n",
      "The classification loss after processing this batch is:  0.12375716865062714\n",
      "The representation loss after processing this batch is:  0.0034088194370269775\n",
      "\n",
      "The classification loss after processing this batch is:  0.15096861124038696\n",
      "The representation loss after processing this batch is:  0.0032935142517089844\n",
      "\n",
      "The classification loss after processing this batch is:  0.17748981714248657\n",
      "The representation loss after processing this batch is:  0.0031660422682762146\n",
      "\n",
      "The classification loss after processing this batch is:  0.1899453103542328\n",
      "The representation loss after processing this batch is:  0.002715297043323517\n",
      "\n",
      "The classification loss after processing this batch is:  0.1850106567144394\n",
      "The representation loss after processing this batch is:  0.0033254846930503845\n",
      "\n",
      "The classification loss after processing this batch is:  0.23095016181468964\n",
      "The representation loss after processing this batch is:  0.003634147346019745\n",
      "\n",
      "The classification loss after processing this batch is:  0.45665693283081055\n",
      "The representation loss after processing this batch is:  0.003415629267692566\n",
      "\n",
      "The classification loss after processing this batch is:  0.3608759939670563\n",
      "The representation loss after processing this batch is:  0.003553621470928192\n",
      "\n",
      "The classification loss after processing this batch is:  0.15989045798778534\n",
      "The representation loss after processing this batch is:  0.003313198685646057\n",
      "\n",
      "The classification loss after processing this batch is:  0.19003455340862274\n",
      "The representation loss after processing this batch is:  0.004128225147724152\n",
      "\n",
      "The classification loss after processing this batch is:  0.18706785142421722\n",
      "The representation loss after processing this batch is:  0.0035474449396133423\n",
      "\n",
      "The classification loss after processing this batch is:  0.18227028846740723\n",
      "The representation loss after processing this batch is:  0.0032569020986557007\n",
      "\n",
      "The classification loss after processing this batch is:  0.12023773789405823\n",
      "The representation loss after processing this batch is:  0.0036717206239700317\n",
      "\n",
      "The classification loss after processing this batch is:  0.1789865493774414\n",
      "The representation loss after processing this batch is:  0.003706216812133789\n",
      "\n",
      "The classification loss after processing this batch is:  0.23857083916664124\n",
      "The representation loss after processing this batch is:  0.003321215510368347\n",
      "\n",
      "The classification loss after processing this batch is:  0.2917015850543976\n",
      "The representation loss after processing this batch is:  0.0035254620015621185\n",
      "\n",
      "The classification loss after processing this batch is:  0.16053253412246704\n",
      "The representation loss after processing this batch is:  0.003124251961708069\n",
      "\n",
      "The classification loss after processing this batch is:  0.15684892237186432\n",
      "The representation loss after processing this batch is:  0.0030069947242736816\n",
      "\n",
      "The classification loss after processing this batch is:  0.1427825540304184\n",
      "The representation loss after processing this batch is:  0.0030433237552642822\n",
      "\n",
      "The classification loss after processing this batch is:  0.33132535219192505\n",
      "The representation loss after processing this batch is:  0.0034245923161506653\n",
      "\n",
      "The classification loss after processing this batch is:  0.18220382928848267\n",
      "The representation loss after processing this batch is:  0.003404393792152405\n",
      "\n",
      "The classification loss after processing this batch is:  0.13521790504455566\n",
      "The representation loss after processing this batch is:  0.00333540141582489\n",
      "\n",
      "The classification loss after processing this batch is:  0.25942060351371765\n",
      "The representation loss after processing this batch is:  0.0035068094730377197\n",
      "\n",
      "The classification loss after processing this batch is:  0.16968244314193726\n",
      "The representation loss after processing this batch is:  0.0029893293976783752\n",
      "\n",
      "The classification loss after processing this batch is:  0.17092329263687134\n",
      "The representation loss after processing this batch is:  0.0034519731998443604\n",
      "\n",
      "The classification loss after processing this batch is:  0.24391363561153412\n",
      "The representation loss after processing this batch is:  0.003429841250181198\n",
      "\n",
      "The classification loss after processing this batch is:  0.1502825766801834\n",
      "The representation loss after processing this batch is:  0.0032867565751075745\n",
      "\n",
      "The classification loss after processing this batch is:  0.19662907719612122\n",
      "The representation loss after processing this batch is:  0.003415919840335846\n",
      "\n",
      "The classification loss after processing this batch is:  0.2946185767650604\n",
      "The representation loss after processing this batch is:  0.003169964998960495\n",
      "\n",
      "The classification loss after processing this batch is:  0.2910442650318146\n",
      "The representation loss after processing this batch is:  0.0031730905175209045\n",
      "\n",
      "The classification loss after processing this batch is:  0.2720312178134918\n",
      "The representation loss after processing this batch is:  0.003573603928089142\n",
      "\n",
      "The classification loss after processing this batch is:  0.3230935335159302\n",
      "The representation loss after processing this batch is:  0.0031489580869674683\n",
      "\n",
      "The classification loss after processing this batch is:  0.18962551653385162\n",
      "The representation loss after processing this batch is:  0.003409929573535919\n",
      "\n",
      "The classification loss after processing this batch is:  0.23819205164909363\n",
      "The representation loss after processing this batch is:  0.003235265612602234\n",
      "\n",
      "The classification loss after processing this batch is:  0.1757034957408905\n",
      "The representation loss after processing this batch is:  0.003780767321586609\n",
      "\n",
      "The classification loss after processing this batch is:  0.23693540692329407\n",
      "The representation loss after processing this batch is:  0.0034611187875270844\n",
      "\n",
      "The classification loss after processing this batch is:  0.17257365584373474\n",
      "The representation loss after processing this batch is:  0.002962671220302582\n",
      "\n",
      "The classification loss after processing this batch is:  0.24628354609012604\n",
      "The representation loss after processing this batch is:  0.003137446939945221\n",
      "\n",
      "The classification loss after processing this batch is:  0.15849079191684723\n",
      "The representation loss after processing this batch is:  0.003201000392436981\n",
      "\n",
      "The classification loss after processing this batch is:  0.22033211588859558\n",
      "The representation loss after processing this batch is:  0.0031854845583438873\n",
      "\n",
      "The classification loss after processing this batch is:  0.22225402295589447\n",
      "The representation loss after processing this batch is:  0.002999980002641678\n",
      "\n",
      "The classification loss after processing this batch is:  0.22321780025959015\n",
      "The representation loss after processing this batch is:  0.003271818161010742\n",
      "\n",
      "The classification loss after processing this batch is:  0.268612802028656\n",
      "The representation loss after processing this batch is:  0.003139011561870575\n",
      "\n",
      "The classification loss after processing this batch is:  0.3057316839694977\n",
      "The representation loss after processing this batch is:  0.00309203565120697\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.3009938895702362\n",
      "The representation loss after processing this batch is:  0.0033625252544879913\n",
      "\n",
      "The classification loss after processing this batch is:  0.3612629473209381\n",
      "The representation loss after processing this batch is:  0.0034259334206581116\n",
      "\n",
      "The classification loss after processing this batch is:  0.3930358290672302\n",
      "The representation loss after processing this batch is:  0.0031015612185001373\n",
      "\n",
      "The classification loss after processing this batch is:  0.3145298361778259\n",
      "The representation loss after processing this batch is:  0.002842407673597336\n",
      "\n",
      "The classification loss after processing this batch is:  0.15854091942310333\n",
      "The representation loss after processing this batch is:  0.0034428685903549194\n",
      "\n",
      "The classification loss after processing this batch is:  0.2286839783191681\n",
      "The representation loss after processing this batch is:  0.0034615322947502136\n",
      "\n",
      "The classification loss after processing this batch is:  0.15581877529621124\n",
      "The representation loss after processing this batch is:  0.003318294882774353\n",
      "\n",
      "The classification loss after processing this batch is:  0.21192452311515808\n",
      "The representation loss after processing this batch is:  0.0036843642592430115\n",
      "\n",
      "The classification loss after processing this batch is:  0.35966116189956665\n",
      "The representation loss after processing this batch is:  0.003818906843662262\n",
      "\n",
      "The classification loss after processing this batch is:  0.37070924043655396\n",
      "The representation loss after processing this batch is:  0.003519810736179352\n",
      "\n",
      "The classification loss after processing this batch is:  0.4455624222755432\n",
      "The representation loss after processing this batch is:  0.0033186376094818115\n",
      "\n",
      "The classification loss after processing this batch is:  0.2822002172470093\n",
      "The representation loss after processing this batch is:  0.0034999512135982513\n",
      "\n",
      "The classification loss after processing this batch is:  0.16491492092609406\n",
      "The representation loss after processing this batch is:  0.003199368715286255\n",
      "\n",
      "The classification loss after processing this batch is:  0.16677549481391907\n",
      "The representation loss after processing this batch is:  0.0034971460700035095\n",
      "\n",
      "The classification loss after processing this batch is:  0.28759369254112244\n",
      "The representation loss after processing this batch is:  0.002931557595729828\n",
      "\n",
      "The classification loss after processing this batch is:  0.15949580073356628\n",
      "The representation loss after processing this batch is:  0.0036046504974365234\n",
      "\n",
      "The classification loss after processing this batch is:  0.16828390955924988\n",
      "The representation loss after processing this batch is:  0.0035739168524742126\n",
      "\n",
      "The classification loss after processing this batch is:  0.14369061589241028\n",
      "The representation loss after processing this batch is:  0.0035514235496520996\n",
      "\n",
      "The classification loss after processing this batch is:  0.07523928582668304\n",
      "The representation loss after processing this batch is:  0.0034706592559814453\n",
      "\n",
      "The classification loss after processing this batch is:  0.23599128425121307\n",
      "The representation loss after processing this batch is:  0.00354192778468132\n",
      "\n",
      "The classification loss after processing this batch is:  0.17879971861839294\n",
      "The representation loss after processing this batch is:  0.003882531076669693\n",
      "\n",
      "The classification loss after processing this batch is:  0.2703405022621155\n",
      "The representation loss after processing this batch is:  0.003196772187948227\n",
      "\n",
      "The classification loss after processing this batch is:  0.24104981124401093\n",
      "The representation loss after processing this batch is:  0.0031970180571079254\n",
      "\n",
      "The classification loss after processing this batch is:  0.22456035017967224\n",
      "The representation loss after processing this batch is:  0.00355607271194458\n",
      "\n",
      "The classification loss after processing this batch is:  0.26614910364151\n",
      "The representation loss after processing this batch is:  0.0033823922276496887\n",
      "\n",
      "The classification loss after processing this batch is:  0.2054518759250641\n",
      "The representation loss after processing this batch is:  0.0033582262694835663\n",
      "\n",
      "The classification loss after processing this batch is:  0.23030085861682892\n",
      "The representation loss after processing this batch is:  0.0035837143659591675\n",
      "\n",
      "The classification loss after processing this batch is:  0.2757968604564667\n",
      "The representation loss after processing this batch is:  0.0036993250250816345\n",
      "\n",
      "The classification loss after processing this batch is:  0.2753428518772125\n",
      "The representation loss after processing this batch is:  0.0035650432109832764\n",
      "\n",
      "The classification loss after processing this batch is:  0.20739074051380157\n",
      "The representation loss after processing this batch is:  0.0031157657504081726\n",
      "\n",
      "The classification loss after processing this batch is:  0.3079024851322174\n",
      "The representation loss after processing this batch is:  0.003363288938999176\n",
      "\n",
      "The classification loss after processing this batch is:  0.35612067580223083\n",
      "The representation loss after processing this batch is:  0.0036630779504776\n",
      "\n",
      "The classification loss after processing this batch is:  0.169978529214859\n",
      "The representation loss after processing this batch is:  0.002941638231277466\n",
      "\n",
      "The classification loss after processing this batch is:  0.20375247299671173\n",
      "The representation loss after processing this batch is:  0.0034729987382888794\n",
      "\n",
      "The classification loss after processing this batch is:  0.2406446784734726\n",
      "The representation loss after processing this batch is:  0.003344442695379257\n",
      "\n",
      "The classification loss after processing this batch is:  0.2574625015258789\n",
      "The representation loss after processing this batch is:  0.0032479017972946167\n",
      "\n",
      "The classification loss after processing this batch is:  0.3300166130065918\n",
      "The representation loss after processing this batch is:  0.0036640390753746033\n",
      "\n",
      "The classification loss after processing this batch is:  0.3248191177845001\n",
      "The representation loss after processing this batch is:  0.003908246755599976\n",
      "\n",
      "The classification loss after processing this batch is:  0.33402320742607117\n",
      "The representation loss after processing this batch is:  0.0036719590425491333\n",
      "\n",
      "The classification loss after processing this batch is:  0.2915383279323578\n",
      "The representation loss after processing this batch is:  0.0037618204951286316\n",
      "\n",
      "The classification loss after processing this batch is:  0.22677291929721832\n",
      "The representation loss after processing this batch is:  0.0031679347157478333\n",
      "\n",
      "The classification loss after processing this batch is:  0.20684027671813965\n",
      "The representation loss after processing this batch is:  0.003908231854438782\n",
      "\n",
      "The classification loss after processing this batch is:  0.15034770965576172\n",
      "The representation loss after processing this batch is:  0.003626883029937744\n",
      "\n",
      "The classification loss after processing this batch is:  0.26201894879341125\n",
      "The representation loss after processing this batch is:  0.0033707022666931152\n",
      "\n",
      "The classification loss after processing this batch is:  0.2385367751121521\n",
      "The representation loss after processing this batch is:  0.003357537090778351\n",
      "\n",
      "The classification loss after processing this batch is:  0.18071669340133667\n",
      "The representation loss after processing this batch is:  0.0029616989195346832\n",
      "\n",
      "The classification loss after processing this batch is:  0.2035258710384369\n",
      "The representation loss after processing this batch is:  0.003176353871822357\n",
      "\n",
      "The classification loss after processing this batch is:  0.17938818037509918\n",
      "The representation loss after processing this batch is:  0.00422060489654541\n",
      "\n",
      "The classification loss after processing this batch is:  0.2098625749349594\n",
      "The representation loss after processing this batch is:  0.003239009529352188\n",
      "\n",
      "The classification loss after processing this batch is:  0.18545888364315033\n",
      "The representation loss after processing this batch is:  0.0033353567123413086\n",
      "\n",
      "The classification loss after processing this batch is:  0.22128139436244965\n",
      "The representation loss after processing this batch is:  0.0031608417630195618\n",
      "\n",
      "The classification loss after processing this batch is:  0.14074236154556274\n",
      "The representation loss after processing this batch is:  0.0029963329434394836\n",
      "\n",
      "The classification loss after processing this batch is:  0.17725448310375214\n",
      "The representation loss after processing this batch is:  0.00293571874499321\n",
      "\n",
      "The classification loss after processing this batch is:  0.17359355092048645\n",
      "The representation loss after processing this batch is:  0.002918913960456848\n",
      "\n",
      "The classification loss after processing this batch is:  0.5916696786880493\n",
      "The representation loss after processing this batch is:  0.003537379205226898\n",
      "\n",
      "The classification loss after processing this batch is:  0.2040894478559494\n",
      "The representation loss after processing this batch is:  0.0033022090792655945\n",
      "\n",
      "The classification loss after processing this batch is:  0.37745967507362366\n",
      "The representation loss after processing this batch is:  0.003149237483739853\n",
      "\n",
      "The classification loss after processing this batch is:  0.3594416379928589\n",
      "The representation loss after processing this batch is:  0.003133036196231842\n",
      "\n",
      "The classification loss after processing this batch is:  0.2238774597644806\n",
      "The representation loss after processing this batch is:  0.003231927752494812\n",
      "\n",
      "The classification loss after processing this batch is:  0.4316999316215515\n",
      "The representation loss after processing this batch is:  0.003737799823284149\n",
      "\n",
      "The classification loss after processing this batch is:  0.21135781705379486\n",
      "The representation loss after processing this batch is:  0.0032685697078704834\n",
      "\n",
      "The classification loss after processing this batch is:  0.3543234169483185\n",
      "The representation loss after processing this batch is:  0.003284398466348648\n",
      "\n",
      "The classification loss after processing this batch is:  0.12740573287010193\n",
      "The representation loss after processing this batch is:  0.0032975003123283386\n",
      "\n",
      "The classification loss after processing this batch is:  0.14622411131858826\n",
      "The representation loss after processing this batch is:  0.0030058547854423523\n",
      "\n",
      "The classification loss after processing this batch is:  0.12505364418029785\n",
      "The representation loss after processing this batch is:  0.0036966651678085327\n",
      "\n",
      "The classification loss after processing this batch is:  0.1150037869811058\n",
      "The representation loss after processing this batch is:  0.003275051712989807\n",
      "\n",
      "The classification loss after processing this batch is:  0.18909400701522827\n",
      "The representation loss after processing this batch is:  0.0032869577407836914\n",
      "\n",
      "The classification loss after processing this batch is:  0.1432131826877594\n",
      "The representation loss after processing this batch is:  0.0028433948755264282\n",
      "\n",
      "The classification loss after processing this batch is:  0.1849568486213684\n",
      "The representation loss after processing this batch is:  0.0036691129207611084\n",
      "\n",
      "The classification loss after processing this batch is:  0.1545839160680771\n",
      "The representation loss after processing this batch is:  0.0035353004932403564\n",
      "\n",
      "The classification loss after processing this batch is:  0.1811913102865219\n",
      "The representation loss after processing this batch is:  0.003396160900592804\n",
      "\n",
      "The classification loss after processing this batch is:  0.21913589537143707\n",
      "The representation loss after processing this batch is:  0.0030014999210834503\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14382165670394897\n",
      "The representation loss after processing this batch is:  0.0033036768436431885\n",
      "\n",
      "The classification loss after processing this batch is:  0.22924740612506866\n",
      "The representation loss after processing this batch is:  0.0033150315284729004\n",
      "\n",
      "The classification loss after processing this batch is:  0.20804277062416077\n",
      "The representation loss after processing this batch is:  0.003183230757713318\n",
      "\n",
      "The classification loss after processing this batch is:  0.27347710728645325\n",
      "The representation loss after processing this batch is:  0.003545604646205902\n",
      "\n",
      "The classification loss after processing this batch is:  0.22903622686862946\n",
      "The representation loss after processing this batch is:  0.003051169216632843\n",
      "\n",
      "The classification loss after processing this batch is:  0.16287033259868622\n",
      "The representation loss after processing this batch is:  0.0030770376324653625\n",
      "\n",
      "The classification loss after processing this batch is:  0.3283197581768036\n",
      "The representation loss after processing this batch is:  0.0038019418716430664\n",
      "\n",
      "The classification loss after processing this batch is:  0.2578613758087158\n",
      "The representation loss after processing this batch is:  0.003208056092262268\n",
      "\n",
      "The classification loss after processing this batch is:  0.2380826473236084\n",
      "The representation loss after processing this batch is:  0.0034451112151145935\n",
      "\n",
      "The classification loss after processing this batch is:  0.1361326277256012\n",
      "The representation loss after processing this batch is:  0.003200829029083252\n",
      "\n",
      "The classification loss after processing this batch is:  0.1792793869972229\n",
      "The representation loss after processing this batch is:  0.003479696810245514\n",
      "\n",
      "The classification loss after processing this batch is:  0.2344392091035843\n",
      "The representation loss after processing this batch is:  0.003347240388393402\n",
      "\n",
      "The classification loss after processing this batch is:  0.22336626052856445\n",
      "The representation loss after processing this batch is:  0.004034675657749176\n",
      "\n",
      "The classification loss after processing this batch is:  0.19062671065330505\n",
      "The representation loss after processing this batch is:  0.003947392106056213\n",
      "\n",
      "The classification loss after processing this batch is:  0.2168610543012619\n",
      "The representation loss after processing this batch is:  0.004110705107450485\n",
      "\n",
      "The classification loss after processing this batch is:  0.2694430947303772\n",
      "The representation loss after processing this batch is:  0.003695562481880188\n",
      "\n",
      "The classification loss after processing this batch is:  0.367198646068573\n",
      "The representation loss after processing this batch is:  0.0032046064734458923\n",
      "\n",
      "The classification loss after processing this batch is:  0.2685526907444\n",
      "The representation loss after processing this batch is:  0.003969624638557434\n",
      "\n",
      "The classification loss after processing this batch is:  0.23353596031665802\n",
      "The representation loss after processing this batch is:  0.0030352771282196045\n",
      "\n",
      "The classification loss after processing this batch is:  0.17005060613155365\n",
      "The representation loss after processing this batch is:  0.0028238222002983093\n",
      "\n",
      "The classification loss after processing this batch is:  0.29829856753349304\n",
      "The representation loss after processing this batch is:  0.0030614659190177917\n",
      "\n",
      "The classification loss after processing this batch is:  0.13918696343898773\n",
      "The representation loss after processing this batch is:  0.003254242241382599\n",
      "\n",
      "The classification loss after processing this batch is:  0.18875141441822052\n",
      "The representation loss after processing this batch is:  0.0033905506134033203\n",
      "\n",
      "The classification loss after processing this batch is:  0.17085717618465424\n",
      "The representation loss after processing this batch is:  0.0034343674778938293\n",
      "\n",
      "The classification loss after processing this batch is:  0.1815294623374939\n",
      "The representation loss after processing this batch is:  0.003202386200428009\n",
      "\n",
      "The classification loss after processing this batch is:  0.16331960260868073\n",
      "The representation loss after processing this batch is:  0.003672100603580475\n",
      "\n",
      "The classification loss after processing this batch is:  0.2785123884677887\n",
      "The representation loss after processing this batch is:  0.0034324228763580322\n",
      "\n",
      "The classification loss after processing this batch is:  0.2316402792930603\n",
      "The representation loss after processing this batch is:  0.0037303492426872253\n",
      "\n",
      "The classification loss after processing this batch is:  0.2668510973453522\n",
      "The representation loss after processing this batch is:  0.0032323896884918213\n",
      "\n",
      "The classification loss after processing this batch is:  0.22324933111667633\n",
      "The representation loss after processing this batch is:  0.003655754029750824\n",
      "\n",
      "The classification loss after processing this batch is:  0.20501120388507843\n",
      "The representation loss after processing this batch is:  0.0034041404724121094\n",
      "\n",
      "The classification loss after processing this batch is:  0.15465326607227325\n",
      "The representation loss after processing this batch is:  0.0031374767422676086\n",
      "\n",
      "The classification loss after processing this batch is:  0.17023658752441406\n",
      "The representation loss after processing this batch is:  0.0036144405603408813\n",
      "\n",
      "The classification loss after processing this batch is:  0.18884462118148804\n",
      "The representation loss after processing this batch is:  0.003486916422843933\n",
      "\n",
      "The classification loss after processing this batch is:  0.11895199120044708\n",
      "The representation loss after processing this batch is:  0.003290124237537384\n",
      "\n",
      "The classification loss after processing this batch is:  0.11032266914844513\n",
      "The representation loss after processing this batch is:  0.003162328153848648\n",
      "\n",
      "The classification loss after processing this batch is:  0.18184366822242737\n",
      "The representation loss after processing this batch is:  0.003579474985599518\n",
      "\n",
      "The classification loss after processing this batch is:  0.132022425532341\n",
      "The representation loss after processing this batch is:  0.0034556537866592407\n",
      "\n",
      "The classification loss after processing this batch is:  0.27076423168182373\n",
      "The representation loss after processing this batch is:  0.003507092595100403\n",
      "\n",
      "The classification loss after processing this batch is:  0.1844872534275055\n",
      "The representation loss after processing this batch is:  0.002899516373872757\n",
      "\n",
      "The classification loss after processing this batch is:  0.24878817796707153\n",
      "The representation loss after processing this batch is:  0.003411516547203064\n",
      "\n",
      "The classification loss after processing this batch is:  0.12328915297985077\n",
      "The representation loss after processing this batch is:  0.0034959912300109863\n",
      "\n",
      "The classification loss after processing this batch is:  0.2755320370197296\n",
      "The representation loss after processing this batch is:  0.0033187568187713623\n",
      "\n",
      "The classification loss after processing this batch is:  0.2295016646385193\n",
      "The representation loss after processing this batch is:  0.0033753737807273865\n",
      "\n",
      "The classification loss after processing this batch is:  0.17559580504894257\n",
      "The representation loss after processing this batch is:  0.003040984272956848\n",
      "\n",
      "The classification loss after processing this batch is:  0.27227985858917236\n",
      "The representation loss after processing this batch is:  0.0032646656036376953\n",
      "\n",
      "The classification loss after processing this batch is:  0.24650073051452637\n",
      "The representation loss after processing this batch is:  0.0034608542919158936\n",
      "\n",
      "The classification loss after processing this batch is:  0.11515996605157852\n",
      "The representation loss after processing this batch is:  0.0030385926365852356\n",
      "\n",
      "The classification loss after processing this batch is:  0.15984566509723663\n",
      "The representation loss after processing this batch is:  0.003078952431678772\n",
      "\n",
      "The classification loss after processing this batch is:  0.16481880843639374\n",
      "The representation loss after processing this batch is:  0.0028974413871765137\n",
      "\n",
      "The classification loss after processing this batch is:  0.25405511260032654\n",
      "The representation loss after processing this batch is:  0.0032223090529441833\n",
      "\n",
      "The classification loss after processing this batch is:  0.23917563259601593\n",
      "The representation loss after processing this batch is:  0.003135599195957184\n",
      "\n",
      "The classification loss after processing this batch is:  0.2147897183895111\n",
      "The representation loss after processing this batch is:  0.004077211022377014\n",
      "\n",
      "The classification loss after processing this batch is:  0.3046899437904358\n",
      "The representation loss after processing this batch is:  0.003279179334640503\n",
      "\n",
      "The classification loss after processing this batch is:  0.2888982892036438\n",
      "The representation loss after processing this batch is:  0.003243878483772278\n",
      "\n",
      "The classification loss after processing this batch is:  0.23620566725730896\n",
      "The representation loss after processing this batch is:  0.002981245517730713\n",
      "\n",
      "The classification loss after processing this batch is:  0.40966156125068665\n",
      "The representation loss after processing this batch is:  0.0030532218515872955\n",
      "\n",
      "The classification loss after processing this batch is:  0.2732313871383667\n",
      "The representation loss after processing this batch is:  0.003124173730611801\n",
      "\n",
      "The classification loss after processing this batch is:  0.22389380633831024\n",
      "The representation loss after processing this batch is:  0.003098573535680771\n",
      "\n",
      "The classification loss after processing this batch is:  0.16940924525260925\n",
      "The representation loss after processing this batch is:  0.0032007023692131042\n",
      "\n",
      "The classification loss after processing this batch is:  0.119584821164608\n",
      "The representation loss after processing this batch is:  0.0032479241490364075\n",
      "\n",
      "The classification loss after processing this batch is:  0.12266428023576736\n",
      "The representation loss after processing this batch is:  0.0030483826994895935\n",
      "\n",
      "The classification loss after processing this batch is:  0.1922335922718048\n",
      "The representation loss after processing this batch is:  0.00394710898399353\n",
      "\n",
      "The classification loss after processing this batch is:  0.17802466452121735\n",
      "The representation loss after processing this batch is:  0.003061354160308838\n",
      "\n",
      "The classification loss after processing this batch is:  0.1674186885356903\n",
      "The representation loss after processing this batch is:  0.0031063854694366455\n",
      "\n",
      "The classification loss after processing this batch is:  0.25464364886283875\n",
      "The representation loss after processing this batch is:  0.003202110528945923\n",
      "\n",
      "The classification loss after processing this batch is:  0.22889269888401031\n",
      "The representation loss after processing this batch is:  0.0037318840622901917\n",
      "\n",
      "The classification loss after processing this batch is:  0.2799087464809418\n",
      "The representation loss after processing this batch is:  0.003165610134601593\n",
      "\n",
      "The classification loss after processing this batch is:  0.19979515671730042\n",
      "The representation loss after processing this batch is:  0.0032150447368621826\n",
      "\n",
      "The classification loss after processing this batch is:  0.28445929288864136\n",
      "The representation loss after processing this batch is:  0.003118623048067093\n",
      "\n",
      "The classification loss after processing this batch is:  0.22413727641105652\n",
      "The representation loss after processing this batch is:  0.0031946711242198944\n",
      "\n",
      "The classification loss after processing this batch is:  0.12169460207223892\n",
      "The representation loss after processing this batch is:  0.003352321684360504\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2577012777328491\n",
      "The representation loss after processing this batch is:  0.0030939429998397827\n",
      "\n",
      "The classification loss after processing this batch is:  0.11121843010187149\n",
      "The representation loss after processing this batch is:  0.003062315285205841\n",
      "\n",
      "The classification loss after processing this batch is:  0.1286459118127823\n",
      "The representation loss after processing this batch is:  0.0030135884881019592\n",
      "\n",
      "The classification loss after processing this batch is:  0.16875621676445007\n",
      "The representation loss after processing this batch is:  0.0037376731634140015\n",
      "\n",
      "The classification loss after processing this batch is:  0.23651114106178284\n",
      "The representation loss after processing this batch is:  0.0031775012612342834\n",
      "\n",
      "The classification loss after processing this batch is:  0.23041152954101562\n",
      "The representation loss after processing this batch is:  0.0031470656394958496\n",
      "\n",
      "The classification loss after processing this batch is:  0.142118901014328\n",
      "The representation loss after processing this batch is:  0.003477253019809723\n",
      "\n",
      "The classification loss after processing this batch is:  0.2119445502758026\n",
      "The representation loss after processing this batch is:  0.0038096457719802856\n",
      "\n",
      "The classification loss after processing this batch is:  0.13929320871829987\n",
      "The representation loss after processing this batch is:  0.0033115148544311523\n",
      "\n",
      "The classification loss after processing this batch is:  0.26344069838523865\n",
      "The representation loss after processing this batch is:  0.0035104602575302124\n",
      "\n",
      "The classification loss after processing this batch is:  0.1296684294939041\n",
      "The representation loss after processing this batch is:  0.00291433185338974\n",
      "\n",
      "The classification loss after processing this batch is:  0.1119999811053276\n",
      "The representation loss after processing this batch is:  0.0033798441290855408\n",
      "\n",
      "The classification loss after processing this batch is:  0.17766539752483368\n",
      "The representation loss after processing this batch is:  0.004110291600227356\n",
      "\n",
      "The classification loss after processing this batch is:  0.17877550423145294\n",
      "The representation loss after processing this batch is:  0.0034477785229682922\n",
      "\n",
      "The classification loss after processing this batch is:  0.16958504915237427\n",
      "The representation loss after processing this batch is:  0.003715232014656067\n",
      "\n",
      "The classification loss after processing this batch is:  0.1422511488199234\n",
      "The representation loss after processing this batch is:  0.0032057687640190125\n",
      "\n",
      "The classification loss after processing this batch is:  0.22178325057029724\n",
      "The representation loss after processing this batch is:  0.003493271768093109\n",
      "\n",
      "The classification loss after processing this batch is:  0.3179251551628113\n",
      "The representation loss after processing this batch is:  0.003397427499294281\n",
      "\n",
      "The classification loss after processing this batch is:  0.29630985856056213\n",
      "The representation loss after processing this batch is:  0.0033615007996559143\n",
      "\n",
      "The classification loss after processing this batch is:  0.2717183828353882\n",
      "The representation loss after processing this batch is:  0.0037466660141944885\n",
      "\n",
      "The classification loss after processing this batch is:  0.14066031575202942\n",
      "The representation loss after processing this batch is:  0.003328666090965271\n",
      "\n",
      "The classification loss after processing this batch is:  0.15949992835521698\n",
      "The representation loss after processing this batch is:  0.002858716994524002\n",
      "\n",
      "The classification loss after processing this batch is:  0.31948456168174744\n",
      "The representation loss after processing this batch is:  0.0035374537110328674\n",
      "\n",
      "The classification loss after processing this batch is:  0.36760732531547546\n",
      "The representation loss after processing this batch is:  0.004132308065891266\n",
      "\n",
      "The classification loss after processing this batch is:  0.32610195875167847\n",
      "The representation loss after processing this batch is:  0.00385342538356781\n",
      "\n",
      "The classification loss after processing this batch is:  0.356557697057724\n",
      "The representation loss after processing this batch is:  0.00369374081492424\n",
      "\n",
      "The classification loss after processing this batch is:  0.18842096626758575\n",
      "The representation loss after processing this batch is:  0.002783801406621933\n",
      "\n",
      "The classification loss after processing this batch is:  0.28811347484588623\n",
      "The representation loss after processing this batch is:  0.00316060334444046\n",
      "\n",
      "The classification loss after processing this batch is:  0.23421593010425568\n",
      "The representation loss after processing this batch is:  0.003270849585533142\n",
      "\n",
      "The classification loss after processing this batch is:  0.21377047896385193\n",
      "The representation loss after processing this batch is:  0.003180667757987976\n",
      "\n",
      "The classification loss after processing this batch is:  0.16451917588710785\n",
      "The representation loss after processing this batch is:  0.003212668001651764\n",
      "\n",
      "The classification loss after processing this batch is:  0.21710357069969177\n",
      "The representation loss after processing this batch is:  0.0034347549080848694\n",
      "\n",
      "The classification loss after processing this batch is:  0.2154114693403244\n",
      "The representation loss after processing this batch is:  0.003528214991092682\n",
      "\n",
      "The classification loss after processing this batch is:  0.22680331766605377\n",
      "The representation loss after processing this batch is:  0.0031455345451831818\n",
      "\n",
      "The classification loss after processing this batch is:  0.21356119215488434\n",
      "The representation loss after processing this batch is:  0.0032414793968200684\n",
      "\n",
      "The classification loss after processing this batch is:  0.1195395216345787\n",
      "The representation loss after processing this batch is:  0.0036315396428108215\n",
      "\n",
      "The classification loss after processing this batch is:  0.15175844728946686\n",
      "The representation loss after processing this batch is:  0.0034853145480155945\n",
      "\n",
      "The classification loss after processing this batch is:  0.18924503028392792\n",
      "The representation loss after processing this batch is:  0.0036717578768730164\n",
      "\n",
      "The classification loss after processing this batch is:  0.17777541279792786\n",
      "The representation loss after processing this batch is:  0.0033847391605377197\n",
      "\n",
      "The classification loss after processing this batch is:  0.14251184463500977\n",
      "The representation loss after processing this batch is:  0.003865636885166168\n",
      "\n",
      "The classification loss after processing this batch is:  0.14509955048561096\n",
      "The representation loss after processing this batch is:  0.002881072461605072\n",
      "\n",
      "The classification loss after processing this batch is:  0.22796790301799774\n",
      "The representation loss after processing this batch is:  0.0034812167286872864\n",
      "\n",
      "The classification loss after processing this batch is:  0.2688007652759552\n",
      "The representation loss after processing this batch is:  0.0035398826003074646\n",
      "\n",
      "The classification loss after processing this batch is:  0.22601374983787537\n",
      "The representation loss after processing this batch is:  0.0029754266142845154\n",
      "\n",
      "The classification loss after processing this batch is:  0.17435172200202942\n",
      "The representation loss after processing this batch is:  0.002907209098339081\n",
      "\n",
      "The classification loss after processing this batch is:  0.15655413269996643\n",
      "The representation loss after processing this batch is:  0.0033734366297721863\n",
      "\n",
      "The classification loss after processing this batch is:  0.13372911512851715\n",
      "The representation loss after processing this batch is:  0.00302853062748909\n",
      "\n",
      "The classification loss after processing this batch is:  0.19201971590518951\n",
      "The representation loss after processing this batch is:  0.003312505781650543\n",
      "\n",
      "The classification loss after processing this batch is:  0.26808878779411316\n",
      "The representation loss after processing this batch is:  0.003301657736301422\n",
      "\n",
      "The classification loss after processing this batch is:  0.2470550835132599\n",
      "The representation loss after processing this batch is:  0.0033780187368392944\n",
      "\n",
      "The classification loss after processing this batch is:  0.1498641073703766\n",
      "The representation loss after processing this batch is:  0.003360442817211151\n",
      "\n",
      "The classification loss after processing this batch is:  0.2518358826637268\n",
      "The representation loss after processing this batch is:  0.0031877681612968445\n",
      "\n",
      "The classification loss after processing this batch is:  0.31164753437042236\n",
      "The representation loss after processing this batch is:  0.003321141004562378\n",
      "\n",
      "The classification loss after processing this batch is:  0.11248597502708435\n",
      "The representation loss after processing this batch is:  0.003404855728149414\n",
      "\n",
      "The classification loss after processing this batch is:  0.15560197830200195\n",
      "The representation loss after processing this batch is:  0.002873603254556656\n",
      "\n",
      "The classification loss after processing this batch is:  0.26687318086624146\n",
      "The representation loss after processing this batch is:  0.003067106008529663\n",
      "\n",
      "The classification loss after processing this batch is:  0.24004337191581726\n",
      "The representation loss after processing this batch is:  0.002991192042827606\n",
      "\n",
      "The classification loss after processing this batch is:  0.164178267121315\n",
      "The representation loss after processing this batch is:  0.0031333565711975098\n",
      "\n",
      "The classification loss after processing this batch is:  0.3869747221469879\n",
      "The representation loss after processing this batch is:  0.003146335482597351\n",
      "\n",
      "The classification loss after processing this batch is:  0.25006794929504395\n",
      "The representation loss after processing this batch is:  0.003723233938217163\n",
      "\n",
      "The classification loss after processing this batch is:  0.3286871612071991\n",
      "The representation loss after processing this batch is:  0.003453396260738373\n",
      "\n",
      "The classification loss after processing this batch is:  0.2236281782388687\n",
      "The representation loss after processing this batch is:  0.0036678090691566467\n",
      "\n",
      "The classification loss after processing this batch is:  0.27064287662506104\n",
      "The representation loss after processing this batch is:  0.0030779168009757996\n",
      "\n",
      "The classification loss after processing this batch is:  0.18722191452980042\n",
      "The representation loss after processing this batch is:  0.0043666064739227295\n",
      "\n",
      "The classification loss after processing this batch is:  0.18678592145442963\n",
      "The representation loss after processing this batch is:  0.003250814974308014\n",
      "\n",
      "The classification loss after processing this batch is:  0.2092593014240265\n",
      "The representation loss after processing this batch is:  0.0030740201473236084\n",
      "\n",
      "The classification loss after processing this batch is:  0.21967503428459167\n",
      "The representation loss after processing this batch is:  0.0029102936387062073\n",
      "\n",
      "The classification loss after processing this batch is:  0.2004881650209427\n",
      "The representation loss after processing this batch is:  0.0031550005078315735\n",
      "\n",
      "The classification loss after processing this batch is:  0.18917657434940338\n",
      "The representation loss after processing this batch is:  0.00310632586479187\n",
      "\n",
      "The classification loss after processing this batch is:  0.27452367544174194\n",
      "The representation loss after processing this batch is:  0.003103438764810562\n",
      "\n",
      "The classification loss after processing this batch is:  0.1768595427274704\n",
      "The representation loss after processing this batch is:  0.0033108144998550415\n",
      "\n",
      "The classification loss after processing this batch is:  0.15207698941230774\n",
      "The representation loss after processing this batch is:  0.00370614230632782\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2335597723722458\n",
      "The representation loss after processing this batch is:  0.0037666335701942444\n",
      "\n",
      "The classification loss after processing this batch is:  0.13717256486415863\n",
      "The representation loss after processing this batch is:  0.0032817497849464417\n",
      "\n",
      "The classification loss after processing this batch is:  0.17472119629383087\n",
      "The representation loss after processing this batch is:  0.003070250153541565\n",
      "\n",
      "The classification loss after processing this batch is:  0.10966301709413528\n",
      "The representation loss after processing this batch is:  0.0035804584622383118\n",
      "\n",
      "The classification loss after processing this batch is:  0.12963372468948364\n",
      "The representation loss after processing this batch is:  0.003055587410926819\n",
      "\n",
      "The classification loss after processing this batch is:  0.22447939217090607\n",
      "The representation loss after processing this batch is:  0.003495544195175171\n",
      "\n",
      "The classification loss after processing this batch is:  0.2476956695318222\n",
      "The representation loss after processing this batch is:  0.00441790372133255\n",
      "\n",
      "The classification loss after processing this batch is:  0.21602238714694977\n",
      "The representation loss after processing this batch is:  0.003736548125743866\n",
      "\n",
      "The classification loss after processing this batch is:  0.18698619306087494\n",
      "The representation loss after processing this batch is:  0.0035706013441085815\n",
      "\n",
      "The classification loss after processing this batch is:  0.17697663605213165\n",
      "The representation loss after processing this batch is:  0.0033081695437431335\n",
      "\n",
      "The classification loss after processing this batch is:  0.1447482705116272\n",
      "The representation loss after processing this batch is:  0.0028501972556114197\n",
      "\n",
      "The classification loss after processing this batch is:  0.12534114718437195\n",
      "The representation loss after processing this batch is:  0.003430977463722229\n",
      "\n",
      "The classification loss after processing this batch is:  0.14888904988765717\n",
      "The representation loss after processing this batch is:  0.0033346787095069885\n",
      "\n",
      "The classification loss after processing this batch is:  0.16428647935390472\n",
      "The representation loss after processing this batch is:  0.0033192336559295654\n",
      "\n",
      "The classification loss after processing this batch is:  0.26260557770729065\n",
      "The representation loss after processing this batch is:  0.004023104906082153\n",
      "\n",
      "The classification loss after processing this batch is:  0.23707635700702667\n",
      "The representation loss after processing this batch is:  0.0035586506128311157\n",
      "\n",
      "The classification loss after processing this batch is:  0.21562165021896362\n",
      "The representation loss after processing this batch is:  0.003437057137489319\n",
      "\n",
      "The classification loss after processing this batch is:  0.16894277930259705\n",
      "The representation loss after processing this batch is:  0.003969550132751465\n",
      "\n",
      "The classification loss after processing this batch is:  0.18442195653915405\n",
      "The representation loss after processing this batch is:  0.0035811513662338257\n",
      "\n",
      "The classification loss after processing this batch is:  0.27247893810272217\n",
      "The representation loss after processing this batch is:  0.0031803883612155914\n",
      "\n",
      "The classification loss after processing this batch is:  0.18827828764915466\n",
      "The representation loss after processing this batch is:  0.0032352283596992493\n",
      "\n",
      "The classification loss after processing this batch is:  0.4167478382587433\n",
      "The representation loss after processing this batch is:  0.003492578864097595\n",
      "\n",
      "The classification loss after processing this batch is:  0.25185203552246094\n",
      "The representation loss after processing this batch is:  0.003445766866207123\n",
      "\n",
      "The classification loss after processing this batch is:  0.2927796542644501\n",
      "The representation loss after processing this batch is:  0.004160426557064056\n",
      "\n",
      "The classification loss after processing this batch is:  0.1818530261516571\n",
      "The representation loss after processing this batch is:  0.0032000914216041565\n",
      "\n",
      "The classification loss after processing this batch is:  0.16648904979228973\n",
      "The representation loss after processing this batch is:  0.003229483962059021\n",
      "\n",
      "The classification loss after processing this batch is:  0.22069291770458221\n",
      "The representation loss after processing this batch is:  0.0029155313968658447\n",
      "\n",
      "The classification loss after processing this batch is:  0.23386335372924805\n",
      "The representation loss after processing this batch is:  0.003383032977581024\n",
      "\n",
      "The classification loss after processing this batch is:  0.34515348076820374\n",
      "The representation loss after processing this batch is:  0.0029986724257469177\n",
      "\n",
      "The classification loss after processing this batch is:  0.3371056318283081\n",
      "The representation loss after processing this batch is:  0.0036906898021698\n",
      "\n",
      "The classification loss after processing this batch is:  0.24402621388435364\n",
      "The representation loss after processing this batch is:  0.0034615397453308105\n",
      "\n",
      "The classification loss after processing this batch is:  0.22336257994174957\n",
      "The representation loss after processing this batch is:  0.003058895468711853\n",
      "\n",
      "The classification loss after processing this batch is:  0.11367785930633545\n",
      "The representation loss after processing this batch is:  0.003407306969165802\n",
      "\n",
      "The classification loss after processing this batch is:  0.1850179135799408\n",
      "The representation loss after processing this batch is:  0.0030298419296741486\n",
      "\n",
      "The classification loss after processing this batch is:  0.15544261038303375\n",
      "The representation loss after processing this batch is:  0.0029452666640281677\n",
      "\n",
      "The classification loss after processing this batch is:  0.13968969881534576\n",
      "The representation loss after processing this batch is:  0.0033724308013916016\n",
      "\n",
      "The classification loss after processing this batch is:  0.18154332041740417\n",
      "The representation loss after processing this batch is:  0.0030423924326896667\n",
      "\n",
      "The classification loss after processing this batch is:  0.287263423204422\n",
      "The representation loss after processing this batch is:  0.003202304244041443\n",
      "\n",
      "The classification loss after processing this batch is:  0.23654253780841827\n",
      "The representation loss after processing this batch is:  0.002740684896707535\n",
      "\n",
      "The classification loss after processing this batch is:  0.1934918910264969\n",
      "The representation loss after processing this batch is:  0.0035447999835014343\n",
      "\n",
      "The classification loss after processing this batch is:  0.182577446103096\n",
      "The representation loss after processing this batch is:  0.0032229870557785034\n",
      "\n",
      "The classification loss after processing this batch is:  0.14058572053909302\n",
      "The representation loss after processing this batch is:  0.0036660954356193542\n",
      "\n",
      "The classification loss after processing this batch is:  0.1953999549150467\n",
      "The representation loss after processing this batch is:  0.0036575421690940857\n",
      "\n",
      "The classification loss after processing this batch is:  0.11228693276643753\n",
      "The representation loss after processing this batch is:  0.0034853368997573853\n",
      "\n",
      "The classification loss after processing this batch is:  0.21510352194309235\n",
      "The representation loss after processing this batch is:  0.0030541568994522095\n",
      "\n",
      "The classification loss after processing this batch is:  0.24561230838298798\n",
      "The representation loss after processing this batch is:  0.0032317936420440674\n",
      "\n",
      "The classification loss after processing this batch is:  0.1363440901041031\n",
      "The representation loss after processing this batch is:  0.0030742958188056946\n",
      "\n",
      "The classification loss after processing this batch is:  0.2652372717857361\n",
      "The representation loss after processing this batch is:  0.0027383044362068176\n",
      "\n",
      "The classification loss after processing this batch is:  0.20090998709201813\n",
      "The representation loss after processing this batch is:  0.003164529800415039\n",
      "\n",
      "The classification loss after processing this batch is:  0.143244206905365\n",
      "The representation loss after processing this batch is:  0.0034055188298225403\n",
      "\n",
      "The classification loss after processing this batch is:  0.13550175726413727\n",
      "The representation loss after processing this batch is:  0.003410644829273224\n",
      "\n",
      "The classification loss after processing this batch is:  0.18475398421287537\n",
      "The representation loss after processing this batch is:  0.003391154110431671\n",
      "\n",
      "The classification loss after processing this batch is:  0.14598649740219116\n",
      "The representation loss after processing this batch is:  0.003132171928882599\n",
      "\n",
      "The classification loss after processing this batch is:  0.4523332417011261\n",
      "The representation loss after processing this batch is:  0.0029495060443878174\n",
      "\n",
      "The classification loss after processing this batch is:  0.23395787179470062\n",
      "The representation loss after processing this batch is:  0.0035082027316093445\n",
      "\n",
      "The classification loss after processing this batch is:  0.2416614592075348\n",
      "The representation loss after processing this batch is:  0.0029907748103141785\n",
      "\n",
      "The classification loss after processing this batch is:  0.19857095181941986\n",
      "The representation loss after processing this batch is:  0.0028952211141586304\n",
      "\n",
      "The classification loss after processing this batch is:  0.23220638930797577\n",
      "The representation loss after processing this batch is:  0.003533650189638138\n",
      "\n",
      "The classification loss after processing this batch is:  0.17385171353816986\n",
      "The representation loss after processing this batch is:  0.0029091425240039825\n",
      "\n",
      "The classification loss after processing this batch is:  0.19246125221252441\n",
      "The representation loss after processing this batch is:  0.003223791718482971\n",
      "\n",
      "The classification loss after processing this batch is:  0.2672306001186371\n",
      "The representation loss after processing this batch is:  0.0034042075276374817\n",
      "\n",
      "The classification loss after processing this batch is:  0.22349904477596283\n",
      "The representation loss after processing this batch is:  0.0040218159556388855\n",
      "\n",
      "The classification loss after processing this batch is:  0.2283918410539627\n",
      "The representation loss after processing this batch is:  0.00359194353222847\n",
      "\n",
      "The classification loss after processing this batch is:  0.1926811784505844\n",
      "The representation loss after processing this batch is:  0.003031104803085327\n",
      "\n",
      "The classification loss after processing this batch is:  0.2925788462162018\n",
      "The representation loss after processing this batch is:  0.003064781427383423\n",
      "\n",
      "The classification loss after processing this batch is:  0.19846399128437042\n",
      "The representation loss after processing this batch is:  0.0032973214983940125\n",
      "\n",
      "The classification loss after processing this batch is:  0.25697341561317444\n",
      "The representation loss after processing this batch is:  0.0029511526226997375\n",
      "\n",
      "The classification loss after processing this batch is:  0.20928992331027985\n",
      "The representation loss after processing this batch is:  0.003181375563144684\n",
      "\n",
      "The classification loss after processing this batch is:  0.17857733368873596\n",
      "The representation loss after processing this batch is:  0.0034176334738731384\n",
      "\n",
      "The classification loss after processing this batch is:  0.1282704770565033\n",
      "The representation loss after processing this batch is:  0.003408297896385193\n",
      "\n",
      "The classification loss after processing this batch is:  0.3012739419937134\n",
      "The representation loss after processing this batch is:  0.0031042098999023438\n",
      "\n",
      "The classification loss after processing this batch is:  0.413889080286026\n",
      "The representation loss after processing this batch is:  0.0032853931188583374\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1885945349931717\n",
      "The representation loss after processing this batch is:  0.003299728035926819\n",
      "\n",
      "The classification loss after processing this batch is:  0.3428775668144226\n",
      "The representation loss after processing this batch is:  0.0035716593265533447\n",
      "\n",
      "The classification loss after processing this batch is:  0.2973051965236664\n",
      "The representation loss after processing this batch is:  0.0034048855304718018\n",
      "\n",
      "The classification loss after processing this batch is:  0.27892258763313293\n",
      "The representation loss after processing this batch is:  0.003523491322994232\n",
      "\n",
      "The classification loss after processing this batch is:  0.1450141966342926\n",
      "The representation loss after processing this batch is:  0.003167197108268738\n",
      "\n",
      "The classification loss after processing this batch is:  0.27773815393447876\n",
      "The representation loss after processing this batch is:  0.0031620673835277557\n",
      "\n",
      "The classification loss after processing this batch is:  0.2794809639453888\n",
      "The representation loss after processing this batch is:  0.0036272630095481873\n",
      "\n",
      "The classification loss after processing this batch is:  0.22459697723388672\n",
      "The representation loss after processing this batch is:  0.0034262873232364655\n",
      "\n",
      "The classification loss after processing this batch is:  0.09932618588209152\n",
      "The representation loss after processing this batch is:  0.003375709056854248\n",
      "\n",
      "The classification loss after processing this batch is:  0.1805933564901352\n",
      "The representation loss after processing this batch is:  0.0034875422716140747\n",
      "\n",
      "The classification loss after processing this batch is:  0.1878235787153244\n",
      "The representation loss after processing this batch is:  0.0034285634756088257\n",
      "\n",
      "The classification loss after processing this batch is:  0.21518628299236298\n",
      "The representation loss after processing this batch is:  0.0028754062950611115\n",
      "\n",
      "The classification loss after processing this batch is:  0.2736023962497711\n",
      "The representation loss after processing this batch is:  0.003218144178390503\n",
      "\n",
      "The classification loss after processing this batch is:  0.20257295668125153\n",
      "The representation loss after processing this batch is:  0.002923976629972458\n",
      "\n",
      "The classification loss after processing this batch is:  0.2106960266828537\n",
      "The representation loss after processing this batch is:  0.004211772233247757\n",
      "\n",
      "The classification loss after processing this batch is:  0.2548995316028595\n",
      "The representation loss after processing this batch is:  0.0037928372621536255\n",
      "\n",
      "The classification loss after processing this batch is:  0.1977771818637848\n",
      "The representation loss after processing this batch is:  0.004358187317848206\n",
      "\n",
      "The classification loss after processing this batch is:  0.15273253619670868\n",
      "The representation loss after processing this batch is:  0.0034286901354789734\n",
      "\n",
      "The classification loss after processing this batch is:  0.35670292377471924\n",
      "The representation loss after processing this batch is:  0.003543853759765625\n",
      "\n",
      "The classification loss after processing this batch is:  0.26858511567115784\n",
      "The representation loss after processing this batch is:  0.003687061369419098\n",
      "\n",
      "The classification loss after processing this batch is:  0.2103855460882187\n",
      "The representation loss after processing this batch is:  0.003589935600757599\n",
      "\n",
      "The classification loss after processing this batch is:  0.18404392898082733\n",
      "The representation loss after processing this batch is:  0.003100905567407608\n",
      "\n",
      "The classification loss after processing this batch is:  0.16909068822860718\n",
      "The representation loss after processing this batch is:  0.0028313323855400085\n",
      "\n",
      "The classification loss after processing this batch is:  0.1786242574453354\n",
      "The representation loss after processing this batch is:  0.0034100785851478577\n",
      "\n",
      "The classification loss after processing this batch is:  0.19378095865249634\n",
      "The representation loss after processing this batch is:  0.0031070299446582794\n",
      "\n",
      "The classification loss after processing this batch is:  0.37992143630981445\n",
      "The representation loss after processing this batch is:  0.0033649876713752747\n",
      "\n",
      "The classification loss after processing this batch is:  0.3189605176448822\n",
      "The representation loss after processing this batch is:  0.003419220447540283\n",
      "\n",
      "The classification loss after processing this batch is:  0.19967468082904816\n",
      "The representation loss after processing this batch is:  0.0029156170785427094\n",
      "\n",
      "The classification loss after processing this batch is:  0.21767285466194153\n",
      "The representation loss after processing this batch is:  0.003088913857936859\n",
      "\n",
      "The classification loss after processing this batch is:  0.2150750756263733\n",
      "The representation loss after processing this batch is:  0.002796158194541931\n",
      "\n",
      "The classification loss after processing this batch is:  0.22838881611824036\n",
      "The representation loss after processing this batch is:  0.003218378871679306\n",
      "\n",
      "The classification loss after processing this batch is:  0.29976412653923035\n",
      "The representation loss after processing this batch is:  0.003450196236371994\n",
      "\n",
      "The classification loss after processing this batch is:  0.23563596606254578\n",
      "The representation loss after processing this batch is:  0.0027851350605487823\n",
      "\n",
      "The classification loss after processing this batch is:  0.330352783203125\n",
      "The representation loss after processing this batch is:  0.003306761384010315\n",
      "\n",
      "The classification loss after processing this batch is:  0.23136290907859802\n",
      "The representation loss after processing this batch is:  0.0030000507831573486\n",
      "\n",
      "The classification loss after processing this batch is:  0.1053507849574089\n",
      "The representation loss after processing this batch is:  0.003967359662055969\n",
      "\n",
      "The classification loss after processing this batch is:  0.23714180290699005\n",
      "The representation loss after processing this batch is:  0.0031774453818798065\n",
      "\n",
      "The classification loss after processing this batch is:  0.1799420714378357\n",
      "The representation loss after processing this batch is:  0.003270745277404785\n",
      "\n",
      "The classification loss after processing this batch is:  0.25802791118621826\n",
      "The representation loss after processing this batch is:  0.003362111747264862\n",
      "\n",
      "The classification loss after processing this batch is:  0.23899182677268982\n",
      "The representation loss after processing this batch is:  0.0028038397431373596\n",
      "\n",
      "The classification loss after processing this batch is:  0.2517055869102478\n",
      "The representation loss after processing this batch is:  0.0031881183385849\n",
      "\n",
      "The classification loss after processing this batch is:  0.21544581651687622\n",
      "The representation loss after processing this batch is:  0.003281012177467346\n",
      "\n",
      "The classification loss after processing this batch is:  0.2688794434070587\n",
      "The representation loss after processing this batch is:  0.003245048224925995\n",
      "\n",
      "The classification loss after processing this batch is:  0.32492414116859436\n",
      "The representation loss after processing this batch is:  0.0030456632375717163\n",
      "\n",
      "The classification loss after processing this batch is:  0.3444972336292267\n",
      "The representation loss after processing this batch is:  0.002842739224433899\n",
      "\n",
      "The classification loss after processing this batch is:  0.2515527009963989\n",
      "The representation loss after processing this batch is:  0.0032072365283966064\n",
      "\n",
      "The classification loss after processing this batch is:  0.12876294553279877\n",
      "The representation loss after processing this batch is:  0.0036328956484794617\n",
      "\n",
      "The classification loss after processing this batch is:  0.07743025571107864\n",
      "The representation loss after processing this batch is:  0.003442615270614624\n",
      "\n",
      "The classification loss after processing this batch is:  0.2144656479358673\n",
      "The representation loss after processing this batch is:  0.0035711005330085754\n",
      "\n",
      "The classification loss after processing this batch is:  0.14565469324588776\n",
      "The representation loss after processing this batch is:  0.004930905997753143\n",
      "\n",
      "The classification loss after processing this batch is:  0.25918930768966675\n",
      "The representation loss after processing this batch is:  0.002955719828605652\n",
      "\n",
      "The classification loss after processing this batch is:  0.15221388638019562\n",
      "The representation loss after processing this batch is:  0.0035977959632873535\n",
      "\n",
      "The classification loss after processing this batch is:  0.26099953055381775\n",
      "The representation loss after processing this batch is:  0.0032613277435302734\n",
      "\n",
      "The classification loss after processing this batch is:  0.09180286526679993\n",
      "The representation loss after processing this batch is:  0.003321327269077301\n",
      "\n",
      "The classification loss after processing this batch is:  0.23474937677383423\n",
      "The representation loss after processing this batch is:  0.0033919401466846466\n",
      "\n",
      "The classification loss after processing this batch is:  0.22481918334960938\n",
      "The representation loss after processing this batch is:  0.003488890826702118\n",
      "\n",
      "The classification loss after processing this batch is:  0.24571718275547028\n",
      "The representation loss after processing this batch is:  0.0036708563566207886\n",
      "\n",
      "The classification loss after processing this batch is:  0.2056160271167755\n",
      "The representation loss after processing this batch is:  0.0035643205046653748\n",
      "\n",
      "The classification loss after processing this batch is:  0.1307690590620041\n",
      "The representation loss after processing this batch is:  0.003104615956544876\n",
      "\n",
      "The classification loss after processing this batch is:  0.1873856484889984\n",
      "The representation loss after processing this batch is:  0.0034070834517478943\n",
      "\n",
      "The classification loss after processing this batch is:  0.2024683803319931\n",
      "The representation loss after processing this batch is:  0.0030256807804107666\n",
      "\n",
      "The classification loss after processing this batch is:  0.20888391137123108\n",
      "The representation loss after processing this batch is:  0.003398030996322632\n",
      "\n",
      "The classification loss after processing this batch is:  0.15871955454349518\n",
      "The representation loss after processing this batch is:  0.0031702443957328796\n",
      "\n",
      "The classification loss after processing this batch is:  0.1403510868549347\n",
      "The representation loss after processing this batch is:  0.003380812704563141\n",
      "\n",
      "The classification loss after processing this batch is:  0.0900714173913002\n",
      "The representation loss after processing this batch is:  0.0033333972096443176\n",
      "\n",
      "The classification loss after processing this batch is:  0.13507205247879028\n",
      "The representation loss after processing this batch is:  0.0035637319087982178\n",
      "\n",
      "The classification loss after processing this batch is:  0.11107688397169113\n",
      "The representation loss after processing this batch is:  0.003531038761138916\n",
      "\n",
      "The classification loss after processing this batch is:  0.22930018603801727\n",
      "The representation loss after processing this batch is:  0.0031065866351127625\n",
      "\n",
      "The classification loss after processing this batch is:  0.14024662971496582\n",
      "The representation loss after processing this batch is:  0.0028645768761634827\n",
      "\n",
      "The classification loss after processing this batch is:  0.1248641237616539\n",
      "The representation loss after processing this batch is:  0.002955131232738495\n",
      "\n",
      "The classification loss after processing this batch is:  0.1737024337053299\n",
      "The representation loss after processing this batch is:  0.003577493131160736\n",
      "\n",
      "The classification loss after processing this batch is:  0.1912514865398407\n",
      "The representation loss after processing this batch is:  0.0032875239849090576\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.13268350064754486\n",
      "The representation loss after processing this batch is:  0.0034064874053001404\n",
      "\n",
      "The classification loss after processing this batch is:  0.14689655601978302\n",
      "The representation loss after processing this batch is:  0.0032081007957458496\n",
      "\n",
      "The classification loss after processing this batch is:  0.11362399905920029\n",
      "The representation loss after processing this batch is:  0.002940163016319275\n",
      "\n",
      "The classification loss after processing this batch is:  0.11783022433519363\n",
      "The representation loss after processing this batch is:  0.00337962806224823\n",
      "\n",
      "The classification loss after processing this batch is:  0.19716185331344604\n",
      "The representation loss after processing this batch is:  0.0033421143889427185\n",
      "\n",
      "The classification loss after processing this batch is:  0.20132191479206085\n",
      "The representation loss after processing this batch is:  0.003609895706176758\n",
      "\n",
      "The classification loss after processing this batch is:  0.12518265843391418\n",
      "The representation loss after processing this batch is:  0.003399081528186798\n",
      "\n",
      "The classification loss after processing this batch is:  0.25060856342315674\n",
      "The representation loss after processing this batch is:  0.0036888569593429565\n",
      "\n",
      "The classification loss after processing this batch is:  0.1551433652639389\n",
      "The representation loss after processing this batch is:  0.003314375877380371\n",
      "\n",
      "The classification loss after processing this batch is:  0.20661510527133942\n",
      "The representation loss after processing this batch is:  0.003085140138864517\n",
      "\n",
      "The classification loss after processing this batch is:  0.22377896308898926\n",
      "The representation loss after processing this batch is:  0.0038520433008670807\n",
      "\n",
      "The classification loss after processing this batch is:  0.14267724752426147\n",
      "The representation loss after processing this batch is:  0.0038255825638771057\n",
      "\n",
      "The classification loss after processing this batch is:  0.3093138635158539\n",
      "The representation loss after processing this batch is:  0.003377668559551239\n",
      "\n",
      "The classification loss after processing this batch is:  0.22538061439990997\n",
      "The representation loss after processing this batch is:  0.0026297420263290405\n",
      "\n",
      "The classification loss after processing this batch is:  0.19337408244609833\n",
      "The representation loss after processing this batch is:  0.003230348229408264\n",
      "\n",
      "The classification loss after processing this batch is:  0.2205863893032074\n",
      "The representation loss after processing this batch is:  0.003198683261871338\n",
      "\n",
      "The classification loss after processing this batch is:  0.17179571092128754\n",
      "The representation loss after processing this batch is:  0.00336475670337677\n",
      "\n",
      "The classification loss after processing this batch is:  0.1869821548461914\n",
      "The representation loss after processing this batch is:  0.002718273550271988\n",
      "\n",
      "The classification loss after processing this batch is:  0.19163089990615845\n",
      "The representation loss after processing this batch is:  0.0029327720403671265\n",
      "\n",
      "The classification loss after processing this batch is:  0.2597028613090515\n",
      "The representation loss after processing this batch is:  0.0032749027013778687\n",
      "\n",
      "The classification loss after processing this batch is:  0.2402297407388687\n",
      "The representation loss after processing this batch is:  0.0032963231205940247\n",
      "\n",
      "The classification loss after processing this batch is:  0.13738292455673218\n",
      "The representation loss after processing this batch is:  0.002840772271156311\n",
      "\n",
      "The classification loss after processing this batch is:  0.15064947307109833\n",
      "The representation loss after processing this batch is:  0.003100261092185974\n",
      "\n",
      "The classification loss after processing this batch is:  0.26537585258483887\n",
      "The representation loss after processing this batch is:  0.002831600606441498\n",
      "\n",
      "The classification loss after processing this batch is:  0.14245916903018951\n",
      "The representation loss after processing this batch is:  0.003140375018119812\n",
      "\n",
      "The classification loss after processing this batch is:  0.21717996895313263\n",
      "The representation loss after processing this batch is:  0.003383167088031769\n",
      "\n",
      "The classification loss after processing this batch is:  0.2395901381969452\n",
      "The representation loss after processing this batch is:  0.0030582770705223083\n",
      "\n",
      "The classification loss after processing this batch is:  0.11817913502454758\n",
      "The representation loss after processing this batch is:  0.0036190971732139587\n",
      "\n",
      "The classification loss after processing this batch is:  0.13242335617542267\n",
      "The representation loss after processing this batch is:  0.0028762072324752808\n",
      "\n",
      "The classification loss after processing this batch is:  0.18252117931842804\n",
      "The representation loss after processing this batch is:  0.0033985599875450134\n",
      "\n",
      "The classification loss after processing this batch is:  0.18412278592586517\n",
      "The representation loss after processing this batch is:  0.0032358914613723755\n",
      "\n",
      "The classification loss after processing this batch is:  0.21508322656154633\n",
      "The representation loss after processing this batch is:  0.0035183802247047424\n",
      "\n",
      "The classification loss after processing this batch is:  0.2362210750579834\n",
      "The representation loss after processing this batch is:  0.0038470886647701263\n",
      "\n",
      "The classification loss after processing this batch is:  0.15700316429138184\n",
      "The representation loss after processing this batch is:  0.0029388442635536194\n",
      "\n",
      "The classification loss after processing this batch is:  0.22889100015163422\n",
      "The representation loss after processing this batch is:  0.0025940313935279846\n",
      "\n",
      "The classification loss after processing this batch is:  0.20574894547462463\n",
      "The representation loss after processing this batch is:  0.0032812729477882385\n",
      "\n",
      "The classification loss after processing this batch is:  0.09276188910007477\n",
      "The representation loss after processing this batch is:  0.003550387918949127\n",
      "\n",
      "The classification loss after processing this batch is:  0.136916384100914\n",
      "The representation loss after processing this batch is:  0.0032760314643383026\n",
      "\n",
      "The classification loss after processing this batch is:  0.17130158841609955\n",
      "The representation loss after processing this batch is:  0.0031420886516571045\n",
      "\n",
      "The classification loss after processing this batch is:  0.15466342866420746\n",
      "The representation loss after processing this batch is:  0.0033704042434692383\n",
      "\n",
      "The classification loss after processing this batch is:  0.1661386787891388\n",
      "The representation loss after processing this batch is:  0.0031846612691879272\n",
      "\n",
      "The classification loss after processing this batch is:  0.20329898595809937\n",
      "The representation loss after processing this batch is:  0.003522183746099472\n",
      "\n",
      "The classification loss after processing this batch is:  0.18264009058475494\n",
      "The representation loss after processing this batch is:  0.003855764865875244\n",
      "\n",
      "The classification loss after processing this batch is:  0.14209671318531036\n",
      "The representation loss after processing this batch is:  0.003612145781517029\n",
      "\n",
      "The classification loss after processing this batch is:  0.2410430610179901\n",
      "The representation loss after processing this batch is:  0.0031778141856193542\n",
      "\n",
      "The classification loss after processing this batch is:  0.24234037101268768\n",
      "The representation loss after processing this batch is:  0.0030283257365226746\n",
      "\n",
      "The classification loss after processing this batch is:  0.24726733565330505\n",
      "The representation loss after processing this batch is:  0.0032713860273361206\n",
      "\n",
      "The classification loss after processing this batch is:  0.14179936051368713\n",
      "The representation loss after processing this batch is:  0.0032399892807006836\n",
      "\n",
      "The classification loss after processing this batch is:  0.12510889768600464\n",
      "The representation loss after processing this batch is:  0.0030572712421417236\n",
      "\n",
      "The classification loss after processing this batch is:  0.2846415936946869\n",
      "The representation loss after processing this batch is:  0.0028784796595573425\n",
      "\n",
      "The classification loss after processing this batch is:  0.29272395372390747\n",
      "The representation loss after processing this batch is:  0.002870231866836548\n",
      "\n",
      "The classification loss after processing this batch is:  0.2775031626224518\n",
      "The representation loss after processing this batch is:  0.0031563714146614075\n",
      "\n",
      "The classification loss after processing this batch is:  0.22805802524089813\n",
      "The representation loss after processing this batch is:  0.0030780062079429626\n",
      "\n",
      "The classification loss after processing this batch is:  0.23900346457958221\n",
      "The representation loss after processing this batch is:  0.0029948875308036804\n",
      "\n",
      "The classification loss after processing this batch is:  0.2839019000530243\n",
      "The representation loss after processing this batch is:  0.002904631197452545\n",
      "\n",
      "The classification loss after processing this batch is:  0.29187366366386414\n",
      "The representation loss after processing this batch is:  0.003010418266057968\n",
      "\n",
      "The classification loss after processing this batch is:  0.29259347915649414\n",
      "The representation loss after processing this batch is:  0.003218606114387512\n",
      "\n",
      "The classification loss after processing this batch is:  0.28818437457084656\n",
      "The representation loss after processing this batch is:  0.003299601376056671\n",
      "\n",
      "The classification loss after processing this batch is:  0.1689434051513672\n",
      "The representation loss after processing this batch is:  0.003664374351501465\n",
      "\n",
      "The classification loss after processing this batch is:  0.10503346472978592\n",
      "The representation loss after processing this batch is:  0.003278374671936035\n",
      "\n",
      "The classification loss after processing this batch is:  0.20969384908676147\n",
      "The representation loss after processing this batch is:  0.003655537962913513\n",
      "\n",
      "The classification loss after processing this batch is:  0.19563886523246765\n",
      "The representation loss after processing this batch is:  0.0029662176966667175\n",
      "\n",
      "The classification loss after processing this batch is:  0.1290254145860672\n",
      "The representation loss after processing this batch is:  0.002787221223115921\n",
      "\n",
      "The classification loss after processing this batch is:  0.17688967287540436\n",
      "The representation loss after processing this batch is:  0.003260653465986252\n",
      "\n",
      "The classification loss after processing this batch is:  0.17311064898967743\n",
      "The representation loss after processing this batch is:  0.0030147433280944824\n",
      "\n",
      "The classification loss after processing this batch is:  0.18281887471675873\n",
      "The representation loss after processing this batch is:  0.002972438931465149\n",
      "\n",
      "The classification loss after processing this batch is:  0.18170808255672455\n",
      "The representation loss after processing this batch is:  0.0033198706805706024\n",
      "\n",
      "The classification loss after processing this batch is:  0.16230101883411407\n",
      "The representation loss after processing this batch is:  0.0028194785118103027\n",
      "\n",
      "The classification loss after processing this batch is:  0.15222857892513275\n",
      "The representation loss after processing this batch is:  0.0031669214367866516\n",
      "\n",
      "The classification loss after processing this batch is:  0.21948735415935516\n",
      "The representation loss after processing this batch is:  0.0031446069478988647\n",
      "\n",
      "The classification loss after processing this batch is:  0.21255527436733246\n",
      "The representation loss after processing this batch is:  0.0033004507422447205\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2355474829673767\n",
      "The representation loss after processing this batch is:  0.003957338631153107\n",
      "\n",
      "The classification loss after processing this batch is:  0.1537773162126541\n",
      "The representation loss after processing this batch is:  0.003001689910888672\n",
      "\n",
      "The classification loss after processing this batch is:  0.12274745106697083\n",
      "The representation loss after processing this batch is:  0.0035117343068122864\n",
      "\n",
      "The classification loss after processing this batch is:  0.2101619690656662\n",
      "The representation loss after processing this batch is:  0.0029177963733673096\n",
      "\n",
      "The classification loss after processing this batch is:  0.3193896412849426\n",
      "The representation loss after processing this batch is:  0.002755865454673767\n",
      "\n",
      "The classification loss after processing this batch is:  0.18718194961547852\n",
      "The representation loss after processing this batch is:  0.0031083151698112488\n",
      "\n",
      "The classification loss after processing this batch is:  0.11244221776723862\n",
      "The representation loss after processing this batch is:  0.003128349781036377\n",
      "\n",
      "The classification loss after processing this batch is:  0.207554891705513\n",
      "The representation loss after processing this batch is:  0.003014475107192993\n",
      "\n",
      "The classification loss after processing this batch is:  0.07112445682287216\n",
      "The representation loss after processing this batch is:  0.0031920671463012695\n",
      "\n",
      "The classification loss after processing this batch is:  0.21258217096328735\n",
      "The representation loss after processing this batch is:  0.0030836760997772217\n",
      "\n",
      "The classification loss after processing this batch is:  0.2119375616312027\n",
      "The representation loss after processing this batch is:  0.0035830140113830566\n",
      "\n",
      "The classification loss after processing this batch is:  0.11620893329381943\n",
      "The representation loss after processing this batch is:  0.0032389238476753235\n",
      "\n",
      "The classification loss after processing this batch is:  0.1520623415708542\n",
      "The representation loss after processing this batch is:  0.0034830570220947266\n",
      "\n",
      "The classification loss after processing this batch is:  0.14796733856201172\n",
      "The representation loss after processing this batch is:  0.0031219646334648132\n",
      "\n",
      "The classification loss after processing this batch is:  0.09906478226184845\n",
      "The representation loss after processing this batch is:  0.003371402621269226\n",
      "\n",
      "The classification loss after processing this batch is:  0.32618582248687744\n",
      "The representation loss after processing this batch is:  0.003008481115102768\n",
      "\n",
      "The classification loss after processing this batch is:  0.3211687207221985\n",
      "The representation loss after processing this batch is:  0.00292142853140831\n",
      "\n",
      "The classification loss after processing this batch is:  0.2611260712146759\n",
      "The representation loss after processing this batch is:  0.0029944032430648804\n",
      "\n",
      "The classification loss after processing this batch is:  0.2957439422607422\n",
      "The representation loss after processing this batch is:  0.0029415972530841827\n",
      "\n",
      "The classification loss after processing this batch is:  0.19608815014362335\n",
      "The representation loss after processing this batch is:  0.0031935125589370728\n",
      "\n",
      "The classification loss after processing this batch is:  0.1731242835521698\n",
      "The representation loss after processing this batch is:  0.003076121211051941\n",
      "\n",
      "The classification loss after processing this batch is:  0.2934427857398987\n",
      "The representation loss after processing this batch is:  0.003031022846698761\n",
      "\n",
      "The classification loss after processing this batch is:  0.1679958999156952\n",
      "The representation loss after processing this batch is:  0.0031914375722408295\n",
      "\n",
      "The classification loss after processing this batch is:  0.2458506077528\n",
      "The representation loss after processing this batch is:  0.0032898783683776855\n",
      "\n",
      "The classification loss after processing this batch is:  0.1916676163673401\n",
      "The representation loss after processing this batch is:  0.0033152401447296143\n",
      "\n",
      "The classification loss after processing this batch is:  0.24437515437602997\n",
      "The representation loss after processing this batch is:  0.002695564180612564\n",
      "\n",
      "The classification loss after processing this batch is:  0.19080615043640137\n",
      "The representation loss after processing this batch is:  0.00301925465464592\n",
      "\n",
      "The classification loss after processing this batch is:  0.16825005412101746\n",
      "The representation loss after processing this batch is:  0.0030799806118011475\n",
      "\n",
      "The classification loss after processing this batch is:  0.21149644255638123\n",
      "The representation loss after processing this batch is:  0.00331096351146698\n",
      "\n",
      "The classification loss after processing this batch is:  0.12421594560146332\n",
      "The representation loss after processing this batch is:  0.003415532410144806\n",
      "\n",
      "The classification loss after processing this batch is:  0.10996206104755402\n",
      "The representation loss after processing this batch is:  0.002729330211877823\n",
      "\n",
      "The classification loss after processing this batch is:  0.184087336063385\n",
      "The representation loss after processing this batch is:  0.003191724419593811\n",
      "\n",
      "The classification loss after processing this batch is:  0.24993818998336792\n",
      "The representation loss after processing this batch is:  0.003154762089252472\n",
      "\n",
      "The classification loss after processing this batch is:  0.09719385206699371\n",
      "The representation loss after processing this batch is:  0.0030964314937591553\n",
      "\n",
      "The classification loss after processing this batch is:  0.1238156259059906\n",
      "The representation loss after processing this batch is:  0.0027844496071338654\n",
      "\n",
      "The classification loss after processing this batch is:  0.23237785696983337\n",
      "The representation loss after processing this batch is:  0.0033862516283988953\n",
      "\n",
      "The classification loss after processing this batch is:  0.19983485341072083\n",
      "The representation loss after processing this batch is:  0.003024466335773468\n",
      "\n",
      "The classification loss after processing this batch is:  0.19215942919254303\n",
      "The representation loss after processing this batch is:  0.0031558647751808167\n",
      "\n",
      "The classification loss after processing this batch is:  0.30940812826156616\n",
      "The representation loss after processing this batch is:  0.0028939247131347656\n",
      "\n",
      "The classification loss after processing this batch is:  0.12761364877223969\n",
      "The representation loss after processing this batch is:  0.003590621054172516\n",
      "\n",
      "The classification loss after processing this batch is:  0.09785852581262589\n",
      "The representation loss after processing this batch is:  0.0030211322009563446\n",
      "\n",
      "The classification loss after processing this batch is:  0.10450121015310287\n",
      "The representation loss after processing this batch is:  0.0035137757658958435\n",
      "\n",
      "The classification loss after processing this batch is:  0.19595174491405487\n",
      "The representation loss after processing this batch is:  0.0036891549825668335\n",
      "\n",
      "The classification loss after processing this batch is:  0.20143328607082367\n",
      "The representation loss after processing this batch is:  0.0032656118273735046\n",
      "\n",
      "The classification loss after processing this batch is:  0.15216395258903503\n",
      "The representation loss after processing this batch is:  0.0033991336822509766\n",
      "\n",
      "The classification loss after processing this batch is:  0.17405472695827484\n",
      "The representation loss after processing this batch is:  0.003028370440006256\n",
      "\n",
      "The classification loss after processing this batch is:  0.15717755258083344\n",
      "The representation loss after processing this batch is:  0.0031728409230709076\n",
      "\n",
      "The classification loss after processing this batch is:  0.16284707188606262\n",
      "The representation loss after processing this batch is:  0.0032648853957653046\n",
      "\n",
      "The classification loss after processing this batch is:  0.18274497985839844\n",
      "The representation loss after processing this batch is:  0.003478739410638809\n",
      "\n",
      "The classification loss after processing this batch is:  0.24634726345539093\n",
      "The representation loss after processing this batch is:  0.003189925104379654\n",
      "\n",
      "The classification loss after processing this batch is:  0.21350452303886414\n",
      "The representation loss after processing this batch is:  0.003743208944797516\n",
      "\n",
      "The classification loss after processing this batch is:  0.33132097125053406\n",
      "The representation loss after processing this batch is:  0.002994336187839508\n",
      "\n",
      "The classification loss after processing this batch is:  0.2714212238788605\n",
      "The representation loss after processing this batch is:  0.0030186958611011505\n",
      "\n",
      "The classification loss after processing this batch is:  0.23353616893291473\n",
      "The representation loss after processing this batch is:  0.003364764153957367\n",
      "\n",
      "The classification loss after processing this batch is:  0.24160824716091156\n",
      "The representation loss after processing this batch is:  0.003308221697807312\n",
      "\n",
      "The classification loss after processing this batch is:  0.07887744903564453\n",
      "The representation loss after processing this batch is:  0.0030346065759658813\n",
      "\n",
      "The classification loss after processing this batch is:  0.1753990203142166\n",
      "The representation loss after processing this batch is:  0.0039772652089595795\n",
      "\n",
      "The classification loss after processing this batch is:  0.1621650606393814\n",
      "The representation loss after processing this batch is:  0.0035996288061141968\n",
      "\n",
      "The classification loss after processing this batch is:  0.1692078560590744\n",
      "The representation loss after processing this batch is:  0.003408491611480713\n",
      "\n",
      "The classification loss after processing this batch is:  0.21671605110168457\n",
      "The representation loss after processing this batch is:  0.002690490335226059\n",
      "\n",
      "The classification loss after processing this batch is:  0.15919192135334015\n",
      "The representation loss after processing this batch is:  0.002944380044937134\n",
      "\n",
      "The classification loss after processing this batch is:  0.2144729495048523\n",
      "The representation loss after processing this batch is:  0.0028487369418144226\n",
      "\n",
      "The classification loss after processing this batch is:  0.2456328123807907\n",
      "The representation loss after processing this batch is:  0.002780809998512268\n",
      "\n",
      "The classification loss after processing this batch is:  0.2235657125711441\n",
      "The representation loss after processing this batch is:  0.003345400094985962\n",
      "\n",
      "The classification loss after processing this batch is:  0.3058829605579376\n",
      "The representation loss after processing this batch is:  0.0034119412302970886\n",
      "\n",
      "The classification loss after processing this batch is:  0.17436456680297852\n",
      "The representation loss after processing this batch is:  0.0031042173504829407\n",
      "\n",
      "The classification loss after processing this batch is:  0.22569938004016876\n",
      "The representation loss after processing this batch is:  0.0027935691177845\n",
      "\n",
      "The classification loss after processing this batch is:  0.15164661407470703\n",
      "The representation loss after processing this batch is:  0.0034170597791671753\n",
      "\n",
      "The classification loss after processing this batch is:  0.30522409081459045\n",
      "The representation loss after processing this batch is:  0.0031785741448402405\n",
      "\n",
      "The classification loss after processing this batch is:  0.2928120195865631\n",
      "The representation loss after processing this batch is:  0.003640972077846527\n",
      "\n",
      "The classification loss after processing this batch is:  0.09687410295009613\n",
      "The representation loss after processing this batch is:  0.002725847065448761\n",
      "\n",
      "The classification loss after processing this batch is:  0.11852729320526123\n",
      "The representation loss after processing this batch is:  0.003130011260509491\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2862902879714966\n",
      "The representation loss after processing this batch is:  0.002951432019472122\n",
      "\n",
      "The classification loss after processing this batch is:  0.10411146283149719\n",
      "The representation loss after processing this batch is:  0.0031725019216537476\n",
      "\n",
      "The classification loss after processing this batch is:  0.19798310101032257\n",
      "The representation loss after processing this batch is:  0.0030117854475975037\n",
      "\n",
      "The classification loss after processing this batch is:  0.2260427474975586\n",
      "The representation loss after processing this batch is:  0.003107137978076935\n",
      "\n",
      "The classification loss after processing this batch is:  0.1855299174785614\n",
      "The representation loss after processing this batch is:  0.0033134371042251587\n",
      "\n",
      "The classification loss after processing this batch is:  0.3192365765571594\n",
      "The representation loss after processing this batch is:  0.0036269724369049072\n",
      "\n",
      "The classification loss after processing this batch is:  0.23784221708774567\n",
      "The representation loss after processing this batch is:  0.003126777708530426\n",
      "\n",
      "The classification loss after processing this batch is:  0.2393050491809845\n",
      "The representation loss after processing this batch is:  0.0036292672157287598\n",
      "\n",
      "The classification loss after processing this batch is:  0.1640862375497818\n",
      "The representation loss after processing this batch is:  0.0029767826199531555\n",
      "\n",
      "The classification loss after processing this batch is:  0.25108757615089417\n",
      "The representation loss after processing this batch is:  0.0027803145349025726\n",
      "\n",
      "The classification loss after processing this batch is:  0.10415074229240417\n",
      "The representation loss after processing this batch is:  0.003173932433128357\n",
      "\n",
      "The classification loss after processing this batch is:  0.09159738570451736\n",
      "The representation loss after processing this batch is:  0.0029204711318016052\n",
      "\n",
      "The classification loss after processing this batch is:  0.11252734065055847\n",
      "The representation loss after processing this batch is:  0.0030275359749794006\n",
      "\n",
      "The classification loss after processing this batch is:  0.09760214388370514\n",
      "The representation loss after processing this batch is:  0.0029986798763275146\n",
      "\n",
      "The classification loss after processing this batch is:  0.16583947837352753\n",
      "The representation loss after processing this batch is:  0.003075122833251953\n",
      "\n",
      "The classification loss after processing this batch is:  0.11852232366800308\n",
      "The representation loss after processing this batch is:  0.0029512494802474976\n",
      "\n",
      "The classification loss after processing this batch is:  0.13289882242679596\n",
      "The representation loss after processing this batch is:  0.0028400495648384094\n",
      "\n",
      "The classification loss after processing this batch is:  0.1746128350496292\n",
      "The representation loss after processing this batch is:  0.003252040594816208\n",
      "\n",
      "The classification loss after processing this batch is:  0.25404176115989685\n",
      "The representation loss after processing this batch is:  0.0032484084367752075\n",
      "\n",
      "The classification loss after processing this batch is:  0.24637769162654877\n",
      "The representation loss after processing this batch is:  0.0029611513018608093\n",
      "\n",
      "The classification loss after processing this batch is:  0.20024815201759338\n",
      "The representation loss after processing this batch is:  0.003180675208568573\n",
      "\n",
      "The classification loss after processing this batch is:  0.2604893147945404\n",
      "The representation loss after processing this batch is:  0.003124777227640152\n",
      "\n",
      "The classification loss after processing this batch is:  0.16496674716472626\n",
      "The representation loss after processing this batch is:  0.0029609277844429016\n",
      "\n",
      "The classification loss after processing this batch is:  0.2110505849123001\n",
      "The representation loss after processing this batch is:  0.003262266516685486\n",
      "\n",
      "The classification loss after processing this batch is:  0.3274134695529938\n",
      "The representation loss after processing this batch is:  0.0031556859612464905\n",
      "\n",
      "The classification loss after processing this batch is:  0.15764020383358002\n",
      "The representation loss after processing this batch is:  0.0029249638319015503\n",
      "\n",
      "The classification loss after processing this batch is:  0.2868534028530121\n",
      "The representation loss after processing this batch is:  0.002927333116531372\n",
      "\n",
      "The classification loss after processing this batch is:  0.24640125036239624\n",
      "The representation loss after processing this batch is:  0.0030073150992393494\n",
      "\n",
      "The classification loss after processing this batch is:  0.23036950826644897\n",
      "The representation loss after processing this batch is:  0.003039468079805374\n",
      "\n",
      "The classification loss after processing this batch is:  0.16575226187705994\n",
      "The representation loss after processing this batch is:  0.0033044815063476562\n",
      "\n",
      "The classification loss after processing this batch is:  0.11253683269023895\n",
      "The representation loss after processing this batch is:  0.0029473602771759033\n",
      "\n",
      "The classification loss after processing this batch is:  0.14594285190105438\n",
      "The representation loss after processing this batch is:  0.002798505127429962\n",
      "\n",
      "The classification loss after processing this batch is:  0.11906098574399948\n",
      "The representation loss after processing this batch is:  0.003027908504009247\n",
      "\n",
      "The classification loss after processing this batch is:  0.10264000296592712\n",
      "The representation loss after processing this batch is:  0.002939864993095398\n",
      "\n",
      "The classification loss after processing this batch is:  0.2319650501012802\n",
      "The representation loss after processing this batch is:  0.003258518874645233\n",
      "\n",
      "The classification loss after processing this batch is:  0.11444880813360214\n",
      "The representation loss after processing this batch is:  0.0032563582062721252\n",
      "\n",
      "The classification loss after processing this batch is:  0.25919634103775024\n",
      "The representation loss after processing this batch is:  0.0035291165113449097\n",
      "\n",
      "The classification loss after processing this batch is:  0.16548863053321838\n",
      "The representation loss after processing this batch is:  0.003332763910293579\n",
      "\n",
      "The classification loss after processing this batch is:  0.23988667130470276\n",
      "The representation loss after processing this batch is:  0.0030434243381023407\n",
      "\n",
      "The classification loss after processing this batch is:  0.38368502259254456\n",
      "The representation loss after processing this batch is:  0.0027145445346832275\n",
      "\n",
      "The classification loss after processing this batch is:  0.2219211608171463\n",
      "The representation loss after processing this batch is:  0.0025688111782073975\n",
      "\n",
      "The classification loss after processing this batch is:  0.10455765575170517\n",
      "The representation loss after processing this batch is:  0.0030848123133182526\n",
      "\n",
      "The classification loss after processing this batch is:  0.12734343111515045\n",
      "The representation loss after processing this batch is:  0.0036383047699928284\n",
      "\n",
      "The classification loss after processing this batch is:  0.11724410206079483\n",
      "The representation loss after processing this batch is:  0.003423914313316345\n",
      "\n",
      "The classification loss after processing this batch is:  0.1395910233259201\n",
      "The representation loss after processing this batch is:  0.0030047744512557983\n",
      "\n",
      "The classification loss after processing this batch is:  0.13202112913131714\n",
      "The representation loss after processing this batch is:  0.0031176507472991943\n",
      "\n",
      "The classification loss after processing this batch is:  0.30428212881088257\n",
      "The representation loss after processing this batch is:  0.0030591674149036407\n",
      "\n",
      "The classification loss after processing this batch is:  0.2613026797771454\n",
      "The representation loss after processing this batch is:  0.003037739545106888\n",
      "\n",
      "The classification loss after processing this batch is:  0.20297008752822876\n",
      "The representation loss after processing this batch is:  0.0031946077942848206\n",
      "\n",
      "The classification loss after processing this batch is:  0.32533398270606995\n",
      "The representation loss after processing this batch is:  0.003758929669857025\n",
      "\n",
      "The classification loss after processing this batch is:  0.14649353921413422\n",
      "The representation loss after processing this batch is:  0.003170520067214966\n",
      "\n",
      "The classification loss after processing this batch is:  0.18471580743789673\n",
      "The representation loss after processing this batch is:  0.0030840225517749786\n",
      "\n",
      "The classification loss after processing this batch is:  0.2729162275791168\n",
      "The representation loss after processing this batch is:  0.003085322678089142\n",
      "\n",
      "The classification loss after processing this batch is:  0.1829841434955597\n",
      "The representation loss after processing this batch is:  0.003897670656442642\n",
      "\n",
      "The classification loss after processing this batch is:  0.19652196764945984\n",
      "The representation loss after processing this batch is:  0.0043705180287361145\n",
      "\n",
      "The classification loss after processing this batch is:  0.12725479900836945\n",
      "The representation loss after processing this batch is:  0.003748767077922821\n",
      "\n",
      "The classification loss after processing this batch is:  0.24110689759254456\n",
      "The representation loss after processing this batch is:  0.0038751736283302307\n",
      "\n",
      "The classification loss after processing this batch is:  0.23371943831443787\n",
      "The representation loss after processing this batch is:  0.003922387957572937\n",
      "\n",
      "The classification loss after processing this batch is:  0.16989129781723022\n",
      "The representation loss after processing this batch is:  0.003641568124294281\n",
      "\n",
      "The classification loss after processing this batch is:  0.20312850177288055\n",
      "The representation loss after processing this batch is:  0.0035751014947891235\n",
      "\n",
      "The classification loss after processing this batch is:  0.24406059086322784\n",
      "The representation loss after processing this batch is:  0.002981513738632202\n",
      "\n",
      "The classification loss after processing this batch is:  0.24463587999343872\n",
      "The representation loss after processing this batch is:  0.0026656389236450195\n",
      "\n",
      "The classification loss after processing this batch is:  0.22349180281162262\n",
      "The representation loss after processing this batch is:  0.00284547358751297\n",
      "\n",
      "The classification loss after processing this batch is:  0.1493344008922577\n",
      "The representation loss after processing this batch is:  0.003667861223220825\n",
      "\n",
      "The classification loss after processing this batch is:  0.06733402609825134\n",
      "The representation loss after processing this batch is:  0.0031215474009513855\n",
      "\n",
      "The classification loss after processing this batch is:  0.17701324820518494\n",
      "The representation loss after processing this batch is:  0.003208763897418976\n",
      "\n",
      "The classification loss after processing this batch is:  0.13341929018497467\n",
      "The representation loss after processing this batch is:  0.003255777060985565\n",
      "\n",
      "The classification loss after processing this batch is:  0.26846078038215637\n",
      "The representation loss after processing this batch is:  0.0028408095240592957\n",
      "\n",
      "The classification loss after processing this batch is:  0.1256827861070633\n",
      "The representation loss after processing this batch is:  0.0032449662685394287\n",
      "\n",
      "The classification loss after processing this batch is:  0.166032075881958\n",
      "The representation loss after processing this batch is:  0.002936147153377533\n",
      "\n",
      "The classification loss after processing this batch is:  0.21174338459968567\n",
      "The representation loss after processing this batch is:  0.0033571943640708923\n",
      "\n",
      "The classification loss after processing this batch is:  0.17697270214557648\n",
      "The representation loss after processing this batch is:  0.003036223351955414\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.22292956709861755\n",
      "The representation loss after processing this batch is:  0.0031353160738945007\n",
      "\n",
      "The classification loss after processing this batch is:  0.13545112311840057\n",
      "The representation loss after processing this batch is:  0.0029840394854545593\n",
      "\n",
      "The classification loss after processing this batch is:  0.14550800621509552\n",
      "The representation loss after processing this batch is:  0.002818979322910309\n",
      "\n",
      "The classification loss after processing this batch is:  0.15191151201725006\n",
      "The representation loss after processing this batch is:  0.0030937939882278442\n",
      "\n",
      "The classification loss after processing this batch is:  0.2422749549150467\n",
      "The representation loss after processing this batch is:  0.0037182122468948364\n",
      "\n",
      "The classification loss after processing this batch is:  0.2360859513282776\n",
      "The representation loss after processing this batch is:  0.0030868053436279297\n",
      "\n",
      "The classification loss after processing this batch is:  0.2251783162355423\n",
      "The representation loss after processing this batch is:  0.002836383879184723\n",
      "\n",
      "The classification loss after processing this batch is:  0.244894877076149\n",
      "The representation loss after processing this batch is:  0.003038167953491211\n",
      "\n",
      "The classification loss after processing this batch is:  0.329273521900177\n",
      "The representation loss after processing this batch is:  0.0030766911804676056\n",
      "\n",
      "The classification loss after processing this batch is:  0.1839206963777542\n",
      "The representation loss after processing this batch is:  0.0035374313592910767\n",
      "\n",
      "The classification loss after processing this batch is:  0.30285683274269104\n",
      "The representation loss after processing this batch is:  0.0030527040362358093\n",
      "\n",
      "The classification loss after processing this batch is:  0.18259623646736145\n",
      "The representation loss after processing this batch is:  0.0030792877078056335\n",
      "\n",
      "The classification loss after processing this batch is:  0.10814040154218674\n",
      "The representation loss after processing this batch is:  0.0031387582421302795\n",
      "\n",
      "The classification loss after processing this batch is:  0.07996886223554611\n",
      "The representation loss after processing this batch is:  0.0027118846774101257\n",
      "\n",
      "The classification loss after processing this batch is:  0.11011795699596405\n",
      "The representation loss after processing this batch is:  0.0032155364751815796\n",
      "\n",
      "The classification loss after processing this batch is:  0.286120742559433\n",
      "The representation loss after processing this batch is:  0.0033057406544685364\n",
      "\n",
      "The classification loss after processing this batch is:  0.13950398564338684\n",
      "The representation loss after processing this batch is:  0.0032997503876686096\n",
      "\n",
      "The classification loss after processing this batch is:  0.16378743946552277\n",
      "The representation loss after processing this batch is:  0.0031722933053970337\n",
      "\n",
      "The classification loss after processing this batch is:  0.21069888770580292\n",
      "The representation loss after processing this batch is:  0.003346487879753113\n",
      "\n",
      "The classification loss after processing this batch is:  0.15732768177986145\n",
      "The representation loss after processing this batch is:  0.0031060799956321716\n",
      "\n",
      "The classification loss after processing this batch is:  0.12170465290546417\n",
      "The representation loss after processing this batch is:  0.0029531344771385193\n",
      "\n",
      "The classification loss after processing this batch is:  0.21763595938682556\n",
      "The representation loss after processing this batch is:  0.0026975050568580627\n",
      "\n",
      "The classification loss after processing this batch is:  0.25117823481559753\n",
      "The representation loss after processing this batch is:  0.003000691533088684\n",
      "\n",
      "The classification loss after processing this batch is:  0.26360800862312317\n",
      "The representation loss after processing this batch is:  0.0031219273805618286\n",
      "\n",
      "The classification loss after processing this batch is:  0.11568985134363174\n",
      "The representation loss after processing this batch is:  0.0028989240527153015\n",
      "\n",
      "The classification loss after processing this batch is:  0.30106863379478455\n",
      "The representation loss after processing this batch is:  0.0029345788061618805\n",
      "\n",
      "The classification loss after processing this batch is:  0.14973142743110657\n",
      "The representation loss after processing this batch is:  0.002737760543823242\n",
      "\n",
      "The classification loss after processing this batch is:  0.2144290953874588\n",
      "The representation loss after processing this batch is:  0.0027138888835906982\n",
      "\n",
      "The classification loss after processing this batch is:  0.1896849274635315\n",
      "The representation loss after processing this batch is:  0.0032434090971946716\n",
      "\n",
      "The classification loss after processing this batch is:  0.14093290269374847\n",
      "The representation loss after processing this batch is:  0.0029093921184539795\n",
      "\n",
      "The classification loss after processing this batch is:  0.17976102232933044\n",
      "The representation loss after processing this batch is:  0.003079816699028015\n",
      "\n",
      "The classification loss after processing this batch is:  0.18968862295150757\n",
      "The representation loss after processing this batch is:  0.003440849483013153\n",
      "\n",
      "The classification loss after processing this batch is:  0.2603875994682312\n",
      "The representation loss after processing this batch is:  0.0033010095357894897\n",
      "\n",
      "The classification loss after processing this batch is:  0.3250865936279297\n",
      "The representation loss after processing this batch is:  0.0032771527767181396\n",
      "\n",
      "The classification loss after processing this batch is:  0.2766425907611847\n",
      "The representation loss after processing this batch is:  0.0031028836965560913\n",
      "\n",
      "The classification loss after processing this batch is:  0.20089738070964813\n",
      "The representation loss after processing this batch is:  0.0033039115369319916\n",
      "\n",
      "The classification loss after processing this batch is:  0.14691860973834991\n",
      "The representation loss after processing this batch is:  0.003430180251598358\n",
      "\n",
      "The classification loss after processing this batch is:  0.24973459541797638\n",
      "The representation loss after processing this batch is:  0.002695433795452118\n",
      "\n",
      "The classification loss after processing this batch is:  0.2155667394399643\n",
      "The representation loss after processing this batch is:  0.002985335886478424\n",
      "\n",
      "The classification loss after processing this batch is:  0.07695455849170685\n",
      "The representation loss after processing this batch is:  0.003004826605319977\n",
      "\n",
      "The classification loss after processing this batch is:  0.17020264267921448\n",
      "The representation loss after processing this batch is:  0.0027211569249629974\n",
      "\n",
      "The classification loss after processing this batch is:  0.37641656398773193\n",
      "The representation loss after processing this batch is:  0.003422968089580536\n",
      "\n",
      "The classification loss after processing this batch is:  0.40261194109916687\n",
      "The representation loss after processing this batch is:  0.003202676773071289\n",
      "\n",
      "The classification loss after processing this batch is:  0.365958034992218\n",
      "The representation loss after processing this batch is:  0.0031256303191184998\n",
      "\n",
      "The classification loss after processing this batch is:  0.23122358322143555\n",
      "The representation loss after processing this batch is:  0.003022998571395874\n",
      "\n",
      "The classification loss after processing this batch is:  0.13530083000659943\n",
      "The representation loss after processing this batch is:  0.0027684643864631653\n",
      "\n",
      "The classification loss after processing this batch is:  0.18055646121501923\n",
      "The representation loss after processing this batch is:  0.003136463463306427\n",
      "\n",
      "The classification loss after processing this batch is:  0.18211539089679718\n",
      "The representation loss after processing this batch is:  0.003206193447113037\n",
      "\n",
      "The classification loss after processing this batch is:  0.2586858570575714\n",
      "The representation loss after processing this batch is:  0.003260582685470581\n",
      "\n",
      "The classification loss after processing this batch is:  0.17448358237743378\n",
      "The representation loss after processing this batch is:  0.003619454801082611\n",
      "\n",
      "The classification loss after processing this batch is:  0.18634939193725586\n",
      "The representation loss after processing this batch is:  0.00416874885559082\n",
      "\n",
      "The classification loss after processing this batch is:  0.14990924298763275\n",
      "The representation loss after processing this batch is:  0.0031775906682014465\n",
      "\n",
      "The classification loss after processing this batch is:  0.1710941046476364\n",
      "The representation loss after processing this batch is:  0.003386855125427246\n",
      "\n",
      "The classification loss after processing this batch is:  0.23208951950073242\n",
      "The representation loss after processing this batch is:  0.003538966178894043\n",
      "\n",
      "The classification loss after processing this batch is:  0.22305311262607574\n",
      "The representation loss after processing this batch is:  0.0029684826731681824\n",
      "\n",
      "The classification loss after processing this batch is:  0.1809101104736328\n",
      "The representation loss after processing this batch is:  0.0027763284742832184\n",
      "\n",
      "The classification loss after processing this batch is:  0.34436824917793274\n",
      "The representation loss after processing this batch is:  0.0036457031965255737\n",
      "\n",
      "The classification loss after processing this batch is:  0.4140687882900238\n",
      "The representation loss after processing this batch is:  0.003601774573326111\n",
      "\n",
      "The classification loss after processing this batch is:  0.2589297890663147\n",
      "The representation loss after processing this batch is:  0.003443323075771332\n",
      "\n",
      "The classification loss after processing this batch is:  0.17794238030910492\n",
      "The representation loss after processing this batch is:  0.0033980384469032288\n",
      "\n",
      "The classification loss after processing this batch is:  0.15891499817371368\n",
      "The representation loss after processing this batch is:  0.003391861915588379\n",
      "\n",
      "The classification loss after processing this batch is:  0.13246417045593262\n",
      "The representation loss after processing this batch is:  0.0032616332173347473\n",
      "\n",
      "The classification loss after processing this batch is:  0.29711464047431946\n",
      "The representation loss after processing this batch is:  0.0034010186791419983\n",
      "\n",
      "The classification loss after processing this batch is:  0.23824673891067505\n",
      "The representation loss after processing this batch is:  0.0034387484192848206\n",
      "\n",
      "The classification loss after processing this batch is:  0.18683382868766785\n",
      "The representation loss after processing this batch is:  0.0034228935837745667\n",
      "\n",
      "The classification loss after processing this batch is:  0.3168550431728363\n",
      "The representation loss after processing this batch is:  0.00283871591091156\n",
      "\n",
      "The classification loss after processing this batch is:  0.0814172700047493\n",
      "The representation loss after processing this batch is:  0.002999931573867798\n",
      "\n",
      "The classification loss after processing this batch is:  0.12328492850065231\n",
      "The representation loss after processing this batch is:  0.0030663907527923584\n",
      "\n",
      "The classification loss after processing this batch is:  0.1791011542081833\n",
      "The representation loss after processing this batch is:  0.0030217617750167847\n",
      "\n",
      "The classification loss after processing this batch is:  0.2557695806026459\n",
      "The representation loss after processing this batch is:  0.002615083009004593\n",
      "\n",
      "The classification loss after processing this batch is:  0.2658810317516327\n",
      "The representation loss after processing this batch is:  0.003054603934288025\n",
      "\n",
      "The classification loss after processing this batch is:  0.1419447511434555\n",
      "The representation loss after processing this batch is:  0.0030945390462875366\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.17217230796813965\n",
      "The representation loss after processing this batch is:  0.003173813223838806\n",
      "\n",
      "The classification loss after processing this batch is:  0.0947924479842186\n",
      "The representation loss after processing this batch is:  0.0029251351952552795\n",
      "\n",
      "The classification loss after processing this batch is:  0.13241276144981384\n",
      "The representation loss after processing this batch is:  0.002779550850391388\n",
      "\n",
      "The classification loss after processing this batch is:  0.12921571731567383\n",
      "The representation loss after processing this batch is:  0.0031021609902381897\n",
      "\n",
      "The classification loss after processing this batch is:  0.12504549324512482\n",
      "The representation loss after processing this batch is:  0.0029898062348365784\n",
      "\n",
      "The classification loss after processing this batch is:  0.17449480295181274\n",
      "The representation loss after processing this batch is:  0.0027794167399406433\n",
      "\n",
      "The classification loss after processing this batch is:  0.19996292889118195\n",
      "The representation loss after processing this batch is:  0.003111794590950012\n",
      "\n",
      "The classification loss after processing this batch is:  0.2547878921031952\n",
      "The representation loss after processing this batch is:  0.003422372043132782\n",
      "\n",
      "The classification loss after processing this batch is:  0.08305918425321579\n",
      "The representation loss after processing this batch is:  0.0028533898293972015\n",
      "\n",
      "The classification loss after processing this batch is:  0.1237075999379158\n",
      "The representation loss after processing this batch is:  0.0029468461871147156\n",
      "\n",
      "The classification loss after processing this batch is:  0.13932697474956512\n",
      "The representation loss after processing this batch is:  0.003764018416404724\n",
      "\n",
      "The classification loss after processing this batch is:  0.22224505245685577\n",
      "The representation loss after processing this batch is:  0.0030852556228637695\n",
      "\n",
      "The classification loss after processing this batch is:  0.1322767585515976\n",
      "The representation loss after processing this batch is:  0.004158809781074524\n",
      "\n",
      "The classification loss after processing this batch is:  0.27692872285842896\n",
      "The representation loss after processing this batch is:  0.003451317548751831\n",
      "\n",
      "The classification loss after processing this batch is:  0.2894144058227539\n",
      "The representation loss after processing this batch is:  0.003119543194770813\n",
      "\n",
      "The classification loss after processing this batch is:  0.253880113363266\n",
      "The representation loss after processing this batch is:  0.0032945945858955383\n",
      "\n",
      "The classification loss after processing this batch is:  0.21962322294712067\n",
      "The representation loss after processing this batch is:  0.003276236355304718\n",
      "\n",
      "The classification loss after processing this batch is:  0.14220823347568512\n",
      "The representation loss after processing this batch is:  0.0031846091151237488\n",
      "\n",
      "The classification loss after processing this batch is:  0.2075180560350418\n",
      "The representation loss after processing this batch is:  0.002800755202770233\n",
      "\n",
      "The classification loss after processing this batch is:  0.20624367892742157\n",
      "The representation loss after processing this batch is:  0.0029864683747291565\n",
      "\n",
      "The classification loss after processing this batch is:  0.16621407866477966\n",
      "The representation loss after processing this batch is:  0.0031085610389709473\n",
      "\n",
      "The classification loss after processing this batch is:  0.06862259656190872\n",
      "The representation loss after processing this batch is:  0.0026991739869117737\n",
      "\n",
      "The classification loss after processing this batch is:  0.25425973534584045\n",
      "The representation loss after processing this batch is:  0.0031640827655792236\n",
      "\n",
      "The classification loss after processing this batch is:  0.32290172576904297\n",
      "The representation loss after processing this batch is:  0.0026377514004707336\n",
      "\n",
      "The classification loss after processing this batch is:  0.19150277972221375\n",
      "The representation loss after processing this batch is:  0.002964004874229431\n",
      "\n",
      "The classification loss after processing this batch is:  0.2688491940498352\n",
      "The representation loss after processing this batch is:  0.0030171796679496765\n",
      "\n",
      "The classification loss after processing this batch is:  0.32443472743034363\n",
      "The representation loss after processing this batch is:  0.003270164132118225\n",
      "\n",
      "The classification loss after processing this batch is:  0.46327289938926697\n",
      "The representation loss after processing this batch is:  0.003252267837524414\n",
      "\n",
      "The classification loss after processing this batch is:  0.23070864379405975\n",
      "The representation loss after processing this batch is:  0.002868145704269409\n",
      "\n",
      "The classification loss after processing this batch is:  0.16811710596084595\n",
      "The representation loss after processing this batch is:  0.003116331994533539\n",
      "\n",
      "The classification loss after processing this batch is:  0.2319537252187729\n",
      "The representation loss after processing this batch is:  0.003544233739376068\n",
      "\n",
      "The classification loss after processing this batch is:  0.15432752668857574\n",
      "The representation loss after processing this batch is:  0.003213845193386078\n",
      "\n",
      "The classification loss after processing this batch is:  0.12539654970169067\n",
      "The representation loss after processing this batch is:  0.0031443312764167786\n",
      "\n",
      "The classification loss after processing this batch is:  0.1234198585152626\n",
      "The representation loss after processing this batch is:  0.002976931631565094\n",
      "\n",
      "The classification loss after processing this batch is:  0.10197756439447403\n",
      "The representation loss after processing this batch is:  0.002886436879634857\n",
      "\n",
      "The classification loss after processing this batch is:  0.0778573527932167\n",
      "The representation loss after processing this batch is:  0.0034222155809402466\n",
      "\n",
      "The classification loss after processing this batch is:  0.22885873913764954\n",
      "The representation loss after processing this batch is:  0.002987891435623169\n",
      "\n",
      "The classification loss after processing this batch is:  0.23279206454753876\n",
      "The representation loss after processing this batch is:  0.002721533179283142\n",
      "\n",
      "The classification loss after processing this batch is:  0.10979490727186203\n",
      "The representation loss after processing this batch is:  0.00338803231716156\n",
      "\n",
      "The classification loss after processing this batch is:  0.1578265130519867\n",
      "The representation loss after processing this batch is:  0.00315837562084198\n",
      "\n",
      "The classification loss after processing this batch is:  0.19008789956569672\n",
      "The representation loss after processing this batch is:  0.0032357871532440186\n",
      "\n",
      "The classification loss after processing this batch is:  0.06951331347227097\n",
      "The representation loss after processing this batch is:  0.0030764639377593994\n",
      "\n",
      "The classification loss after processing this batch is:  0.26655811071395874\n",
      "The representation loss after processing this batch is:  0.0030302926898002625\n",
      "\n",
      "The classification loss after processing this batch is:  0.161884143948555\n",
      "The representation loss after processing this batch is:  0.0030065178871154785\n",
      "\n",
      "The classification loss after processing this batch is:  0.29362571239471436\n",
      "The representation loss after processing this batch is:  0.002994529902935028\n",
      "\n",
      "The classification loss after processing this batch is:  0.22993281483650208\n",
      "The representation loss after processing this batch is:  0.0033520832657814026\n",
      "\n",
      "The classification loss after processing this batch is:  0.24878983199596405\n",
      "The representation loss after processing this batch is:  0.0028574541211128235\n",
      "\n",
      "The classification loss after processing this batch is:  0.08401672542095184\n",
      "The representation loss after processing this batch is:  0.002865210175514221\n",
      "\n",
      "The classification loss after processing this batch is:  0.08542607724666595\n",
      "The representation loss after processing this batch is:  0.0028543397784233093\n",
      "\n",
      "The classification loss after processing this batch is:  0.1972372829914093\n",
      "The representation loss after processing this batch is:  0.0033537745475769043\n",
      "\n",
      "The classification loss after processing this batch is:  0.09946952760219574\n",
      "The representation loss after processing this batch is:  0.0035269856452941895\n",
      "\n",
      "The classification loss after processing this batch is:  0.21725374460220337\n",
      "The representation loss after processing this batch is:  0.0032424628734588623\n",
      "\n",
      "The classification loss after processing this batch is:  0.12509912252426147\n",
      "The representation loss after processing this batch is:  0.002947978675365448\n",
      "\n",
      "The classification loss after processing this batch is:  0.18734778463840485\n",
      "The representation loss after processing this batch is:  0.0034573450684547424\n",
      "\n",
      "The classification loss after processing this batch is:  0.21064996719360352\n",
      "The representation loss after processing this batch is:  0.0028977468609809875\n",
      "\n",
      "The classification loss after processing this batch is:  0.17800229787826538\n",
      "The representation loss after processing this batch is:  0.0031495392322540283\n",
      "\n",
      "The classification loss after processing this batch is:  0.18362927436828613\n",
      "The representation loss after processing this batch is:  0.0032202675938606262\n",
      "\n",
      "The classification loss after processing this batch is:  0.19590921700000763\n",
      "The representation loss after processing this batch is:  0.0032559260725975037\n",
      "\n",
      "The classification loss after processing this batch is:  0.22316256165504456\n",
      "The representation loss after processing this batch is:  0.003236919641494751\n",
      "\n",
      "The classification loss after processing this batch is:  0.2772640287876129\n",
      "The representation loss after processing this batch is:  0.0032053515315055847\n",
      "\n",
      "The classification loss after processing this batch is:  0.3141426146030426\n",
      "The representation loss after processing this batch is:  0.0034468472003936768\n",
      "\n",
      "The classification loss after processing this batch is:  0.23384815454483032\n",
      "The representation loss after processing this batch is:  0.002688586711883545\n",
      "\n",
      "The classification loss after processing this batch is:  0.16760747134685516\n",
      "The representation loss after processing this batch is:  0.0030822306871414185\n",
      "\n",
      "The classification loss after processing this batch is:  0.13102896511554718\n",
      "The representation loss after processing this batch is:  0.0027668699622154236\n",
      "\n",
      "The classification loss after processing this batch is:  0.14144334197044373\n",
      "The representation loss after processing this batch is:  0.0031301304697990417\n",
      "\n",
      "The classification loss after processing this batch is:  0.12674926221370697\n",
      "The representation loss after processing this batch is:  0.0033474862575531006\n",
      "\n",
      "The classification loss after processing this batch is:  0.18037401139736176\n",
      "The representation loss after processing this batch is:  0.0025701969861984253\n",
      "\n",
      "The classification loss after processing this batch is:  0.12454686313867569\n",
      "The representation loss after processing this batch is:  0.0032360032200813293\n",
      "\n",
      "The classification loss after processing this batch is:  0.1790744662284851\n",
      "The representation loss after processing this batch is:  0.003349222242832184\n",
      "\n",
      "The classification loss after processing this batch is:  0.12249292433261871\n",
      "The representation loss after processing this batch is:  0.0031290575861930847\n",
      "\n",
      "The classification loss after processing this batch is:  0.2078782469034195\n",
      "The representation loss after processing this batch is:  0.0031648948788642883\n",
      "\n",
      "The classification loss after processing this batch is:  0.151677668094635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.003176644444465637\n",
      "\n",
      "The classification loss after processing this batch is:  0.21146105229854584\n",
      "The representation loss after processing this batch is:  0.002939082682132721\n",
      "\n",
      "The classification loss after processing this batch is:  0.20397451519966125\n",
      "The representation loss after processing this batch is:  0.0033210143446922302\n",
      "\n",
      "The classification loss after processing this batch is:  0.15998175740242004\n",
      "The representation loss after processing this batch is:  0.0032424256205558777\n",
      "\n",
      "The classification loss after processing this batch is:  0.16609424352645874\n",
      "The representation loss after processing this batch is:  0.0032787173986434937\n",
      "\n",
      "The classification loss after processing this batch is:  0.265093594789505\n",
      "The representation loss after processing this batch is:  0.0034381747245788574\n",
      "\n",
      "The classification loss after processing this batch is:  0.12145504355430603\n",
      "The representation loss after processing this batch is:  0.0031762123107910156\n",
      "\n",
      "The classification loss after processing this batch is:  0.109776072204113\n",
      "The representation loss after processing this batch is:  0.0030119121074676514\n",
      "\n",
      "The classification loss after processing this batch is:  0.1655627191066742\n",
      "The representation loss after processing this batch is:  0.003075145184993744\n",
      "\n",
      "The classification loss after processing this batch is:  0.13498714566230774\n",
      "The representation loss after processing this batch is:  0.0028906166553497314\n",
      "\n",
      "The classification loss after processing this batch is:  0.23808437585830688\n",
      "The representation loss after processing this batch is:  0.0026941075921058655\n",
      "\n",
      "The classification loss after processing this batch is:  0.234796941280365\n",
      "The representation loss after processing this batch is:  0.003259524703025818\n",
      "\n",
      "The classification loss after processing this batch is:  0.20655374228954315\n",
      "The representation loss after processing this batch is:  0.003497682511806488\n",
      "\n",
      "The classification loss after processing this batch is:  0.12958773970603943\n",
      "The representation loss after processing this batch is:  0.003354787826538086\n",
      "\n",
      "The classification loss after processing this batch is:  0.15440623462200165\n",
      "The representation loss after processing this batch is:  0.0031159520149230957\n",
      "\n",
      "The classification loss after processing this batch is:  0.3010987639427185\n",
      "The representation loss after processing this batch is:  0.0030960626900196075\n",
      "\n",
      "The classification loss after processing this batch is:  0.09078630059957504\n",
      "The representation loss after processing this batch is:  0.0032936260104179382\n",
      "\n",
      "The classification loss after processing this batch is:  0.1482485681772232\n",
      "The representation loss after processing this batch is:  0.003302261233329773\n",
      "\n",
      "The classification loss after processing this batch is:  0.21158266067504883\n",
      "The representation loss after processing this batch is:  0.0028414130210876465\n",
      "\n",
      "The classification loss after processing this batch is:  0.4195863604545593\n",
      "The representation loss after processing this batch is:  0.0031887367367744446\n",
      "\n",
      "The classification loss after processing this batch is:  0.12730327248573303\n",
      "The representation loss after processing this batch is:  0.0028992220759391785\n",
      "\n",
      "The classification loss after processing this batch is:  0.19913902878761292\n",
      "The representation loss after processing this batch is:  0.002709716558456421\n",
      "\n",
      "The classification loss after processing this batch is:  0.11806552857160568\n",
      "The representation loss after processing this batch is:  0.0030351653695106506\n",
      "\n",
      "The classification loss after processing this batch is:  0.09330279380083084\n",
      "The representation loss after processing this batch is:  0.0030068978667259216\n",
      "\n",
      "The classification loss after processing this batch is:  0.16962788999080658\n",
      "The representation loss after processing this batch is:  0.003642849624156952\n",
      "\n",
      "The classification loss after processing this batch is:  0.13819773495197296\n",
      "The representation loss after processing this batch is:  0.004148110747337341\n",
      "\n",
      "The classification loss after processing this batch is:  0.09607041627168655\n",
      "The representation loss after processing this batch is:  0.0031880736351013184\n",
      "\n",
      "The classification loss after processing this batch is:  0.09754730015993118\n",
      "The representation loss after processing this batch is:  0.002856925129890442\n",
      "\n",
      "The classification loss after processing this batch is:  0.22565771639347076\n",
      "The representation loss after processing this batch is:  0.0030587948858737946\n",
      "\n",
      "The classification loss after processing this batch is:  0.1978914588689804\n",
      "The representation loss after processing this batch is:  0.002988971769809723\n",
      "\n",
      "The classification loss after processing this batch is:  0.12202999740839005\n",
      "The representation loss after processing this batch is:  0.0028221383690834045\n",
      "\n",
      "The classification loss after processing this batch is:  0.16455979645252228\n",
      "The representation loss after processing this batch is:  0.003058217465877533\n",
      "\n",
      "The classification loss after processing this batch is:  0.19983504712581635\n",
      "The representation loss after processing this batch is:  0.0029440000653266907\n",
      "\n",
      "The classification loss after processing this batch is:  0.24149860441684723\n",
      "The representation loss after processing this batch is:  0.0031444579362869263\n",
      "\n",
      "The classification loss after processing this batch is:  0.2554445266723633\n",
      "The representation loss after processing this batch is:  0.002855859696865082\n",
      "\n",
      "The classification loss after processing this batch is:  0.19292981922626495\n",
      "The representation loss after processing this batch is:  0.0031991899013519287\n",
      "\n",
      "The classification loss after processing this batch is:  0.3439455032348633\n",
      "The representation loss after processing this batch is:  0.0029413551092147827\n",
      "\n",
      "The classification loss after processing this batch is:  0.14817222952842712\n",
      "The representation loss after processing this batch is:  0.0031588226556777954\n",
      "\n",
      "The classification loss after processing this batch is:  0.13084468245506287\n",
      "The representation loss after processing this batch is:  0.0034453794360160828\n",
      "\n",
      "The classification loss after processing this batch is:  0.11460800468921661\n",
      "The representation loss after processing this batch is:  0.0029899999499320984\n",
      "\n",
      "The classification loss after processing this batch is:  0.10220499336719513\n",
      "The representation loss after processing this batch is:  0.0028872862458229065\n",
      "\n",
      "The classification loss after processing this batch is:  0.23435059189796448\n",
      "The representation loss after processing this batch is:  0.003107994794845581\n",
      "\n",
      "The classification loss after processing this batch is:  0.13194473087787628\n",
      "The representation loss after processing this batch is:  0.0035168975591659546\n",
      "\n",
      "The classification loss after processing this batch is:  0.0857902467250824\n",
      "The representation loss after processing this batch is:  0.002989649772644043\n",
      "\n",
      "The classification loss after processing this batch is:  0.08318573981523514\n",
      "The representation loss after processing this batch is:  0.003645777702331543\n",
      "\n",
      "The classification loss after processing this batch is:  0.08411284536123276\n",
      "The representation loss after processing this batch is:  0.0033551231026649475\n",
      "\n",
      "The classification loss after processing this batch is:  0.10451237857341766\n",
      "The representation loss after processing this batch is:  0.0037646517157554626\n",
      "\n",
      "The classification loss after processing this batch is:  0.15451978147029877\n",
      "The representation loss after processing this batch is:  0.003224708139896393\n",
      "\n",
      "The classification loss after processing this batch is:  0.110416479408741\n",
      "The representation loss after processing this batch is:  0.003292590379714966\n",
      "\n",
      "The classification loss after processing this batch is:  0.06702106446027756\n",
      "The representation loss after processing this batch is:  0.0033777132630348206\n",
      "\n",
      "The classification loss after processing this batch is:  0.10440564900636673\n",
      "The representation loss after processing this batch is:  0.003575161099433899\n",
      "\n",
      "The classification loss after processing this batch is:  0.10778442770242691\n",
      "The representation loss after processing this batch is:  0.004494473338127136\n",
      "\n",
      "The classification loss after processing this batch is:  0.04558516666293144\n",
      "The representation loss after processing this batch is:  0.004344388842582703\n",
      "\n",
      "The classification loss after processing this batch is:  0.06485457718372345\n",
      "The representation loss after processing this batch is:  0.003743104636669159\n",
      "\n",
      "The classification loss after processing this batch is:  0.2200234979391098\n",
      "The representation loss after processing this batch is:  0.0033752694725990295\n",
      "\n",
      "The classification loss after processing this batch is:  0.07935130596160889\n",
      "The representation loss after processing this batch is:  0.0036790594458580017\n",
      "\n",
      "The classification loss after processing this batch is:  0.03859127312898636\n",
      "The representation loss after processing this batch is:  0.0034005120396614075\n",
      "\n",
      "The classification loss after processing this batch is:  0.08689489960670471\n",
      "The representation loss after processing this batch is:  0.003944076597690582\n",
      "\n",
      "The classification loss after processing this batch is:  0.06879886984825134\n",
      "The representation loss after processing this batch is:  0.0034309327602386475\n",
      "\n",
      "The classification loss after processing this batch is:  0.05643622577190399\n",
      "The representation loss after processing this batch is:  0.0032391175627708435\n",
      "\n",
      "The classification loss after processing this batch is:  0.048918526619672775\n",
      "The representation loss after processing this batch is:  0.0036055296659469604\n",
      "\n",
      "The classification loss after processing this batch is:  0.04680505767464638\n",
      "The representation loss after processing this batch is:  0.004221819341182709\n",
      "\n",
      "The classification loss after processing this batch is:  0.4065132439136505\n",
      "The representation loss after processing this batch is:  0.0042359307408332825\n",
      "\n",
      "The classification loss after processing this batch is:  0.4048728942871094\n",
      "The representation loss after processing this batch is:  0.0038256943225860596\n",
      "\n",
      "The classification loss after processing this batch is:  0.3215217590332031\n",
      "The representation loss after processing this batch is:  0.0040641650557518005\n",
      "\n",
      "The classification loss after processing this batch is:  0.08123741298913956\n",
      "The representation loss after processing this batch is:  0.003307744860649109\n",
      "\n",
      "The classification loss after processing this batch is:  0.04982643201947212\n",
      "The representation loss after processing this batch is:  0.004023835062980652\n",
      "\n",
      "The classification loss after processing this batch is:  0.04842304810881615\n",
      "The representation loss after processing this batch is:  0.002751275897026062\n",
      "\n",
      "The classification loss after processing this batch is:  0.13782106339931488\n",
      "The representation loss after processing this batch is:  0.0029282867908477783\n",
      "\n",
      "The classification loss after processing this batch is:  0.4175080955028534\n",
      "The representation loss after processing this batch is:  0.0034094303846359253\n",
      "\n",
      "The classification loss after processing this batch is:  0.12168195098638535\n",
      "The representation loss after processing this batch is:  0.0032435432076454163\n",
      "\n",
      "The classification loss after processing this batch is:  0.07538115233182907\n",
      "The representation loss after processing this batch is:  0.0036897361278533936\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10737302154302597\n",
      "The representation loss after processing this batch is:  0.0036871209740638733\n",
      "\n",
      "The classification loss after processing this batch is:  0.08076626807451248\n",
      "The representation loss after processing this batch is:  0.004158109426498413\n",
      "\n",
      "The classification loss after processing this batch is:  0.17510508000850677\n",
      "The representation loss after processing this batch is:  0.003070943057537079\n",
      "\n",
      "The classification loss after processing this batch is:  0.0839814692735672\n",
      "The representation loss after processing this batch is:  0.0028237923979759216\n",
      "\n",
      "The classification loss after processing this batch is:  0.18180027604103088\n",
      "The representation loss after processing this batch is:  0.0030418038368225098\n",
      "\n",
      "The classification loss after processing this batch is:  0.14955087006092072\n",
      "The representation loss after processing this batch is:  0.002872813493013382\n",
      "\n",
      "The classification loss after processing this batch is:  0.2151557356119156\n",
      "The representation loss after processing this batch is:  0.002909734845161438\n",
      "\n",
      "The classification loss after processing this batch is:  0.10624467581510544\n",
      "The representation loss after processing this batch is:  0.0032650530338287354\n",
      "\n",
      "The classification loss after processing this batch is:  0.15177544951438904\n",
      "The representation loss after processing this batch is:  0.003743104636669159\n",
      "\n",
      "The classification loss after processing this batch is:  0.14548227190971375\n",
      "The representation loss after processing this batch is:  0.003043234348297119\n",
      "\n",
      "The classification loss after processing this batch is:  0.18806402385234833\n",
      "The representation loss after processing this batch is:  0.002757605165243149\n",
      "\n",
      "The classification loss after processing this batch is:  0.16851945221424103\n",
      "The representation loss after processing this batch is:  0.002942468971014023\n",
      "\n",
      "The classification loss after processing this batch is:  0.24008308351039886\n",
      "The representation loss after processing this batch is:  0.002777300775051117\n",
      "\n",
      "The classification loss after processing this batch is:  0.11679800599813461\n",
      "The representation loss after processing this batch is:  0.002780616283416748\n",
      "\n",
      "The classification loss after processing this batch is:  0.1787099987268448\n",
      "The representation loss after processing this batch is:  0.0031874999403953552\n",
      "\n",
      "The classification loss after processing this batch is:  0.09787008911371231\n",
      "The representation loss after processing this batch is:  0.0028363242745399475\n",
      "\n",
      "The classification loss after processing this batch is:  0.3799813687801361\n",
      "The representation loss after processing this batch is:  0.0031450949609279633\n",
      "\n",
      "The classification loss after processing this batch is:  0.19630053639411926\n",
      "The representation loss after processing this batch is:  0.0030131712555885315\n",
      "\n",
      "The classification loss after processing this batch is:  0.22698666155338287\n",
      "The representation loss after processing this batch is:  0.003051444888114929\n",
      "\n",
      "The classification loss after processing this batch is:  0.33646366000175476\n",
      "The representation loss after processing this batch is:  0.0038509704172611237\n",
      "\n",
      "The classification loss after processing this batch is:  0.23072300851345062\n",
      "The representation loss after processing this batch is:  0.0032633766531944275\n",
      "\n",
      "The classification loss after processing this batch is:  0.1010817140340805\n",
      "The representation loss after processing this batch is:  0.003413058817386627\n",
      "\n",
      "The classification loss after processing this batch is:  0.31147468090057373\n",
      "The representation loss after processing this batch is:  0.003981359302997589\n",
      "\n",
      "The classification loss after processing this batch is:  0.21538080275058746\n",
      "The representation loss after processing this batch is:  0.003157198429107666\n",
      "\n",
      "The classification loss after processing this batch is:  0.3794422447681427\n",
      "The representation loss after processing this batch is:  0.003072485327720642\n",
      "\n",
      "The classification loss after processing this batch is:  0.1541949212551117\n",
      "The representation loss after processing this batch is:  0.0026291199028491974\n",
      "\n",
      "The classification loss after processing this batch is:  0.11280506104230881\n",
      "The representation loss after processing this batch is:  0.0031358227133750916\n",
      "\n",
      "The classification loss after processing this batch is:  0.14411644637584686\n",
      "The representation loss after processing this batch is:  0.0027893073856830597\n",
      "\n",
      "The classification loss after processing this batch is:  0.19747430086135864\n",
      "The representation loss after processing this batch is:  0.00261901319026947\n",
      "\n",
      "The classification loss after processing this batch is:  0.14133518934249878\n",
      "The representation loss after processing this batch is:  0.0030659958720207214\n",
      "\n",
      "The classification loss after processing this batch is:  0.0951819196343422\n",
      "The representation loss after processing this batch is:  0.0029283687472343445\n",
      "\n",
      "The classification loss after processing this batch is:  0.07562819123268127\n",
      "The representation loss after processing this batch is:  0.0030372589826583862\n",
      "\n",
      "The classification loss after processing this batch is:  0.09850755333900452\n",
      "The representation loss after processing this batch is:  0.0028521977365016937\n",
      "\n",
      "The classification loss after processing this batch is:  0.11674679070711136\n",
      "The representation loss after processing this batch is:  0.003136947751045227\n",
      "\n",
      "The classification loss after processing this batch is:  0.22374770045280457\n",
      "The representation loss after processing this batch is:  0.0031277835369110107\n",
      "\n",
      "The classification loss after processing this batch is:  0.16232843697071075\n",
      "The representation loss after processing this batch is:  0.0033982321619987488\n",
      "\n",
      "The classification loss after processing this batch is:  0.15778201818466187\n",
      "The representation loss after processing this batch is:  0.0028633177280426025\n",
      "\n",
      "The classification loss after processing this batch is:  0.08458006381988525\n",
      "The representation loss after processing this batch is:  0.0032782480120658875\n",
      "\n",
      "The classification loss after processing this batch is:  0.11946547776460648\n",
      "The representation loss after processing this batch is:  0.003200419247150421\n",
      "\n",
      "The classification loss after processing this batch is:  0.16544409096240997\n",
      "The representation loss after processing this batch is:  0.003214612603187561\n",
      "\n",
      "The classification loss after processing this batch is:  0.08120384812355042\n",
      "The representation loss after processing this batch is:  0.0032468214631080627\n",
      "\n",
      "The classification loss after processing this batch is:  0.12351798266172409\n",
      "The representation loss after processing this batch is:  0.0030032768845558167\n",
      "\n",
      "The classification loss after processing this batch is:  0.23019902408123016\n",
      "The representation loss after processing this batch is:  0.003601871430873871\n",
      "\n",
      "The classification loss after processing this batch is:  0.12624219059944153\n",
      "The representation loss after processing this batch is:  0.0030510053038597107\n",
      "\n",
      "The classification loss after processing this batch is:  0.1580677628517151\n",
      "The representation loss after processing this batch is:  0.0028430186212062836\n",
      "\n",
      "The classification loss after processing this batch is:  0.1637071818113327\n",
      "The representation loss after processing this batch is:  0.0028986856341362\n",
      "\n",
      "The classification loss after processing this batch is:  0.14422562718391418\n",
      "The representation loss after processing this batch is:  0.0027902796864509583\n",
      "\n",
      "The classification loss after processing this batch is:  0.17639945447444916\n",
      "The representation loss after processing this batch is:  0.0026765353977680206\n",
      "\n",
      "The classification loss after processing this batch is:  0.23204678297042847\n",
      "The representation loss after processing this batch is:  0.0031974278390407562\n",
      "\n",
      "The classification loss after processing this batch is:  0.08272991329431534\n",
      "The representation loss after processing this batch is:  0.0030424147844314575\n",
      "\n",
      "The classification loss after processing this batch is:  0.1965055763721466\n",
      "The representation loss after processing this batch is:  0.0030855387449264526\n",
      "\n",
      "The classification loss after processing this batch is:  0.13397598266601562\n",
      "The representation loss after processing this batch is:  0.003076225519180298\n",
      "\n",
      "The classification loss after processing this batch is:  0.1726963222026825\n",
      "The representation loss after processing this batch is:  0.0028874054551124573\n",
      "\n",
      "The classification loss after processing this batch is:  0.165669247508049\n",
      "The representation loss after processing this batch is:  0.0032063573598861694\n",
      "\n",
      "The classification loss after processing this batch is:  0.12029457092285156\n",
      "The representation loss after processing this batch is:  0.0030805692076683044\n",
      "\n",
      "The classification loss after processing this batch is:  0.12708675861358643\n",
      "The representation loss after processing this batch is:  0.00317971408367157\n",
      "\n",
      "The classification loss after processing this batch is:  0.1504708081483841\n",
      "The representation loss after processing this batch is:  0.003063708543777466\n",
      "\n",
      "The classification loss after processing this batch is:  0.174405038356781\n",
      "The representation loss after processing this batch is:  0.0029230117797851562\n",
      "\n",
      "The classification loss after processing this batch is:  0.19415831565856934\n",
      "The representation loss after processing this batch is:  0.002818487584590912\n",
      "\n",
      "The classification loss after processing this batch is:  0.12137921154499054\n",
      "The representation loss after processing this batch is:  0.003135599195957184\n",
      "\n",
      "The classification loss after processing this batch is:  0.1700923889875412\n",
      "The representation loss after processing this batch is:  0.0032421499490737915\n",
      "\n",
      "The classification loss after processing this batch is:  0.10639730840921402\n",
      "The representation loss after processing this batch is:  0.0029727891087532043\n",
      "\n",
      "The classification loss after processing this batch is:  0.10181459784507751\n",
      "The representation loss after processing this batch is:  0.0027709417045116425\n",
      "\n",
      "The classification loss after processing this batch is:  0.19190239906311035\n",
      "The representation loss after processing this batch is:  0.0028493106365203857\n",
      "\n",
      "The classification loss after processing this batch is:  0.1885422319173813\n",
      "The representation loss after processing this batch is:  0.0029967576265335083\n",
      "\n",
      "The classification loss after processing this batch is:  0.129202201962471\n",
      "The representation loss after processing this batch is:  0.0027892068028450012\n",
      "\n",
      "The classification loss after processing this batch is:  0.1406131386756897\n",
      "The representation loss after processing this batch is:  0.002808980643749237\n",
      "\n",
      "The classification loss after processing this batch is:  0.11890426278114319\n",
      "The representation loss after processing this batch is:  0.0028003454208374023\n",
      "\n",
      "The classification loss after processing this batch is:  0.19686158001422882\n",
      "The representation loss after processing this batch is:  0.0035129711031913757\n",
      "\n",
      "The classification loss after processing this batch is:  0.1988789588212967\n",
      "The representation loss after processing this batch is:  0.002519451081752777\n",
      "\n",
      "The classification loss after processing this batch is:  0.09094544500112534\n",
      "The representation loss after processing this batch is:  0.0026596784591674805\n",
      "\n",
      "The classification loss after processing this batch is:  0.24339310824871063\n",
      "The representation loss after processing this batch is:  0.003315616399049759\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.15581919252872467\n",
      "The representation loss after processing this batch is:  0.0030328556895256042\n",
      "\n",
      "The classification loss after processing this batch is:  0.1552792489528656\n",
      "The representation loss after processing this batch is:  0.0029670894145965576\n",
      "\n",
      "The classification loss after processing this batch is:  0.14599227905273438\n",
      "The representation loss after processing this batch is:  0.002451010048389435\n",
      "\n",
      "The classification loss after processing this batch is:  0.11064226180315018\n",
      "The representation loss after processing this batch is:  0.0029842332005500793\n",
      "\n",
      "The classification loss after processing this batch is:  0.13148440420627594\n",
      "The representation loss after processing this batch is:  0.0026840828359127045\n",
      "\n",
      "The classification loss after processing this batch is:  0.19831949472427368\n",
      "The representation loss after processing this batch is:  0.0028476566076278687\n",
      "\n",
      "The classification loss after processing this batch is:  0.11101958155632019\n",
      "The representation loss after processing this batch is:  0.0027483180165290833\n",
      "\n",
      "The classification loss after processing this batch is:  0.3184226453304291\n",
      "The representation loss after processing this batch is:  0.0027223527431488037\n",
      "\n",
      "The classification loss after processing this batch is:  0.17231003940105438\n",
      "The representation loss after processing this batch is:  0.0028715208172798157\n",
      "\n",
      "The classification loss after processing this batch is:  0.12770213186740875\n",
      "The representation loss after processing this batch is:  0.0035783424973487854\n",
      "\n",
      "The classification loss after processing this batch is:  0.188272163271904\n",
      "The representation loss after processing this batch is:  0.002904243767261505\n",
      "\n",
      "The classification loss after processing this batch is:  0.1566372960805893\n",
      "The representation loss after processing this batch is:  0.003162682056427002\n",
      "\n",
      "The classification loss after processing this batch is:  0.32731643319129944\n",
      "The representation loss after processing this batch is:  0.0031198635697364807\n",
      "\n",
      "The classification loss after processing this batch is:  0.17351163923740387\n",
      "The representation loss after processing this batch is:  0.0031922832131385803\n",
      "\n",
      "The classification loss after processing this batch is:  0.1850963532924652\n",
      "The representation loss after processing this batch is:  0.00257280096411705\n",
      "\n",
      "The classification loss after processing this batch is:  0.3382919430732727\n",
      "The representation loss after processing this batch is:  0.002924073487520218\n",
      "\n",
      "The classification loss after processing this batch is:  0.19299288094043732\n",
      "The representation loss after processing this batch is:  0.0027826055884361267\n",
      "\n",
      "The classification loss after processing this batch is:  0.09668942540884018\n",
      "The representation loss after processing this batch is:  0.003252580761909485\n",
      "\n",
      "The classification loss after processing this batch is:  0.22200067341327667\n",
      "The representation loss after processing this batch is:  0.002785090357065201\n",
      "\n",
      "The classification loss after processing this batch is:  0.23264560103416443\n",
      "The representation loss after processing this batch is:  0.002657175064086914\n",
      "\n",
      "The classification loss after processing this batch is:  0.1659436821937561\n",
      "The representation loss after processing this batch is:  0.0030893534421920776\n",
      "\n",
      "The classification loss after processing this batch is:  0.10633878409862518\n",
      "The representation loss after processing this batch is:  0.002577751874923706\n",
      "\n",
      "The classification loss after processing this batch is:  0.1700701117515564\n",
      "The representation loss after processing this batch is:  0.0028361231088638306\n",
      "\n",
      "The classification loss after processing this batch is:  0.19606521725654602\n",
      "The representation loss after processing this batch is:  0.002792835235595703\n",
      "\n",
      "The classification loss after processing this batch is:  0.17507483065128326\n",
      "The representation loss after processing this batch is:  0.003171466290950775\n",
      "\n",
      "The classification loss after processing this batch is:  0.2370453178882599\n",
      "The representation loss after processing this batch is:  0.0027247443795204163\n",
      "\n",
      "The classification loss after processing this batch is:  0.1955394297838211\n",
      "The representation loss after processing this batch is:  0.0031484439969062805\n",
      "\n",
      "The classification loss after processing this batch is:  0.19794316589832306\n",
      "The representation loss after processing this batch is:  0.003470577299594879\n",
      "\n",
      "The classification loss after processing this batch is:  0.113579161465168\n",
      "The representation loss after processing this batch is:  0.003376774489879608\n",
      "\n",
      "The classification loss after processing this batch is:  0.13078127801418304\n",
      "The representation loss after processing this batch is:  0.0029339157044887543\n",
      "\n",
      "The classification loss after processing this batch is:  0.08408204466104507\n",
      "The representation loss after processing this batch is:  0.0030098073184490204\n",
      "\n",
      "The classification loss after processing this batch is:  0.17247286438941956\n",
      "The representation loss after processing this batch is:  0.003351569175720215\n",
      "\n",
      "The classification loss after processing this batch is:  0.1148335188627243\n",
      "The representation loss after processing this batch is:  0.002909548580646515\n",
      "\n",
      "The classification loss after processing this batch is:  0.3181803524494171\n",
      "The representation loss after processing this batch is:  0.0032843947410583496\n",
      "\n",
      "The classification loss after processing this batch is:  0.32590991258621216\n",
      "The representation loss after processing this batch is:  0.0031623542308807373\n",
      "\n",
      "The classification loss after processing this batch is:  0.14622627198696136\n",
      "The representation loss after processing this batch is:  0.0028841793537139893\n",
      "\n",
      "The classification loss after processing this batch is:  0.15064191818237305\n",
      "The representation loss after processing this batch is:  0.003246307373046875\n",
      "\n",
      "The classification loss after processing this batch is:  0.16144442558288574\n",
      "The representation loss after processing this batch is:  0.00267656147480011\n",
      "\n",
      "The classification loss after processing this batch is:  0.08450135588645935\n",
      "The representation loss after processing this batch is:  0.0033242926001548767\n",
      "\n",
      "The classification loss after processing this batch is:  0.10104469954967499\n",
      "The representation loss after processing this batch is:  0.003056839108467102\n",
      "\n",
      "The classification loss after processing this batch is:  0.18312883377075195\n",
      "The representation loss after processing this batch is:  0.002819530665874481\n",
      "\n",
      "The classification loss after processing this batch is:  0.1267475038766861\n",
      "The representation loss after processing this batch is:  0.0038258880376815796\n",
      "\n",
      "The classification loss after processing this batch is:  0.1231556236743927\n",
      "The representation loss after processing this batch is:  0.003023870289325714\n",
      "\n",
      "The classification loss after processing this batch is:  0.26672598719596863\n",
      "The representation loss after processing this batch is:  0.003919705748558044\n",
      "\n",
      "The classification loss after processing this batch is:  0.2560279071331024\n",
      "The representation loss after processing this batch is:  0.002557508647441864\n",
      "\n",
      "The classification loss after processing this batch is:  0.18542636930942535\n",
      "The representation loss after processing this batch is:  0.0031714066863059998\n",
      "\n",
      "The classification loss after processing this batch is:  0.2616686522960663\n",
      "The representation loss after processing this batch is:  0.003248050808906555\n",
      "\n",
      "The classification loss after processing this batch is:  0.17925450205802917\n",
      "The representation loss after processing this batch is:  0.002846263349056244\n",
      "\n",
      "The classification loss after processing this batch is:  0.09973195195198059\n",
      "The representation loss after processing this batch is:  0.002898663282394409\n",
      "\n",
      "The classification loss after processing this batch is:  0.24384739995002747\n",
      "The representation loss after processing this batch is:  0.003015805035829544\n",
      "\n",
      "The classification loss after processing this batch is:  0.3975662589073181\n",
      "The representation loss after processing this batch is:  0.0038156360387802124\n",
      "\n",
      "The classification loss after processing this batch is:  0.22419942915439606\n",
      "The representation loss after processing this batch is:  0.0038204416632652283\n",
      "\n",
      "The classification loss after processing this batch is:  0.1564771831035614\n",
      "The representation loss after processing this batch is:  0.0037587955594062805\n",
      "\n",
      "The classification loss after processing this batch is:  0.1491660475730896\n",
      "The representation loss after processing this batch is:  0.0033692121505737305\n",
      "\n",
      "The classification loss after processing this batch is:  0.10835724323987961\n",
      "The representation loss after processing this batch is:  0.003157667815685272\n",
      "\n",
      "The classification loss after processing this batch is:  0.16111060976982117\n",
      "The representation loss after processing this batch is:  0.003041587769985199\n",
      "\n",
      "The classification loss after processing this batch is:  0.11616750806570053\n",
      "The representation loss after processing this batch is:  0.003091759979724884\n",
      "\n",
      "The classification loss after processing this batch is:  0.16970515251159668\n",
      "The representation loss after processing this batch is:  0.002800889313220978\n",
      "\n",
      "The classification loss after processing this batch is:  0.16058193147182465\n",
      "The representation loss after processing this batch is:  0.003040086477994919\n",
      "\n",
      "The classification loss after processing this batch is:  0.2813119888305664\n",
      "The representation loss after processing this batch is:  0.0030159056186676025\n",
      "\n",
      "The classification loss after processing this batch is:  0.13989725708961487\n",
      "The representation loss after processing this batch is:  0.002825312316417694\n",
      "\n",
      "The classification loss after processing this batch is:  0.14856252074241638\n",
      "The representation loss after processing this batch is:  0.002652309834957123\n",
      "\n",
      "The classification loss after processing this batch is:  0.16413834691047668\n",
      "The representation loss after processing this batch is:  0.0026975423097610474\n",
      "\n",
      "The classification loss after processing this batch is:  0.15438826382160187\n",
      "The representation loss after processing this batch is:  0.0028030462563037872\n",
      "\n",
      "The classification loss after processing this batch is:  0.11833319067955017\n",
      "The representation loss after processing this batch is:  0.003147207200527191\n",
      "\n",
      "The classification loss after processing this batch is:  0.21925359964370728\n",
      "The representation loss after processing this batch is:  0.002895824611186981\n",
      "\n",
      "The classification loss after processing this batch is:  0.22299152612686157\n",
      "The representation loss after processing this batch is:  0.003069154918193817\n",
      "\n",
      "The classification loss after processing this batch is:  0.2588079571723938\n",
      "The representation loss after processing this batch is:  0.00282079353928566\n",
      "\n",
      "The classification loss after processing this batch is:  0.14101459085941315\n",
      "The representation loss after processing this batch is:  0.002929404377937317\n",
      "\n",
      "The classification loss after processing this batch is:  0.2250632345676422\n",
      "The representation loss after processing this batch is:  0.0030454546213150024\n",
      "\n",
      "The classification loss after processing this batch is:  0.2316589057445526\n",
      "The representation loss after processing this batch is:  0.0031940825283527374\n",
      "\n",
      "The classification loss after processing this batch is:  0.20325036346912384\n",
      "The representation loss after processing this batch is:  0.0029489323496818542\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10860288143157959\n",
      "The representation loss after processing this batch is:  0.003162696957588196\n",
      "\n",
      "The classification loss after processing this batch is:  0.16592258214950562\n",
      "The representation loss after processing this batch is:  0.0034427642822265625\n",
      "\n",
      "The classification loss after processing this batch is:  0.3272947371006012\n",
      "The representation loss after processing this batch is:  0.0030359476804733276\n",
      "\n",
      "The classification loss after processing this batch is:  0.2752979099750519\n",
      "The representation loss after processing this batch is:  0.0029809288680553436\n",
      "\n",
      "The classification loss after processing this batch is:  0.2811955213546753\n",
      "The representation loss after processing this batch is:  0.0033764615654945374\n",
      "\n",
      "The classification loss after processing this batch is:  0.38137537240982056\n",
      "The representation loss after processing this batch is:  0.0029434934258461\n",
      "\n",
      "The classification loss after processing this batch is:  0.287704735994339\n",
      "The representation loss after processing this batch is:  0.002764008939266205\n",
      "\n",
      "The classification loss after processing this batch is:  0.11003570258617401\n",
      "The representation loss after processing this batch is:  0.002585276961326599\n",
      "\n",
      "The classification loss after processing this batch is:  0.11613533645868301\n",
      "The representation loss after processing this batch is:  0.002873264253139496\n",
      "\n",
      "The classification loss after processing this batch is:  0.1490563452243805\n",
      "The representation loss after processing this batch is:  0.0034437179565429688\n",
      "\n",
      "The classification loss after processing this batch is:  0.19052086770534515\n",
      "The representation loss after processing this batch is:  0.004095248878002167\n",
      "\n",
      "The classification loss after processing this batch is:  0.07305613905191422\n",
      "The representation loss after processing this batch is:  0.0032944455742836\n",
      "\n",
      "The classification loss after processing this batch is:  0.23798097670078278\n",
      "The representation loss after processing this batch is:  0.0036646947264671326\n",
      "\n",
      "The classification loss after processing this batch is:  0.18270276486873627\n",
      "The representation loss after processing this batch is:  0.0028574392199516296\n",
      "\n",
      "The classification loss after processing this batch is:  0.1587504744529724\n",
      "The representation loss after processing this batch is:  0.002863660454750061\n",
      "\n",
      "The classification loss after processing this batch is:  0.2681036591529846\n",
      "The representation loss after processing this batch is:  0.0030343979597091675\n",
      "\n",
      "The classification loss after processing this batch is:  0.12781396508216858\n",
      "The representation loss after processing this batch is:  0.0034261494874954224\n",
      "\n",
      "The classification loss after processing this batch is:  0.23560793697834015\n",
      "The representation loss after processing this batch is:  0.0035414323210716248\n",
      "\n",
      "The classification loss after processing this batch is:  0.2248803973197937\n",
      "The representation loss after processing this batch is:  0.0033996328711509705\n",
      "\n",
      "The classification loss after processing this batch is:  0.1436886042356491\n",
      "The representation loss after processing this batch is:  0.0036161616444587708\n",
      "\n",
      "The classification loss after processing this batch is:  0.1795627772808075\n",
      "The representation loss after processing this batch is:  0.0025276988744735718\n",
      "\n",
      "The classification loss after processing this batch is:  0.12454284727573395\n",
      "The representation loss after processing this batch is:  0.0030197128653526306\n",
      "\n",
      "The classification loss after processing this batch is:  0.08804523199796677\n",
      "The representation loss after processing this batch is:  0.002942688763141632\n",
      "\n",
      "The classification loss after processing this batch is:  0.11330075562000275\n",
      "The representation loss after processing this batch is:  0.0030029788613319397\n",
      "\n",
      "The classification loss after processing this batch is:  0.11671985685825348\n",
      "The representation loss after processing this batch is:  0.00278598815202713\n",
      "\n",
      "The classification loss after processing this batch is:  0.13526135683059692\n",
      "The representation loss after processing this batch is:  0.0025368742644786835\n",
      "\n",
      "The classification loss after processing this batch is:  0.15518563985824585\n",
      "The representation loss after processing this batch is:  0.002868339419364929\n",
      "\n",
      "The classification loss after processing this batch is:  0.17943191528320312\n",
      "The representation loss after processing this batch is:  0.0029707252979278564\n",
      "\n",
      "The classification loss after processing this batch is:  0.41959714889526367\n",
      "The representation loss after processing this batch is:  0.003140680491924286\n",
      "\n",
      "The classification loss after processing this batch is:  0.289033442735672\n",
      "The representation loss after processing this batch is:  0.0033441931009292603\n",
      "\n",
      "The classification loss after processing this batch is:  0.12959988415241241\n",
      "The representation loss after processing this batch is:  0.0028700754046440125\n",
      "\n",
      "The classification loss after processing this batch is:  0.13459868729114532\n",
      "The representation loss after processing this batch is:  0.003438025712966919\n",
      "\n",
      "The classification loss after processing this batch is:  0.11887996643781662\n",
      "The representation loss after processing this batch is:  0.0031956732273101807\n",
      "\n",
      "The classification loss after processing this batch is:  0.12409723550081253\n",
      "The representation loss after processing this batch is:  0.002908743917942047\n",
      "\n",
      "The classification loss after processing this batch is:  0.07100444287061691\n",
      "The representation loss after processing this batch is:  0.0032503530383110046\n",
      "\n",
      "The classification loss after processing this batch is:  0.12266779690980911\n",
      "The representation loss after processing this batch is:  0.003118768334388733\n",
      "\n",
      "The classification loss after processing this batch is:  0.17032594978809357\n",
      "The representation loss after processing this batch is:  0.0028598085045814514\n",
      "\n",
      "The classification loss after processing this batch is:  0.25274452567100525\n",
      "The representation loss after processing this batch is:  0.002847488969564438\n",
      "\n",
      "The classification loss after processing this batch is:  0.12761296331882477\n",
      "The representation loss after processing this batch is:  0.0027647167444229126\n",
      "\n",
      "The classification loss after processing this batch is:  0.11266280710697174\n",
      "The representation loss after processing this batch is:  0.002810753881931305\n",
      "\n",
      "The classification loss after processing this batch is:  0.09146518260240555\n",
      "The representation loss after processing this batch is:  0.0028855428099632263\n",
      "\n",
      "The classification loss after processing this batch is:  0.28211259841918945\n",
      "The representation loss after processing this batch is:  0.003073815256357193\n",
      "\n",
      "The classification loss after processing this batch is:  0.14016558229923248\n",
      "The representation loss after processing this batch is:  0.0031438693404197693\n",
      "\n",
      "The classification loss after processing this batch is:  0.10034999251365662\n",
      "The representation loss after processing this batch is:  0.003018774092197418\n",
      "\n",
      "The classification loss after processing this batch is:  0.19687208533287048\n",
      "The representation loss after processing this batch is:  0.0031189322471618652\n",
      "\n",
      "The classification loss after processing this batch is:  0.13684776425361633\n",
      "The representation loss after processing this batch is:  0.002521432936191559\n",
      "\n",
      "The classification loss after processing this batch is:  0.10933347791433334\n",
      "The representation loss after processing this batch is:  0.0027400702238082886\n",
      "\n",
      "The classification loss after processing this batch is:  0.17784157395362854\n",
      "The representation loss after processing this batch is:  0.003020375967025757\n",
      "\n",
      "The classification loss after processing this batch is:  0.11290296912193298\n",
      "The representation loss after processing this batch is:  0.002790205180644989\n",
      "\n",
      "The classification loss after processing this batch is:  0.1360664665699005\n",
      "The representation loss after processing this batch is:  0.0030216574668884277\n",
      "\n",
      "The classification loss after processing this batch is:  0.23490406572818756\n",
      "The representation loss after processing this batch is:  0.002873718738555908\n",
      "\n",
      "The classification loss after processing this batch is:  0.22887302935123444\n",
      "The representation loss after processing this batch is:  0.0027921050786972046\n",
      "\n",
      "The classification loss after processing this batch is:  0.22042173147201538\n",
      "The representation loss after processing this batch is:  0.0031529366970062256\n",
      "\n",
      "The classification loss after processing this batch is:  0.23659373819828033\n",
      "The representation loss after processing this batch is:  0.0028492100536823273\n",
      "\n",
      "The classification loss after processing this batch is:  0.1371990144252777\n",
      "The representation loss after processing this batch is:  0.0029983744025230408\n",
      "\n",
      "The classification loss after processing this batch is:  0.20184971392154694\n",
      "The representation loss after processing this batch is:  0.002871207892894745\n",
      "\n",
      "The classification loss after processing this batch is:  0.12590719759464264\n",
      "The representation loss after processing this batch is:  0.0032165944576263428\n",
      "\n",
      "The classification loss after processing this batch is:  0.1798563003540039\n",
      "The representation loss after processing this batch is:  0.0032974258065223694\n",
      "\n",
      "The classification loss after processing this batch is:  0.12073100358247757\n",
      "The representation loss after processing this batch is:  0.002645164728164673\n",
      "\n",
      "The classification loss after processing this batch is:  0.21216903626918793\n",
      "The representation loss after processing this batch is:  0.0026693344116210938\n",
      "\n",
      "The classification loss after processing this batch is:  0.11887199431657791\n",
      "The representation loss after processing this batch is:  0.002976559102535248\n",
      "\n",
      "The classification loss after processing this batch is:  0.166355699300766\n",
      "The representation loss after processing this batch is:  0.0025747381150722504\n",
      "\n",
      "The classification loss after processing this batch is:  0.17689211666584015\n",
      "The representation loss after processing this batch is:  0.002642996609210968\n",
      "\n",
      "The classification loss after processing this batch is:  0.16654831171035767\n",
      "The representation loss after processing this batch is:  0.002848386764526367\n",
      "\n",
      "The classification loss after processing this batch is:  0.22038856148719788\n",
      "The representation loss after processing this batch is:  0.0026542842388153076\n",
      "\n",
      "The classification loss after processing this batch is:  0.2154720276594162\n",
      "The representation loss after processing this batch is:  0.0025767236948013306\n",
      "\n",
      "The classification loss after processing this batch is:  0.2372654229402542\n",
      "The representation loss after processing this batch is:  0.0026809461414813995\n",
      "\n",
      "The classification loss after processing this batch is:  0.27196985483169556\n",
      "The representation loss after processing this batch is:  0.00291278213262558\n",
      "\n",
      "The classification loss after processing this batch is:  0.31328821182250977\n",
      "The representation loss after processing this batch is:  0.0028436630964279175\n",
      "\n",
      "The classification loss after processing this batch is:  0.2522243857383728\n",
      "The representation loss after processing this batch is:  0.0024544447660446167\n",
      "\n",
      "The classification loss after processing this batch is:  0.10735604912042618\n",
      "The representation loss after processing this batch is:  0.0029453039169311523\n",
      "\n",
      "The classification loss after processing this batch is:  0.19668236374855042\n",
      "The representation loss after processing this batch is:  0.0030740946531295776\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14265435934066772\n",
      "The representation loss after processing this batch is:  0.0030111074447631836\n",
      "\n",
      "The classification loss after processing this batch is:  0.14791423082351685\n",
      "The representation loss after processing this batch is:  0.0033531934022903442\n",
      "\n",
      "The classification loss after processing this batch is:  0.2630229890346527\n",
      "The representation loss after processing this batch is:  0.003498546779155731\n",
      "\n",
      "The classification loss after processing this batch is:  0.2814476788043976\n",
      "The representation loss after processing this batch is:  0.0032105743885040283\n",
      "\n",
      "The classification loss after processing this batch is:  0.3727394938468933\n",
      "The representation loss after processing this batch is:  0.003054581582546234\n",
      "\n",
      "The classification loss after processing this batch is:  0.20580196380615234\n",
      "The representation loss after processing this batch is:  0.0032469667494297028\n",
      "\n",
      "The classification loss after processing this batch is:  0.11167384684085846\n",
      "The representation loss after processing this batch is:  0.0029457733035087585\n",
      "\n",
      "The classification loss after processing this batch is:  0.12173309922218323\n",
      "The representation loss after processing this batch is:  0.003048434853553772\n",
      "\n",
      "The classification loss after processing this batch is:  0.2410750538110733\n",
      "The representation loss after processing this batch is:  0.002676643431186676\n",
      "\n",
      "The classification loss after processing this batch is:  0.1181173175573349\n",
      "The representation loss after processing this batch is:  0.002978108823299408\n",
      "\n",
      "The classification loss after processing this batch is:  0.1417107880115509\n",
      "The representation loss after processing this batch is:  0.002927921712398529\n",
      "\n",
      "The classification loss after processing this batch is:  0.11306148022413254\n",
      "The representation loss after processing this batch is:  0.003232434391975403\n",
      "\n",
      "The classification loss after processing this batch is:  0.05101243779063225\n",
      "The representation loss after processing this batch is:  0.002897590398788452\n",
      "\n",
      "The classification loss after processing this batch is:  0.18582512438297272\n",
      "The representation loss after processing this batch is:  0.003140464425086975\n",
      "\n",
      "The classification loss after processing this batch is:  0.14401739835739136\n",
      "The representation loss after processing this batch is:  0.0033893175423145294\n",
      "\n",
      "The classification loss after processing this batch is:  0.21760374307632446\n",
      "The representation loss after processing this batch is:  0.0028067082166671753\n",
      "\n",
      "The classification loss after processing this batch is:  0.19231148064136505\n",
      "The representation loss after processing this batch is:  0.002603106200695038\n",
      "\n",
      "The classification loss after processing this batch is:  0.17222703993320465\n",
      "The representation loss after processing this batch is:  0.0029963254928588867\n",
      "\n",
      "The classification loss after processing this batch is:  0.19471560418605804\n",
      "The representation loss after processing this batch is:  0.002849787473678589\n",
      "\n",
      "The classification loss after processing this batch is:  0.16571523249149323\n",
      "The representation loss after processing this batch is:  0.002934850752353668\n",
      "\n",
      "The classification loss after processing this batch is:  0.17735831439495087\n",
      "The representation loss after processing this batch is:  0.0032379180192947388\n",
      "\n",
      "The classification loss after processing this batch is:  0.21776215732097626\n",
      "The representation loss after processing this batch is:  0.0032668262720108032\n",
      "\n",
      "The classification loss after processing this batch is:  0.20688432455062866\n",
      "The representation loss after processing this batch is:  0.003310099244117737\n",
      "\n",
      "The classification loss after processing this batch is:  0.16483575105667114\n",
      "The representation loss after processing this batch is:  0.002721533179283142\n",
      "\n",
      "The classification loss after processing this batch is:  0.25369611382484436\n",
      "The representation loss after processing this batch is:  0.0029747597873210907\n",
      "\n",
      "The classification loss after processing this batch is:  0.28457915782928467\n",
      "The representation loss after processing this batch is:  0.0031753331422805786\n",
      "\n",
      "The classification loss after processing this batch is:  0.1288345456123352\n",
      "The representation loss after processing this batch is:  0.0025283806025981903\n",
      "\n",
      "The classification loss after processing this batch is:  0.16179010272026062\n",
      "The representation loss after processing this batch is:  0.0031675733625888824\n",
      "\n",
      "The classification loss after processing this batch is:  0.18294160068035126\n",
      "The representation loss after processing this batch is:  0.0030216313898563385\n",
      "\n",
      "The classification loss after processing this batch is:  0.19526711106300354\n",
      "The representation loss after processing this batch is:  0.00284498929977417\n",
      "\n",
      "The classification loss after processing this batch is:  0.2579185366630554\n",
      "The representation loss after processing this batch is:  0.0035046860575675964\n",
      "\n",
      "The classification loss after processing this batch is:  0.28502240777015686\n",
      "The representation loss after processing this batch is:  0.003482341766357422\n",
      "\n",
      "The classification loss after processing this batch is:  0.2839130461215973\n",
      "The representation loss after processing this batch is:  0.003228895366191864\n",
      "\n",
      "The classification loss after processing this batch is:  0.22226931154727936\n",
      "The representation loss after processing this batch is:  0.003141462802886963\n",
      "\n",
      "The classification loss after processing this batch is:  0.1839827597141266\n",
      "The representation loss after processing this batch is:  0.0030745938420295715\n",
      "\n",
      "The classification loss after processing this batch is:  0.146297886967659\n",
      "The representation loss after processing this batch is:  0.0033608004450798035\n",
      "\n",
      "The classification loss after processing this batch is:  0.10855236649513245\n",
      "The representation loss after processing this batch is:  0.0031069517135620117\n",
      "\n",
      "The classification loss after processing this batch is:  0.2219536155462265\n",
      "The representation loss after processing this batch is:  0.0030153654515743256\n",
      "\n",
      "The classification loss after processing this batch is:  0.19960568845272064\n",
      "The representation loss after processing this batch is:  0.00289299339056015\n",
      "\n",
      "The classification loss after processing this batch is:  0.12730750441551208\n",
      "The representation loss after processing this batch is:  0.002790607511997223\n",
      "\n",
      "The classification loss after processing this batch is:  0.17545193433761597\n",
      "The representation loss after processing this batch is:  0.003048337996006012\n",
      "\n",
      "The classification loss after processing this batch is:  0.14788247644901276\n",
      "The representation loss after processing this batch is:  0.0036152303218841553\n",
      "\n",
      "The classification loss after processing this batch is:  0.19435222446918488\n",
      "The representation loss after processing this batch is:  0.0030092820525169373\n",
      "\n",
      "The classification loss after processing this batch is:  0.1484266072511673\n",
      "The representation loss after processing this batch is:  0.003008037805557251\n",
      "\n",
      "The classification loss after processing this batch is:  0.1486663520336151\n",
      "The representation loss after processing this batch is:  0.0028880536556243896\n",
      "\n",
      "The classification loss after processing this batch is:  0.09209839254617691\n",
      "The representation loss after processing this batch is:  0.002702467143535614\n",
      "\n",
      "The classification loss after processing this batch is:  0.14113755524158478\n",
      "The representation loss after processing this batch is:  0.002600114792585373\n",
      "\n",
      "The classification loss after processing this batch is:  0.13180974125862122\n",
      "The representation loss after processing this batch is:  0.00264141708612442\n",
      "\n",
      "The classification loss after processing this batch is:  0.5029442310333252\n",
      "The representation loss after processing this batch is:  0.003197677433490753\n",
      "\n",
      "The classification loss after processing this batch is:  0.15060825645923615\n",
      "The representation loss after processing this batch is:  0.002812623977661133\n",
      "\n",
      "The classification loss after processing this batch is:  0.31217366456985474\n",
      "The representation loss after processing this batch is:  0.0026406608521938324\n",
      "\n",
      "The classification loss after processing this batch is:  0.3105056583881378\n",
      "The representation loss after processing this batch is:  0.002975478768348694\n",
      "\n",
      "The classification loss after processing this batch is:  0.1678801029920578\n",
      "The representation loss after processing this batch is:  0.0027747303247451782\n",
      "\n",
      "The classification loss after processing this batch is:  0.3346378207206726\n",
      "The representation loss after processing this batch is:  0.0034720003604888916\n",
      "\n",
      "The classification loss after processing this batch is:  0.15960797667503357\n",
      "The representation loss after processing this batch is:  0.0028891079127788544\n",
      "\n",
      "The classification loss after processing this batch is:  0.29170629382133484\n",
      "The representation loss after processing this batch is:  0.0029615499079227448\n",
      "\n",
      "The classification loss after processing this batch is:  0.1005515307188034\n",
      "The representation loss after processing this batch is:  0.0028909817337989807\n",
      "\n",
      "The classification loss after processing this batch is:  0.11725056171417236\n",
      "The representation loss after processing this batch is:  0.0027885138988494873\n",
      "\n",
      "The classification loss after processing this batch is:  0.08979041874408722\n",
      "The representation loss after processing this batch is:  0.0032496824860572815\n",
      "\n",
      "The classification loss after processing this batch is:  0.07768554985523224\n",
      "The representation loss after processing this batch is:  0.002935364842414856\n",
      "\n",
      "The classification loss after processing this batch is:  0.13728603720664978\n",
      "The representation loss after processing this batch is:  0.002984553575515747\n",
      "\n",
      "The classification loss after processing this batch is:  0.10723520815372467\n",
      "The representation loss after processing this batch is:  0.002674505114555359\n",
      "\n",
      "The classification loss after processing this batch is:  0.16975265741348267\n",
      "The representation loss after processing this batch is:  0.003204941749572754\n",
      "\n",
      "The classification loss after processing this batch is:  0.11718297004699707\n",
      "The representation loss after processing this batch is:  0.0034192726016044617\n",
      "\n",
      "The classification loss after processing this batch is:  0.13638052344322205\n",
      "The representation loss after processing this batch is:  0.0028039366006851196\n",
      "\n",
      "The classification loss after processing this batch is:  0.16281916201114655\n",
      "The representation loss after processing this batch is:  0.002703443169593811\n",
      "\n",
      "The classification loss after processing this batch is:  0.08798098564147949\n",
      "The representation loss after processing this batch is:  0.002876102924346924\n",
      "\n",
      "The classification loss after processing this batch is:  0.17729128897190094\n",
      "The representation loss after processing this batch is:  0.002933099865913391\n",
      "\n",
      "The classification loss after processing this batch is:  0.17286093533039093\n",
      "The representation loss after processing this batch is:  0.002967134118080139\n",
      "\n",
      "The classification loss after processing this batch is:  0.2294066697359085\n",
      "The representation loss after processing this batch is:  0.0032782629132270813\n",
      "\n",
      "The classification loss after processing this batch is:  0.16327939927577972\n",
      "The representation loss after processing this batch is:  0.0025724321603775024\n",
      "\n",
      "The classification loss after processing this batch is:  0.11457981914281845\n",
      "The representation loss after processing this batch is:  0.0025709159672260284\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2777210474014282\n",
      "The representation loss after processing this batch is:  0.0032371655106544495\n",
      "\n",
      "The classification loss after processing this batch is:  0.212239071726799\n",
      "The representation loss after processing this batch is:  0.002950623631477356\n",
      "\n",
      "The classification loss after processing this batch is:  0.1936061829328537\n",
      "The representation loss after processing this batch is:  0.0030132755637168884\n",
      "\n",
      "The classification loss after processing this batch is:  0.09797158092260361\n",
      "The representation loss after processing this batch is:  0.0028102993965148926\n",
      "\n",
      "The classification loss after processing this batch is:  0.14222854375839233\n",
      "The representation loss after processing this batch is:  0.0028921663761138916\n",
      "\n",
      "The classification loss after processing this batch is:  0.16384242475032806\n",
      "The representation loss after processing this batch is:  0.0028941482305526733\n",
      "\n",
      "The classification loss after processing this batch is:  0.19061610102653503\n",
      "The representation loss after processing this batch is:  0.0036256201565265656\n",
      "\n",
      "The classification loss after processing this batch is:  0.16167917847633362\n",
      "The representation loss after processing this batch is:  0.0035092979669570923\n",
      "\n",
      "The classification loss after processing this batch is:  0.16723455488681793\n",
      "The representation loss after processing this batch is:  0.003499966114759445\n",
      "\n",
      "The classification loss after processing this batch is:  0.20791493356227875\n",
      "The representation loss after processing this batch is:  0.0031978487968444824\n",
      "\n",
      "The classification loss after processing this batch is:  0.2963423728942871\n",
      "The representation loss after processing this batch is:  0.0029777921736240387\n",
      "\n",
      "The classification loss after processing this batch is:  0.2038239687681198\n",
      "The representation loss after processing this batch is:  0.0036569014191627502\n",
      "\n",
      "The classification loss after processing this batch is:  0.19036278128623962\n",
      "The representation loss after processing this batch is:  0.0027154013514518738\n",
      "\n",
      "The classification loss after processing this batch is:  0.12757688760757446\n",
      "The representation loss after processing this batch is:  0.0026340894401073456\n",
      "\n",
      "The classification loss after processing this batch is:  0.23518531024456024\n",
      "The representation loss after processing this batch is:  0.002889782190322876\n",
      "\n",
      "The classification loss after processing this batch is:  0.09919717907905579\n",
      "The representation loss after processing this batch is:  0.003013603389263153\n",
      "\n",
      "The classification loss after processing this batch is:  0.15513962507247925\n",
      "The representation loss after processing this batch is:  0.0028630420565605164\n",
      "\n",
      "The classification loss after processing this batch is:  0.13241226971149445\n",
      "The representation loss after processing this batch is:  0.0030420422554016113\n",
      "\n",
      "The classification loss after processing this batch is:  0.13937047123908997\n",
      "The representation loss after processing this batch is:  0.0027862340211868286\n",
      "\n",
      "The classification loss after processing this batch is:  0.12592510879039764\n",
      "The representation loss after processing this batch is:  0.0031446442008018494\n",
      "\n",
      "The classification loss after processing this batch is:  0.2167176604270935\n",
      "The representation loss after processing this batch is:  0.0031324252486228943\n",
      "\n",
      "The classification loss after processing this batch is:  0.18294492363929749\n",
      "The representation loss after processing this batch is:  0.0033659636974334717\n",
      "\n",
      "The classification loss after processing this batch is:  0.21212901175022125\n",
      "The representation loss after processing this batch is:  0.0028572119772434235\n",
      "\n",
      "The classification loss after processing this batch is:  0.1917632520198822\n",
      "The representation loss after processing this batch is:  0.0033633187413215637\n",
      "\n",
      "The classification loss after processing this batch is:  0.171938955783844\n",
      "The representation loss after processing this batch is:  0.0031118243932724\n",
      "\n",
      "The classification loss after processing this batch is:  0.1294524222612381\n",
      "The representation loss after processing this batch is:  0.002936750650405884\n",
      "\n",
      "The classification loss after processing this batch is:  0.10985781252384186\n",
      "The representation loss after processing this batch is:  0.003274276852607727\n",
      "\n",
      "The classification loss after processing this batch is:  0.13715606927871704\n",
      "The representation loss after processing this batch is:  0.003113921731710434\n",
      "\n",
      "The classification loss after processing this batch is:  0.07681896537542343\n",
      "The representation loss after processing this batch is:  0.0029801689088344574\n",
      "\n",
      "The classification loss after processing this batch is:  0.08008439093828201\n",
      "The representation loss after processing this batch is:  0.002809271216392517\n",
      "\n",
      "The classification loss after processing this batch is:  0.12313244491815567\n",
      "The representation loss after processing this batch is:  0.0031091272830963135\n",
      "\n",
      "The classification loss after processing this batch is:  0.08455263078212738\n",
      "The representation loss after processing this batch is:  0.00315750390291214\n",
      "\n",
      "The classification loss after processing this batch is:  0.19298222661018372\n",
      "The representation loss after processing this batch is:  0.0029148459434509277\n",
      "\n",
      "The classification loss after processing this batch is:  0.13610944151878357\n",
      "The representation loss after processing this batch is:  0.00262262299656868\n",
      "\n",
      "The classification loss after processing this batch is:  0.19067220389842987\n",
      "The representation loss after processing this batch is:  0.002969857305288315\n",
      "\n",
      "The classification loss after processing this batch is:  0.0838480070233345\n",
      "The representation loss after processing this batch is:  0.003364071249961853\n",
      "\n",
      "The classification loss after processing this batch is:  0.2260836809873581\n",
      "The representation loss after processing this batch is:  0.0029626451432704926\n",
      "\n",
      "The classification loss after processing this batch is:  0.19078880548477173\n",
      "The representation loss after processing this batch is:  0.0031046196818351746\n",
      "\n",
      "The classification loss after processing this batch is:  0.14178742468357086\n",
      "The representation loss after processing this batch is:  0.002684392035007477\n",
      "\n",
      "The classification loss after processing this batch is:  0.20061169564723969\n",
      "The representation loss after processing this batch is:  0.0029804110527038574\n",
      "\n",
      "The classification loss after processing this batch is:  0.19033314287662506\n",
      "The representation loss after processing this batch is:  0.003227055072784424\n",
      "\n",
      "The classification loss after processing this batch is:  0.08047979325056076\n",
      "The representation loss after processing this batch is:  0.002661287784576416\n",
      "\n",
      "The classification loss after processing this batch is:  0.1193932518362999\n",
      "The representation loss after processing this batch is:  0.002764478325843811\n",
      "\n",
      "The classification loss after processing this batch is:  0.12193522602319717\n",
      "The representation loss after processing this batch is:  0.0026673004031181335\n",
      "\n",
      "The classification loss after processing this batch is:  0.22113925218582153\n",
      "The representation loss after processing this batch is:  0.0029169470071792603\n",
      "\n",
      "The classification loss after processing this batch is:  0.20437195897102356\n",
      "The representation loss after processing this batch is:  0.0027691423892974854\n",
      "\n",
      "The classification loss after processing this batch is:  0.17880065739154816\n",
      "The representation loss after processing this batch is:  0.0036375299096107483\n",
      "\n",
      "The classification loss after processing this batch is:  0.24194839596748352\n",
      "The representation loss after processing this batch is:  0.002933815121650696\n",
      "\n",
      "The classification loss after processing this batch is:  0.22858098149299622\n",
      "The representation loss after processing this batch is:  0.003056161105632782\n",
      "\n",
      "The classification loss after processing this batch is:  0.21002382040023804\n",
      "The representation loss after processing this batch is:  0.0026759058237075806\n",
      "\n",
      "The classification loss after processing this batch is:  0.3546708822250366\n",
      "The representation loss after processing this batch is:  0.0027593299746513367\n",
      "\n",
      "The classification loss after processing this batch is:  0.2289682775735855\n",
      "The representation loss after processing this batch is:  0.0027556903660297394\n",
      "\n",
      "The classification loss after processing this batch is:  0.17229923605918884\n",
      "The representation loss after processing this batch is:  0.002677515149116516\n",
      "\n",
      "The classification loss after processing this batch is:  0.1326511949300766\n",
      "The representation loss after processing this batch is:  0.0029904544353485107\n",
      "\n",
      "The classification loss after processing this batch is:  0.08721831440925598\n",
      "The representation loss after processing this batch is:  0.002848707139492035\n",
      "\n",
      "The classification loss after processing this batch is:  0.08422780781984329\n",
      "The representation loss after processing this batch is:  0.0027904659509658813\n",
      "\n",
      "The classification loss after processing this batch is:  0.12745535373687744\n",
      "The representation loss after processing this batch is:  0.0035344064235687256\n",
      "\n",
      "The classification loss after processing this batch is:  0.1435035765171051\n",
      "The representation loss after processing this batch is:  0.002705872058868408\n",
      "\n",
      "The classification loss after processing this batch is:  0.12333700060844421\n",
      "The representation loss after processing this batch is:  0.0029907450079917908\n",
      "\n",
      "The classification loss after processing this batch is:  0.2082986980676651\n",
      "The representation loss after processing this batch is:  0.00305137038230896\n",
      "\n",
      "The classification loss after processing this batch is:  0.20404036343097687\n",
      "The representation loss after processing this batch is:  0.0032050982117652893\n",
      "\n",
      "The classification loss after processing this batch is:  0.22416594624519348\n",
      "The representation loss after processing this batch is:  0.0027771182358264923\n",
      "\n",
      "The classification loss after processing this batch is:  0.15890687704086304\n",
      "The representation loss after processing this batch is:  0.0027639493346214294\n",
      "\n",
      "The classification loss after processing this batch is:  0.23581475019454956\n",
      "The representation loss after processing this batch is:  0.0027202554047107697\n",
      "\n",
      "The classification loss after processing this batch is:  0.18143314123153687\n",
      "The representation loss after processing this batch is:  0.0027521178126335144\n",
      "\n",
      "The classification loss after processing this batch is:  0.10313980281352997\n",
      "The representation loss after processing this batch is:  0.0029998943209648132\n",
      "\n",
      "The classification loss after processing this batch is:  0.2238176316022873\n",
      "The representation loss after processing this batch is:  0.0028331056237220764\n",
      "\n",
      "The classification loss after processing this batch is:  0.08229027688503265\n",
      "The representation loss after processing this batch is:  0.0028179585933685303\n",
      "\n",
      "The classification loss after processing this batch is:  0.08994738757610321\n",
      "The representation loss after processing this batch is:  0.002597600221633911\n",
      "\n",
      "The classification loss after processing this batch is:  0.13912099599838257\n",
      "The representation loss after processing this batch is:  0.0032204389572143555\n",
      "\n",
      "The classification loss after processing this batch is:  0.20214350521564484\n",
      "The representation loss after processing this batch is:  0.0027994737029075623\n",
      "\n",
      "The classification loss after processing this batch is:  0.17232151329517365\n",
      "The representation loss after processing this batch is:  0.003120526671409607\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10721408575773239\n",
      "The representation loss after processing this batch is:  0.003099799156188965\n",
      "\n",
      "The classification loss after processing this batch is:  0.1750689446926117\n",
      "The representation loss after processing this batch is:  0.0033560767769813538\n",
      "\n",
      "The classification loss after processing this batch is:  0.10629144310951233\n",
      "The representation loss after processing this batch is:  0.0029787495732307434\n",
      "\n",
      "The classification loss after processing this batch is:  0.23274558782577515\n",
      "The representation loss after processing this batch is:  0.0031112954020500183\n",
      "\n",
      "The classification loss after processing this batch is:  0.09033571928739548\n",
      "The representation loss after processing this batch is:  0.0025969892740249634\n",
      "\n",
      "The classification loss after processing this batch is:  0.08386723697185516\n",
      "The representation loss after processing this batch is:  0.0030882731080055237\n",
      "\n",
      "The classification loss after processing this batch is:  0.15405002236366272\n",
      "The representation loss after processing this batch is:  0.0037819892168045044\n",
      "\n",
      "The classification loss after processing this batch is:  0.1503111571073532\n",
      "The representation loss after processing this batch is:  0.0031499341130256653\n",
      "\n",
      "The classification loss after processing this batch is:  0.14924314618110657\n",
      "The representation loss after processing this batch is:  0.003515690565109253\n",
      "\n",
      "The classification loss after processing this batch is:  0.11145865172147751\n",
      "The representation loss after processing this batch is:  0.002986367791891098\n",
      "\n",
      "The classification loss after processing this batch is:  0.18243303894996643\n",
      "The representation loss after processing this batch is:  0.0032418668270111084\n",
      "\n",
      "The classification loss after processing this batch is:  0.25273221731185913\n",
      "The representation loss after processing this batch is:  0.003086693584918976\n",
      "\n",
      "The classification loss after processing this batch is:  0.23377418518066406\n",
      "The representation loss after processing this batch is:  0.0029569119215011597\n",
      "\n",
      "The classification loss after processing this batch is:  0.2045065313577652\n",
      "The representation loss after processing this batch is:  0.0033868923783302307\n",
      "\n",
      "The classification loss after processing this batch is:  0.10314897447824478\n",
      "The representation loss after processing this batch is:  0.002918653190135956\n",
      "\n",
      "The classification loss after processing this batch is:  0.10778234899044037\n",
      "The representation loss after processing this batch is:  0.0025156401097774506\n",
      "\n",
      "The classification loss after processing this batch is:  0.24542236328125\n",
      "The representation loss after processing this batch is:  0.003473639488220215\n",
      "\n",
      "The classification loss after processing this batch is:  0.3173520267009735\n",
      "The representation loss after processing this batch is:  0.0035838782787323\n",
      "\n",
      "The classification loss after processing this batch is:  0.2734384536743164\n",
      "The representation loss after processing this batch is:  0.0036010146141052246\n",
      "\n",
      "The classification loss after processing this batch is:  0.300711452960968\n",
      "The representation loss after processing this batch is:  0.003149893134832382\n",
      "\n",
      "The classification loss after processing this batch is:  0.13577787578105927\n",
      "The representation loss after processing this batch is:  0.0026757419109344482\n",
      "\n",
      "The classification loss after processing this batch is:  0.23377862572669983\n",
      "The representation loss after processing this batch is:  0.0028144121170043945\n",
      "\n",
      "The classification loss after processing this batch is:  0.16920562088489532\n",
      "The representation loss after processing this batch is:  0.002893418073654175\n",
      "\n",
      "The classification loss after processing this batch is:  0.17313797771930695\n",
      "The representation loss after processing this batch is:  0.002812787890434265\n",
      "\n",
      "The classification loss after processing this batch is:  0.12603814899921417\n",
      "The representation loss after processing this batch is:  0.002755172550678253\n",
      "\n",
      "The classification loss after processing this batch is:  0.1868184208869934\n",
      "The representation loss after processing this batch is:  0.002939291298389435\n",
      "\n",
      "The classification loss after processing this batch is:  0.16717611253261566\n",
      "The representation loss after processing this batch is:  0.003072895109653473\n",
      "\n",
      "The classification loss after processing this batch is:  0.19181694090366364\n",
      "The representation loss after processing this batch is:  0.002707459032535553\n",
      "\n",
      "The classification loss after processing this batch is:  0.17992442846298218\n",
      "The representation loss after processing this batch is:  0.0027868226170539856\n",
      "\n",
      "The classification loss after processing this batch is:  0.0836443156003952\n",
      "The representation loss after processing this batch is:  0.0030510053038597107\n",
      "\n",
      "The classification loss after processing this batch is:  0.11759305745363235\n",
      "The representation loss after processing this batch is:  0.0030127838253974915\n",
      "\n",
      "The classification loss after processing this batch is:  0.17267730832099915\n",
      "The representation loss after processing this batch is:  0.003077492117881775\n",
      "\n",
      "The classification loss after processing this batch is:  0.1436462551355362\n",
      "The representation loss after processing this batch is:  0.003016166388988495\n",
      "\n",
      "The classification loss after processing this batch is:  0.10523464530706406\n",
      "The representation loss after processing this batch is:  0.0034803226590156555\n",
      "\n",
      "The classification loss after processing this batch is:  0.10801346600055695\n",
      "The representation loss after processing this batch is:  0.0026139020919799805\n",
      "\n",
      "The classification loss after processing this batch is:  0.2178516387939453\n",
      "The representation loss after processing this batch is:  0.003279969096183777\n",
      "\n",
      "The classification loss after processing this batch is:  0.2107696682214737\n",
      "The representation loss after processing this batch is:  0.00288265198469162\n",
      "\n",
      "The classification loss after processing this batch is:  0.17827892303466797\n",
      "The representation loss after processing this batch is:  0.002675667405128479\n",
      "\n",
      "The classification loss after processing this batch is:  0.13349761068820953\n",
      "The representation loss after processing this batch is:  0.002609759569168091\n",
      "\n",
      "The classification loss after processing this batch is:  0.12181874364614487\n",
      "The representation loss after processing this batch is:  0.00290004163980484\n",
      "\n",
      "The classification loss after processing this batch is:  0.1013629138469696\n",
      "The representation loss after processing this batch is:  0.0027168840169906616\n",
      "\n",
      "The classification loss after processing this batch is:  0.14569200575351715\n",
      "The representation loss after processing this batch is:  0.0028364434838294983\n",
      "\n",
      "The classification loss after processing this batch is:  0.20779991149902344\n",
      "The representation loss after processing this batch is:  0.0030968710780143738\n",
      "\n",
      "The classification loss after processing this batch is:  0.2054305374622345\n",
      "The representation loss after processing this batch is:  0.003223806619644165\n",
      "\n",
      "The classification loss after processing this batch is:  0.1117386668920517\n",
      "The representation loss after processing this batch is:  0.0032888203859329224\n",
      "\n",
      "The classification loss after processing this batch is:  0.20646673440933228\n",
      "The representation loss after processing this batch is:  0.0028063133358955383\n",
      "\n",
      "The classification loss after processing this batch is:  0.25193917751312256\n",
      "The representation loss after processing this batch is:  0.002855271100997925\n",
      "\n",
      "The classification loss after processing this batch is:  0.0782315731048584\n",
      "The representation loss after processing this batch is:  0.0028985068202018738\n",
      "\n",
      "The classification loss after processing this batch is:  0.11436616629362106\n",
      "The representation loss after processing this batch is:  0.0025813691318035126\n",
      "\n",
      "The classification loss after processing this batch is:  0.21275955438613892\n",
      "The representation loss after processing this batch is:  0.0027945637702941895\n",
      "\n",
      "The classification loss after processing this batch is:  0.18910878896713257\n",
      "The representation loss after processing this batch is:  0.002834886312484741\n",
      "\n",
      "The classification loss after processing this batch is:  0.13245265185832977\n",
      "The representation loss after processing this batch is:  0.0030016154050827026\n",
      "\n",
      "The classification loss after processing this batch is:  0.31537583470344543\n",
      "The representation loss after processing this batch is:  0.002873651683330536\n",
      "\n",
      "The classification loss after processing this batch is:  0.20721596479415894\n",
      "The representation loss after processing this batch is:  0.0032197535037994385\n",
      "\n",
      "The classification loss after processing this batch is:  0.26106318831443787\n",
      "The representation loss after processing this batch is:  0.0030774176120758057\n",
      "\n",
      "The classification loss after processing this batch is:  0.1762486845254898\n",
      "The representation loss after processing this batch is:  0.003246091306209564\n",
      "\n",
      "The classification loss after processing this batch is:  0.20280307531356812\n",
      "The representation loss after processing this batch is:  0.0026036053895950317\n",
      "\n",
      "The classification loss after processing this batch is:  0.14127220213413239\n",
      "The representation loss after processing this batch is:  0.0040229931473731995\n",
      "\n",
      "The classification loss after processing this batch is:  0.13760234415531158\n",
      "The representation loss after processing this batch is:  0.002834826707839966\n",
      "\n",
      "The classification loss after processing this batch is:  0.1632584035396576\n",
      "The representation loss after processing this batch is:  0.0028104260563850403\n",
      "\n",
      "The classification loss after processing this batch is:  0.16901268064975739\n",
      "The representation loss after processing this batch is:  0.0024539679288864136\n",
      "\n",
      "The classification loss after processing this batch is:  0.16217803955078125\n",
      "The representation loss after processing this batch is:  0.0027612075209617615\n",
      "\n",
      "The classification loss after processing this batch is:  0.15477418899536133\n",
      "The representation loss after processing this batch is:  0.0027863308787345886\n",
      "\n",
      "The classification loss after processing this batch is:  0.2196500152349472\n",
      "The representation loss after processing this batch is:  0.0027767345309257507\n",
      "\n",
      "The classification loss after processing this batch is:  0.12338893860578537\n",
      "The representation loss after processing this batch is:  0.003123074769973755\n",
      "\n",
      "The classification loss after processing this batch is:  0.1113651841878891\n",
      "The representation loss after processing this batch is:  0.0032354891300201416\n",
      "\n",
      "The classification loss after processing this batch is:  0.1893450766801834\n",
      "The representation loss after processing this batch is:  0.0033934488892555237\n",
      "\n",
      "The classification loss after processing this batch is:  0.09855996072292328\n",
      "The representation loss after processing this batch is:  0.002904564142227173\n",
      "\n",
      "The classification loss after processing this batch is:  0.1315700262784958\n",
      "The representation loss after processing this batch is:  0.002831108868122101\n",
      "\n",
      "The classification loss after processing this batch is:  0.07655869424343109\n",
      "The representation loss after processing this batch is:  0.0032379254698753357\n",
      "\n",
      "The classification loss after processing this batch is:  0.11524320393800735\n",
      "The representation loss after processing this batch is:  0.0027095377445220947\n",
      "\n",
      "The classification loss after processing this batch is:  0.21134451031684875\n",
      "The representation loss after processing this batch is:  0.003197088837623596\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.21836547553539276\n",
      "The representation loss after processing this batch is:  0.004278115928173065\n",
      "\n",
      "The classification loss after processing this batch is:  0.16851727664470673\n",
      "The representation loss after processing this batch is:  0.0033228546380996704\n",
      "\n",
      "The classification loss after processing this batch is:  0.1535903960466385\n",
      "The representation loss after processing this batch is:  0.0031697824597358704\n",
      "\n",
      "The classification loss after processing this batch is:  0.14722351729869843\n",
      "The representation loss after processing this batch is:  0.0030187591910362244\n",
      "\n",
      "The classification loss after processing this batch is:  0.134164959192276\n",
      "The representation loss after processing this batch is:  0.002717539668083191\n",
      "\n",
      "The classification loss after processing this batch is:  0.09396518766880035\n",
      "The representation loss after processing this batch is:  0.003161318600177765\n",
      "\n",
      "The classification loss after processing this batch is:  0.10210230201482773\n",
      "The representation loss after processing this batch is:  0.00298134982585907\n",
      "\n",
      "The classification loss after processing this batch is:  0.11350496858358383\n",
      "The representation loss after processing this batch is:  0.0028798729181289673\n",
      "\n",
      "The classification loss after processing this batch is:  0.22422140836715698\n",
      "The representation loss after processing this batch is:  0.003507513552904129\n",
      "\n",
      "The classification loss after processing this batch is:  0.19778916239738464\n",
      "The representation loss after processing this batch is:  0.00330284982919693\n",
      "\n",
      "The classification loss after processing this batch is:  0.19202204048633575\n",
      "The representation loss after processing this batch is:  0.0029341503977775574\n",
      "\n",
      "The classification loss after processing this batch is:  0.15224075317382812\n",
      "The representation loss after processing this batch is:  0.003827229142189026\n",
      "\n",
      "The classification loss after processing this batch is:  0.1529982089996338\n",
      "The representation loss after processing this batch is:  0.003191150724887848\n",
      "\n",
      "The classification loss after processing this batch is:  0.2045241743326187\n",
      "The representation loss after processing this batch is:  0.003087136894464493\n",
      "\n",
      "The classification loss after processing this batch is:  0.15100225806236267\n",
      "The representation loss after processing this batch is:  0.002977617084980011\n",
      "\n",
      "The classification loss after processing this batch is:  0.35002246499061584\n",
      "The representation loss after processing this batch is:  0.0033312439918518066\n",
      "\n",
      "The classification loss after processing this batch is:  0.20627696812152863\n",
      "The representation loss after processing this batch is:  0.0029897838830947876\n",
      "\n",
      "The classification loss after processing this batch is:  0.2538227140903473\n",
      "The representation loss after processing this batch is:  0.00351068377494812\n",
      "\n",
      "The classification loss after processing this batch is:  0.1298546940088272\n",
      "The representation loss after processing this batch is:  0.002883315086364746\n",
      "\n",
      "The classification loss after processing this batch is:  0.116031214594841\n",
      "The representation loss after processing this batch is:  0.003023594617843628\n",
      "\n",
      "The classification loss after processing this batch is:  0.2083035409450531\n",
      "The representation loss after processing this batch is:  0.0026119500398635864\n",
      "\n",
      "The classification loss after processing this batch is:  0.17355868220329285\n",
      "The representation loss after processing this batch is:  0.0030451565980911255\n",
      "\n",
      "The classification loss after processing this batch is:  0.288995623588562\n",
      "The representation loss after processing this batch is:  0.002683013677597046\n",
      "\n",
      "The classification loss after processing this batch is:  0.2630982995033264\n",
      "The representation loss after processing this batch is:  0.0034353509545326233\n",
      "\n",
      "The classification loss after processing this batch is:  0.2071254998445511\n",
      "The representation loss after processing this batch is:  0.003319844603538513\n",
      "\n",
      "The classification loss after processing this batch is:  0.1641015112400055\n",
      "The representation loss after processing this batch is:  0.002879887819290161\n",
      "\n",
      "The classification loss after processing this batch is:  0.08199957758188248\n",
      "The representation loss after processing this batch is:  0.0029197409749031067\n",
      "\n",
      "The classification loss after processing this batch is:  0.13944755494594574\n",
      "The representation loss after processing this batch is:  0.0026015453040599823\n",
      "\n",
      "The classification loss after processing this batch is:  0.13335298001766205\n",
      "The representation loss after processing this batch is:  0.0027944743633270264\n",
      "\n",
      "The classification loss after processing this batch is:  0.11464203149080276\n",
      "The representation loss after processing this batch is:  0.003095760941505432\n",
      "\n",
      "The classification loss after processing this batch is:  0.14984585344791412\n",
      "The representation loss after processing this batch is:  0.0027044638991355896\n",
      "\n",
      "The classification loss after processing this batch is:  0.24581189453601837\n",
      "The representation loss after processing this batch is:  0.0029141902923583984\n",
      "\n",
      "The classification loss after processing this batch is:  0.18780069053173065\n",
      "The representation loss after processing this batch is:  0.002531573176383972\n",
      "\n",
      "The classification loss after processing this batch is:  0.1530940681695938\n",
      "The representation loss after processing this batch is:  0.0029880329966545105\n",
      "\n",
      "The classification loss after processing this batch is:  0.14555208384990692\n",
      "The representation loss after processing this batch is:  0.002944350242614746\n",
      "\n",
      "The classification loss after processing this batch is:  0.11133110523223877\n",
      "The representation loss after processing this batch is:  0.0031875818967819214\n",
      "\n",
      "The classification loss after processing this batch is:  0.1608191877603531\n",
      "The representation loss after processing this batch is:  0.003338657319545746\n",
      "\n",
      "The classification loss after processing this batch is:  0.08264854550361633\n",
      "The representation loss after processing this batch is:  0.003394022583961487\n",
      "\n",
      "The classification loss after processing this batch is:  0.18572883307933807\n",
      "The representation loss after processing this batch is:  0.002713322639465332\n",
      "\n",
      "The classification loss after processing this batch is:  0.1918906569480896\n",
      "The representation loss after processing this batch is:  0.002978537231683731\n",
      "\n",
      "The classification loss after processing this batch is:  0.09251920878887177\n",
      "The representation loss after processing this batch is:  0.002907484769821167\n",
      "\n",
      "The classification loss after processing this batch is:  0.23739808797836304\n",
      "The representation loss after processing this batch is:  0.002644326537847519\n",
      "\n",
      "The classification loss after processing this batch is:  0.16154922544956207\n",
      "The representation loss after processing this batch is:  0.0029411911964416504\n",
      "\n",
      "The classification loss after processing this batch is:  0.113164521753788\n",
      "The representation loss after processing this batch is:  0.0031036585569381714\n",
      "\n",
      "The classification loss after processing this batch is:  0.10621390491724014\n",
      "The representation loss after processing this batch is:  0.0031479299068450928\n",
      "\n",
      "The classification loss after processing this batch is:  0.1275777518749237\n",
      "The representation loss after processing this batch is:  0.0031627118587493896\n",
      "\n",
      "The classification loss after processing this batch is:  0.10329236835241318\n",
      "The representation loss after processing this batch is:  0.0028034821152687073\n",
      "\n",
      "The classification loss after processing this batch is:  0.438527911901474\n",
      "The representation loss after processing this batch is:  0.002773486077785492\n",
      "\n",
      "The classification loss after processing this batch is:  0.17986486852169037\n",
      "The representation loss after processing this batch is:  0.00328807532787323\n",
      "\n",
      "The classification loss after processing this batch is:  0.2135067880153656\n",
      "The representation loss after processing this batch is:  0.0027991682291030884\n",
      "\n",
      "The classification loss after processing this batch is:  0.14724095165729523\n",
      "The representation loss after processing this batch is:  0.0026290379464626312\n",
      "\n",
      "The classification loss after processing this batch is:  0.18217982351779938\n",
      "The representation loss after processing this batch is:  0.0031443946063518524\n",
      "\n",
      "The classification loss after processing this batch is:  0.11302996426820755\n",
      "The representation loss after processing this batch is:  0.0027726776897907257\n",
      "\n",
      "The classification loss after processing this batch is:  0.12950916588306427\n",
      "The representation loss after processing this batch is:  0.0029715783894062042\n",
      "\n",
      "The classification loss after processing this batch is:  0.22288331389427185\n",
      "The representation loss after processing this batch is:  0.0031803101301193237\n",
      "\n",
      "The classification loss after processing this batch is:  0.17518314719200134\n",
      "The representation loss after processing this batch is:  0.003801438957452774\n",
      "\n",
      "The classification loss after processing this batch is:  0.18496370315551758\n",
      "The representation loss after processing this batch is:  0.0033035054802894592\n",
      "\n",
      "The classification loss after processing this batch is:  0.14731833338737488\n",
      "The representation loss after processing this batch is:  0.0028166770935058594\n",
      "\n",
      "The classification loss after processing this batch is:  0.2564369738101959\n",
      "The representation loss after processing this batch is:  0.0030027851462364197\n",
      "\n",
      "The classification loss after processing this batch is:  0.16767321527004242\n",
      "The representation loss after processing this batch is:  0.0030462518334388733\n",
      "\n",
      "The classification loss after processing this batch is:  0.2379441261291504\n",
      "The representation loss after processing this batch is:  0.002880372107028961\n",
      "\n",
      "The classification loss after processing this batch is:  0.16378015279769897\n",
      "The representation loss after processing this batch is:  0.0029666125774383545\n",
      "\n",
      "The classification loss after processing this batch is:  0.1448172926902771\n",
      "The representation loss after processing this batch is:  0.003158971667289734\n",
      "\n",
      "The classification loss after processing this batch is:  0.09100386500358582\n",
      "The representation loss after processing this batch is:  0.0030181705951690674\n",
      "\n",
      "The classification loss after processing this batch is:  0.2586310803890228\n",
      "The representation loss after processing this batch is:  0.0027825646102428436\n",
      "\n",
      "The classification loss after processing this batch is:  0.3358738124370575\n",
      "The representation loss after processing this batch is:  0.0031040161848068237\n",
      "\n",
      "The classification loss after processing this batch is:  0.14632463455200195\n",
      "The representation loss after processing this batch is:  0.0030320659279823303\n",
      "\n",
      "The classification loss after processing this batch is:  0.2748441696166992\n",
      "The representation loss after processing this batch is:  0.0033859983086586\n",
      "\n",
      "The classification loss after processing this batch is:  0.23084323108196259\n",
      "The representation loss after processing this batch is:  0.0030839815735816956\n",
      "\n",
      "The classification loss after processing this batch is:  0.22131076455116272\n",
      "The representation loss after processing this batch is:  0.003172311931848526\n",
      "\n",
      "The classification loss after processing this batch is:  0.10989730060100555\n",
      "The representation loss after processing this batch is:  0.0029068663716316223\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.20545223355293274\n",
      "The representation loss after processing this batch is:  0.003041766583919525\n",
      "\n",
      "The classification loss after processing this batch is:  0.20957161486148834\n",
      "The representation loss after processing this batch is:  0.003298655152320862\n",
      "\n",
      "The classification loss after processing this batch is:  0.1847189962863922\n",
      "The representation loss after processing this batch is:  0.0031612738966941833\n",
      "\n",
      "The classification loss after processing this batch is:  0.06897439062595367\n",
      "The representation loss after processing this batch is:  0.0031503066420555115\n",
      "\n",
      "The classification loss after processing this batch is:  0.13027803599834442\n",
      "The representation loss after processing this batch is:  0.003314405679702759\n",
      "\n",
      "The classification loss after processing this batch is:  0.1293213665485382\n",
      "The representation loss after processing this batch is:  0.0031305626034736633\n",
      "\n",
      "The classification loss after processing this batch is:  0.17521755397319794\n",
      "The representation loss after processing this batch is:  0.002595774829387665\n",
      "\n",
      "The classification loss after processing this batch is:  0.23973743617534637\n",
      "The representation loss after processing this batch is:  0.0028484202921390533\n",
      "\n",
      "The classification loss after processing this batch is:  0.16342493891716003\n",
      "The representation loss after processing this batch is:  0.0025758296251296997\n",
      "\n",
      "The classification loss after processing this batch is:  0.18138304352760315\n",
      "The representation loss after processing this batch is:  0.0036285147070884705\n",
      "\n",
      "The classification loss after processing this batch is:  0.2027757167816162\n",
      "The representation loss after processing this batch is:  0.003265637904405594\n",
      "\n",
      "The classification loss after processing this batch is:  0.16302591562271118\n",
      "The representation loss after processing this batch is:  0.0038486123085021973\n",
      "\n",
      "The classification loss after processing this batch is:  0.11650270968675613\n",
      "The representation loss after processing this batch is:  0.003018110990524292\n",
      "\n",
      "The classification loss after processing this batch is:  0.2567802369594574\n",
      "The representation loss after processing this batch is:  0.0030869990587234497\n",
      "\n",
      "The classification loss after processing this batch is:  0.20564177632331848\n",
      "The representation loss after processing this batch is:  0.003243260085582733\n",
      "\n",
      "The classification loss after processing this batch is:  0.16891984641551971\n",
      "The representation loss after processing this batch is:  0.00331839919090271\n",
      "\n",
      "The classification loss after processing this batch is:  0.14338582754135132\n",
      "The representation loss after processing this batch is:  0.002835232764482498\n",
      "\n",
      "The classification loss after processing this batch is:  0.13615162670612335\n",
      "The representation loss after processing this batch is:  0.002675674855709076\n",
      "\n",
      "The classification loss after processing this batch is:  0.1429063379764557\n",
      "The representation loss after processing this batch is:  0.0030333399772644043\n",
      "\n",
      "The classification loss after processing this batch is:  0.14837220311164856\n",
      "The representation loss after processing this batch is:  0.00274784117937088\n",
      "\n",
      "The classification loss after processing this batch is:  0.280809611082077\n",
      "The representation loss after processing this batch is:  0.003147941082715988\n",
      "\n",
      "The classification loss after processing this batch is:  0.27544885873794556\n",
      "The representation loss after processing this batch is:  0.003162562847137451\n",
      "\n",
      "The classification loss after processing this batch is:  0.15329910814762115\n",
      "The representation loss after processing this batch is:  0.002650417387485504\n",
      "\n",
      "The classification loss after processing this batch is:  0.1770799160003662\n",
      "The representation loss after processing this batch is:  0.0029366686940193176\n",
      "\n",
      "The classification loss after processing this batch is:  0.17368268966674805\n",
      "The representation loss after processing this batch is:  0.0027233362197875977\n",
      "\n",
      "The classification loss after processing this batch is:  0.1864163726568222\n",
      "The representation loss after processing this batch is:  0.0028851591050624847\n",
      "\n",
      "The classification loss after processing this batch is:  0.2346356362104416\n",
      "The representation loss after processing this batch is:  0.0031163357198238373\n",
      "\n",
      "The classification loss after processing this batch is:  0.1746043562889099\n",
      "The representation loss after processing this batch is:  0.002626609057188034\n",
      "\n",
      "The classification loss after processing this batch is:  0.3022433817386627\n",
      "The representation loss after processing this batch is:  0.0029355958104133606\n",
      "\n",
      "The classification loss after processing this batch is:  0.21348272264003754\n",
      "The representation loss after processing this batch is:  0.0026950016617774963\n",
      "\n",
      "The classification loss after processing this batch is:  0.08368509262800217\n",
      "The representation loss after processing this batch is:  0.003811284899711609\n",
      "\n",
      "The classification loss after processing this batch is:  0.18181777000427246\n",
      "The representation loss after processing this batch is:  0.002947770059108734\n",
      "\n",
      "The classification loss after processing this batch is:  0.12839670479297638\n",
      "The representation loss after processing this batch is:  0.002954140305519104\n",
      "\n",
      "The classification loss after processing this batch is:  0.2075527459383011\n",
      "The representation loss after processing this batch is:  0.0032096952199935913\n",
      "\n",
      "The classification loss after processing this batch is:  0.18050441145896912\n",
      "The representation loss after processing this batch is:  0.002714451402425766\n",
      "\n",
      "The classification loss after processing this batch is:  0.18700282275676727\n",
      "The representation loss after processing this batch is:  0.002957358956336975\n",
      "\n",
      "The classification loss after processing this batch is:  0.16188374161720276\n",
      "The representation loss after processing this batch is:  0.003040887415409088\n",
      "\n",
      "The classification loss after processing this batch is:  0.20872463285923004\n",
      "The representation loss after processing this batch is:  0.002937138080596924\n",
      "\n",
      "The classification loss after processing this batch is:  0.26952019333839417\n",
      "The representation loss after processing this batch is:  0.0027947649359703064\n",
      "\n",
      "The classification loss after processing this batch is:  0.27674251794815063\n",
      "The representation loss after processing this batch is:  0.0027817487716674805\n",
      "\n",
      "The classification loss after processing this batch is:  0.18926042318344116\n",
      "The representation loss after processing this batch is:  0.002912268042564392\n",
      "\n",
      "The classification loss after processing this batch is:  0.08168637007474899\n",
      "The representation loss after processing this batch is:  0.0033824294805526733\n",
      "\n",
      "The classification loss after processing this batch is:  0.05341734364628792\n",
      "The representation loss after processing this batch is:  0.0030621960759162903\n",
      "\n",
      "The classification loss after processing this batch is:  0.1802072823047638\n",
      "The representation loss after processing this batch is:  0.0032598301768302917\n",
      "\n",
      "The classification loss after processing this batch is:  0.11143327504396439\n",
      "The representation loss after processing this batch is:  0.004168011248111725\n",
      "\n",
      "The classification loss after processing this batch is:  0.20374323427677155\n",
      "The representation loss after processing this batch is:  0.0028939247131347656\n",
      "\n",
      "The classification loss after processing this batch is:  0.12772713601589203\n",
      "The representation loss after processing this batch is:  0.003285035490989685\n",
      "\n",
      "The classification loss after processing this batch is:  0.22910156846046448\n",
      "The representation loss after processing this batch is:  0.002865247428417206\n",
      "\n",
      "The classification loss after processing this batch is:  0.07406830787658691\n",
      "The representation loss after processing this batch is:  0.0030692070722579956\n",
      "\n",
      "The classification loss after processing this batch is:  0.1936039924621582\n",
      "The representation loss after processing this batch is:  0.0029648318886756897\n",
      "\n",
      "The classification loss after processing this batch is:  0.19285129010677338\n",
      "The representation loss after processing this batch is:  0.0032251477241516113\n",
      "\n",
      "The classification loss after processing this batch is:  0.21731939911842346\n",
      "The representation loss after processing this batch is:  0.003196440637111664\n",
      "\n",
      "The classification loss after processing this batch is:  0.15826044976711273\n",
      "The representation loss after processing this batch is:  0.00328846275806427\n",
      "\n",
      "The classification loss after processing this batch is:  0.0961843878030777\n",
      "The representation loss after processing this batch is:  0.0028513260185718536\n",
      "\n",
      "The classification loss after processing this batch is:  0.1518314927816391\n",
      "The representation loss after processing this batch is:  0.00317276269197464\n",
      "\n",
      "The classification loss after processing this batch is:  0.15793076157569885\n",
      "The representation loss after processing this batch is:  0.002752743661403656\n",
      "\n",
      "The classification loss after processing this batch is:  0.16741624474525452\n",
      "The representation loss after processing this batch is:  0.0029903873801231384\n",
      "\n",
      "The classification loss after processing this batch is:  0.14381550252437592\n",
      "The representation loss after processing this batch is:  0.0028533712029457092\n",
      "\n",
      "The classification loss after processing this batch is:  0.11585868149995804\n",
      "The representation loss after processing this batch is:  0.002950116991996765\n",
      "\n",
      "The classification loss after processing this batch is:  0.06526245176792145\n",
      "The representation loss after processing this batch is:  0.0028934404253959656\n",
      "\n",
      "The classification loss after processing this batch is:  0.10845950990915298\n",
      "The representation loss after processing this batch is:  0.0032104700803756714\n",
      "\n",
      "The classification loss after processing this batch is:  0.08001381903886795\n",
      "The representation loss after processing this batch is:  0.0032741129398345947\n",
      "\n",
      "The classification loss after processing this batch is:  0.17202900350093842\n",
      "The representation loss after processing this batch is:  0.002894960343837738\n",
      "\n",
      "The classification loss after processing this batch is:  0.1176176592707634\n",
      "The representation loss after processing this batch is:  0.0027373209595680237\n",
      "\n",
      "The classification loss after processing this batch is:  0.09730267524719238\n",
      "The representation loss after processing this batch is:  0.0026639699935913086\n",
      "\n",
      "The classification loss after processing this batch is:  0.13738898932933807\n",
      "The representation loss after processing this batch is:  0.0032850056886672974\n",
      "\n",
      "The classification loss after processing this batch is:  0.13558921217918396\n",
      "The representation loss after processing this batch is:  0.002898566424846649\n",
      "\n",
      "The classification loss after processing this batch is:  0.08757492899894714\n",
      "The representation loss after processing this batch is:  0.0031308159232139587\n",
      "\n",
      "The classification loss after processing this batch is:  0.12376512587070465\n",
      "The representation loss after processing this batch is:  0.0028359144926071167\n",
      "\n",
      "The classification loss after processing this batch is:  0.08750969916582108\n",
      "The representation loss after processing this batch is:  0.002785034477710724\n",
      "\n",
      "The classification loss after processing this batch is:  0.08343926817178726\n",
      "The representation loss after processing this batch is:  0.0030578598380088806\n",
      "\n",
      "The classification loss after processing this batch is:  0.16866236925125122\n",
      "The representation loss after processing this batch is:  0.0030045807361602783\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.16553525626659393\n",
      "The representation loss after processing this batch is:  0.003205239772796631\n",
      "\n",
      "The classification loss after processing this batch is:  0.09424161165952682\n",
      "The representation loss after processing this batch is:  0.003214225172996521\n",
      "\n",
      "The classification loss after processing this batch is:  0.21696268022060394\n",
      "The representation loss after processing this batch is:  0.0032609179615974426\n",
      "\n",
      "The classification loss after processing this batch is:  0.11116089671850204\n",
      "The representation loss after processing this batch is:  0.002848297357559204\n",
      "\n",
      "The classification loss after processing this batch is:  0.16122688353061676\n",
      "The representation loss after processing this batch is:  0.002906765788793564\n",
      "\n",
      "The classification loss after processing this batch is:  0.1773504614830017\n",
      "The representation loss after processing this batch is:  0.003523368388414383\n",
      "\n",
      "The classification loss after processing this batch is:  0.10269048064947128\n",
      "The representation loss after processing this batch is:  0.003430113196372986\n",
      "\n",
      "The classification loss after processing this batch is:  0.24220438301563263\n",
      "The representation loss after processing this batch is:  0.002951301634311676\n",
      "\n",
      "The classification loss after processing this batch is:  0.20278018712997437\n",
      "The representation loss after processing this batch is:  0.002528160810470581\n",
      "\n",
      "The classification loss after processing this batch is:  0.16324956715106964\n",
      "The representation loss after processing this batch is:  0.0029836446046829224\n",
      "\n",
      "The classification loss after processing this batch is:  0.18832506239414215\n",
      "The representation loss after processing this batch is:  0.0028818845748901367\n",
      "\n",
      "The classification loss after processing this batch is:  0.11630015075206757\n",
      "The representation loss after processing this batch is:  0.0030086487531661987\n",
      "\n",
      "The classification loss after processing this batch is:  0.14432010054588318\n",
      "The representation loss after processing this batch is:  0.0024895034730434418\n",
      "\n",
      "The classification loss after processing this batch is:  0.15101321041584015\n",
      "The representation loss after processing this batch is:  0.0028463900089263916\n",
      "\n",
      "The classification loss after processing this batch is:  0.21763445436954498\n",
      "The representation loss after processing this batch is:  0.0029288381338119507\n",
      "\n",
      "The classification loss after processing this batch is:  0.20276786386966705\n",
      "The representation loss after processing this batch is:  0.0029355213046073914\n",
      "\n",
      "The classification loss after processing this batch is:  0.09731072932481766\n",
      "The representation loss after processing this batch is:  0.0026805326342582703\n",
      "\n",
      "The classification loss after processing this batch is:  0.1107090637087822\n",
      "The representation loss after processing this batch is:  0.0029312223196029663\n",
      "\n",
      "The classification loss after processing this batch is:  0.2254866063594818\n",
      "The representation loss after processing this batch is:  0.0024900808930397034\n",
      "\n",
      "The classification loss after processing this batch is:  0.11042855679988861\n",
      "The representation loss after processing this batch is:  0.0028740987181663513\n",
      "\n",
      "The classification loss after processing this batch is:  0.1774522215127945\n",
      "The representation loss after processing this batch is:  0.002948164939880371\n",
      "\n",
      "The classification loss after processing this batch is:  0.19940295815467834\n",
      "The representation loss after processing this batch is:  0.0027974173426628113\n",
      "\n",
      "The classification loss after processing this batch is:  0.09900162369012833\n",
      "The representation loss after processing this batch is:  0.003316737711429596\n",
      "\n",
      "The classification loss after processing this batch is:  0.09772847592830658\n",
      "The representation loss after processing this batch is:  0.002800270915031433\n",
      "\n",
      "The classification loss after processing this batch is:  0.1595643311738968\n",
      "The representation loss after processing this batch is:  0.0030694007873535156\n",
      "\n",
      "The classification loss after processing this batch is:  0.16103646159172058\n",
      "The representation loss after processing this batch is:  0.0028314217925071716\n",
      "\n",
      "The classification loss after processing this batch is:  0.17740114033222198\n",
      "The representation loss after processing this batch is:  0.0030801668763160706\n",
      "\n",
      "The classification loss after processing this batch is:  0.2232407033443451\n",
      "The representation loss after processing this batch is:  0.003527507185935974\n",
      "\n",
      "The classification loss after processing this batch is:  0.12970253825187683\n",
      "The representation loss after processing this batch is:  0.0027945861220359802\n",
      "\n",
      "The classification loss after processing this batch is:  0.19277487695217133\n",
      "The representation loss after processing this batch is:  0.002456914633512497\n",
      "\n",
      "The classification loss after processing this batch is:  0.16926297545433044\n",
      "The representation loss after processing this batch is:  0.00302056223154068\n",
      "\n",
      "The classification loss after processing this batch is:  0.07090296596288681\n",
      "The representation loss after processing this batch is:  0.0030831843614578247\n",
      "\n",
      "The classification loss after processing this batch is:  0.09908930212259293\n",
      "The representation loss after processing this batch is:  0.002930372953414917\n",
      "\n",
      "The classification loss after processing this batch is:  0.12363652884960175\n",
      "The representation loss after processing this batch is:  0.002824157476425171\n",
      "\n",
      "The classification loss after processing this batch is:  0.12876945734024048\n",
      "The representation loss after processing this batch is:  0.003148503601551056\n",
      "\n",
      "The classification loss after processing this batch is:  0.127249076962471\n",
      "The representation loss after processing this batch is:  0.00302722305059433\n",
      "\n",
      "The classification loss after processing this batch is:  0.15541550517082214\n",
      "The representation loss after processing this batch is:  0.003335006535053253\n",
      "\n",
      "The classification loss after processing this batch is:  0.15976190567016602\n",
      "The representation loss after processing this batch is:  0.0032596737146377563\n",
      "\n",
      "The classification loss after processing this batch is:  0.12213107943534851\n",
      "The representation loss after processing this batch is:  0.0033736303448677063\n",
      "\n",
      "The classification loss after processing this batch is:  0.19960235059261322\n",
      "The representation loss after processing this batch is:  0.0031117312610149384\n",
      "\n",
      "The classification loss after processing this batch is:  0.20161710679531097\n",
      "The representation loss after processing this batch is:  0.0027784183621406555\n",
      "\n",
      "The classification loss after processing this batch is:  0.22214709222316742\n",
      "The representation loss after processing this batch is:  0.002953946590423584\n",
      "\n",
      "The classification loss after processing this batch is:  0.11545086652040482\n",
      "The representation loss after processing this batch is:  0.003138326108455658\n",
      "\n",
      "The classification loss after processing this batch is:  0.09858281165361404\n",
      "The representation loss after processing this batch is:  0.00282345712184906\n",
      "\n",
      "The classification loss after processing this batch is:  0.24447523057460785\n",
      "The representation loss after processing this batch is:  0.0026240795850753784\n",
      "\n",
      "The classification loss after processing this batch is:  0.2541232705116272\n",
      "The representation loss after processing this batch is:  0.0026181116700172424\n",
      "\n",
      "The classification loss after processing this batch is:  0.21792840957641602\n",
      "The representation loss after processing this batch is:  0.0029905959963798523\n",
      "\n",
      "The classification loss after processing this batch is:  0.17477211356163025\n",
      "The representation loss after processing this batch is:  0.002888612449169159\n",
      "\n",
      "The classification loss after processing this batch is:  0.1886269450187683\n",
      "The representation loss after processing this batch is:  0.0029319003224372864\n",
      "\n",
      "The classification loss after processing this batch is:  0.2571876049041748\n",
      "The representation loss after processing this batch is:  0.0026332512497901917\n",
      "\n",
      "The classification loss after processing this batch is:  0.2625705301761627\n",
      "The representation loss after processing this batch is:  0.0027343854308128357\n",
      "\n",
      "The classification loss after processing this batch is:  0.2545849084854126\n",
      "The representation loss after processing this batch is:  0.0029640942811965942\n",
      "\n",
      "The classification loss after processing this batch is:  0.23776088654994965\n",
      "The representation loss after processing this batch is:  0.002832934260368347\n",
      "\n",
      "The classification loss after processing this batch is:  0.13258971273899078\n",
      "The representation loss after processing this batch is:  0.003528788685798645\n",
      "\n",
      "The classification loss after processing this batch is:  0.08649558573961258\n",
      "The representation loss after processing this batch is:  0.003081008791923523\n",
      "\n",
      "The classification loss after processing this batch is:  0.18596205115318298\n",
      "The representation loss after processing this batch is:  0.003421492874622345\n",
      "\n",
      "The classification loss after processing this batch is:  0.16258785128593445\n",
      "The representation loss after processing this batch is:  0.002657294273376465\n",
      "\n",
      "The classification loss after processing this batch is:  0.09663747251033783\n",
      "The representation loss after processing this batch is:  0.0026312097907066345\n",
      "\n",
      "The classification loss after processing this batch is:  0.12356310337781906\n",
      "The representation loss after processing this batch is:  0.0029513612389564514\n",
      "\n",
      "The classification loss after processing this batch is:  0.14031998813152313\n",
      "The representation loss after processing this batch is:  0.002676665782928467\n",
      "\n",
      "The classification loss after processing this batch is:  0.13721971213817596\n",
      "The representation loss after processing this batch is:  0.0028004497289657593\n",
      "\n",
      "The classification loss after processing this batch is:  0.14120905101299286\n",
      "The representation loss after processing this batch is:  0.003056079149246216\n",
      "\n",
      "The classification loss after processing this batch is:  0.1264214962720871\n",
      "The representation loss after processing this batch is:  0.0026731938123703003\n",
      "\n",
      "The classification loss after processing this batch is:  0.11630504578351974\n",
      "The representation loss after processing this batch is:  0.0029311738908290863\n",
      "\n",
      "The classification loss after processing this batch is:  0.19908319413661957\n",
      "The representation loss after processing this batch is:  0.0029609352350234985\n",
      "\n",
      "The classification loss after processing this batch is:  0.16032975912094116\n",
      "The representation loss after processing this batch is:  0.0029021985828876495\n",
      "\n",
      "The classification loss after processing this batch is:  0.21100549399852753\n",
      "The representation loss after processing this batch is:  0.0033575743436813354\n",
      "\n",
      "The classification loss after processing this batch is:  0.1008688285946846\n",
      "The representation loss after processing this batch is:  0.002701595425605774\n",
      "\n",
      "The classification loss after processing this batch is:  0.09205535054206848\n",
      "The representation loss after processing this batch is:  0.003321327269077301\n",
      "\n",
      "The classification loss after processing this batch is:  0.18100860714912415\n",
      "The representation loss after processing this batch is:  0.0027858465909957886\n",
      "\n",
      "The classification loss after processing this batch is:  0.26975151896476746\n",
      "The representation loss after processing this batch is:  0.0027696192264556885\n",
      "\n",
      "The classification loss after processing this batch is:  0.14813050627708435\n",
      "The representation loss after processing this batch is:  0.0029070526361465454\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08395961672067642\n",
      "The representation loss after processing this batch is:  0.002936694771051407\n",
      "\n",
      "The classification loss after processing this batch is:  0.16110171377658844\n",
      "The representation loss after processing this batch is:  0.0026697255671024323\n",
      "\n",
      "The classification loss after processing this batch is:  0.043298132717609406\n",
      "The representation loss after processing this batch is:  0.002971857786178589\n",
      "\n",
      "The classification loss after processing this batch is:  0.19393786787986755\n",
      "The representation loss after processing this batch is:  0.0028653740882873535\n",
      "\n",
      "The classification loss after processing this batch is:  0.191026970744133\n",
      "The representation loss after processing this batch is:  0.003078863024711609\n",
      "\n",
      "The classification loss after processing this batch is:  0.10307140648365021\n",
      "The representation loss after processing this batch is:  0.002979971468448639\n",
      "\n",
      "The classification loss after processing this batch is:  0.12889808416366577\n",
      "The representation loss after processing this batch is:  0.003136545419692993\n",
      "\n",
      "The classification loss after processing this batch is:  0.12979649007320404\n",
      "The representation loss after processing this batch is:  0.0029390305280685425\n",
      "\n",
      "The classification loss after processing this batch is:  0.0731278657913208\n",
      "The representation loss after processing this batch is:  0.003203369677066803\n",
      "\n",
      "The classification loss after processing this batch is:  0.29527559876441956\n",
      "The representation loss after processing this batch is:  0.002632245421409607\n",
      "\n",
      "The classification loss after processing this batch is:  0.2763034999370575\n",
      "The representation loss after processing this batch is:  0.002658277750015259\n",
      "\n",
      "The classification loss after processing this batch is:  0.2148410528898239\n",
      "The representation loss after processing this batch is:  0.0026930198073387146\n",
      "\n",
      "The classification loss after processing this batch is:  0.24698400497436523\n",
      "The representation loss after processing this batch is:  0.0027161911129951477\n",
      "\n",
      "The classification loss after processing this batch is:  0.16527540981769562\n",
      "The representation loss after processing this batch is:  0.002884499728679657\n",
      "\n",
      "The classification loss after processing this batch is:  0.13748420774936676\n",
      "The representation loss after processing this batch is:  0.0026546716690063477\n",
      "\n",
      "The classification loss after processing this batch is:  0.25663620233535767\n",
      "The representation loss after processing this batch is:  0.002753816545009613\n",
      "\n",
      "The classification loss after processing this batch is:  0.14222680032253265\n",
      "The representation loss after processing this batch is:  0.002909824252128601\n",
      "\n",
      "The classification loss after processing this batch is:  0.21643689274787903\n",
      "The representation loss after processing this batch is:  0.003070894628763199\n",
      "\n",
      "The classification loss after processing this batch is:  0.1506461352109909\n",
      "The representation loss after processing this batch is:  0.0030172988772392273\n",
      "\n",
      "The classification loss after processing this batch is:  0.19962599873542786\n",
      "The representation loss after processing this batch is:  0.0024873949587345123\n",
      "\n",
      "The classification loss after processing this batch is:  0.14159901440143585\n",
      "The representation loss after processing this batch is:  0.002739928662776947\n",
      "\n",
      "The classification loss after processing this batch is:  0.13777998089790344\n",
      "The representation loss after processing this batch is:  0.00313471257686615\n",
      "\n",
      "The classification loss after processing this batch is:  0.17110881209373474\n",
      "The representation loss after processing this batch is:  0.0029944926500320435\n",
      "\n",
      "The classification loss after processing this batch is:  0.09006804972887039\n",
      "The representation loss after processing this batch is:  0.0030350536108016968\n",
      "\n",
      "The classification loss after processing this batch is:  0.0748092383146286\n",
      "The representation loss after processing this batch is:  0.002633236348628998\n",
      "\n",
      "The classification loss after processing this batch is:  0.1370096206665039\n",
      "The representation loss after processing this batch is:  0.0028386861085891724\n",
      "\n",
      "The classification loss after processing this batch is:  0.2458801418542862\n",
      "The representation loss after processing this batch is:  0.0029457658529281616\n",
      "\n",
      "The classification loss after processing this batch is:  0.06677817553281784\n",
      "The representation loss after processing this batch is:  0.0028870850801467896\n",
      "\n",
      "The classification loss after processing this batch is:  0.09103672951459885\n",
      "The representation loss after processing this batch is:  0.002767503261566162\n",
      "\n",
      "The classification loss after processing this batch is:  0.18925313651561737\n",
      "The representation loss after processing this batch is:  0.003035441040992737\n",
      "\n",
      "The classification loss after processing this batch is:  0.1802128255367279\n",
      "The representation loss after processing this batch is:  0.002858497202396393\n",
      "\n",
      "The classification loss after processing this batch is:  0.1443232148885727\n",
      "The representation loss after processing this batch is:  0.0030244141817092896\n",
      "\n",
      "The classification loss after processing this batch is:  0.26315757632255554\n",
      "The representation loss after processing this batch is:  0.0027594491839408875\n",
      "\n",
      "The classification loss after processing this batch is:  0.10206275433301926\n",
      "The representation loss after processing this batch is:  0.0033886879682540894\n",
      "\n",
      "The classification loss after processing this batch is:  0.07364089787006378\n",
      "The representation loss after processing this batch is:  0.0027268044650554657\n",
      "\n",
      "The classification loss after processing this batch is:  0.07723264396190643\n",
      "The representation loss after processing this batch is:  0.003272533416748047\n",
      "\n",
      "The classification loss after processing this batch is:  0.17274610698223114\n",
      "The representation loss after processing this batch is:  0.0032429099082946777\n",
      "\n",
      "The classification loss after processing this batch is:  0.17777875065803528\n",
      "The representation loss after processing this batch is:  0.003130502998828888\n",
      "\n",
      "The classification loss after processing this batch is:  0.1192300096154213\n",
      "The representation loss after processing this batch is:  0.003262169659137726\n",
      "\n",
      "The classification loss after processing this batch is:  0.14024478197097778\n",
      "The representation loss after processing this batch is:  0.0030008703470230103\n",
      "\n",
      "The classification loss after processing this batch is:  0.1312875598669052\n",
      "The representation loss after processing this batch is:  0.0029610134661197662\n",
      "\n",
      "The classification loss after processing this batch is:  0.13220030069351196\n",
      "The representation loss after processing this batch is:  0.0031862109899520874\n",
      "\n",
      "The classification loss after processing this batch is:  0.1552066206932068\n",
      "The representation loss after processing this batch is:  0.003059621900320053\n",
      "\n",
      "The classification loss after processing this batch is:  0.1988171935081482\n",
      "The representation loss after processing this batch is:  0.003054380416870117\n",
      "\n",
      "The classification loss after processing this batch is:  0.17466871440410614\n",
      "The representation loss after processing this batch is:  0.0034015774726867676\n",
      "\n",
      "The classification loss after processing this batch is:  0.2963044047355652\n",
      "The representation loss after processing this batch is:  0.002734959125518799\n",
      "\n",
      "The classification loss after processing this batch is:  0.2318885177373886\n",
      "The representation loss after processing this batch is:  0.002763349562883377\n",
      "\n",
      "The classification loss after processing this batch is:  0.18437640368938446\n",
      "The representation loss after processing this batch is:  0.0030803456902503967\n",
      "\n",
      "The classification loss after processing this batch is:  0.1842738837003708\n",
      "The representation loss after processing this batch is:  0.0030616596341133118\n",
      "\n",
      "The classification loss after processing this batch is:  0.058757152408361435\n",
      "The representation loss after processing this batch is:  0.0028373226523399353\n",
      "\n",
      "The classification loss after processing this batch is:  0.13815779983997345\n",
      "The representation loss after processing this batch is:  0.003479205071926117\n",
      "\n",
      "The classification loss after processing this batch is:  0.12532417476177216\n",
      "The representation loss after processing this batch is:  0.003237001597881317\n",
      "\n",
      "The classification loss after processing this batch is:  0.1431148499250412\n",
      "The representation loss after processing this batch is:  0.0030611343681812286\n",
      "\n",
      "The classification loss after processing this batch is:  0.17094676196575165\n",
      "The representation loss after processing this batch is:  0.0025627315044403076\n",
      "\n",
      "The classification loss after processing this batch is:  0.12100303918123245\n",
      "The representation loss after processing this batch is:  0.002694852650165558\n",
      "\n",
      "The classification loss after processing this batch is:  0.17126044631004333\n",
      "The representation loss after processing this batch is:  0.0026304125785827637\n",
      "\n",
      "The classification loss after processing this batch is:  0.20453448593616486\n",
      "The representation loss after processing this batch is:  0.0027049779891967773\n",
      "\n",
      "The classification loss after processing this batch is:  0.17059071362018585\n",
      "The representation loss after processing this batch is:  0.0030736103653907776\n",
      "\n",
      "The classification loss after processing this batch is:  0.2602332532405853\n",
      "The representation loss after processing this batch is:  0.003152213990688324\n",
      "\n",
      "The classification loss after processing this batch is:  0.1307757943868637\n",
      "The representation loss after processing this batch is:  0.0029769763350486755\n",
      "\n",
      "The classification loss after processing this batch is:  0.1731114685535431\n",
      "The representation loss after processing this batch is:  0.002525024116039276\n",
      "\n",
      "The classification loss after processing this batch is:  0.11815997213125229\n",
      "The representation loss after processing this batch is:  0.003058493137359619\n",
      "\n",
      "The classification loss after processing this batch is:  0.2617020308971405\n",
      "The representation loss after processing this batch is:  0.003051251173019409\n",
      "\n",
      "The classification loss after processing this batch is:  0.2379189282655716\n",
      "The representation loss after processing this batch is:  0.003221563994884491\n",
      "\n",
      "The classification loss after processing this batch is:  0.07197941839694977\n",
      "The representation loss after processing this batch is:  0.0026634633541107178\n",
      "\n",
      "The classification loss after processing this batch is:  0.09459604322910309\n",
      "The representation loss after processing this batch is:  0.00293944776058197\n",
      "\n",
      "The classification loss after processing this batch is:  0.2552502751350403\n",
      "The representation loss after processing this batch is:  0.002723541110754013\n",
      "\n",
      "The classification loss after processing this batch is:  0.082282155752182\n",
      "The representation loss after processing this batch is:  0.0029237717390060425\n",
      "\n",
      "The classification loss after processing this batch is:  0.1398889422416687\n",
      "The representation loss after processing this batch is:  0.0030063092708587646\n",
      "\n",
      "The classification loss after processing this batch is:  0.18886642158031464\n",
      "The representation loss after processing this batch is:  0.0029019340872764587\n",
      "\n",
      "The classification loss after processing this batch is:  0.14213623106479645\n",
      "The representation loss after processing this batch is:  0.0030284076929092407\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.26909610629081726\n",
      "The representation loss after processing this batch is:  0.0033110156655311584\n",
      "\n",
      "The classification loss after processing this batch is:  0.1879640370607376\n",
      "The representation loss after processing this batch is:  0.003121800720691681\n",
      "\n",
      "The classification loss after processing this batch is:  0.1878996342420578\n",
      "The representation loss after processing this batch is:  0.003547579050064087\n",
      "\n",
      "The classification loss after processing this batch is:  0.13525912165641785\n",
      "The representation loss after processing this batch is:  0.0028097927570343018\n",
      "\n",
      "The classification loss after processing this batch is:  0.20737716555595398\n",
      "The representation loss after processing this batch is:  0.002520263195037842\n",
      "\n",
      "The classification loss after processing this batch is:  0.07662679255008698\n",
      "The representation loss after processing this batch is:  0.00291597843170166\n",
      "\n",
      "The classification loss after processing this batch is:  0.06981755793094635\n",
      "The representation loss after processing this batch is:  0.0026422888040542603\n",
      "\n",
      "The classification loss after processing this batch is:  0.095041923224926\n",
      "The representation loss after processing this batch is:  0.00287020206451416\n",
      "\n",
      "The classification loss after processing this batch is:  0.07973314076662064\n",
      "The representation loss after processing this batch is:  0.002778097987174988\n",
      "\n",
      "The classification loss after processing this batch is:  0.13891921937465668\n",
      "The representation loss after processing this batch is:  0.00288565456867218\n",
      "\n",
      "The classification loss after processing this batch is:  0.09807419776916504\n",
      "The representation loss after processing this batch is:  0.002693682909011841\n",
      "\n",
      "The classification loss after processing this batch is:  0.11059987545013428\n",
      "The representation loss after processing this batch is:  0.002635303884744644\n",
      "\n",
      "The classification loss after processing this batch is:  0.15306904911994934\n",
      "The representation loss after processing this batch is:  0.0029882751405239105\n",
      "\n",
      "The classification loss after processing this batch is:  0.22112685441970825\n",
      "The representation loss after processing this batch is:  0.0029251649975776672\n",
      "\n",
      "The classification loss after processing this batch is:  0.2016163021326065\n",
      "The representation loss after processing this batch is:  0.0027429722249507904\n",
      "\n",
      "The classification loss after processing this batch is:  0.1760755181312561\n",
      "The representation loss after processing this batch is:  0.003037668764591217\n",
      "\n",
      "The classification loss after processing this batch is:  0.22411562502384186\n",
      "The representation loss after processing this batch is:  0.0027289502322673798\n",
      "\n",
      "The classification loss after processing this batch is:  0.13338273763656616\n",
      "The representation loss after processing this batch is:  0.002786584198474884\n",
      "\n",
      "The classification loss after processing this batch is:  0.18396338820457458\n",
      "The representation loss after processing this batch is:  0.002991221845149994\n",
      "\n",
      "The classification loss after processing this batch is:  0.28160789608955383\n",
      "The representation loss after processing this batch is:  0.0030604004859924316\n",
      "\n",
      "The classification loss after processing this batch is:  0.12025627493858337\n",
      "The representation loss after processing this batch is:  0.0027593225240707397\n",
      "\n",
      "The classification loss after processing this batch is:  0.23549534380435944\n",
      "The representation loss after processing this batch is:  0.0026878565549850464\n",
      "\n",
      "The classification loss after processing this batch is:  0.21180902421474457\n",
      "The representation loss after processing this batch is:  0.002727888524532318\n",
      "\n",
      "The classification loss after processing this batch is:  0.19426393508911133\n",
      "The representation loss after processing this batch is:  0.0027440935373306274\n",
      "\n",
      "The classification loss after processing this batch is:  0.12569373846054077\n",
      "The representation loss after processing this batch is:  0.003095492720603943\n",
      "\n",
      "The classification loss after processing this batch is:  0.0925571545958519\n",
      "The representation loss after processing this batch is:  0.002699650824069977\n",
      "\n",
      "The classification loss after processing this batch is:  0.12292078137397766\n",
      "The representation loss after processing this batch is:  0.0026453807950019836\n",
      "\n",
      "The classification loss after processing this batch is:  0.0937352254986763\n",
      "The representation loss after processing this batch is:  0.002895936369895935\n",
      "\n",
      "The classification loss after processing this batch is:  0.06934743374586105\n",
      "The representation loss after processing this batch is:  0.002785511314868927\n",
      "\n",
      "The classification loss after processing this batch is:  0.18728062510490417\n",
      "The representation loss after processing this batch is:  0.003016427159309387\n",
      "\n",
      "The classification loss after processing this batch is:  0.08603834360837936\n",
      "The representation loss after processing this batch is:  0.003154963254928589\n",
      "\n",
      "The classification loss after processing this batch is:  0.22907590866088867\n",
      "The representation loss after processing this batch is:  0.0033347830176353455\n",
      "\n",
      "The classification loss after processing this batch is:  0.14578519761562347\n",
      "The representation loss after processing this batch is:  0.002937912940979004\n",
      "\n",
      "The classification loss after processing this batch is:  0.22182556986808777\n",
      "The representation loss after processing this batch is:  0.002887967973947525\n",
      "\n",
      "The classification loss after processing this batch is:  0.3610478639602661\n",
      "The representation loss after processing this batch is:  0.0025283098220825195\n",
      "\n",
      "The classification loss after processing this batch is:  0.1814228892326355\n",
      "The representation loss after processing this batch is:  0.0024749301373958588\n",
      "\n",
      "The classification loss after processing this batch is:  0.07368728518486023\n",
      "The representation loss after processing this batch is:  0.0028834268450737\n",
      "\n",
      "The classification loss after processing this batch is:  0.10167994350194931\n",
      "The representation loss after processing this batch is:  0.003328949213027954\n",
      "\n",
      "The classification loss after processing this batch is:  0.08654232323169708\n",
      "The representation loss after processing this batch is:  0.0032346174120903015\n",
      "\n",
      "The classification loss after processing this batch is:  0.11144577711820602\n",
      "The representation loss after processing this batch is:  0.002840891480445862\n",
      "\n",
      "The classification loss after processing this batch is:  0.10970689356327057\n",
      "The representation loss after processing this batch is:  0.0027968473732471466\n",
      "\n",
      "The classification loss after processing this batch is:  0.2534887492656708\n",
      "The representation loss after processing this batch is:  0.002776317298412323\n",
      "\n",
      "The classification loss after processing this batch is:  0.20921292901039124\n",
      "The representation loss after processing this batch is:  0.0028131306171417236\n",
      "\n",
      "The classification loss after processing this batch is:  0.18426617980003357\n",
      "The representation loss after processing this batch is:  0.003117278218269348\n",
      "\n",
      "The classification loss after processing this batch is:  0.2887575328350067\n",
      "The representation loss after processing this batch is:  0.003495514392852783\n",
      "\n",
      "The classification loss after processing this batch is:  0.13235720992088318\n",
      "The representation loss after processing this batch is:  0.002970367670059204\n",
      "\n",
      "The classification loss after processing this batch is:  0.15135274827480316\n",
      "The representation loss after processing this batch is:  0.0029762759804725647\n",
      "\n",
      "The classification loss after processing this batch is:  0.224765807390213\n",
      "The representation loss after processing this batch is:  0.0028149746358394623\n",
      "\n",
      "The classification loss after processing this batch is:  0.14125610888004303\n",
      "The representation loss after processing this batch is:  0.0034692957997322083\n",
      "\n",
      "The classification loss after processing this batch is:  0.16848672926425934\n",
      "The representation loss after processing this batch is:  0.004096895456314087\n",
      "\n",
      "The classification loss after processing this batch is:  0.09277034550905228\n",
      "The representation loss after processing this batch is:  0.003315392881631851\n",
      "\n",
      "The classification loss after processing this batch is:  0.19629409909248352\n",
      "The representation loss after processing this batch is:  0.003442622721195221\n",
      "\n",
      "The classification loss after processing this batch is:  0.19721241295337677\n",
      "The representation loss after processing this batch is:  0.0035795681178569794\n",
      "\n",
      "The classification loss after processing this batch is:  0.1355447769165039\n",
      "The representation loss after processing this batch is:  0.0034249424934387207\n",
      "\n",
      "The classification loss after processing this batch is:  0.18589159846305847\n",
      "The representation loss after processing this batch is:  0.003080211579799652\n",
      "\n",
      "The classification loss after processing this batch is:  0.20011430978775024\n",
      "The representation loss after processing this batch is:  0.002612520009279251\n",
      "\n",
      "The classification loss after processing this batch is:  0.20328646898269653\n",
      "The representation loss after processing this batch is:  0.002500474452972412\n",
      "\n",
      "The classification loss after processing this batch is:  0.19128260016441345\n",
      "The representation loss after processing this batch is:  0.0027451738715171814\n",
      "\n",
      "The classification loss after processing this batch is:  0.1370031088590622\n",
      "The representation loss after processing this batch is:  0.0032020211219787598\n",
      "\n",
      "The classification loss after processing this batch is:  0.051165398210287094\n",
      "The representation loss after processing this batch is:  0.0029370635747909546\n",
      "\n",
      "The classification loss after processing this batch is:  0.14619947969913483\n",
      "The representation loss after processing this batch is:  0.0029602646827697754\n",
      "\n",
      "The classification loss after processing this batch is:  0.10224414616823196\n",
      "The representation loss after processing this batch is:  0.0030374079942703247\n",
      "\n",
      "The classification loss after processing this batch is:  0.2359572798013687\n",
      "The representation loss after processing this batch is:  0.0028095990419387817\n",
      "\n",
      "The classification loss after processing this batch is:  0.09864618629217148\n",
      "The representation loss after processing this batch is:  0.0031406432390213013\n",
      "\n",
      "The classification loss after processing this batch is:  0.13935521245002747\n",
      "The representation loss after processing this batch is:  0.0027559250593185425\n",
      "\n",
      "The classification loss after processing this batch is:  0.191018745303154\n",
      "The representation loss after processing this batch is:  0.003083430230617523\n",
      "\n",
      "The classification loss after processing this batch is:  0.15244224667549133\n",
      "The representation loss after processing this batch is:  0.00293702632188797\n",
      "\n",
      "The classification loss after processing this batch is:  0.1882505565881729\n",
      "The representation loss after processing this batch is:  0.002827189862728119\n",
      "\n",
      "The classification loss after processing this batch is:  0.11116712540388107\n",
      "The representation loss after processing this batch is:  0.0027491971850395203\n",
      "\n",
      "The classification loss after processing this batch is:  0.11175079643726349\n",
      "The representation loss after processing this batch is:  0.0026299431920051575\n",
      "\n",
      "The classification loss after processing this batch is:  0.11516211926937103\n",
      "The representation loss after processing this batch is:  0.0026934966444969177\n",
      "\n",
      "The classification loss after processing this batch is:  0.20610195398330688\n",
      "The representation loss after processing this batch is:  0.0033018067479133606\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.20511992275714874\n",
      "The representation loss after processing this batch is:  0.0029774829745292664\n",
      "\n",
      "The classification loss after processing this batch is:  0.1893138736486435\n",
      "The representation loss after processing this batch is:  0.002644278109073639\n",
      "\n",
      "The classification loss after processing this batch is:  0.2052755504846573\n",
      "The representation loss after processing this batch is:  0.002614915370941162\n",
      "\n",
      "The classification loss after processing this batch is:  0.28221455216407776\n",
      "The representation loss after processing this batch is:  0.002923164516687393\n",
      "\n",
      "The classification loss after processing this batch is:  0.150273859500885\n",
      "The representation loss after processing this batch is:  0.003247976303100586\n",
      "\n",
      "The classification loss after processing this batch is:  0.2578289806842804\n",
      "The representation loss after processing this batch is:  0.0029077231884002686\n",
      "\n",
      "The classification loss after processing this batch is:  0.14294110238552094\n",
      "The representation loss after processing this batch is:  0.002984941005706787\n",
      "\n",
      "The classification loss after processing this batch is:  0.07872963696718216\n",
      "The representation loss after processing this batch is:  0.0029468610882759094\n",
      "\n",
      "The classification loss after processing this batch is:  0.06496889144182205\n",
      "The representation loss after processing this batch is:  0.0024828538298606873\n",
      "\n",
      "The classification loss after processing this batch is:  0.08758626878261566\n",
      "The representation loss after processing this batch is:  0.002906620502471924\n",
      "\n",
      "The classification loss after processing this batch is:  0.24827289581298828\n",
      "The representation loss after processing this batch is:  0.003187902271747589\n",
      "\n",
      "The classification loss after processing this batch is:  0.11034239083528519\n",
      "The representation loss after processing this batch is:  0.0031195133924484253\n",
      "\n",
      "The classification loss after processing this batch is:  0.14077097177505493\n",
      "The representation loss after processing this batch is:  0.003083370625972748\n",
      "\n",
      "The classification loss after processing this batch is:  0.17021776735782623\n",
      "The representation loss after processing this batch is:  0.003072291612625122\n",
      "\n",
      "The classification loss after processing this batch is:  0.1242051050066948\n",
      "The representation loss after processing this batch is:  0.0030613765120506287\n",
      "\n",
      "The classification loss after processing this batch is:  0.10017650574445724\n",
      "The representation loss after processing this batch is:  0.0026937276124954224\n",
      "\n",
      "The classification loss after processing this batch is:  0.19954095780849457\n",
      "The representation loss after processing this batch is:  0.002567872405052185\n",
      "\n",
      "The classification loss after processing this batch is:  0.23903729021549225\n",
      "The representation loss after processing this batch is:  0.00273808091878891\n",
      "\n",
      "The classification loss after processing this batch is:  0.21743813157081604\n",
      "The representation loss after processing this batch is:  0.003064103424549103\n",
      "\n",
      "The classification loss after processing this batch is:  0.09813632816076279\n",
      "The representation loss after processing this batch is:  0.0027669891715049744\n",
      "\n",
      "The classification loss after processing this batch is:  0.2581116259098053\n",
      "The representation loss after processing this batch is:  0.002676241099834442\n",
      "\n",
      "The classification loss after processing this batch is:  0.11657105386257172\n",
      "The representation loss after processing this batch is:  0.0024853944778442383\n",
      "\n",
      "The classification loss after processing this batch is:  0.18051718175411224\n",
      "The representation loss after processing this batch is:  0.0025642812252044678\n",
      "\n",
      "The classification loss after processing this batch is:  0.1748298853635788\n",
      "The representation loss after processing this batch is:  0.0031169727444648743\n",
      "\n",
      "The classification loss after processing this batch is:  0.1311729997396469\n",
      "The representation loss after processing this batch is:  0.0027351975440979004\n",
      "\n",
      "The classification loss after processing this batch is:  0.15390105545520782\n",
      "The representation loss after processing this batch is:  0.002833127975463867\n",
      "\n",
      "The classification loss after processing this batch is:  0.15758158266544342\n",
      "The representation loss after processing this batch is:  0.003244824707508087\n",
      "\n",
      "The classification loss after processing this batch is:  0.2295706570148468\n",
      "The representation loss after processing this batch is:  0.002916250377893448\n",
      "\n",
      "The classification loss after processing this batch is:  0.28407225012779236\n",
      "The representation loss after processing this batch is:  0.0029959455132484436\n",
      "\n",
      "The classification loss after processing this batch is:  0.2361847460269928\n",
      "The representation loss after processing this batch is:  0.002803511917591095\n",
      "\n",
      "The classification loss after processing this batch is:  0.15779529511928558\n",
      "The representation loss after processing this batch is:  0.0030211694538593292\n",
      "\n",
      "The classification loss after processing this batch is:  0.1172785684466362\n",
      "The representation loss after processing this batch is:  0.0033353790640830994\n",
      "\n",
      "The classification loss after processing this batch is:  0.2118040919303894\n",
      "The representation loss after processing this batch is:  0.0024998821318149567\n",
      "\n",
      "The classification loss after processing this batch is:  0.1858328878879547\n",
      "The representation loss after processing this batch is:  0.002722378820180893\n",
      "\n",
      "The classification loss after processing this batch is:  0.057258449494838715\n",
      "The representation loss after processing this batch is:  0.002802453935146332\n",
      "\n",
      "The classification loss after processing this batch is:  0.1538759022951126\n",
      "The representation loss after processing this batch is:  0.0027785412967205048\n",
      "\n",
      "The classification loss after processing this batch is:  0.34187448024749756\n",
      "The representation loss after processing this batch is:  0.003199554979801178\n",
      "\n",
      "The classification loss after processing this batch is:  0.3533845841884613\n",
      "The representation loss after processing this batch is:  0.003019459545612335\n",
      "\n",
      "The classification loss after processing this batch is:  0.3179749548435211\n",
      "The representation loss after processing this batch is:  0.002806350588798523\n",
      "\n",
      "The classification loss after processing this batch is:  0.1997339129447937\n",
      "The representation loss after processing this batch is:  0.0028112567961215973\n",
      "\n",
      "The classification loss after processing this batch is:  0.10097069293260574\n",
      "The representation loss after processing this batch is:  0.002581622451543808\n",
      "\n",
      "The classification loss after processing this batch is:  0.1650909036397934\n",
      "The representation loss after processing this batch is:  0.0029093846678733826\n",
      "\n",
      "The classification loss after processing this batch is:  0.1657184660434723\n",
      "The representation loss after processing this batch is:  0.003070823848247528\n",
      "\n",
      "The classification loss after processing this batch is:  0.23742301762104034\n",
      "The representation loss after processing this batch is:  0.0030846521258354187\n",
      "\n",
      "The classification loss after processing this batch is:  0.14852425456047058\n",
      "The representation loss after processing this batch is:  0.003523416817188263\n",
      "\n",
      "The classification loss after processing this batch is:  0.13892404735088348\n",
      "The representation loss after processing this batch is:  0.0036258772015571594\n",
      "\n",
      "The classification loss after processing this batch is:  0.11079633980989456\n",
      "The representation loss after processing this batch is:  0.002845868468284607\n",
      "\n",
      "The classification loss after processing this batch is:  0.15248587727546692\n",
      "The representation loss after processing this batch is:  0.0030744820833206177\n",
      "\n",
      "The classification loss after processing this batch is:  0.20198087394237518\n",
      "The representation loss after processing this batch is:  0.003328196704387665\n",
      "\n",
      "The classification loss after processing this batch is:  0.18578635156154633\n",
      "The representation loss after processing this batch is:  0.0026727095246315002\n",
      "\n",
      "The classification loss after processing this batch is:  0.1318141520023346\n",
      "The representation loss after processing this batch is:  0.0026365146040916443\n",
      "\n",
      "The classification loss after processing this batch is:  0.2954311668872833\n",
      "The representation loss after processing this batch is:  0.003317110240459442\n",
      "\n",
      "The classification loss after processing this batch is:  0.3837990462779999\n",
      "The representation loss after processing this batch is:  0.0033734217286109924\n",
      "\n",
      "The classification loss after processing this batch is:  0.23121242225170135\n",
      "The representation loss after processing this batch is:  0.003181852400302887\n",
      "\n",
      "The classification loss after processing this batch is:  0.14370089769363403\n",
      "The representation loss after processing this batch is:  0.003114178776741028\n",
      "\n",
      "The classification loss after processing this batch is:  0.14097724854946136\n",
      "The representation loss after processing this batch is:  0.003239870071411133\n",
      "\n",
      "The classification loss after processing this batch is:  0.11566056311130524\n",
      "The representation loss after processing this batch is:  0.0030383840203285217\n",
      "\n",
      "The classification loss after processing this batch is:  0.2657703459262848\n",
      "The representation loss after processing this batch is:  0.0029918327927589417\n",
      "\n",
      "The classification loss after processing this batch is:  0.20896200835704803\n",
      "The representation loss after processing this batch is:  0.0032942965626716614\n",
      "\n",
      "The classification loss after processing this batch is:  0.16125193238258362\n",
      "The representation loss after processing this batch is:  0.0032078027725219727\n",
      "\n",
      "The classification loss after processing this batch is:  0.2873901128768921\n",
      "The representation loss after processing this batch is:  0.00257670134305954\n",
      "\n",
      "The classification loss after processing this batch is:  0.05712095648050308\n",
      "The representation loss after processing this batch is:  0.00298493355512619\n",
      "\n",
      "The classification loss after processing this batch is:  0.08346942067146301\n",
      "The representation loss after processing this batch is:  0.0029479190707206726\n",
      "\n",
      "The classification loss after processing this batch is:  0.14027424156665802\n",
      "The representation loss after processing this batch is:  0.002843812108039856\n",
      "\n",
      "The classification loss after processing this batch is:  0.21578505635261536\n",
      "The representation loss after processing this batch is:  0.0024682916700839996\n",
      "\n",
      "The classification loss after processing this batch is:  0.2127225250005722\n",
      "The representation loss after processing this batch is:  0.0029637813568115234\n",
      "\n",
      "The classification loss after processing this batch is:  0.11397122591733932\n",
      "The representation loss after processing this batch is:  0.0030081793665885925\n",
      "\n",
      "The classification loss after processing this batch is:  0.14121407270431519\n",
      "The representation loss after processing this batch is:  0.003100559115409851\n",
      "\n",
      "The classification loss after processing this batch is:  0.07823329418897629\n",
      "The representation loss after processing this batch is:  0.002805471420288086\n",
      "\n",
      "The classification loss after processing this batch is:  0.11067605763673782\n",
      "The representation loss after processing this batch is:  0.002728760242462158\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10941357910633087\n",
      "The representation loss after processing this batch is:  0.0029310882091522217\n",
      "\n",
      "The classification loss after processing this batch is:  0.10294137895107269\n",
      "The representation loss after processing this batch is:  0.002908848226070404\n",
      "\n",
      "The classification loss after processing this batch is:  0.14241856336593628\n",
      "The representation loss after processing this batch is:  0.002714242786169052\n",
      "\n",
      "The classification loss after processing this batch is:  0.18053343892097473\n",
      "The representation loss after processing this batch is:  0.0027362406253814697\n",
      "\n",
      "The classification loss after processing this batch is:  0.23394879698753357\n",
      "The representation loss after processing this batch is:  0.003218740224838257\n",
      "\n",
      "The classification loss after processing this batch is:  0.0678941085934639\n",
      "The representation loss after processing this batch is:  0.0025383196771144867\n",
      "\n",
      "The classification loss after processing this batch is:  0.0997309759259224\n",
      "The representation loss after processing this batch is:  0.0027377530932426453\n",
      "\n",
      "The classification loss after processing this batch is:  0.11552584916353226\n",
      "The representation loss after processing this batch is:  0.0035013332962989807\n",
      "\n",
      "The classification loss after processing this batch is:  0.1885966658592224\n",
      "The representation loss after processing this batch is:  0.0028039589524269104\n",
      "\n",
      "The classification loss after processing this batch is:  0.10453130304813385\n",
      "The representation loss after processing this batch is:  0.003788977861404419\n",
      "\n",
      "The classification loss after processing this batch is:  0.20921070873737335\n",
      "The representation loss after processing this batch is:  0.0032870620489120483\n",
      "\n",
      "The classification loss after processing this batch is:  0.24742253124713898\n",
      "The representation loss after processing this batch is:  0.002787575125694275\n",
      "\n",
      "The classification loss after processing this batch is:  0.20835988223552704\n",
      "The representation loss after processing this batch is:  0.003086082637310028\n",
      "\n",
      "The classification loss after processing this batch is:  0.18982522189617157\n",
      "The representation loss after processing this batch is:  0.003042645752429962\n",
      "\n",
      "The classification loss after processing this batch is:  0.11502709239721298\n",
      "The representation loss after processing this batch is:  0.0028850585222244263\n",
      "\n",
      "The classification loss after processing this batch is:  0.1822628676891327\n",
      "The representation loss after processing this batch is:  0.002623222768306732\n",
      "\n",
      "The classification loss after processing this batch is:  0.17405417561531067\n",
      "The representation loss after processing this batch is:  0.0026714056730270386\n",
      "\n",
      "The classification loss after processing this batch is:  0.12778371572494507\n",
      "The representation loss after processing this batch is:  0.0029114708304405212\n",
      "\n",
      "The classification loss after processing this batch is:  0.051796961575746536\n",
      "The representation loss after processing this batch is:  0.0025110989809036255\n",
      "\n",
      "The classification loss after processing this batch is:  0.23386721312999725\n",
      "The representation loss after processing this batch is:  0.0030432790517807007\n",
      "\n",
      "The classification loss after processing this batch is:  0.3026299774646759\n",
      "The representation loss after processing this batch is:  0.002566918730735779\n",
      "\n",
      "The classification loss after processing this batch is:  0.15281786024570465\n",
      "The representation loss after processing this batch is:  0.0027820244431495667\n",
      "\n",
      "The classification loss after processing this batch is:  0.24527879059314728\n",
      "The representation loss after processing this batch is:  0.0028629302978515625\n",
      "\n",
      "The classification loss after processing this batch is:  0.2793739438056946\n",
      "The representation loss after processing this batch is:  0.0030612796545028687\n",
      "\n",
      "The classification loss after processing this batch is:  0.4045729637145996\n",
      "The representation loss after processing this batch is:  0.0030871257185935974\n",
      "\n",
      "The classification loss after processing this batch is:  0.19361338019371033\n",
      "The representation loss after processing this batch is:  0.002775736153125763\n",
      "\n",
      "The classification loss after processing this batch is:  0.13495327532291412\n",
      "The representation loss after processing this batch is:  0.0029163286089897156\n",
      "\n",
      "The classification loss after processing this batch is:  0.18971195816993713\n",
      "The representation loss after processing this batch is:  0.003395386040210724\n",
      "\n",
      "The classification loss after processing this batch is:  0.12728042900562286\n",
      "The representation loss after processing this batch is:  0.003003738820552826\n",
      "\n",
      "The classification loss after processing this batch is:  0.08926893770694733\n",
      "The representation loss after processing this batch is:  0.0029363706707954407\n",
      "\n",
      "The classification loss after processing this batch is:  0.09343409538269043\n",
      "The representation loss after processing this batch is:  0.0028196126222610474\n",
      "\n",
      "The classification loss after processing this batch is:  0.08024889975786209\n",
      "The representation loss after processing this batch is:  0.0027714595198631287\n",
      "\n",
      "The classification loss after processing this batch is:  0.05843694135546684\n",
      "The representation loss after processing this batch is:  0.0029879212379455566\n",
      "\n",
      "The classification loss after processing this batch is:  0.19535766541957855\n",
      "The representation loss after processing this batch is:  0.002816487103700638\n",
      "\n",
      "The classification loss after processing this batch is:  0.195673406124115\n",
      "The representation loss after processing this batch is:  0.002560928463935852\n",
      "\n",
      "The classification loss after processing this batch is:  0.08229700475931168\n",
      "The representation loss after processing this batch is:  0.003096550703048706\n",
      "\n",
      "The classification loss after processing this batch is:  0.13024082779884338\n",
      "The representation loss after processing this batch is:  0.0029494017362594604\n",
      "\n",
      "The classification loss after processing this batch is:  0.16142338514328003\n",
      "The representation loss after processing this batch is:  0.0030330047011375427\n",
      "\n",
      "The classification loss after processing this batch is:  0.05405406653881073\n",
      "The representation loss after processing this batch is:  0.0028983578085899353\n",
      "\n",
      "The classification loss after processing this batch is:  0.23959897458553314\n",
      "The representation loss after processing this batch is:  0.0027265846729278564\n",
      "\n",
      "The classification loss after processing this batch is:  0.12432399392127991\n",
      "The representation loss after processing this batch is:  0.002897918224334717\n",
      "\n",
      "The classification loss after processing this batch is:  0.27200406789779663\n",
      "The representation loss after processing this batch is:  0.0026879310607910156\n",
      "\n",
      "The classification loss after processing this batch is:  0.18434877693653107\n",
      "The representation loss after processing this batch is:  0.003106236457824707\n",
      "\n",
      "The classification loss after processing this batch is:  0.19795069098472595\n",
      "The representation loss after processing this batch is:  0.002648554742336273\n",
      "\n",
      "The classification loss after processing this batch is:  0.06742184609174728\n",
      "The representation loss after processing this batch is:  0.002759791910648346\n",
      "\n",
      "The classification loss after processing this batch is:  0.05978168919682503\n",
      "The representation loss after processing this batch is:  0.002839289605617523\n",
      "\n",
      "The classification loss after processing this batch is:  0.16225145757198334\n",
      "The representation loss after processing this batch is:  0.002947688102722168\n",
      "\n",
      "The classification loss after processing this batch is:  0.07691598683595657\n",
      "The representation loss after processing this batch is:  0.003349810838699341\n",
      "\n",
      "The classification loss after processing this batch is:  0.17873749136924744\n",
      "The representation loss after processing this batch is:  0.003085590898990631\n",
      "\n",
      "The classification loss after processing this batch is:  0.11058688163757324\n",
      "The representation loss after processing this batch is:  0.0028405562043190002\n",
      "\n",
      "The classification loss after processing this batch is:  0.1497776359319687\n",
      "The representation loss after processing this batch is:  0.0031784996390342712\n",
      "\n",
      "The classification loss after processing this batch is:  0.16927124559879303\n",
      "The representation loss after processing this batch is:  0.002829313278198242\n",
      "\n",
      "The classification loss after processing this batch is:  0.13289806246757507\n",
      "The representation loss after processing this batch is:  0.003036201000213623\n",
      "\n",
      "The classification loss after processing this batch is:  0.16679424047470093\n",
      "The representation loss after processing this batch is:  0.0029104501008987427\n",
      "\n",
      "The classification loss after processing this batch is:  0.16750462353229523\n",
      "The representation loss after processing this batch is:  0.003004029393196106\n",
      "\n",
      "The classification loss after processing this batch is:  0.18583618104457855\n",
      "The representation loss after processing this batch is:  0.0029483139514923096\n",
      "\n",
      "The classification loss after processing this batch is:  0.22568826377391815\n",
      "The representation loss after processing this batch is:  0.002930968999862671\n",
      "\n",
      "The classification loss after processing this batch is:  0.2557741701602936\n",
      "The representation loss after processing this batch is:  0.0032308921217918396\n",
      "\n",
      "The classification loss after processing this batch is:  0.18612892925739288\n",
      "The representation loss after processing this batch is:  0.0025507360696792603\n",
      "\n",
      "The classification loss after processing this batch is:  0.1351795792579651\n",
      "The representation loss after processing this batch is:  0.002889886498451233\n",
      "\n",
      "The classification loss after processing this batch is:  0.10419194400310516\n",
      "The representation loss after processing this batch is:  0.002701982855796814\n",
      "\n",
      "The classification loss after processing this batch is:  0.11988434940576553\n",
      "The representation loss after processing this batch is:  0.0030876994132995605\n",
      "\n",
      "The classification loss after processing this batch is:  0.10074245184659958\n",
      "The representation loss after processing this batch is:  0.0031248927116394043\n",
      "\n",
      "The classification loss after processing this batch is:  0.1365203857421875\n",
      "The representation loss after processing this batch is:  0.002435889095067978\n",
      "\n",
      "The classification loss after processing this batch is:  0.10325167328119278\n",
      "The representation loss after processing this batch is:  0.002916783094406128\n",
      "\n",
      "The classification loss after processing this batch is:  0.13767287135124207\n",
      "The representation loss after processing this batch is:  0.003010362386703491\n",
      "\n",
      "The classification loss after processing this batch is:  0.10156810283660889\n",
      "The representation loss after processing this batch is:  0.002845756709575653\n",
      "\n",
      "The classification loss after processing this batch is:  0.16903167963027954\n",
      "The representation loss after processing this batch is:  0.002878725528717041\n",
      "\n",
      "The classification loss after processing this batch is:  0.12260541319847107\n",
      "The representation loss after processing this batch is:  0.003076106309890747\n",
      "\n",
      "The classification loss after processing this batch is:  0.16951397061347961\n",
      "The representation loss after processing this batch is:  0.0029298514127731323\n",
      "\n",
      "The classification loss after processing this batch is:  0.18368381261825562\n",
      "The representation loss after processing this batch is:  0.00307590514421463\n",
      "\n",
      "The classification loss after processing this batch is:  0.13326449692249298\n",
      "The representation loss after processing this batch is:  0.003034353256225586\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1262664496898651\n",
      "The representation loss after processing this batch is:  0.00307377427816391\n",
      "\n",
      "The classification loss after processing this batch is:  0.22815637290477753\n",
      "The representation loss after processing this batch is:  0.0031790435314178467\n",
      "\n",
      "The classification loss after processing this batch is:  0.09184816479682922\n",
      "The representation loss after processing this batch is:  0.002988368272781372\n",
      "\n",
      "The classification loss after processing this batch is:  0.09275753051042557\n",
      "The representation loss after processing this batch is:  0.002845458686351776\n",
      "\n",
      "The classification loss after processing this batch is:  0.13378016650676727\n",
      "The representation loss after processing this batch is:  0.0028422176837921143\n",
      "\n",
      "The classification loss after processing this batch is:  0.10578662902116776\n",
      "The representation loss after processing this batch is:  0.0028026774525642395\n",
      "\n",
      "The classification loss after processing this batch is:  0.20615889132022858\n",
      "The representation loss after processing this batch is:  0.002499103546142578\n",
      "\n",
      "The classification loss after processing this batch is:  0.1975886970758438\n",
      "The representation loss after processing this batch is:  0.0028410926461219788\n",
      "\n",
      "The classification loss after processing this batch is:  0.18234482407569885\n",
      "The representation loss after processing this batch is:  0.0032536759972572327\n",
      "\n",
      "The classification loss after processing this batch is:  0.10673948377370834\n",
      "The representation loss after processing this batch is:  0.003162093460559845\n",
      "\n",
      "The classification loss after processing this batch is:  0.13666817545890808\n",
      "The representation loss after processing this batch is:  0.0028806254267692566\n",
      "\n",
      "The classification loss after processing this batch is:  0.25956448912620544\n",
      "The representation loss after processing this batch is:  0.0028972215950489044\n",
      "\n",
      "The classification loss after processing this batch is:  0.06889698654413223\n",
      "The representation loss after processing this batch is:  0.0029439404606819153\n",
      "\n",
      "The classification loss after processing this batch is:  0.12324324995279312\n",
      "The representation loss after processing this batch is:  0.0031332597136497498\n",
      "\n",
      "The classification loss after processing this batch is:  0.1945199966430664\n",
      "The representation loss after processing this batch is:  0.002671763300895691\n",
      "\n",
      "The classification loss after processing this batch is:  0.38953182101249695\n",
      "The representation loss after processing this batch is:  0.003098912537097931\n",
      "\n",
      "The classification loss after processing this batch is:  0.09775769710540771\n",
      "The representation loss after processing this batch is:  0.002835407853126526\n",
      "\n",
      "The classification loss after processing this batch is:  0.1759909689426422\n",
      "The representation loss after processing this batch is:  0.002500467002391815\n",
      "\n",
      "The classification loss after processing this batch is:  0.10156338661909103\n",
      "The representation loss after processing this batch is:  0.0028564482927322388\n",
      "\n",
      "The classification loss after processing this batch is:  0.0724446102976799\n",
      "The representation loss after processing this batch is:  0.0028899237513542175\n",
      "\n",
      "The classification loss after processing this batch is:  0.13362595438957214\n",
      "The representation loss after processing this batch is:  0.0035397931933403015\n",
      "\n",
      "The classification loss after processing this batch is:  0.12433654814958572\n",
      "The representation loss after processing this batch is:  0.003892861306667328\n",
      "\n",
      "The classification loss after processing this batch is:  0.07481730729341507\n",
      "The representation loss after processing this batch is:  0.003010585904121399\n",
      "\n",
      "The classification loss after processing this batch is:  0.07252577692270279\n",
      "The representation loss after processing this batch is:  0.002622172236442566\n",
      "\n",
      "The classification loss after processing this batch is:  0.19210058450698853\n",
      "The representation loss after processing this batch is:  0.002876363694667816\n",
      "\n",
      "The classification loss after processing this batch is:  0.16437435150146484\n",
      "The representation loss after processing this batch is:  0.0028189197182655334\n",
      "\n",
      "The classification loss after processing this batch is:  0.10087814927101135\n",
      "The representation loss after processing this batch is:  0.0026831552386283875\n",
      "\n",
      "The classification loss after processing this batch is:  0.12201271951198578\n",
      "The representation loss after processing this batch is:  0.002980262041091919\n",
      "\n",
      "The classification loss after processing this batch is:  0.1724960058927536\n",
      "The representation loss after processing this batch is:  0.002852506935596466\n",
      "\n",
      "The classification loss after processing this batch is:  0.20469090342521667\n",
      "The representation loss after processing this batch is:  0.002832271158695221\n",
      "\n",
      "The classification loss after processing this batch is:  0.23760738968849182\n",
      "The representation loss after processing this batch is:  0.0025916025042533875\n",
      "\n",
      "The classification loss after processing this batch is:  0.1543322205543518\n",
      "The representation loss after processing this batch is:  0.0029766112565994263\n",
      "\n",
      "The classification loss after processing this batch is:  0.29625266790390015\n",
      "The representation loss after processing this batch is:  0.002781115472316742\n",
      "\n",
      "The classification loss after processing this batch is:  0.12617598474025726\n",
      "The representation loss after processing this batch is:  0.002925388514995575\n",
      "\n",
      "The classification loss after processing this batch is:  0.11204304546117783\n",
      "The representation loss after processing this batch is:  0.0032048821449279785\n",
      "\n",
      "The classification loss after processing this batch is:  0.09573199599981308\n",
      "The representation loss after processing this batch is:  0.002815522253513336\n",
      "\n",
      "The classification loss after processing this batch is:  0.07992792129516602\n",
      "The representation loss after processing this batch is:  0.0027326568961143494\n",
      "\n",
      "The classification loss after processing this batch is:  0.2075791358947754\n",
      "The representation loss after processing this batch is:  0.0029729530215263367\n",
      "\n",
      "The classification loss after processing this batch is:  0.10935072600841522\n",
      "The representation loss after processing this batch is:  0.003321133553981781\n",
      "\n",
      "The classification loss after processing this batch is:  0.07427100092172623\n",
      "The representation loss after processing this batch is:  0.0028382763266563416\n",
      "\n",
      "The classification loss after processing this batch is:  0.06790678948163986\n",
      "The representation loss after processing this batch is:  0.003542870283126831\n",
      "\n",
      "The classification loss after processing this batch is:  0.059995319694280624\n",
      "The representation loss after processing this batch is:  0.003142610192298889\n",
      "\n",
      "The classification loss after processing this batch is:  0.07222305238246918\n",
      "The representation loss after processing this batch is:  0.003748364746570587\n",
      "\n",
      "The classification loss after processing this batch is:  0.11695174127817154\n",
      "The representation loss after processing this batch is:  0.003056474030017853\n",
      "\n",
      "The classification loss after processing this batch is:  0.08792708814144135\n",
      "The representation loss after processing this batch is:  0.0031269267201423645\n",
      "\n",
      "The classification loss after processing this batch is:  0.04064462333917618\n",
      "The representation loss after processing this batch is:  0.0031205937266349792\n",
      "\n",
      "The classification loss after processing this batch is:  0.07532308250665665\n",
      "The representation loss after processing this batch is:  0.003337867558002472\n",
      "\n",
      "The classification loss after processing this batch is:  0.09063880890607834\n",
      "The representation loss after processing this batch is:  0.00407303124666214\n",
      "\n",
      "The classification loss after processing this batch is:  0.028476189821958542\n",
      "The representation loss after processing this batch is:  0.0040634796023368835\n",
      "\n",
      "The classification loss after processing this batch is:  0.04285907745361328\n",
      "The representation loss after processing this batch is:  0.0034329816699028015\n",
      "\n",
      "The classification loss after processing this batch is:  0.19420665502548218\n",
      "The representation loss after processing this batch is:  0.0031793341040611267\n",
      "\n",
      "The classification loss after processing this batch is:  0.05489898845553398\n",
      "The representation loss after processing this batch is:  0.003385797142982483\n",
      "\n",
      "The classification loss after processing this batch is:  0.028453031554818153\n",
      "The representation loss after processing this batch is:  0.0032434388995170593\n",
      "\n",
      "The classification loss after processing this batch is:  0.06115084886550903\n",
      "The representation loss after processing this batch is:  0.003767356276512146\n",
      "\n",
      "The classification loss after processing this batch is:  0.04318418353796005\n",
      "The representation loss after processing this batch is:  0.003331109881401062\n",
      "\n",
      "The classification loss after processing this batch is:  0.03587919846177101\n",
      "The representation loss after processing this batch is:  0.0031563565135002136\n",
      "\n",
      "The classification loss after processing this batch is:  0.03170986846089363\n",
      "The representation loss after processing this batch is:  0.003416411578655243\n",
      "\n",
      "The classification loss after processing this batch is:  0.02929403819143772\n",
      "The representation loss after processing this batch is:  0.003980815410614014\n",
      "\n",
      "The classification loss after processing this batch is:  0.409748911857605\n",
      "The representation loss after processing this batch is:  0.004223629832267761\n",
      "\n",
      "The classification loss after processing this batch is:  0.36007577180862427\n",
      "The representation loss after processing this batch is:  0.0037180930376052856\n",
      "\n",
      "The classification loss after processing this batch is:  0.27245983481407166\n",
      "The representation loss after processing this batch is:  0.0039588212966918945\n",
      "\n",
      "The classification loss after processing this batch is:  0.06335323303937912\n",
      "The representation loss after processing this batch is:  0.0031635984778404236\n",
      "\n",
      "The classification loss after processing this batch is:  0.03019949607551098\n",
      "The representation loss after processing this batch is:  0.003790847957134247\n",
      "\n",
      "The classification loss after processing this batch is:  0.031465984880924225\n",
      "The representation loss after processing this batch is:  0.002685368061065674\n",
      "\n",
      "The classification loss after processing this batch is:  0.11091591417789459\n",
      "The representation loss after processing this batch is:  0.0028245076537132263\n",
      "\n",
      "The classification loss after processing this batch is:  0.4025862514972687\n",
      "The representation loss after processing this batch is:  0.0032295212149620056\n",
      "\n",
      "The classification loss after processing this batch is:  0.09738819301128387\n",
      "The representation loss after processing this batch is:  0.0030808746814727783\n",
      "\n",
      "The classification loss after processing this batch is:  0.06072954833507538\n",
      "The representation loss after processing this batch is:  0.0034556984901428223\n",
      "\n",
      "The classification loss after processing this batch is:  0.07984355092048645\n",
      "The representation loss after processing this batch is:  0.0035652220249176025\n",
      "\n",
      "The classification loss after processing this batch is:  0.05810394138097763\n",
      "The representation loss after processing this batch is:  0.003946729004383087\n",
      "\n",
      "The classification loss after processing this batch is:  0.1496891975402832\n",
      "The representation loss after processing this batch is:  0.0027841702103614807\n",
      "\n",
      "The classification loss after processing this batch is:  0.06312540918588638\n",
      "The representation loss after processing this batch is:  0.0025710836052894592\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1567305624485016\n",
      "The representation loss after processing this batch is:  0.0028835460543632507\n",
      "\n",
      "The classification loss after processing this batch is:  0.13434413075447083\n",
      "The representation loss after processing this batch is:  0.002675037831068039\n",
      "\n",
      "The classification loss after processing this batch is:  0.19836999475955963\n",
      "The representation loss after processing this batch is:  0.0027819275856018066\n",
      "\n",
      "The classification loss after processing this batch is:  0.0791507214307785\n",
      "The representation loss after processing this batch is:  0.0031175315380096436\n",
      "\n",
      "The classification loss after processing this batch is:  0.11717464029788971\n",
      "The representation loss after processing this batch is:  0.003353014588356018\n",
      "\n",
      "The classification loss after processing this batch is:  0.11859847605228424\n",
      "The representation loss after processing this batch is:  0.0029028579592704773\n",
      "\n",
      "The classification loss after processing this batch is:  0.1639544516801834\n",
      "The representation loss after processing this batch is:  0.0025633350014686584\n",
      "\n",
      "The classification loss after processing this batch is:  0.1312171369791031\n",
      "The representation loss after processing this batch is:  0.0027346089482307434\n",
      "\n",
      "The classification loss after processing this batch is:  0.20153051614761353\n",
      "The representation loss after processing this batch is:  0.002436026930809021\n",
      "\n",
      "The classification loss after processing this batch is:  0.0998164489865303\n",
      "The representation loss after processing this batch is:  0.00273122638463974\n",
      "\n",
      "The classification loss after processing this batch is:  0.14612726867198944\n",
      "The representation loss after processing this batch is:  0.002978123724460602\n",
      "\n",
      "The classification loss after processing this batch is:  0.07325378805398941\n",
      "The representation loss after processing this batch is:  0.002797640860080719\n",
      "\n",
      "The classification loss after processing this batch is:  0.32104000449180603\n",
      "The representation loss after processing this batch is:  0.0029782354831695557\n",
      "\n",
      "The classification loss after processing this batch is:  0.1709924042224884\n",
      "The representation loss after processing this batch is:  0.002805367112159729\n",
      "\n",
      "The classification loss after processing this batch is:  0.19878023862838745\n",
      "The representation loss after processing this batch is:  0.002774186432361603\n",
      "\n",
      "The classification loss after processing this batch is:  0.2913183271884918\n",
      "The representation loss after processing this batch is:  0.003527674823999405\n",
      "\n",
      "The classification loss after processing this batch is:  0.18979236483573914\n",
      "The representation loss after processing this batch is:  0.003150172531604767\n",
      "\n",
      "The classification loss after processing this batch is:  0.08713201433420181\n",
      "The representation loss after processing this batch is:  0.003269653767347336\n",
      "\n",
      "The classification loss after processing this batch is:  0.2803906500339508\n",
      "The representation loss after processing this batch is:  0.0036635994911193848\n",
      "\n",
      "The classification loss after processing this batch is:  0.18879172205924988\n",
      "The representation loss after processing this batch is:  0.0030044540762901306\n",
      "\n",
      "The classification loss after processing this batch is:  0.34325212240219116\n",
      "The representation loss after processing this batch is:  0.002827942371368408\n",
      "\n",
      "The classification loss after processing this batch is:  0.12203545868396759\n",
      "The representation loss after processing this batch is:  0.002547338604927063\n",
      "\n",
      "The classification loss after processing this batch is:  0.09369533509016037\n",
      "The representation loss after processing this batch is:  0.002843223512172699\n",
      "\n",
      "The classification loss after processing this batch is:  0.11473345011472702\n",
      "The representation loss after processing this batch is:  0.0025852173566818237\n",
      "\n",
      "The classification loss after processing this batch is:  0.15860368311405182\n",
      "The representation loss after processing this batch is:  0.002537675201892853\n",
      "\n",
      "The classification loss after processing this batch is:  0.10674382001161575\n",
      "The representation loss after processing this batch is:  0.0029505938291549683\n",
      "\n",
      "The classification loss after processing this batch is:  0.0697743147611618\n",
      "The representation loss after processing this batch is:  0.0027837157249450684\n",
      "\n",
      "The classification loss after processing this batch is:  0.06315610557794571\n",
      "The representation loss after processing this batch is:  0.0028767958283424377\n",
      "\n",
      "The classification loss after processing this batch is:  0.07031145691871643\n",
      "The representation loss after processing this batch is:  0.002650577574968338\n",
      "\n",
      "The classification loss after processing this batch is:  0.09556370228528976\n",
      "The representation loss after processing this batch is:  0.0029405876994132996\n",
      "\n",
      "The classification loss after processing this batch is:  0.19889281690120697\n",
      "The representation loss after processing this batch is:  0.00298435240983963\n",
      "\n",
      "The classification loss after processing this batch is:  0.12320014089345932\n",
      "The representation loss after processing this batch is:  0.0032295212149620056\n",
      "\n",
      "The classification loss after processing this batch is:  0.14135071635246277\n",
      "The representation loss after processing this batch is:  0.00256182998418808\n",
      "\n",
      "The classification loss after processing this batch is:  0.07149802893400192\n",
      "The representation loss after processing this batch is:  0.0030831024050712585\n",
      "\n",
      "The classification loss after processing this batch is:  0.08997384458780289\n",
      "The representation loss after processing this batch is:  0.0029963329434394836\n",
      "\n",
      "The classification loss after processing this batch is:  0.1403018832206726\n",
      "The representation loss after processing this batch is:  0.0028645172715187073\n",
      "\n",
      "The classification loss after processing this batch is:  0.06440221518278122\n",
      "The representation loss after processing this batch is:  0.0031990185379981995\n",
      "\n",
      "The classification loss after processing this batch is:  0.08919115364551544\n",
      "The representation loss after processing this batch is:  0.0028596892952919006\n",
      "\n",
      "The classification loss after processing this batch is:  0.19784052670001984\n",
      "The representation loss after processing this batch is:  0.003376781940460205\n",
      "\n",
      "The classification loss after processing this batch is:  0.1078731119632721\n",
      "The representation loss after processing this batch is:  0.0028810277581214905\n",
      "\n",
      "The classification loss after processing this batch is:  0.12502554059028625\n",
      "The representation loss after processing this batch is:  0.0026918426156044006\n",
      "\n",
      "The classification loss after processing this batch is:  0.14903052151203156\n",
      "The representation loss after processing this batch is:  0.0026225894689559937\n",
      "\n",
      "The classification loss after processing this batch is:  0.13115130364894867\n",
      "The representation loss after processing this batch is:  0.002694733440876007\n",
      "\n",
      "The classification loss after processing this batch is:  0.1516844779253006\n",
      "The representation loss after processing this batch is:  0.0025293640792369843\n",
      "\n",
      "The classification loss after processing this batch is:  0.22017408907413483\n",
      "The representation loss after processing this batch is:  0.002959076315164566\n",
      "\n",
      "The classification loss after processing this batch is:  0.06572795659303665\n",
      "The representation loss after processing this batch is:  0.0028034672141075134\n",
      "\n",
      "The classification loss after processing this batch is:  0.16973604261875153\n",
      "The representation loss after processing this batch is:  0.0029617473483085632\n",
      "\n",
      "The classification loss after processing this batch is:  0.1046348363161087\n",
      "The representation loss after processing this batch is:  0.002770543098449707\n",
      "\n",
      "The classification loss after processing this batch is:  0.15368908643722534\n",
      "The representation loss after processing this batch is:  0.0028859376907348633\n",
      "\n",
      "The classification loss after processing this batch is:  0.13457584381103516\n",
      "The representation loss after processing this batch is:  0.0032040029764175415\n",
      "\n",
      "The classification loss after processing this batch is:  0.08496216684579849\n",
      "The representation loss after processing this batch is:  0.002936922013759613\n",
      "\n",
      "The classification loss after processing this batch is:  0.10519547760486603\n",
      "The representation loss after processing this batch is:  0.0030159279704093933\n",
      "\n",
      "The classification loss after processing this batch is:  0.1284157782793045\n",
      "The representation loss after processing this batch is:  0.002832852303981781\n",
      "\n",
      "The classification loss after processing this batch is:  0.14572976529598236\n",
      "The representation loss after processing this batch is:  0.0027622580528259277\n",
      "\n",
      "The classification loss after processing this batch is:  0.17551304399967194\n",
      "The representation loss after processing this batch is:  0.0025976672768592834\n",
      "\n",
      "The classification loss after processing this batch is:  0.0988227128982544\n",
      "The representation loss after processing this batch is:  0.003111906349658966\n",
      "\n",
      "The classification loss after processing this batch is:  0.15516647696495056\n",
      "The representation loss after processing this batch is:  0.002988360822200775\n",
      "\n",
      "The classification loss after processing this batch is:  0.09177340567111969\n",
      "The representation loss after processing this batch is:  0.0027789026498794556\n",
      "\n",
      "The classification loss after processing this batch is:  0.07635169476270676\n",
      "The representation loss after processing this batch is:  0.0026425980031490326\n",
      "\n",
      "The classification loss after processing this batch is:  0.16605708003044128\n",
      "The representation loss after processing this batch is:  0.002740420401096344\n",
      "\n",
      "The classification loss after processing this batch is:  0.15171360969543457\n",
      "The representation loss after processing this batch is:  0.0028723999857902527\n",
      "\n",
      "The classification loss after processing this batch is:  0.10705945640802383\n",
      "The representation loss after processing this batch is:  0.0026862435042858124\n",
      "\n",
      "The classification loss after processing this batch is:  0.11976925283670425\n",
      "The representation loss after processing this batch is:  0.0025791674852371216\n",
      "\n",
      "The classification loss after processing this batch is:  0.0860135480761528\n",
      "The representation loss after processing this batch is:  0.0025994107127189636\n",
      "\n",
      "The classification loss after processing this batch is:  0.1553327441215515\n",
      "The representation loss after processing this batch is:  0.0031896233558654785\n",
      "\n",
      "The classification loss after processing this batch is:  0.16697236895561218\n",
      "The representation loss after processing this batch is:  0.0024681389331817627\n",
      "\n",
      "The classification loss after processing this batch is:  0.07315397262573242\n",
      "The representation loss after processing this batch is:  0.002542942762374878\n",
      "\n",
      "The classification loss after processing this batch is:  0.20239944756031036\n",
      "The representation loss after processing this batch is:  0.003122754395008087\n",
      "\n",
      "The classification loss after processing this batch is:  0.13110819458961487\n",
      "The representation loss after processing this batch is:  0.0027745068073272705\n",
      "\n",
      "The classification loss after processing this batch is:  0.11783935129642487\n",
      "The representation loss after processing this batch is:  0.00263947993516922\n",
      "\n",
      "The classification loss after processing this batch is:  0.11816169321537018\n",
      "The representation loss after processing this batch is:  0.0024440884590148926\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08594571053981781\n",
      "The representation loss after processing this batch is:  0.0029909536242485046\n",
      "\n",
      "The classification loss after processing this batch is:  0.10410717129707336\n",
      "The representation loss after processing this batch is:  0.0024571865797042847\n",
      "\n",
      "The classification loss after processing this batch is:  0.17924539744853973\n",
      "The representation loss after processing this batch is:  0.002956502139568329\n",
      "\n",
      "The classification loss after processing this batch is:  0.0882805660367012\n",
      "The representation loss after processing this batch is:  0.0025667697191238403\n",
      "\n",
      "The classification loss after processing this batch is:  0.2853560149669647\n",
      "The representation loss after processing this batch is:  0.002719402313232422\n",
      "\n",
      "The classification loss after processing this batch is:  0.1450161337852478\n",
      "The representation loss after processing this batch is:  0.002738445997238159\n",
      "\n",
      "The classification loss after processing this batch is:  0.11283247172832489\n",
      "The representation loss after processing this batch is:  0.003423057496547699\n",
      "\n",
      "The classification loss after processing this batch is:  0.14035886526107788\n",
      "The representation loss after processing this batch is:  0.002719379961490631\n",
      "\n",
      "The classification loss after processing this batch is:  0.12527571618556976\n",
      "The representation loss after processing this batch is:  0.0030375197529792786\n",
      "\n",
      "The classification loss after processing this batch is:  0.29263514280319214\n",
      "The representation loss after processing this batch is:  0.003030434250831604\n",
      "\n",
      "The classification loss after processing this batch is:  0.1427590399980545\n",
      "The representation loss after processing this batch is:  0.002958238124847412\n",
      "\n",
      "The classification loss after processing this batch is:  0.15329767763614655\n",
      "The representation loss after processing this batch is:  0.0023777931928634644\n",
      "\n",
      "The classification loss after processing this batch is:  0.3040483295917511\n",
      "The representation loss after processing this batch is:  0.002775728702545166\n",
      "\n",
      "The classification loss after processing this batch is:  0.15511083602905273\n",
      "The representation loss after processing this batch is:  0.002593711018562317\n",
      "\n",
      "The classification loss after processing this batch is:  0.07216344028711319\n",
      "The representation loss after processing this batch is:  0.002978965640068054\n",
      "\n",
      "The classification loss after processing this batch is:  0.17540937662124634\n",
      "The representation loss after processing this batch is:  0.002670641988515854\n",
      "\n",
      "The classification loss after processing this batch is:  0.19641278684139252\n",
      "The representation loss after processing this batch is:  0.0025100409984588623\n",
      "\n",
      "The classification loss after processing this batch is:  0.14568261802196503\n",
      "The representation loss after processing this batch is:  0.002939000725746155\n",
      "\n",
      "The classification loss after processing this batch is:  0.0818561539053917\n",
      "The representation loss after processing this batch is:  0.002421073615550995\n",
      "\n",
      "The classification loss after processing this batch is:  0.14895150065422058\n",
      "The representation loss after processing this batch is:  0.0026051998138427734\n",
      "\n",
      "The classification loss after processing this batch is:  0.16671361029148102\n",
      "The representation loss after processing this batch is:  0.002610936760902405\n",
      "\n",
      "The classification loss after processing this batch is:  0.17309574782848358\n",
      "The representation loss after processing this batch is:  0.003130674362182617\n",
      "\n",
      "The classification loss after processing this batch is:  0.20156599581241608\n",
      "The representation loss after processing this batch is:  0.0025330185890197754\n",
      "\n",
      "The classification loss after processing this batch is:  0.1586633026599884\n",
      "The representation loss after processing this batch is:  0.0029971301555633545\n",
      "\n",
      "The classification loss after processing this batch is:  0.16397126019001007\n",
      "The representation loss after processing this batch is:  0.0032850131392478943\n",
      "\n",
      "The classification loss after processing this batch is:  0.09144637733697891\n",
      "The representation loss after processing this batch is:  0.0031999126076698303\n",
      "\n",
      "The classification loss after processing this batch is:  0.10532306879758835\n",
      "The representation loss after processing this batch is:  0.002745494246482849\n",
      "\n",
      "The classification loss after processing this batch is:  0.06089944392442703\n",
      "The representation loss after processing this batch is:  0.0028019696474075317\n",
      "\n",
      "The classification loss after processing this batch is:  0.1529921591281891\n",
      "The representation loss after processing this batch is:  0.0031319409608840942\n",
      "\n",
      "The classification loss after processing this batch is:  0.09718341380357742\n",
      "The representation loss after processing this batch is:  0.0028432831168174744\n",
      "\n",
      "The classification loss after processing this batch is:  0.2708057463169098\n",
      "The representation loss after processing this batch is:  0.0031451284885406494\n",
      "\n",
      "The classification loss after processing this batch is:  0.272321492433548\n",
      "The representation loss after processing this batch is:  0.0030057579278945923\n",
      "\n",
      "The classification loss after processing this batch is:  0.11764036864042282\n",
      "The representation loss after processing this batch is:  0.002751186490058899\n",
      "\n",
      "The classification loss after processing this batch is:  0.12545527517795563\n",
      "The representation loss after processing this batch is:  0.003152810037136078\n",
      "\n",
      "The classification loss after processing this batch is:  0.13755451142787933\n",
      "The representation loss after processing this batch is:  0.0026118047535419464\n",
      "\n",
      "The classification loss after processing this batch is:  0.06151373311877251\n",
      "The representation loss after processing this batch is:  0.003062203526496887\n",
      "\n",
      "The classification loss after processing this batch is:  0.08104869723320007\n",
      "The representation loss after processing this batch is:  0.0029008090496063232\n",
      "\n",
      "The classification loss after processing this batch is:  0.15219704806804657\n",
      "The representation loss after processing this batch is:  0.0025939643383026123\n",
      "\n",
      "The classification loss after processing this batch is:  0.0984821766614914\n",
      "The representation loss after processing this batch is:  0.0034625977277755737\n",
      "\n",
      "The classification loss after processing this batch is:  0.10445509850978851\n",
      "The representation loss after processing this batch is:  0.0028953328728675842\n",
      "\n",
      "The classification loss after processing this batch is:  0.24718357622623444\n",
      "The representation loss after processing this batch is:  0.0036646202206611633\n",
      "\n",
      "The classification loss after processing this batch is:  0.22616954147815704\n",
      "The representation loss after processing this batch is:  0.002557847648859024\n",
      "\n",
      "The classification loss after processing this batch is:  0.14673593640327454\n",
      "The representation loss after processing this batch is:  0.003004692494869232\n",
      "\n",
      "The classification loss after processing this batch is:  0.22819337248802185\n",
      "The representation loss after processing this batch is:  0.0031471550464630127\n",
      "\n",
      "The classification loss after processing this batch is:  0.14948399364948273\n",
      "The representation loss after processing this batch is:  0.0027576684951782227\n",
      "\n",
      "The classification loss after processing this batch is:  0.07861611992120743\n",
      "The representation loss after processing this batch is:  0.002794019877910614\n",
      "\n",
      "The classification loss after processing this batch is:  0.2036312371492386\n",
      "The representation loss after processing this batch is:  0.0028117895126342773\n",
      "\n",
      "The classification loss after processing this batch is:  0.3649846911430359\n",
      "The representation loss after processing this batch is:  0.0034531503915786743\n",
      "\n",
      "The classification loss after processing this batch is:  0.18867667019367218\n",
      "The representation loss after processing this batch is:  0.003457285463809967\n",
      "\n",
      "The classification loss after processing this batch is:  0.14142699539661407\n",
      "The representation loss after processing this batch is:  0.0033455565571784973\n",
      "\n",
      "The classification loss after processing this batch is:  0.11094270646572113\n",
      "The representation loss after processing this batch is:  0.0030960217118263245\n",
      "\n",
      "The classification loss after processing this batch is:  0.08867677301168442\n",
      "The representation loss after processing this batch is:  0.0030745714902877808\n",
      "\n",
      "The classification loss after processing this batch is:  0.13583463430404663\n",
      "The representation loss after processing this batch is:  0.002886176109313965\n",
      "\n",
      "The classification loss after processing this batch is:  0.10868347436189651\n",
      "The representation loss after processing this batch is:  0.0029342100024223328\n",
      "\n",
      "The classification loss after processing this batch is:  0.14800161123275757\n",
      "The representation loss after processing this batch is:  0.002671942114830017\n",
      "\n",
      "The classification loss after processing this batch is:  0.13799592852592468\n",
      "The representation loss after processing this batch is:  0.003010660409927368\n",
      "\n",
      "The classification loss after processing this batch is:  0.25250786542892456\n",
      "The representation loss after processing this batch is:  0.0029911845922470093\n",
      "\n",
      "The classification loss after processing this batch is:  0.10736791044473648\n",
      "The representation loss after processing this batch is:  0.0025949031114578247\n",
      "\n",
      "The classification loss after processing this batch is:  0.12670889496803284\n",
      "The representation loss after processing this batch is:  0.0025277510285377502\n",
      "\n",
      "The classification loss after processing this batch is:  0.13385817408561707\n",
      "The representation loss after processing this batch is:  0.0024629756808280945\n",
      "\n",
      "The classification loss after processing this batch is:  0.12980042397975922\n",
      "The representation loss after processing this batch is:  0.002669587731361389\n",
      "\n",
      "The classification loss after processing this batch is:  0.1052132099866867\n",
      "The representation loss after processing this batch is:  0.002916678786277771\n",
      "\n",
      "The classification loss after processing this batch is:  0.19402500987052917\n",
      "The representation loss after processing this batch is:  0.002822093665599823\n",
      "\n",
      "The classification loss after processing this batch is:  0.19221684336662292\n",
      "The representation loss after processing this batch is:  0.002997279167175293\n",
      "\n",
      "The classification loss after processing this batch is:  0.21087220311164856\n",
      "The representation loss after processing this batch is:  0.0026749931275844574\n",
      "\n",
      "The classification loss after processing this batch is:  0.10088253766298294\n",
      "The representation loss after processing this batch is:  0.0028236880898475647\n",
      "\n",
      "The classification loss after processing this batch is:  0.21854159235954285\n",
      "The representation loss after processing this batch is:  0.0029077231884002686\n",
      "\n",
      "The classification loss after processing this batch is:  0.19501318037509918\n",
      "The representation loss after processing this batch is:  0.0029788613319396973\n",
      "\n",
      "The classification loss after processing this batch is:  0.17701095342636108\n",
      "The representation loss after processing this batch is:  0.002788655459880829\n",
      "\n",
      "The classification loss after processing this batch is:  0.08978254348039627\n",
      "The representation loss after processing this batch is:  0.0030538812279701233\n",
      "\n",
      "The classification loss after processing this batch is:  0.12698116898536682\n",
      "The representation loss after processing this batch is:  0.003456525504589081\n",
      "\n",
      "The classification loss after processing this batch is:  0.2884378135204315\n",
      "The representation loss after processing this batch is:  0.0028997063636779785\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.25187334418296814\n",
      "The representation loss after processing this batch is:  0.0026914142072200775\n",
      "\n",
      "The classification loss after processing this batch is:  0.25261157751083374\n",
      "The representation loss after processing this batch is:  0.0031489990651607513\n",
      "\n",
      "The classification loss after processing this batch is:  0.33990076184272766\n",
      "The representation loss after processing this batch is:  0.002774357795715332\n",
      "\n",
      "The classification loss after processing this batch is:  0.26324203610420227\n",
      "The representation loss after processing this batch is:  0.0026476234197616577\n",
      "\n",
      "The classification loss after processing this batch is:  0.085414819419384\n",
      "The representation loss after processing this batch is:  0.0026598870754241943\n",
      "\n",
      "The classification loss after processing this batch is:  0.09209392964839935\n",
      "The representation loss after processing this batch is:  0.0027373507618904114\n",
      "\n",
      "The classification loss after processing this batch is:  0.11854305118322372\n",
      "The representation loss after processing this batch is:  0.003143906593322754\n",
      "\n",
      "The classification loss after processing this batch is:  0.15551428496837616\n",
      "The representation loss after processing this batch is:  0.0037113502621650696\n",
      "\n",
      "The classification loss after processing this batch is:  0.052829328924417496\n",
      "The representation loss after processing this batch is:  0.0031864792108535767\n",
      "\n",
      "The classification loss after processing this batch is:  0.20199720561504364\n",
      "The representation loss after processing this batch is:  0.00362367182970047\n",
      "\n",
      "The classification loss after processing this batch is:  0.16289077699184418\n",
      "The representation loss after processing this batch is:  0.002681836485862732\n",
      "\n",
      "The classification loss after processing this batch is:  0.14474931359291077\n",
      "The representation loss after processing this batch is:  0.002829980105161667\n",
      "\n",
      "The classification loss after processing this batch is:  0.24084138870239258\n",
      "The representation loss after processing this batch is:  0.0028479918837547302\n",
      "\n",
      "The classification loss after processing this batch is:  0.11552876979112625\n",
      "The representation loss after processing this batch is:  0.0031853988766670227\n",
      "\n",
      "The classification loss after processing this batch is:  0.1982775330543518\n",
      "The representation loss after processing this batch is:  0.003611914813518524\n",
      "\n",
      "The classification loss after processing this batch is:  0.19405317306518555\n",
      "The representation loss after processing this batch is:  0.0031470879912376404\n",
      "\n",
      "The classification loss after processing this batch is:  0.13070188462734222\n",
      "The representation loss after processing this batch is:  0.003605775535106659\n",
      "\n",
      "The classification loss after processing this batch is:  0.14262491464614868\n",
      "The representation loss after processing this batch is:  0.0024628862738609314\n",
      "\n",
      "The classification loss after processing this batch is:  0.09678971767425537\n",
      "The representation loss after processing this batch is:  0.002825722098350525\n",
      "\n",
      "The classification loss after processing this batch is:  0.06870425492525101\n",
      "The representation loss after processing this batch is:  0.002807304263114929\n",
      "\n",
      "The classification loss after processing this batch is:  0.10008014738559723\n",
      "The representation loss after processing this batch is:  0.002756446599960327\n",
      "\n",
      "The classification loss after processing this batch is:  0.0858868807554245\n",
      "The representation loss after processing this batch is:  0.002701845020055771\n",
      "\n",
      "The classification loss after processing this batch is:  0.10888274013996124\n",
      "The representation loss after processing this batch is:  0.0024142414331436157\n",
      "\n",
      "The classification loss after processing this batch is:  0.12967565655708313\n",
      "The representation loss after processing this batch is:  0.002625875174999237\n",
      "\n",
      "The classification loss after processing this batch is:  0.15315522253513336\n",
      "The representation loss after processing this batch is:  0.002666883170604706\n",
      "\n",
      "The classification loss after processing this batch is:  0.38787010312080383\n",
      "The representation loss after processing this batch is:  0.0030681416392326355\n",
      "\n",
      "The classification loss after processing this batch is:  0.2560700476169586\n",
      "The representation loss after processing this batch is:  0.0031739771366119385\n",
      "\n",
      "The classification loss after processing this batch is:  0.1109432652592659\n",
      "The representation loss after processing this batch is:  0.0026539191603660583\n",
      "\n",
      "The classification loss after processing this batch is:  0.1042865663766861\n",
      "The representation loss after processing this batch is:  0.003123261034488678\n",
      "\n",
      "The classification loss after processing this batch is:  0.08780813962221146\n",
      "The representation loss after processing this batch is:  0.0031070858240127563\n",
      "\n",
      "The classification loss after processing this batch is:  0.09939530491828918\n",
      "The representation loss after processing this batch is:  0.002751268446445465\n",
      "\n",
      "The classification loss after processing this batch is:  0.047256793826818466\n",
      "The representation loss after processing this batch is:  0.003019295632839203\n",
      "\n",
      "The classification loss after processing this batch is:  0.10738220810890198\n",
      "The representation loss after processing this batch is:  0.002947300672531128\n",
      "\n",
      "The classification loss after processing this batch is:  0.13276706635951996\n",
      "The representation loss after processing this batch is:  0.002695821225643158\n",
      "\n",
      "The classification loss after processing this batch is:  0.23949028551578522\n",
      "The representation loss after processing this batch is:  0.0027295947074890137\n",
      "\n",
      "The classification loss after processing this batch is:  0.10752187669277191\n",
      "The representation loss after processing this batch is:  0.002556726336479187\n",
      "\n",
      "The classification loss after processing this batch is:  0.08676429837942123\n",
      "The representation loss after processing this batch is:  0.002652384340763092\n",
      "\n",
      "The classification loss after processing this batch is:  0.07006832957267761\n",
      "The representation loss after processing this batch is:  0.0027350634336471558\n",
      "\n",
      "The classification loss after processing this batch is:  0.2598283886909485\n",
      "The representation loss after processing this batch is:  0.002862691879272461\n",
      "\n",
      "The classification loss after processing this batch is:  0.11134921759366989\n",
      "The representation loss after processing this batch is:  0.0029575228691101074\n",
      "\n",
      "The classification loss after processing this batch is:  0.08887896686792374\n",
      "The representation loss after processing this batch is:  0.0028569623827934265\n",
      "\n",
      "The classification loss after processing this batch is:  0.15635904669761658\n",
      "The representation loss after processing this batch is:  0.0030335038900375366\n",
      "\n",
      "The classification loss after processing this batch is:  0.12490611523389816\n",
      "The representation loss after processing this batch is:  0.002362288534641266\n",
      "\n",
      "The classification loss after processing this batch is:  0.0778895914554596\n",
      "The representation loss after processing this batch is:  0.0026488378643989563\n",
      "\n",
      "The classification loss after processing this batch is:  0.14238856732845306\n",
      "The representation loss after processing this batch is:  0.0027085766196250916\n",
      "\n",
      "The classification loss after processing this batch is:  0.09461424499750137\n",
      "The representation loss after processing this batch is:  0.0026535838842391968\n",
      "\n",
      "The classification loss after processing this batch is:  0.11083587259054184\n",
      "The representation loss after processing this batch is:  0.002816595137119293\n",
      "\n",
      "The classification loss after processing this batch is:  0.19773060083389282\n",
      "The representation loss after processing this batch is:  0.0027413293719291687\n",
      "\n",
      "The classification loss after processing this batch is:  0.1961379200220108\n",
      "The representation loss after processing this batch is:  0.002712331712245941\n",
      "\n",
      "The classification loss after processing this batch is:  0.1871337592601776\n",
      "The representation loss after processing this batch is:  0.0028157904744148254\n",
      "\n",
      "The classification loss after processing this batch is:  0.1903875321149826\n",
      "The representation loss after processing this batch is:  0.0025622695684432983\n",
      "\n",
      "The classification loss after processing this batch is:  0.11390014737844467\n",
      "The representation loss after processing this batch is:  0.002831932157278061\n",
      "\n",
      "The classification loss after processing this batch is:  0.18258489668369293\n",
      "The representation loss after processing this batch is:  0.0027640312910079956\n",
      "\n",
      "The classification loss after processing this batch is:  0.11061032116413116\n",
      "The representation loss after processing this batch is:  0.003094688057899475\n",
      "\n",
      "The classification loss after processing this batch is:  0.15049953758716583\n",
      "The representation loss after processing this batch is:  0.002913959324359894\n",
      "\n",
      "The classification loss after processing this batch is:  0.08830133825540543\n",
      "The representation loss after processing this batch is:  0.0025121793150901794\n",
      "\n",
      "The classification loss after processing this batch is:  0.19582001864910126\n",
      "The representation loss after processing this batch is:  0.0025201886892318726\n",
      "\n",
      "The classification loss after processing this batch is:  0.09928644448518753\n",
      "The representation loss after processing this batch is:  0.0028588026762008667\n",
      "\n",
      "The classification loss after processing this batch is:  0.13493569195270538\n",
      "The representation loss after processing this batch is:  0.0024324171245098114\n",
      "\n",
      "The classification loss after processing this batch is:  0.14283506572246552\n",
      "The representation loss after processing this batch is:  0.0025844797492027283\n",
      "\n",
      "The classification loss after processing this batch is:  0.1330912709236145\n",
      "The representation loss after processing this batch is:  0.0026207342743873596\n",
      "\n",
      "The classification loss after processing this batch is:  0.1849098801612854\n",
      "The representation loss after processing this batch is:  0.0023857280611991882\n",
      "\n",
      "The classification loss after processing this batch is:  0.156523659825325\n",
      "The representation loss after processing this batch is:  0.0024971365928649902\n",
      "\n",
      "The classification loss after processing this batch is:  0.21493469178676605\n",
      "The representation loss after processing this batch is:  0.002558726817369461\n",
      "\n",
      "The classification loss after processing this batch is:  0.22546085715293884\n",
      "The representation loss after processing this batch is:  0.002714402973651886\n",
      "\n",
      "The classification loss after processing this batch is:  0.2962082326412201\n",
      "The representation loss after processing this batch is:  0.0027492307126522064\n",
      "\n",
      "The classification loss after processing this batch is:  0.22287923097610474\n",
      "The representation loss after processing this batch is:  0.0023737922310829163\n",
      "\n",
      "The classification loss after processing this batch is:  0.08309317380189896\n",
      "The representation loss after processing this batch is:  0.0027886778116226196\n",
      "\n",
      "The classification loss after processing this batch is:  0.18085168302059174\n",
      "The representation loss after processing this batch is:  0.0029351040720939636\n",
      "\n",
      "The classification loss after processing this batch is:  0.12631459534168243\n",
      "The representation loss after processing this batch is:  0.0028955787420272827\n",
      "\n",
      "The classification loss after processing this batch is:  0.1234598308801651\n",
      "The representation loss after processing this batch is:  0.0031603388488292694\n",
      "\n",
      "The classification loss after processing this batch is:  0.2221466451883316\n",
      "The representation loss after processing this batch is:  0.0033122822642326355\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.23354752361774445\n",
      "The representation loss after processing this batch is:  0.0030924081802368164\n",
      "\n",
      "The classification loss after processing this batch is:  0.33674633502960205\n",
      "The representation loss after processing this batch is:  0.002884812653064728\n",
      "\n",
      "The classification loss after processing this batch is:  0.1723131537437439\n",
      "The representation loss after processing this batch is:  0.0029462985694408417\n",
      "\n",
      "The classification loss after processing this batch is:  0.0927363708615303\n",
      "The representation loss after processing this batch is:  0.002930089831352234\n",
      "\n",
      "The classification loss after processing this batch is:  0.10763992369174957\n",
      "The representation loss after processing this batch is:  0.0028497204184532166\n",
      "\n",
      "The classification loss after processing this batch is:  0.21855367720127106\n",
      "The representation loss after processing this batch is:  0.002518169581890106\n",
      "\n",
      "The classification loss after processing this batch is:  0.10058493912220001\n",
      "The representation loss after processing this batch is:  0.0028109923005104065\n",
      "\n",
      "The classification loss after processing this batch is:  0.12407439202070236\n",
      "The representation loss after processing this batch is:  0.0026790648698806763\n",
      "\n",
      "The classification loss after processing this batch is:  0.09049983322620392\n",
      "The representation loss after processing this batch is:  0.0030065178871154785\n",
      "\n",
      "The classification loss after processing this batch is:  0.03884592279791832\n",
      "The representation loss after processing this batch is:  0.00274541974067688\n",
      "\n",
      "The classification loss after processing this batch is:  0.16121551394462585\n",
      "The representation loss after processing this batch is:  0.002887491136789322\n",
      "\n",
      "The classification loss after processing this batch is:  0.14135430753231049\n",
      "The representation loss after processing this batch is:  0.003160964697599411\n",
      "\n",
      "The classification loss after processing this batch is:  0.19434325397014618\n",
      "The representation loss after processing this batch is:  0.0027251653373241425\n",
      "\n",
      "The classification loss after processing this batch is:  0.17561639845371246\n",
      "The representation loss after processing this batch is:  0.002451501786708832\n",
      "\n",
      "The classification loss after processing this batch is:  0.14579881727695465\n",
      "The representation loss after processing this batch is:  0.0028241798281669617\n",
      "\n",
      "The classification loss after processing this batch is:  0.16616496443748474\n",
      "The representation loss after processing this batch is:  0.002673022449016571\n",
      "\n",
      "The classification loss after processing this batch is:  0.15172262489795685\n",
      "The representation loss after processing this batch is:  0.00268666073679924\n",
      "\n",
      "The classification loss after processing this batch is:  0.1594569981098175\n",
      "The representation loss after processing this batch is:  0.003094591200351715\n",
      "\n",
      "The classification loss after processing this batch is:  0.18389615416526794\n",
      "The representation loss after processing this batch is:  0.0031184256076812744\n",
      "\n",
      "The classification loss after processing this batch is:  0.17102257907390594\n",
      "The representation loss after processing this batch is:  0.0031582191586494446\n",
      "\n",
      "The classification loss after processing this batch is:  0.14531543850898743\n",
      "The representation loss after processing this batch is:  0.0025604218244552612\n",
      "\n",
      "The classification loss after processing this batch is:  0.22584401071071625\n",
      "The representation loss after processing this batch is:  0.002771608531475067\n",
      "\n",
      "The classification loss after processing this batch is:  0.23977361619472504\n",
      "The representation loss after processing this batch is:  0.0030390992760658264\n",
      "\n",
      "The classification loss after processing this batch is:  0.10745131969451904\n",
      "The representation loss after processing this batch is:  0.0024232976138591766\n",
      "\n",
      "The classification loss after processing this batch is:  0.1330445408821106\n",
      "The representation loss after processing this batch is:  0.003101784735918045\n",
      "\n",
      "The classification loss after processing this batch is:  0.14814823865890503\n",
      "The representation loss after processing this batch is:  0.00281674787402153\n",
      "\n",
      "The classification loss after processing this batch is:  0.16320618987083435\n",
      "The representation loss after processing this batch is:  0.002691973000764847\n",
      "\n",
      "The classification loss after processing this batch is:  0.21485236287117004\n",
      "The representation loss after processing this batch is:  0.0033043697476387024\n",
      "\n",
      "The classification loss after processing this batch is:  0.2698209881782532\n",
      "The representation loss after processing this batch is:  0.003203757107257843\n",
      "\n",
      "The classification loss after processing this batch is:  0.255388081073761\n",
      "The representation loss after processing this batch is:  0.003206901252269745\n",
      "\n",
      "The classification loss after processing this batch is:  0.18184490501880646\n",
      "The representation loss after processing this batch is:  0.0029936209321022034\n",
      "\n",
      "The classification loss after processing this batch is:  0.15346430242061615\n",
      "The representation loss after processing this batch is:  0.002885032445192337\n",
      "\n",
      "The classification loss after processing this batch is:  0.11042705923318863\n",
      "The representation loss after processing this batch is:  0.003435298800468445\n",
      "\n",
      "The classification loss after processing this batch is:  0.0816430151462555\n",
      "The representation loss after processing this batch is:  0.002986729145050049\n",
      "\n",
      "The classification loss after processing this batch is:  0.198526069521904\n",
      "The representation loss after processing this batch is:  0.0029256194829940796\n",
      "\n",
      "The classification loss after processing this batch is:  0.1683194488286972\n",
      "The representation loss after processing this batch is:  0.00269453227519989\n",
      "\n",
      "The classification loss after processing this batch is:  0.09909935295581818\n",
      "The representation loss after processing this batch is:  0.002695128321647644\n",
      "\n",
      "The classification loss after processing this batch is:  0.15672729909420013\n",
      "The representation loss after processing this batch is:  0.0029072463512420654\n",
      "\n",
      "The classification loss after processing this batch is:  0.1279798150062561\n",
      "The representation loss after processing this batch is:  0.0033001452684402466\n",
      "\n",
      "The classification loss after processing this batch is:  0.18850864470005035\n",
      "The representation loss after processing this batch is:  0.0028403252363204956\n",
      "\n",
      "The classification loss after processing this batch is:  0.12962539494037628\n",
      "The representation loss after processing this batch is:  0.002915814518928528\n",
      "\n",
      "The classification loss after processing this batch is:  0.11946702003479004\n",
      "The representation loss after processing this batch is:  0.00270969420671463\n",
      "\n",
      "The classification loss after processing this batch is:  0.06710769236087799\n",
      "The representation loss after processing this batch is:  0.0026888325810432434\n",
      "\n",
      "The classification loss after processing this batch is:  0.1285114586353302\n",
      "The representation loss after processing this batch is:  0.002585954964160919\n",
      "\n",
      "The classification loss after processing this batch is:  0.11769993603229523\n",
      "The representation loss after processing this batch is:  0.00248582661151886\n",
      "\n",
      "The classification loss after processing this batch is:  0.47213253378868103\n",
      "The representation loss after processing this batch is:  0.002928309142589569\n",
      "\n",
      "The classification loss after processing this batch is:  0.12631945312023163\n",
      "The representation loss after processing this batch is:  0.0027258768677711487\n",
      "\n",
      "The classification loss after processing this batch is:  0.2642684280872345\n",
      "The representation loss after processing this batch is:  0.002483125776052475\n",
      "\n",
      "The classification loss after processing this batch is:  0.2875756621360779\n",
      "The representation loss after processing this batch is:  0.003009941428899765\n",
      "\n",
      "The classification loss after processing this batch is:  0.1310901641845703\n",
      "The representation loss after processing this batch is:  0.002758532762527466\n",
      "\n",
      "The classification loss after processing this batch is:  0.2793440520763397\n",
      "The representation loss after processing this batch is:  0.003285028040409088\n",
      "\n",
      "The classification loss after processing this batch is:  0.1398705095052719\n",
      "The representation loss after processing this batch is:  0.0027597248554229736\n",
      "\n",
      "The classification loss after processing this batch is:  0.24979668855667114\n",
      "The representation loss after processing this batch is:  0.0026936307549476624\n",
      "\n",
      "The classification loss after processing this batch is:  0.0819973573088646\n",
      "The representation loss after processing this batch is:  0.0026800334453582764\n",
      "\n",
      "The classification loss after processing this batch is:  0.09841988235712051\n",
      "The representation loss after processing this batch is:  0.0027177929878234863\n",
      "\n",
      "The classification loss after processing this batch is:  0.07616504281759262\n",
      "The representation loss after processing this batch is:  0.003117486834526062\n",
      "\n",
      "The classification loss after processing this batch is:  0.06344486027956009\n",
      "The representation loss after processing this batch is:  0.002717748284339905\n",
      "\n",
      "The classification loss after processing this batch is:  0.1245817318558693\n",
      "The representation loss after processing this batch is:  0.0028252676129341125\n",
      "\n",
      "The classification loss after processing this batch is:  0.09187928587198257\n",
      "The representation loss after processing this batch is:  0.002421051263809204\n",
      "\n",
      "The classification loss after processing this batch is:  0.1508367359638214\n",
      "The representation loss after processing this batch is:  0.003192588686943054\n",
      "\n",
      "The classification loss after processing this batch is:  0.09604080766439438\n",
      "The representation loss after processing this batch is:  0.0030848458409309387\n",
      "\n",
      "The classification loss after processing this batch is:  0.10598836094141006\n",
      "The representation loss after processing this batch is:  0.002652287483215332\n",
      "\n",
      "The classification loss after processing this batch is:  0.13696925342082977\n",
      "The representation loss after processing this batch is:  0.0025952234864234924\n",
      "\n",
      "The classification loss after processing this batch is:  0.06806673854589462\n",
      "The representation loss after processing this batch is:  0.0026162415742874146\n",
      "\n",
      "The classification loss after processing this batch is:  0.1501319855451584\n",
      "The representation loss after processing this batch is:  0.0027789846062660217\n",
      "\n",
      "The classification loss after processing this batch is:  0.15413346886634827\n",
      "The representation loss after processing this batch is:  0.002766139805316925\n",
      "\n",
      "The classification loss after processing this batch is:  0.2106618583202362\n",
      "The representation loss after processing this batch is:  0.003210626542568207\n",
      "\n",
      "The classification loss after processing this batch is:  0.131434366106987\n",
      "The representation loss after processing this batch is:  0.002551853656768799\n",
      "\n",
      "The classification loss after processing this batch is:  0.09265977889299393\n",
      "The representation loss after processing this batch is:  0.0024356134235858917\n",
      "\n",
      "The classification loss after processing this batch is:  0.24150146543979645\n",
      "The representation loss after processing this batch is:  0.0030203908681869507\n",
      "\n",
      "The classification loss after processing this batch is:  0.19087691605091095\n",
      "The representation loss after processing this batch is:  0.0028701797127723694\n",
      "\n",
      "The classification loss after processing this batch is:  0.16544033586978912\n",
      "The representation loss after processing this batch is:  0.0029156282544136047\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.07277455925941467\n",
      "The representation loss after processing this batch is:  0.002728484570980072\n",
      "\n",
      "The classification loss after processing this batch is:  0.1224859282374382\n",
      "The representation loss after processing this batch is:  0.0027031973004341125\n",
      "\n",
      "The classification loss after processing this batch is:  0.13216997683048248\n",
      "The representation loss after processing this batch is:  0.0028259828686714172\n",
      "\n",
      "The classification loss after processing this batch is:  0.1755395084619522\n",
      "The representation loss after processing this batch is:  0.003300316631793976\n",
      "\n",
      "The classification loss after processing this batch is:  0.14013433456420898\n",
      "The representation loss after processing this batch is:  0.0033841952681541443\n",
      "\n",
      "The classification loss after processing this batch is:  0.1264452189207077\n",
      "The representation loss after processing this batch is:  0.003337681293487549\n",
      "\n",
      "The classification loss after processing this batch is:  0.17745700478553772\n",
      "The representation loss after processing this batch is:  0.0030424222350120544\n",
      "\n",
      "The classification loss after processing this batch is:  0.2641044557094574\n",
      "The representation loss after processing this batch is:  0.002729516476392746\n",
      "\n",
      "The classification loss after processing this batch is:  0.16775637865066528\n",
      "The representation loss after processing this batch is:  0.003602936863899231\n",
      "\n",
      "The classification loss after processing this batch is:  0.16641190648078918\n",
      "The representation loss after processing this batch is:  0.002604745328426361\n",
      "\n",
      "The classification loss after processing this batch is:  0.10023783892393112\n",
      "The representation loss after processing this batch is:  0.002579938620328903\n",
      "\n",
      "The classification loss after processing this batch is:  0.21526141464710236\n",
      "The representation loss after processing this batch is:  0.002701982855796814\n",
      "\n",
      "The classification loss after processing this batch is:  0.08048009872436523\n",
      "The representation loss after processing this batch is:  0.002737976610660553\n",
      "\n",
      "The classification loss after processing this batch is:  0.14300918579101562\n",
      "The representation loss after processing this batch is:  0.0027436167001724243\n",
      "\n",
      "The classification loss after processing this batch is:  0.11478365957736969\n",
      "The representation loss after processing this batch is:  0.0029531121253967285\n",
      "\n",
      "The classification loss after processing this batch is:  0.1200874000787735\n",
      "The representation loss after processing this batch is:  0.002637632191181183\n",
      "\n",
      "The classification loss after processing this batch is:  0.119407519698143\n",
      "The representation loss after processing this batch is:  0.002969518303871155\n",
      "\n",
      "The classification loss after processing this batch is:  0.19049091637134552\n",
      "The representation loss after processing this batch is:  0.0030373409390449524\n",
      "\n",
      "The classification loss after processing this batch is:  0.15336322784423828\n",
      "The representation loss after processing this batch is:  0.0029632896184921265\n",
      "\n",
      "The classification loss after processing this batch is:  0.17906036972999573\n",
      "The representation loss after processing this batch is:  0.00261080265045166\n",
      "\n",
      "The classification loss after processing this batch is:  0.179057776927948\n",
      "The representation loss after processing this batch is:  0.0031096413731575012\n",
      "\n",
      "The classification loss after processing this batch is:  0.15655231475830078\n",
      "The representation loss after processing this batch is:  0.002804681658744812\n",
      "\n",
      "The classification loss after processing this batch is:  0.11952982097864151\n",
      "The representation loss after processing this batch is:  0.0027648434042930603\n",
      "\n",
      "The classification loss after processing this batch is:  0.08602406829595566\n",
      "The representation loss after processing this batch is:  0.003178931772708893\n",
      "\n",
      "The classification loss after processing this batch is:  0.1059424877166748\n",
      "The representation loss after processing this batch is:  0.002923008054494858\n",
      "\n",
      "The classification loss after processing this batch is:  0.06096390262246132\n",
      "The representation loss after processing this batch is:  0.002800438553094864\n",
      "\n",
      "The classification loss after processing this batch is:  0.06552968919277191\n",
      "The representation loss after processing this batch is:  0.0026994124054908752\n",
      "\n",
      "The classification loss after processing this batch is:  0.09144347161054611\n",
      "The representation loss after processing this batch is:  0.002846747636795044\n",
      "\n",
      "The classification loss after processing this batch is:  0.0632915049791336\n",
      "The representation loss after processing this batch is:  0.003115043044090271\n",
      "\n",
      "The classification loss after processing this batch is:  0.16109517216682434\n",
      "The representation loss after processing this batch is:  0.0027372166514396667\n",
      "\n",
      "The classification loss after processing this batch is:  0.11067290604114532\n",
      "The representation loss after processing this batch is:  0.002474229782819748\n",
      "\n",
      "The classification loss after processing this batch is:  0.15711818635463715\n",
      "The representation loss after processing this batch is:  0.002796672284603119\n",
      "\n",
      "The classification loss after processing this batch is:  0.07035359740257263\n",
      "The representation loss after processing this batch is:  0.0030639171600341797\n",
      "\n",
      "The classification loss after processing this batch is:  0.1963156759738922\n",
      "The representation loss after processing this batch is:  0.00276782363653183\n",
      "\n",
      "The classification loss after processing this batch is:  0.1778755784034729\n",
      "The representation loss after processing this batch is:  0.0030221566557884216\n",
      "\n",
      "The classification loss after processing this batch is:  0.12290475517511368\n",
      "The representation loss after processing this batch is:  0.0024973824620246887\n",
      "\n",
      "The classification loss after processing this batch is:  0.16410697996616364\n",
      "The representation loss after processing this batch is:  0.0029038414359092712\n",
      "\n",
      "The classification loss after processing this batch is:  0.1485045999288559\n",
      "The representation loss after processing this batch is:  0.003086574375629425\n",
      "\n",
      "The classification loss after processing this batch is:  0.058066174387931824\n",
      "The representation loss after processing this batch is:  0.002524040639400482\n",
      "\n",
      "The classification loss after processing this batch is:  0.09021232277154922\n",
      "The representation loss after processing this batch is:  0.0025842860341072083\n",
      "\n",
      "The classification loss after processing this batch is:  0.10121824592351913\n",
      "The representation loss after processing this batch is:  0.0024925321340560913\n",
      "\n",
      "The classification loss after processing this batch is:  0.21496054530143738\n",
      "The representation loss after processing this batch is:  0.002751678228378296\n",
      "\n",
      "The classification loss after processing this batch is:  0.18202313780784607\n",
      "The representation loss after processing this batch is:  0.00257294625043869\n",
      "\n",
      "The classification loss after processing this batch is:  0.16381947696208954\n",
      "The representation loss after processing this batch is:  0.003456331789493561\n",
      "\n",
      "The classification loss after processing this batch is:  0.20760275423526764\n",
      "The representation loss after processing this batch is:  0.0027435719966888428\n",
      "\n",
      "The classification loss after processing this batch is:  0.2035483866930008\n",
      "The representation loss after processing this batch is:  0.0029174908995628357\n",
      "\n",
      "The classification loss after processing this batch is:  0.20828168094158173\n",
      "The representation loss after processing this batch is:  0.0024205446243286133\n",
      "\n",
      "The classification loss after processing this batch is:  0.3164716362953186\n",
      "The representation loss after processing this batch is:  0.002713572233915329\n",
      "\n",
      "The classification loss after processing this batch is:  0.2047581970691681\n",
      "The representation loss after processing this batch is:  0.002622108906507492\n",
      "\n",
      "The classification loss after processing this batch is:  0.14439325034618378\n",
      "The representation loss after processing this batch is:  0.0024748817086219788\n",
      "\n",
      "The classification loss after processing this batch is:  0.1083308681845665\n",
      "The representation loss after processing this batch is:  0.00292050838470459\n",
      "\n",
      "The classification loss after processing this batch is:  0.07137086987495422\n",
      "The representation loss after processing this batch is:  0.0026767179369926453\n",
      "\n",
      "The classification loss after processing this batch is:  0.06916510313749313\n",
      "The representation loss after processing this batch is:  0.002674899995326996\n",
      "\n",
      "The classification loss after processing this batch is:  0.09905090183019638\n",
      "The representation loss after processing this batch is:  0.0033768415451049805\n",
      "\n",
      "The classification loss after processing this batch is:  0.132913738489151\n",
      "The representation loss after processing this batch is:  0.0024858862161636353\n",
      "\n",
      "The classification loss after processing this batch is:  0.09178592264652252\n",
      "The representation loss after processing this batch is:  0.002851538360118866\n",
      "\n",
      "The classification loss after processing this batch is:  0.18685321509838104\n",
      "The representation loss after processing this batch is:  0.0027487315237522125\n",
      "\n",
      "The classification loss after processing this batch is:  0.18483874201774597\n",
      "The representation loss after processing this batch is:  0.00303022563457489\n",
      "\n",
      "The classification loss after processing this batch is:  0.2022353857755661\n",
      "The representation loss after processing this batch is:  0.0026241354644298553\n",
      "\n",
      "The classification loss after processing this batch is:  0.14598186314105988\n",
      "The representation loss after processing this batch is:  0.0026286765933036804\n",
      "\n",
      "The classification loss after processing this batch is:  0.21371795237064362\n",
      "The representation loss after processing this batch is:  0.00259312242269516\n",
      "\n",
      "The classification loss after processing this batch is:  0.16023746132850647\n",
      "The representation loss after processing this batch is:  0.002584211528301239\n",
      "\n",
      "The classification loss after processing this batch is:  0.09112592786550522\n",
      "The representation loss after processing this batch is:  0.002885371446609497\n",
      "\n",
      "The classification loss after processing this batch is:  0.20259150862693787\n",
      "The representation loss after processing this batch is:  0.0026649534702301025\n",
      "\n",
      "The classification loss after processing this batch is:  0.0700710341334343\n",
      "The representation loss after processing this batch is:  0.0026556774973869324\n",
      "\n",
      "The classification loss after processing this batch is:  0.0676802471280098\n",
      "The representation loss after processing this batch is:  0.0024200379848480225\n",
      "\n",
      "The classification loss after processing this batch is:  0.12403415888547897\n",
      "The representation loss after processing this batch is:  0.0030431151390075684\n",
      "\n",
      "The classification loss after processing this batch is:  0.1825980246067047\n",
      "The representation loss after processing this batch is:  0.002750575542449951\n",
      "\n",
      "The classification loss after processing this batch is:  0.14175020158290863\n",
      "The representation loss after processing this batch is:  0.0031287670135498047\n",
      "\n",
      "The classification loss after processing this batch is:  0.09078746289014816\n",
      "The representation loss after processing this batch is:  0.0030264705419540405\n",
      "\n",
      "The classification loss after processing this batch is:  0.15266695618629456\n",
      "The representation loss after processing this batch is:  0.003301069140434265\n",
      "\n",
      "The classification loss after processing this batch is:  0.09288004785776138\n",
      "The representation loss after processing this batch is:  0.0028293654322624207\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.21579374372959137\n",
      "The representation loss after processing this batch is:  0.0029291436076164246\n",
      "\n",
      "The classification loss after processing this batch is:  0.06949607282876968\n",
      "The representation loss after processing this batch is:  0.00250929594039917\n",
      "\n",
      "The classification loss after processing this batch is:  0.0700053721666336\n",
      "The representation loss after processing this batch is:  0.002907894551753998\n",
      "\n",
      "The classification loss after processing this batch is:  0.14182059466838837\n",
      "The representation loss after processing this batch is:  0.0035403668880462646\n",
      "\n",
      "The classification loss after processing this batch is:  0.12922443449497223\n",
      "The representation loss after processing this batch is:  0.0030432119965553284\n",
      "\n",
      "The classification loss after processing this batch is:  0.129673570394516\n",
      "The representation loss after processing this batch is:  0.0033340901136398315\n",
      "\n",
      "The classification loss after processing this batch is:  0.09257517009973526\n",
      "The representation loss after processing this batch is:  0.0028045065701007843\n",
      "\n",
      "The classification loss after processing this batch is:  0.16292470693588257\n",
      "The representation loss after processing this batch is:  0.0031324848532676697\n",
      "\n",
      "The classification loss after processing this batch is:  0.2056480348110199\n",
      "The representation loss after processing this batch is:  0.0030555352568626404\n",
      "\n",
      "The classification loss after processing this batch is:  0.2106618881225586\n",
      "The representation loss after processing this batch is:  0.0028180480003356934\n",
      "\n",
      "The classification loss after processing this batch is:  0.1670275181531906\n",
      "The representation loss after processing this batch is:  0.0031882449984550476\n",
      "\n",
      "The classification loss after processing this batch is:  0.0769481509923935\n",
      "The representation loss after processing this batch is:  0.002740032970905304\n",
      "\n",
      "The classification loss after processing this batch is:  0.08192510902881622\n",
      "The representation loss after processing this batch is:  0.002396807074546814\n",
      "\n",
      "The classification loss after processing this batch is:  0.20412574708461761\n",
      "The representation loss after processing this batch is:  0.003275081515312195\n",
      "\n",
      "The classification loss after processing this batch is:  0.2719942629337311\n",
      "The representation loss after processing this batch is:  0.0034139007329940796\n",
      "\n",
      "The classification loss after processing this batch is:  0.2535099685192108\n",
      "The representation loss after processing this batch is:  0.003300156444311142\n",
      "\n",
      "The classification loss after processing this batch is:  0.25875338912010193\n",
      "The representation loss after processing this batch is:  0.002921637147665024\n",
      "\n",
      "The classification loss after processing this batch is:  0.10899202525615692\n",
      "The representation loss after processing this batch is:  0.002657342702150345\n",
      "\n",
      "The classification loss after processing this batch is:  0.20485152304172516\n",
      "The representation loss after processing this batch is:  0.0025888830423355103\n",
      "\n",
      "The classification loss after processing this batch is:  0.13492828607559204\n",
      "The representation loss after processing this batch is:  0.002708122134208679\n",
      "\n",
      "The classification loss after processing this batch is:  0.14971263706684113\n",
      "The representation loss after processing this batch is:  0.0026387423276901245\n",
      "\n",
      "The classification loss after processing this batch is:  0.101397804915905\n",
      "The representation loss after processing this batch is:  0.0025995373725891113\n",
      "\n",
      "The classification loss after processing this batch is:  0.17219600081443787\n",
      "The representation loss after processing this batch is:  0.002672359347343445\n",
      "\n",
      "The classification loss after processing this batch is:  0.14107193052768707\n",
      "The representation loss after processing this batch is:  0.0027994737029075623\n",
      "\n",
      "The classification loss after processing this batch is:  0.1623965948820114\n",
      "The representation loss after processing this batch is:  0.0024803727865219116\n",
      "\n",
      "The classification loss after processing this batch is:  0.16518154740333557\n",
      "The representation loss after processing this batch is:  0.0026087388396263123\n",
      "\n",
      "The classification loss after processing this batch is:  0.07179322093725204\n",
      "The representation loss after processing this batch is:  0.002883724868297577\n",
      "\n",
      "The classification loss after processing this batch is:  0.11159076541662216\n",
      "The representation loss after processing this batch is:  0.0028462782502174377\n",
      "\n",
      "The classification loss after processing this batch is:  0.15721745789051056\n",
      "The representation loss after processing this batch is:  0.0027965977787971497\n",
      "\n",
      "The classification loss after processing this batch is:  0.1260162591934204\n",
      "The representation loss after processing this batch is:  0.002883628010749817\n",
      "\n",
      "The classification loss after processing this batch is:  0.08027349412441254\n",
      "The representation loss after processing this batch is:  0.003259517252445221\n",
      "\n",
      "The classification loss after processing this batch is:  0.0940985456109047\n",
      "The representation loss after processing this batch is:  0.002427447587251663\n",
      "\n",
      "The classification loss after processing this batch is:  0.21883524954319\n",
      "The representation loss after processing this batch is:  0.003241419792175293\n",
      "\n",
      "The classification loss after processing this batch is:  0.17846135795116425\n",
      "The representation loss after processing this batch is:  0.002710968255996704\n",
      "\n",
      "The classification loss after processing this batch is:  0.15289367735385895\n",
      "The representation loss after processing this batch is:  0.0025186538696289062\n",
      "\n",
      "The classification loss after processing this batch is:  0.11744177341461182\n",
      "The representation loss after processing this batch is:  0.0025024190545082092\n",
      "\n",
      "The classification loss after processing this batch is:  0.1018264964222908\n",
      "The representation loss after processing this batch is:  0.0027126744389533997\n",
      "\n",
      "The classification loss after processing this batch is:  0.08947906643152237\n",
      "The representation loss after processing this batch is:  0.0025742724537849426\n",
      "\n",
      "The classification loss after processing this batch is:  0.12165490537881851\n",
      "The representation loss after processing this batch is:  0.002720378339290619\n",
      "\n",
      "The classification loss after processing this batch is:  0.16512556374073029\n",
      "The representation loss after processing this batch is:  0.002872839570045471\n",
      "\n",
      "The classification loss after processing this batch is:  0.16839991509914398\n",
      "The representation loss after processing this batch is:  0.0032267048954963684\n",
      "\n",
      "The classification loss after processing this batch is:  0.0980849638581276\n",
      "The representation loss after processing this batch is:  0.002993285655975342\n",
      "\n",
      "The classification loss after processing this batch is:  0.18365360796451569\n",
      "The representation loss after processing this batch is:  0.002568434923887253\n",
      "\n",
      "The classification loss after processing this batch is:  0.21237708628177643\n",
      "The representation loss after processing this batch is:  0.0026124045252799988\n",
      "\n",
      "The classification loss after processing this batch is:  0.06049756705760956\n",
      "The representation loss after processing this batch is:  0.0026511400938034058\n",
      "\n",
      "The classification loss after processing this batch is:  0.08953903615474701\n",
      "The representation loss after processing this batch is:  0.0024889223277568817\n",
      "\n",
      "The classification loss after processing this batch is:  0.18512369692325592\n",
      "The representation loss after processing this batch is:  0.0026379451155662537\n",
      "\n",
      "The classification loss after processing this batch is:  0.1634218841791153\n",
      "The representation loss after processing this batch is:  0.0028601735830307007\n",
      "\n",
      "The classification loss after processing this batch is:  0.1095331460237503\n",
      "The representation loss after processing this batch is:  0.0028967075049877167\n",
      "\n",
      "The classification loss after processing this batch is:  0.2664293944835663\n",
      "The representation loss after processing this batch is:  0.0027634352445602417\n",
      "\n",
      "The classification loss after processing this batch is:  0.17125587165355682\n",
      "The representation loss after processing this batch is:  0.003100752830505371\n",
      "\n",
      "The classification loss after processing this batch is:  0.2277287393808365\n",
      "The representation loss after processing this batch is:  0.0029639676213264465\n",
      "\n",
      "The classification loss after processing this batch is:  0.14484268426895142\n",
      "The representation loss after processing this batch is:  0.0031054839491844177\n",
      "\n",
      "The classification loss after processing this batch is:  0.1812952607870102\n",
      "The representation loss after processing this batch is:  0.0024386942386627197\n",
      "\n",
      "The classification loss after processing this batch is:  0.1170029416680336\n",
      "The representation loss after processing this batch is:  0.003843165934085846\n",
      "\n",
      "The classification loss after processing this batch is:  0.11179157346487045\n",
      "The representation loss after processing this batch is:  0.0027764663100242615\n",
      "\n",
      "The classification loss after processing this batch is:  0.13739344477653503\n",
      "The representation loss after processing this batch is:  0.0027389898896217346\n",
      "\n",
      "The classification loss after processing this batch is:  0.1389264166355133\n",
      "The representation loss after processing this batch is:  0.0023808106780052185\n",
      "\n",
      "The classification loss after processing this batch is:  0.13322189450263977\n",
      "The representation loss after processing this batch is:  0.002607986330986023\n",
      "\n",
      "The classification loss after processing this batch is:  0.12185702472925186\n",
      "The representation loss after processing this batch is:  0.002610631287097931\n",
      "\n",
      "The classification loss after processing this batch is:  0.19488376379013062\n",
      "The representation loss after processing this batch is:  0.0027171187102794647\n",
      "\n",
      "The classification loss after processing this batch is:  0.09657725691795349\n",
      "The representation loss after processing this batch is:  0.0031952038407325745\n",
      "\n",
      "The classification loss after processing this batch is:  0.08762647956609726\n",
      "The representation loss after processing this batch is:  0.003072485327720642\n",
      "\n",
      "The classification loss after processing this batch is:  0.16274617612361908\n",
      "The representation loss after processing this batch is:  0.0031758397817611694\n",
      "\n",
      "The classification loss after processing this batch is:  0.08183503895998001\n",
      "The representation loss after processing this batch is:  0.002739734947681427\n",
      "\n",
      "The classification loss after processing this batch is:  0.10809405148029327\n",
      "The representation loss after processing this batch is:  0.0028103068470954895\n",
      "\n",
      "The classification loss after processing this batch is:  0.06837160140275955\n",
      "The representation loss after processing this batch is:  0.002956278622150421\n",
      "\n",
      "The classification loss after processing this batch is:  0.11091320961713791\n",
      "The representation loss after processing this batch is:  0.0024600476026535034\n",
      "\n",
      "The classification loss after processing this batch is:  0.19730070233345032\n",
      "The representation loss after processing this batch is:  0.0030487626791000366\n",
      "\n",
      "The classification loss after processing this batch is:  0.19960464537143707\n",
      "The representation loss after processing this batch is:  0.0040114447474479675\n",
      "\n",
      "The classification loss after processing this batch is:  0.1505058854818344\n",
      "The representation loss after processing this batch is:  0.0032302066683769226\n",
      "\n",
      "The classification loss after processing this batch is:  0.13424839079380035\n",
      "The representation loss after processing this batch is:  0.003045126795768738\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.12821397185325623\n",
      "The representation loss after processing this batch is:  0.0028632022440433502\n",
      "\n",
      "The classification loss after processing this batch is:  0.1305994689464569\n",
      "The representation loss after processing this batch is:  0.0025850310921669006\n",
      "\n",
      "The classification loss after processing this batch is:  0.08565027266740799\n",
      "The representation loss after processing this batch is:  0.002876885235309601\n",
      "\n",
      "The classification loss after processing this batch is:  0.08288772404193878\n",
      "The representation loss after processing this batch is:  0.002909712493419647\n",
      "\n",
      "The classification loss after processing this batch is:  0.0824819952249527\n",
      "The representation loss after processing this batch is:  0.002727501094341278\n",
      "\n",
      "The classification loss after processing this batch is:  0.19808731973171234\n",
      "The representation loss after processing this batch is:  0.0032950565218925476\n",
      "\n",
      "The classification loss after processing this batch is:  0.19061504304409027\n",
      "The representation loss after processing this batch is:  0.0030082128942012787\n",
      "\n",
      "The classification loss after processing this batch is:  0.1702824980020523\n",
      "The representation loss after processing this batch is:  0.002691499888896942\n",
      "\n",
      "The classification loss after processing this batch is:  0.1416013389825821\n",
      "The representation loss after processing this batch is:  0.00365544855594635\n",
      "\n",
      "The classification loss after processing this batch is:  0.13514505326747894\n",
      "The representation loss after processing this batch is:  0.003088250756263733\n",
      "\n",
      "The classification loss after processing this batch is:  0.17053104937076569\n",
      "The representation loss after processing this batch is:  0.0030337944626808167\n",
      "\n",
      "The classification loss after processing this batch is:  0.11858198046684265\n",
      "The representation loss after processing this batch is:  0.0028523728251457214\n",
      "\n",
      "The classification loss after processing this batch is:  0.3126642405986786\n",
      "The representation loss after processing this batch is:  0.00338570773601532\n",
      "\n",
      "The classification loss after processing this batch is:  0.17716620862483978\n",
      "The representation loss after processing this batch is:  0.0029667317867279053\n",
      "\n",
      "The classification loss after processing this batch is:  0.22774924337863922\n",
      "The representation loss after processing this batch is:  0.0032976195216178894\n",
      "\n",
      "The classification loss after processing this batch is:  0.10313843935728073\n",
      "The representation loss after processing this batch is:  0.002663522958755493\n",
      "\n",
      "The classification loss after processing this batch is:  0.08843490481376648\n",
      "The representation loss after processing this batch is:  0.0027788877487182617\n",
      "\n",
      "The classification loss after processing this batch is:  0.19235387444496155\n",
      "The representation loss after processing this batch is:  0.0025429874658584595\n",
      "\n",
      "The classification loss after processing this batch is:  0.14967212080955505\n",
      "The representation loss after processing this batch is:  0.002916477620601654\n",
      "\n",
      "The classification loss after processing this batch is:  0.27844080328941345\n",
      "The representation loss after processing this batch is:  0.0026017501950263977\n",
      "\n",
      "The classification loss after processing this batch is:  0.22663767635822296\n",
      "The representation loss after processing this batch is:  0.0034076571464538574\n",
      "\n",
      "The classification loss after processing this batch is:  0.18521295487880707\n",
      "The representation loss after processing this batch is:  0.0033331289887428284\n",
      "\n",
      "The classification loss after processing this batch is:  0.1402132362127304\n",
      "The representation loss after processing this batch is:  0.002779170870780945\n",
      "\n",
      "The classification loss after processing this batch is:  0.0668306052684784\n",
      "The representation loss after processing this batch is:  0.002776317298412323\n",
      "\n",
      "The classification loss after processing this batch is:  0.11950384825468063\n",
      "The representation loss after processing this batch is:  0.0024707764387130737\n",
      "\n",
      "The classification loss after processing this batch is:  0.12449391931295395\n",
      "The representation loss after processing this batch is:  0.002667739987373352\n",
      "\n",
      "The classification loss after processing this batch is:  0.09313178807497025\n",
      "The representation loss after processing this batch is:  0.0028979480266571045\n",
      "\n",
      "The classification loss after processing this batch is:  0.13629528880119324\n",
      "The representation loss after processing this batch is:  0.002559676766395569\n",
      "\n",
      "The classification loss after processing this batch is:  0.22331543266773224\n",
      "The representation loss after processing this batch is:  0.002836063504219055\n",
      "\n",
      "The classification loss after processing this batch is:  0.16846726834774017\n",
      "The representation loss after processing this batch is:  0.002439446747303009\n",
      "\n",
      "The classification loss after processing this batch is:  0.12278057634830475\n",
      "The representation loss after processing this batch is:  0.0028856396675109863\n",
      "\n",
      "The classification loss after processing this batch is:  0.11996118724346161\n",
      "The representation loss after processing this batch is:  0.0027629435062408447\n",
      "\n",
      "The classification loss after processing this batch is:  0.0906679779291153\n",
      "The representation loss after processing this batch is:  0.003081299364566803\n",
      "\n",
      "The classification loss after processing this batch is:  0.12944085896015167\n",
      "The representation loss after processing this batch is:  0.0033096224069595337\n",
      "\n",
      "The classification loss after processing this batch is:  0.0705856904387474\n",
      "The representation loss after processing this batch is:  0.0032505393028259277\n",
      "\n",
      "The classification loss after processing this batch is:  0.165877103805542\n",
      "The representation loss after processing this batch is:  0.0025187060236930847\n",
      "\n",
      "The classification loss after processing this batch is:  0.16547097265720367\n",
      "The representation loss after processing this batch is:  0.0028763562440872192\n",
      "\n",
      "The classification loss after processing this batch is:  0.07277549058198929\n",
      "The representation loss after processing this batch is:  0.00279245525598526\n",
      "\n",
      "The classification loss after processing this batch is:  0.22462306916713715\n",
      "The representation loss after processing this batch is:  0.0025084540247917175\n",
      "\n",
      "The classification loss after processing this batch is:  0.13402202725410461\n",
      "The representation loss after processing this batch is:  0.002715460956096649\n",
      "\n",
      "The classification loss after processing this batch is:  0.1007760763168335\n",
      "The representation loss after processing this batch is:  0.0028553009033203125\n",
      "\n",
      "The classification loss after processing this batch is:  0.08885116875171661\n",
      "The representation loss after processing this batch is:  0.003039039671421051\n",
      "\n",
      "The classification loss after processing this batch is:  0.1037764698266983\n",
      "The representation loss after processing this batch is:  0.002943001687526703\n",
      "\n",
      "The classification loss after processing this batch is:  0.08461198955774307\n",
      "The representation loss after processing this batch is:  0.0026379525661468506\n",
      "\n",
      "The classification loss after processing this batch is:  0.41363850235939026\n",
      "The representation loss after processing this batch is:  0.002584170550107956\n",
      "\n",
      "The classification loss after processing this batch is:  0.1511356383562088\n",
      "The representation loss after processing this batch is:  0.0030263811349868774\n",
      "\n",
      "The classification loss after processing this batch is:  0.1938079297542572\n",
      "The representation loss after processing this batch is:  0.0026702582836151123\n",
      "\n",
      "The classification loss after processing this batch is:  0.12005913257598877\n",
      "The representation loss after processing this batch is:  0.0025571398437023163\n",
      "\n",
      "The classification loss after processing this batch is:  0.15227890014648438\n",
      "The representation loss after processing this batch is:  0.0029917247593402863\n",
      "\n",
      "The classification loss after processing this batch is:  0.08710992336273193\n",
      "The representation loss after processing this batch is:  0.002617020159959793\n",
      "\n",
      "The classification loss after processing this batch is:  0.09943888336420059\n",
      "The representation loss after processing this batch is:  0.0028356164693832397\n",
      "\n",
      "The classification loss after processing this batch is:  0.20351570844650269\n",
      "The representation loss after processing this batch is:  0.002927333116531372\n",
      "\n",
      "The classification loss after processing this batch is:  0.1436934620141983\n",
      "The representation loss after processing this batch is:  0.003588549792766571\n",
      "\n",
      "The classification loss after processing this batch is:  0.1777089685201645\n",
      "The representation loss after processing this batch is:  0.0031504854559898376\n",
      "\n",
      "The classification loss after processing this batch is:  0.12135563790798187\n",
      "The representation loss after processing this batch is:  0.0025382861495018005\n",
      "\n",
      "The classification loss after processing this batch is:  0.23278382420539856\n",
      "The representation loss after processing this batch is:  0.002891652286052704\n",
      "\n",
      "The classification loss after processing this batch is:  0.15143033862113953\n",
      "The representation loss after processing this batch is:  0.002872936427593231\n",
      "\n",
      "The classification loss after processing this batch is:  0.22003039717674255\n",
      "The representation loss after processing this batch is:  0.0027847886085510254\n",
      "\n",
      "The classification loss after processing this batch is:  0.13949230313301086\n",
      "The representation loss after processing this batch is:  0.0028762072324752808\n",
      "\n",
      "The classification loss after processing this batch is:  0.11740176379680634\n",
      "The representation loss after processing this batch is:  0.0031396150588989258\n",
      "\n",
      "The classification loss after processing this batch is:  0.06414677947759628\n",
      "The representation loss after processing this batch is:  0.0027909204363822937\n",
      "\n",
      "The classification loss after processing this batch is:  0.22103649377822876\n",
      "The representation loss after processing this batch is:  0.002705860882997513\n",
      "\n",
      "The classification loss after processing this batch is:  0.3020816147327423\n",
      "The representation loss after processing this batch is:  0.0030359886586666107\n",
      "\n",
      "The classification loss after processing this batch is:  0.13057062029838562\n",
      "The representation loss after processing this batch is:  0.0028622448444366455\n",
      "\n",
      "The classification loss after processing this batch is:  0.23460134863853455\n",
      "The representation loss after processing this batch is:  0.003316551446914673\n",
      "\n",
      "The classification loss after processing this batch is:  0.19972677528858185\n",
      "The representation loss after processing this batch is:  0.002938695251941681\n",
      "\n",
      "The classification loss after processing this batch is:  0.1932191550731659\n",
      "The representation loss after processing this batch is:  0.0029429681599140167\n",
      "\n",
      "The classification loss after processing this batch is:  0.09370293468236923\n",
      "The representation loss after processing this batch is:  0.0027273334562778473\n",
      "\n",
      "The classification loss after processing this batch is:  0.16451337933540344\n",
      "The representation loss after processing this batch is:  0.0028294026851654053\n",
      "\n",
      "The classification loss after processing this batch is:  0.17633086442947388\n",
      "The representation loss after processing this batch is:  0.003000512719154358\n",
      "\n",
      "The classification loss after processing this batch is:  0.15007881820201874\n",
      "The representation loss after processing this batch is:  0.0030301064252853394\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.05333553999662399\n",
      "The representation loss after processing this batch is:  0.002993859350681305\n",
      "\n",
      "The classification loss after processing this batch is:  0.09889722615480423\n",
      "The representation loss after processing this batch is:  0.003169037401676178\n",
      "\n",
      "The classification loss after processing this batch is:  0.10712536424398422\n",
      "The representation loss after processing this batch is:  0.002984151244163513\n",
      "\n",
      "The classification loss after processing this batch is:  0.14516466856002808\n",
      "The representation loss after processing this batch is:  0.0024733766913414\n",
      "\n",
      "The classification loss after processing this batch is:  0.21520455181598663\n",
      "The representation loss after processing this batch is:  0.0027011334896087646\n",
      "\n",
      "The classification loss after processing this batch is:  0.12459740787744522\n",
      "The representation loss after processing this batch is:  0.0024954117834568024\n",
      "\n",
      "The classification loss after processing this batch is:  0.15866708755493164\n",
      "The representation loss after processing this batch is:  0.0034303516149520874\n",
      "\n",
      "The classification loss after processing this batch is:  0.1834903359413147\n",
      "The representation loss after processing this batch is:  0.0029829218983650208\n",
      "\n",
      "The classification loss after processing this batch is:  0.13761617243289948\n",
      "The representation loss after processing this batch is:  0.003593921661376953\n",
      "\n",
      "The classification loss after processing this batch is:  0.09867643564939499\n",
      "The representation loss after processing this batch is:  0.0027555227279663086\n",
      "\n",
      "The classification loss after processing this batch is:  0.21415087580680847\n",
      "The representation loss after processing this batch is:  0.002834528684616089\n",
      "\n",
      "The classification loss after processing this batch is:  0.1855524629354477\n",
      "The representation loss after processing this batch is:  0.0030815601348876953\n",
      "\n",
      "The classification loss after processing this batch is:  0.1487920582294464\n",
      "The representation loss after processing this batch is:  0.0031379759311676025\n",
      "\n",
      "The classification loss after processing this batch is:  0.11304037272930145\n",
      "The representation loss after processing this batch is:  0.0026084743440151215\n",
      "\n",
      "The classification loss after processing this batch is:  0.11493796855211258\n",
      "The representation loss after processing this batch is:  0.0025400444865226746\n",
      "\n",
      "The classification loss after processing this batch is:  0.11321236193180084\n",
      "The representation loss after processing this batch is:  0.002981327474117279\n",
      "\n",
      "The classification loss after processing this batch is:  0.1289213001728058\n",
      "The representation loss after processing this batch is:  0.002697724848985672\n",
      "\n",
      "The classification loss after processing this batch is:  0.22988292574882507\n",
      "The representation loss after processing this batch is:  0.0029188692569732666\n",
      "\n",
      "The classification loss after processing this batch is:  0.26070496439933777\n",
      "The representation loss after processing this batch is:  0.0028849467635154724\n",
      "\n",
      "The classification loss after processing this batch is:  0.1395547240972519\n",
      "The representation loss after processing this batch is:  0.00254923477768898\n",
      "\n",
      "The classification loss after processing this batch is:  0.15408402681350708\n",
      "The representation loss after processing this batch is:  0.002824634313583374\n",
      "\n",
      "The classification loss after processing this batch is:  0.1452663540840149\n",
      "The representation loss after processing this batch is:  0.0025995969772338867\n",
      "\n",
      "The classification loss after processing this batch is:  0.16865210235118866\n",
      "The representation loss after processing this batch is:  0.0027352869510650635\n",
      "\n",
      "The classification loss after processing this batch is:  0.20288197696208954\n",
      "The representation loss after processing this batch is:  0.0029376521706581116\n",
      "\n",
      "The classification loss after processing this batch is:  0.15264813601970673\n",
      "The representation loss after processing this batch is:  0.0026033371686935425\n",
      "\n",
      "The classification loss after processing this batch is:  0.30363211035728455\n",
      "The representation loss after processing this batch is:  0.0027483031153678894\n",
      "\n",
      "The classification loss after processing this batch is:  0.19168305397033691\n",
      "The representation loss after processing this batch is:  0.002602718770503998\n",
      "\n",
      "The classification loss after processing this batch is:  0.07573473453521729\n",
      "The representation loss after processing this batch is:  0.0036927834153175354\n",
      "\n",
      "The classification loss after processing this batch is:  0.1503402441740036\n",
      "The representation loss after processing this batch is:  0.0030089914798736572\n",
      "\n",
      "The classification loss after processing this batch is:  0.10662296414375305\n",
      "The representation loss after processing this batch is:  0.0029254257678985596\n",
      "\n",
      "The classification loss after processing this batch is:  0.179439514875412\n",
      "The representation loss after processing this batch is:  0.002993471920490265\n",
      "\n",
      "The classification loss after processing this batch is:  0.15426109731197357\n",
      "The representation loss after processing this batch is:  0.002661377191543579\n",
      "\n",
      "The classification loss after processing this batch is:  0.1553230583667755\n",
      "The representation loss after processing this batch is:  0.0028625428676605225\n",
      "\n",
      "The classification loss after processing this batch is:  0.13057023286819458\n",
      "The representation loss after processing this batch is:  0.002859927713871002\n",
      "\n",
      "The classification loss after processing this batch is:  0.1772390902042389\n",
      "The representation loss after processing this batch is:  0.0027354173362255096\n",
      "\n",
      "The classification loss after processing this batch is:  0.2310229390859604\n",
      "The representation loss after processing this batch is:  0.0026109889149665833\n",
      "\n",
      "The classification loss after processing this batch is:  0.23844702541828156\n",
      "The representation loss after processing this batch is:  0.0027514025568962097\n",
      "\n",
      "The classification loss after processing this batch is:  0.16323964297771454\n",
      "The representation loss after processing this batch is:  0.002642400562763214\n",
      "\n",
      "The classification loss after processing this batch is:  0.06342955678701401\n",
      "The representation loss after processing this batch is:  0.0031918957829475403\n",
      "\n",
      "The classification loss after processing this batch is:  0.040836405009031296\n",
      "The representation loss after processing this batch is:  0.0028306394815444946\n",
      "\n",
      "The classification loss after processing this batch is:  0.16620272397994995\n",
      "The representation loss after processing this batch is:  0.0031706318259239197\n",
      "\n",
      "The classification loss after processing this batch is:  0.09008926898241043\n",
      "The representation loss after processing this batch is:  0.004032641649246216\n",
      "\n",
      "The classification loss after processing this batch is:  0.18162217736244202\n",
      "The representation loss after processing this batch is:  0.00282365083694458\n",
      "\n",
      "The classification loss after processing this batch is:  0.1264393925666809\n",
      "The representation loss after processing this batch is:  0.003133326768875122\n",
      "\n",
      "The classification loss after processing this batch is:  0.20895101130008698\n",
      "The representation loss after processing this batch is:  0.0026722028851509094\n",
      "\n",
      "The classification loss after processing this batch is:  0.06227301061153412\n",
      "The representation loss after processing this batch is:  0.0029491782188415527\n",
      "\n",
      "The classification loss after processing this batch is:  0.16235531866550446\n",
      "The representation loss after processing this batch is:  0.0028598904609680176\n",
      "\n",
      "The classification loss after processing this batch is:  0.16743209958076477\n",
      "The representation loss after processing this batch is:  0.003143526613712311\n",
      "\n",
      "The classification loss after processing this batch is:  0.20122076570987701\n",
      "The representation loss after processing this batch is:  0.0030757933855056763\n",
      "\n",
      "The classification loss after processing this batch is:  0.13220147788524628\n",
      "The representation loss after processing this batch is:  0.003161124885082245\n",
      "\n",
      "The classification loss after processing this batch is:  0.08270806819200516\n",
      "The representation loss after processing this batch is:  0.00264919176697731\n",
      "\n",
      "The classification loss after processing this batch is:  0.13017906248569489\n",
      "The representation loss after processing this batch is:  0.003147698938846588\n",
      "\n",
      "The classification loss after processing this batch is:  0.13119126856327057\n",
      "The representation loss after processing this batch is:  0.002638503909111023\n",
      "\n",
      "The classification loss after processing this batch is:  0.1379782259464264\n",
      "The representation loss after processing this batch is:  0.0028004348278045654\n",
      "\n",
      "The classification loss after processing this batch is:  0.14096151292324066\n",
      "The representation loss after processing this batch is:  0.002688974142074585\n",
      "\n",
      "The classification loss after processing this batch is:  0.10112147778272629\n",
      "The representation loss after processing this batch is:  0.002737671136856079\n",
      "\n",
      "The classification loss after processing this batch is:  0.052084676921367645\n",
      "The representation loss after processing this batch is:  0.0026718974113464355\n",
      "\n",
      "The classification loss after processing this batch is:  0.09981154650449753\n",
      "The representation loss after processing this batch is:  0.0030778199434280396\n",
      "\n",
      "The classification loss after processing this batch is:  0.06047069653868675\n",
      "The representation loss after processing this batch is:  0.0031300559639930725\n",
      "\n",
      "The classification loss after processing this batch is:  0.1344473510980606\n",
      "The representation loss after processing this batch is:  0.002795666456222534\n",
      "\n",
      "The classification loss after processing this batch is:  0.09788694977760315\n",
      "The representation loss after processing this batch is:  0.0026596039533615112\n",
      "\n",
      "The classification loss after processing this batch is:  0.07902166247367859\n",
      "The representation loss after processing this batch is:  0.0025671496987342834\n",
      "\n",
      "The classification loss after processing this batch is:  0.11842992156744003\n",
      "The representation loss after processing this batch is:  0.0032146871089935303\n",
      "\n",
      "The classification loss after processing this batch is:  0.10626072436571121\n",
      "The representation loss after processing this batch is:  0.002939775586128235\n",
      "\n",
      "The classification loss after processing this batch is:  0.06815275549888611\n",
      "The representation loss after processing this batch is:  0.002973906695842743\n",
      "\n",
      "The classification loss after processing this batch is:  0.11005380004644394\n",
      "The representation loss after processing this batch is:  0.002810858190059662\n",
      "\n",
      "The classification loss after processing this batch is:  0.07813772559165955\n",
      "The representation loss after processing this batch is:  0.0027246102690696716\n",
      "\n",
      "The classification loss after processing this batch is:  0.06268845498561859\n",
      "The representation loss after processing this batch is:  0.002848520874977112\n",
      "\n",
      "The classification loss after processing this batch is:  0.139092355966568\n",
      "The representation loss after processing this batch is:  0.0028970763087272644\n",
      "\n",
      "The classification loss after processing this batch is:  0.15527722239494324\n",
      "The representation loss after processing this batch is:  0.002971336245536804\n",
      "\n",
      "The classification loss after processing this batch is:  0.07537414878606796\n",
      "The representation loss after processing this batch is:  0.003097221255302429\n",
      "\n",
      "The classification loss after processing this batch is:  0.2194146364927292\n",
      "The representation loss after processing this batch is:  0.0030674561858177185\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.088913194835186\n",
      "The representation loss after processing this batch is:  0.002694346010684967\n",
      "\n",
      "The classification loss after processing this batch is:  0.14874926209449768\n",
      "The representation loss after processing this batch is:  0.0026972591876983643\n",
      "\n",
      "The classification loss after processing this batch is:  0.15925131738185883\n",
      "The representation loss after processing this batch is:  0.00325620174407959\n",
      "\n",
      "The classification loss after processing this batch is:  0.08595962077379227\n",
      "The representation loss after processing this batch is:  0.0032826438546180725\n",
      "\n",
      "The classification loss after processing this batch is:  0.2064528465270996\n",
      "The representation loss after processing this batch is:  0.002745814621448517\n",
      "\n",
      "The classification loss after processing this batch is:  0.18656475841999054\n",
      "The representation loss after processing this batch is:  0.0024246945977211\n",
      "\n",
      "The classification loss after processing this batch is:  0.16398032009601593\n",
      "The representation loss after processing this batch is:  0.0027326643466949463\n",
      "\n",
      "The classification loss after processing this batch is:  0.1610288769006729\n",
      "The representation loss after processing this batch is:  0.0027180016040802\n",
      "\n",
      "The classification loss after processing this batch is:  0.09812398999929428\n",
      "The representation loss after processing this batch is:  0.0029936283826828003\n",
      "\n",
      "The classification loss after processing this batch is:  0.12371540814638138\n",
      "The representation loss after processing this batch is:  0.0024003125727176666\n",
      "\n",
      "The classification loss after processing this batch is:  0.1315796971321106\n",
      "The representation loss after processing this batch is:  0.0029110610485076904\n",
      "\n",
      "The classification loss after processing this batch is:  0.19541557133197784\n",
      "The representation loss after processing this batch is:  0.0026566386222839355\n",
      "\n",
      "The classification loss after processing this batch is:  0.19076785445213318\n",
      "The representation loss after processing this batch is:  0.0026930198073387146\n",
      "\n",
      "The classification loss after processing this batch is:  0.07706121355295181\n",
      "The representation loss after processing this batch is:  0.002498932182788849\n",
      "\n",
      "The classification loss after processing this batch is:  0.09650757908821106\n",
      "The representation loss after processing this batch is:  0.002769090235233307\n",
      "\n",
      "The classification loss after processing this batch is:  0.20479191839694977\n",
      "The representation loss after processing this batch is:  0.0023041963577270508\n",
      "\n",
      "The classification loss after processing this batch is:  0.09569497406482697\n",
      "The representation loss after processing this batch is:  0.002702973783016205\n",
      "\n",
      "The classification loss after processing this batch is:  0.15295034646987915\n",
      "The representation loss after processing this batch is:  0.0027832314372062683\n",
      "\n",
      "The classification loss after processing this batch is:  0.16457252204418182\n",
      "The representation loss after processing this batch is:  0.0026749446988105774\n",
      "\n",
      "The classification loss after processing this batch is:  0.0858461782336235\n",
      "The representation loss after processing this batch is:  0.0031579360365867615\n",
      "\n",
      "The classification loss after processing this batch is:  0.07700446993112564\n",
      "The representation loss after processing this batch is:  0.0027345046401023865\n",
      "\n",
      "The classification loss after processing this batch is:  0.14879758656024933\n",
      "The representation loss after processing this batch is:  0.0028564482927322388\n",
      "\n",
      "The classification loss after processing this batch is:  0.15062594413757324\n",
      "The representation loss after processing this batch is:  0.002677474170923233\n",
      "\n",
      "The classification loss after processing this batch is:  0.15870258212089539\n",
      "The representation loss after processing this batch is:  0.0028688758611679077\n",
      "\n",
      "The classification loss after processing this batch is:  0.2139127105474472\n",
      "The representation loss after processing this batch is:  0.0034354478120803833\n",
      "\n",
      "The classification loss after processing this batch is:  0.12279012799263\n",
      "The representation loss after processing this batch is:  0.0026786327362060547\n",
      "\n",
      "The classification loss after processing this batch is:  0.1774953156709671\n",
      "The representation loss after processing this batch is:  0.002248186618089676\n",
      "\n",
      "The classification loss after processing this batch is:  0.14357583224773407\n",
      "The representation loss after processing this batch is:  0.0030346885323524475\n",
      "\n",
      "The classification loss after processing this batch is:  0.06305892765522003\n",
      "The representation loss after processing this batch is:  0.0029989629983901978\n",
      "\n",
      "The classification loss after processing this batch is:  0.08903729915618896\n",
      "The representation loss after processing this batch is:  0.0027090050280094147\n",
      "\n",
      "The classification loss after processing this batch is:  0.109432652592659\n",
      "The representation loss after processing this batch is:  0.0027379021048545837\n",
      "\n",
      "The classification loss after processing this batch is:  0.12166940420866013\n",
      "The representation loss after processing this batch is:  0.0030164867639541626\n",
      "\n",
      "The classification loss after processing this batch is:  0.11123035848140717\n",
      "The representation loss after processing this batch is:  0.0028764009475708008\n",
      "\n",
      "The classification loss after processing this batch is:  0.13883759081363678\n",
      "The representation loss after processing this batch is:  0.0031731948256492615\n",
      "\n",
      "The classification loss after processing this batch is:  0.1559501588344574\n",
      "The representation loss after processing this batch is:  0.0031552836298942566\n",
      "\n",
      "The classification loss after processing this batch is:  0.10422896593809128\n",
      "The representation loss after processing this batch is:  0.0031578615307807922\n",
      "\n",
      "The classification loss after processing this batch is:  0.18607330322265625\n",
      "The representation loss after processing this batch is:  0.0029403045773506165\n",
      "\n",
      "The classification loss after processing this batch is:  0.18277399241924286\n",
      "The representation loss after processing this batch is:  0.002626746892929077\n",
      "\n",
      "The classification loss after processing this batch is:  0.22118350863456726\n",
      "The representation loss after processing this batch is:  0.002731233835220337\n",
      "\n",
      "The classification loss after processing this batch is:  0.10047610849142075\n",
      "The representation loss after processing this batch is:  0.003021709620952606\n",
      "\n",
      "The classification loss after processing this batch is:  0.08757094293832779\n",
      "The representation loss after processing this batch is:  0.0026651695370674133\n",
      "\n",
      "The classification loss after processing this batch is:  0.22564968466758728\n",
      "The representation loss after processing this batch is:  0.0025238990783691406\n",
      "\n",
      "The classification loss after processing this batch is:  0.22199295461177826\n",
      "The representation loss after processing this batch is:  0.0024673938751220703\n",
      "\n",
      "The classification loss after processing this batch is:  0.17922140657901764\n",
      "The representation loss after processing this batch is:  0.002837933599948883\n",
      "\n",
      "The classification loss after processing this batch is:  0.15131936967372894\n",
      "The representation loss after processing this batch is:  0.0026343166828155518\n",
      "\n",
      "The classification loss after processing this batch is:  0.16558901965618134\n",
      "The representation loss after processing this batch is:  0.002795923501253128\n",
      "\n",
      "The classification loss after processing this batch is:  0.24887427687644958\n",
      "The representation loss after processing this batch is:  0.0025318190455436707\n",
      "\n",
      "The classification loss after processing this batch is:  0.23630470037460327\n",
      "The representation loss after processing this batch is:  0.0025852546095848083\n",
      "\n",
      "The classification loss after processing this batch is:  0.2195349782705307\n",
      "The representation loss after processing this batch is:  0.0028859302401542664\n",
      "\n",
      "The classification loss after processing this batch is:  0.20672127604484558\n",
      "The representation loss after processing this batch is:  0.0026558786630630493\n",
      "\n",
      "The classification loss after processing this batch is:  0.10909692943096161\n",
      "The representation loss after processing this batch is:  0.0032526999711990356\n",
      "\n",
      "The classification loss after processing this batch is:  0.07666311413049698\n",
      "The representation loss after processing this batch is:  0.002950601279735565\n",
      "\n",
      "The classification loss after processing this batch is:  0.16816356778144836\n",
      "The representation loss after processing this batch is:  0.003090325742959976\n",
      "\n",
      "The classification loss after processing this batch is:  0.1370081603527069\n",
      "The representation loss after processing this batch is:  0.002587266266345978\n",
      "\n",
      "The classification loss after processing this batch is:  0.07866094261407852\n",
      "The representation loss after processing this batch is:  0.0025285035371780396\n",
      "\n",
      "The classification loss after processing this batch is:  0.09500706940889359\n",
      "The representation loss after processing this batch is:  0.0027410052716732025\n",
      "\n",
      "The classification loss after processing this batch is:  0.12319923937320709\n",
      "The representation loss after processing this batch is:  0.002526797354221344\n",
      "\n",
      "The classification loss after processing this batch is:  0.12455321103334427\n",
      "The representation loss after processing this batch is:  0.002775058150291443\n",
      "\n",
      "The classification loss after processing this batch is:  0.10089920461177826\n",
      "The representation loss after processing this batch is:  0.0029191263020038605\n",
      "\n",
      "The classification loss after processing this batch is:  0.11349894851446152\n",
      "The representation loss after processing this batch is:  0.00259978324174881\n",
      "\n",
      "The classification loss after processing this batch is:  0.1029665470123291\n",
      "The representation loss after processing this batch is:  0.002837635576725006\n",
      "\n",
      "The classification loss after processing this batch is:  0.19493232667446136\n",
      "The representation loss after processing this batch is:  0.0028365179896354675\n",
      "\n",
      "The classification loss after processing this batch is:  0.12987259030342102\n",
      "The representation loss after processing this batch is:  0.002727687358856201\n",
      "\n",
      "The classification loss after processing this batch is:  0.1900452971458435\n",
      "The representation loss after processing this batch is:  0.0030688121914863586\n",
      "\n",
      "The classification loss after processing this batch is:  0.07789957523345947\n",
      "The representation loss after processing this batch is:  0.0025807544589042664\n",
      "\n",
      "The classification loss after processing this batch is:  0.07250923663377762\n",
      "The representation loss after processing this batch is:  0.0030665993690490723\n",
      "\n",
      "The classification loss after processing this batch is:  0.15970975160598755\n",
      "The representation loss after processing this batch is:  0.0026362016797065735\n",
      "\n",
      "The classification loss after processing this batch is:  0.2324080616235733\n",
      "The representation loss after processing this batch is:  0.0027015693485736847\n",
      "\n",
      "The classification loss after processing this batch is:  0.12886562943458557\n",
      "The representation loss after processing this batch is:  0.002775222063064575\n",
      "\n",
      "The classification loss after processing this batch is:  0.06969534605741501\n",
      "The representation loss after processing this batch is:  0.002657584846019745\n",
      "\n",
      "The classification loss after processing this batch is:  0.13544447720050812\n",
      "The representation loss after processing this batch is:  0.0024314969778060913\n",
      "\n",
      "The classification loss after processing this batch is:  0.030518237501382828\n",
      "The representation loss after processing this batch is:  0.0029388070106506348\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.18422554433345795\n",
      "The representation loss after processing this batch is:  0.0027141645550727844\n",
      "\n",
      "The classification loss after processing this batch is:  0.15730072557926178\n",
      "The representation loss after processing this batch is:  0.0030225515365600586\n",
      "\n",
      "The classification loss after processing this batch is:  0.09461494535207748\n",
      "The representation loss after processing this batch is:  0.0027618855237960815\n",
      "\n",
      "The classification loss after processing this batch is:  0.10524234175682068\n",
      "The representation loss after processing this batch is:  0.002932608127593994\n",
      "\n",
      "The classification loss after processing this batch is:  0.11992119997739792\n",
      "The representation loss after processing this batch is:  0.0028384551405906677\n",
      "\n",
      "The classification loss after processing this batch is:  0.054858092218637466\n",
      "The representation loss after processing this batch is:  0.002998441457748413\n",
      "\n",
      "The classification loss after processing this batch is:  0.2798270285129547\n",
      "The representation loss after processing this batch is:  0.002546347677707672\n",
      "\n",
      "The classification loss after processing this batch is:  0.2416568100452423\n",
      "The representation loss after processing this batch is:  0.002632472664117813\n",
      "\n",
      "The classification loss after processing this batch is:  0.18125097453594208\n",
      "The representation loss after processing this batch is:  0.00253305584192276\n",
      "\n",
      "The classification loss after processing this batch is:  0.21017241477966309\n",
      "The representation loss after processing this batch is:  0.0025782473385334015\n",
      "\n",
      "The classification loss after processing this batch is:  0.14025980234146118\n",
      "The representation loss after processing this batch is:  0.002774439752101898\n",
      "\n",
      "The classification loss after processing this batch is:  0.1178273856639862\n",
      "The representation loss after processing this batch is:  0.0025912001729011536\n",
      "\n",
      "The classification loss after processing this batch is:  0.22700205445289612\n",
      "The representation loss after processing this batch is:  0.002620518207550049\n",
      "\n",
      "The classification loss after processing this batch is:  0.12398717552423477\n",
      "The representation loss after processing this batch is:  0.002681031823158264\n",
      "\n",
      "The classification loss after processing this batch is:  0.19245567917823792\n",
      "The representation loss after processing this batch is:  0.0028970055282115936\n",
      "\n",
      "The classification loss after processing this batch is:  0.12458430230617523\n",
      "The representation loss after processing this batch is:  0.0028692930936813354\n",
      "\n",
      "The classification loss after processing this batch is:  0.17314085364341736\n",
      "The representation loss after processing this batch is:  0.002464164048433304\n",
      "\n",
      "The classification loss after processing this batch is:  0.11711465567350388\n",
      "The representation loss after processing this batch is:  0.0026148371398448944\n",
      "\n",
      "The classification loss after processing this batch is:  0.11362838745117188\n",
      "The representation loss after processing this batch is:  0.003082059323787689\n",
      "\n",
      "The classification loss after processing this batch is:  0.14590924978256226\n",
      "The representation loss after processing this batch is:  0.0028064697980880737\n",
      "\n",
      "The classification loss after processing this batch is:  0.07560423761606216\n",
      "The representation loss after processing this batch is:  0.0027191191911697388\n",
      "\n",
      "The classification loss after processing this batch is:  0.053533975034952164\n",
      "The representation loss after processing this batch is:  0.002657964825630188\n",
      "\n",
      "The classification loss after processing this batch is:  0.10828468948602676\n",
      "The representation loss after processing this batch is:  0.002701304852962494\n",
      "\n",
      "The classification loss after processing this batch is:  0.23890063166618347\n",
      "The representation loss after processing this batch is:  0.002788744866847992\n",
      "\n",
      "The classification loss after processing this batch is:  0.05016106739640236\n",
      "The representation loss after processing this batch is:  0.0027949437499046326\n",
      "\n",
      "The classification loss after processing this batch is:  0.07828430831432343\n",
      "The representation loss after processing this batch is:  0.0026894621551036835\n",
      "\n",
      "The classification loss after processing this batch is:  0.15660305321216583\n",
      "The representation loss after processing this batch is:  0.002737700939178467\n",
      "\n",
      "The classification loss after processing this batch is:  0.1627632975578308\n",
      "The representation loss after processing this batch is:  0.0027182400226593018\n",
      "\n",
      "The classification loss after processing this batch is:  0.11666328459978104\n",
      "The representation loss after processing this batch is:  0.002827852964401245\n",
      "\n",
      "The classification loss after processing this batch is:  0.23784488439559937\n",
      "The representation loss after processing this batch is:  0.002542298287153244\n",
      "\n",
      "The classification loss after processing this batch is:  0.09508497267961502\n",
      "The representation loss after processing this batch is:  0.0031430572271347046\n",
      "\n",
      "The classification loss after processing this batch is:  0.05682775750756264\n",
      "The representation loss after processing this batch is:  0.00255633145570755\n",
      "\n",
      "The classification loss after processing this batch is:  0.06073148921132088\n",
      "The representation loss after processing this batch is:  0.003123447299003601\n",
      "\n",
      "The classification loss after processing this batch is:  0.1633453220129013\n",
      "The representation loss after processing this batch is:  0.0031388550996780396\n",
      "\n",
      "The classification loss after processing this batch is:  0.15811572968959808\n",
      "The representation loss after processing this batch is:  0.0029444172978401184\n",
      "\n",
      "The classification loss after processing this batch is:  0.10377255082130432\n",
      "The representation loss after processing this batch is:  0.0031225979328155518\n",
      "\n",
      "The classification loss after processing this batch is:  0.1280176192522049\n",
      "The representation loss after processing this batch is:  0.0028799250721931458\n",
      "\n",
      "The classification loss after processing this batch is:  0.11139693856239319\n",
      "The representation loss after processing this batch is:  0.002867385745048523\n",
      "\n",
      "The classification loss after processing this batch is:  0.10878510773181915\n",
      "The representation loss after processing this batch is:  0.0029318220913410187\n",
      "\n",
      "The classification loss after processing this batch is:  0.13302190601825714\n",
      "The representation loss after processing this batch is:  0.002832714468240738\n",
      "\n",
      "The classification loss after processing this batch is:  0.18088653683662415\n",
      "The representation loss after processing this batch is:  0.002940036356449127\n",
      "\n",
      "The classification loss after processing this batch is:  0.1554276943206787\n",
      "The representation loss after processing this batch is:  0.0031699389219284058\n",
      "\n",
      "The classification loss after processing this batch is:  0.27237945795059204\n",
      "The representation loss after processing this batch is:  0.0024450942873954773\n",
      "\n",
      "The classification loss after processing this batch is:  0.2034614533185959\n",
      "The representation loss after processing this batch is:  0.0026845596730709076\n",
      "\n",
      "The classification loss after processing this batch is:  0.15034699440002441\n",
      "The representation loss after processing this batch is:  0.002924598753452301\n",
      "\n",
      "The classification loss after processing this batch is:  0.1557759940624237\n",
      "The representation loss after processing this batch is:  0.002969972789287567\n",
      "\n",
      "The classification loss after processing this batch is:  0.047673359513282776\n",
      "The representation loss after processing this batch is:  0.002736009657382965\n",
      "\n",
      "The classification loss after processing this batch is:  0.12416966259479523\n",
      "The representation loss after processing this batch is:  0.003174901008605957\n",
      "\n",
      "The classification loss after processing this batch is:  0.10214020311832428\n",
      "The representation loss after processing this batch is:  0.003131955862045288\n",
      "\n",
      "The classification loss after processing this batch is:  0.13226333260536194\n",
      "The representation loss after processing this batch is:  0.0028469227254390717\n",
      "\n",
      "The classification loss after processing this batch is:  0.14885812997817993\n",
      "The representation loss after processing this batch is:  0.0024963468313217163\n",
      "\n",
      "The classification loss after processing this batch is:  0.10007981210947037\n",
      "The representation loss after processing this batch is:  0.0024808160960674286\n",
      "\n",
      "The classification loss after processing this batch is:  0.15158605575561523\n",
      "The representation loss after processing this batch is:  0.0025614798069000244\n",
      "\n",
      "The classification loss after processing this batch is:  0.18135903775691986\n",
      "The representation loss after processing this batch is:  0.002592034637928009\n",
      "\n",
      "The classification loss after processing this batch is:  0.14726634323596954\n",
      "The representation loss after processing this batch is:  0.002923905849456787\n",
      "\n",
      "The classification loss after processing this batch is:  0.23532915115356445\n",
      "The representation loss after processing this batch is:  0.002948954701423645\n",
      "\n",
      "The classification loss after processing this batch is:  0.1073443591594696\n",
      "The representation loss after processing this batch is:  0.002844385802745819\n",
      "\n",
      "The classification loss after processing this batch is:  0.1482824981212616\n",
      "The representation loss after processing this batch is:  0.0023553483188152313\n",
      "\n",
      "The classification loss after processing this batch is:  0.10312756896018982\n",
      "The representation loss after processing this batch is:  0.0028584077954292297\n",
      "\n",
      "The classification loss after processing this batch is:  0.24070312082767487\n",
      "The representation loss after processing this batch is:  0.002979770302772522\n",
      "\n",
      "The classification loss after processing this batch is:  0.22344253957271576\n",
      "The representation loss after processing this batch is:  0.003052540123462677\n",
      "\n",
      "The classification loss after processing this batch is:  0.057733163237571716\n",
      "The representation loss after processing this batch is:  0.002681747078895569\n",
      "\n",
      "The classification loss after processing this batch is:  0.08107160776853561\n",
      "The representation loss after processing this batch is:  0.0028668642044067383\n",
      "\n",
      "The classification loss after processing this batch is:  0.24866177141666412\n",
      "The representation loss after processing this batch is:  0.002608098089694977\n",
      "\n",
      "The classification loss after processing this batch is:  0.07802678644657135\n",
      "The representation loss after processing this batch is:  0.002737574279308319\n",
      "\n",
      "The classification loss after processing this batch is:  0.1046263799071312\n",
      "The representation loss after processing this batch is:  0.0028786882758140564\n",
      "\n",
      "The classification loss after processing this batch is:  0.16336344182491302\n",
      "The representation loss after processing this batch is:  0.002732411026954651\n",
      "\n",
      "The classification loss after processing this batch is:  0.11662188917398453\n",
      "The representation loss after processing this batch is:  0.002903573215007782\n",
      "\n",
      "The classification loss after processing this batch is:  0.2408338487148285\n",
      "The representation loss after processing this batch is:  0.0031652897596359253\n",
      "\n",
      "The classification loss after processing this batch is:  0.16043180227279663\n",
      "The representation loss after processing this batch is:  0.003120921552181244\n",
      "\n",
      "The classification loss after processing this batch is:  0.16949988901615143\n",
      "The representation loss after processing this batch is:  0.003338754177093506\n",
      "\n",
      "The classification loss after processing this batch is:  0.1257053017616272\n",
      "The representation loss after processing this batch is:  0.0026690512895584106\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.18802553415298462\n",
      "The representation loss after processing this batch is:  0.0023956261575222015\n",
      "\n",
      "The classification loss after processing this batch is:  0.062337134033441544\n",
      "The representation loss after processing this batch is:  0.0025811567902565002\n",
      "\n",
      "The classification loss after processing this batch is:  0.06002973020076752\n",
      "The representation loss after processing this batch is:  0.002590663731098175\n",
      "\n",
      "The classification loss after processing this batch is:  0.08786790817975998\n",
      "The representation loss after processing this batch is:  0.0027464814484119415\n",
      "\n",
      "The classification loss after processing this batch is:  0.0682547315955162\n",
      "The representation loss after processing this batch is:  0.002697490155696869\n",
      "\n",
      "The classification loss after processing this batch is:  0.12182428687810898\n",
      "The representation loss after processing this batch is:  0.002922419458627701\n",
      "\n",
      "The classification loss after processing this batch is:  0.08041153848171234\n",
      "The representation loss after processing this batch is:  0.0025536268949508667\n",
      "\n",
      "The classification loss after processing this batch is:  0.09525840729475021\n",
      "The representation loss after processing this batch is:  0.002435382455587387\n",
      "\n",
      "The classification loss after processing this batch is:  0.14099811017513275\n",
      "The representation loss after processing this batch is:  0.002747088670730591\n",
      "\n",
      "The classification loss after processing this batch is:  0.20164722204208374\n",
      "The representation loss after processing this batch is:  0.002797752618789673\n",
      "\n",
      "The classification loss after processing this batch is:  0.17779101431369781\n",
      "The representation loss after processing this batch is:  0.0025506094098091125\n",
      "\n",
      "The classification loss after processing this batch is:  0.16233128309249878\n",
      "The representation loss after processing this batch is:  0.002988584339618683\n",
      "\n",
      "The classification loss after processing this batch is:  0.19693374633789062\n",
      "The representation loss after processing this batch is:  0.002586282789707184\n",
      "\n",
      "The classification loss after processing this batch is:  0.11201856285333633\n",
      "The representation loss after processing this batch is:  0.0026745572686195374\n",
      "\n",
      "The classification loss after processing this batch is:  0.16466566920280457\n",
      "The representation loss after processing this batch is:  0.0029208436608314514\n",
      "\n",
      "The classification loss after processing this batch is:  0.2570241093635559\n",
      "The representation loss after processing this batch is:  0.002957254648208618\n",
      "\n",
      "The classification loss after processing this batch is:  0.0995267927646637\n",
      "The representation loss after processing this batch is:  0.002725273370742798\n",
      "\n",
      "The classification loss after processing this batch is:  0.1975114941596985\n",
      "The representation loss after processing this batch is:  0.0025356821715831757\n",
      "\n",
      "The classification loss after processing this batch is:  0.18589304387569427\n",
      "The representation loss after processing this batch is:  0.002512909471988678\n",
      "\n",
      "The classification loss after processing this batch is:  0.1742267608642578\n",
      "The representation loss after processing this batch is:  0.0024568215012550354\n",
      "\n",
      "The classification loss after processing this batch is:  0.10428007692098618\n",
      "The representation loss after processing this batch is:  0.0029587894678115845\n",
      "\n",
      "The classification loss after processing this batch is:  0.07841846346855164\n",
      "The representation loss after processing this batch is:  0.00265318900346756\n",
      "\n",
      "The classification loss after processing this batch is:  0.11507111042737961\n",
      "The representation loss after processing this batch is:  0.0024803951382637024\n",
      "\n",
      "The classification loss after processing this batch is:  0.07872485369443893\n",
      "The representation loss after processing this batch is:  0.0027377307415008545\n",
      "\n",
      "The classification loss after processing this batch is:  0.0548635758459568\n",
      "The representation loss after processing this batch is:  0.0027417540550231934\n",
      "\n",
      "The classification loss after processing this batch is:  0.170710951089859\n",
      "The representation loss after processing this batch is:  0.0029432401061058044\n",
      "\n",
      "The classification loss after processing this batch is:  0.06651689112186432\n",
      "The representation loss after processing this batch is:  0.003037668764591217\n",
      "\n",
      "The classification loss after processing this batch is:  0.2076319307088852\n",
      "The representation loss after processing this batch is:  0.0032685622572898865\n",
      "\n",
      "The classification loss after processing this batch is:  0.13536636531352997\n",
      "The representation loss after processing this batch is:  0.002703920006752014\n",
      "\n",
      "The classification loss after processing this batch is:  0.2067795693874359\n",
      "The representation loss after processing this batch is:  0.00273045152425766\n",
      "\n",
      "The classification loss after processing this batch is:  0.34823766350746155\n",
      "The representation loss after processing this batch is:  0.0023217052221298218\n",
      "\n",
      "The classification loss after processing this batch is:  0.1601354330778122\n",
      "The representation loss after processing this batch is:  0.002586919814348221\n",
      "\n",
      "The classification loss after processing this batch is:  0.058356575667858124\n",
      "The representation loss after processing this batch is:  0.002780698239803314\n",
      "\n",
      "The classification loss after processing this batch is:  0.08679448813199997\n",
      "The representation loss after processing this batch is:  0.003148898482322693\n",
      "\n",
      "The classification loss after processing this batch is:  0.07331463694572449\n",
      "The representation loss after processing this batch is:  0.0030810758471488953\n",
      "\n",
      "The classification loss after processing this batch is:  0.0888596847653389\n",
      "The representation loss after processing this batch is:  0.0027954131364822388\n",
      "\n",
      "The classification loss after processing this batch is:  0.09125515073537827\n",
      "The representation loss after processing this batch is:  0.002642601728439331\n",
      "\n",
      "The classification loss after processing this batch is:  0.22119691967964172\n",
      "The representation loss after processing this batch is:  0.0026167109608650208\n",
      "\n",
      "The classification loss after processing this batch is:  0.1801339089870453\n",
      "The representation loss after processing this batch is:  0.002654731273651123\n",
      "\n",
      "The classification loss after processing this batch is:  0.16906818747520447\n",
      "The representation loss after processing this batch is:  0.0031420812010765076\n",
      "\n",
      "The classification loss after processing this batch is:  0.2608557939529419\n",
      "The representation loss after processing this batch is:  0.0034106597304344177\n",
      "\n",
      "The classification loss after processing this batch is:  0.1158813089132309\n",
      "The representation loss after processing this batch is:  0.002842821180820465\n",
      "\n",
      "The classification loss after processing this batch is:  0.1293000727891922\n",
      "The representation loss after processing this batch is:  0.002877555787563324\n",
      "\n",
      "The classification loss after processing this batch is:  0.1989665925502777\n",
      "The representation loss after processing this batch is:  0.0026252977550029755\n",
      "\n",
      "The classification loss after processing this batch is:  0.13159938156604767\n",
      "The representation loss after processing this batch is:  0.003268703818321228\n",
      "\n",
      "The classification loss after processing this batch is:  0.15415631234645844\n",
      "The representation loss after processing this batch is:  0.003978021442890167\n",
      "\n",
      "The classification loss after processing this batch is:  0.07953473180532455\n",
      "The representation loss after processing this batch is:  0.0030144378542900085\n",
      "\n",
      "The classification loss after processing this batch is:  0.17539939284324646\n",
      "The representation loss after processing this batch is:  0.0032642483711242676\n",
      "\n",
      "The classification loss after processing this batch is:  0.17614123225212097\n",
      "The representation loss after processing this batch is:  0.0034047365188598633\n",
      "\n",
      "The classification loss after processing this batch is:  0.11941585689783096\n",
      "The representation loss after processing this batch is:  0.003376781940460205\n",
      "\n",
      "The classification loss after processing this batch is:  0.17012526094913483\n",
      "The representation loss after processing this batch is:  0.0028600692749023438\n",
      "\n",
      "The classification loss after processing this batch is:  0.169631227850914\n",
      "The representation loss after processing this batch is:  0.002485353499650955\n",
      "\n",
      "The classification loss after processing this batch is:  0.16648037731647491\n",
      "The representation loss after processing this batch is:  0.0024362951517105103\n",
      "\n",
      "The classification loss after processing this batch is:  0.1631837636232376\n",
      "The representation loss after processing this batch is:  0.002723120152950287\n",
      "\n",
      "The classification loss after processing this batch is:  0.12079756706953049\n",
      "The representation loss after processing this batch is:  0.002934567630290985\n",
      "\n",
      "The classification loss after processing this batch is:  0.041105158627033234\n",
      "The representation loss after processing this batch is:  0.0027624815702438354\n",
      "\n",
      "The classification loss after processing this batch is:  0.1371147334575653\n",
      "The representation loss after processing this batch is:  0.002865433692932129\n",
      "\n",
      "The classification loss after processing this batch is:  0.0821705088019371\n",
      "The representation loss after processing this batch is:  0.002964608371257782\n",
      "\n",
      "The classification loss after processing this batch is:  0.2310309112071991\n",
      "The representation loss after processing this batch is:  0.0027446746826171875\n",
      "\n",
      "The classification loss after processing this batch is:  0.07608450204133987\n",
      "The representation loss after processing this batch is:  0.0030897855758666992\n",
      "\n",
      "The classification loss after processing this batch is:  0.11704900860786438\n",
      "The representation loss after processing this batch is:  0.0025947168469429016\n",
      "\n",
      "The classification loss after processing this batch is:  0.1764666736125946\n",
      "The representation loss after processing this batch is:  0.0030246302485466003\n",
      "\n",
      "The classification loss after processing this batch is:  0.13765573501586914\n",
      "The representation loss after processing this batch is:  0.002858951687812805\n",
      "\n",
      "The classification loss after processing this batch is:  0.16736911237239838\n",
      "The representation loss after processing this batch is:  0.0027540400624275208\n",
      "\n",
      "The classification loss after processing this batch is:  0.09774066507816315\n",
      "The representation loss after processing this batch is:  0.0025731027126312256\n",
      "\n",
      "The classification loss after processing this batch is:  0.09403998404741287\n",
      "The representation loss after processing this batch is:  0.0025732629001140594\n",
      "\n",
      "The classification loss after processing this batch is:  0.10099273175001144\n",
      "The representation loss after processing this batch is:  0.0025497525930404663\n",
      "\n",
      "The classification loss after processing this batch is:  0.18179689347743988\n",
      "The representation loss after processing this batch is:  0.0029890164732933044\n",
      "\n",
      "The classification loss after processing this batch is:  0.2009146809577942\n",
      "The representation loss after processing this batch is:  0.002940662205219269\n",
      "\n",
      "The classification loss after processing this batch is:  0.18504831194877625\n",
      "The representation loss after processing this batch is:  0.0024023279547691345\n",
      "\n",
      "The classification loss after processing this batch is:  0.17512083053588867\n",
      "The representation loss after processing this batch is:  0.002497173845767975\n",
      "\n",
      "The classification loss after processing this batch is:  0.2630999684333801\n",
      "The representation loss after processing this batch is:  0.0027544796466827393\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1322566419839859\n",
      "The representation loss after processing this batch is:  0.0030489563941955566\n",
      "\n",
      "The classification loss after processing this batch is:  0.23541103303432465\n",
      "The representation loss after processing this batch is:  0.0028450414538383484\n",
      "\n",
      "The classification loss after processing this batch is:  0.12143739312887192\n",
      "The representation loss after processing this batch is:  0.0028416067361831665\n",
      "\n",
      "The classification loss after processing this batch is:  0.06378121674060822\n",
      "The representation loss after processing this batch is:  0.0028318464756011963\n",
      "\n",
      "The classification loss after processing this batch is:  0.05502598360180855\n",
      "The representation loss after processing this batch is:  0.0024301856756210327\n",
      "\n",
      "The classification loss after processing this batch is:  0.07741130143404007\n",
      "The representation loss after processing this batch is:  0.0027753710746765137\n",
      "\n",
      "The classification loss after processing this batch is:  0.22036559879779816\n",
      "The representation loss after processing this batch is:  0.002979859709739685\n",
      "\n",
      "The classification loss after processing this batch is:  0.09373307228088379\n",
      "The representation loss after processing this batch is:  0.0028845369815826416\n",
      "\n",
      "The classification loss after processing this batch is:  0.1382533758878708\n",
      "The representation loss after processing this batch is:  0.002962343394756317\n",
      "\n",
      "The classification loss after processing this batch is:  0.15096984803676605\n",
      "The representation loss after processing this batch is:  0.002996794879436493\n",
      "\n",
      "The classification loss after processing this batch is:  0.10346312075853348\n",
      "The representation loss after processing this batch is:  0.0029380470514297485\n",
      "\n",
      "The classification loss after processing this batch is:  0.08332733809947968\n",
      "The representation loss after processing this batch is:  0.002556741237640381\n",
      "\n",
      "The classification loss after processing this batch is:  0.18004602193832397\n",
      "The representation loss after processing this batch is:  0.002531670033931732\n",
      "\n",
      "The classification loss after processing this batch is:  0.22139981389045715\n",
      "The representation loss after processing this batch is:  0.002575606107711792\n",
      "\n",
      "The classification loss after processing this batch is:  0.1893092542886734\n",
      "The representation loss after processing this batch is:  0.002918615937232971\n",
      "\n",
      "The classification loss after processing this batch is:  0.08683861047029495\n",
      "The representation loss after processing this batch is:  0.0026995614171028137\n",
      "\n",
      "The classification loss after processing this batch is:  0.23835422098636627\n",
      "The representation loss after processing this batch is:  0.002571575343608856\n",
      "\n",
      "The classification loss after processing this batch is:  0.09624375402927399\n",
      "The representation loss after processing this batch is:  0.00233464315533638\n",
      "\n",
      "The classification loss after processing this batch is:  0.17270579934120178\n",
      "The representation loss after processing this batch is:  0.002485111355781555\n",
      "\n",
      "The classification loss after processing this batch is:  0.16792459785938263\n",
      "The representation loss after processing this batch is:  0.0029650256037712097\n",
      "\n",
      "The classification loss after processing this batch is:  0.12337259203195572\n",
      "The representation loss after processing this batch is:  0.002702847123146057\n",
      "\n",
      "The classification loss after processing this batch is:  0.1487482190132141\n",
      "The representation loss after processing this batch is:  0.002750888466835022\n",
      "\n",
      "The classification loss after processing this batch is:  0.14344002306461334\n",
      "The representation loss after processing this batch is:  0.0031698793172836304\n",
      "\n",
      "The classification loss after processing this batch is:  0.20459410548210144\n",
      "The representation loss after processing this batch is:  0.0026726536452770233\n",
      "\n",
      "The classification loss after processing this batch is:  0.26379889249801636\n",
      "The representation loss after processing this batch is:  0.0028916820883750916\n",
      "\n",
      "The classification loss after processing this batch is:  0.21421128511428833\n",
      "The representation loss after processing this batch is:  0.0028274506330490112\n",
      "\n",
      "The classification loss after processing this batch is:  0.13223806023597717\n",
      "The representation loss after processing this batch is:  0.002779640257358551\n",
      "\n",
      "The classification loss after processing this batch is:  0.09864618629217148\n",
      "The representation loss after processing this batch is:  0.003190472722053528\n",
      "\n",
      "The classification loss after processing this batch is:  0.18919549882411957\n",
      "The representation loss after processing this batch is:  0.0023355521261692047\n",
      "\n",
      "The classification loss after processing this batch is:  0.1648259311914444\n",
      "The representation loss after processing this batch is:  0.0026871301233768463\n",
      "\n",
      "The classification loss after processing this batch is:  0.04559403285384178\n",
      "The representation loss after processing this batch is:  0.002673014998435974\n",
      "\n",
      "The classification loss after processing this batch is:  0.14096766710281372\n",
      "The representation loss after processing this batch is:  0.0026306845247745514\n",
      "\n",
      "The classification loss after processing this batch is:  0.31735357642173767\n",
      "The representation loss after processing this batch is:  0.003091316670179367\n",
      "\n",
      "The classification loss after processing this batch is:  0.3307687044143677\n",
      "The representation loss after processing this batch is:  0.002914018929004669\n",
      "\n",
      "The classification loss after processing this batch is:  0.28343072533607483\n",
      "The representation loss after processing this batch is:  0.0026683174073696136\n",
      "\n",
      "The classification loss after processing this batch is:  0.19326426088809967\n",
      "The representation loss after processing this batch is:  0.0026460960507392883\n",
      "\n",
      "The classification loss after processing this batch is:  0.08136531710624695\n",
      "The representation loss after processing this batch is:  0.0025100111961364746\n",
      "\n",
      "The classification loss after processing this batch is:  0.16245006024837494\n",
      "The representation loss after processing this batch is:  0.002698540687561035\n",
      "\n",
      "The classification loss after processing this batch is:  0.15813836455345154\n",
      "The representation loss after processing this batch is:  0.0029006674885749817\n",
      "\n",
      "The classification loss after processing this batch is:  0.2316884994506836\n",
      "The representation loss after processing this batch is:  0.002978213131427765\n",
      "\n",
      "The classification loss after processing this batch is:  0.136542409658432\n",
      "The representation loss after processing this batch is:  0.0032018721103668213\n",
      "\n",
      "The classification loss after processing this batch is:  0.11871261894702911\n",
      "The representation loss after processing this batch is:  0.0032593905925750732\n",
      "\n",
      "The classification loss after processing this batch is:  0.09116653352975845\n",
      "The representation loss after processing this batch is:  0.002809293568134308\n",
      "\n",
      "The classification loss after processing this batch is:  0.14062021672725677\n",
      "The representation loss after processing this batch is:  0.002839215099811554\n",
      "\n",
      "The classification loss after processing this batch is:  0.1855177879333496\n",
      "The representation loss after processing this batch is:  0.0030683502554893494\n",
      "\n",
      "The classification loss after processing this batch is:  0.16718821227550507\n",
      "The representation loss after processing this batch is:  0.002616666257381439\n",
      "\n",
      "The classification loss after processing this batch is:  0.10586374253034592\n",
      "The representation loss after processing this batch is:  0.0024727582931518555\n",
      "\n",
      "The classification loss after processing this batch is:  0.27736422419548035\n",
      "The representation loss after processing this batch is:  0.0032804422080516815\n",
      "\n",
      "The classification loss after processing this batch is:  0.3602849543094635\n",
      "The representation loss after processing this batch is:  0.00329478457570076\n",
      "\n",
      "The classification loss after processing this batch is:  0.2146342694759369\n",
      "The representation loss after processing this batch is:  0.002984948456287384\n",
      "\n",
      "The classification loss after processing this batch is:  0.132278174161911\n",
      "The representation loss after processing this batch is:  0.003168553113937378\n",
      "\n",
      "The classification loss after processing this batch is:  0.12424851208925247\n",
      "The representation loss after processing this batch is:  0.0030460283160209656\n",
      "\n",
      "The classification loss after processing this batch is:  0.10099587589502335\n",
      "The representation loss after processing this batch is:  0.0028960779309272766\n",
      "\n",
      "The classification loss after processing this batch is:  0.26310089230537415\n",
      "The representation loss after processing this batch is:  0.0027684494853019714\n",
      "\n",
      "The classification loss after processing this batch is:  0.18255072832107544\n",
      "The representation loss after processing this batch is:  0.0032761916518211365\n",
      "\n",
      "The classification loss after processing this batch is:  0.15225842595100403\n",
      "The representation loss after processing this batch is:  0.0030929669737815857\n",
      "\n",
      "The classification loss after processing this batch is:  0.26405981183052063\n",
      "The representation loss after processing this batch is:  0.002428866922855377\n",
      "\n",
      "The classification loss after processing this batch is:  0.043553080409765244\n",
      "The representation loss after processing this batch is:  0.0028457343578338623\n",
      "\n",
      "The classification loss after processing this batch is:  0.06524036079645157\n",
      "The representation loss after processing this batch is:  0.00285155326128006\n",
      "\n",
      "The classification loss after processing this batch is:  0.11386895179748535\n",
      "The representation loss after processing this batch is:  0.0028062015771865845\n",
      "\n",
      "The classification loss after processing this batch is:  0.18922404944896698\n",
      "The representation loss after processing this batch is:  0.0023573003709316254\n",
      "\n",
      "The classification loss after processing this batch is:  0.19041357934474945\n",
      "The representation loss after processing this batch is:  0.0027551203966140747\n",
      "\n",
      "The classification loss after processing this batch is:  0.10225875675678253\n",
      "The representation loss after processing this batch is:  0.00279940664768219\n",
      "\n",
      "The classification loss after processing this batch is:  0.13050512969493866\n",
      "The representation loss after processing this batch is:  0.0029200762510299683\n",
      "\n",
      "The classification loss after processing this batch is:  0.06158530339598656\n",
      "The representation loss after processing this batch is:  0.0026381388306617737\n",
      "\n",
      "The classification loss after processing this batch is:  0.0987171158194542\n",
      "The representation loss after processing this batch is:  0.002608470618724823\n",
      "\n",
      "The classification loss after processing this batch is:  0.09003758430480957\n",
      "The representation loss after processing this batch is:  0.002794906497001648\n",
      "\n",
      "The classification loss after processing this batch is:  0.08724446594715118\n",
      "The representation loss after processing this batch is:  0.0028982311487197876\n",
      "\n",
      "The classification loss after processing this batch is:  0.11797894537448883\n",
      "The representation loss after processing this batch is:  0.002709764987230301\n",
      "\n",
      "The classification loss after processing this batch is:  0.1664963811635971\n",
      "The representation loss after processing this batch is:  0.0026559829711914062\n",
      "\n",
      "The classification loss after processing this batch is:  0.2157672792673111\n",
      "The representation loss after processing this batch is:  0.0030355677008628845\n",
      "\n",
      "The classification loss after processing this batch is:  0.05903283506631851\n",
      "The representation loss after processing this batch is:  0.002396725118160248\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08284951001405716\n",
      "The representation loss after processing this batch is:  0.00255710631608963\n",
      "\n",
      "The classification loss after processing this batch is:  0.09847225248813629\n",
      "The representation loss after processing this batch is:  0.0033729299902915955\n",
      "\n",
      "The classification loss after processing this batch is:  0.1691000908613205\n",
      "The representation loss after processing this batch is:  0.002765316516160965\n",
      "\n",
      "The classification loss after processing this batch is:  0.0887642577290535\n",
      "The representation loss after processing this batch is:  0.0036236271262168884\n",
      "\n",
      "The classification loss after processing this batch is:  0.1769423633813858\n",
      "The representation loss after processing this batch is:  0.003193765878677368\n",
      "\n",
      "The classification loss after processing this batch is:  0.21801084280014038\n",
      "The representation loss after processing this batch is:  0.002798020839691162\n",
      "\n",
      "The classification loss after processing this batch is:  0.17991389334201813\n",
      "The representation loss after processing this batch is:  0.0029316842555999756\n",
      "\n",
      "The classification loss after processing this batch is:  0.1828860193490982\n",
      "The representation loss after processing this batch is:  0.002943776547908783\n",
      "\n",
      "The classification loss after processing this batch is:  0.09707161784172058\n",
      "The representation loss after processing this batch is:  0.0028501302003860474\n",
      "\n",
      "The classification loss after processing this batch is:  0.1633588671684265\n",
      "The representation loss after processing this batch is:  0.0025217533111572266\n",
      "\n",
      "The classification loss after processing this batch is:  0.15402571856975555\n",
      "The representation loss after processing this batch is:  0.0025359168648719788\n",
      "\n",
      "The classification loss after processing this batch is:  0.10989958792924881\n",
      "The representation loss after processing this batch is:  0.0028290972113609314\n",
      "\n",
      "The classification loss after processing this batch is:  0.04141983017325401\n",
      "The representation loss after processing this batch is:  0.002452962100505829\n",
      "\n",
      "The classification loss after processing this batch is:  0.2261999547481537\n",
      "The representation loss after processing this batch is:  0.002959698438644409\n",
      "\n",
      "The classification loss after processing this batch is:  0.2933758497238159\n",
      "The representation loss after processing this batch is:  0.0025558434426784515\n",
      "\n",
      "The classification loss after processing this batch is:  0.11980532854795456\n",
      "The representation loss after processing this batch is:  0.0027115195989608765\n",
      "\n",
      "The classification loss after processing this batch is:  0.2352493852376938\n",
      "The representation loss after processing this batch is:  0.0027788877487182617\n",
      "\n",
      "The classification loss after processing this batch is:  0.25844699144363403\n",
      "The representation loss after processing this batch is:  0.0029233023524284363\n",
      "\n",
      "The classification loss after processing this batch is:  0.3565156161785126\n",
      "The representation loss after processing this batch is:  0.0028712600469589233\n",
      "\n",
      "The classification loss after processing this batch is:  0.17199820280075073\n",
      "The representation loss after processing this batch is:  0.0028500929474830627\n",
      "\n",
      "The classification loss after processing this batch is:  0.1194574311375618\n",
      "The representation loss after processing this batch is:  0.002792470157146454\n",
      "\n",
      "The classification loss after processing this batch is:  0.18047989904880524\n",
      "The representation loss after processing this batch is:  0.003188416361808777\n",
      "\n",
      "The classification loss after processing this batch is:  0.10650937259197235\n",
      "The representation loss after processing this batch is:  0.0028922930359840393\n",
      "\n",
      "The classification loss after processing this batch is:  0.06210664287209511\n",
      "The representation loss after processing this batch is:  0.002846553921699524\n",
      "\n",
      "The classification loss after processing this batch is:  0.07970324158668518\n",
      "The representation loss after processing this batch is:  0.00270891934633255\n",
      "\n",
      "The classification loss after processing this batch is:  0.07329315692186356\n",
      "The representation loss after processing this batch is:  0.0027543380856513977\n",
      "\n",
      "The classification loss after processing this batch is:  0.05335391312837601\n",
      "The representation loss after processing this batch is:  0.002779267728328705\n",
      "\n",
      "The classification loss after processing this batch is:  0.1660572737455368\n",
      "The representation loss after processing this batch is:  0.0027196183800697327\n",
      "\n",
      "The classification loss after processing this batch is:  0.16717858612537384\n",
      "The representation loss after processing this batch is:  0.0025493428111076355\n",
      "\n",
      "The classification loss after processing this batch is:  0.06964460760354996\n",
      "The representation loss after processing this batch is:  0.002931162714958191\n",
      "\n",
      "The classification loss after processing this batch is:  0.11971595883369446\n",
      "The representation loss after processing this batch is:  0.0027879998087882996\n",
      "\n",
      "The classification loss after processing this batch is:  0.13989748060703278\n",
      "The representation loss after processing this batch is:  0.0029839202761650085\n",
      "\n",
      "The classification loss after processing this batch is:  0.043136175721883774\n",
      "The representation loss after processing this batch is:  0.0029060840606689453\n",
      "\n",
      "The classification loss after processing this batch is:  0.21907980740070343\n",
      "The representation loss after processing this batch is:  0.00271037220954895\n",
      "\n",
      "The classification loss after processing this batch is:  0.10370535403490067\n",
      "The representation loss after processing this batch is:  0.0027095824480056763\n",
      "\n",
      "The classification loss after processing this batch is:  0.2630294859409332\n",
      "The representation loss after processing this batch is:  0.00250089168548584\n",
      "\n",
      "The classification loss after processing this batch is:  0.15585027635097504\n",
      "The representation loss after processing this batch is:  0.0030829235911369324\n",
      "\n",
      "The classification loss after processing this batch is:  0.16506427526474\n",
      "The representation loss after processing this batch is:  0.002519015222787857\n",
      "\n",
      "The classification loss after processing this batch is:  0.0570015050470829\n",
      "The representation loss after processing this batch is:  0.0027696192264556885\n",
      "\n",
      "The classification loss after processing this batch is:  0.05028926581144333\n",
      "The representation loss after processing this batch is:  0.0027090534567832947\n",
      "\n",
      "The classification loss after processing this batch is:  0.15262676775455475\n",
      "The representation loss after processing this batch is:  0.0027349740266799927\n",
      "\n",
      "The classification loss after processing this batch is:  0.06009197235107422\n",
      "The representation loss after processing this batch is:  0.003085397183895111\n",
      "\n",
      "The classification loss after processing this batch is:  0.15348030626773834\n",
      "The representation loss after processing this batch is:  0.0029469281435012817\n",
      "\n",
      "The classification loss after processing this batch is:  0.1008826270699501\n",
      "The representation loss after processing this batch is:  0.0026873424649238586\n",
      "\n",
      "The classification loss after processing this batch is:  0.13394445180892944\n",
      "The representation loss after processing this batch is:  0.0029337480664253235\n",
      "\n",
      "The classification loss after processing this batch is:  0.14167314767837524\n",
      "The representation loss after processing this batch is:  0.0027229636907577515\n",
      "\n",
      "The classification loss after processing this batch is:  0.11215648800134659\n",
      "The representation loss after processing this batch is:  0.0028269141912460327\n",
      "\n",
      "The classification loss after processing this batch is:  0.1520349681377411\n",
      "The representation loss after processing this batch is:  0.002934284508228302\n",
      "\n",
      "The classification loss after processing this batch is:  0.15329600870609283\n",
      "The representation loss after processing this batch is:  0.002678878605365753\n",
      "\n",
      "The classification loss after processing this batch is:  0.1631331890821457\n",
      "The representation loss after processing this batch is:  0.002830013632774353\n",
      "\n",
      "The classification loss after processing this batch is:  0.20116043090820312\n",
      "The representation loss after processing this batch is:  0.00286845862865448\n",
      "\n",
      "The classification loss after processing this batch is:  0.22872179746627808\n",
      "The representation loss after processing this batch is:  0.0029604434967041016\n",
      "\n",
      "The classification loss after processing this batch is:  0.15668605268001556\n",
      "The representation loss after processing this batch is:  0.0025132596492767334\n",
      "\n",
      "The classification loss after processing this batch is:  0.11597103625535965\n",
      "The representation loss after processing this batch is:  0.0027480050921440125\n",
      "\n",
      "The classification loss after processing this batch is:  0.08713334053754807\n",
      "The representation loss after processing this batch is:  0.0026735886931419373\n",
      "\n",
      "The classification loss after processing this batch is:  0.10069688409566879\n",
      "The representation loss after processing this batch is:  0.0029642805457115173\n",
      "\n",
      "The classification loss after processing this batch is:  0.08746811002492905\n",
      "The representation loss after processing this batch is:  0.00297575443983078\n",
      "\n",
      "The classification loss after processing this batch is:  0.11181964725255966\n",
      "The representation loss after processing this batch is:  0.0024056807160377502\n",
      "\n",
      "The classification loss after processing this batch is:  0.08993072062730789\n",
      "The representation loss after processing this batch is:  0.002770468592643738\n",
      "\n",
      "The classification loss after processing this batch is:  0.11651953309774399\n",
      "The representation loss after processing this batch is:  0.002955898642539978\n",
      "\n",
      "The classification loss after processing this batch is:  0.08419343084096909\n",
      "The representation loss after processing this batch is:  0.002681419253349304\n",
      "\n",
      "The classification loss after processing this batch is:  0.14691345393657684\n",
      "The representation loss after processing this batch is:  0.002751775085926056\n",
      "\n",
      "The classification loss after processing this batch is:  0.10539843887090683\n",
      "The representation loss after processing this batch is:  0.0028761103749275208\n",
      "\n",
      "The classification loss after processing this batch is:  0.15054276585578918\n",
      "The representation loss after processing this batch is:  0.0027901828289031982\n",
      "\n",
      "The classification loss after processing this batch is:  0.16377748548984528\n",
      "The representation loss after processing this batch is:  0.0029959380626678467\n",
      "\n",
      "The classification loss after processing this batch is:  0.12333406507968903\n",
      "The representation loss after processing this batch is:  0.002944067120552063\n",
      "\n",
      "The classification loss after processing this batch is:  0.10393539071083069\n",
      "The representation loss after processing this batch is:  0.003064103424549103\n",
      "\n",
      "The classification loss after processing this batch is:  0.19962389767169952\n",
      "The representation loss after processing this batch is:  0.002904660999774933\n",
      "\n",
      "The classification loss after processing this batch is:  0.07822638005018234\n",
      "The representation loss after processing this batch is:  0.002817481756210327\n",
      "\n",
      "The classification loss after processing this batch is:  0.07798083126544952\n",
      "The representation loss after processing this batch is:  0.0027197301387786865\n",
      "\n",
      "The classification loss after processing this batch is:  0.1136409267783165\n",
      "The representation loss after processing this batch is:  0.0026443153619766235\n",
      "\n",
      "The classification loss after processing this batch is:  0.0868295207619667\n",
      "The representation loss after processing this batch is:  0.002681337296962738\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.19455038011074066\n",
      "The representation loss after processing this batch is:  0.002365361899137497\n",
      "\n",
      "The classification loss after processing this batch is:  0.18759329617023468\n",
      "The representation loss after processing this batch is:  0.00260133296251297\n",
      "\n",
      "The classification loss after processing this batch is:  0.15238343179225922\n",
      "The representation loss after processing this batch is:  0.0030656903982162476\n",
      "\n",
      "The classification loss after processing this batch is:  0.09568431228399277\n",
      "The representation loss after processing this batch is:  0.0030918866395950317\n",
      "\n",
      "The classification loss after processing this batch is:  0.1247120127081871\n",
      "The representation loss after processing this batch is:  0.002751678228378296\n",
      "\n",
      "The classification loss after processing this batch is:  0.24409911036491394\n",
      "The representation loss after processing this batch is:  0.002740830183029175\n",
      "\n",
      "The classification loss after processing this batch is:  0.056491918861866\n",
      "The representation loss after processing this batch is:  0.0027879998087882996\n",
      "\n",
      "The classification loss after processing this batch is:  0.10618303716182709\n",
      "The representation loss after processing this batch is:  0.0030232444405555725\n",
      "\n",
      "The classification loss after processing this batch is:  0.17997032403945923\n",
      "The representation loss after processing this batch is:  0.0025491416454315186\n",
      "\n",
      "The classification loss after processing this batch is:  0.3700058162212372\n",
      "The representation loss after processing this batch is:  0.0029808133840560913\n",
      "\n",
      "The classification loss after processing this batch is:  0.08535515516996384\n",
      "The representation loss after processing this batch is:  0.002765171229839325\n",
      "\n",
      "The classification loss after processing this batch is:  0.16574133932590485\n",
      "The representation loss after processing this batch is:  0.0023755282163619995\n",
      "\n",
      "The classification loss after processing this batch is:  0.08576574921607971\n",
      "The representation loss after processing this batch is:  0.00271393358707428\n",
      "\n",
      "The classification loss after processing this batch is:  0.06068949028849602\n",
      "The representation loss after processing this batch is:  0.00288517028093338\n",
      "\n",
      "The classification loss after processing this batch is:  0.1156429871916771\n",
      "The representation loss after processing this batch is:  0.003446713089942932\n",
      "\n",
      "The classification loss after processing this batch is:  0.11841607093811035\n",
      "The representation loss after processing this batch is:  0.0037423372268676758\n",
      "\n",
      "The classification loss after processing this batch is:  0.06848304718732834\n",
      "The representation loss after processing this batch is:  0.003011450171470642\n",
      "\n",
      "The classification loss after processing this batch is:  0.06110750511288643\n",
      "The representation loss after processing this batch is:  0.0025400668382644653\n",
      "\n",
      "The classification loss after processing this batch is:  0.1734692007303238\n",
      "The representation loss after processing this batch is:  0.002849157899618149\n",
      "\n",
      "The classification loss after processing this batch is:  0.14078696072101593\n",
      "The representation loss after processing this batch is:  0.002766937017440796\n",
      "\n",
      "The classification loss after processing this batch is:  0.08300754427909851\n",
      "The representation loss after processing this batch is:  0.002607092261314392\n",
      "\n",
      "The classification loss after processing this batch is:  0.09253363311290741\n",
      "The representation loss after processing this batch is:  0.0028578713536262512\n",
      "\n",
      "The classification loss after processing this batch is:  0.16377726197242737\n",
      "The representation loss after processing this batch is:  0.002741284668445587\n",
      "\n",
      "The classification loss after processing this batch is:  0.18607451021671295\n",
      "The representation loss after processing this batch is:  0.002727106213569641\n",
      "\n",
      "The classification loss after processing this batch is:  0.22737903892993927\n",
      "The representation loss after processing this batch is:  0.002392411231994629\n",
      "\n",
      "The classification loss after processing this batch is:  0.13034431636333466\n",
      "The representation loss after processing this batch is:  0.0028697699308395386\n",
      "\n",
      "The classification loss after processing this batch is:  0.2683422267436981\n",
      "The representation loss after processing this batch is:  0.0026976019144058228\n",
      "\n",
      "The classification loss after processing this batch is:  0.10295272618532181\n",
      "The representation loss after processing this batch is:  0.002920888364315033\n",
      "\n",
      "The classification loss after processing this batch is:  0.10055575519800186\n",
      "The representation loss after processing this batch is:  0.003250688314437866\n",
      "\n",
      "The classification loss after processing this batch is:  0.07943157106637955\n",
      "The representation loss after processing this batch is:  0.0026843249797821045\n",
      "\n",
      "The classification loss after processing this batch is:  0.07101194560527802\n",
      "The representation loss after processing this batch is:  0.0026396140456199646\n",
      "\n",
      "The classification loss after processing this batch is:  0.19388344883918762\n",
      "The representation loss after processing this batch is:  0.002827014774084091\n",
      "\n",
      "The classification loss after processing this batch is:  0.09527840465307236\n",
      "The representation loss after processing this batch is:  0.0031112730503082275\n",
      "\n",
      "The classification loss after processing this batch is:  0.06182080879807472\n",
      "The representation loss after processing this batch is:  0.0027033165097236633\n",
      "\n",
      "The classification loss after processing this batch is:  0.05946328490972519\n",
      "The representation loss after processing this batch is:  0.003323987126350403\n",
      "\n",
      "The classification loss after processing this batch is:  0.04563521593809128\n",
      "The representation loss after processing this batch is:  0.0031452924013137817\n",
      "\n",
      "The classification loss after processing this batch is:  0.06044751778244972\n",
      "The representation loss after processing this batch is:  0.0037670135498046875\n",
      "\n",
      "The classification loss after processing this batch is:  0.09414145350456238\n",
      "The representation loss after processing this batch is:  0.0029088184237480164\n",
      "\n",
      "The classification loss after processing this batch is:  0.07365025579929352\n",
      "The representation loss after processing this batch is:  0.0030310526490211487\n",
      "\n",
      "The classification loss after processing this batch is:  0.026665035635232925\n",
      "The representation loss after processing this batch is:  0.0028919577598571777\n",
      "\n",
      "The classification loss after processing this batch is:  0.0592946782708168\n",
      "The representation loss after processing this batch is:  0.0032931044697761536\n",
      "\n",
      "The classification loss after processing this batch is:  0.07759670168161392\n",
      "The representation loss after processing this batch is:  0.0037406310439109802\n",
      "\n",
      "The classification loss after processing this batch is:  0.020486561581492424\n",
      "The representation loss after processing this batch is:  0.0040852949023246765\n",
      "\n",
      "The classification loss after processing this batch is:  0.03576571121811867\n",
      "The representation loss after processing this batch is:  0.003191441297531128\n",
      "\n",
      "The classification loss after processing this batch is:  0.18733088672161102\n",
      "The representation loss after processing this batch is:  0.003040522336959839\n",
      "\n",
      "The classification loss after processing this batch is:  0.04325515031814575\n",
      "The representation loss after processing this batch is:  0.003222517669200897\n",
      "\n",
      "The classification loss after processing this batch is:  0.02325904369354248\n",
      "The representation loss after processing this batch is:  0.003123350441455841\n",
      "\n",
      "The classification loss after processing this batch is:  0.05346376821398735\n",
      "The representation loss after processing this batch is:  0.0035459697246551514\n",
      "\n",
      "The classification loss after processing this batch is:  0.03664844110608101\n",
      "The representation loss after processing this batch is:  0.0031095072627067566\n",
      "\n",
      "The classification loss after processing this batch is:  0.02903502807021141\n",
      "The representation loss after processing this batch is:  0.003037862479686737\n",
      "\n",
      "The classification loss after processing this batch is:  0.02386222593486309\n",
      "The representation loss after processing this batch is:  0.003325045108795166\n",
      "\n",
      "The classification loss after processing this batch is:  0.021997801959514618\n",
      "The representation loss after processing this batch is:  0.0037666484713554382\n",
      "\n",
      "The classification loss after processing this batch is:  0.4166554808616638\n",
      "The representation loss after processing this batch is:  0.004037395119667053\n",
      "\n",
      "The classification loss after processing this batch is:  0.32839030027389526\n",
      "The representation loss after processing this batch is:  0.0034497901797294617\n",
      "\n",
      "The classification loss after processing this batch is:  0.23934248089790344\n",
      "The representation loss after processing this batch is:  0.003966920077800751\n",
      "\n",
      "The classification loss after processing this batch is:  0.055149246007204056\n",
      "The representation loss after processing this batch is:  0.003043852746486664\n",
      "\n",
      "The classification loss after processing this batch is:  0.021200625225901604\n",
      "The representation loss after processing this batch is:  0.0035460814833641052\n",
      "\n",
      "The classification loss after processing this batch is:  0.023213164880871773\n",
      "The representation loss after processing this batch is:  0.0025796443223953247\n",
      "\n",
      "The classification loss after processing this batch is:  0.09744042903184891\n",
      "The representation loss after processing this batch is:  0.0026783794164657593\n",
      "\n",
      "The classification loss after processing this batch is:  0.3841784596443176\n",
      "The representation loss after processing this batch is:  0.0030877888202667236\n",
      "\n",
      "The classification loss after processing this batch is:  0.08192940056324005\n",
      "The representation loss after processing this batch is:  0.002941139042377472\n",
      "\n",
      "The classification loss after processing this batch is:  0.05099298804998398\n",
      "The representation loss after processing this batch is:  0.0033972784876823425\n",
      "\n",
      "The classification loss after processing this batch is:  0.0580618642270565\n",
      "The representation loss after processing this batch is:  0.003427654504776001\n",
      "\n",
      "The classification loss after processing this batch is:  0.04706374928355217\n",
      "The representation loss after processing this batch is:  0.003988221287727356\n",
      "\n",
      "The classification loss after processing this batch is:  0.1264932006597519\n",
      "The representation loss after processing this batch is:  0.0025786831974983215\n",
      "\n",
      "The classification loss after processing this batch is:  0.05176589637994766\n",
      "The representation loss after processing this batch is:  0.002448722720146179\n",
      "\n",
      "The classification loss after processing this batch is:  0.13395729660987854\n",
      "The representation loss after processing this batch is:  0.002731435000896454\n",
      "\n",
      "The classification loss after processing this batch is:  0.12739376723766327\n",
      "The representation loss after processing this batch is:  0.002532191574573517\n",
      "\n",
      "The classification loss after processing this batch is:  0.18868286907672882\n",
      "The representation loss after processing this batch is:  0.0026826485991477966\n",
      "\n",
      "The classification loss after processing this batch is:  0.0644664615392685\n",
      "The representation loss after processing this batch is:  0.0029912590980529785\n",
      "\n",
      "The classification loss after processing this batch is:  0.10173490643501282\n",
      "The representation loss after processing this batch is:  0.003138415515422821\n",
      "\n",
      "The classification loss after processing this batch is:  0.10234145075082779\n",
      "The representation loss after processing this batch is:  0.002728275954723358\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14320841431617737\n",
      "The representation loss after processing this batch is:  0.0024688318371772766\n",
      "\n",
      "The classification loss after processing this batch is:  0.11492173373699188\n",
      "The representation loss after processing this batch is:  0.002724692225456238\n",
      "\n",
      "The classification loss after processing this batch is:  0.17983338236808777\n",
      "The representation loss after processing this batch is:  0.0022596903145313263\n",
      "\n",
      "The classification loss after processing this batch is:  0.09270035475492477\n",
      "The representation loss after processing this batch is:  0.002675876021385193\n",
      "\n",
      "The classification loss after processing this batch is:  0.1338348686695099\n",
      "The representation loss after processing this batch is:  0.002901799976825714\n",
      "\n",
      "The classification loss after processing this batch is:  0.06187007203698158\n",
      "The representation loss after processing this batch is:  0.0027153342962265015\n",
      "\n",
      "The classification loss after processing this batch is:  0.29549679160118103\n",
      "The representation loss after processing this batch is:  0.002881251275539398\n",
      "\n",
      "The classification loss after processing this batch is:  0.1544695943593979\n",
      "The representation loss after processing this batch is:  0.0027686133980751038\n",
      "\n",
      "The classification loss after processing this batch is:  0.1752215027809143\n",
      "The representation loss after processing this batch is:  0.00268375501036644\n",
      "\n",
      "The classification loss after processing this batch is:  0.2614506483078003\n",
      "The representation loss after processing this batch is:  0.003351867198944092\n",
      "\n",
      "The classification loss after processing this batch is:  0.1724584698677063\n",
      "The representation loss after processing this batch is:  0.0030844733119010925\n",
      "\n",
      "The classification loss after processing this batch is:  0.07749991863965988\n",
      "The representation loss after processing this batch is:  0.003159470856189728\n",
      "\n",
      "The classification loss after processing this batch is:  0.25795575976371765\n",
      "The representation loss after processing this batch is:  0.0036531537771224976\n",
      "\n",
      "The classification loss after processing this batch is:  0.15621942281723022\n",
      "The representation loss after processing this batch is:  0.002947598695755005\n",
      "\n",
      "The classification loss after processing this batch is:  0.3170609772205353\n",
      "The representation loss after processing this batch is:  0.0027601048350334167\n",
      "\n",
      "The classification loss after processing this batch is:  0.10103496164083481\n",
      "The representation loss after processing this batch is:  0.002538572996854782\n",
      "\n",
      "The classification loss after processing this batch is:  0.07532335072755814\n",
      "The representation loss after processing this batch is:  0.0026449039578437805\n",
      "\n",
      "The classification loss after processing this batch is:  0.09605524688959122\n",
      "The representation loss after processing this batch is:  0.002478562295436859\n",
      "\n",
      "The classification loss after processing this batch is:  0.1340682953596115\n",
      "The representation loss after processing this batch is:  0.0024986006319522858\n",
      "\n",
      "The classification loss after processing this batch is:  0.08811289817094803\n",
      "The representation loss after processing this batch is:  0.002718716859817505\n",
      "\n",
      "The classification loss after processing this batch is:  0.06295511871576309\n",
      "The representation loss after processing this batch is:  0.0026945099234580994\n",
      "\n",
      "The classification loss after processing this batch is:  0.05537169799208641\n",
      "The representation loss after processing this batch is:  0.0028681680560112\n",
      "\n",
      "The classification loss after processing this batch is:  0.05601564422249794\n",
      "The representation loss after processing this batch is:  0.0025617480278015137\n",
      "\n",
      "The classification loss after processing this batch is:  0.08109426498413086\n",
      "The representation loss after processing this batch is:  0.0027829036116600037\n",
      "\n",
      "The classification loss after processing this batch is:  0.18430116772651672\n",
      "The representation loss after processing this batch is:  0.0028615817427635193\n",
      "\n",
      "The classification loss after processing this batch is:  0.0991513803601265\n",
      "The representation loss after processing this batch is:  0.0031230151653289795\n",
      "\n",
      "The classification loss after processing this batch is:  0.13352875411510468\n",
      "The representation loss after processing this batch is:  0.0023888573050498962\n",
      "\n",
      "The classification loss after processing this batch is:  0.05981818959116936\n",
      "The representation loss after processing this batch is:  0.002902805805206299\n",
      "\n",
      "The classification loss after processing this batch is:  0.0685674250125885\n",
      "The representation loss after processing this batch is:  0.002810552716255188\n",
      "\n",
      "The classification loss after processing this batch is:  0.12632949650287628\n",
      "The representation loss after processing this batch is:  0.0027496814727783203\n",
      "\n",
      "The classification loss after processing this batch is:  0.05490767955780029\n",
      "The representation loss after processing this batch is:  0.0029921308159828186\n",
      "\n",
      "The classification loss after processing this batch is:  0.07142341881990433\n",
      "The representation loss after processing this batch is:  0.0027348846197128296\n",
      "\n",
      "The classification loss after processing this batch is:  0.18153490126132965\n",
      "The representation loss after processing this batch is:  0.003096841275691986\n",
      "\n",
      "The classification loss after processing this batch is:  0.09744728356599808\n",
      "The representation loss after processing this batch is:  0.0027413740754127502\n",
      "\n",
      "The classification loss after processing this batch is:  0.11153459548950195\n",
      "The representation loss after processing this batch is:  0.0025441981852054596\n",
      "\n",
      "The classification loss after processing this batch is:  0.1431123912334442\n",
      "The representation loss after processing this batch is:  0.0025362521409988403\n",
      "\n",
      "The classification loss after processing this batch is:  0.12406177818775177\n",
      "The representation loss after processing this batch is:  0.002570696175098419\n",
      "\n",
      "The classification loss after processing this batch is:  0.13440993428230286\n",
      "The representation loss after processing this batch is:  0.0023824721574783325\n",
      "\n",
      "The classification loss after processing this batch is:  0.2108646035194397\n",
      "The representation loss after processing this batch is:  0.002713974565267563\n",
      "\n",
      "The classification loss after processing this batch is:  0.06166936457157135\n",
      "The representation loss after processing this batch is:  0.002711467444896698\n",
      "\n",
      "The classification loss after processing this batch is:  0.14521153271198273\n",
      "The representation loss after processing this batch is:  0.0029436349868774414\n",
      "\n",
      "The classification loss after processing this batch is:  0.0874839648604393\n",
      "The representation loss after processing this batch is:  0.0025640875101089478\n",
      "\n",
      "The classification loss after processing this batch is:  0.13578693568706512\n",
      "The representation loss after processing this batch is:  0.002779841423034668\n",
      "\n",
      "The classification loss after processing this batch is:  0.11726651340723038\n",
      "The representation loss after processing this batch is:  0.003086000680923462\n",
      "\n",
      "The classification loss after processing this batch is:  0.06880304217338562\n",
      "The representation loss after processing this batch is:  0.002817608416080475\n",
      "\n",
      "The classification loss after processing this batch is:  0.09683017432689667\n",
      "The representation loss after processing this batch is:  0.00291530042886734\n",
      "\n",
      "The classification loss after processing this batch is:  0.11507849395275116\n",
      "The representation loss after processing this batch is:  0.0027898550033569336\n",
      "\n",
      "The classification loss after processing this batch is:  0.12751923501491547\n",
      "The representation loss after processing this batch is:  0.002713598310947418\n",
      "\n",
      "The classification loss after processing this batch is:  0.16056127846240997\n",
      "The representation loss after processing this batch is:  0.0024845823645591736\n",
      "\n",
      "The classification loss after processing this batch is:  0.09142634272575378\n",
      "The representation loss after processing this batch is:  0.003148972988128662\n",
      "\n",
      "The classification loss after processing this batch is:  0.14988106489181519\n",
      "The representation loss after processing this batch is:  0.0028148069977760315\n",
      "\n",
      "The classification loss after processing this batch is:  0.08745848387479782\n",
      "The representation loss after processing this batch is:  0.0026583895087242126\n",
      "\n",
      "The classification loss after processing this batch is:  0.058706771582365036\n",
      "The representation loss after processing this batch is:  0.0025483891367912292\n",
      "\n",
      "The classification loss after processing this batch is:  0.15653446316719055\n",
      "The representation loss after processing this batch is:  0.002663753926753998\n",
      "\n",
      "The classification loss after processing this batch is:  0.13378556072711945\n",
      "The representation loss after processing this batch is:  0.002770371735095978\n",
      "\n",
      "The classification loss after processing this batch is:  0.09698878228664398\n",
      "The representation loss after processing this batch is:  0.002713385969400406\n",
      "\n",
      "The classification loss after processing this batch is:  0.09846412390470505\n",
      "The representation loss after processing this batch is:  0.0025882795453071594\n",
      "\n",
      "The classification loss after processing this batch is:  0.07041826099157333\n",
      "The representation loss after processing this batch is:  0.0024567320942878723\n",
      "\n",
      "The classification loss after processing this batch is:  0.12618085741996765\n",
      "The representation loss after processing this batch is:  0.0029272139072418213\n",
      "\n",
      "The classification loss after processing this batch is:  0.14522896707057953\n",
      "The representation loss after processing this batch is:  0.0023959651589393616\n",
      "\n",
      "The classification loss after processing this batch is:  0.06417031586170197\n",
      "The representation loss after processing this batch is:  0.0024514347314834595\n",
      "\n",
      "The classification loss after processing this batch is:  0.17220796644687653\n",
      "The representation loss after processing this batch is:  0.0029776059091091156\n",
      "\n",
      "The classification loss after processing this batch is:  0.11830833554267883\n",
      "The representation loss after processing this batch is:  0.0025754161179065704\n",
      "\n",
      "The classification loss after processing this batch is:  0.09694693982601166\n",
      "The representation loss after processing this batch is:  0.00260191410779953\n",
      "\n",
      "The classification loss after processing this batch is:  0.09876175224781036\n",
      "The representation loss after processing this batch is:  0.002377718687057495\n",
      "\n",
      "The classification loss after processing this batch is:  0.07738197594881058\n",
      "The representation loss after processing this batch is:  0.0029627829790115356\n",
      "\n",
      "The classification loss after processing this batch is:  0.09994277358055115\n",
      "The representation loss after processing this batch is:  0.0023091621696949005\n",
      "\n",
      "The classification loss after processing this batch is:  0.16837318241596222\n",
      "The representation loss after processing this batch is:  0.0027729198336601257\n",
      "\n",
      "The classification loss after processing this batch is:  0.07092738896608353\n",
      "The representation loss after processing this batch is:  0.0025230348110198975\n",
      "\n",
      "The classification loss after processing this batch is:  0.26856377720832825\n",
      "The representation loss after processing this batch is:  0.002686046063899994\n",
      "\n",
      "The classification loss after processing this batch is:  0.12870033085346222\n",
      "The representation loss after processing this batch is:  0.0026171840727329254\n",
      "\n",
      "The classification loss after processing this batch is:  0.09618201106786728\n",
      "The representation loss after processing this batch is:  0.003238484263420105\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.11463489383459091\n",
      "The representation loss after processing this batch is:  0.002570211887359619\n",
      "\n",
      "The classification loss after processing this batch is:  0.10446980595588684\n",
      "The representation loss after processing this batch is:  0.002861201763153076\n",
      "\n",
      "The classification loss after processing this batch is:  0.260759562253952\n",
      "The representation loss after processing this batch is:  0.003142639994621277\n",
      "\n",
      "The classification loss after processing this batch is:  0.12657293677330017\n",
      "The representation loss after processing this batch is:  0.002781994640827179\n",
      "\n",
      "The classification loss after processing this batch is:  0.13751620054244995\n",
      "The representation loss after processing this batch is:  0.0023254379630088806\n",
      "\n",
      "The classification loss after processing this batch is:  0.2761844992637634\n",
      "The representation loss after processing this batch is:  0.002641439437866211\n",
      "\n",
      "The classification loss after processing this batch is:  0.13385657966136932\n",
      "The representation loss after processing this batch is:  0.0024916082620620728\n",
      "\n",
      "The classification loss after processing this batch is:  0.05991141498088837\n",
      "The representation loss after processing this batch is:  0.002718411386013031\n",
      "\n",
      "The classification loss after processing this batch is:  0.14744454622268677\n",
      "The representation loss after processing this batch is:  0.0026323236525058746\n",
      "\n",
      "The classification loss after processing this batch is:  0.1698502153158188\n",
      "The representation loss after processing this batch is:  0.0024526119232177734\n",
      "\n",
      "The classification loss after processing this batch is:  0.1311188042163849\n",
      "The representation loss after processing this batch is:  0.0028032884001731873\n",
      "\n",
      "The classification loss after processing this batch is:  0.06944416463375092\n",
      "The representation loss after processing this batch is:  0.0023664161562919617\n",
      "\n",
      "The classification loss after processing this batch is:  0.13906189799308777\n",
      "The representation loss after processing this batch is:  0.0024624690413475037\n",
      "\n",
      "The classification loss after processing this batch is:  0.14810582995414734\n",
      "The representation loss after processing this batch is:  0.002527199685573578\n",
      "\n",
      "The classification loss after processing this batch is:  0.17663833498954773\n",
      "The representation loss after processing this batch is:  0.0030549094080924988\n",
      "\n",
      "The classification loss after processing this batch is:  0.18298299610614777\n",
      "The representation loss after processing this batch is:  0.0024602413177490234\n",
      "\n",
      "The classification loss after processing this batch is:  0.1437809318304062\n",
      "The representation loss after processing this batch is:  0.0029085278511047363\n",
      "\n",
      "The classification loss after processing this batch is:  0.14205344021320343\n",
      "The representation loss after processing this batch is:  0.0031101107597351074\n",
      "\n",
      "The classification loss after processing this batch is:  0.07772650569677353\n",
      "The representation loss after processing this batch is:  0.0030233487486839294\n",
      "\n",
      "The classification loss after processing this batch is:  0.09332086890935898\n",
      "The representation loss after processing this batch is:  0.0026286467909812927\n",
      "\n",
      "The classification loss after processing this batch is:  0.05092070251703262\n",
      "The representation loss after processing this batch is:  0.0026209428906440735\n",
      "\n",
      "The classification loss after processing this batch is:  0.14546267688274384\n",
      "The representation loss after processing this batch is:  0.002910800278186798\n",
      "\n",
      "The classification loss after processing this batch is:  0.08029662072658539\n",
      "The representation loss after processing this batch is:  0.002899087965488434\n",
      "\n",
      "The classification loss after processing this batch is:  0.24968887865543365\n",
      "The representation loss after processing this batch is:  0.0030743777751922607\n",
      "\n",
      "The classification loss after processing this batch is:  0.23859286308288574\n",
      "The representation loss after processing this batch is:  0.002957068383693695\n",
      "\n",
      "The classification loss after processing this batch is:  0.09908003360033035\n",
      "The representation loss after processing this batch is:  0.0028287097811698914\n",
      "\n",
      "The classification loss after processing this batch is:  0.10293016582727432\n",
      "The representation loss after processing this batch is:  0.0031074509024620056\n",
      "\n",
      "The classification loss after processing this batch is:  0.12161470949649811\n",
      "The representation loss after processing this batch is:  0.002512957900762558\n",
      "\n",
      "The classification loss after processing this batch is:  0.05156846344470978\n",
      "The representation loss after processing this batch is:  0.0028840526938438416\n",
      "\n",
      "The classification loss after processing this batch is:  0.06605991721153259\n",
      "The representation loss after processing this batch is:  0.002807609736919403\n",
      "\n",
      "The classification loss after processing this batch is:  0.14092309772968292\n",
      "The representation loss after processing this batch is:  0.002513982355594635\n",
      "\n",
      "The classification loss after processing this batch is:  0.0857013687491417\n",
      "The representation loss after processing this batch is:  0.0032487958669662476\n",
      "\n",
      "The classification loss after processing this batch is:  0.09793777018785477\n",
      "The representation loss after processing this batch is:  0.0028749406337738037\n",
      "\n",
      "The classification loss after processing this batch is:  0.2267094999551773\n",
      "The representation loss after processing this batch is:  0.0034970268607139587\n",
      "\n",
      "The classification loss after processing this batch is:  0.21578402817249298\n",
      "The representation loss after processing this batch is:  0.0025696158409118652\n",
      "\n",
      "The classification loss after processing this batch is:  0.1188245564699173\n",
      "The representation loss after processing this batch is:  0.0028475821018218994\n",
      "\n",
      "The classification loss after processing this batch is:  0.21678335964679718\n",
      "The representation loss after processing this batch is:  0.0030612051486968994\n",
      "\n",
      "The classification loss after processing this batch is:  0.14035102725028992\n",
      "The representation loss after processing this batch is:  0.0026305168867111206\n",
      "\n",
      "The classification loss after processing this batch is:  0.06854470819234848\n",
      "The representation loss after processing this batch is:  0.002737082540988922\n",
      "\n",
      "The classification loss after processing this batch is:  0.17769894003868103\n",
      "The representation loss after processing this batch is:  0.0026926957070827484\n",
      "\n",
      "The classification loss after processing this batch is:  0.36466771364212036\n",
      "The representation loss after processing this batch is:  0.003260485827922821\n",
      "\n",
      "The classification loss after processing this batch is:  0.16017886996269226\n",
      "The representation loss after processing this batch is:  0.003297213464975357\n",
      "\n",
      "The classification loss after processing this batch is:  0.13198159635066986\n",
      "The representation loss after processing this batch is:  0.0031117722392082214\n",
      "\n",
      "The classification loss after processing this batch is:  0.08558489382266998\n",
      "The representation loss after processing this batch is:  0.003013402223587036\n",
      "\n",
      "The classification loss after processing this batch is:  0.0729258805513382\n",
      "The representation loss after processing this batch is:  0.003018610179424286\n",
      "\n",
      "The classification loss after processing this batch is:  0.1273164600133896\n",
      "The representation loss after processing this batch is:  0.0028524249792099\n",
      "\n",
      "The classification loss after processing this batch is:  0.10193910449743271\n",
      "The representation loss after processing this batch is:  0.0029188767075538635\n",
      "\n",
      "The classification loss after processing this batch is:  0.12955491244792938\n",
      "The representation loss after processing this batch is:  0.002577446401119232\n",
      "\n",
      "The classification loss after processing this batch is:  0.12198556214570999\n",
      "The representation loss after processing this batch is:  0.002777963876724243\n",
      "\n",
      "The classification loss after processing this batch is:  0.22311319410800934\n",
      "The representation loss after processing this batch is:  0.0029746517539024353\n",
      "\n",
      "The classification loss after processing this batch is:  0.08822017163038254\n",
      "The representation loss after processing this batch is:  0.002401340752840042\n",
      "\n",
      "The classification loss after processing this batch is:  0.1188608929514885\n",
      "The representation loss after processing this batch is:  0.0023788362741470337\n",
      "\n",
      "The classification loss after processing this batch is:  0.10740698873996735\n",
      "The representation loss after processing this batch is:  0.0023185834288597107\n",
      "\n",
      "The classification loss after processing this batch is:  0.12599141895771027\n",
      "The representation loss after processing this batch is:  0.0026299282908439636\n",
      "\n",
      "The classification loss after processing this batch is:  0.09543894231319427\n",
      "The representation loss after processing this batch is:  0.002650626003742218\n",
      "\n",
      "The classification loss after processing this batch is:  0.18441906571388245\n",
      "The representation loss after processing this batch is:  0.002686507999897003\n",
      "\n",
      "The classification loss after processing this batch is:  0.1679641753435135\n",
      "The representation loss after processing this batch is:  0.002763614058494568\n",
      "\n",
      "The classification loss after processing this batch is:  0.17724546790122986\n",
      "The representation loss after processing this batch is:  0.002544194459915161\n",
      "\n",
      "The classification loss after processing this batch is:  0.08259567618370056\n",
      "The representation loss after processing this batch is:  0.0027359500527381897\n",
      "\n",
      "The classification loss after processing this batch is:  0.20678125321865082\n",
      "The representation loss after processing this batch is:  0.0027654170989990234\n",
      "\n",
      "The classification loss after processing this batch is:  0.17334552109241486\n",
      "The representation loss after processing this batch is:  0.002808157354593277\n",
      "\n",
      "The classification loss after processing this batch is:  0.16668827831745148\n",
      "The representation loss after processing this batch is:  0.002698346972465515\n",
      "\n",
      "The classification loss after processing this batch is:  0.07927336543798447\n",
      "The representation loss after processing this batch is:  0.0029723942279815674\n",
      "\n",
      "The classification loss after processing this batch is:  0.10555073618888855\n",
      "The representation loss after processing this batch is:  0.003487303853034973\n",
      "\n",
      "The classification loss after processing this batch is:  0.2671307623386383\n",
      "The representation loss after processing this batch is:  0.0027313828468322754\n",
      "\n",
      "The classification loss after processing this batch is:  0.24346575140953064\n",
      "The representation loss after processing this batch is:  0.0025384537875652313\n",
      "\n",
      "The classification loss after processing this batch is:  0.24105459451675415\n",
      "The representation loss after processing this batch is:  0.00307614728808403\n",
      "\n",
      "The classification loss after processing this batch is:  0.3194555640220642\n",
      "The representation loss after processing this batch is:  0.002690553665161133\n",
      "\n",
      "The classification loss after processing this batch is:  0.24384646117687225\n",
      "The representation loss after processing this batch is:  0.0025217533111572266\n",
      "\n",
      "The classification loss after processing this batch is:  0.07043696939945221\n",
      "The representation loss after processing this batch is:  0.0026213601231575012\n",
      "\n",
      "The classification loss after processing this batch is:  0.08008117973804474\n",
      "The representation loss after processing this batch is:  0.002661660313606262\n",
      "\n",
      "The classification loss after processing this batch is:  0.09847608953714371\n",
      "The representation loss after processing this batch is:  0.003018803894519806\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14413762092590332\n",
      "The representation loss after processing this batch is:  0.0035040155053138733\n",
      "\n",
      "The classification loss after processing this batch is:  0.0438244566321373\n",
      "The representation loss after processing this batch is:  0.0030514076352119446\n",
      "\n",
      "The classification loss after processing this batch is:  0.18525156378746033\n",
      "The representation loss after processing this batch is:  0.003575824201107025\n",
      "\n",
      "The classification loss after processing this batch is:  0.15114109218120575\n",
      "The representation loss after processing this batch is:  0.002667531371116638\n",
      "\n",
      "The classification loss after processing this batch is:  0.1438031643629074\n",
      "The representation loss after processing this batch is:  0.0027846917510032654\n",
      "\n",
      "The classification loss after processing this batch is:  0.20598530769348145\n",
      "The representation loss after processing this batch is:  0.002795964479446411\n",
      "\n",
      "The classification loss after processing this batch is:  0.10938187688589096\n",
      "The representation loss after processing this batch is:  0.0030165165662765503\n",
      "\n",
      "The classification loss after processing this batch is:  0.15886618196964264\n",
      "The representation loss after processing this batch is:  0.0034787654876708984\n",
      "\n",
      "The classification loss after processing this batch is:  0.17434094846248627\n",
      "The representation loss after processing this batch is:  0.0030766576528549194\n",
      "\n",
      "The classification loss after processing this batch is:  0.12538877129554749\n",
      "The representation loss after processing this batch is:  0.0033800527453422546\n",
      "\n",
      "The classification loss after processing this batch is:  0.12632542848587036\n",
      "The representation loss after processing this batch is:  0.002464406192302704\n",
      "\n",
      "The classification loss after processing this batch is:  0.07589419186115265\n",
      "The representation loss after processing this batch is:  0.0026821792125701904\n",
      "\n",
      "The classification loss after processing this batch is:  0.053103916347026825\n",
      "The representation loss after processing this batch is:  0.002708040177822113\n",
      "\n",
      "The classification loss after processing this batch is:  0.08894465118646622\n",
      "The representation loss after processing this batch is:  0.0025975778698921204\n",
      "\n",
      "The classification loss after processing this batch is:  0.06889534741640091\n",
      "The representation loss after processing this batch is:  0.0025514066219329834\n",
      "\n",
      "The classification loss after processing this batch is:  0.09242434799671173\n",
      "The representation loss after processing this batch is:  0.0023058541119098663\n",
      "\n",
      "The classification loss after processing this batch is:  0.11719263345003128\n",
      "The representation loss after processing this batch is:  0.0026190578937530518\n",
      "\n",
      "The classification loss after processing this batch is:  0.1287195384502411\n",
      "The representation loss after processing this batch is:  0.0025464072823524475\n",
      "\n",
      "The classification loss after processing this batch is:  0.3558245897293091\n",
      "The representation loss after processing this batch is:  0.0029642581939697266\n",
      "\n",
      "The classification loss after processing this batch is:  0.22788681089878082\n",
      "The representation loss after processing this batch is:  0.0030537769198417664\n",
      "\n",
      "The classification loss after processing this batch is:  0.0981198400259018\n",
      "The representation loss after processing this batch is:  0.002592936158180237\n",
      "\n",
      "The classification loss after processing this batch is:  0.08516981452703476\n",
      "The representation loss after processing this batch is:  0.0029314830899238586\n",
      "\n",
      "The classification loss after processing this batch is:  0.07365427166223526\n",
      "The representation loss after processing this batch is:  0.0029355958104133606\n",
      "\n",
      "The classification loss after processing this batch is:  0.08549559861421585\n",
      "The representation loss after processing this batch is:  0.002737283706665039\n",
      "\n",
      "The classification loss after processing this batch is:  0.03477425500750542\n",
      "The representation loss after processing this batch is:  0.0029242709279060364\n",
      "\n",
      "The classification loss after processing this batch is:  0.09672530740499496\n",
      "The representation loss after processing this batch is:  0.002739451825618744\n",
      "\n",
      "The classification loss after processing this batch is:  0.11106452345848083\n",
      "The representation loss after processing this batch is:  0.0025780871510505676\n",
      "\n",
      "The classification loss after processing this batch is:  0.22840990126132965\n",
      "The representation loss after processing this batch is:  0.002707410603761673\n",
      "\n",
      "The classification loss after processing this batch is:  0.09985236078500748\n",
      "The representation loss after processing this batch is:  0.002493433654308319\n",
      "\n",
      "The classification loss after processing this batch is:  0.07375700771808624\n",
      "The representation loss after processing this batch is:  0.0026016607880592346\n",
      "\n",
      "The classification loss after processing this batch is:  0.05438407510519028\n",
      "The representation loss after processing this batch is:  0.0026747286319732666\n",
      "\n",
      "The classification loss after processing this batch is:  0.2540052533149719\n",
      "The representation loss after processing this batch is:  0.002676602452993393\n",
      "\n",
      "The classification loss after processing this batch is:  0.0936991423368454\n",
      "The representation loss after processing this batch is:  0.0027857571840286255\n",
      "\n",
      "The classification loss after processing this batch is:  0.08165943622589111\n",
      "The representation loss after processing this batch is:  0.0027048736810684204\n",
      "\n",
      "The classification loss after processing this batch is:  0.12354481220245361\n",
      "The representation loss after processing this batch is:  0.002930067479610443\n",
      "\n",
      "The classification loss after processing this batch is:  0.10999471694231033\n",
      "The representation loss after processing this batch is:  0.002292640507221222\n",
      "\n",
      "The classification loss after processing this batch is:  0.061933353543281555\n",
      "The representation loss after processing this batch is:  0.0024703145027160645\n",
      "\n",
      "The classification loss after processing this batch is:  0.12194684147834778\n",
      "The representation loss after processing this batch is:  0.002520546317100525\n",
      "\n",
      "The classification loss after processing this batch is:  0.08125089854001999\n",
      "The representation loss after processing this batch is:  0.00261552631855011\n",
      "\n",
      "The classification loss after processing this batch is:  0.09166530519723892\n",
      "The representation loss after processing this batch is:  0.0027526766061782837\n",
      "\n",
      "The classification loss after processing this batch is:  0.17156842350959778\n",
      "The representation loss after processing this batch is:  0.002574615180492401\n",
      "\n",
      "The classification loss after processing this batch is:  0.1760779470205307\n",
      "The representation loss after processing this batch is:  0.00276261568069458\n",
      "\n",
      "The classification loss after processing this batch is:  0.1711326241493225\n",
      "The representation loss after processing this batch is:  0.002603098750114441\n",
      "\n",
      "The classification loss after processing this batch is:  0.17197729647159576\n",
      "The representation loss after processing this batch is:  0.0025056377053260803\n",
      "\n",
      "The classification loss after processing this batch is:  0.09133274108171463\n",
      "The representation loss after processing this batch is:  0.0027176514267921448\n",
      "\n",
      "The classification loss after processing this batch is:  0.16130512952804565\n",
      "The representation loss after processing this batch is:  0.0026696249842643738\n",
      "\n",
      "The classification loss after processing this batch is:  0.0947718396782875\n",
      "The representation loss after processing this batch is:  0.0031369850039482117\n",
      "\n",
      "The classification loss after processing this batch is:  0.13518203794956207\n",
      "The representation loss after processing this batch is:  0.002744525671005249\n",
      "\n",
      "The classification loss after processing this batch is:  0.07047920674085617\n",
      "The representation loss after processing this batch is:  0.002424493432044983\n",
      "\n",
      "The classification loss after processing this batch is:  0.17509695887565613\n",
      "The representation loss after processing this batch is:  0.002456486225128174\n",
      "\n",
      "The classification loss after processing this batch is:  0.08660455048084259\n",
      "The representation loss after processing this batch is:  0.002812609076499939\n",
      "\n",
      "The classification loss after processing this batch is:  0.11731370538473129\n",
      "The representation loss after processing this batch is:  0.00237298384308815\n",
      "\n",
      "The classification loss after processing this batch is:  0.11937499791383743\n",
      "The representation loss after processing this batch is:  0.0025013014674186707\n",
      "\n",
      "The classification loss after processing this batch is:  0.11078284680843353\n",
      "The representation loss after processing this batch is:  0.0024955496191978455\n",
      "\n",
      "The classification loss after processing this batch is:  0.15933962166309357\n",
      "The representation loss after processing this batch is:  0.0023666173219680786\n",
      "\n",
      "The classification loss after processing this batch is:  0.1215386837720871\n",
      "The representation loss after processing this batch is:  0.002402976155281067\n",
      "\n",
      "The classification loss after processing this batch is:  0.19123651087284088\n",
      "The representation loss after processing this batch is:  0.002427097409963608\n",
      "\n",
      "The classification loss after processing this batch is:  0.19289728999137878\n",
      "The representation loss after processing this batch is:  0.0025636106729507446\n",
      "\n",
      "The classification loss after processing this batch is:  0.2771172523498535\n",
      "The representation loss after processing this batch is:  0.0026264190673828125\n",
      "\n",
      "The classification loss after processing this batch is:  0.2018825113773346\n",
      "The representation loss after processing this batch is:  0.002264834940433502\n",
      "\n",
      "The classification loss after processing this batch is:  0.0744163990020752\n",
      "The representation loss after processing this batch is:  0.002675369381904602\n",
      "\n",
      "The classification loss after processing this batch is:  0.17159786820411682\n",
      "The representation loss after processing this batch is:  0.002734355628490448\n",
      "\n",
      "The classification loss after processing this batch is:  0.1112898513674736\n",
      "The representation loss after processing this batch is:  0.0027205049991607666\n",
      "\n",
      "The classification loss after processing this batch is:  0.10204489529132843\n",
      "The representation loss after processing this batch is:  0.0030113384127616882\n",
      "\n",
      "The classification loss after processing this batch is:  0.19787877798080444\n",
      "The representation loss after processing this batch is:  0.003157377243041992\n",
      "\n",
      "The classification loss after processing this batch is:  0.20556704699993134\n",
      "The representation loss after processing this batch is:  0.0029183179140090942\n",
      "\n",
      "The classification loss after processing this batch is:  0.3119681477546692\n",
      "The representation loss after processing this batch is:  0.0027162283658981323\n",
      "\n",
      "The classification loss after processing this batch is:  0.15891383588314056\n",
      "The representation loss after processing this batch is:  0.00286092609167099\n",
      "\n",
      "The classification loss after processing this batch is:  0.08032382279634476\n",
      "The representation loss after processing this batch is:  0.0028771907091140747\n",
      "\n",
      "The classification loss after processing this batch is:  0.09550926089286804\n",
      "The representation loss after processing this batch is:  0.0027565062046051025\n",
      "\n",
      "The classification loss after processing this batch is:  0.19692745804786682\n",
      "The representation loss after processing this batch is:  0.0024288706481456757\n",
      "\n",
      "The classification loss after processing this batch is:  0.09593432396650314\n",
      "The representation loss after processing this batch is:  0.0027215704321861267\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.11468314379453659\n",
      "The representation loss after processing this batch is:  0.0024806782603263855\n",
      "\n",
      "The classification loss after processing this batch is:  0.08390220254659653\n",
      "The representation loss after processing this batch is:  0.002881750464439392\n",
      "\n",
      "The classification loss after processing this batch is:  0.03347336873412132\n",
      "The representation loss after processing this batch is:  0.0026471540331840515\n",
      "\n",
      "The classification loss after processing this batch is:  0.14733019471168518\n",
      "The representation loss after processing this batch is:  0.002816181629896164\n",
      "\n",
      "The classification loss after processing this batch is:  0.13435028493404388\n",
      "The representation loss after processing this batch is:  0.0030446499586105347\n",
      "\n",
      "The classification loss after processing this batch is:  0.1712789237499237\n",
      "The representation loss after processing this batch is:  0.0026164017617702484\n",
      "\n",
      "The classification loss after processing this batch is:  0.1624443382024765\n",
      "The representation loss after processing this batch is:  0.0023093298077583313\n",
      "\n",
      "The classification loss after processing this batch is:  0.1291179060935974\n",
      "The representation loss after processing this batch is:  0.0026881471276283264\n",
      "\n",
      "The classification loss after processing this batch is:  0.1488499641418457\n",
      "The representation loss after processing this batch is:  0.002654053270816803\n",
      "\n",
      "The classification loss after processing this batch is:  0.1367146223783493\n",
      "The representation loss after processing this batch is:  0.0026008114218711853\n",
      "\n",
      "The classification loss after processing this batch is:  0.14285731315612793\n",
      "The representation loss after processing this batch is:  0.0029844045639038086\n",
      "\n",
      "The classification loss after processing this batch is:  0.15780028700828552\n",
      "The representation loss after processing this batch is:  0.003001399338245392\n",
      "\n",
      "The classification loss after processing this batch is:  0.15428310632705688\n",
      "The representation loss after processing this batch is:  0.0031512975692749023\n",
      "\n",
      "The classification loss after processing this batch is:  0.13218072056770325\n",
      "The representation loss after processing this batch is:  0.0024165138602256775\n",
      "\n",
      "The classification loss after processing this batch is:  0.21399764716625214\n",
      "The representation loss after processing this batch is:  0.0025859661400318146\n",
      "\n",
      "The classification loss after processing this batch is:  0.2080756276845932\n",
      "The representation loss after processing this batch is:  0.0029051750898361206\n",
      "\n",
      "The classification loss after processing this batch is:  0.08691229671239853\n",
      "The representation loss after processing this batch is:  0.002340443432331085\n",
      "\n",
      "The classification loss after processing this batch is:  0.12210024893283844\n",
      "The representation loss after processing this batch is:  0.003070477396249771\n",
      "\n",
      "The classification loss after processing this batch is:  0.13234347105026245\n",
      "The representation loss after processing this batch is:  0.0027835220098495483\n",
      "\n",
      "The classification loss after processing this batch is:  0.13495168089866638\n",
      "The representation loss after processing this batch is:  0.002674572169780731\n",
      "\n",
      "The classification loss after processing this batch is:  0.1818903088569641\n",
      "The representation loss after processing this batch is:  0.0032195299863815308\n",
      "\n",
      "The classification loss after processing this batch is:  0.26556873321533203\n",
      "The representation loss after processing this batch is:  0.0030662789940834045\n",
      "\n",
      "The classification loss after processing this batch is:  0.24939166009426117\n",
      "The representation loss after processing this batch is:  0.003244176506996155\n",
      "\n",
      "The classification loss after processing this batch is:  0.16316673159599304\n",
      "The representation loss after processing this batch is:  0.0028188899159431458\n",
      "\n",
      "The classification loss after processing this batch is:  0.13713496923446655\n",
      "The representation loss after processing this batch is:  0.0027422532439231873\n",
      "\n",
      "The classification loss after processing this batch is:  0.09230257570743561\n",
      "The representation loss after processing this batch is:  0.0032777786254882812\n",
      "\n",
      "The classification loss after processing this batch is:  0.06863126158714294\n",
      "The representation loss after processing this batch is:  0.0028144419193267822\n",
      "\n",
      "The classification loss after processing this batch is:  0.18144115805625916\n",
      "The representation loss after processing this batch is:  0.002829167991876602\n",
      "\n",
      "The classification loss after processing this batch is:  0.1453840285539627\n",
      "The representation loss after processing this batch is:  0.0025551915168762207\n",
      "\n",
      "The classification loss after processing this batch is:  0.08831210434436798\n",
      "The representation loss after processing this batch is:  0.0025389567017555237\n",
      "\n",
      "The classification loss after processing this batch is:  0.13179728388786316\n",
      "The representation loss after processing this batch is:  0.0027884766459465027\n",
      "\n",
      "The classification loss after processing this batch is:  0.11800505220890045\n",
      "The representation loss after processing this batch is:  0.0031859949231147766\n",
      "\n",
      "The classification loss after processing this batch is:  0.18499727547168732\n",
      "The representation loss after processing this batch is:  0.0027010105550289154\n",
      "\n",
      "The classification loss after processing this batch is:  0.11997833102941513\n",
      "The representation loss after processing this batch is:  0.002746671438217163\n",
      "\n",
      "The classification loss after processing this batch is:  0.0988030731678009\n",
      "The representation loss after processing this batch is:  0.002586260437965393\n",
      "\n",
      "The classification loss after processing this batch is:  0.05564095452427864\n",
      "The representation loss after processing this batch is:  0.0026331469416618347\n",
      "\n",
      "The classification loss after processing this batch is:  0.11871783435344696\n",
      "The representation loss after processing this batch is:  0.0025149881839752197\n",
      "\n",
      "The classification loss after processing this batch is:  0.10757659375667572\n",
      "The representation loss after processing this batch is:  0.0023555196821689606\n",
      "\n",
      "The classification loss after processing this batch is:  0.4383234679698944\n",
      "The representation loss after processing this batch is:  0.002820424735546112\n",
      "\n",
      "The classification loss after processing this batch is:  0.11191096901893616\n",
      "The representation loss after processing this batch is:  0.0025936588644981384\n",
      "\n",
      "The classification loss after processing this batch is:  0.24453949928283691\n",
      "The representation loss after processing this batch is:  0.002464462071657181\n",
      "\n",
      "The classification loss after processing this batch is:  0.2656176686286926\n",
      "The representation loss after processing this batch is:  0.0029084309935569763\n",
      "\n",
      "The classification loss after processing this batch is:  0.10412658005952835\n",
      "The representation loss after processing this batch is:  0.0027296990156173706\n",
      "\n",
      "The classification loss after processing this batch is:  0.25204306840896606\n",
      "The representation loss after processing this batch is:  0.0031449422240257263\n",
      "\n",
      "The classification loss after processing this batch is:  0.1308090090751648\n",
      "The representation loss after processing this batch is:  0.0027833878993988037\n",
      "\n",
      "The classification loss after processing this batch is:  0.22660407423973083\n",
      "The representation loss after processing this batch is:  0.0025642029941082\n",
      "\n",
      "The classification loss after processing this batch is:  0.06833195686340332\n",
      "The representation loss after processing this batch is:  0.0025115832686424255\n",
      "\n",
      "The classification loss after processing this batch is:  0.08526333421468735\n",
      "The representation loss after processing this batch is:  0.00281360000371933\n",
      "\n",
      "The classification loss after processing this batch is:  0.06990435719490051\n",
      "The representation loss after processing this batch is:  0.0029997751116752625\n",
      "\n",
      "The classification loss after processing this batch is:  0.051968012005090714\n",
      "The representation loss after processing this batch is:  0.0026124566793441772\n",
      "\n",
      "The classification loss after processing this batch is:  0.10868211090564728\n",
      "The representation loss after processing this batch is:  0.0027275830507278442\n",
      "\n",
      "The classification loss after processing this batch is:  0.07810630649328232\n",
      "The representation loss after processing this batch is:  0.0023675039410591125\n",
      "\n",
      "The classification loss after processing this batch is:  0.14135953783988953\n",
      "The representation loss after processing this batch is:  0.0030943378806114197\n",
      "\n",
      "The classification loss after processing this batch is:  0.08054345101118088\n",
      "The representation loss after processing this batch is:  0.0030032098293304443\n",
      "\n",
      "The classification loss after processing this batch is:  0.09342627227306366\n",
      "The representation loss after processing this batch is:  0.002515241503715515\n",
      "\n",
      "The classification loss after processing this batch is:  0.11759606748819351\n",
      "The representation loss after processing this batch is:  0.0025501735508441925\n",
      "\n",
      "The classification loss after processing this batch is:  0.055576179176568985\n",
      "The representation loss after processing this batch is:  0.0025164783000946045\n",
      "\n",
      "The classification loss after processing this batch is:  0.1311647742986679\n",
      "The representation loss after processing this batch is:  0.00271761417388916\n",
      "\n",
      "The classification loss after processing this batch is:  0.13761886954307556\n",
      "The representation loss after processing this batch is:  0.0027741342782974243\n",
      "\n",
      "The classification loss after processing this batch is:  0.212517648935318\n",
      "The representation loss after processing this batch is:  0.0032135024666786194\n",
      "\n",
      "The classification loss after processing this batch is:  0.11788596957921982\n",
      "The representation loss after processing this batch is:  0.0025231465697288513\n",
      "\n",
      "The classification loss after processing this batch is:  0.08434309810400009\n",
      "The representation loss after processing this batch is:  0.0023774057626724243\n",
      "\n",
      "The classification loss after processing this batch is:  0.2174702286720276\n",
      "The representation loss after processing this batch is:  0.0028254836797714233\n",
      "\n",
      "The classification loss after processing this batch is:  0.1648717075586319\n",
      "The representation loss after processing this batch is:  0.002736233174800873\n",
      "\n",
      "The classification loss after processing this batch is:  0.1399889439344406\n",
      "The representation loss after processing this batch is:  0.002832569181919098\n",
      "\n",
      "The classification loss after processing this batch is:  0.05414703115820885\n",
      "The representation loss after processing this batch is:  0.002649173140525818\n",
      "\n",
      "The classification loss after processing this batch is:  0.11156260222196579\n",
      "The representation loss after processing this batch is:  0.0026021748781204224\n",
      "\n",
      "The classification loss after processing this batch is:  0.11976288259029388\n",
      "The representation loss after processing this batch is:  0.002734515815973282\n",
      "\n",
      "The classification loss after processing this batch is:  0.15724612772464752\n",
      "The representation loss after processing this batch is:  0.003143809735774994\n",
      "\n",
      "The classification loss after processing this batch is:  0.12696720659732819\n",
      "The representation loss after processing this batch is:  0.0032029077410697937\n",
      "\n",
      "The classification loss after processing this batch is:  0.10070175677537918\n",
      "The representation loss after processing this batch is:  0.0033443868160247803\n",
      "\n",
      "The classification loss after processing this batch is:  0.15714117884635925\n",
      "The representation loss after processing this batch is:  0.003044210374355316\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.24497193098068237\n",
      "The representation loss after processing this batch is:  0.0026299916207790375\n",
      "\n",
      "The classification loss after processing this batch is:  0.1401629000902176\n",
      "The representation loss after processing this batch is:  0.003458172082901001\n",
      "\n",
      "The classification loss after processing this batch is:  0.15075458586215973\n",
      "The representation loss after processing this batch is:  0.0025423020124435425\n",
      "\n",
      "The classification loss after processing this batch is:  0.08125559985637665\n",
      "The representation loss after processing this batch is:  0.0025728121399879456\n",
      "\n",
      "The classification loss after processing this batch is:  0.19931112229824066\n",
      "The representation loss after processing this batch is:  0.0025292187929153442\n",
      "\n",
      "The classification loss after processing this batch is:  0.0667610913515091\n",
      "The representation loss after processing this batch is:  0.0026473253965377808\n",
      "\n",
      "The classification loss after processing this batch is:  0.13009075820446014\n",
      "The representation loss after processing this batch is:  0.002722606062889099\n",
      "\n",
      "The classification loss after processing this batch is:  0.10457588732242584\n",
      "The representation loss after processing this batch is:  0.0029400140047073364\n",
      "\n",
      "The classification loss after processing this batch is:  0.1119162067770958\n",
      "The representation loss after processing this batch is:  0.002608753740787506\n",
      "\n",
      "The classification loss after processing this batch is:  0.12394725531339645\n",
      "The representation loss after processing this batch is:  0.002839483320713043\n",
      "\n",
      "The classification loss after processing this batch is:  0.16545425355434418\n",
      "The representation loss after processing this batch is:  0.0029435455799102783\n",
      "\n",
      "The classification loss after processing this batch is:  0.13122355937957764\n",
      "The representation loss after processing this batch is:  0.0028071850538253784\n",
      "\n",
      "The classification loss after processing this batch is:  0.15298178791999817\n",
      "The representation loss after processing this batch is:  0.002491980791091919\n",
      "\n",
      "The classification loss after processing this batch is:  0.17286954820156097\n",
      "The representation loss after processing this batch is:  0.0031159892678260803\n",
      "\n",
      "The classification loss after processing this batch is:  0.1353846937417984\n",
      "The representation loss after processing this batch is:  0.00266227126121521\n",
      "\n",
      "The classification loss after processing this batch is:  0.11042371392250061\n",
      "The representation loss after processing this batch is:  0.002727784216403961\n",
      "\n",
      "The classification loss after processing this batch is:  0.06961163878440857\n",
      "The representation loss after processing this batch is:  0.0030826032161712646\n",
      "\n",
      "The classification loss after processing this batch is:  0.08587025105953217\n",
      "The representation loss after processing this batch is:  0.002858433872461319\n",
      "\n",
      "The classification loss after processing this batch is:  0.05250219628214836\n",
      "The representation loss after processing this batch is:  0.0026427246630191803\n",
      "\n",
      "The classification loss after processing this batch is:  0.058171432465314865\n",
      "The representation loss after processing this batch is:  0.002584412693977356\n",
      "\n",
      "The classification loss after processing this batch is:  0.07452324777841568\n",
      "The representation loss after processing this batch is:  0.0027299076318740845\n",
      "\n",
      "The classification loss after processing this batch is:  0.04899514466524124\n",
      "The representation loss after processing this batch is:  0.0030430257320404053\n",
      "\n",
      "The classification loss after processing this batch is:  0.1368507444858551\n",
      "The representation loss after processing this batch is:  0.002641350030899048\n",
      "\n",
      "The classification loss after processing this batch is:  0.09448122978210449\n",
      "The representation loss after processing this batch is:  0.0024081096053123474\n",
      "\n",
      "The classification loss after processing this batch is:  0.1367338001728058\n",
      "The representation loss after processing this batch is:  0.002669423818588257\n",
      "\n",
      "The classification loss after processing this batch is:  0.06390465795993805\n",
      "The representation loss after processing this batch is:  0.00286034494638443\n",
      "\n",
      "The classification loss after processing this batch is:  0.17856839299201965\n",
      "The representation loss after processing this batch is:  0.0026787593960762024\n",
      "\n",
      "The classification loss after processing this batch is:  0.17100933194160461\n",
      "The representation loss after processing this batch is:  0.002794139087200165\n",
      "\n",
      "The classification loss after processing this batch is:  0.112233005464077\n",
      "The representation loss after processing this batch is:  0.002482697367668152\n",
      "\n",
      "The classification loss after processing this batch is:  0.14635658264160156\n",
      "The representation loss after processing this batch is:  0.0028018131852149963\n",
      "\n",
      "The classification loss after processing this batch is:  0.12174529582262039\n",
      "The representation loss after processing this batch is:  0.0030349865555763245\n",
      "\n",
      "The classification loss after processing this batch is:  0.04889321327209473\n",
      "The representation loss after processing this batch is:  0.0025385916233062744\n",
      "\n",
      "The classification loss after processing this batch is:  0.07665758579969406\n",
      "The representation loss after processing this batch is:  0.0025516003370285034\n",
      "\n",
      "The classification loss after processing this batch is:  0.0856056660413742\n",
      "The representation loss after processing this batch is:  0.002391032874584198\n",
      "\n",
      "The classification loss after processing this batch is:  0.20976339280605316\n",
      "The representation loss after processing this batch is:  0.0026988908648490906\n",
      "\n",
      "The classification loss after processing this batch is:  0.16402943432331085\n",
      "The representation loss after processing this batch is:  0.0025101155042648315\n",
      "\n",
      "The classification loss after processing this batch is:  0.16238650679588318\n",
      "The representation loss after processing this batch is:  0.003319084644317627\n",
      "\n",
      "The classification loss after processing this batch is:  0.1872890442609787\n",
      "The representation loss after processing this batch is:  0.0026524141430854797\n",
      "\n",
      "The classification loss after processing this batch is:  0.19042734801769257\n",
      "The representation loss after processing this batch is:  0.002879105508327484\n",
      "\n",
      "The classification loss after processing this batch is:  0.20006583631038666\n",
      "The representation loss after processing this batch is:  0.0023585110902786255\n",
      "\n",
      "The classification loss after processing this batch is:  0.28652140498161316\n",
      "The representation loss after processing this batch is:  0.002684209495782852\n",
      "\n",
      "The classification loss after processing this batch is:  0.1860145777463913\n",
      "The representation loss after processing this batch is:  0.002521935850381851\n",
      "\n",
      "The classification loss after processing this batch is:  0.11779650300741196\n",
      "The representation loss after processing this batch is:  0.002339757978916168\n",
      "\n",
      "The classification loss after processing this batch is:  0.0980364978313446\n",
      "The representation loss after processing this batch is:  0.002710774540901184\n",
      "\n",
      "The classification loss after processing this batch is:  0.060016028583049774\n",
      "The representation loss after processing this batch is:  0.002521991729736328\n",
      "\n",
      "The classification loss after processing this batch is:  0.06808453053236008\n",
      "The representation loss after processing this batch is:  0.0025912299752235413\n",
      "\n",
      "The classification loss after processing this batch is:  0.0852547213435173\n",
      "The representation loss after processing this batch is:  0.003229297697544098\n",
      "\n",
      "The classification loss after processing this batch is:  0.12537789344787598\n",
      "The representation loss after processing this batch is:  0.0024296045303344727\n",
      "\n",
      "The classification loss after processing this batch is:  0.08009221404790878\n",
      "The representation loss after processing this batch is:  0.0027676820755004883\n",
      "\n",
      "The classification loss after processing this batch is:  0.1725960075855255\n",
      "The representation loss after processing this batch is:  0.002587113529443741\n",
      "\n",
      "The classification loss after processing this batch is:  0.16754311323165894\n",
      "The representation loss after processing this batch is:  0.0028779953718185425\n",
      "\n",
      "The classification loss after processing this batch is:  0.18141908943653107\n",
      "The representation loss after processing this batch is:  0.0025951899588108063\n",
      "\n",
      "The classification loss after processing this batch is:  0.13199059665203094\n",
      "The representation loss after processing this batch is:  0.002518370747566223\n",
      "\n",
      "The classification loss after processing this batch is:  0.1921829879283905\n",
      "The representation loss after processing this batch is:  0.002541717141866684\n",
      "\n",
      "The classification loss after processing this batch is:  0.1423606276512146\n",
      "The representation loss after processing this batch is:  0.002536855638027191\n",
      "\n",
      "The classification loss after processing this batch is:  0.08421061933040619\n",
      "The representation loss after processing this batch is:  0.0027254298329353333\n",
      "\n",
      "The classification loss after processing this batch is:  0.18769794702529907\n",
      "The representation loss after processing this batch is:  0.002551831305027008\n",
      "\n",
      "The classification loss after processing this batch is:  0.05538151413202286\n",
      "The representation loss after processing this batch is:  0.002524547278881073\n",
      "\n",
      "The classification loss after processing this batch is:  0.05451774224638939\n",
      "The representation loss after processing this batch is:  0.002345360815525055\n",
      "\n",
      "The classification loss after processing this batch is:  0.11371099948883057\n",
      "The representation loss after processing this batch is:  0.002920202910900116\n",
      "\n",
      "The classification loss after processing this batch is:  0.1681564599275589\n",
      "The representation loss after processing this batch is:  0.002713240683078766\n",
      "\n",
      "The classification loss after processing this batch is:  0.12636514008045197\n",
      "The representation loss after processing this batch is:  0.003033079206943512\n",
      "\n",
      "The classification loss after processing this batch is:  0.07979362457990646\n",
      "The representation loss after processing this batch is:  0.0030229613184928894\n",
      "\n",
      "The classification loss after processing this batch is:  0.13480030000209808\n",
      "The representation loss after processing this batch is:  0.003063701093196869\n",
      "\n",
      "The classification loss after processing this batch is:  0.0947386771440506\n",
      "The representation loss after processing this batch is:  0.0027683228254318237\n",
      "\n",
      "The classification loss after processing this batch is:  0.20140831172466278\n",
      "The representation loss after processing this batch is:  0.0027165114879608154\n",
      "\n",
      "The classification loss after processing this batch is:  0.05587893724441528\n",
      "The representation loss after processing this batch is:  0.002543620765209198\n",
      "\n",
      "The classification loss after processing this batch is:  0.061774447560310364\n",
      "The representation loss after processing this batch is:  0.0028167814016342163\n",
      "\n",
      "The classification loss after processing this batch is:  0.12618738412857056\n",
      "The representation loss after processing this batch is:  0.0033715516328811646\n",
      "\n",
      "The classification loss after processing this batch is:  0.12001845240592957\n",
      "The representation loss after processing this batch is:  0.002907104790210724\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.11073155701160431\n",
      "The representation loss after processing this batch is:  0.0032212436199188232\n",
      "\n",
      "The classification loss after processing this batch is:  0.08300676196813583\n",
      "The representation loss after processing this batch is:  0.0026477500796318054\n",
      "\n",
      "The classification loss after processing this batch is:  0.15604418516159058\n",
      "The representation loss after processing this batch is:  0.003096744418144226\n",
      "\n",
      "The classification loss after processing this batch is:  0.18663471937179565\n",
      "The representation loss after processing this batch is:  0.003078572452068329\n",
      "\n",
      "The classification loss after processing this batch is:  0.2055186629295349\n",
      "The representation loss after processing this batch is:  0.002695418894290924\n",
      "\n",
      "The classification loss after processing this batch is:  0.15161392092704773\n",
      "The representation loss after processing this batch is:  0.003118157386779785\n",
      "\n",
      "The classification loss after processing this batch is:  0.06144808605313301\n",
      "The representation loss after processing this batch is:  0.002629391849040985\n",
      "\n",
      "The classification loss after processing this batch is:  0.06981804221868515\n",
      "The representation loss after processing this batch is:  0.0024339407682418823\n",
      "\n",
      "The classification loss after processing this batch is:  0.18145841360092163\n",
      "The representation loss after processing this batch is:  0.003089793026447296\n",
      "\n",
      "The classification loss after processing this batch is:  0.24450083076953888\n",
      "The representation loss after processing this batch is:  0.003287866711616516\n",
      "\n",
      "The classification loss after processing this batch is:  0.24700762331485748\n",
      "The representation loss after processing this batch is:  0.0031767860054969788\n",
      "\n",
      "The classification loss after processing this batch is:  0.23238667845726013\n",
      "The representation loss after processing this batch is:  0.0027926675975322723\n",
      "\n",
      "The classification loss after processing this batch is:  0.09401238709688187\n",
      "The representation loss after processing this batch is:  0.0025951899588108063\n",
      "\n",
      "The classification loss after processing this batch is:  0.19176359474658966\n",
      "The representation loss after processing this batch is:  0.0024862587451934814\n",
      "\n",
      "The classification loss after processing this batch is:  0.10970327258110046\n",
      "The representation loss after processing this batch is:  0.002556025981903076\n",
      "\n",
      "The classification loss after processing this batch is:  0.1269042193889618\n",
      "The representation loss after processing this batch is:  0.0025907978415489197\n",
      "\n",
      "The classification loss after processing this batch is:  0.08397472649812698\n",
      "The representation loss after processing this batch is:  0.0025554075837135315\n",
      "\n",
      "The classification loss after processing this batch is:  0.16741149127483368\n",
      "The representation loss after processing this batch is:  0.0025299489498138428\n",
      "\n",
      "The classification loss after processing this batch is:  0.11729422211647034\n",
      "The representation loss after processing this batch is:  0.002588123083114624\n",
      "\n",
      "The classification loss after processing this batch is:  0.14464527368545532\n",
      "The representation loss after processing this batch is:  0.0024127215147018433\n",
      "\n",
      "The classification loss after processing this batch is:  0.1493849754333496\n",
      "The representation loss after processing this batch is:  0.0025263801217079163\n",
      "\n",
      "The classification loss after processing this batch is:  0.06136922910809517\n",
      "The representation loss after processing this batch is:  0.0028328076004981995\n",
      "\n",
      "The classification loss after processing this batch is:  0.10764996707439423\n",
      "The representation loss after processing this batch is:  0.002818956971168518\n",
      "\n",
      "The classification loss after processing this batch is:  0.15511034429073334\n",
      "The representation loss after processing this batch is:  0.002654559910297394\n",
      "\n",
      "The classification loss after processing this batch is:  0.11597970873117447\n",
      "The representation loss after processing this batch is:  0.002745598554611206\n",
      "\n",
      "The classification loss after processing this batch is:  0.07019500434398651\n",
      "The representation loss after processing this batch is:  0.0030873939394950867\n",
      "\n",
      "The classification loss after processing this batch is:  0.08282551914453506\n",
      "The representation loss after processing this batch is:  0.0023651905357837677\n",
      "\n",
      "The classification loss after processing this batch is:  0.2238692343235016\n",
      "The representation loss after processing this batch is:  0.003248751163482666\n",
      "\n",
      "The classification loss after processing this batch is:  0.16129611432552338\n",
      "The representation loss after processing this batch is:  0.0025924518704414368\n",
      "\n",
      "The classification loss after processing this batch is:  0.12481925636529922\n",
      "The representation loss after processing this batch is:  0.0025780275464057922\n",
      "\n",
      "The classification loss after processing this batch is:  0.10464779287576675\n",
      "The representation loss after processing this batch is:  0.0024458840489387512\n",
      "\n",
      "The classification loss after processing this batch is:  0.09590666741132736\n",
      "The representation loss after processing this batch is:  0.0026112347841262817\n",
      "\n",
      "The classification loss after processing this batch is:  0.09402920305728912\n",
      "The representation loss after processing this batch is:  0.0024921298027038574\n",
      "\n",
      "The classification loss after processing this batch is:  0.10709340870380402\n",
      "The representation loss after processing this batch is:  0.002729251980781555\n",
      "\n",
      "The classification loss after processing this batch is:  0.1360924392938614\n",
      "The representation loss after processing this batch is:  0.0027457773685455322\n",
      "\n",
      "The classification loss after processing this batch is:  0.14473173022270203\n",
      "The representation loss after processing this batch is:  0.0032255053520202637\n",
      "\n",
      "The classification loss after processing this batch is:  0.0887226015329361\n",
      "The representation loss after processing this batch is:  0.0028981640934944153\n",
      "\n",
      "The classification loss after processing this batch is:  0.16514278948307037\n",
      "The representation loss after processing this batch is:  0.0024677328765392303\n",
      "\n",
      "The classification loss after processing this batch is:  0.19486616551876068\n",
      "The representation loss after processing this batch is:  0.002516821026802063\n",
      "\n",
      "The classification loss after processing this batch is:  0.050118688493967056\n",
      "The representation loss after processing this batch is:  0.002559676766395569\n",
      "\n",
      "The classification loss after processing this batch is:  0.07457941025495529\n",
      "The representation loss after processing this batch is:  0.0024149827659130096\n",
      "\n",
      "The classification loss after processing this batch is:  0.1667628288269043\n",
      "The representation loss after processing this batch is:  0.0025570690631866455\n",
      "\n",
      "The classification loss after processing this batch is:  0.1566954255104065\n",
      "The representation loss after processing this batch is:  0.0028152242302894592\n",
      "\n",
      "The classification loss after processing this batch is:  0.09861022979021072\n",
      "The representation loss after processing this batch is:  0.002712894231081009\n",
      "\n",
      "The classification loss after processing this batch is:  0.23593148589134216\n",
      "The representation loss after processing this batch is:  0.002703152596950531\n",
      "\n",
      "The classification loss after processing this batch is:  0.16229894757270813\n",
      "The representation loss after processing this batch is:  0.0030780211091041565\n",
      "\n",
      "The classification loss after processing this batch is:  0.21052046120166779\n",
      "The representation loss after processing this batch is:  0.002898968756198883\n",
      "\n",
      "The classification loss after processing this batch is:  0.1169230192899704\n",
      "The representation loss after processing this batch is:  0.0030574575066566467\n",
      "\n",
      "The classification loss after processing this batch is:  0.16772910952568054\n",
      "The representation loss after processing this batch is:  0.002416938543319702\n",
      "\n",
      "The classification loss after processing this batch is:  0.09807638078927994\n",
      "The representation loss after processing this batch is:  0.0037438422441482544\n",
      "\n",
      "The classification loss after processing this batch is:  0.09949193894863129\n",
      "The representation loss after processing this batch is:  0.0026794597506523132\n",
      "\n",
      "The classification loss after processing this batch is:  0.1259225755929947\n",
      "The representation loss after processing this batch is:  0.0027151107788085938\n",
      "\n",
      "The classification loss after processing this batch is:  0.12314952909946442\n",
      "The representation loss after processing this batch is:  0.0023263320326805115\n",
      "\n",
      "The classification loss after processing this batch is:  0.12167677283287048\n",
      "The representation loss after processing this batch is:  0.002544090151786804\n",
      "\n",
      "The classification loss after processing this batch is:  0.11451995372772217\n",
      "The representation loss after processing this batch is:  0.002626389265060425\n",
      "\n",
      "The classification loss after processing this batch is:  0.1823285073041916\n",
      "The representation loss after processing this batch is:  0.002607390284538269\n",
      "\n",
      "The classification loss after processing this batch is:  0.08399830013513565\n",
      "The representation loss after processing this batch is:  0.0030734166502952576\n",
      "\n",
      "The classification loss after processing this batch is:  0.07455181330442429\n",
      "The representation loss after processing this batch is:  0.00291336327791214\n",
      "\n",
      "The classification loss after processing this batch is:  0.14844229817390442\n",
      "The representation loss after processing this batch is:  0.002926945686340332\n",
      "\n",
      "The classification loss after processing this batch is:  0.0738930031657219\n",
      "The representation loss after processing this batch is:  0.0026768147945404053\n",
      "\n",
      "The classification loss after processing this batch is:  0.09081218391656876\n",
      "The representation loss after processing this batch is:  0.002785824239253998\n",
      "\n",
      "The classification loss after processing this batch is:  0.06696153432130814\n",
      "The representation loss after processing this batch is:  0.0027716532349586487\n",
      "\n",
      "The classification loss after processing this batch is:  0.12522980570793152\n",
      "The representation loss after processing this batch is:  0.002332344651222229\n",
      "\n",
      "The classification loss after processing this batch is:  0.18069995939731598\n",
      "The representation loss after processing this batch is:  0.0030653253197669983\n",
      "\n",
      "The classification loss after processing this batch is:  0.18964652717113495\n",
      "The representation loss after processing this batch is:  0.0038005709648132324\n",
      "\n",
      "The classification loss after processing this batch is:  0.14371357858181\n",
      "The representation loss after processing this batch is:  0.003203444182872772\n",
      "\n",
      "The classification loss after processing this batch is:  0.11524974554777145\n",
      "The representation loss after processing this batch is:  0.002904839813709259\n",
      "\n",
      "The classification loss after processing this batch is:  0.11074549704790115\n",
      "The representation loss after processing this batch is:  0.0027334243059158325\n",
      "\n",
      "The classification loss after processing this batch is:  0.1307198703289032\n",
      "The representation loss after processing this batch is:  0.0025503337383270264\n",
      "\n",
      "The classification loss after processing this batch is:  0.07520736753940582\n",
      "The representation loss after processing this batch is:  0.002761557698249817\n",
      "\n",
      "The classification loss after processing this batch is:  0.06918124854564667\n",
      "The representation loss after processing this batch is:  0.002802908420562744\n",
      "\n",
      "The classification loss after processing this batch is:  0.06575509160757065\n",
      "The representation loss after processing this batch is:  0.0026781409978866577\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.20044828951358795\n",
      "The representation loss after processing this batch is:  0.003212057054042816\n",
      "\n",
      "The classification loss after processing this batch is:  0.1649518460035324\n",
      "The representation loss after processing this batch is:  0.0028598010540008545\n",
      "\n",
      "The classification loss after processing this batch is:  0.16025438904762268\n",
      "The representation loss after processing this batch is:  0.002633199095726013\n",
      "\n",
      "The classification loss after processing this batch is:  0.1431802660226822\n",
      "The representation loss after processing this batch is:  0.0034895315766334534\n",
      "\n",
      "The classification loss after processing this batch is:  0.13092191517353058\n",
      "The representation loss after processing this batch is:  0.0029179900884628296\n",
      "\n",
      "The classification loss after processing this batch is:  0.14685599505901337\n",
      "The representation loss after processing this batch is:  0.002978198230266571\n",
      "\n",
      "The classification loss after processing this batch is:  0.09826145321130753\n",
      "The representation loss after processing this batch is:  0.00280606746673584\n",
      "\n",
      "The classification loss after processing this batch is:  0.2993566393852234\n",
      "The representation loss after processing this batch is:  0.00330236554145813\n",
      "\n",
      "The classification loss after processing this batch is:  0.15679559111595154\n",
      "The representation loss after processing this batch is:  0.0029620304703712463\n",
      "\n",
      "The classification loss after processing this batch is:  0.2209533005952835\n",
      "The representation loss after processing this batch is:  0.003243684768676758\n",
      "\n",
      "The classification loss after processing this batch is:  0.09631989896297455\n",
      "The representation loss after processing this batch is:  0.0025182589888572693\n",
      "\n",
      "The classification loss after processing this batch is:  0.07317645102739334\n",
      "The representation loss after processing this batch is:  0.002713508903980255\n",
      "\n",
      "The classification loss after processing this batch is:  0.18957510590553284\n",
      "The representation loss after processing this batch is:  0.0024420171976089478\n",
      "\n",
      "The classification loss after processing this batch is:  0.1474926620721817\n",
      "The representation loss after processing this batch is:  0.0029087811708450317\n",
      "\n",
      "The classification loss after processing this batch is:  0.2576013207435608\n",
      "The representation loss after processing this batch is:  0.002584017813205719\n",
      "\n",
      "The classification loss after processing this batch is:  0.19886675477027893\n",
      "The representation loss after processing this batch is:  0.003393717110157013\n",
      "\n",
      "The classification loss after processing this batch is:  0.1638636291027069\n",
      "The representation loss after processing this batch is:  0.0033670738339424133\n",
      "\n",
      "The classification loss after processing this batch is:  0.13334904611110687\n",
      "The representation loss after processing this batch is:  0.0027785524725914\n",
      "\n",
      "The classification loss after processing this batch is:  0.05835769698023796\n",
      "The representation loss after processing this batch is:  0.002631083130836487\n",
      "\n",
      "The classification loss after processing this batch is:  0.1073220893740654\n",
      "The representation loss after processing this batch is:  0.0024578794836997986\n",
      "\n",
      "The classification loss after processing this batch is:  0.1174779087305069\n",
      "The representation loss after processing this batch is:  0.002579696476459503\n",
      "\n",
      "The classification loss after processing this batch is:  0.07669887691736221\n",
      "The representation loss after processing this batch is:  0.002732992172241211\n",
      "\n",
      "The classification loss after processing this batch is:  0.12390842288732529\n",
      "The representation loss after processing this batch is:  0.0024577081203460693\n",
      "\n",
      "The classification loss after processing this batch is:  0.21214301884174347\n",
      "The representation loss after processing this batch is:  0.002776592969894409\n",
      "\n",
      "The classification loss after processing this batch is:  0.15484210848808289\n",
      "The representation loss after processing this batch is:  0.0023650601506233215\n",
      "\n",
      "The classification loss after processing this batch is:  0.10375753790140152\n",
      "The representation loss after processing this batch is:  0.0027899593114852905\n",
      "\n",
      "The classification loss after processing this batch is:  0.10224916785955429\n",
      "The representation loss after processing this batch is:  0.002748154103755951\n",
      "\n",
      "The classification loss after processing this batch is:  0.07517801225185394\n",
      "The representation loss after processing this batch is:  0.0030030161142349243\n",
      "\n",
      "The classification loss after processing this batch is:  0.11836030334234238\n",
      "The representation loss after processing this batch is:  0.0031909868121147156\n",
      "\n",
      "The classification loss after processing this batch is:  0.06391395628452301\n",
      "The representation loss after processing this batch is:  0.003049612045288086\n",
      "\n",
      "The classification loss after processing this batch is:  0.1481476128101349\n",
      "The representation loss after processing this batch is:  0.00246623158454895\n",
      "\n",
      "The classification loss after processing this batch is:  0.15312394499778748\n",
      "The representation loss after processing this batch is:  0.002846222370862961\n",
      "\n",
      "The classification loss after processing this batch is:  0.06218128278851509\n",
      "The representation loss after processing this batch is:  0.002714499831199646\n",
      "\n",
      "The classification loss after processing this batch is:  0.22076819837093353\n",
      "The representation loss after processing this batch is:  0.002413500100374222\n",
      "\n",
      "The classification loss after processing this batch is:  0.11793509870767593\n",
      "The representation loss after processing this batch is:  0.0026165619492530823\n",
      "\n",
      "The classification loss after processing this batch is:  0.091800756752491\n",
      "The representation loss after processing this batch is:  0.002616576850414276\n",
      "\n",
      "The classification loss after processing this batch is:  0.07183648645877838\n",
      "The representation loss after processing this batch is:  0.002975381910800934\n",
      "\n",
      "The classification loss after processing this batch is:  0.08772274106740952\n",
      "The representation loss after processing this batch is:  0.0027952566742897034\n",
      "\n",
      "The classification loss after processing this batch is:  0.07514414191246033\n",
      "The representation loss after processing this batch is:  0.0025566816329956055\n",
      "\n",
      "The classification loss after processing this batch is:  0.3753185570240021\n",
      "The representation loss after processing this batch is:  0.002420734614133835\n",
      "\n",
      "The classification loss after processing this batch is:  0.13347472250461578\n",
      "The representation loss after processing this batch is:  0.002842135727405548\n",
      "\n",
      "The classification loss after processing this batch is:  0.1750531792640686\n",
      "The representation loss after processing this batch is:  0.002482682466506958\n",
      "\n",
      "The classification loss after processing this batch is:  0.099124975502491\n",
      "The representation loss after processing this batch is:  0.0024876631796360016\n",
      "\n",
      "The classification loss after processing this batch is:  0.13540758192539215\n",
      "The representation loss after processing this batch is:  0.0028519481420516968\n",
      "\n",
      "The classification loss after processing this batch is:  0.06816651672124863\n",
      "The representation loss after processing this batch is:  0.00257883220911026\n",
      "\n",
      "The classification loss after processing this batch is:  0.08342790603637695\n",
      "The representation loss after processing this batch is:  0.002751067280769348\n",
      "\n",
      "The classification loss after processing this batch is:  0.1910993903875351\n",
      "The representation loss after processing this batch is:  0.00277913361787796\n",
      "\n",
      "The classification loss after processing this batch is:  0.12768498063087463\n",
      "The representation loss after processing this batch is:  0.003429122269153595\n",
      "\n",
      "The classification loss after processing this batch is:  0.16070504486560822\n",
      "The representation loss after processing this batch is:  0.0030950121581554413\n",
      "\n",
      "The classification loss after processing this batch is:  0.10196355730295181\n",
      "The representation loss after processing this batch is:  0.002435654401779175\n",
      "\n",
      "The classification loss after processing this batch is:  0.2162892073392868\n",
      "The representation loss after processing this batch is:  0.002713814377784729\n",
      "\n",
      "The classification loss after processing this batch is:  0.14286676049232483\n",
      "The representation loss after processing this batch is:  0.0028200745582580566\n",
      "\n",
      "The classification loss after processing this batch is:  0.20926128327846527\n",
      "The representation loss after processing this batch is:  0.002698749303817749\n",
      "\n",
      "The classification loss after processing this batch is:  0.10830815136432648\n",
      "The representation loss after processing this batch is:  0.002864338457584381\n",
      "\n",
      "The classification loss after processing this batch is:  0.09935009479522705\n",
      "The representation loss after processing this batch is:  0.0031029656529426575\n",
      "\n",
      "The classification loss after processing this batch is:  0.04848465695977211\n",
      "The representation loss after processing this batch is:  0.0026934370398521423\n",
      "\n",
      "The classification loss after processing this batch is:  0.2026333212852478\n",
      "The representation loss after processing this batch is:  0.0026426687836647034\n",
      "\n",
      "The classification loss after processing this batch is:  0.27493950724601746\n",
      "The representation loss after processing this batch is:  0.0030288510024547577\n",
      "\n",
      "The classification loss after processing this batch is:  0.11796322464942932\n",
      "The representation loss after processing this batch is:  0.002706676721572876\n",
      "\n",
      "The classification loss after processing this batch is:  0.203739732503891\n",
      "The representation loss after processing this batch is:  0.0032822415232658386\n",
      "\n",
      "The classification loss after processing this batch is:  0.17458225786685944\n",
      "The representation loss after processing this batch is:  0.002973422408103943\n",
      "\n",
      "The classification loss after processing this batch is:  0.1756400316953659\n",
      "The representation loss after processing this batch is:  0.0028974972665309906\n",
      "\n",
      "The classification loss after processing this batch is:  0.07527098804712296\n",
      "The representation loss after processing this batch is:  0.002627246081829071\n",
      "\n",
      "The classification loss after processing this batch is:  0.13398872315883636\n",
      "The representation loss after processing this batch is:  0.0026700571179389954\n",
      "\n",
      "The classification loss after processing this batch is:  0.15698203444480896\n",
      "The representation loss after processing this batch is:  0.002981744706630707\n",
      "\n",
      "The classification loss after processing this batch is:  0.12186681479215622\n",
      "The representation loss after processing this batch is:  0.002917550504207611\n",
      "\n",
      "The classification loss after processing this batch is:  0.046388331800699234\n",
      "The representation loss after processing this batch is:  0.0029392316937446594\n",
      "\n",
      "The classification loss after processing this batch is:  0.08358902484178543\n",
      "The representation loss after processing this batch is:  0.003106929361820221\n",
      "\n",
      "The classification loss after processing this batch is:  0.09197370707988739\n",
      "The representation loss after processing this batch is:  0.0029218196868896484\n",
      "\n",
      "The classification loss after processing this batch is:  0.12712682783603668\n",
      "The representation loss after processing this batch is:  0.0024567507207393646\n",
      "\n",
      "The classification loss after processing this batch is:  0.1850241720676422\n",
      "The representation loss after processing this batch is:  0.0026481449604034424\n",
      "\n",
      "The classification loss after processing this batch is:  0.10651635378599167\n",
      "The representation loss after processing this batch is:  0.002458173781633377\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.13670477271080017\n",
      "The representation loss after processing this batch is:  0.0032454580068588257\n",
      "\n",
      "The classification loss after processing this batch is:  0.1725100427865982\n",
      "The representation loss after processing this batch is:  0.002812705934047699\n",
      "\n",
      "The classification loss after processing this batch is:  0.1277071088552475\n",
      "The representation loss after processing this batch is:  0.0034457817673683167\n",
      "\n",
      "The classification loss after processing this batch is:  0.09103916585445404\n",
      "The representation loss after processing this batch is:  0.0026805996894836426\n",
      "\n",
      "The classification loss after processing this batch is:  0.17954055964946747\n",
      "The representation loss after processing this batch is:  0.002765461802482605\n",
      "\n",
      "The classification loss after processing this batch is:  0.1598711907863617\n",
      "The representation loss after processing this batch is:  0.0031237900257110596\n",
      "\n",
      "The classification loss after processing this batch is:  0.13727889955043793\n",
      "The representation loss after processing this batch is:  0.002963446080684662\n",
      "\n",
      "The classification loss after processing this batch is:  0.09918244183063507\n",
      "The representation loss after processing this batch is:  0.0025444068014621735\n",
      "\n",
      "The classification loss after processing this batch is:  0.10141143202781677\n",
      "The representation loss after processing this batch is:  0.0024676918983459473\n",
      "\n",
      "The classification loss after processing this batch is:  0.1029495969414711\n",
      "The representation loss after processing this batch is:  0.0027898699045181274\n",
      "\n",
      "The classification loss after processing this batch is:  0.11543087661266327\n",
      "The representation loss after processing this batch is:  0.002673935145139694\n",
      "\n",
      "The classification loss after processing this batch is:  0.19602909684181213\n",
      "The representation loss after processing this batch is:  0.002779025584459305\n",
      "\n",
      "The classification loss after processing this batch is:  0.2586687207221985\n",
      "The representation loss after processing this batch is:  0.002754427492618561\n",
      "\n",
      "The classification loss after processing this batch is:  0.13651452958583832\n",
      "The representation loss after processing this batch is:  0.002537693828344345\n",
      "\n",
      "The classification loss after processing this batch is:  0.13776104152202606\n",
      "The representation loss after processing this batch is:  0.0027002692222595215\n",
      "\n",
      "The classification loss after processing this batch is:  0.12554782629013062\n",
      "The representation loss after processing this batch is:  0.002579260617494583\n",
      "\n",
      "The classification loss after processing this batch is:  0.15553997457027435\n",
      "The representation loss after processing this batch is:  0.0026152171194553375\n",
      "\n",
      "The classification loss after processing this batch is:  0.1909901201725006\n",
      "The representation loss after processing this batch is:  0.0028066597878932953\n",
      "\n",
      "The classification loss after processing this batch is:  0.13963034749031067\n",
      "The representation loss after processing this batch is:  0.002581581473350525\n",
      "\n",
      "The classification loss after processing this batch is:  0.31069889664649963\n",
      "The representation loss after processing this batch is:  0.0026991665363311768\n",
      "\n",
      "The classification loss after processing this batch is:  0.1765604317188263\n",
      "The representation loss after processing this batch is:  0.0025373995304107666\n",
      "\n",
      "The classification loss after processing this batch is:  0.06895378977060318\n",
      "The representation loss after processing this batch is:  0.00351744145154953\n",
      "\n",
      "The classification loss after processing this batch is:  0.12251592427492142\n",
      "The representation loss after processing this batch is:  0.0029550157487392426\n",
      "\n",
      "The classification loss after processing this batch is:  0.09343661367893219\n",
      "The representation loss after processing this batch is:  0.002773478627204895\n",
      "\n",
      "The classification loss after processing this batch is:  0.16937555372714996\n",
      "The representation loss after processing this batch is:  0.002863489091396332\n",
      "\n",
      "The classification loss after processing this batch is:  0.1309307962656021\n",
      "The representation loss after processing this batch is:  0.0025256015360355377\n",
      "\n",
      "The classification loss after processing this batch is:  0.12986686825752258\n",
      "The representation loss after processing this batch is:  0.0026870891451835632\n",
      "\n",
      "The classification loss after processing this batch is:  0.11341499537229538\n",
      "The representation loss after processing this batch is:  0.0027898848056793213\n",
      "\n",
      "The classification loss after processing this batch is:  0.15399904549121857\n",
      "The representation loss after processing this batch is:  0.002632100135087967\n",
      "\n",
      "The classification loss after processing this batch is:  0.2054983675479889\n",
      "The representation loss after processing this batch is:  0.0025100484490394592\n",
      "\n",
      "The classification loss after processing this batch is:  0.21377849578857422\n",
      "The representation loss after processing this batch is:  0.0026595890522003174\n",
      "\n",
      "The classification loss after processing this batch is:  0.14041632413864136\n",
      "The representation loss after processing this batch is:  0.002619996666908264\n",
      "\n",
      "The classification loss after processing this batch is:  0.05506208911538124\n",
      "The representation loss after processing this batch is:  0.003099098801612854\n",
      "\n",
      "The classification loss after processing this batch is:  0.03259182721376419\n",
      "The representation loss after processing this batch is:  0.0027557313442230225\n",
      "\n",
      "The classification loss after processing this batch is:  0.1421726793050766\n",
      "The representation loss after processing this batch is:  0.0030982568860054016\n",
      "\n",
      "The classification loss after processing this batch is:  0.07819513231515884\n",
      "The representation loss after processing this batch is:  0.003901340067386627\n",
      "\n",
      "The classification loss after processing this batch is:  0.1670835316181183\n",
      "The representation loss after processing this batch is:  0.002847731113433838\n",
      "\n",
      "The classification loss after processing this batch is:  0.12189728766679764\n",
      "The representation loss after processing this batch is:  0.0029425323009490967\n",
      "\n",
      "The classification loss after processing this batch is:  0.19298259913921356\n",
      "The representation loss after processing this batch is:  0.0025566071271896362\n",
      "\n",
      "The classification loss after processing this batch is:  0.05271879583597183\n",
      "The representation loss after processing this batch is:  0.002805188298225403\n",
      "\n",
      "The classification loss after processing this batch is:  0.14069980382919312\n",
      "The representation loss after processing this batch is:  0.002705007791519165\n",
      "\n",
      "The classification loss after processing this batch is:  0.15333200991153717\n",
      "The representation loss after processing this batch is:  0.0031254589557647705\n",
      "\n",
      "The classification loss after processing this batch is:  0.1923115998506546\n",
      "The representation loss after processing this batch is:  0.0029501020908355713\n",
      "\n",
      "The classification loss after processing this batch is:  0.1129576712846756\n",
      "The representation loss after processing this batch is:  0.0030199289321899414\n",
      "\n",
      "The classification loss after processing this batch is:  0.07164359092712402\n",
      "The representation loss after processing this batch is:  0.002513498067855835\n",
      "\n",
      "The classification loss after processing this batch is:  0.1214916855096817\n",
      "The representation loss after processing this batch is:  0.003010399639606476\n",
      "\n",
      "The classification loss after processing this batch is:  0.10597529262304306\n",
      "The representation loss after processing this batch is:  0.002534054219722748\n",
      "\n",
      "The classification loss after processing this batch is:  0.11772449314594269\n",
      "The representation loss after processing this batch is:  0.0026335716247558594\n",
      "\n",
      "The classification loss after processing this batch is:  0.13752099871635437\n",
      "The representation loss after processing this batch is:  0.0025819092988967896\n",
      "\n",
      "The classification loss after processing this batch is:  0.09379465132951736\n",
      "The representation loss after processing this batch is:  0.002637811005115509\n",
      "\n",
      "The classification loss after processing this batch is:  0.038496557623147964\n",
      "The representation loss after processing this batch is:  0.002607695758342743\n",
      "\n",
      "The classification loss after processing this batch is:  0.08713553845882416\n",
      "The representation loss after processing this batch is:  0.0029749125242233276\n",
      "\n",
      "The classification loss after processing this batch is:  0.04436163976788521\n",
      "The representation loss after processing this batch is:  0.003061838448047638\n",
      "\n",
      "The classification loss after processing this batch is:  0.11320725828409195\n",
      "The representation loss after processing this batch is:  0.0027250051498413086\n",
      "\n",
      "The classification loss after processing this batch is:  0.07854954898357391\n",
      "The representation loss after processing this batch is:  0.0026756227016448975\n",
      "\n",
      "The classification loss after processing this batch is:  0.06379015743732452\n",
      "The representation loss after processing this batch is:  0.0025947242975234985\n",
      "\n",
      "The classification loss after processing this batch is:  0.10938460379838943\n",
      "The representation loss after processing this batch is:  0.0031652823090553284\n",
      "\n",
      "The classification loss after processing this batch is:  0.08109274506568909\n",
      "The representation loss after processing this batch is:  0.002836756408214569\n",
      "\n",
      "The classification loss after processing this batch is:  0.05706031993031502\n",
      "The representation loss after processing this batch is:  0.002858266234397888\n",
      "\n",
      "The classification loss after processing this batch is:  0.09848298132419586\n",
      "The representation loss after processing this batch is:  0.002678819000720978\n",
      "\n",
      "The classification loss after processing this batch is:  0.06683175265789032\n",
      "The representation loss after processing this batch is:  0.0026796311140060425\n",
      "\n",
      "The classification loss after processing this batch is:  0.05433301627635956\n",
      "The representation loss after processing this batch is:  0.0027281716465950012\n",
      "\n",
      "The classification loss after processing this batch is:  0.12007152289152145\n",
      "The representation loss after processing this batch is:  0.0028275176882743835\n",
      "\n",
      "The classification loss after processing this batch is:  0.13968320190906525\n",
      "The representation loss after processing this batch is:  0.0029667094349861145\n",
      "\n",
      "The classification loss after processing this batch is:  0.06592194736003876\n",
      "The representation loss after processing this batch is:  0.0030673742294311523\n",
      "\n",
      "The classification loss after processing this batch is:  0.20875832438468933\n",
      "The representation loss after processing this batch is:  0.002893418073654175\n",
      "\n",
      "The classification loss after processing this batch is:  0.06702917069196701\n",
      "The representation loss after processing this batch is:  0.0026893168687820435\n",
      "\n",
      "The classification loss after processing this batch is:  0.13563063740730286\n",
      "The representation loss after processing this batch is:  0.002575509250164032\n",
      "\n",
      "The classification loss after processing this batch is:  0.13973063230514526\n",
      "The representation loss after processing this batch is:  0.003134623169898987\n",
      "\n",
      "The classification loss after processing this batch is:  0.07210512459278107\n",
      "The representation loss after processing this batch is:  0.0032555535435676575\n",
      "\n",
      "The classification loss after processing this batch is:  0.1818493902683258\n",
      "The representation loss after processing this batch is:  0.002767398953437805\n",
      "\n",
      "The classification loss after processing this batch is:  0.16504386067390442\n",
      "The representation loss after processing this batch is:  0.0024086609482765198\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1556965708732605\n",
      "The representation loss after processing this batch is:  0.0026470646262168884\n",
      "\n",
      "The classification loss after processing this batch is:  0.14898373186588287\n",
      "The representation loss after processing this batch is:  0.002677902579307556\n",
      "\n",
      "The classification loss after processing this batch is:  0.08292972296476364\n",
      "The representation loss after processing this batch is:  0.003016069531440735\n",
      "\n",
      "The classification loss after processing this batch is:  0.10647641867399216\n",
      "The representation loss after processing this batch is:  0.00237254798412323\n",
      "\n",
      "The classification loss after processing this batch is:  0.11657547205686569\n",
      "The representation loss after processing this batch is:  0.0028388500213623047\n",
      "\n",
      "The classification loss after processing this batch is:  0.17366249859333038\n",
      "The representation loss after processing this batch is:  0.0025616586208343506\n",
      "\n",
      "The classification loss after processing this batch is:  0.16492591798305511\n",
      "The representation loss after processing this batch is:  0.0025615692138671875\n",
      "\n",
      "The classification loss after processing this batch is:  0.0659467801451683\n",
      "The representation loss after processing this batch is:  0.0024143829941749573\n",
      "\n",
      "The classification loss after processing this batch is:  0.09165962040424347\n",
      "The representation loss after processing this batch is:  0.002603866159915924\n",
      "\n",
      "The classification loss after processing this batch is:  0.18912632763385773\n",
      "The representation loss after processing this batch is:  0.002212345600128174\n",
      "\n",
      "The classification loss after processing this batch is:  0.08404149115085602\n",
      "The representation loss after processing this batch is:  0.002631150186061859\n",
      "\n",
      "The classification loss after processing this batch is:  0.14147208631038666\n",
      "The representation loss after processing this batch is:  0.002673119306564331\n",
      "\n",
      "The classification loss after processing this batch is:  0.14672881364822388\n",
      "The representation loss after processing this batch is:  0.0026131346821784973\n",
      "\n",
      "The classification loss after processing this batch is:  0.07715753465890884\n",
      "The representation loss after processing this batch is:  0.0031084343791007996\n",
      "\n",
      "The classification loss after processing this batch is:  0.059007324278354645\n",
      "The representation loss after processing this batch is:  0.002788349986076355\n",
      "\n",
      "The classification loss after processing this batch is:  0.1305111050605774\n",
      "The representation loss after processing this batch is:  0.0027378052473068237\n",
      "\n",
      "The classification loss after processing this batch is:  0.15168613195419312\n",
      "The representation loss after processing this batch is:  0.0027386434376239777\n",
      "\n",
      "The classification loss after processing this batch is:  0.15028852224349976\n",
      "The representation loss after processing this batch is:  0.0028435364365577698\n",
      "\n",
      "The classification loss after processing this batch is:  0.2077624350786209\n",
      "The representation loss after processing this batch is:  0.003307301551103592\n",
      "\n",
      "The classification loss after processing this batch is:  0.12315861135721207\n",
      "The representation loss after processing this batch is:  0.002723909914493561\n",
      "\n",
      "The classification loss after processing this batch is:  0.16505677998065948\n",
      "The representation loss after processing this batch is:  0.0022056400775909424\n",
      "\n",
      "The classification loss after processing this batch is:  0.12202516943216324\n",
      "The representation loss after processing this batch is:  0.002962358295917511\n",
      "\n",
      "The classification loss after processing this batch is:  0.06139402464032173\n",
      "The representation loss after processing this batch is:  0.002923712134361267\n",
      "\n",
      "The classification loss after processing this batch is:  0.07111633569002151\n",
      "The representation loss after processing this batch is:  0.0026519857347011566\n",
      "\n",
      "The classification loss after processing this batch is:  0.09416583925485611\n",
      "The representation loss after processing this batch is:  0.002738170325756073\n",
      "\n",
      "The classification loss after processing this batch is:  0.11359091848134995\n",
      "The representation loss after processing this batch is:  0.0028832927346229553\n",
      "\n",
      "The classification loss after processing this batch is:  0.09982199221849442\n",
      "The representation loss after processing this batch is:  0.002785690128803253\n",
      "\n",
      "The classification loss after processing this batch is:  0.12459591776132584\n",
      "The representation loss after processing this batch is:  0.0031023621559143066\n",
      "\n",
      "The classification loss after processing this batch is:  0.14305929839611053\n",
      "The representation loss after processing this batch is:  0.0030443742871284485\n",
      "\n",
      "The classification loss after processing this batch is:  0.0934375524520874\n",
      "The representation loss after processing this batch is:  0.0030285418033599854\n",
      "\n",
      "The classification loss after processing this batch is:  0.1740109771490097\n",
      "The representation loss after processing this batch is:  0.0028328895568847656\n",
      "\n",
      "The classification loss after processing this batch is:  0.17440861463546753\n",
      "The representation loss after processing this batch is:  0.0025496408343315125\n",
      "\n",
      "The classification loss after processing this batch is:  0.20644144713878632\n",
      "The representation loss after processing this batch is:  0.0026700496673583984\n",
      "\n",
      "The classification loss after processing this batch is:  0.09063341468572617\n",
      "The representation loss after processing this batch is:  0.0029361024498939514\n",
      "\n",
      "The classification loss after processing this batch is:  0.08323745429515839\n",
      "The representation loss after processing this batch is:  0.0025538206100463867\n",
      "\n",
      "The classification loss after processing this batch is:  0.22191017866134644\n",
      "The representation loss after processing this batch is:  0.0025327354669570923\n",
      "\n",
      "The classification loss after processing this batch is:  0.20782198011875153\n",
      "The representation loss after processing this batch is:  0.0024873018264770508\n",
      "\n",
      "The classification loss after processing this batch is:  0.15992577373981476\n",
      "The representation loss after processing this batch is:  0.0028369203209877014\n",
      "\n",
      "The classification loss after processing this batch is:  0.13827724754810333\n",
      "The representation loss after processing this batch is:  0.0025621578097343445\n",
      "\n",
      "The classification loss after processing this batch is:  0.15382051467895508\n",
      "The representation loss after processing this batch is:  0.002681344747543335\n",
      "\n",
      "The classification loss after processing this batch is:  0.23821544647216797\n",
      "The representation loss after processing this batch is:  0.0024631917476654053\n",
      "\n",
      "The classification loss after processing this batch is:  0.2141079306602478\n",
      "The representation loss after processing this batch is:  0.002498723566532135\n",
      "\n",
      "The classification loss after processing this batch is:  0.2030407339334488\n",
      "The representation loss after processing this batch is:  0.002763420343399048\n",
      "\n",
      "The classification loss after processing this batch is:  0.18138234317302704\n",
      "The representation loss after processing this batch is:  0.0026037171483039856\n",
      "\n",
      "The classification loss after processing this batch is:  0.09533777087926865\n",
      "The representation loss after processing this batch is:  0.00306527316570282\n",
      "\n",
      "The classification loss after processing this batch is:  0.06661438196897507\n",
      "The representation loss after processing this batch is:  0.002727814018726349\n",
      "\n",
      "The classification loss after processing this batch is:  0.1486513316631317\n",
      "The representation loss after processing this batch is:  0.0029281042516231537\n",
      "\n",
      "The classification loss after processing this batch is:  0.12036727368831635\n",
      "The representation loss after processing this batch is:  0.0025157183408737183\n",
      "\n",
      "The classification loss after processing this batch is:  0.06813417375087738\n",
      "The representation loss after processing this batch is:  0.002420589327812195\n",
      "\n",
      "The classification loss after processing this batch is:  0.07460436969995499\n",
      "The representation loss after processing this batch is:  0.002632223069667816\n",
      "\n",
      "The classification loss after processing this batch is:  0.11246554553508759\n",
      "The representation loss after processing this batch is:  0.0025017932057380676\n",
      "\n",
      "The classification loss after processing this batch is:  0.11782855540513992\n",
      "The representation loss after processing this batch is:  0.0027364790439605713\n",
      "\n",
      "The classification loss after processing this batch is:  0.08238637447357178\n",
      "The representation loss after processing this batch is:  0.0029186420142650604\n",
      "\n",
      "The classification loss after processing this batch is:  0.10371994972229004\n",
      "The representation loss after processing this batch is:  0.002519160509109497\n",
      "\n",
      "The classification loss after processing this batch is:  0.0961068868637085\n",
      "The representation loss after processing this batch is:  0.0027856454253196716\n",
      "\n",
      "The classification loss after processing this batch is:  0.18450148403644562\n",
      "The representation loss after processing this batch is:  0.0027079731225967407\n",
      "\n",
      "The classification loss after processing this batch is:  0.11429904401302338\n",
      "The representation loss after processing this batch is:  0.002629704773426056\n",
      "\n",
      "The classification loss after processing this batch is:  0.17404872179031372\n",
      "The representation loss after processing this batch is:  0.002936616539955139\n",
      "\n",
      "The classification loss after processing this batch is:  0.060414575040340424\n",
      "The representation loss after processing this batch is:  0.0025589540600776672\n",
      "\n",
      "The classification loss after processing this batch is:  0.06234961003065109\n",
      "The representation loss after processing this batch is:  0.002955526113510132\n",
      "\n",
      "The classification loss after processing this batch is:  0.14030936360359192\n",
      "The representation loss after processing this batch is:  0.0025443732738494873\n",
      "\n",
      "The classification loss after processing this batch is:  0.19879868626594543\n",
      "The representation loss after processing this batch is:  0.0026344507932662964\n",
      "\n",
      "The classification loss after processing this batch is:  0.11444211006164551\n",
      "The representation loss after processing this batch is:  0.0026946812868118286\n",
      "\n",
      "The classification loss after processing this batch is:  0.06311406195163727\n",
      "The representation loss after processing this batch is:  0.002517443150281906\n",
      "\n",
      "The classification loss after processing this batch is:  0.1186465248465538\n",
      "The representation loss after processing this batch is:  0.0023132339119911194\n",
      "\n",
      "The classification loss after processing this batch is:  0.0268388744443655\n",
      "The representation loss after processing this batch is:  0.002889588475227356\n",
      "\n",
      "The classification loss after processing this batch is:  0.16833899915218353\n",
      "The representation loss after processing this batch is:  0.002611316740512848\n",
      "\n",
      "The classification loss after processing this batch is:  0.12962578237056732\n",
      "The representation loss after processing this batch is:  0.0029365643858909607\n",
      "\n",
      "The classification loss after processing this batch is:  0.08646532893180847\n",
      "The representation loss after processing this batch is:  0.0026872530579566956\n",
      "\n",
      "The classification loss after processing this batch is:  0.09750842303037643\n",
      "The representation loss after processing this batch is:  0.002780422568321228\n",
      "\n",
      "The classification loss after processing this batch is:  0.10789132863283157\n",
      "The representation loss after processing this batch is:  0.0027683302760124207\n",
      "\n",
      "The classification loss after processing this batch is:  0.04805820807814598\n",
      "The representation loss after processing this batch is:  0.0027763918042182922\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2641490399837494\n",
      "The representation loss after processing this batch is:  0.0024997442960739136\n",
      "\n",
      "The classification loss after processing this batch is:  0.22569335997104645\n",
      "The representation loss after processing this batch is:  0.002641495317220688\n",
      "\n",
      "The classification loss after processing this batch is:  0.16741544008255005\n",
      "The representation loss after processing this batch is:  0.0025287866592407227\n",
      "\n",
      "The classification loss after processing this batch is:  0.18526537716388702\n",
      "The representation loss after processing this batch is:  0.002481691539287567\n",
      "\n",
      "The classification loss after processing this batch is:  0.12145648151636124\n",
      "The representation loss after processing this batch is:  0.0027083903551101685\n",
      "\n",
      "The classification loss after processing this batch is:  0.10175105929374695\n",
      "The representation loss after processing this batch is:  0.002460204064846039\n",
      "\n",
      "The classification loss after processing this batch is:  0.21774336695671082\n",
      "The representation loss after processing this batch is:  0.002603761851787567\n",
      "\n",
      "The classification loss after processing this batch is:  0.11429848521947861\n",
      "The representation loss after processing this batch is:  0.002580314874649048\n",
      "\n",
      "The classification loss after processing this batch is:  0.17910833656787872\n",
      "The representation loss after processing this batch is:  0.00267665833234787\n",
      "\n",
      "The classification loss after processing this batch is:  0.10757028311491013\n",
      "The representation loss after processing this batch is:  0.002836965024471283\n",
      "\n",
      "The classification loss after processing this batch is:  0.16506458818912506\n",
      "The representation loss after processing this batch is:  0.0024420134723186493\n",
      "\n",
      "The classification loss after processing this batch is:  0.09415384382009506\n",
      "The representation loss after processing this batch is:  0.0025570355355739594\n",
      "\n",
      "The classification loss after processing this batch is:  0.09104276448488235\n",
      "The representation loss after processing this batch is:  0.0029971525073051453\n",
      "\n",
      "The classification loss after processing this batch is:  0.1290551871061325\n",
      "The representation loss after processing this batch is:  0.0026515349745750427\n",
      "\n",
      "The classification loss after processing this batch is:  0.0636386051774025\n",
      "The representation loss after processing this batch is:  0.0026097372174263\n",
      "\n",
      "The classification loss after processing this batch is:  0.04418407380580902\n",
      "The representation loss after processing this batch is:  0.002688974142074585\n",
      "\n",
      "The classification loss after processing this batch is:  0.09782473742961884\n",
      "The representation loss after processing this batch is:  0.0026824846863746643\n",
      "\n",
      "The classification loss after processing this batch is:  0.2374066710472107\n",
      "The representation loss after processing this batch is:  0.002762250602245331\n",
      "\n",
      "The classification loss after processing this batch is:  0.04033781960606575\n",
      "The representation loss after processing this batch is:  0.002733670175075531\n",
      "\n",
      "The classification loss after processing this batch is:  0.06913245469331741\n",
      "The representation loss after processing this batch is:  0.0025789551436901093\n",
      "\n",
      "The classification loss after processing this batch is:  0.1387244611978531\n",
      "The representation loss after processing this batch is:  0.002618260681629181\n",
      "\n",
      "The classification loss after processing this batch is:  0.16685517132282257\n",
      "The representation loss after processing this batch is:  0.002647027373313904\n",
      "\n",
      "The classification loss after processing this batch is:  0.10445258021354675\n",
      "The representation loss after processing this batch is:  0.0027242451906204224\n",
      "\n",
      "The classification loss after processing this batch is:  0.21031521260738373\n",
      "The representation loss after processing this batch is:  0.0024893656373023987\n",
      "\n",
      "The classification loss after processing this batch is:  0.08898437768220901\n",
      "The representation loss after processing this batch is:  0.0030198246240615845\n",
      "\n",
      "The classification loss after processing this batch is:  0.048543430864810944\n",
      "The representation loss after processing this batch is:  0.0024639256298542023\n",
      "\n",
      "The classification loss after processing this batch is:  0.051589302718639374\n",
      "The representation loss after processing this batch is:  0.003092467784881592\n",
      "\n",
      "The classification loss after processing this batch is:  0.1542988419532776\n",
      "The representation loss after processing this batch is:  0.0030685439705848694\n",
      "\n",
      "The classification loss after processing this batch is:  0.13893236219882965\n",
      "The representation loss after processing this batch is:  0.002845369279384613\n",
      "\n",
      "The classification loss after processing this batch is:  0.09031396359205246\n",
      "The representation loss after processing this batch is:  0.0031134337186813354\n",
      "\n",
      "The classification loss after processing this batch is:  0.12905791401863098\n",
      "The representation loss after processing this batch is:  0.0028689876198768616\n",
      "\n",
      "The classification loss after processing this batch is:  0.09719805419445038\n",
      "The representation loss after processing this batch is:  0.002824965864419937\n",
      "\n",
      "The classification loss after processing this batch is:  0.09887337684631348\n",
      "The representation loss after processing this batch is:  0.002734668552875519\n",
      "\n",
      "The classification loss after processing this batch is:  0.11643995344638824\n",
      "The representation loss after processing this batch is:  0.0027990154922008514\n",
      "\n",
      "The classification loss after processing this batch is:  0.15465708076953888\n",
      "The representation loss after processing this batch is:  0.00286981463432312\n",
      "\n",
      "The classification loss after processing this batch is:  0.14378979802131653\n",
      "The representation loss after processing this batch is:  0.0030467063188552856\n",
      "\n",
      "The classification loss after processing this batch is:  0.2719264328479767\n",
      "The representation loss after processing this batch is:  0.002371549606323242\n",
      "\n",
      "The classification loss after processing this batch is:  0.18968161940574646\n",
      "The representation loss after processing this batch is:  0.002613157033920288\n",
      "\n",
      "The classification loss after processing this batch is:  0.13548775017261505\n",
      "The representation loss after processing this batch is:  0.0028481483459472656\n",
      "\n",
      "The classification loss after processing this batch is:  0.13967694342136383\n",
      "The representation loss after processing this batch is:  0.0028983280062675476\n",
      "\n",
      "The classification loss after processing this batch is:  0.044312216341495514\n",
      "The representation loss after processing this batch is:  0.002648979425430298\n",
      "\n",
      "The classification loss after processing this batch is:  0.11044850200414658\n",
      "The representation loss after processing this batch is:  0.0030662305653095245\n",
      "\n",
      "The classification loss after processing this batch is:  0.08774717152118683\n",
      "The representation loss after processing this batch is:  0.002901926636695862\n",
      "\n",
      "The classification loss after processing this batch is:  0.13201098144054413\n",
      "The representation loss after processing this batch is:  0.00268632173538208\n",
      "\n",
      "The classification loss after processing this batch is:  0.1381342113018036\n",
      "The representation loss after processing this batch is:  0.002401486039161682\n",
      "\n",
      "The classification loss after processing this batch is:  0.08843787759542465\n",
      "The representation loss after processing this batch is:  0.002408750355243683\n",
      "\n",
      "The classification loss after processing this batch is:  0.13171906769275665\n",
      "The representation loss after processing this batch is:  0.0025419294834136963\n",
      "\n",
      "The classification loss after processing this batch is:  0.17041946947574615\n",
      "The representation loss after processing this batch is:  0.002482764422893524\n",
      "\n",
      "The classification loss after processing this batch is:  0.13619233667850494\n",
      "The representation loss after processing this batch is:  0.002782665193080902\n",
      "\n",
      "The classification loss after processing this batch is:  0.22898003458976746\n",
      "The representation loss after processing this batch is:  0.002892822027206421\n",
      "\n",
      "The classification loss after processing this batch is:  0.09227272868156433\n",
      "The representation loss after processing this batch is:  0.0028207972645759583\n",
      "\n",
      "The classification loss after processing this batch is:  0.12252532690763474\n",
      "The representation loss after processing this batch is:  0.002332005649805069\n",
      "\n",
      "The classification loss after processing this batch is:  0.09477146714925766\n",
      "The representation loss after processing this batch is:  0.002715371549129486\n",
      "\n",
      "The classification loss after processing this batch is:  0.22842520475387573\n",
      "The representation loss after processing this batch is:  0.0028535202145576477\n",
      "\n",
      "The classification loss after processing this batch is:  0.20635949075222015\n",
      "The representation loss after processing this batch is:  0.00298464298248291\n",
      "\n",
      "The classification loss after processing this batch is:  0.0516246072947979\n",
      "The representation loss after processing this batch is:  0.002646036446094513\n",
      "\n",
      "The classification loss after processing this batch is:  0.07310383766889572\n",
      "The representation loss after processing this batch is:  0.002795681357383728\n",
      "\n",
      "The classification loss after processing this batch is:  0.2393469214439392\n",
      "The representation loss after processing this batch is:  0.002469167113304138\n",
      "\n",
      "The classification loss after processing this batch is:  0.07789012044668198\n",
      "The representation loss after processing this batch is:  0.002634391188621521\n",
      "\n",
      "The classification loss after processing this batch is:  0.08475933969020844\n",
      "The representation loss after processing this batch is:  0.002771541476249695\n",
      "\n",
      "The classification loss after processing this batch is:  0.13826614618301392\n",
      "The representation loss after processing this batch is:  0.0026240572333335876\n",
      "\n",
      "The classification loss after processing this batch is:  0.10363872349262238\n",
      "The representation loss after processing this batch is:  0.0027889981865882874\n",
      "\n",
      "The classification loss after processing this batch is:  0.21201194822788239\n",
      "The representation loss after processing this batch is:  0.003047570586204529\n",
      "\n",
      "The classification loss after processing this batch is:  0.14095459878444672\n",
      "The representation loss after processing this batch is:  0.0030955225229263306\n",
      "\n",
      "The classification loss after processing this batch is:  0.15368877351284027\n",
      "The representation loss after processing this batch is:  0.0032340437173843384\n",
      "\n",
      "The classification loss after processing this batch is:  0.12786446511745453\n",
      "The representation loss after processing this batch is:  0.0026046186685562134\n",
      "\n",
      "The classification loss after processing this batch is:  0.1720576286315918\n",
      "The representation loss after processing this batch is:  0.0023130401968955994\n",
      "\n",
      "The classification loss after processing this batch is:  0.05043516680598259\n",
      "The representation loss after processing this batch is:  0.002481698989868164\n",
      "\n",
      "The classification loss after processing this batch is:  0.05564592778682709\n",
      "The representation loss after processing this batch is:  0.002487964928150177\n",
      "\n",
      "The classification loss after processing this batch is:  0.07907852530479431\n",
      "The representation loss after processing this batch is:  0.002605646848678589\n",
      "\n",
      "The classification loss after processing this batch is:  0.06336537003517151\n",
      "The representation loss after processing this batch is:  0.0026828348636627197\n",
      "\n",
      "The classification loss after processing this batch is:  0.11114848405122757\n",
      "The representation loss after processing this batch is:  0.002858635038137436\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.07080354541540146\n",
      "The representation loss after processing this batch is:  0.0024664700031280518\n",
      "\n",
      "The classification loss after processing this batch is:  0.08226791769266129\n",
      "The representation loss after processing this batch is:  0.0023644641041755676\n",
      "\n",
      "The classification loss after processing this batch is:  0.13098028302192688\n",
      "The representation loss after processing this batch is:  0.0026682987809181213\n",
      "\n",
      "The classification loss after processing this batch is:  0.18363456428050995\n",
      "The representation loss after processing this batch is:  0.0028008222579956055\n",
      "\n",
      "The classification loss after processing this batch is:  0.16999879479408264\n",
      "The representation loss after processing this batch is:  0.0025295130908489227\n",
      "\n",
      "The classification loss after processing this batch is:  0.15708604454994202\n",
      "The representation loss after processing this batch is:  0.002907790243625641\n",
      "\n",
      "The classification loss after processing this batch is:  0.18280243873596191\n",
      "The representation loss after processing this batch is:  0.002500329166650772\n",
      "\n",
      "The classification loss after processing this batch is:  0.09766626358032227\n",
      "The representation loss after processing this batch is:  0.002657361328601837\n",
      "\n",
      "The classification loss after processing this batch is:  0.15145164728164673\n",
      "The representation loss after processing this batch is:  0.0028524547815322876\n",
      "\n",
      "The classification loss after processing this batch is:  0.2446918487548828\n",
      "The representation loss after processing this batch is:  0.002781219780445099\n",
      "\n",
      "The classification loss after processing this batch is:  0.09036515653133392\n",
      "The representation loss after processing this batch is:  0.002629268914461136\n",
      "\n",
      "The classification loss after processing this batch is:  0.17744608223438263\n",
      "The representation loss after processing this batch is:  0.0024071671068668365\n",
      "\n",
      "The classification loss after processing this batch is:  0.16821934282779694\n",
      "The representation loss after processing this batch is:  0.0024367496371269226\n",
      "\n",
      "The classification loss after processing this batch is:  0.15292803943157196\n",
      "The representation loss after processing this batch is:  0.002353522926568985\n",
      "\n",
      "The classification loss after processing this batch is:  0.08874302357435226\n",
      "The representation loss after processing this batch is:  0.002804115414619446\n",
      "\n",
      "The classification loss after processing this batch is:  0.07509931176900864\n",
      "The representation loss after processing this batch is:  0.0026232823729515076\n",
      "\n",
      "The classification loss after processing this batch is:  0.10520283132791519\n",
      "The representation loss after processing this batch is:  0.0024331212043762207\n",
      "\n",
      "The classification loss after processing this batch is:  0.06531532853841782\n",
      "The representation loss after processing this batch is:  0.002752654254436493\n",
      "\n",
      "The classification loss after processing this batch is:  0.04385370388627052\n",
      "The representation loss after processing this batch is:  0.002609260380268097\n",
      "\n",
      "The classification loss after processing this batch is:  0.15282373130321503\n",
      "The representation loss after processing this batch is:  0.0030061081051826477\n",
      "\n",
      "The classification loss after processing this batch is:  0.055825814604759216\n",
      "The representation loss after processing this batch is:  0.0030039995908737183\n",
      "\n",
      "The classification loss after processing this batch is:  0.20159682631492615\n",
      "The representation loss after processing this batch is:  0.00312785804271698\n",
      "\n",
      "The classification loss after processing this batch is:  0.12641026079654694\n",
      "The representation loss after processing this batch is:  0.0026618391275405884\n",
      "\n",
      "The classification loss after processing this batch is:  0.19779258966445923\n",
      "The representation loss after processing this batch is:  0.002701900899410248\n",
      "\n",
      "The classification loss after processing this batch is:  0.338748574256897\n",
      "The representation loss after processing this batch is:  0.0021842867136001587\n",
      "\n",
      "The classification loss after processing this batch is:  0.14595137536525726\n",
      "The representation loss after processing this batch is:  0.002608947455883026\n",
      "\n",
      "The classification loss after processing this batch is:  0.05014423280954361\n",
      "The representation loss after processing this batch is:  0.002673007547855377\n",
      "\n",
      "The classification loss after processing this batch is:  0.08345851302146912\n",
      "The representation loss after processing this batch is:  0.0030642151832580566\n",
      "\n",
      "The classification loss after processing this batch is:  0.0648152157664299\n",
      "The representation loss after processing this batch is:  0.002911902964115143\n",
      "\n",
      "The classification loss after processing this batch is:  0.07348832488059998\n",
      "The representation loss after processing this batch is:  0.0027534738183021545\n",
      "\n",
      "The classification loss after processing this batch is:  0.08291785418987274\n",
      "The representation loss after processing this batch is:  0.0025626718997955322\n",
      "\n",
      "The classification loss after processing this batch is:  0.19428764283657074\n",
      "The representation loss after processing this batch is:  0.0025713518261909485\n",
      "\n",
      "The classification loss after processing this batch is:  0.1630270779132843\n",
      "The representation loss after processing this batch is:  0.0026712752878665924\n",
      "\n",
      "The classification loss after processing this batch is:  0.1563262641429901\n",
      "The representation loss after processing this batch is:  0.0032196566462516785\n",
      "\n",
      "The classification loss after processing this batch is:  0.23874790966510773\n",
      "The representation loss after processing this batch is:  0.00334332138299942\n",
      "\n",
      "The classification loss after processing this batch is:  0.10280315577983856\n",
      "The representation loss after processing this batch is:  0.0027378499507904053\n",
      "\n",
      "The classification loss after processing this batch is:  0.11766015738248825\n",
      "The representation loss after processing this batch is:  0.0027566850185394287\n",
      "\n",
      "The classification loss after processing this batch is:  0.18652589619159698\n",
      "The representation loss after processing this batch is:  0.0025733672082424164\n",
      "\n",
      "The classification loss after processing this batch is:  0.12117765843868256\n",
      "The representation loss after processing this batch is:  0.0030832067131996155\n",
      "\n",
      "The classification loss after processing this batch is:  0.14990785717964172\n",
      "The representation loss after processing this batch is:  0.003885902464389801\n",
      "\n",
      "The classification loss after processing this batch is:  0.06923715770244598\n",
      "The representation loss after processing this batch is:  0.0028249993920326233\n",
      "\n",
      "The classification loss after processing this batch is:  0.17031234502792358\n",
      "The representation loss after processing this batch is:  0.0030919834971427917\n",
      "\n",
      "The classification loss after processing this batch is:  0.16467083990573883\n",
      "The representation loss after processing this batch is:  0.0033095702528953552\n",
      "\n",
      "The classification loss after processing this batch is:  0.10758212208747864\n",
      "The representation loss after processing this batch is:  0.003288254141807556\n",
      "\n",
      "The classification loss after processing this batch is:  0.15866123139858246\n",
      "The representation loss after processing this batch is:  0.0027620643377304077\n",
      "\n",
      "The classification loss after processing this batch is:  0.15509454905986786\n",
      "The representation loss after processing this batch is:  0.002442002296447754\n",
      "\n",
      "The classification loss after processing this batch is:  0.1423422247171402\n",
      "The representation loss after processing this batch is:  0.002398453652858734\n",
      "\n",
      "The classification loss after processing this batch is:  0.14637097716331482\n",
      "The representation loss after processing this batch is:  0.0026503801345825195\n",
      "\n",
      "The classification loss after processing this batch is:  0.1102147251367569\n",
      "The representation loss after processing this batch is:  0.0028485283255577087\n",
      "\n",
      "The classification loss after processing this batch is:  0.03439570218324661\n",
      "The representation loss after processing this batch is:  0.002689264714717865\n",
      "\n",
      "The classification loss after processing this batch is:  0.1272556036710739\n",
      "The representation loss after processing this batch is:  0.002795867621898651\n",
      "\n",
      "The classification loss after processing this batch is:  0.07069376111030579\n",
      "The representation loss after processing this batch is:  0.002905242145061493\n",
      "\n",
      "The classification loss after processing this batch is:  0.23251844942569733\n",
      "The representation loss after processing this batch is:  0.002672150731086731\n",
      "\n",
      "The classification loss after processing this batch is:  0.06529390066862106\n",
      "The representation loss after processing this batch is:  0.0030526667833328247\n",
      "\n",
      "The classification loss after processing this batch is:  0.10706201195716858\n",
      "The representation loss after processing this batch is:  0.0025621429085731506\n",
      "\n",
      "The classification loss after processing this batch is:  0.16704776883125305\n",
      "The representation loss after processing this batch is:  0.002900727093219757\n",
      "\n",
      "The classification loss after processing this batch is:  0.12370436638593674\n",
      "The representation loss after processing this batch is:  0.0028407052159309387\n",
      "\n",
      "The classification loss after processing this batch is:  0.1490439772605896\n",
      "The representation loss after processing this batch is:  0.002650350332260132\n",
      "\n",
      "The classification loss after processing this batch is:  0.08737656474113464\n",
      "The representation loss after processing this batch is:  0.0025698915123939514\n",
      "\n",
      "The classification loss after processing this batch is:  0.07855691760778427\n",
      "The representation loss after processing this batch is:  0.0024590492248535156\n",
      "\n",
      "The classification loss after processing this batch is:  0.09159567952156067\n",
      "The representation loss after processing this batch is:  0.002432003617286682\n",
      "\n",
      "The classification loss after processing this batch is:  0.17779019474983215\n",
      "The representation loss after processing this batch is:  0.0029597505927085876\n",
      "\n",
      "The classification loss after processing this batch is:  0.19135621190071106\n",
      "The representation loss after processing this batch is:  0.00274793803691864\n",
      "\n",
      "The classification loss after processing this batch is:  0.1705031543970108\n",
      "The representation loss after processing this batch is:  0.0022924505174160004\n",
      "\n",
      "The classification loss after processing this batch is:  0.15205682814121246\n",
      "The representation loss after processing this batch is:  0.0024459324777126312\n",
      "\n",
      "The classification loss after processing this batch is:  0.24004575610160828\n",
      "The representation loss after processing this batch is:  0.002622656524181366\n",
      "\n",
      "The classification loss after processing this batch is:  0.1149216964840889\n",
      "The representation loss after processing this batch is:  0.002880975604057312\n",
      "\n",
      "The classification loss after processing this batch is:  0.22979828715324402\n",
      "The representation loss after processing this batch is:  0.00276898592710495\n",
      "\n",
      "The classification loss after processing this batch is:  0.10976331681013107\n",
      "The representation loss after processing this batch is:  0.002811625599861145\n",
      "\n",
      "The classification loss after processing this batch is:  0.05733853951096535\n",
      "The representation loss after processing this batch is:  0.0028157830238342285\n",
      "\n",
      "The classification loss after processing this batch is:  0.047292210161685944\n",
      "The representation loss after processing this batch is:  0.0024099498987197876\n",
      "\n",
      "The classification loss after processing this batch is:  0.06489124894142151\n",
      "The representation loss after processing this batch is:  0.0026456043124198914\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.20285698771476746\n",
      "The representation loss after processing this batch is:  0.0027940720319747925\n",
      "\n",
      "The classification loss after processing this batch is:  0.07988312840461731\n",
      "The representation loss after processing this batch is:  0.002796940505504608\n",
      "\n",
      "The classification loss after processing this batch is:  0.12678857147693634\n",
      "The representation loss after processing this batch is:  0.002824045717716217\n",
      "\n",
      "The classification loss after processing this batch is:  0.14064718782901764\n",
      "The representation loss after processing this batch is:  0.002950236201286316\n",
      "\n",
      "The classification loss after processing this batch is:  0.09247813373804092\n",
      "The representation loss after processing this batch is:  0.002857901155948639\n",
      "\n",
      "The classification loss after processing this batch is:  0.07145866751670837\n",
      "The representation loss after processing this batch is:  0.002527475357055664\n",
      "\n",
      "The classification loss after processing this batch is:  0.16789032518863678\n",
      "The representation loss after processing this batch is:  0.0024823248386383057\n",
      "\n",
      "The classification loss after processing this batch is:  0.2085784524679184\n",
      "The representation loss after processing this batch is:  0.00256241112947464\n",
      "\n",
      "The classification loss after processing this batch is:  0.1794055551290512\n",
      "The representation loss after processing this batch is:  0.002846658229827881\n",
      "\n",
      "The classification loss after processing this batch is:  0.0802542120218277\n",
      "The representation loss after processing this batch is:  0.002653166651725769\n",
      "\n",
      "The classification loss after processing this batch is:  0.22725547850131989\n",
      "The representation loss after processing this batch is:  0.0025039874017238617\n",
      "\n",
      "The classification loss after processing this batch is:  0.08322718739509583\n",
      "The representation loss after processing this batch is:  0.002279020845890045\n",
      "\n",
      "The classification loss after processing this batch is:  0.16307847201824188\n",
      "The representation loss after processing this batch is:  0.002462301403284073\n",
      "\n",
      "The classification loss after processing this batch is:  0.16521449387073517\n",
      "The representation loss after processing this batch is:  0.0029379799962043762\n",
      "\n",
      "The classification loss after processing this batch is:  0.1233295202255249\n",
      "The representation loss after processing this batch is:  0.0026124268770217896\n",
      "\n",
      "The classification loss after processing this batch is:  0.15056590735912323\n",
      "The representation loss after processing this batch is:  0.0027632787823677063\n",
      "\n",
      "The classification loss after processing this batch is:  0.1363099366426468\n",
      "The representation loss after processing this batch is:  0.0030759796500205994\n",
      "\n",
      "The classification loss after processing this batch is:  0.19503329694271088\n",
      "The representation loss after processing this batch is:  0.002573922276496887\n",
      "\n",
      "The classification loss after processing this batch is:  0.252570778131485\n",
      "The representation loss after processing this batch is:  0.0028604045510292053\n",
      "\n",
      "The classification loss after processing this batch is:  0.1972174197435379\n",
      "The representation loss after processing this batch is:  0.0027053579688072205\n",
      "\n",
      "The classification loss after processing this batch is:  0.12103172391653061\n",
      "The representation loss after processing this batch is:  0.0026725120842456818\n",
      "\n",
      "The classification loss after processing this batch is:  0.08785955607891083\n",
      "The representation loss after processing this batch is:  0.003063686192035675\n",
      "\n",
      "The classification loss after processing this batch is:  0.17252381145954132\n",
      "The representation loss after processing this batch is:  0.0022816210985183716\n",
      "\n",
      "The classification loss after processing this batch is:  0.1483815312385559\n",
      "The representation loss after processing this batch is:  0.002595089375972748\n",
      "\n",
      "The classification loss after processing this batch is:  0.0370495468378067\n",
      "The representation loss after processing this batch is:  0.002589702606201172\n",
      "\n",
      "The classification loss after processing this batch is:  0.13191211223602295\n",
      "The representation loss after processing this batch is:  0.0025662630796432495\n",
      "\n",
      "The classification loss after processing this batch is:  0.29971373081207275\n",
      "The representation loss after processing this batch is:  0.003042910248041153\n",
      "\n",
      "The classification loss after processing this batch is:  0.30471885204315186\n",
      "The representation loss after processing this batch is:  0.0028656721115112305\n",
      "\n",
      "The classification loss after processing this batch is:  0.2561522126197815\n",
      "The representation loss after processing this batch is:  0.0026016198098659515\n",
      "\n",
      "The classification loss after processing this batch is:  0.18672925233840942\n",
      "The representation loss after processing this batch is:  0.0025955811142921448\n",
      "\n",
      "The classification loss after processing this batch is:  0.06689829379320145\n",
      "The representation loss after processing this batch is:  0.0025232434272766113\n",
      "\n",
      "The classification loss after processing this batch is:  0.15778307616710663\n",
      "The representation loss after processing this batch is:  0.0026417598128318787\n",
      "\n",
      "The classification loss after processing this batch is:  0.1527094691991806\n",
      "The representation loss after processing this batch is:  0.0028207823634147644\n",
      "\n",
      "The classification loss after processing this batch is:  0.22223663330078125\n",
      "The representation loss after processing this batch is:  0.0029832571744918823\n",
      "\n",
      "The classification loss after processing this batch is:  0.12586738169193268\n",
      "The representation loss after processing this batch is:  0.0029557794332504272\n",
      "\n",
      "The classification loss after processing this batch is:  0.10667291283607483\n",
      "The representation loss after processing this batch is:  0.00316571444272995\n",
      "\n",
      "The classification loss after processing this batch is:  0.08066905289888382\n",
      "The representation loss after processing this batch is:  0.0028032660484313965\n",
      "\n",
      "The classification loss after processing this batch is:  0.13032181560993195\n",
      "The representation loss after processing this batch is:  0.0027366802096366882\n",
      "\n",
      "The classification loss after processing this batch is:  0.17858706414699554\n",
      "The representation loss after processing this batch is:  0.0030435919761657715\n",
      "\n",
      "The classification loss after processing this batch is:  0.1543259471654892\n",
      "The representation loss after processing this batch is:  0.002581179141998291\n",
      "\n",
      "The classification loss after processing this batch is:  0.0857078954577446\n",
      "The representation loss after processing this batch is:  0.002436526119709015\n",
      "\n",
      "The classification loss after processing this batch is:  0.2721463441848755\n",
      "The representation loss after processing this batch is:  0.003208514302968979\n",
      "\n",
      "The classification loss after processing this batch is:  0.3436081111431122\n",
      "The representation loss after processing this batch is:  0.003261599689722061\n",
      "\n",
      "The classification loss after processing this batch is:  0.20305703580379486\n",
      "The representation loss after processing this batch is:  0.0028992146253585815\n",
      "\n",
      "The classification loss after processing this batch is:  0.11946269124746323\n",
      "The representation loss after processing this batch is:  0.0030656978487968445\n",
      "\n",
      "The classification loss after processing this batch is:  0.11344218254089355\n",
      "The representation loss after processing this batch is:  0.002870820462703705\n",
      "\n",
      "The classification loss after processing this batch is:  0.08983262628316879\n",
      "The representation loss after processing this batch is:  0.002848908305168152\n",
      "\n",
      "The classification loss after processing this batch is:  0.25448179244995117\n",
      "The representation loss after processing this batch is:  0.0026574432849884033\n",
      "\n",
      "The classification loss after processing this batch is:  0.16336525976657867\n",
      "The representation loss after processing this batch is:  0.00324413925409317\n",
      "\n",
      "The classification loss after processing this batch is:  0.138058140873909\n",
      "The representation loss after processing this batch is:  0.0031541138887405396\n",
      "\n",
      "The classification loss after processing this batch is:  0.24374423921108246\n",
      "The representation loss after processing this batch is:  0.002496667206287384\n",
      "\n",
      "The classification loss after processing this batch is:  0.03521452844142914\n",
      "The representation loss after processing this batch is:  0.002656497061252594\n",
      "\n",
      "The classification loss after processing this batch is:  0.05269600450992584\n",
      "The representation loss after processing this batch is:  0.0027757808566093445\n",
      "\n",
      "The classification loss after processing this batch is:  0.09933071583509445\n",
      "The representation loss after processing this batch is:  0.002787873148918152\n",
      "\n",
      "The classification loss after processing this batch is:  0.15909145772457123\n",
      "The representation loss after processing this batch is:  0.002330571413040161\n",
      "\n",
      "The classification loss after processing this batch is:  0.17653746902942657\n",
      "The representation loss after processing this batch is:  0.0027064457535743713\n",
      "\n",
      "The classification loss after processing this batch is:  0.0956965982913971\n",
      "The representation loss after processing this batch is:  0.0027180910110473633\n",
      "\n",
      "The classification loss after processing this batch is:  0.11811313033103943\n",
      "The representation loss after processing this batch is:  0.0027932673692703247\n",
      "\n",
      "The classification loss after processing this batch is:  0.0508025661110878\n",
      "The representation loss after processing this batch is:  0.0026242733001708984\n",
      "\n",
      "The classification loss after processing this batch is:  0.09987035393714905\n",
      "The representation loss after processing this batch is:  0.0024856626987457275\n",
      "\n",
      "The classification loss after processing this batch is:  0.07973800599575043\n",
      "The representation loss after processing this batch is:  0.0027465373277664185\n",
      "\n",
      "The classification loss after processing this batch is:  0.07610148936510086\n",
      "The representation loss after processing this batch is:  0.002921678125858307\n",
      "\n",
      "The classification loss after processing this batch is:  0.10344283282756805\n",
      "The representation loss after processing this batch is:  0.002671506255865097\n",
      "\n",
      "The classification loss after processing this batch is:  0.14916127920150757\n",
      "The representation loss after processing this batch is:  0.002598792314529419\n",
      "\n",
      "The classification loss after processing this batch is:  0.19663317501544952\n",
      "The representation loss after processing this batch is:  0.002899467945098877\n",
      "\n",
      "The classification loss after processing this batch is:  0.05196555331349373\n",
      "The representation loss after processing this batch is:  0.002401541918516159\n",
      "\n",
      "The classification loss after processing this batch is:  0.06929092109203339\n",
      "The representation loss after processing this batch is:  0.002573542296886444\n",
      "\n",
      "The classification loss after processing this batch is:  0.08332623541355133\n",
      "The representation loss after processing this batch is:  0.003214620053768158\n",
      "\n",
      "The classification loss after processing this batch is:  0.15772031247615814\n",
      "The representation loss after processing this batch is:  0.00273311510682106\n",
      "\n",
      "The classification loss after processing this batch is:  0.08002983033657074\n",
      "The representation loss after processing this batch is:  0.003425031900405884\n",
      "\n",
      "The classification loss after processing this batch is:  0.15770959854125977\n",
      "The representation loss after processing this batch is:  0.0030981674790382385\n",
      "\n",
      "The classification loss after processing this batch is:  0.20175981521606445\n",
      "The representation loss after processing this batch is:  0.0027421340346336365\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.16891442239284515\n",
      "The representation loss after processing this batch is:  0.0028793811798095703\n",
      "\n",
      "The classification loss after processing this batch is:  0.17401260137557983\n",
      "The representation loss after processing this batch is:  0.0028484538197517395\n",
      "\n",
      "The classification loss after processing this batch is:  0.08348586410284042\n",
      "The representation loss after processing this batch is:  0.002781316637992859\n",
      "\n",
      "The classification loss after processing this batch is:  0.14222274720668793\n",
      "The representation loss after processing this batch is:  0.002482183277606964\n",
      "\n",
      "The classification loss after processing this batch is:  0.14878441393375397\n",
      "The representation loss after processing this batch is:  0.002440527081489563\n",
      "\n",
      "The classification loss after processing this batch is:  0.09530460089445114\n",
      "The representation loss after processing this batch is:  0.0027530714869499207\n",
      "\n",
      "The classification loss after processing this batch is:  0.03392843157052994\n",
      "The representation loss after processing this batch is:  0.0024204999208450317\n",
      "\n",
      "The classification loss after processing this batch is:  0.2250347137451172\n",
      "The representation loss after processing this batch is:  0.0029052942991256714\n",
      "\n",
      "The classification loss after processing this batch is:  0.2794171869754791\n",
      "The representation loss after processing this batch is:  0.0025146566331386566\n",
      "\n",
      "The classification loss after processing this batch is:  0.10119438171386719\n",
      "The representation loss after processing this batch is:  0.0026371777057647705\n",
      "\n",
      "The classification loss after processing this batch is:  0.23311305046081543\n",
      "The representation loss after processing this batch is:  0.002704121172428131\n",
      "\n",
      "The classification loss after processing this batch is:  0.23757663369178772\n",
      "The representation loss after processing this batch is:  0.002893991768360138\n",
      "\n",
      "The classification loss after processing this batch is:  0.318051278591156\n",
      "The representation loss after processing this batch is:  0.0028028860688209534\n",
      "\n",
      "The classification loss after processing this batch is:  0.15628275275230408\n",
      "The representation loss after processing this batch is:  0.0028010308742523193\n",
      "\n",
      "The classification loss after processing this batch is:  0.10747279971837997\n",
      "The representation loss after processing this batch is:  0.0027309581637382507\n",
      "\n",
      "The classification loss after processing this batch is:  0.16348828375339508\n",
      "The representation loss after processing this batch is:  0.0031458064913749695\n",
      "\n",
      "The classification loss after processing this batch is:  0.08920247852802277\n",
      "The representation loss after processing this batch is:  0.0028683170676231384\n",
      "\n",
      "The classification loss after processing this batch is:  0.04996747523546219\n",
      "The representation loss after processing this batch is:  0.0027383342385292053\n",
      "\n",
      "The classification loss after processing this batch is:  0.07020919770002365\n",
      "The representation loss after processing this batch is:  0.0025906413793563843\n",
      "\n",
      "The classification loss after processing this batch is:  0.06589873135089874\n",
      "The representation loss after processing this batch is:  0.002759404480457306\n",
      "\n",
      "The classification loss after processing this batch is:  0.0477474182844162\n",
      "The representation loss after processing this batch is:  0.0027013570070266724\n",
      "\n",
      "The classification loss after processing this batch is:  0.1473449021577835\n",
      "The representation loss after processing this batch is:  0.002612084150314331\n",
      "\n",
      "The classification loss after processing this batch is:  0.14797016978263855\n",
      "The representation loss after processing this batch is:  0.002447456121444702\n",
      "\n",
      "The classification loss after processing this batch is:  0.06187644973397255\n",
      "The representation loss after processing this batch is:  0.002863369882106781\n",
      "\n",
      "The classification loss after processing this batch is:  0.11152232438325882\n",
      "The representation loss after processing this batch is:  0.002736523747444153\n",
      "\n",
      "The classification loss after processing this batch is:  0.11908949911594391\n",
      "The representation loss after processing this batch is:  0.0029330402612686157\n",
      "\n",
      "The classification loss after processing this batch is:  0.03903202340006828\n",
      "The representation loss after processing this batch is:  0.0028259754180908203\n",
      "\n",
      "The classification loss after processing this batch is:  0.1944880485534668\n",
      "The representation loss after processing this batch is:  0.0027416497468948364\n",
      "\n",
      "The classification loss after processing this batch is:  0.09314827620983124\n",
      "The representation loss after processing this batch is:  0.002619616687297821\n",
      "\n",
      "The classification loss after processing this batch is:  0.24830558896064758\n",
      "The representation loss after processing this batch is:  0.00244729220867157\n",
      "\n",
      "The classification loss after processing this batch is:  0.13447727262973785\n",
      "The representation loss after processing this batch is:  0.003096938133239746\n",
      "\n",
      "The classification loss after processing this batch is:  0.14548438787460327\n",
      "The representation loss after processing this batch is:  0.0024272315204143524\n",
      "\n",
      "The classification loss after processing this batch is:  0.04847099632024765\n",
      "The representation loss after processing this batch is:  0.002641819417476654\n",
      "\n",
      "The classification loss after processing this batch is:  0.04435105621814728\n",
      "The representation loss after processing this batch is:  0.0026261135935783386\n",
      "\n",
      "The classification loss after processing this batch is:  0.14786475896835327\n",
      "The representation loss after processing this batch is:  0.002625301480293274\n",
      "\n",
      "The classification loss after processing this batch is:  0.05007403343915939\n",
      "The representation loss after processing this batch is:  0.0029232725501060486\n",
      "\n",
      "The classification loss after processing this batch is:  0.12863436341285706\n",
      "The representation loss after processing this batch is:  0.0028097257018089294\n",
      "\n",
      "The classification loss after processing this batch is:  0.08949735015630722\n",
      "The representation loss after processing this batch is:  0.0026595741510391235\n",
      "\n",
      "The classification loss after processing this batch is:  0.1184581071138382\n",
      "The representation loss after processing this batch is:  0.0029009580612182617\n",
      "\n",
      "The classification loss after processing this batch is:  0.12672045826911926\n",
      "The representation loss after processing this batch is:  0.0026124417781829834\n",
      "\n",
      "The classification loss after processing this batch is:  0.09680101275444031\n",
      "The representation loss after processing this batch is:  0.0027732402086257935\n",
      "\n",
      "The classification loss after processing this batch is:  0.14472238719463348\n",
      "The representation loss after processing this batch is:  0.0029317066073417664\n",
      "\n",
      "The classification loss after processing this batch is:  0.15237337350845337\n",
      "The representation loss after processing this batch is:  0.002572201192378998\n",
      "\n",
      "The classification loss after processing this batch is:  0.147416889667511\n",
      "The representation loss after processing this batch is:  0.002828747034072876\n",
      "\n",
      "The classification loss after processing this batch is:  0.18029960989952087\n",
      "The representation loss after processing this batch is:  0.0027958378195762634\n",
      "\n",
      "The classification loss after processing this batch is:  0.2048662155866623\n",
      "The representation loss after processing this batch is:  0.002786293625831604\n",
      "\n",
      "The classification loss after processing this batch is:  0.13697212934494019\n",
      "The representation loss after processing this batch is:  0.0024770721793174744\n",
      "\n",
      "The classification loss after processing this batch is:  0.10588838160037994\n",
      "The representation loss after processing this batch is:  0.0027192160487174988\n",
      "\n",
      "The classification loss after processing this batch is:  0.07432349026203156\n",
      "The representation loss after processing this batch is:  0.002616964280605316\n",
      "\n",
      "The classification loss after processing this batch is:  0.08635281771421432\n",
      "The representation loss after processing this batch is:  0.002890944480895996\n",
      "\n",
      "The classification loss after processing this batch is:  0.0780358836054802\n",
      "The representation loss after processing this batch is:  0.0028265714645385742\n",
      "\n",
      "The classification loss after processing this batch is:  0.09807118773460388\n",
      "The representation loss after processing this batch is:  0.0023887045681476593\n",
      "\n",
      "The classification loss after processing this batch is:  0.08230564743280411\n",
      "The representation loss after processing this batch is:  0.0027359798550605774\n",
      "\n",
      "The classification loss after processing this batch is:  0.10678870230913162\n",
      "The representation loss after processing this batch is:  0.002865836024284363\n",
      "\n",
      "The classification loss after processing this batch is:  0.072662353515625\n",
      "The representation loss after processing this batch is:  0.002620801329612732\n",
      "\n",
      "The classification loss after processing this batch is:  0.13948799669742584\n",
      "The representation loss after processing this batch is:  0.002655632793903351\n",
      "\n",
      "The classification loss after processing this batch is:  0.08924500644207001\n",
      "The representation loss after processing this batch is:  0.002825811505317688\n",
      "\n",
      "The classification loss after processing this batch is:  0.1467595249414444\n",
      "The representation loss after processing this batch is:  0.0027318373322486877\n",
      "\n",
      "The classification loss after processing this batch is:  0.15198126435279846\n",
      "The representation loss after processing this batch is:  0.0028951242566108704\n",
      "\n",
      "The classification loss after processing this batch is:  0.11022915691137314\n",
      "The representation loss after processing this batch is:  0.00290863960981369\n",
      "\n",
      "The classification loss after processing this batch is:  0.09055303037166595\n",
      "The representation loss after processing this batch is:  0.002999626100063324\n",
      "\n",
      "The classification loss after processing this batch is:  0.18674398958683014\n",
      "The representation loss after processing this batch is:  0.0027853548526763916\n",
      "\n",
      "The classification loss after processing this batch is:  0.0695178359746933\n",
      "The representation loss after processing this batch is:  0.0028448253870010376\n",
      "\n",
      "The classification loss after processing this batch is:  0.06745970994234085\n",
      "The representation loss after processing this batch is:  0.0026421919465065002\n",
      "\n",
      "The classification loss after processing this batch is:  0.10082273185253143\n",
      "The representation loss after processing this batch is:  0.0026012882590293884\n",
      "\n",
      "The classification loss after processing this batch is:  0.07673456519842148\n",
      "The representation loss after processing this batch is:  0.0026108473539352417\n",
      "\n",
      "The classification loss after processing this batch is:  0.1835496574640274\n",
      "The representation loss after processing this batch is:  0.0022583305835723877\n",
      "\n",
      "The classification loss after processing this batch is:  0.16763676702976227\n",
      "The representation loss after processing this batch is:  0.0025648772716522217\n",
      "\n",
      "The classification loss after processing this batch is:  0.14007431268692017\n",
      "The representation loss after processing this batch is:  0.0030371323227882385\n",
      "\n",
      "The classification loss after processing this batch is:  0.08701165020465851\n",
      "The representation loss after processing this batch is:  0.0030182674527168274\n",
      "\n",
      "The classification loss after processing this batch is:  0.11753423511981964\n",
      "The representation loss after processing this batch is:  0.0026535391807556152\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2368754744529724\n",
      "The representation loss after processing this batch is:  0.0027084872126579285\n",
      "\n",
      "The classification loss after processing this batch is:  0.047950394451618195\n",
      "The representation loss after processing this batch is:  0.002754613757133484\n",
      "\n",
      "The classification loss after processing this batch is:  0.09463144838809967\n",
      "The representation loss after processing this batch is:  0.002930760383605957\n",
      "\n",
      "The classification loss after processing this batch is:  0.1753263771533966\n",
      "The representation loss after processing this batch is:  0.002468787133693695\n",
      "\n",
      "The classification loss after processing this batch is:  0.34506815671920776\n",
      "The representation loss after processing this batch is:  0.0029023215174674988\n",
      "\n",
      "The classification loss after processing this batch is:  0.07651158422231674\n",
      "The representation loss after processing this batch is:  0.0026473402976989746\n",
      "\n",
      "The classification loss after processing this batch is:  0.1519896388053894\n",
      "The representation loss after processing this batch is:  0.002318844199180603\n",
      "\n",
      "The classification loss after processing this batch is:  0.0797475278377533\n",
      "The representation loss after processing this batch is:  0.0026702284812927246\n",
      "\n",
      "The classification loss after processing this batch is:  0.04916965216398239\n",
      "The representation loss after processing this batch is:  0.0028412416577339172\n",
      "\n",
      "The classification loss after processing this batch is:  0.10749948769807816\n",
      "The representation loss after processing this batch is:  0.003308437764644623\n",
      "\n",
      "The classification loss after processing this batch is:  0.11425738036632538\n",
      "The representation loss after processing this batch is:  0.0037931501865386963\n",
      "\n",
      "The classification loss after processing this batch is:  0.06353535503149033\n",
      "The representation loss after processing this batch is:  0.003037724643945694\n",
      "\n",
      "The classification loss after processing this batch is:  0.052737124264240265\n",
      "The representation loss after processing this batch is:  0.002484358847141266\n",
      "\n",
      "The classification loss after processing this batch is:  0.16144560277462006\n",
      "The representation loss after processing this batch is:  0.0028380267322063446\n",
      "\n",
      "The classification loss after processing this batch is:  0.12217282503843307\n",
      "The representation loss after processing this batch is:  0.0027076154947280884\n",
      "\n",
      "The classification loss after processing this batch is:  0.07686202973127365\n",
      "The representation loss after processing this batch is:  0.0025266632437705994\n",
      "\n",
      "The classification loss after processing this batch is:  0.0759345144033432\n",
      "The representation loss after processing this batch is:  0.0028024837374687195\n",
      "\n",
      "The classification loss after processing this batch is:  0.15077994763851166\n",
      "The representation loss after processing this batch is:  0.0027199983596801758\n",
      "\n",
      "The classification loss after processing this batch is:  0.16068747639656067\n",
      "The representation loss after processing this batch is:  0.0027088597416877747\n",
      "\n",
      "The classification loss after processing this batch is:  0.2229212075471878\n",
      "The representation loss after processing this batch is:  0.0023888051509857178\n",
      "\n",
      "The classification loss after processing this batch is:  0.1186770498752594\n",
      "The representation loss after processing this batch is:  0.0027742162346839905\n",
      "\n",
      "The classification loss after processing this batch is:  0.24583688378334045\n",
      "The representation loss after processing this batch is:  0.002573169767856598\n",
      "\n",
      "The classification loss after processing this batch is:  0.08781502395868301\n",
      "The representation loss after processing this batch is:  0.002928316593170166\n",
      "\n",
      "The classification loss after processing this batch is:  0.09544561803340912\n",
      "The representation loss after processing this batch is:  0.003201603889465332\n",
      "\n",
      "The classification loss after processing this batch is:  0.0729457437992096\n",
      "The representation loss after processing this batch is:  0.0026409700512886047\n",
      "\n",
      "The classification loss after processing this batch is:  0.0683116689324379\n",
      "The representation loss after processing this batch is:  0.0026064664125442505\n",
      "\n",
      "The classification loss after processing this batch is:  0.17918357253074646\n",
      "The representation loss after processing this batch is:  0.0026165172457695007\n",
      "\n",
      "The classification loss after processing this batch is:  0.08634205907583237\n",
      "The representation loss after processing this batch is:  0.002967916429042816\n",
      "\n",
      "The classification loss after processing this batch is:  0.05161388963460922\n",
      "The representation loss after processing this batch is:  0.0026621222496032715\n",
      "\n",
      "The classification loss after processing this batch is:  0.054701175540685654\n",
      "The representation loss after processing this batch is:  0.0032355859875679016\n",
      "\n",
      "The classification loss after processing this batch is:  0.032645031809806824\n",
      "The representation loss after processing this batch is:  0.003063574433326721\n",
      "\n",
      "The classification loss after processing this batch is:  0.0510624535381794\n",
      "The representation loss after processing this batch is:  0.003564000129699707\n",
      "\n",
      "The classification loss after processing this batch is:  0.07967065274715424\n",
      "The representation loss after processing this batch is:  0.002940155565738678\n",
      "\n",
      "The classification loss after processing this batch is:  0.06065572053194046\n",
      "The representation loss after processing this batch is:  0.002991795539855957\n",
      "\n",
      "The classification loss after processing this batch is:  0.019001659005880356\n",
      "The representation loss after processing this batch is:  0.0028444677591323853\n",
      "\n",
      "The classification loss after processing this batch is:  0.0502781867980957\n",
      "The representation loss after processing this batch is:  0.003276720643043518\n",
      "\n",
      "The classification loss after processing this batch is:  0.07415946573019028\n",
      "The representation loss after processing this batch is:  0.003617420792579651\n",
      "\n",
      "The classification loss after processing this batch is:  0.01608029194176197\n",
      "The representation loss after processing this batch is:  0.0038969963788986206\n",
      "\n",
      "The classification loss after processing this batch is:  0.02868836373090744\n",
      "The representation loss after processing this batch is:  0.003130495548248291\n",
      "\n",
      "The classification loss after processing this batch is:  0.18134644627571106\n",
      "The representation loss after processing this batch is:  0.003005281090736389\n",
      "\n",
      "The classification loss after processing this batch is:  0.03908315673470497\n",
      "The representation loss after processing this batch is:  0.0031940191984176636\n",
      "\n",
      "The classification loss after processing this batch is:  0.01996590383350849\n",
      "The representation loss after processing this batch is:  0.0030108466744422913\n",
      "\n",
      "The classification loss after processing this batch is:  0.04324197769165039\n",
      "The representation loss after processing this batch is:  0.0034972578287124634\n",
      "\n",
      "The classification loss after processing this batch is:  0.029855625703930855\n",
      "The representation loss after processing this batch is:  0.003053337335586548\n",
      "\n",
      "The classification loss after processing this batch is:  0.023801246657967567\n",
      "The representation loss after processing this batch is:  0.0029412880539894104\n",
      "\n",
      "The classification loss after processing this batch is:  0.018505001440644264\n",
      "The representation loss after processing this batch is:  0.0033157169818878174\n",
      "\n",
      "The classification loss after processing this batch is:  0.017927980050444603\n",
      "The representation loss after processing this batch is:  0.003644399344921112\n",
      "\n",
      "The classification loss after processing this batch is:  0.3767980635166168\n",
      "The representation loss after processing this batch is:  0.0037975013256073\n",
      "\n",
      "The classification loss after processing this batch is:  0.296939492225647\n",
      "The representation loss after processing this batch is:  0.0034198835492134094\n",
      "\n",
      "The classification loss after processing this batch is:  0.21717382967472076\n",
      "The representation loss after processing this batch is:  0.003987051546573639\n",
      "\n",
      "The classification loss after processing this batch is:  0.04879096895456314\n",
      "The representation loss after processing this batch is:  0.0029553771018981934\n",
      "\n",
      "The classification loss after processing this batch is:  0.016208648681640625\n",
      "The representation loss after processing this batch is:  0.0034060925245285034\n",
      "\n",
      "The classification loss after processing this batch is:  0.01746734045445919\n",
      "The representation loss after processing this batch is:  0.002570435404777527\n",
      "\n",
      "The classification loss after processing this batch is:  0.08867523074150085\n",
      "The representation loss after processing this batch is:  0.0025666356086730957\n",
      "\n",
      "The classification loss after processing this batch is:  0.36058056354522705\n",
      "The representation loss after processing this batch is:  0.0030359625816345215\n",
      "\n",
      "The classification loss after processing this batch is:  0.06675945967435837\n",
      "The representation loss after processing this batch is:  0.0029247626662254333\n",
      "\n",
      "The classification loss after processing this batch is:  0.041190918534994125\n",
      "The representation loss after processing this batch is:  0.0034505650401115417\n",
      "\n",
      "The classification loss after processing this batch is:  0.04701744392514229\n",
      "The representation loss after processing this batch is:  0.0033471062779426575\n",
      "\n",
      "The classification loss after processing this batch is:  0.04523312300443649\n",
      "The representation loss after processing this batch is:  0.003944523632526398\n",
      "\n",
      "The classification loss after processing this batch is:  0.10927462577819824\n",
      "The representation loss after processing this batch is:  0.0024732425808906555\n",
      "\n",
      "The classification loss after processing this batch is:  0.045399945229291916\n",
      "The representation loss after processing this batch is:  0.0024392828345298767\n",
      "\n",
      "The classification loss after processing this batch is:  0.12568582594394684\n",
      "The representation loss after processing this batch is:  0.0027019381523132324\n",
      "\n",
      "The classification loss after processing this batch is:  0.12015294283628464\n",
      "The representation loss after processing this batch is:  0.0024906210601329803\n",
      "\n",
      "The classification loss after processing this batch is:  0.16950221359729767\n",
      "The representation loss after processing this batch is:  0.00270138680934906\n",
      "\n",
      "The classification loss after processing this batch is:  0.0515068918466568\n",
      "The representation loss after processing this batch is:  0.002933129668235779\n",
      "\n",
      "The classification loss after processing this batch is:  0.08652167022228241\n",
      "The representation loss after processing this batch is:  0.003037586808204651\n",
      "\n",
      "The classification loss after processing this batch is:  0.08849699050188065\n",
      "The representation loss after processing this batch is:  0.002579711377620697\n",
      "\n",
      "The classification loss after processing this batch is:  0.12068410962820053\n",
      "The representation loss after processing this batch is:  0.0024043768644332886\n",
      "\n",
      "The classification loss after processing this batch is:  0.09846611320972443\n",
      "The representation loss after processing this batch is:  0.002660401165485382\n",
      "\n",
      "The classification loss after processing this batch is:  0.15554408729076385\n",
      "The representation loss after processing this batch is:  0.0022746622562408447\n",
      "\n",
      "The classification loss after processing this batch is:  0.08653541654348373\n",
      "The representation loss after processing this batch is:  0.0025974251329898834\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.12053437530994415\n",
      "The representation loss after processing this batch is:  0.002948082983493805\n",
      "\n",
      "The classification loss after processing this batch is:  0.05454104766249657\n",
      "The representation loss after processing this batch is:  0.002656713128089905\n",
      "\n",
      "The classification loss after processing this batch is:  0.26220059394836426\n",
      "The representation loss after processing this batch is:  0.0028348341584205627\n",
      "\n",
      "The classification loss after processing this batch is:  0.14410008490085602\n",
      "The representation loss after processing this batch is:  0.00273963063955307\n",
      "\n",
      "The classification loss after processing this batch is:  0.15680748224258423\n",
      "The representation loss after processing this batch is:  0.0026261024177074432\n",
      "\n",
      "The classification loss after processing this batch is:  0.22869181632995605\n",
      "The representation loss after processing this batch is:  0.0033270902931690216\n",
      "\n",
      "The classification loss after processing this batch is:  0.14900900423526764\n",
      "The representation loss after processing this batch is:  0.0029681622982025146\n",
      "\n",
      "The classification loss after processing this batch is:  0.07405642420053482\n",
      "The representation loss after processing this batch is:  0.0029483437538146973\n",
      "\n",
      "The classification loss after processing this batch is:  0.24124187231063843\n",
      "The representation loss after processing this batch is:  0.003550112247467041\n",
      "\n",
      "The classification loss after processing this batch is:  0.13542461395263672\n",
      "The representation loss after processing this batch is:  0.002940632402896881\n",
      "\n",
      "The classification loss after processing this batch is:  0.30761539936065674\n",
      "The representation loss after processing this batch is:  0.0027624890208244324\n",
      "\n",
      "The classification loss after processing this batch is:  0.08858920633792877\n",
      "The representation loss after processing this batch is:  0.0024835318326950073\n",
      "\n",
      "The classification loss after processing this batch is:  0.06264569610357285\n",
      "The representation loss after processing this batch is:  0.00257255882024765\n",
      "\n",
      "The classification loss after processing this batch is:  0.08674243092536926\n",
      "The representation loss after processing this batch is:  0.002406306564807892\n",
      "\n",
      "The classification loss after processing this batch is:  0.11896082013845444\n",
      "The representation loss after processing this batch is:  0.0024798251688480377\n",
      "\n",
      "The classification loss after processing this batch is:  0.07712578773498535\n",
      "The representation loss after processing this batch is:  0.002613857388496399\n",
      "\n",
      "The classification loss after processing this batch is:  0.05972547456622124\n",
      "The representation loss after processing this batch is:  0.0026799216866493225\n",
      "\n",
      "The classification loss after processing this batch is:  0.052150361239910126\n",
      "The representation loss after processing this batch is:  0.002815559506416321\n",
      "\n",
      "The classification loss after processing this batch is:  0.04681340232491493\n",
      "The representation loss after processing this batch is:  0.0024763457477092743\n",
      "\n",
      "The classification loss after processing this batch is:  0.06992573291063309\n",
      "The representation loss after processing this batch is:  0.002782367169857025\n",
      "\n",
      "The classification loss after processing this batch is:  0.17289665341377258\n",
      "The representation loss after processing this batch is:  0.002803623676300049\n",
      "\n",
      "The classification loss after processing this batch is:  0.0819704458117485\n",
      "The representation loss after processing this batch is:  0.0031026676297187805\n",
      "\n",
      "The classification loss after processing this batch is:  0.12359323352575302\n",
      "The representation loss after processing this batch is:  0.0022898539900779724\n",
      "\n",
      "The classification loss after processing this batch is:  0.0541859045624733\n",
      "The representation loss after processing this batch is:  0.002767302095890045\n",
      "\n",
      "The classification loss after processing this batch is:  0.053490735590457916\n",
      "The representation loss after processing this batch is:  0.0026575326919555664\n",
      "\n",
      "The classification loss after processing this batch is:  0.1204163059592247\n",
      "The representation loss after processing this batch is:  0.0027587413787841797\n",
      "\n",
      "The classification loss after processing this batch is:  0.04309402406215668\n",
      "The representation loss after processing this batch is:  0.0028816908597946167\n",
      "\n",
      "The classification loss after processing this batch is:  0.05726790055632591\n",
      "The representation loss after processing this batch is:  0.0026737377047538757\n",
      "\n",
      "The classification loss after processing this batch is:  0.16870369017124176\n",
      "The representation loss after processing this batch is:  0.002975933253765106\n",
      "\n",
      "The classification loss after processing this batch is:  0.09092499315738678\n",
      "The representation loss after processing this batch is:  0.002682015299797058\n",
      "\n",
      "The classification loss after processing this batch is:  0.09985125064849854\n",
      "The representation loss after processing this batch is:  0.002416737377643585\n",
      "\n",
      "The classification loss after processing this batch is:  0.13758014142513275\n",
      "The representation loss after processing this batch is:  0.002463303506374359\n",
      "\n",
      "The classification loss after processing this batch is:  0.11047086864709854\n",
      "The representation loss after processing this batch is:  0.002515338361263275\n",
      "\n",
      "The classification loss after processing this batch is:  0.12006314843893051\n",
      "The representation loss after processing this batch is:  0.0023461580276489258\n",
      "\n",
      "The classification loss after processing this batch is:  0.20258741080760956\n",
      "The representation loss after processing this batch is:  0.0026104897260665894\n",
      "\n",
      "The classification loss after processing this batch is:  0.05606796592473984\n",
      "The representation loss after processing this batch is:  0.0026650354266166687\n",
      "\n",
      "The classification loss after processing this batch is:  0.13155297935009003\n",
      "The representation loss after processing this batch is:  0.002849780023097992\n",
      "\n",
      "The classification loss after processing this batch is:  0.07308284193277359\n",
      "The representation loss after processing this batch is:  0.0024657174944877625\n",
      "\n",
      "The classification loss after processing this batch is:  0.11681678891181946\n",
      "The representation loss after processing this batch is:  0.0027402639389038086\n",
      "\n",
      "The classification loss after processing this batch is:  0.10366179794073105\n",
      "The representation loss after processing this batch is:  0.0029728859663009644\n",
      "\n",
      "The classification loss after processing this batch is:  0.058122940361499786\n",
      "The representation loss after processing this batch is:  0.0027398094534873962\n",
      "\n",
      "The classification loss after processing this batch is:  0.09810922294855118\n",
      "The representation loss after processing this batch is:  0.0027595236897468567\n",
      "\n",
      "The classification loss after processing this batch is:  0.10421477258205414\n",
      "The representation loss after processing this batch is:  0.002772130072116852\n",
      "\n",
      "The classification loss after processing this batch is:  0.10977008193731308\n",
      "The representation loss after processing this batch is:  0.00265677273273468\n",
      "\n",
      "The classification loss after processing this batch is:  0.1526346355676651\n",
      "The representation loss after processing this batch is:  0.002431020140647888\n",
      "\n",
      "The classification loss after processing this batch is:  0.08543150871992111\n",
      "The representation loss after processing this batch is:  0.003210112452507019\n",
      "\n",
      "The classification loss after processing this batch is:  0.1487838178873062\n",
      "The representation loss after processing this batch is:  0.0026931390166282654\n",
      "\n",
      "The classification loss after processing this batch is:  0.08165223896503448\n",
      "The representation loss after processing this batch is:  0.002587363123893738\n",
      "\n",
      "The classification loss after processing this batch is:  0.049448952078819275\n",
      "The representation loss after processing this batch is:  0.0024836845695972443\n",
      "\n",
      "The classification loss after processing this batch is:  0.14000174403190613\n",
      "The representation loss after processing this batch is:  0.0026835203170776367\n",
      "\n",
      "The classification loss after processing this batch is:  0.11831977218389511\n",
      "The representation loss after processing this batch is:  0.0026716887950897217\n",
      "\n",
      "The classification loss after processing this batch is:  0.08129267394542694\n",
      "The representation loss after processing this batch is:  0.0026471465826034546\n",
      "\n",
      "The classification loss after processing this batch is:  0.0819116085767746\n",
      "The representation loss after processing this batch is:  0.0025437623262405396\n",
      "\n",
      "The classification loss after processing this batch is:  0.0603271946310997\n",
      "The representation loss after processing this batch is:  0.0023937225341796875\n",
      "\n",
      "The classification loss after processing this batch is:  0.10294152051210403\n",
      "The representation loss after processing this batch is:  0.002760961651802063\n",
      "\n",
      "The classification loss after processing this batch is:  0.1337873339653015\n",
      "The representation loss after processing this batch is:  0.002302899956703186\n",
      "\n",
      "The classification loss after processing this batch is:  0.05779554694890976\n",
      "The representation loss after processing this batch is:  0.002384088933467865\n",
      "\n",
      "The classification loss after processing this batch is:  0.1667923927307129\n",
      "The representation loss after processing this batch is:  0.002808649092912674\n",
      "\n",
      "The classification loss after processing this batch is:  0.10737696290016174\n",
      "The representation loss after processing this batch is:  0.0024511106312274933\n",
      "\n",
      "The classification loss after processing this batch is:  0.08214061707258224\n",
      "The representation loss after processing this batch is:  0.0025922060012817383\n",
      "\n",
      "The classification loss after processing this batch is:  0.08507808297872543\n",
      "The representation loss after processing this batch is:  0.0022812187671661377\n",
      "\n",
      "The classification loss after processing this batch is:  0.07234083116054535\n",
      "The representation loss after processing this batch is:  0.0028913915157318115\n",
      "\n",
      "The classification loss after processing this batch is:  0.09295237809419632\n",
      "The representation loss after processing this batch is:  0.0022252388298511505\n",
      "\n",
      "The classification loss after processing this batch is:  0.1637842059135437\n",
      "The representation loss after processing this batch is:  0.0027158409357070923\n",
      "\n",
      "The classification loss after processing this batch is:  0.06191966310143471\n",
      "The representation loss after processing this batch is:  0.0025178194046020508\n",
      "\n",
      "The classification loss after processing this batch is:  0.2582851052284241\n",
      "The representation loss after processing this batch is:  0.002618752419948578\n",
      "\n",
      "The classification loss after processing this batch is:  0.11865736544132233\n",
      "The representation loss after processing this batch is:  0.00255424901843071\n",
      "\n",
      "The classification loss after processing this batch is:  0.08769568800926208\n",
      "The representation loss after processing this batch is:  0.00318107008934021\n",
      "\n",
      "The classification loss after processing this batch is:  0.09890012443065643\n",
      "The representation loss after processing this batch is:  0.002562187612056732\n",
      "\n",
      "The classification loss after processing this batch is:  0.08773276209831238\n",
      "The representation loss after processing this batch is:  0.002821192145347595\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.23406489193439484\n",
      "The representation loss after processing this batch is:  0.0029667839407920837\n",
      "\n",
      "The classification loss after processing this batch is:  0.11542381346225739\n",
      "The representation loss after processing this batch is:  0.002678424119949341\n",
      "\n",
      "The classification loss after processing this batch is:  0.12854328751564026\n",
      "The representation loss after processing this batch is:  0.0022599101066589355\n",
      "\n",
      "The classification loss after processing this batch is:  0.24353547394275665\n",
      "The representation loss after processing this batch is:  0.0026022866368293762\n",
      "\n",
      "The classification loss after processing this batch is:  0.1153726577758789\n",
      "The representation loss after processing this batch is:  0.0024903863668441772\n",
      "\n",
      "The classification loss after processing this batch is:  0.04826126992702484\n",
      "The representation loss after processing this batch is:  0.0026892274618148804\n",
      "\n",
      "The classification loss after processing this batch is:  0.13177044689655304\n",
      "The representation loss after processing this batch is:  0.002579301595687866\n",
      "\n",
      "The classification loss after processing this batch is:  0.14765141904354095\n",
      "The representation loss after processing this batch is:  0.002406097948551178\n",
      "\n",
      "The classification loss after processing this batch is:  0.1255742758512497\n",
      "The representation loss after processing this batch is:  0.002723313868045807\n",
      "\n",
      "The classification loss after processing this batch is:  0.05905436724424362\n",
      "The representation loss after processing this batch is:  0.0023104920983314514\n",
      "\n",
      "The classification loss after processing this batch is:  0.13596929609775543\n",
      "The representation loss after processing this batch is:  0.0023582130670547485\n",
      "\n",
      "The classification loss after processing this batch is:  0.13422241806983948\n",
      "The representation loss after processing this batch is:  0.0024529173970222473\n",
      "\n",
      "The classification loss after processing this batch is:  0.17524927854537964\n",
      "The representation loss after processing this batch is:  0.0029228702187538147\n",
      "\n",
      "The classification loss after processing this batch is:  0.16176848113536835\n",
      "The representation loss after processing this batch is:  0.0024664923548698425\n",
      "\n",
      "The classification loss after processing this batch is:  0.13119301199913025\n",
      "The representation loss after processing this batch is:  0.0029026269912719727\n",
      "\n",
      "The classification loss after processing this batch is:  0.12854616343975067\n",
      "The representation loss after processing this batch is:  0.0030418559908866882\n",
      "\n",
      "The classification loss after processing this batch is:  0.07010349631309509\n",
      "The representation loss after processing this batch is:  0.002961955964565277\n",
      "\n",
      "The classification loss after processing this batch is:  0.08315901458263397\n",
      "The representation loss after processing this batch is:  0.0026207715272903442\n",
      "\n",
      "The classification loss after processing this batch is:  0.044670019298791885\n",
      "The representation loss after processing this batch is:  0.0025672465562820435\n",
      "\n",
      "The classification loss after processing this batch is:  0.13942931592464447\n",
      "The representation loss after processing this batch is:  0.0028138235211372375\n",
      "\n",
      "The classification loss after processing this batch is:  0.0698603168129921\n",
      "The representation loss after processing this batch is:  0.002904064953327179\n",
      "\n",
      "The classification loss after processing this batch is:  0.2245643585920334\n",
      "The representation loss after processing this batch is:  0.0030508264899253845\n",
      "\n",
      "The classification loss after processing this batch is:  0.22805292904376984\n",
      "The representation loss after processing this batch is:  0.002883821725845337\n",
      "\n",
      "The classification loss after processing this batch is:  0.08998791128396988\n",
      "The representation loss after processing this batch is:  0.0028799399733543396\n",
      "\n",
      "The classification loss after processing this batch is:  0.08768569678068161\n",
      "The representation loss after processing this batch is:  0.0030037537217140198\n",
      "\n",
      "The classification loss after processing this batch is:  0.11829207092523575\n",
      "The representation loss after processing this batch is:  0.002400781959295273\n",
      "\n",
      "The classification loss after processing this batch is:  0.04191911220550537\n",
      "The representation loss after processing this batch is:  0.002800680696964264\n",
      "\n",
      "The classification loss after processing this batch is:  0.05627446249127388\n",
      "The representation loss after processing this batch is:  0.0026991143822669983\n",
      "\n",
      "The classification loss after processing this batch is:  0.1368202120065689\n",
      "The representation loss after processing this batch is:  0.0024757087230682373\n",
      "\n",
      "The classification loss after processing this batch is:  0.07496552169322968\n",
      "The representation loss after processing this batch is:  0.003177061676979065\n",
      "\n",
      "The classification loss after processing this batch is:  0.09190129488706589\n",
      "The representation loss after processing this batch is:  0.002776302397251129\n",
      "\n",
      "The classification loss after processing this batch is:  0.21466325223445892\n",
      "The representation loss after processing this batch is:  0.003401242196559906\n",
      "\n",
      "The classification loss after processing this batch is:  0.20347118377685547\n",
      "The representation loss after processing this batch is:  0.002538081258535385\n",
      "\n",
      "The classification loss after processing this batch is:  0.10511510074138641\n",
      "The representation loss after processing this batch is:  0.002703368663787842\n",
      "\n",
      "The classification loss after processing this batch is:  0.2116580754518509\n",
      "The representation loss after processing this batch is:  0.002996399998664856\n",
      "\n",
      "The classification loss after processing this batch is:  0.1312555968761444\n",
      "The representation loss after processing this batch is:  0.0025307685136795044\n",
      "\n",
      "The classification loss after processing this batch is:  0.06514760851860046\n",
      "The representation loss after processing this batch is:  0.002681948244571686\n",
      "\n",
      "The classification loss after processing this batch is:  0.15620867908000946\n",
      "The representation loss after processing this batch is:  0.00255400687456131\n",
      "\n",
      "The classification loss after processing this batch is:  0.35400164127349854\n",
      "The representation loss after processing this batch is:  0.003143526613712311\n",
      "\n",
      "The classification loss after processing this batch is:  0.1395305097103119\n",
      "The representation loss after processing this batch is:  0.003139398992061615\n",
      "\n",
      "The classification loss after processing this batch is:  0.11446662247180939\n",
      "The representation loss after processing this batch is:  0.002999834716320038\n",
      "\n",
      "The classification loss after processing this batch is:  0.06977072358131409\n",
      "The representation loss after processing this batch is:  0.0029948651790618896\n",
      "\n",
      "The classification loss after processing this batch is:  0.06711447238922119\n",
      "The representation loss after processing this batch is:  0.002897307276725769\n",
      "\n",
      "The classification loss after processing this batch is:  0.1170862689614296\n",
      "The representation loss after processing this batch is:  0.002810269594192505\n",
      "\n",
      "The classification loss after processing this batch is:  0.09819339215755463\n",
      "The representation loss after processing this batch is:  0.0028481855988502502\n",
      "\n",
      "The classification loss after processing this batch is:  0.11520038545131683\n",
      "The representation loss after processing this batch is:  0.0025994032621383667\n",
      "\n",
      "The classification loss after processing this batch is:  0.11071694642305374\n",
      "The representation loss after processing this batch is:  0.002699635922908783\n",
      "\n",
      "The classification loss after processing this batch is:  0.20446087419986725\n",
      "The representation loss after processing this batch is:  0.0029299557209014893\n",
      "\n",
      "The classification loss after processing this batch is:  0.07165654003620148\n",
      "The representation loss after processing this batch is:  0.002359490841627121\n",
      "\n",
      "The classification loss after processing this batch is:  0.1108856052160263\n",
      "The representation loss after processing this batch is:  0.002338118851184845\n",
      "\n",
      "The classification loss after processing this batch is:  0.09539362788200378\n",
      "The representation loss after processing this batch is:  0.002258099615573883\n",
      "\n",
      "The classification loss after processing this batch is:  0.11472704261541367\n",
      "The representation loss after processing this batch is:  0.0025489777326583862\n",
      "\n",
      "The classification loss after processing this batch is:  0.08840633183717728\n",
      "The representation loss after processing this batch is:  0.002583898603916168\n",
      "\n",
      "The classification loss after processing this batch is:  0.16984911262989044\n",
      "The representation loss after processing this batch is:  0.0026829540729522705\n",
      "\n",
      "The classification loss after processing this batch is:  0.1487778127193451\n",
      "The representation loss after processing this batch is:  0.0026662051677703857\n",
      "\n",
      "The classification loss after processing this batch is:  0.1549891084432602\n",
      "The representation loss after processing this batch is:  0.002511296421289444\n",
      "\n",
      "The classification loss after processing this batch is:  0.07129604369401932\n",
      "The representation loss after processing this batch is:  0.002723999321460724\n",
      "\n",
      "The classification loss after processing this batch is:  0.2065473049879074\n",
      "The representation loss after processing this batch is:  0.0026851221919059753\n",
      "\n",
      "The classification loss after processing this batch is:  0.15694379806518555\n",
      "The representation loss after processing this batch is:  0.002779535949230194\n",
      "\n",
      "The classification loss after processing this batch is:  0.16269336640834808\n",
      "The representation loss after processing this batch is:  0.002732016146183014\n",
      "\n",
      "The classification loss after processing this batch is:  0.07522249966859818\n",
      "The representation loss after processing this batch is:  0.0029480084776878357\n",
      "\n",
      "The classification loss after processing this batch is:  0.0931411162018776\n",
      "The representation loss after processing this batch is:  0.0033396556973457336\n",
      "\n",
      "The classification loss after processing this batch is:  0.24616768956184387\n",
      "The representation loss after processing this batch is:  0.0026758015155792236\n",
      "\n",
      "The classification loss after processing this batch is:  0.22752298414707184\n",
      "The representation loss after processing this batch is:  0.0024857260286808014\n",
      "\n",
      "The classification loss after processing this batch is:  0.23071818053722382\n",
      "The representation loss after processing this batch is:  0.0029782727360725403\n",
      "\n",
      "The classification loss after processing this batch is:  0.30892932415008545\n",
      "The representation loss after processing this batch is:  0.002663835883140564\n",
      "\n",
      "The classification loss after processing this batch is:  0.23103342950344086\n",
      "The representation loss after processing this batch is:  0.002404250204563141\n",
      "\n",
      "The classification loss after processing this batch is:  0.062415122985839844\n",
      "The representation loss after processing this batch is:  0.002559088170528412\n",
      "\n",
      "The classification loss after processing this batch is:  0.07355263829231262\n",
      "The representation loss after processing this batch is:  0.002615027129650116\n",
      "\n",
      "The classification loss after processing this batch is:  0.08649086207151413\n",
      "The representation loss after processing this batch is:  0.0029184967279434204\n",
      "\n",
      "The classification loss after processing this batch is:  0.1249384880065918\n",
      "The representation loss after processing this batch is:  0.003429919481277466\n",
      "\n",
      "The classification loss after processing this batch is:  0.039628688246011734\n",
      "The representation loss after processing this batch is:  0.00299854576587677\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.17473052442073822\n",
      "The representation loss after processing this batch is:  0.0035058408975601196\n",
      "\n",
      "The classification loss after processing this batch is:  0.14701509475708008\n",
      "The representation loss after processing this batch is:  0.0026098787784576416\n",
      "\n",
      "The classification loss after processing this batch is:  0.13698187470436096\n",
      "The representation loss after processing this batch is:  0.0027795881032943726\n",
      "\n",
      "The classification loss after processing this batch is:  0.19472375512123108\n",
      "The representation loss after processing this batch is:  0.0027011483907699585\n",
      "\n",
      "The classification loss after processing this batch is:  0.09739331156015396\n",
      "The representation loss after processing this batch is:  0.002924583852291107\n",
      "\n",
      "The classification loss after processing this batch is:  0.14506572484970093\n",
      "The representation loss after processing this batch is:  0.003360457718372345\n",
      "\n",
      "The classification loss after processing this batch is:  0.16328424215316772\n",
      "The representation loss after processing this batch is:  0.003038264811038971\n",
      "\n",
      "The classification loss after processing this batch is:  0.11252913624048233\n",
      "The representation loss after processing this batch is:  0.0031928494572639465\n",
      "\n",
      "The classification loss after processing this batch is:  0.11758029460906982\n",
      "The representation loss after processing this batch is:  0.002390347421169281\n",
      "\n",
      "The classification loss after processing this batch is:  0.06295677274465561\n",
      "The representation loss after processing this batch is:  0.002545185387134552\n",
      "\n",
      "The classification loss after processing this batch is:  0.04488266631960869\n",
      "The representation loss after processing this batch is:  0.0026418566703796387\n",
      "\n",
      "The classification loss after processing this batch is:  0.07787736505270004\n",
      "The representation loss after processing this batch is:  0.002544581890106201\n",
      "\n",
      "The classification loss after processing this batch is:  0.059971295297145844\n",
      "The representation loss after processing this batch is:  0.0025009550154209137\n",
      "\n",
      "The classification loss after processing this batch is:  0.08427747339010239\n",
      "The representation loss after processing this batch is:  0.002177588641643524\n",
      "\n",
      "The classification loss after processing this batch is:  0.11117640137672424\n",
      "The representation loss after processing this batch is:  0.002539299428462982\n",
      "\n",
      "The classification loss after processing this batch is:  0.11861521750688553\n",
      "The representation loss after processing this batch is:  0.002527989447116852\n",
      "\n",
      "The classification loss after processing this batch is:  0.34294232726097107\n",
      "The representation loss after processing this batch is:  0.0028607547283172607\n",
      "\n",
      "The classification loss after processing this batch is:  0.21620197594165802\n",
      "The representation loss after processing this batch is:  0.0029708892107009888\n",
      "\n",
      "The classification loss after processing this batch is:  0.0905376523733139\n",
      "The representation loss after processing this batch is:  0.0025207102298736572\n",
      "\n",
      "The classification loss after processing this batch is:  0.07573042064905167\n",
      "The representation loss after processing this batch is:  0.002750612795352936\n",
      "\n",
      "The classification loss after processing this batch is:  0.06167840212583542\n",
      "The representation loss after processing this batch is:  0.0028436556458473206\n",
      "\n",
      "The classification loss after processing this batch is:  0.07104858756065369\n",
      "The representation loss after processing this batch is:  0.002716079354286194\n",
      "\n",
      "The classification loss after processing this batch is:  0.028895346447825432\n",
      "The representation loss after processing this batch is:  0.002870231866836548\n",
      "\n",
      "The classification loss after processing this batch is:  0.0872449204325676\n",
      "The representation loss after processing this batch is:  0.00269346684217453\n",
      "\n",
      "The classification loss after processing this batch is:  0.09885023534297943\n",
      "The representation loss after processing this batch is:  0.002464398741722107\n",
      "\n",
      "The classification loss after processing this batch is:  0.21217645704746246\n",
      "The representation loss after processing this batch is:  0.0027603283524513245\n",
      "\n",
      "The classification loss after processing this batch is:  0.10117422789335251\n",
      "The representation loss after processing this batch is:  0.002419605851173401\n",
      "\n",
      "The classification loss after processing this batch is:  0.06174984201788902\n",
      "The representation loss after processing this batch is:  0.002603389322757721\n",
      "\n",
      "The classification loss after processing this batch is:  0.046173520386219025\n",
      "The representation loss after processing this batch is:  0.002606421709060669\n",
      "\n",
      "The classification loss after processing this batch is:  0.23215122520923615\n",
      "The representation loss after processing this batch is:  0.0026293545961380005\n",
      "\n",
      "The classification loss after processing this batch is:  0.08331338316202164\n",
      "The representation loss after processing this batch is:  0.002757646143436432\n",
      "\n",
      "The classification loss after processing this batch is:  0.07692848145961761\n",
      "The representation loss after processing this batch is:  0.002590768039226532\n",
      "\n",
      "The classification loss after processing this batch is:  0.10309330374002457\n",
      "The representation loss after processing this batch is:  0.0028526484966278076\n",
      "\n",
      "The classification loss after processing this batch is:  0.09861303120851517\n",
      "The representation loss after processing this batch is:  0.0022199824452400208\n",
      "\n",
      "The classification loss after processing this batch is:  0.05045503005385399\n",
      "The representation loss after processing this batch is:  0.002475455403327942\n",
      "\n",
      "The classification loss after processing this batch is:  0.10795389115810394\n",
      "The representation loss after processing this batch is:  0.0024589374661445618\n",
      "\n",
      "The classification loss after processing this batch is:  0.07071559876203537\n",
      "The representation loss after processing this batch is:  0.0025644153356552124\n",
      "\n",
      "The classification loss after processing this batch is:  0.08072736859321594\n",
      "The representation loss after processing this batch is:  0.0026053637266159058\n",
      "\n",
      "The classification loss after processing this batch is:  0.15805663168430328\n",
      "The representation loss after processing this batch is:  0.0024664700031280518\n",
      "\n",
      "The classification loss after processing this batch is:  0.16100788116455078\n",
      "The representation loss after processing this batch is:  0.002707667648792267\n",
      "\n",
      "The classification loss after processing this batch is:  0.15733890235424042\n",
      "The representation loss after processing this batch is:  0.0025079473853111267\n",
      "\n",
      "The classification loss after processing this batch is:  0.15997949242591858\n",
      "The representation loss after processing this batch is:  0.0024711936712265015\n",
      "\n",
      "The classification loss after processing this batch is:  0.07894553989171982\n",
      "The representation loss after processing this batch is:  0.0025843679904937744\n",
      "\n",
      "The classification loss after processing this batch is:  0.1471228301525116\n",
      "The representation loss after processing this batch is:  0.0026648417115211487\n",
      "\n",
      "The classification loss after processing this batch is:  0.08389870822429657\n",
      "The representation loss after processing this batch is:  0.0031124353408813477\n",
      "\n",
      "The classification loss after processing this batch is:  0.12137355655431747\n",
      "The representation loss after processing this batch is:  0.0026571042835712433\n",
      "\n",
      "The classification loss after processing this batch is:  0.0624227300286293\n",
      "The representation loss after processing this batch is:  0.002367183566093445\n",
      "\n",
      "The classification loss after processing this batch is:  0.1606183648109436\n",
      "The representation loss after processing this batch is:  0.0024350211024284363\n",
      "\n",
      "The classification loss after processing this batch is:  0.07606308907270432\n",
      "The representation loss after processing this batch is:  0.0027737990021705627\n",
      "\n",
      "The classification loss after processing this batch is:  0.1008128747344017\n",
      "The representation loss after processing this batch is:  0.0023162811994552612\n",
      "\n",
      "The classification loss after processing this batch is:  0.10809575021266937\n",
      "The representation loss after processing this batch is:  0.0024340972304344177\n",
      "\n",
      "The classification loss after processing this batch is:  0.09685661643743515\n",
      "The representation loss after processing this batch is:  0.002486489713191986\n",
      "\n",
      "The classification loss after processing this batch is:  0.1399127095937729\n",
      "The representation loss after processing this batch is:  0.002366483211517334\n",
      "\n",
      "The classification loss after processing this batch is:  0.1044502928853035\n",
      "The representation loss after processing this batch is:  0.002303142100572586\n",
      "\n",
      "The classification loss after processing this batch is:  0.177128404378891\n",
      "The representation loss after processing this batch is:  0.002466246485710144\n",
      "\n",
      "The classification loss after processing this batch is:  0.169240340590477\n",
      "The representation loss after processing this batch is:  0.002575509250164032\n",
      "\n",
      "The classification loss after processing this batch is:  0.25755244493484497\n",
      "The representation loss after processing this batch is:  0.002539481967687607\n",
      "\n",
      "The classification loss after processing this batch is:  0.18069463968276978\n",
      "The representation loss after processing this batch is:  0.0022532008588314056\n",
      "\n",
      "The classification loss after processing this batch is:  0.07052689045667648\n",
      "The representation loss after processing this batch is:  0.0026055127382278442\n",
      "\n",
      "The classification loss after processing this batch is:  0.1562965214252472\n",
      "The representation loss after processing this batch is:  0.0027240216732025146\n",
      "\n",
      "The classification loss after processing this batch is:  0.09550298750400543\n",
      "The representation loss after processing this batch is:  0.002715170383453369\n",
      "\n",
      "The classification loss after processing this batch is:  0.08428765833377838\n",
      "The representation loss after processing this batch is:  0.0029207170009613037\n",
      "\n",
      "The classification loss after processing this batch is:  0.18391506373882294\n",
      "The representation loss after processing this batch is:  0.003118082880973816\n",
      "\n",
      "The classification loss after processing this batch is:  0.18129390478134155\n",
      "The representation loss after processing this batch is:  0.0028951019048690796\n",
      "\n",
      "The classification loss after processing this batch is:  0.2927250862121582\n",
      "The representation loss after processing this batch is:  0.002703629434108734\n",
      "\n",
      "The classification loss after processing this batch is:  0.13940215110778809\n",
      "The representation loss after processing this batch is:  0.0028681978583335876\n",
      "\n",
      "The classification loss after processing this batch is:  0.0692247673869133\n",
      "The representation loss after processing this batch is:  0.0027449652552604675\n",
      "\n",
      "The classification loss after processing this batch is:  0.08520834147930145\n",
      "The representation loss after processing this batch is:  0.002754315733909607\n",
      "\n",
      "The classification loss after processing this batch is:  0.1834404617547989\n",
      "The representation loss after processing this batch is:  0.002383686602115631\n",
      "\n",
      "The classification loss after processing this batch is:  0.09295036643743515\n",
      "The representation loss after processing this batch is:  0.002681322395801544\n",
      "\n",
      "The classification loss after processing this batch is:  0.09926601499319077\n",
      "The representation loss after processing this batch is:  0.002361081540584564\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.0801176056265831\n",
      "The representation loss after processing this batch is:  0.00279323011636734\n",
      "\n",
      "The classification loss after processing this batch is:  0.03185850381851196\n",
      "The representation loss after processing this batch is:  0.0025665387511253357\n",
      "\n",
      "The classification loss after processing this batch is:  0.1314733326435089\n",
      "The representation loss after processing this batch is:  0.002830851823091507\n",
      "\n",
      "The classification loss after processing this batch is:  0.12879735231399536\n",
      "The representation loss after processing this batch is:  0.0030604414641857147\n",
      "\n",
      "The classification loss after processing this batch is:  0.16708244383335114\n",
      "The representation loss after processing this batch is:  0.0025202035903930664\n",
      "\n",
      "The classification loss after processing this batch is:  0.15021578967571259\n",
      "The representation loss after processing this batch is:  0.002246629446744919\n",
      "\n",
      "The classification loss after processing this batch is:  0.12060865759849548\n",
      "The representation loss after processing this batch is:  0.002611599862575531\n",
      "\n",
      "The classification loss after processing this batch is:  0.13225963711738586\n",
      "The representation loss after processing this batch is:  0.0026557818055152893\n",
      "\n",
      "The classification loss after processing this batch is:  0.12227819114923477\n",
      "The representation loss after processing this batch is:  0.002570316195487976\n",
      "\n",
      "The classification loss after processing this batch is:  0.12458670884370804\n",
      "The representation loss after processing this batch is:  0.0029882043600082397\n",
      "\n",
      "The classification loss after processing this batch is:  0.1485712230205536\n",
      "The representation loss after processing this batch is:  0.002872183918952942\n",
      "\n",
      "The classification loss after processing this batch is:  0.13874545693397522\n",
      "The representation loss after processing this batch is:  0.0031185373663902283\n",
      "\n",
      "The classification loss after processing this batch is:  0.12425290793180466\n",
      "The representation loss after processing this batch is:  0.002411380410194397\n",
      "\n",
      "The classification loss after processing this batch is:  0.2033320516347885\n",
      "The representation loss after processing this batch is:  0.0025203563272953033\n",
      "\n",
      "The classification loss after processing this batch is:  0.18013302981853485\n",
      "The representation loss after processing this batch is:  0.0027891844511032104\n",
      "\n",
      "The classification loss after processing this batch is:  0.07080709934234619\n",
      "The representation loss after processing this batch is:  0.0023315884172916412\n",
      "\n",
      "The classification loss after processing this batch is:  0.1169300451874733\n",
      "The representation loss after processing this batch is:  0.0030394792556762695\n",
      "\n",
      "The classification loss after processing this batch is:  0.12332402914762497\n",
      "The representation loss after processing this batch is:  0.002649649977684021\n",
      "\n",
      "The classification loss after processing this batch is:  0.1176714226603508\n",
      "The representation loss after processing this batch is:  0.0026776008307933807\n",
      "\n",
      "The classification loss after processing this batch is:  0.16711828112602234\n",
      "The representation loss after processing this batch is:  0.0031325817108154297\n",
      "\n",
      "The classification loss after processing this batch is:  0.2523844242095947\n",
      "The representation loss after processing this batch is:  0.002958327531814575\n",
      "\n",
      "The classification loss after processing this batch is:  0.2459275871515274\n",
      "The representation loss after processing this batch is:  0.003238305449485779\n",
      "\n",
      "The classification loss after processing this batch is:  0.13923171162605286\n",
      "The representation loss after processing this batch is:  0.002834007143974304\n",
      "\n",
      "The classification loss after processing this batch is:  0.11753511428833008\n",
      "The representation loss after processing this batch is:  0.0026523321866989136\n",
      "\n",
      "The classification loss after processing this batch is:  0.08192868530750275\n",
      "The representation loss after processing this batch is:  0.003173626959323883\n",
      "\n",
      "The classification loss after processing this batch is:  0.057564787566661835\n",
      "The representation loss after processing this batch is:  0.0027460530400276184\n",
      "\n",
      "The classification loss after processing this batch is:  0.16853775084018707\n",
      "The representation loss after processing this batch is:  0.0028085745871067047\n",
      "\n",
      "The classification loss after processing this batch is:  0.12569260597229004\n",
      "The representation loss after processing this batch is:  0.0025121942162513733\n",
      "\n",
      "The classification loss after processing this batch is:  0.08559824526309967\n",
      "The representation loss after processing this batch is:  0.00245613232254982\n",
      "\n",
      "The classification loss after processing this batch is:  0.12446470558643341\n",
      "The representation loss after processing this batch is:  0.0027335956692695618\n",
      "\n",
      "The classification loss after processing this batch is:  0.10973662883043289\n",
      "The representation loss after processing this batch is:  0.0030245408415794373\n",
      "\n",
      "The classification loss after processing this batch is:  0.18162322044372559\n",
      "The representation loss after processing this batch is:  0.0025982558727264404\n",
      "\n",
      "The classification loss after processing this batch is:  0.11949721723794937\n",
      "The representation loss after processing this batch is:  0.002680353820323944\n",
      "\n",
      "The classification loss after processing this batch is:  0.08942928910255432\n",
      "The representation loss after processing this batch is:  0.0025168657302856445\n",
      "\n",
      "The classification loss after processing this batch is:  0.04664485156536102\n",
      "The representation loss after processing this batch is:  0.0026258155703544617\n",
      "\n",
      "The classification loss after processing this batch is:  0.1086660698056221\n",
      "The representation loss after processing this batch is:  0.0024624504148960114\n",
      "\n",
      "The classification loss after processing this batch is:  0.09717526286840439\n",
      "The representation loss after processing this batch is:  0.0023053549230098724\n",
      "\n",
      "The classification loss after processing this batch is:  0.42021429538726807\n",
      "The representation loss after processing this batch is:  0.0028250515460968018\n",
      "\n",
      "The classification loss after processing this batch is:  0.09897539764642715\n",
      "The representation loss after processing this batch is:  0.002506345510482788\n",
      "\n",
      "The classification loss after processing this batch is:  0.21952129900455475\n",
      "The representation loss after processing this batch is:  0.0024712905287742615\n",
      "\n",
      "The classification loss after processing this batch is:  0.2646549642086029\n",
      "The representation loss after processing this batch is:  0.0026951320469379425\n",
      "\n",
      "The classification loss after processing this batch is:  0.0832265093922615\n",
      "The representation loss after processing this batch is:  0.002667248249053955\n",
      "\n",
      "The classification loss after processing this batch is:  0.22334785759449005\n",
      "The representation loss after processing this batch is:  0.0031281709671020508\n",
      "\n",
      "The classification loss after processing this batch is:  0.12496667355298996\n",
      "The representation loss after processing this batch is:  0.002744242548942566\n",
      "\n",
      "The classification loss after processing this batch is:  0.20297597348690033\n",
      "The representation loss after processing this batch is:  0.002535015344619751\n",
      "\n",
      "The classification loss after processing this batch is:  0.05600066855549812\n",
      "The representation loss after processing this batch is:  0.00240141898393631\n",
      "\n",
      "The classification loss after processing this batch is:  0.07702525705099106\n",
      "The representation loss after processing this batch is:  0.0027876198291778564\n",
      "\n",
      "The classification loss after processing this batch is:  0.05956778675317764\n",
      "The representation loss after processing this batch is:  0.002886466681957245\n",
      "\n",
      "The classification loss after processing this batch is:  0.042871300131082535\n",
      "The representation loss after processing this batch is:  0.0025322288274765015\n",
      "\n",
      "The classification loss after processing this batch is:  0.09584573656320572\n",
      "The representation loss after processing this batch is:  0.0027111470699310303\n",
      "\n",
      "The classification loss after processing this batch is:  0.06792529672384262\n",
      "The representation loss after processing this batch is:  0.0023815184831619263\n",
      "\n",
      "The classification loss after processing this batch is:  0.13564319908618927\n",
      "The representation loss after processing this batch is:  0.0030053481459617615\n",
      "\n",
      "The classification loss after processing this batch is:  0.06857334822416306\n",
      "The representation loss after processing this batch is:  0.0029958337545394897\n",
      "\n",
      "The classification loss after processing this batch is:  0.08303102850914001\n",
      "The representation loss after processing this batch is:  0.0023793503642082214\n",
      "\n",
      "The classification loss after processing this batch is:  0.10306216776371002\n",
      "The representation loss after processing this batch is:  0.0025018826127052307\n",
      "\n",
      "The classification loss after processing this batch is:  0.047443147748708725\n",
      "The representation loss after processing this batch is:  0.002384386956691742\n",
      "\n",
      "The classification loss after processing this batch is:  0.12066081911325455\n",
      "The representation loss after processing this batch is:  0.002657689154148102\n",
      "\n",
      "The classification loss after processing this batch is:  0.12487813830375671\n",
      "The representation loss after processing this batch is:  0.0027875304222106934\n",
      "\n",
      "The classification loss after processing this batch is:  0.21121428906917572\n",
      "The representation loss after processing this batch is:  0.003143131732940674\n",
      "\n",
      "The classification loss after processing this batch is:  0.10460005700588226\n",
      "The representation loss after processing this batch is:  0.00245632603764534\n",
      "\n",
      "The classification loss after processing this batch is:  0.07582685351371765\n",
      "The representation loss after processing this batch is:  0.002308472990989685\n",
      "\n",
      "The classification loss after processing this batch is:  0.20610040426254272\n",
      "The representation loss after processing this batch is:  0.00277884304523468\n",
      "\n",
      "The classification loss after processing this batch is:  0.14871548116207123\n",
      "The representation loss after processing this batch is:  0.002611197531223297\n",
      "\n",
      "The classification loss after processing this batch is:  0.13053041696548462\n",
      "The representation loss after processing this batch is:  0.0027844682335853577\n",
      "\n",
      "The classification loss after processing this batch is:  0.04649145528674126\n",
      "The representation loss after processing this batch is:  0.002579502761363983\n",
      "\n",
      "The classification loss after processing this batch is:  0.10372593253850937\n",
      "The representation loss after processing this batch is:  0.002570204436779022\n",
      "\n",
      "The classification loss after processing this batch is:  0.10735026001930237\n",
      "The representation loss after processing this batch is:  0.0026812702417373657\n",
      "\n",
      "The classification loss after processing this batch is:  0.13437630236148834\n",
      "The representation loss after processing this batch is:  0.003118850290775299\n",
      "\n",
      "The classification loss after processing this batch is:  0.11836583912372589\n",
      "The representation loss after processing this batch is:  0.0030770525336265564\n",
      "\n",
      "The classification loss after processing this batch is:  0.08803186565637589\n",
      "The representation loss after processing this batch is:  0.003260582685470581\n",
      "\n",
      "The classification loss after processing this batch is:  0.1475309580564499\n",
      "The representation loss after processing this batch is:  0.0030326545238494873\n",
      "\n",
      "The classification loss after processing this batch is:  0.22832870483398438\n",
      "The representation loss after processing this batch is:  0.0025186315178871155\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1220390722155571\n",
      "The representation loss after processing this batch is:  0.0033072680234909058\n",
      "\n",
      "The classification loss after processing this batch is:  0.1398206651210785\n",
      "The representation loss after processing this batch is:  0.0025295838713645935\n",
      "\n",
      "The classification loss after processing this batch is:  0.06684861332178116\n",
      "The representation loss after processing this batch is:  0.002505641430616379\n",
      "\n",
      "The classification loss after processing this batch is:  0.19441913068294525\n",
      "The representation loss after processing this batch is:  0.0024861320853233337\n",
      "\n",
      "The classification loss after processing this batch is:  0.058015331625938416\n",
      "The representation loss after processing this batch is:  0.0025782734155654907\n",
      "\n",
      "The classification loss after processing this batch is:  0.12376396358013153\n",
      "The representation loss after processing this batch is:  0.002714991569519043\n",
      "\n",
      "The classification loss after processing this batch is:  0.08882457762956619\n",
      "The representation loss after processing this batch is:  0.002836085855960846\n",
      "\n",
      "The classification loss after processing this batch is:  0.1077466830611229\n",
      "The representation loss after processing this batch is:  0.002627938985824585\n",
      "\n",
      "The classification loss after processing this batch is:  0.12382104992866516\n",
      "The representation loss after processing this batch is:  0.0027486681938171387\n",
      "\n",
      "The classification loss after processing this batch is:  0.1518259197473526\n",
      "The representation loss after processing this batch is:  0.002952791750431061\n",
      "\n",
      "The classification loss after processing this batch is:  0.11939813941717148\n",
      "The representation loss after processing this batch is:  0.0027457699179649353\n",
      "\n",
      "The classification loss after processing this batch is:  0.1384216845035553\n",
      "The representation loss after processing this batch is:  0.0024321936070919037\n",
      "\n",
      "The classification loss after processing this batch is:  0.1653439998626709\n",
      "The representation loss after processing this batch is:  0.0030390769243240356\n",
      "\n",
      "The classification loss after processing this batch is:  0.12447237968444824\n",
      "The representation loss after processing this batch is:  0.0025989115238189697\n",
      "\n",
      "The classification loss after processing this batch is:  0.10649094730615616\n",
      "The representation loss after processing this batch is:  0.0026629045605659485\n",
      "\n",
      "The classification loss after processing this batch is:  0.05918348580598831\n",
      "The representation loss after processing this batch is:  0.00300801545381546\n",
      "\n",
      "The classification loss after processing this batch is:  0.07690899074077606\n",
      "The representation loss after processing this batch is:  0.002792246639728546\n",
      "\n",
      "The classification loss after processing this batch is:  0.047359272837638855\n",
      "The representation loss after processing this batch is:  0.002568855881690979\n",
      "\n",
      "The classification loss after processing this batch is:  0.053607258945703506\n",
      "The representation loss after processing this batch is:  0.0025233328342437744\n",
      "\n",
      "The classification loss after processing this batch is:  0.06446973234415054\n",
      "The representation loss after processing this batch is:  0.0026916414499282837\n",
      "\n",
      "The classification loss after processing this batch is:  0.04203898459672928\n",
      "The representation loss after processing this batch is:  0.0029966160655021667\n",
      "\n",
      "The classification loss after processing this batch is:  0.1235533282160759\n",
      "The representation loss after processing this batch is:  0.002563461661338806\n",
      "\n",
      "The classification loss after processing this batch is:  0.08443806320428848\n",
      "The representation loss after processing this batch is:  0.002337094396352768\n",
      "\n",
      "The classification loss after processing this batch is:  0.12139944732189178\n",
      "The representation loss after processing this batch is:  0.0025769993662834167\n",
      "\n",
      "The classification loss after processing this batch is:  0.057035334408283234\n",
      "The representation loss after processing this batch is:  0.0027511268854141235\n",
      "\n",
      "The classification loss after processing this batch is:  0.16899830102920532\n",
      "The representation loss after processing this batch is:  0.0026313215494155884\n",
      "\n",
      "The classification loss after processing this batch is:  0.15786191821098328\n",
      "The representation loss after processing this batch is:  0.0026705116033554077\n",
      "\n",
      "The classification loss after processing this batch is:  0.10145691782236099\n",
      "The representation loss after processing this batch is:  0.0025107264518737793\n",
      "\n",
      "The classification loss after processing this batch is:  0.13026170432567596\n",
      "The representation loss after processing this batch is:  0.002809487283229828\n",
      "\n",
      "The classification loss after processing this batch is:  0.10959429293870926\n",
      "The representation loss after processing this batch is:  0.002962566912174225\n",
      "\n",
      "The classification loss after processing this batch is:  0.04003416746854782\n",
      "The representation loss after processing this batch is:  0.002505093812942505\n",
      "\n",
      "The classification loss after processing this batch is:  0.07169409096240997\n",
      "The representation loss after processing this batch is:  0.0025532692670822144\n",
      "\n",
      "The classification loss after processing this batch is:  0.07766976207494736\n",
      "The representation loss after processing this batch is:  0.002318963408470154\n",
      "\n",
      "The classification loss after processing this batch is:  0.20905904471874237\n",
      "The representation loss after processing this batch is:  0.002711057662963867\n",
      "\n",
      "The classification loss after processing this batch is:  0.15648724138736725\n",
      "The representation loss after processing this batch is:  0.0024899840354919434\n",
      "\n",
      "The classification loss after processing this batch is:  0.15498463809490204\n",
      "The representation loss after processing this batch is:  0.003345981240272522\n",
      "\n",
      "The classification loss after processing this batch is:  0.17154376208782196\n",
      "The representation loss after processing this batch is:  0.0025967732071876526\n",
      "\n",
      "The classification loss after processing this batch is:  0.17332440614700317\n",
      "The representation loss after processing this batch is:  0.0028680190443992615\n",
      "\n",
      "The classification loss after processing this batch is:  0.18825392425060272\n",
      "The representation loss after processing this batch is:  0.0023571252822875977\n",
      "\n",
      "The classification loss after processing this batch is:  0.26708316802978516\n",
      "The representation loss after processing this batch is:  0.002634715288877487\n",
      "\n",
      "The classification loss after processing this batch is:  0.1716918647289276\n",
      "The representation loss after processing this batch is:  0.002468463033437729\n",
      "\n",
      "The classification loss after processing this batch is:  0.10018755495548248\n",
      "The representation loss after processing this batch is:  0.002284519374370575\n",
      "\n",
      "The classification loss after processing this batch is:  0.08722333610057831\n",
      "The representation loss after processing this batch is:  0.0026885494589805603\n",
      "\n",
      "The classification loss after processing this batch is:  0.05358286574482918\n",
      "The representation loss after processing this batch is:  0.0024107471108436584\n",
      "\n",
      "The classification loss after processing this batch is:  0.0613006167113781\n",
      "The representation loss after processing this batch is:  0.002534210681915283\n",
      "\n",
      "The classification loss after processing this batch is:  0.07158318907022476\n",
      "The representation loss after processing this batch is:  0.0031435489654541016\n",
      "\n",
      "The classification loss after processing this batch is:  0.12109901010990143\n",
      "The representation loss after processing this batch is:  0.0024003013968467712\n",
      "\n",
      "The classification loss after processing this batch is:  0.07320281863212585\n",
      "The representation loss after processing this batch is:  0.002741292119026184\n",
      "\n",
      "The classification loss after processing this batch is:  0.16462892293930054\n",
      "The representation loss after processing this batch is:  0.002511989325284958\n",
      "\n",
      "The classification loss after processing this batch is:  0.14467184245586395\n",
      "The representation loss after processing this batch is:  0.0028815269470214844\n",
      "\n",
      "The classification loss after processing this batch is:  0.17721125483512878\n",
      "The representation loss after processing this batch is:  0.0025642067193984985\n",
      "\n",
      "The classification loss after processing this batch is:  0.12356365472078323\n",
      "The representation loss after processing this batch is:  0.0024732276797294617\n",
      "\n",
      "The classification loss after processing this batch is:  0.17404404282569885\n",
      "The representation loss after processing this batch is:  0.002483069896697998\n",
      "\n",
      "The classification loss after processing this batch is:  0.13344062864780426\n",
      "The representation loss after processing this batch is:  0.0024624988436698914\n",
      "\n",
      "The classification loss after processing this batch is:  0.08058632910251617\n",
      "The representation loss after processing this batch is:  0.0025994330644607544\n",
      "\n",
      "The classification loss after processing this batch is:  0.18337959051132202\n",
      "The representation loss after processing this batch is:  0.0024936944246292114\n",
      "\n",
      "The classification loss after processing this batch is:  0.04739905148744583\n",
      "The representation loss after processing this batch is:  0.0024592503905296326\n",
      "\n",
      "The classification loss after processing this batch is:  0.0456889271736145\n",
      "The representation loss after processing this batch is:  0.002303667366504669\n",
      "\n",
      "The classification loss after processing this batch is:  0.10455142706632614\n",
      "The representation loss after processing this batch is:  0.0028834789991378784\n",
      "\n",
      "The classification loss after processing this batch is:  0.15543359518051147\n",
      "The representation loss after processing this batch is:  0.002665318548679352\n",
      "\n",
      "The classification loss after processing this batch is:  0.11612681299448013\n",
      "The representation loss after processing this batch is:  0.0029483363032341003\n",
      "\n",
      "The classification loss after processing this batch is:  0.06850258260965347\n",
      "The representation loss after processing this batch is:  0.002982407808303833\n",
      "\n",
      "The classification loss after processing this batch is:  0.11911525577306747\n",
      "The representation loss after processing this batch is:  0.0030190423130989075\n",
      "\n",
      "The classification loss after processing this batch is:  0.09138689190149307\n",
      "The representation loss after processing this batch is:  0.0027495920658111572\n",
      "\n",
      "The classification loss after processing this batch is:  0.18566061556339264\n",
      "The representation loss after processing this batch is:  0.0025866106152534485\n",
      "\n",
      "The classification loss after processing this batch is:  0.04812582954764366\n",
      "The representation loss after processing this batch is:  0.002484247088432312\n",
      "\n",
      "The classification loss after processing this batch is:  0.05321027338504791\n",
      "The representation loss after processing this batch is:  0.0027963444590568542\n",
      "\n",
      "The classification loss after processing this batch is:  0.1332029551267624\n",
      "The representation loss after processing this batch is:  0.003378249704837799\n",
      "\n",
      "The classification loss after processing this batch is:  0.11275466531515121\n",
      "The representation loss after processing this batch is:  0.0028761103749275208\n",
      "\n",
      "The classification loss after processing this batch is:  0.096124567091465\n",
      "The representation loss after processing this batch is:  0.0031057000160217285\n",
      "\n",
      "The classification loss after processing this batch is:  0.07252324372529984\n",
      "The representation loss after processing this batch is:  0.0026217028498649597\n",
      "\n",
      "The classification loss after processing this batch is:  0.14474956691265106\n",
      "The representation loss after processing this batch is:  0.002987705171108246\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.16811493039131165\n",
      "The representation loss after processing this batch is:  0.003019273281097412\n",
      "\n",
      "The classification loss after processing this batch is:  0.19602693617343903\n",
      "The representation loss after processing this batch is:  0.0025988519191741943\n",
      "\n",
      "The classification loss after processing this batch is:  0.13709156215190887\n",
      "The representation loss after processing this batch is:  0.0030802711844444275\n",
      "\n",
      "The classification loss after processing this batch is:  0.0478341244161129\n",
      "The representation loss after processing this batch is:  0.002567589282989502\n",
      "\n",
      "The classification loss after processing this batch is:  0.06288889050483704\n",
      "The representation loss after processing this batch is:  0.0023841671645641327\n",
      "\n",
      "The classification loss after processing this batch is:  0.168941468000412\n",
      "The representation loss after processing this batch is:  0.0030259639024734497\n",
      "\n",
      "The classification loss after processing this batch is:  0.2216789424419403\n",
      "The representation loss after processing this batch is:  0.0031570419669151306\n",
      "\n",
      "The classification loss after processing this batch is:  0.22859586775302887\n",
      "The representation loss after processing this batch is:  0.0031734928488731384\n",
      "\n",
      "The classification loss after processing this batch is:  0.227468341588974\n",
      "The representation loss after processing this batch is:  0.0027369074523448944\n",
      "\n",
      "The classification loss after processing this batch is:  0.08125743269920349\n",
      "The representation loss after processing this batch is:  0.002482321113348007\n",
      "\n",
      "The classification loss after processing this batch is:  0.17170704901218414\n",
      "The representation loss after processing this batch is:  0.0024644583463668823\n",
      "\n",
      "The classification loss after processing this batch is:  0.09572439640760422\n",
      "The representation loss after processing this batch is:  0.0024928823113441467\n",
      "\n",
      "The classification loss after processing this batch is:  0.10495633631944656\n",
      "The representation loss after processing this batch is:  0.0025955364108085632\n",
      "\n",
      "The classification loss after processing this batch is:  0.06919247657060623\n",
      "The representation loss after processing this batch is:  0.0025257542729377747\n",
      "\n",
      "The classification loss after processing this batch is:  0.16751031577587128\n",
      "The representation loss after processing this batch is:  0.002406306564807892\n",
      "\n",
      "The classification loss after processing this batch is:  0.10540781915187836\n",
      "The representation loss after processing this batch is:  0.002479642629623413\n",
      "\n",
      "The classification loss after processing this batch is:  0.12906570732593536\n",
      "The representation loss after processing this batch is:  0.002365998923778534\n",
      "\n",
      "The classification loss after processing this batch is:  0.13759663701057434\n",
      "The representation loss after processing this batch is:  0.0024761781096458435\n",
      "\n",
      "The classification loss after processing this batch is:  0.053308986127376556\n",
      "The representation loss after processing this batch is:  0.0027930065989494324\n",
      "\n",
      "The classification loss after processing this batch is:  0.10193207114934921\n",
      "The representation loss after processing this batch is:  0.002801463007926941\n",
      "\n",
      "The classification loss after processing this batch is:  0.14145077764987946\n",
      "The representation loss after processing this batch is:  0.0026038140058517456\n",
      "\n",
      "The classification loss after processing this batch is:  0.10482562333345413\n",
      "The representation loss after processing this batch is:  0.002720870077610016\n",
      "\n",
      "The classification loss after processing this batch is:  0.0635371282696724\n",
      "The representation loss after processing this batch is:  0.002967327833175659\n",
      "\n",
      "The classification loss after processing this batch is:  0.07730629295110703\n",
      "The representation loss after processing this batch is:  0.0023241564631462097\n",
      "\n",
      "The classification loss after processing this batch is:  0.21779949963092804\n",
      "The representation loss after processing this batch is:  0.0031346455216407776\n",
      "\n",
      "The classification loss after processing this batch is:  0.15585613250732422\n",
      "The representation loss after processing this batch is:  0.002544127404689789\n",
      "\n",
      "The classification loss after processing this batch is:  0.11511663347482681\n",
      "The representation loss after processing this batch is:  0.002481803297996521\n",
      "\n",
      "The classification loss after processing this batch is:  0.09561116248369217\n",
      "The representation loss after processing this batch is:  0.0023833811283111572\n",
      "\n",
      "The classification loss after processing this batch is:  0.08454088866710663\n",
      "The representation loss after processing this batch is:  0.002590179443359375\n",
      "\n",
      "The classification loss after processing this batch is:  0.0904708281159401\n",
      "The representation loss after processing this batch is:  0.002384692430496216\n",
      "\n",
      "The classification loss after processing this batch is:  0.10339270532131195\n",
      "The representation loss after processing this batch is:  0.0026761814951896667\n",
      "\n",
      "The classification loss after processing this batch is:  0.11745157837867737\n",
      "The representation loss after processing this batch is:  0.0026814863085746765\n",
      "\n",
      "The classification loss after processing this batch is:  0.12766937911510468\n",
      "The representation loss after processing this batch is:  0.0032202526926994324\n",
      "\n",
      "The classification loss after processing this batch is:  0.08552274852991104\n",
      "The representation loss after processing this batch is:  0.0029078200459480286\n",
      "\n",
      "The classification loss after processing this batch is:  0.15295737981796265\n",
      "The representation loss after processing this batch is:  0.0024232901632785797\n",
      "\n",
      "The classification loss after processing this batch is:  0.17903989553451538\n",
      "The representation loss after processing this batch is:  0.0024337321519851685\n",
      "\n",
      "The classification loss after processing this batch is:  0.04377705603837967\n",
      "The representation loss after processing this batch is:  0.0025720447301864624\n",
      "\n",
      "The classification loss after processing this batch is:  0.06645134091377258\n",
      "The representation loss after processing this batch is:  0.0023469440639019012\n",
      "\n",
      "The classification loss after processing this batch is:  0.15951336920261383\n",
      "The representation loss after processing this batch is:  0.002491191029548645\n",
      "\n",
      "The classification loss after processing this batch is:  0.14818941056728363\n",
      "The representation loss after processing this batch is:  0.002778090536594391\n",
      "\n",
      "The classification loss after processing this batch is:  0.09959731251001358\n",
      "The representation loss after processing this batch is:  0.0026175305247306824\n",
      "\n",
      "The classification loss after processing this batch is:  0.21204596757888794\n",
      "The representation loss after processing this batch is:  0.0026679635047912598\n",
      "\n",
      "The classification loss after processing this batch is:  0.152812197804451\n",
      "The representation loss after processing this batch is:  0.003058977425098419\n",
      "\n",
      "The classification loss after processing this batch is:  0.20128755271434784\n",
      "The representation loss after processing this batch is:  0.0027986541390419006\n",
      "\n",
      "The classification loss after processing this batch is:  0.10293401777744293\n",
      "The representation loss after processing this batch is:  0.002937421202659607\n",
      "\n",
      "The classification loss after processing this batch is:  0.15853552520275116\n",
      "The representation loss after processing this batch is:  0.0024002641439437866\n",
      "\n",
      "The classification loss after processing this batch is:  0.08875108510255814\n",
      "The representation loss after processing this batch is:  0.003707706928253174\n",
      "\n",
      "The classification loss after processing this batch is:  0.09069841355085373\n",
      "The representation loss after processing this batch is:  0.0026551634073257446\n",
      "\n",
      "The classification loss after processing this batch is:  0.10846493393182755\n",
      "The representation loss after processing this batch is:  0.0026733577251434326\n",
      "\n",
      "The classification loss after processing this batch is:  0.10545700043439865\n",
      "The representation loss after processing this batch is:  0.002276994287967682\n",
      "\n",
      "The classification loss after processing this batch is:  0.11708948761224747\n",
      "The representation loss after processing this batch is:  0.002504773437976837\n",
      "\n",
      "The classification loss after processing this batch is:  0.10642109811306\n",
      "The representation loss after processing this batch is:  0.002644374966621399\n",
      "\n",
      "The classification loss after processing this batch is:  0.1757691651582718\n",
      "The representation loss after processing this batch is:  0.002573058009147644\n",
      "\n",
      "The classification loss after processing this batch is:  0.07662887126207352\n",
      "The representation loss after processing this batch is:  0.002971172332763672\n",
      "\n",
      "The classification loss after processing this batch is:  0.07134068012237549\n",
      "The representation loss after processing this batch is:  0.0028836801648139954\n",
      "\n",
      "The classification loss after processing this batch is:  0.139536052942276\n",
      "The representation loss after processing this batch is:  0.0029319673776626587\n",
      "\n",
      "The classification loss after processing this batch is:  0.0741029754281044\n",
      "The representation loss after processing this batch is:  0.002623245120048523\n",
      "\n",
      "The classification loss after processing this batch is:  0.08123038709163666\n",
      "The representation loss after processing this batch is:  0.0027361437678337097\n",
      "\n",
      "The classification loss after processing this batch is:  0.060898177325725555\n",
      "The representation loss after processing this batch is:  0.002735242247581482\n",
      "\n",
      "The classification loss after processing this batch is:  0.12862685322761536\n",
      "The representation loss after processing this batch is:  0.002292625606060028\n",
      "\n",
      "The classification loss after processing this batch is:  0.17296205461025238\n",
      "The representation loss after processing this batch is:  0.003023386001586914\n",
      "\n",
      "The classification loss after processing this batch is:  0.17935022711753845\n",
      "The representation loss after processing this batch is:  0.003687843680381775\n",
      "\n",
      "The classification loss after processing this batch is:  0.13376405835151672\n",
      "The representation loss after processing this batch is:  0.0031510815024375916\n",
      "\n",
      "The classification loss after processing this batch is:  0.1053132489323616\n",
      "The representation loss after processing this batch is:  0.0027452409267425537\n",
      "\n",
      "The classification loss after processing this batch is:  0.09485840052366257\n",
      "The representation loss after processing this batch is:  0.002718202769756317\n",
      "\n",
      "The classification loss after processing this batch is:  0.1363595426082611\n",
      "The representation loss after processing this batch is:  0.0024555325508117676\n",
      "\n",
      "The classification loss after processing this batch is:  0.06969274580478668\n",
      "The representation loss after processing this batch is:  0.002716831862926483\n",
      "\n",
      "The classification loss after processing this batch is:  0.06148788705468178\n",
      "The representation loss after processing this batch is:  0.002706483006477356\n",
      "\n",
      "The classification loss after processing this batch is:  0.04993968456983566\n",
      "The representation loss after processing this batch is:  0.0026119500398635864\n",
      "\n",
      "The classification loss after processing this batch is:  0.17706279456615448\n",
      "The representation loss after processing this batch is:  0.0031327642500400543\n",
      "\n",
      "The classification loss after processing this batch is:  0.15312010049819946\n",
      "The representation loss after processing this batch is:  0.002794809639453888\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.15308275818824768\n",
      "The representation loss after processing this batch is:  0.00261814147233963\n",
      "\n",
      "The classification loss after processing this batch is:  0.14148400723934174\n",
      "The representation loss after processing this batch is:  0.0033689066767692566\n",
      "\n",
      "The classification loss after processing this batch is:  0.12521493434906006\n",
      "The representation loss after processing this batch is:  0.002853214740753174\n",
      "\n",
      "The classification loss after processing this batch is:  0.13601836562156677\n",
      "The representation loss after processing this batch is:  0.0028657689690589905\n",
      "\n",
      "The classification loss after processing this batch is:  0.08940437436103821\n",
      "The representation loss after processing this batch is:  0.002759769558906555\n",
      "\n",
      "The classification loss after processing this batch is:  0.2776106894016266\n",
      "The representation loss after processing this batch is:  0.0032438263297080994\n",
      "\n",
      "The classification loss after processing this batch is:  0.1461532860994339\n",
      "The representation loss after processing this batch is:  0.0029109492897987366\n",
      "\n",
      "The classification loss after processing this batch is:  0.2178574502468109\n",
      "The representation loss after processing this batch is:  0.003223694860935211\n",
      "\n",
      "The classification loss after processing this batch is:  0.08759290724992752\n",
      "The representation loss after processing this batch is:  0.002417616546154022\n",
      "\n",
      "The classification loss after processing this batch is:  0.06560558825731277\n",
      "The representation loss after processing this batch is:  0.002660617232322693\n",
      "\n",
      "The classification loss after processing this batch is:  0.1823895424604416\n",
      "The representation loss after processing this batch is:  0.0024709105491638184\n",
      "\n",
      "The classification loss after processing this batch is:  0.14235356450080872\n",
      "The representation loss after processing this batch is:  0.0028787776827812195\n",
      "\n",
      "The classification loss after processing this batch is:  0.24743565917015076\n",
      "The representation loss after processing this batch is:  0.0025626644492149353\n",
      "\n",
      "The classification loss after processing this batch is:  0.18373142182826996\n",
      "The representation loss after processing this batch is:  0.0033240318298339844\n",
      "\n",
      "The classification loss after processing this batch is:  0.1498318314552307\n",
      "The representation loss after processing this batch is:  0.0033769384026527405\n",
      "\n",
      "The classification loss after processing this batch is:  0.1278086155653\n",
      "The representation loss after processing this batch is:  0.0027199164032936096\n",
      "\n",
      "The classification loss after processing this batch is:  0.0525829903781414\n",
      "The representation loss after processing this batch is:  0.002546161413192749\n",
      "\n",
      "The classification loss after processing this batch is:  0.09544556587934494\n",
      "The representation loss after processing this batch is:  0.002407252788543701\n",
      "\n",
      "The classification loss after processing this batch is:  0.10738351196050644\n",
      "The representation loss after processing this batch is:  0.002517394721508026\n",
      "\n",
      "The classification loss after processing this batch is:  0.06618239730596542\n",
      "The representation loss after processing this batch is:  0.0026872605085372925\n",
      "\n",
      "The classification loss after processing this batch is:  0.12318014353513718\n",
      "The representation loss after processing this batch is:  0.0024131014943122864\n",
      "\n",
      "The classification loss after processing this batch is:  0.19449274241924286\n",
      "The representation loss after processing this batch is:  0.0026695281267166138\n",
      "\n",
      "The classification loss after processing this batch is:  0.13804365694522858\n",
      "The representation loss after processing this batch is:  0.0023088306188583374\n",
      "\n",
      "The classification loss after processing this batch is:  0.09211334586143494\n",
      "The representation loss after processing this batch is:  0.002698272466659546\n",
      "\n",
      "The classification loss after processing this batch is:  0.0966162458062172\n",
      "The representation loss after processing this batch is:  0.00274658203125\n",
      "\n",
      "The classification loss after processing this batch is:  0.06605849415063858\n",
      "The representation loss after processing this batch is:  0.0029368624091148376\n",
      "\n",
      "The classification loss after processing this batch is:  0.10887698084115982\n",
      "The representation loss after processing this batch is:  0.0030324533581733704\n",
      "\n",
      "The classification loss after processing this batch is:  0.05579078942537308\n",
      "The representation loss after processing this batch is:  0.0030126720666885376\n",
      "\n",
      "The classification loss after processing this batch is:  0.13174687325954437\n",
      "The representation loss after processing this batch is:  0.0023967325687408447\n",
      "\n",
      "The classification loss after processing this batch is:  0.13487742841243744\n",
      "The representation loss after processing this batch is:  0.0028346776962280273\n",
      "\n",
      "The classification loss after processing this batch is:  0.051233332604169846\n",
      "The representation loss after processing this batch is:  0.0026940032839775085\n",
      "\n",
      "The classification loss after processing this batch is:  0.21847769618034363\n",
      "The representation loss after processing this batch is:  0.0023729652166366577\n",
      "\n",
      "The classification loss after processing this batch is:  0.10219422727823257\n",
      "The representation loss after processing this batch is:  0.002498544752597809\n",
      "\n",
      "The classification loss after processing this batch is:  0.08712899684906006\n",
      "The representation loss after processing this batch is:  0.0025414228439331055\n",
      "\n",
      "The classification loss after processing this batch is:  0.06185676157474518\n",
      "The representation loss after processing this batch is:  0.0028935372829437256\n",
      "\n",
      "The classification loss after processing this batch is:  0.07261912524700165\n",
      "The representation loss after processing this batch is:  0.002727113664150238\n",
      "\n",
      "The classification loss after processing this batch is:  0.06710121780633926\n",
      "The representation loss after processing this batch is:  0.002551242709159851\n",
      "\n",
      "The classification loss after processing this batch is:  0.3548922836780548\n",
      "The representation loss after processing this batch is:  0.0023666508495807648\n",
      "\n",
      "The classification loss after processing this batch is:  0.11871011555194855\n",
      "The representation loss after processing this batch is:  0.0028104260563850403\n",
      "\n",
      "The classification loss after processing this batch is:  0.15947578847408295\n",
      "The representation loss after processing this batch is:  0.002392977476119995\n",
      "\n",
      "The classification loss after processing this batch is:  0.08128026872873306\n",
      "The representation loss after processing this batch is:  0.0023955851793289185\n",
      "\n",
      "The classification loss after processing this batch is:  0.1212519183754921\n",
      "The representation loss after processing this batch is:  0.002776987850666046\n",
      "\n",
      "The classification loss after processing this batch is:  0.058567777276039124\n",
      "The representation loss after processing this batch is:  0.0026088543236255646\n",
      "\n",
      "The classification loss after processing this batch is:  0.07585436850786209\n",
      "The representation loss after processing this batch is:  0.0027078017592430115\n",
      "\n",
      "The classification loss after processing this batch is:  0.1798849254846573\n",
      "The representation loss after processing this batch is:  0.0027353838086128235\n",
      "\n",
      "The classification loss after processing this batch is:  0.11762622743844986\n",
      "The representation loss after processing this batch is:  0.003306981176137924\n",
      "\n",
      "The classification loss after processing this batch is:  0.1538483053445816\n",
      "The representation loss after processing this batch is:  0.0030191950500011444\n",
      "\n",
      "The classification loss after processing this batch is:  0.0910128802061081\n",
      "The representation loss after processing this batch is:  0.0023955032229423523\n",
      "\n",
      "The classification loss after processing this batch is:  0.1988816261291504\n",
      "The representation loss after processing this batch is:  0.0026272758841514587\n",
      "\n",
      "The classification loss after processing this batch is:  0.12910231947898865\n",
      "The representation loss after processing this batch is:  0.002772517502307892\n",
      "\n",
      "The classification loss after processing this batch is:  0.20201589167118073\n",
      "The representation loss after processing this batch is:  0.0026814937591552734\n",
      "\n",
      "The classification loss after processing this batch is:  0.0918639674782753\n",
      "The representation loss after processing this batch is:  0.002797253429889679\n",
      "\n",
      "The classification loss after processing this batch is:  0.0940965786576271\n",
      "The representation loss after processing this batch is:  0.0030892789363861084\n",
      "\n",
      "The classification loss after processing this batch is:  0.042419806122779846\n",
      "The representation loss after processing this batch is:  0.0025850608944892883\n",
      "\n",
      "The classification loss after processing this batch is:  0.19280344247817993\n",
      "The representation loss after processing this batch is:  0.0026412233710289\n",
      "\n",
      "The classification loss after processing this batch is:  0.252123087644577\n",
      "The representation loss after processing this batch is:  0.0029434338212013245\n",
      "\n",
      "The classification loss after processing this batch is:  0.11309679597616196\n",
      "The representation loss after processing this batch is:  0.0026515796780586243\n",
      "\n",
      "The classification loss after processing this batch is:  0.18327517807483673\n",
      "The representation loss after processing this batch is:  0.003214888274669647\n",
      "\n",
      "The classification loss after processing this batch is:  0.16507822275161743\n",
      "The representation loss after processing this batch is:  0.002909597009420395\n",
      "\n",
      "The classification loss after processing this batch is:  0.16272541880607605\n",
      "The representation loss after processing this batch is:  0.002748411148786545\n",
      "\n",
      "The classification loss after processing this batch is:  0.0668051540851593\n",
      "The representation loss after processing this batch is:  0.0025776252150535583\n",
      "\n",
      "The classification loss after processing this batch is:  0.11512216180562973\n",
      "The representation loss after processing this batch is:  0.0026144757866859436\n",
      "\n",
      "The classification loss after processing this batch is:  0.14492668211460114\n",
      "The representation loss after processing this batch is:  0.0029137209057807922\n",
      "\n",
      "The classification loss after processing this batch is:  0.1078931987285614\n",
      "The representation loss after processing this batch is:  0.0027780309319496155\n",
      "\n",
      "The classification loss after processing this batch is:  0.03917941823601723\n",
      "The representation loss after processing this batch is:  0.0028317272663116455\n",
      "\n",
      "The classification loss after processing this batch is:  0.07459433376789093\n",
      "The representation loss after processing this batch is:  0.0029561519622802734\n",
      "\n",
      "The classification loss after processing this batch is:  0.08338049054145813\n",
      "The representation loss after processing this batch is:  0.002819158136844635\n",
      "\n",
      "The classification loss after processing this batch is:  0.11431988328695297\n",
      "The representation loss after processing this batch is:  0.002376556396484375\n",
      "\n",
      "The classification loss after processing this batch is:  0.1610472947359085\n",
      "The representation loss after processing this batch is:  0.0025802701711654663\n",
      "\n",
      "The classification loss after processing this batch is:  0.095795176923275\n",
      "The representation loss after processing this batch is:  0.0023871809244155884\n",
      "\n",
      "The classification loss after processing this batch is:  0.12278535217046738\n",
      "The representation loss after processing this batch is:  0.0030294060707092285\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.16918043792247772\n",
      "The representation loss after processing this batch is:  0.0027438923716545105\n",
      "\n",
      "The classification loss after processing this batch is:  0.12115467339754105\n",
      "The representation loss after processing this batch is:  0.0033644214272499084\n",
      "\n",
      "The classification loss after processing this batch is:  0.08738406747579575\n",
      "The representation loss after processing this batch is:  0.0027084127068519592\n",
      "\n",
      "The classification loss after processing this batch is:  0.15712763369083405\n",
      "The representation loss after processing this batch is:  0.002759091556072235\n",
      "\n",
      "The classification loss after processing this batch is:  0.14088226854801178\n",
      "The representation loss after processing this batch is:  0.0031129419803619385\n",
      "\n",
      "The classification loss after processing this batch is:  0.13190077245235443\n",
      "The representation loss after processing this batch is:  0.0028148889541625977\n",
      "\n",
      "The classification loss after processing this batch is:  0.09302757680416107\n",
      "The representation loss after processing this batch is:  0.0024870596826076508\n",
      "\n",
      "The classification loss after processing this batch is:  0.09453441202640533\n",
      "The representation loss after processing this batch is:  0.0024680346250534058\n",
      "\n",
      "The classification loss after processing this batch is:  0.09391340613365173\n",
      "The representation loss after processing this batch is:  0.0027042850852012634\n",
      "\n",
      "The classification loss after processing this batch is:  0.10578014701604843\n",
      "The representation loss after processing this batch is:  0.002642970532178879\n",
      "\n",
      "The classification loss after processing this batch is:  0.1823364943265915\n",
      "The representation loss after processing this batch is:  0.0026919320225715637\n",
      "\n",
      "The classification loss after processing this batch is:  0.2631531357765198\n",
      "The representation loss after processing this batch is:  0.0027151480317115784\n",
      "\n",
      "The classification loss after processing this batch is:  0.13814754784107208\n",
      "The representation loss after processing this batch is:  0.002457760274410248\n",
      "\n",
      "The classification loss after processing this batch is:  0.126274973154068\n",
      "The representation loss after processing this batch is:  0.0026190802454948425\n",
      "\n",
      "The classification loss after processing this batch is:  0.11017949879169464\n",
      "The representation loss after processing this batch is:  0.0024866238236427307\n",
      "\n",
      "The classification loss after processing this batch is:  0.1419583261013031\n",
      "The representation loss after processing this batch is:  0.0025446005165576935\n",
      "\n",
      "The classification loss after processing this batch is:  0.17807041108608246\n",
      "The representation loss after processing this batch is:  0.0028014667332172394\n",
      "\n",
      "The classification loss after processing this batch is:  0.13509750366210938\n",
      "The representation loss after processing this batch is:  0.0025607459247112274\n",
      "\n",
      "The classification loss after processing this batch is:  0.32336410880088806\n",
      "The representation loss after processing this batch is:  0.0026486963033676147\n",
      "\n",
      "The classification loss after processing this batch is:  0.16012629866600037\n",
      "The representation loss after processing this batch is:  0.0024917274713516235\n",
      "\n",
      "The classification loss after processing this batch is:  0.06271339952945709\n",
      "The representation loss after processing this batch is:  0.003291971981525421\n",
      "\n",
      "The classification loss after processing this batch is:  0.1077001541852951\n",
      "The representation loss after processing this batch is:  0.0028754472732543945\n",
      "\n",
      "The classification loss after processing this batch is:  0.0864921510219574\n",
      "The representation loss after processing this batch is:  0.0027105510234832764\n",
      "\n",
      "The classification loss after processing this batch is:  0.15321503579616547\n",
      "The representation loss after processing this batch is:  0.0027792081236839294\n",
      "\n",
      "The classification loss after processing this batch is:  0.11753907054662704\n",
      "The representation loss after processing this batch is:  0.0024394355714321136\n",
      "\n",
      "The classification loss after processing this batch is:  0.11274706572294235\n",
      "The representation loss after processing this batch is:  0.0025774165987968445\n",
      "\n",
      "The classification loss after processing this batch is:  0.10049555450677872\n",
      "The representation loss after processing this batch is:  0.0027223527431488037\n",
      "\n",
      "The classification loss after processing this batch is:  0.14006850123405457\n",
      "The representation loss after processing this batch is:  0.0025676265358924866\n",
      "\n",
      "The classification loss after processing this batch is:  0.18144161999225616\n",
      "The representation loss after processing this batch is:  0.002412043511867523\n",
      "\n",
      "The classification loss after processing this batch is:  0.1993221640586853\n",
      "The representation loss after processing this batch is:  0.0026825740933418274\n",
      "\n",
      "The classification loss after processing this batch is:  0.12432878464460373\n",
      "The representation loss after processing this batch is:  0.002611227333545685\n",
      "\n",
      "The classification loss after processing this batch is:  0.04584536328911781\n",
      "The representation loss after processing this batch is:  0.00305301696062088\n",
      "\n",
      "The classification loss after processing this batch is:  0.029492108151316643\n",
      "The representation loss after processing this batch is:  0.0027205944061279297\n",
      "\n",
      "The classification loss after processing this batch is:  0.12470119446516037\n",
      "The representation loss after processing this batch is:  0.003132760524749756\n",
      "\n",
      "The classification loss after processing this batch is:  0.07040698826313019\n",
      "The representation loss after processing this batch is:  0.0038625895977020264\n",
      "\n",
      "The classification loss after processing this batch is:  0.15182927250862122\n",
      "The representation loss after processing this batch is:  0.002816416323184967\n",
      "\n",
      "The classification loss after processing this batch is:  0.12334153801202774\n",
      "The representation loss after processing this batch is:  0.0028663277626037598\n",
      "\n",
      "The classification loss after processing this batch is:  0.1898050606250763\n",
      "The representation loss after processing this batch is:  0.0025263726711273193\n",
      "\n",
      "The classification loss after processing this batch is:  0.04772145673632622\n",
      "The representation loss after processing this batch is:  0.002766422927379608\n",
      "\n",
      "The classification loss after processing this batch is:  0.12943077087402344\n",
      "The representation loss after processing this batch is:  0.0026880577206611633\n",
      "\n",
      "The classification loss after processing this batch is:  0.14052443206310272\n",
      "The representation loss after processing this batch is:  0.0030400454998016357\n",
      "\n",
      "The classification loss after processing this batch is:  0.18229036033153534\n",
      "The representation loss after processing this batch is:  0.0029362887144088745\n",
      "\n",
      "The classification loss after processing this batch is:  0.09695160388946533\n",
      "The representation loss after processing this batch is:  0.002990536391735077\n",
      "\n",
      "The classification loss after processing this batch is:  0.06580094248056412\n",
      "The representation loss after processing this batch is:  0.0023816637694835663\n",
      "\n",
      "The classification loss after processing this batch is:  0.11717874556779861\n",
      "The representation loss after processing this batch is:  0.0029445141553878784\n",
      "\n",
      "The classification loss after processing this batch is:  0.09104053676128387\n",
      "The representation loss after processing this batch is:  0.0024733692407608032\n",
      "\n",
      "The classification loss after processing this batch is:  0.10817655920982361\n",
      "The representation loss after processing this batch is:  0.00255034863948822\n",
      "\n",
      "The classification loss after processing this batch is:  0.14187510311603546\n",
      "The representation loss after processing this batch is:  0.002557694911956787\n",
      "\n",
      "The classification loss after processing this batch is:  0.08483009785413742\n",
      "The representation loss after processing this batch is:  0.002593420445919037\n",
      "\n",
      "The classification loss after processing this batch is:  0.030658308416604996\n",
      "The representation loss after processing this batch is:  0.0025326237082481384\n",
      "\n",
      "The classification loss after processing this batch is:  0.08022065460681915\n",
      "The representation loss after processing this batch is:  0.0029300153255462646\n",
      "\n",
      "The classification loss after processing this batch is:  0.03563138470053673\n",
      "The representation loss after processing this batch is:  0.0029731541872024536\n",
      "\n",
      "The classification loss after processing this batch is:  0.10487233102321625\n",
      "The representation loss after processing this batch is:  0.0026805177330970764\n",
      "\n",
      "The classification loss after processing this batch is:  0.0718388631939888\n",
      "The representation loss after processing this batch is:  0.002688303589820862\n",
      "\n",
      "The classification loss after processing this batch is:  0.05719586834311485\n",
      "The representation loss after processing this batch is:  0.002544611692428589\n",
      "\n",
      "The classification loss after processing this batch is:  0.1006699725985527\n",
      "The representation loss after processing this batch is:  0.0030599385499954224\n",
      "\n",
      "The classification loss after processing this batch is:  0.06962486356496811\n",
      "The representation loss after processing this batch is:  0.0027582719922065735\n",
      "\n",
      "The classification loss after processing this batch is:  0.049223024398088455\n",
      "The representation loss after processing this batch is:  0.00275266170501709\n",
      "\n",
      "The classification loss after processing this batch is:  0.08812496066093445\n",
      "The representation loss after processing this batch is:  0.0026019886136054993\n",
      "\n",
      "The classification loss after processing this batch is:  0.05977409705519676\n",
      "The representation loss after processing this batch is:  0.0026391148567199707\n",
      "\n",
      "The classification loss after processing this batch is:  0.04549071565270424\n",
      "The representation loss after processing this batch is:  0.002656087279319763\n",
      "\n",
      "The classification loss after processing this batch is:  0.09996979683637619\n",
      "The representation loss after processing this batch is:  0.002750970423221588\n",
      "\n",
      "The classification loss after processing this batch is:  0.12732240557670593\n",
      "The representation loss after processing this batch is:  0.002920962870121002\n",
      "\n",
      "The classification loss after processing this batch is:  0.060158733278512955\n",
      "The representation loss after processing this batch is:  0.0030152425169944763\n",
      "\n",
      "The classification loss after processing this batch is:  0.1965811401605606\n",
      "The representation loss after processing this batch is:  0.002808697521686554\n",
      "\n",
      "The classification loss after processing this batch is:  0.05431688204407692\n",
      "The representation loss after processing this batch is:  0.0026392415165901184\n",
      "\n",
      "The classification loss after processing this batch is:  0.12160824984312057\n",
      "The representation loss after processing this batch is:  0.002438269555568695\n",
      "\n",
      "The classification loss after processing this batch is:  0.13279680907726288\n",
      "The representation loss after processing this batch is:  0.0030205175280570984\n",
      "\n",
      "The classification loss after processing this batch is:  0.06840435415506363\n",
      "The representation loss after processing this batch is:  0.003191933035850525\n",
      "\n",
      "The classification loss after processing this batch is:  0.17534738779067993\n",
      "The representation loss after processing this batch is:  0.00272398442029953\n",
      "\n",
      "The classification loss after processing this batch is:  0.15920542180538177\n",
      "The representation loss after processing this batch is:  0.0024132058024406433\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.15483927726745605\n",
      "The representation loss after processing this batch is:  0.002613537013530731\n",
      "\n",
      "The classification loss after processing this batch is:  0.1486496478319168\n",
      "The representation loss after processing this batch is:  0.002620495855808258\n",
      "\n",
      "The classification loss after processing this batch is:  0.07604305446147919\n",
      "The representation loss after processing this batch is:  0.0029515251517295837\n",
      "\n",
      "The classification loss after processing this batch is:  0.09744792431592941\n",
      "The representation loss after processing this batch is:  0.0023369640111923218\n",
      "\n",
      "The classification loss after processing this batch is:  0.1083129495382309\n",
      "The representation loss after processing this batch is:  0.0027661994099617004\n",
      "\n",
      "The classification loss after processing this batch is:  0.16322937607765198\n",
      "The representation loss after processing this batch is:  0.0025062188506126404\n",
      "\n",
      "The classification loss after processing this batch is:  0.15204806625843048\n",
      "The representation loss after processing this batch is:  0.0025344863533973694\n",
      "\n",
      "The classification loss after processing this batch is:  0.06302782148122787\n",
      "The representation loss after processing this batch is:  0.002358660101890564\n",
      "\n",
      "The classification loss after processing this batch is:  0.08342814445495605\n",
      "The representation loss after processing this batch is:  0.002524435520172119\n",
      "\n",
      "The classification loss after processing this batch is:  0.18174003064632416\n",
      "The representation loss after processing this batch is:  0.002195540815591812\n",
      "\n",
      "The classification loss after processing this batch is:  0.07352665066719055\n",
      "The representation loss after processing this batch is:  0.002606593072414398\n",
      "\n",
      "The classification loss after processing this batch is:  0.12790127098560333\n",
      "The representation loss after processing this batch is:  0.0026645511388778687\n",
      "\n",
      "The classification loss after processing this batch is:  0.13645455241203308\n",
      "The representation loss after processing this batch is:  0.002591930329799652\n",
      "\n",
      "The classification loss after processing this batch is:  0.07247195392847061\n",
      "The representation loss after processing this batch is:  0.003048822283744812\n",
      "\n",
      "The classification loss after processing this batch is:  0.05255443602800369\n",
      "The representation loss after processing this batch is:  0.0028497055172920227\n",
      "\n",
      "The classification loss after processing this batch is:  0.11232807487249374\n",
      "The representation loss after processing this batch is:  0.002679869532585144\n",
      "\n",
      "The classification loss after processing this batch is:  0.14590848982334137\n",
      "The representation loss after processing this batch is:  0.0026662349700927734\n",
      "\n",
      "The classification loss after processing this batch is:  0.1498386114835739\n",
      "The representation loss after processing this batch is:  0.0028125494718551636\n",
      "\n",
      "The classification loss after processing this batch is:  0.2049146592617035\n",
      "The representation loss after processing this batch is:  0.003204669803380966\n",
      "\n",
      "The classification loss after processing this batch is:  0.11949459463357925\n",
      "The representation loss after processing this batch is:  0.002738647162914276\n",
      "\n",
      "The classification loss after processing this batch is:  0.15140792727470398\n",
      "The representation loss after processing this batch is:  0.0021873190999031067\n",
      "\n",
      "The classification loss after processing this batch is:  0.10753326863050461\n",
      "The representation loss after processing this batch is:  0.002923347055912018\n",
      "\n",
      "The classification loss after processing this batch is:  0.05365067347884178\n",
      "The representation loss after processing this batch is:  0.002825796604156494\n",
      "\n",
      "The classification loss after processing this batch is:  0.06509634107351303\n",
      "The representation loss after processing this batch is:  0.002597823739051819\n",
      "\n",
      "The classification loss after processing this batch is:  0.08566657453775406\n",
      "The representation loss after processing this batch is:  0.002667628228664398\n",
      "\n",
      "The classification loss after processing this batch is:  0.10865437984466553\n",
      "The representation loss after processing this batch is:  0.002828627824783325\n",
      "\n",
      "The classification loss after processing this batch is:  0.09219077974557877\n",
      "The representation loss after processing this batch is:  0.0027628093957901\n",
      "\n",
      "The classification loss after processing this batch is:  0.12082899361848831\n",
      "The representation loss after processing this batch is:  0.0031314268708229065\n",
      "\n",
      "The classification loss after processing this batch is:  0.13674046099185944\n",
      "The representation loss after processing this batch is:  0.0029969438910484314\n",
      "\n",
      "The classification loss after processing this batch is:  0.08776836097240448\n",
      "The representation loss after processing this batch is:  0.002943560481071472\n",
      "\n",
      "The classification loss after processing this batch is:  0.16201171278953552\n",
      "The representation loss after processing this batch is:  0.002795860171318054\n",
      "\n",
      "The classification loss after processing this batch is:  0.1681205779314041\n",
      "The representation loss after processing this batch is:  0.0025418847799301147\n",
      "\n",
      "The classification loss after processing this batch is:  0.19080431759357452\n",
      "The representation loss after processing this batch is:  0.0026617050170898438\n",
      "\n",
      "The classification loss after processing this batch is:  0.083747498691082\n",
      "The representation loss after processing this batch is:  0.0029122009873390198\n",
      "\n",
      "The classification loss after processing this batch is:  0.07660795748233795\n",
      "The representation loss after processing this batch is:  0.0025583356618881226\n",
      "\n",
      "The classification loss after processing this batch is:  0.21313095092773438\n",
      "The representation loss after processing this batch is:  0.0025479644536972046\n",
      "\n",
      "The classification loss after processing this batch is:  0.18872199952602386\n",
      "The representation loss after processing this batch is:  0.0024865567684173584\n",
      "\n",
      "The classification loss after processing this batch is:  0.1443554311990738\n",
      "The representation loss after processing this batch is:  0.0027734190225601196\n",
      "\n",
      "The classification loss after processing this batch is:  0.1210138127207756\n",
      "The representation loss after processing this batch is:  0.0025590062141418457\n",
      "\n",
      "The classification loss after processing this batch is:  0.13676652312278748\n",
      "The representation loss after processing this batch is:  0.0025793537497520447\n",
      "\n",
      "The classification loss after processing this batch is:  0.23026040196418762\n",
      "The representation loss after processing this batch is:  0.0024133026599884033\n",
      "\n",
      "The classification loss after processing this batch is:  0.19965369999408722\n",
      "The representation loss after processing this batch is:  0.002453930675983429\n",
      "\n",
      "The classification loss after processing this batch is:  0.19495932757854462\n",
      "The representation loss after processing this batch is:  0.002751976251602173\n",
      "\n",
      "The classification loss after processing this batch is:  0.16637389361858368\n",
      "The representation loss after processing this batch is:  0.0025654584169387817\n",
      "\n",
      "The classification loss after processing this batch is:  0.08240829408168793\n",
      "The representation loss after processing this batch is:  0.0029823780059814453\n",
      "\n",
      "The classification loss after processing this batch is:  0.06311208754777908\n",
      "The representation loss after processing this batch is:  0.0026224181056022644\n",
      "\n",
      "The classification loss after processing this batch is:  0.13370174169540405\n",
      "The representation loss after processing this batch is:  0.002797544002532959\n",
      "\n",
      "The classification loss after processing this batch is:  0.10553207248449326\n",
      "The representation loss after processing this batch is:  0.0025229379534721375\n",
      "\n",
      "The classification loss after processing this batch is:  0.05987558513879776\n",
      "The representation loss after processing this batch is:  0.002392202615737915\n",
      "\n",
      "The classification loss after processing this batch is:  0.05967821180820465\n",
      "The representation loss after processing this batch is:  0.0025790706276893616\n",
      "\n",
      "The classification loss after processing this batch is:  0.10282666236162186\n",
      "The representation loss after processing this batch is:  0.0025466755032539368\n",
      "\n",
      "The classification loss after processing this batch is:  0.10911201685667038\n",
      "The representation loss after processing this batch is:  0.0027636438608169556\n",
      "\n",
      "The classification loss after processing this batch is:  0.06850123405456543\n",
      "The representation loss after processing this batch is:  0.002848781645298004\n",
      "\n",
      "The classification loss after processing this batch is:  0.09703407436609268\n",
      "The representation loss after processing this batch is:  0.002459883689880371\n",
      "\n",
      "The classification loss after processing this batch is:  0.08414733409881592\n",
      "The representation loss after processing this batch is:  0.0027478747069835663\n",
      "\n",
      "The classification loss after processing this batch is:  0.17512869834899902\n",
      "The representation loss after processing this batch is:  0.002658471465110779\n",
      "\n",
      "The classification loss after processing this batch is:  0.10185419768095016\n",
      "The representation loss after processing this batch is:  0.0025679469108581543\n",
      "\n",
      "The classification loss after processing this batch is:  0.15969565510749817\n",
      "The representation loss after processing this batch is:  0.0028375759720802307\n",
      "\n",
      "The classification loss after processing this batch is:  0.0516541451215744\n",
      "The representation loss after processing this batch is:  0.0025612860918045044\n",
      "\n",
      "The classification loss after processing this batch is:  0.05326893553137779\n",
      "The representation loss after processing this batch is:  0.00295083224773407\n",
      "\n",
      "The classification loss after processing this batch is:  0.1332109272480011\n",
      "The representation loss after processing this batch is:  0.002531401813030243\n",
      "\n",
      "The classification loss after processing this batch is:  0.17758531868457794\n",
      "The representation loss after processing this batch is:  0.0026074275374412537\n",
      "\n",
      "The classification loss after processing this batch is:  0.10486545413732529\n",
      "The representation loss after processing this batch is:  0.0026058033108711243\n",
      "\n",
      "The classification loss after processing this batch is:  0.057791028171777725\n",
      "The representation loss after processing this batch is:  0.0024619363248348236\n",
      "\n",
      "The classification loss after processing this batch is:  0.11082396656274796\n",
      "The representation loss after processing this batch is:  0.0022679343819618225\n",
      "\n",
      "The classification loss after processing this batch is:  0.02547917328774929\n",
      "The representation loss after processing this batch is:  0.0028548985719680786\n",
      "\n",
      "The classification loss after processing this batch is:  0.16561771929264069\n",
      "The representation loss after processing this batch is:  0.0025707483291625977\n",
      "\n",
      "The classification loss after processing this batch is:  0.11507368832826614\n",
      "The representation loss after processing this batch is:  0.0028876885771751404\n",
      "\n",
      "The classification loss after processing this batch is:  0.08235648274421692\n",
      "The representation loss after processing this batch is:  0.00261630117893219\n",
      "\n",
      "The classification loss after processing this batch is:  0.09293650090694427\n",
      "The representation loss after processing this batch is:  0.0027623847126960754\n",
      "\n",
      "The classification loss after processing this batch is:  0.09664257615804672\n",
      "The representation loss after processing this batch is:  0.0027555376291275024\n",
      "\n",
      "The classification loss after processing this batch is:  0.04245747625827789\n",
      "The representation loss after processing this batch is:  0.0026679933071136475\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.24304717779159546\n",
      "The representation loss after processing this batch is:  0.0025348961353302\n",
      "\n",
      "The classification loss after processing this batch is:  0.22117026150226593\n",
      "The representation loss after processing this batch is:  0.0026174336671829224\n",
      "\n",
      "The classification loss after processing this batch is:  0.16083145141601562\n",
      "The representation loss after processing this batch is:  0.002522118389606476\n",
      "\n",
      "The classification loss after processing this batch is:  0.1713918000459671\n",
      "The representation loss after processing this batch is:  0.002447187900543213\n",
      "\n",
      "The classification loss after processing this batch is:  0.10288974642753601\n",
      "The representation loss after processing this batch is:  0.002627536654472351\n",
      "\n",
      "The classification loss after processing this batch is:  0.08899395167827606\n",
      "The representation loss after processing this batch is:  0.002429381012916565\n",
      "\n",
      "The classification loss after processing this batch is:  0.19509419798851013\n",
      "The representation loss after processing this batch is:  0.0025881752371788025\n",
      "\n",
      "The classification loss after processing this batch is:  0.11245780438184738\n",
      "The representation loss after processing this batch is:  0.0024857893586158752\n",
      "\n",
      "The classification loss after processing this batch is:  0.17395558953285217\n",
      "The representation loss after processing this batch is:  0.002582959830760956\n",
      "\n",
      "The classification loss after processing this batch is:  0.09521657973527908\n",
      "The representation loss after processing this batch is:  0.0027601495385169983\n",
      "\n",
      "The classification loss after processing this batch is:  0.1650814265012741\n",
      "The representation loss after processing this batch is:  0.002410478889942169\n",
      "\n",
      "The classification loss after processing this batch is:  0.08072715252637863\n",
      "The representation loss after processing this batch is:  0.0024744905531406403\n",
      "\n",
      "The classification loss after processing this batch is:  0.07863010466098785\n",
      "The representation loss after processing this batch is:  0.0029069632291793823\n",
      "\n",
      "The classification loss after processing this batch is:  0.11985784024000168\n",
      "The representation loss after processing this batch is:  0.002614252269268036\n",
      "\n",
      "The classification loss after processing this batch is:  0.05242021009325981\n",
      "The representation loss after processing this batch is:  0.002611972391605377\n",
      "\n",
      "The classification loss after processing this batch is:  0.03668362274765968\n",
      "The representation loss after processing this batch is:  0.0026509463787078857\n",
      "\n",
      "The classification loss after processing this batch is:  0.09086772799491882\n",
      "The representation loss after processing this batch is:  0.0026195570826530457\n",
      "\n",
      "The classification loss after processing this batch is:  0.22793637216091156\n",
      "The representation loss after processing this batch is:  0.002684846520423889\n",
      "\n",
      "The classification loss after processing this batch is:  0.03511619567871094\n",
      "The representation loss after processing this batch is:  0.0027400553226470947\n",
      "\n",
      "The classification loss after processing this batch is:  0.06519494205713272\n",
      "The representation loss after processing this batch is:  0.0024892427027225494\n",
      "\n",
      "The classification loss after processing this batch is:  0.13326005637645721\n",
      "The representation loss after processing this batch is:  0.002528361976146698\n",
      "\n",
      "The classification loss after processing this batch is:  0.16823235154151917\n",
      "The representation loss after processing this batch is:  0.002533838152885437\n",
      "\n",
      "The classification loss after processing this batch is:  0.09818807244300842\n",
      "The representation loss after processing this batch is:  0.002716064453125\n",
      "\n",
      "The classification loss after processing this batch is:  0.18491044640541077\n",
      "The representation loss after processing this batch is:  0.00247148796916008\n",
      "\n",
      "The classification loss after processing this batch is:  0.08341392129659653\n",
      "The representation loss after processing this batch is:  0.0029746592044830322\n",
      "\n",
      "The classification loss after processing this batch is:  0.042784128338098526\n",
      "The representation loss after processing this batch is:  0.002422153949737549\n",
      "\n",
      "The classification loss after processing this batch is:  0.0431106835603714\n",
      "The representation loss after processing this batch is:  0.0030321478843688965\n",
      "\n",
      "The classification loss after processing this batch is:  0.1508261114358902\n",
      "The representation loss after processing this batch is:  0.002947106957435608\n",
      "\n",
      "The classification loss after processing this batch is:  0.1317230612039566\n",
      "The representation loss after processing this batch is:  0.0028091520071029663\n",
      "\n",
      "The classification loss after processing this batch is:  0.08273245394229889\n",
      "The representation loss after processing this batch is:  0.0030259788036346436\n",
      "\n",
      "The classification loss after processing this batch is:  0.13691698014736176\n",
      "The representation loss after processing this batch is:  0.0028055906295776367\n",
      "\n",
      "The classification loss after processing this batch is:  0.0843396931886673\n",
      "The representation loss after processing this batch is:  0.0027575790882110596\n",
      "\n",
      "The classification loss after processing this batch is:  0.0937948152422905\n",
      "The representation loss after processing this batch is:  0.0026269182562828064\n",
      "\n",
      "The classification loss after processing this batch is:  0.10394483059644699\n",
      "The representation loss after processing this batch is:  0.002814874053001404\n",
      "\n",
      "The classification loss after processing this batch is:  0.1392156332731247\n",
      "The representation loss after processing this batch is:  0.0028268396854400635\n",
      "\n",
      "The classification loss after processing this batch is:  0.13690480589866638\n",
      "The representation loss after processing this batch is:  0.0030985474586486816\n",
      "\n",
      "The classification loss after processing this batch is:  0.27099815011024475\n",
      "The representation loss after processing this batch is:  0.0023060068488121033\n",
      "\n",
      "The classification loss after processing this batch is:  0.17769768834114075\n",
      "The representation loss after processing this batch is:  0.0025044530630111694\n",
      "\n",
      "The classification loss after processing this batch is:  0.1247708722949028\n",
      "The representation loss after processing this batch is:  0.0028055235743522644\n",
      "\n",
      "The classification loss after processing this batch is:  0.12451447546482086\n",
      "The representation loss after processing this batch is:  0.0028649568557739258\n",
      "\n",
      "The classification loss after processing this batch is:  0.0377487987279892\n",
      "The representation loss after processing this batch is:  0.002562582492828369\n",
      "\n",
      "The classification loss after processing this batch is:  0.0943739041686058\n",
      "The representation loss after processing this batch is:  0.0030071139335632324\n",
      "\n",
      "The classification loss after processing this batch is:  0.07648631185293198\n",
      "The representation loss after processing this batch is:  0.002837352454662323\n",
      "\n",
      "The classification loss after processing this batch is:  0.1311611384153366\n",
      "The representation loss after processing this batch is:  0.002592090517282486\n",
      "\n",
      "The classification loss after processing this batch is:  0.12657852470874786\n",
      "The representation loss after processing this batch is:  0.0023837387561798096\n",
      "\n",
      "The classification loss after processing this batch is:  0.08536534011363983\n",
      "The representation loss after processing this batch is:  0.002360578626394272\n",
      "\n",
      "The classification loss after processing this batch is:  0.12093639373779297\n",
      "The representation loss after processing this batch is:  0.002587363123893738\n",
      "\n",
      "The classification loss after processing this batch is:  0.15396298468112946\n",
      "The representation loss after processing this batch is:  0.002405129373073578\n",
      "\n",
      "The classification loss after processing this batch is:  0.12637852132320404\n",
      "The representation loss after processing this batch is:  0.002703644335269928\n",
      "\n",
      "The classification loss after processing this batch is:  0.21757589280605316\n",
      "The representation loss after processing this batch is:  0.0028345733880996704\n",
      "\n",
      "The classification loss after processing this batch is:  0.08126769959926605\n",
      "The representation loss after processing this batch is:  0.002785220742225647\n",
      "\n",
      "The classification loss after processing this batch is:  0.10769088566303253\n",
      "The representation loss after processing this batch is:  0.002328891307115555\n",
      "\n",
      "The classification loss after processing this batch is:  0.08712287992238998\n",
      "The representation loss after processing this batch is:  0.0026623159646987915\n",
      "\n",
      "The classification loss after processing this batch is:  0.21239976584911346\n",
      "The representation loss after processing this batch is:  0.00282297283411026\n",
      "\n",
      "The classification loss after processing this batch is:  0.1855798363685608\n",
      "The representation loss after processing this batch is:  0.0029708966612815857\n",
      "\n",
      "The classification loss after processing this batch is:  0.04827313497662544\n",
      "The representation loss after processing this batch is:  0.0026000961661338806\n",
      "\n",
      "The classification loss after processing this batch is:  0.07005265355110168\n",
      "The representation loss after processing this batch is:  0.0027871057391166687\n",
      "\n",
      "The classification loss after processing this batch is:  0.23130851984024048\n",
      "The representation loss after processing this batch is:  0.002434663474559784\n",
      "\n",
      "The classification loss after processing this batch is:  0.07301867753267288\n",
      "The representation loss after processing this batch is:  0.0025774985551834106\n",
      "\n",
      "The classification loss after processing this batch is:  0.07021350413560867\n",
      "The representation loss after processing this batch is:  0.0027254968881607056\n",
      "\n",
      "The classification loss after processing this batch is:  0.12463290244340897\n",
      "The representation loss after processing this batch is:  0.0025655850768089294\n",
      "\n",
      "The classification loss after processing this batch is:  0.09366684406995773\n",
      "The representation loss after processing this batch is:  0.002678975462913513\n",
      "\n",
      "The classification loss after processing this batch is:  0.19426684081554413\n",
      "The representation loss after processing this batch is:  0.0030477046966552734\n",
      "\n",
      "The classification loss after processing this batch is:  0.1256464272737503\n",
      "The representation loss after processing this batch is:  0.0030564963817596436\n",
      "\n",
      "The classification loss after processing this batch is:  0.1464022547006607\n",
      "The representation loss after processing this batch is:  0.0031933188438415527\n",
      "\n",
      "The classification loss after processing this batch is:  0.12447820603847504\n",
      "The representation loss after processing this batch is:  0.002544015645980835\n",
      "\n",
      "The classification loss after processing this batch is:  0.16281291842460632\n",
      "The representation loss after processing this batch is:  0.002289310097694397\n",
      "\n",
      "The classification loss after processing this batch is:  0.04455270245671272\n",
      "The representation loss after processing this batch is:  0.0024657323956489563\n",
      "\n",
      "The classification loss after processing this batch is:  0.05010930448770523\n",
      "The representation loss after processing this batch is:  0.002465948462486267\n",
      "\n",
      "The classification loss after processing this batch is:  0.06963184475898743\n",
      "The representation loss after processing this batch is:  0.0025548413395881653\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.06020070239901543\n",
      "The representation loss after processing this batch is:  0.0026911795139312744\n",
      "\n",
      "The classification loss after processing this batch is:  0.09826483577489853\n",
      "The representation loss after processing this batch is:  0.002795681357383728\n",
      "\n",
      "The classification loss after processing this batch is:  0.06460488587617874\n",
      "The representation loss after processing this batch is:  0.002424381673336029\n",
      "\n",
      "The classification loss after processing this batch is:  0.07634308934211731\n",
      "The representation loss after processing this batch is:  0.0023215338587760925\n",
      "\n",
      "The classification loss after processing this batch is:  0.1298561692237854\n",
      "The representation loss after processing this batch is:  0.002625994384288788\n",
      "\n",
      "The classification loss after processing this batch is:  0.16651272773742676\n",
      "The representation loss after processing this batch is:  0.0027599334716796875\n",
      "\n",
      "The classification loss after processing this batch is:  0.1519758552312851\n",
      "The representation loss after processing this batch is:  0.0024898461997509003\n",
      "\n",
      "The classification loss after processing this batch is:  0.15104073286056519\n",
      "The representation loss after processing this batch is:  0.0028212666511535645\n",
      "\n",
      "The classification loss after processing this batch is:  0.16753292083740234\n",
      "The representation loss after processing this batch is:  0.0024208053946495056\n",
      "\n",
      "The classification loss after processing this batch is:  0.08212395012378693\n",
      "The representation loss after processing this batch is:  0.0025376975536346436\n",
      "\n",
      "The classification loss after processing this batch is:  0.14260154962539673\n",
      "The representation loss after processing this batch is:  0.002754226326942444\n",
      "\n",
      "The classification loss after processing this batch is:  0.24142669141292572\n",
      "The representation loss after processing this batch is:  0.002745412290096283\n",
      "\n",
      "The classification loss after processing this batch is:  0.09151116013526917\n",
      "The representation loss after processing this batch is:  0.002550598233938217\n",
      "\n",
      "The classification loss after processing this batch is:  0.1570780873298645\n",
      "The representation loss after processing this batch is:  0.0023767314851284027\n",
      "\n",
      "The classification loss after processing this batch is:  0.1603645384311676\n",
      "The representation loss after processing this batch is:  0.002379804849624634\n",
      "\n",
      "The classification loss after processing this batch is:  0.13989858329296112\n",
      "The representation loss after processing this batch is:  0.002338394522666931\n",
      "\n",
      "The classification loss after processing this batch is:  0.07891272008419037\n",
      "The representation loss after processing this batch is:  0.002704150974750519\n",
      "\n",
      "The classification loss after processing this batch is:  0.07049320638179779\n",
      "The representation loss after processing this batch is:  0.0025802552700042725\n",
      "\n",
      "The classification loss after processing this batch is:  0.09951586276292801\n",
      "The representation loss after processing this batch is:  0.0024435296654701233\n",
      "\n",
      "The classification loss after processing this batch is:  0.055912263691425323\n",
      "The representation loss after processing this batch is:  0.002696216106414795\n",
      "\n",
      "The classification loss after processing this batch is:  0.036143336445093155\n",
      "The representation loss after processing this batch is:  0.002522990107536316\n",
      "\n",
      "The classification loss after processing this batch is:  0.13567565381526947\n",
      "The representation loss after processing this batch is:  0.0030186623334884644\n",
      "\n",
      "The classification loss after processing this batch is:  0.047787465155124664\n",
      "The representation loss after processing this batch is:  0.0030142664909362793\n",
      "\n",
      "The classification loss after processing this batch is:  0.19400332868099213\n",
      "The representation loss after processing this batch is:  0.003048919141292572\n",
      "\n",
      "The classification loss after processing this batch is:  0.1187930479645729\n",
      "The representation loss after processing this batch is:  0.0026069730520248413\n",
      "\n",
      "The classification loss after processing this batch is:  0.18527960777282715\n",
      "The representation loss after processing this batch is:  0.002740137279033661\n",
      "\n",
      "The classification loss after processing this batch is:  0.32736343145370483\n",
      "The representation loss after processing this batch is:  0.0021802373230457306\n",
      "\n",
      "The classification loss after processing this batch is:  0.1378648430109024\n",
      "The representation loss after processing this batch is:  0.0025379471480846405\n",
      "\n",
      "The classification loss after processing this batch is:  0.04376121982932091\n",
      "The representation loss after processing this batch is:  0.002633415162563324\n",
      "\n",
      "The classification loss after processing this batch is:  0.07933187484741211\n",
      "The representation loss after processing this batch is:  0.0029534846544265747\n",
      "\n",
      "The classification loss after processing this batch is:  0.05859227105975151\n",
      "The representation loss after processing this batch is:  0.0028578341007232666\n",
      "\n",
      "The classification loss after processing this batch is:  0.06511196494102478\n",
      "The representation loss after processing this batch is:  0.002723880112171173\n",
      "\n",
      "The classification loss after processing this batch is:  0.07490506023168564\n",
      "The representation loss after processing this batch is:  0.002471737563610077\n",
      "\n",
      "The classification loss after processing this batch is:  0.17956675589084625\n",
      "The representation loss after processing this batch is:  0.0025388672947883606\n",
      "\n",
      "The classification loss after processing this batch is:  0.14911235868930817\n",
      "The representation loss after processing this batch is:  0.0026093609631061554\n",
      "\n",
      "The classification loss after processing this batch is:  0.13859273493289948\n",
      "The representation loss after processing this batch is:  0.003202274441719055\n",
      "\n",
      "The classification loss after processing this batch is:  0.22463534772396088\n",
      "The representation loss after processing this batch is:  0.0033718496561050415\n",
      "\n",
      "The classification loss after processing this batch is:  0.09881008416414261\n",
      "The representation loss after processing this batch is:  0.002691619098186493\n",
      "\n",
      "The classification loss after processing this batch is:  0.10678039491176605\n",
      "The representation loss after processing this batch is:  0.002712700515985489\n",
      "\n",
      "The classification loss after processing this batch is:  0.1793602854013443\n",
      "The representation loss after processing this batch is:  0.0025615356862545013\n",
      "\n",
      "The classification loss after processing this batch is:  0.10887681692838669\n",
      "The representation loss after processing this batch is:  0.003036491572856903\n",
      "\n",
      "The classification loss after processing this batch is:  0.1387091726064682\n",
      "The representation loss after processing this batch is:  0.003856286406517029\n",
      "\n",
      "The classification loss after processing this batch is:  0.06309394538402557\n",
      "The representation loss after processing this batch is:  0.0027305521070957184\n",
      "\n",
      "The classification loss after processing this batch is:  0.15519022941589355\n",
      "The representation loss after processing this batch is:  0.003039643168449402\n",
      "\n",
      "The classification loss after processing this batch is:  0.15087608993053436\n",
      "The representation loss after processing this batch is:  0.0032571330666542053\n",
      "\n",
      "The classification loss after processing this batch is:  0.09604286402463913\n",
      "The representation loss after processing this batch is:  0.0033033639192581177\n",
      "\n",
      "The classification loss after processing this batch is:  0.14623670279979706\n",
      "The representation loss after processing this batch is:  0.0027495846152305603\n",
      "\n",
      "The classification loss after processing this batch is:  0.14546769857406616\n",
      "The representation loss after processing this batch is:  0.002389766275882721\n",
      "\n",
      "The classification loss after processing this batch is:  0.1248500645160675\n",
      "The representation loss after processing this batch is:  0.002411864697933197\n",
      "\n",
      "The classification loss after processing this batch is:  0.1339915245771408\n",
      "The representation loss after processing this batch is:  0.002616681158542633\n",
      "\n",
      "The classification loss after processing this batch is:  0.102598175406456\n",
      "The representation loss after processing this batch is:  0.002858951687812805\n",
      "\n",
      "The classification loss after processing this batch is:  0.032287850975990295\n",
      "The representation loss after processing this batch is:  0.002616666257381439\n",
      "\n",
      "The classification loss after processing this batch is:  0.12319180369377136\n",
      "The representation loss after processing this batch is:  0.0027211830019950867\n",
      "\n",
      "The classification loss after processing this batch is:  0.05838228017091751\n",
      "The representation loss after processing this batch is:  0.002925790846347809\n",
      "\n",
      "The classification loss after processing this batch is:  0.23561926186084747\n",
      "The representation loss after processing this batch is:  0.0026032626628875732\n",
      "\n",
      "The classification loss after processing this batch is:  0.057633452117443085\n",
      "The representation loss after processing this batch is:  0.0029637888073921204\n",
      "\n",
      "The classification loss after processing this batch is:  0.1005789190530777\n",
      "The representation loss after processing this batch is:  0.0025551840662956238\n",
      "\n",
      "The classification loss after processing this batch is:  0.16635562479496002\n",
      "The representation loss after processing this batch is:  0.002876177430152893\n",
      "\n",
      "The classification loss after processing this batch is:  0.11841476708650589\n",
      "The representation loss after processing this batch is:  0.0027958229184150696\n",
      "\n",
      "The classification loss after processing this batch is:  0.13764755427837372\n",
      "The representation loss after processing this batch is:  0.0025703608989715576\n",
      "\n",
      "The classification loss after processing this batch is:  0.08332429081201553\n",
      "The representation loss after processing this batch is:  0.0025276988744735718\n",
      "\n",
      "The classification loss after processing this batch is:  0.06848922371864319\n",
      "The representation loss after processing this batch is:  0.0024161003530025482\n",
      "\n",
      "The classification loss after processing this batch is:  0.08903876692056656\n",
      "The representation loss after processing this batch is:  0.0024049505591392517\n",
      "\n",
      "The classification loss after processing this batch is:  0.17170903086662292\n",
      "The representation loss after processing this batch is:  0.0028903186321258545\n",
      "\n",
      "The classification loss after processing this batch is:  0.18936610221862793\n",
      "The representation loss after processing this batch is:  0.002620600163936615\n",
      "\n",
      "The classification loss after processing this batch is:  0.15358160436153412\n",
      "The representation loss after processing this batch is:  0.0021973401308059692\n",
      "\n",
      "The classification loss after processing this batch is:  0.1396821141242981\n",
      "The representation loss after processing this batch is:  0.0024652257561683655\n",
      "\n",
      "The classification loss after processing this batch is:  0.22766846418380737\n",
      "The representation loss after processing this batch is:  0.002567112445831299\n",
      "\n",
      "The classification loss after processing this batch is:  0.1045517772436142\n",
      "The representation loss after processing this batch is:  0.002819269895553589\n",
      "\n",
      "The classification loss after processing this batch is:  0.21488691866397858\n",
      "The representation loss after processing this batch is:  0.002758115530014038\n",
      "\n",
      "The classification loss after processing this batch is:  0.10495328903198242\n",
      "The representation loss after processing this batch is:  0.0027817562222480774\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.058048080652952194\n",
      "The representation loss after processing this batch is:  0.0027739107608795166\n",
      "\n",
      "The classification loss after processing this batch is:  0.04283067211508751\n",
      "The representation loss after processing this batch is:  0.0024078786373138428\n",
      "\n",
      "The classification loss after processing this batch is:  0.05746384337544441\n",
      "The representation loss after processing this batch is:  0.0025572627782821655\n",
      "\n",
      "The classification loss after processing this batch is:  0.19401241838932037\n",
      "The representation loss after processing this batch is:  0.0027161985635757446\n",
      "\n",
      "The classification loss after processing this batch is:  0.06612711399793625\n",
      "The representation loss after processing this batch is:  0.00273103266954422\n",
      "\n",
      "The classification loss after processing this batch is:  0.12395889312028885\n",
      "The representation loss after processing this batch is:  0.0027373507618904114\n",
      "\n",
      "The classification loss after processing this batch is:  0.12948116660118103\n",
      "The representation loss after processing this batch is:  0.002916291356086731\n",
      "\n",
      "The classification loss after processing this batch is:  0.08855781704187393\n",
      "The representation loss after processing this batch is:  0.0027916058897972107\n",
      "\n",
      "The classification loss after processing this batch is:  0.06067837029695511\n",
      "The representation loss after processing this batch is:  0.002492085099220276\n",
      "\n",
      "The classification loss after processing this batch is:  0.15744924545288086\n",
      "The representation loss after processing this batch is:  0.0024321898818016052\n",
      "\n",
      "The classification loss after processing this batch is:  0.2014402449131012\n",
      "The representation loss after processing this batch is:  0.00257100909948349\n",
      "\n",
      "The classification loss after processing this batch is:  0.16151012480258942\n",
      "The representation loss after processing this batch is:  0.002770267426967621\n",
      "\n",
      "The classification loss after processing this batch is:  0.07895272225141525\n",
      "The representation loss after processing this batch is:  0.0025687813758850098\n",
      "\n",
      "The classification loss after processing this batch is:  0.21277976036071777\n",
      "The representation loss after processing this batch is:  0.0024837590754032135\n",
      "\n",
      "The classification loss after processing this batch is:  0.06909739971160889\n",
      "The representation loss after processing this batch is:  0.0022544190287590027\n",
      "\n",
      "The classification loss after processing this batch is:  0.15689846873283386\n",
      "The representation loss after processing this batch is:  0.0024476051330566406\n",
      "\n",
      "The classification loss after processing this batch is:  0.15671086311340332\n",
      "The representation loss after processing this batch is:  0.0029292404651641846\n",
      "\n",
      "The classification loss after processing this batch is:  0.11619417369365692\n",
      "The representation loss after processing this batch is:  0.0025412514805793762\n",
      "\n",
      "The classification loss after processing this batch is:  0.14702744781970978\n",
      "The representation loss after processing this batch is:  0.002779565751552582\n",
      "\n",
      "The classification loss after processing this batch is:  0.12403074651956558\n",
      "The representation loss after processing this batch is:  0.0030317753553390503\n",
      "\n",
      "The classification loss after processing this batch is:  0.17662185430526733\n",
      "The representation loss after processing this batch is:  0.0025843381881713867\n",
      "\n",
      "The classification loss after processing this batch is:  0.2458764761686325\n",
      "The representation loss after processing this batch is:  0.0028345659375190735\n",
      "\n",
      "The classification loss after processing this batch is:  0.18093852698802948\n",
      "The representation loss after processing this batch is:  0.002631045877933502\n",
      "\n",
      "The classification loss after processing this batch is:  0.11158450692892075\n",
      "The representation loss after processing this batch is:  0.002636060118675232\n",
      "\n",
      "The classification loss after processing this batch is:  0.08053800463676453\n",
      "The representation loss after processing this batch is:  0.003050684928894043\n",
      "\n",
      "The classification loss after processing this batch is:  0.15668579936027527\n",
      "The representation loss after processing this batch is:  0.0023091286420822144\n",
      "\n",
      "The classification loss after processing this batch is:  0.13548898696899414\n",
      "The representation loss after processing this batch is:  0.002499498426914215\n",
      "\n",
      "The classification loss after processing this batch is:  0.03176476061344147\n",
      "The representation loss after processing this batch is:  0.002522706985473633\n",
      "\n",
      "The classification loss after processing this batch is:  0.12601427733898163\n",
      "The representation loss after processing this batch is:  0.0024509094655513763\n",
      "\n",
      "The classification loss after processing this batch is:  0.2942616641521454\n",
      "The representation loss after processing this batch is:  0.003013499081134796\n",
      "\n",
      "The classification loss after processing this batch is:  0.2834668457508087\n",
      "The representation loss after processing this batch is:  0.0028779804706573486\n",
      "\n",
      "The classification loss after processing this batch is:  0.2304927408695221\n",
      "The representation loss after processing this batch is:  0.00253903865814209\n",
      "\n",
      "The classification loss after processing this batch is:  0.18368181586265564\n",
      "The representation loss after processing this batch is:  0.0025451667606830597\n",
      "\n",
      "The classification loss after processing this batch is:  0.05846508964896202\n",
      "The representation loss after processing this batch is:  0.002481997013092041\n",
      "\n",
      "The classification loss after processing this batch is:  0.15665893256664276\n",
      "The representation loss after processing this batch is:  0.002615198493003845\n",
      "\n",
      "The classification loss after processing this batch is:  0.14376847445964813\n",
      "The representation loss after processing this batch is:  0.0027620717883110046\n",
      "\n",
      "The classification loss after processing this batch is:  0.2134653627872467\n",
      "The representation loss after processing this batch is:  0.0029197558760643005\n",
      "\n",
      "The classification loss after processing this batch is:  0.11763772368431091\n",
      "The representation loss after processing this batch is:  0.002881646156311035\n",
      "\n",
      "The classification loss after processing this batch is:  0.09652533382177353\n",
      "The representation loss after processing this batch is:  0.0031183063983917236\n",
      "\n",
      "The classification loss after processing this batch is:  0.07466505467891693\n",
      "The representation loss after processing this batch is:  0.002761244773864746\n",
      "\n",
      "The classification loss after processing this batch is:  0.12307695299386978\n",
      "The representation loss after processing this batch is:  0.002651788294315338\n",
      "\n",
      "The classification loss after processing this batch is:  0.17415279150009155\n",
      "The representation loss after processing this batch is:  0.002978496253490448\n",
      "\n",
      "The classification loss after processing this batch is:  0.14402803778648376\n",
      "The representation loss after processing this batch is:  0.0025139078497886658\n",
      "\n",
      "The classification loss after processing this batch is:  0.07614065706729889\n",
      "The representation loss after processing this batch is:  0.002372514456510544\n",
      "\n",
      "The classification loss after processing this batch is:  0.2609860599040985\n",
      "The representation loss after processing this batch is:  0.0031632408499717712\n",
      "\n",
      "The classification loss after processing this batch is:  0.33340615034103394\n",
      "The representation loss after processing this batch is:  0.003196798264980316\n",
      "\n",
      "The classification loss after processing this batch is:  0.1934528350830078\n",
      "The representation loss after processing this batch is:  0.0028866827487945557\n",
      "\n",
      "The classification loss after processing this batch is:  0.10550685971975327\n",
      "The representation loss after processing this batch is:  0.003003448247909546\n",
      "\n",
      "The classification loss after processing this batch is:  0.10516227036714554\n",
      "The representation loss after processing this batch is:  0.002715952694416046\n",
      "\n",
      "The classification loss after processing this batch is:  0.08120088279247284\n",
      "The representation loss after processing this batch is:  0.0028153881430625916\n",
      "\n",
      "The classification loss after processing this batch is:  0.24460579454898834\n",
      "The representation loss after processing this batch is:  0.002630472183227539\n",
      "\n",
      "The classification loss after processing this batch is:  0.1476997435092926\n",
      "The representation loss after processing this batch is:  0.0031717419624328613\n",
      "\n",
      "The classification loss after processing this batch is:  0.12319966405630112\n",
      "The representation loss after processing this batch is:  0.003214813768863678\n",
      "\n",
      "The classification loss after processing this batch is:  0.23084385693073273\n",
      "The representation loss after processing this batch is:  0.0025912225246429443\n",
      "\n",
      "The classification loss after processing this batch is:  0.030539115890860558\n",
      "The representation loss after processing this batch is:  0.002576597034931183\n",
      "\n",
      "The classification loss after processing this batch is:  0.04364495724439621\n",
      "The representation loss after processing this batch is:  0.002766817808151245\n",
      "\n",
      "The classification loss after processing this batch is:  0.08905749768018723\n",
      "The representation loss after processing this batch is:  0.0027660876512527466\n",
      "\n",
      "The classification loss after processing this batch is:  0.13736659288406372\n",
      "The representation loss after processing this batch is:  0.0023133568465709686\n",
      "\n",
      "The classification loss after processing this batch is:  0.15415118634700775\n",
      "The representation loss after processing this batch is:  0.002652987837791443\n",
      "\n",
      "The classification loss after processing this batch is:  0.0929209515452385\n",
      "The representation loss after processing this batch is:  0.002698473632335663\n",
      "\n",
      "The classification loss after processing this batch is:  0.11232626438140869\n",
      "The representation loss after processing this batch is:  0.0027343854308128357\n",
      "\n",
      "The classification loss after processing this batch is:  0.042064376175403595\n",
      "The representation loss after processing this batch is:  0.0025395601987838745\n",
      "\n",
      "The classification loss after processing this batch is:  0.09422051161527634\n",
      "The representation loss after processing this batch is:  0.0023926198482513428\n",
      "\n",
      "The classification loss after processing this batch is:  0.07311413437128067\n",
      "The representation loss after processing this batch is:  0.0027062073349952698\n",
      "\n",
      "The classification loss after processing this batch is:  0.06698962301015854\n",
      "The representation loss after processing this batch is:  0.002878740429878235\n",
      "\n",
      "The classification loss after processing this batch is:  0.09182903915643692\n",
      "The representation loss after processing this batch is:  0.002600647509098053\n",
      "\n",
      "The classification loss after processing this batch is:  0.13576370477676392\n",
      "The representation loss after processing this batch is:  0.002517916262149811\n",
      "\n",
      "The classification loss after processing this batch is:  0.18108457326889038\n",
      "The representation loss after processing this batch is:  0.0027858763933181763\n",
      "\n",
      "The classification loss after processing this batch is:  0.04521168768405914\n",
      "The representation loss after processing this batch is:  0.0023841485381126404\n",
      "\n",
      "The classification loss after processing this batch is:  0.05970297008752823\n",
      "The representation loss after processing this batch is:  0.0026412010192871094\n",
      "\n",
      "The classification loss after processing this batch is:  0.074244923889637\n",
      "The representation loss after processing this batch is:  0.0031053125858306885\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1507561057806015\n",
      "The representation loss after processing this batch is:  0.002740323543548584\n",
      "\n",
      "The classification loss after processing this batch is:  0.07196283340454102\n",
      "The representation loss after processing this batch is:  0.003398120403289795\n",
      "\n",
      "The classification loss after processing this batch is:  0.14172646403312683\n",
      "The representation loss after processing this batch is:  0.0030171051621437073\n",
      "\n",
      "The classification loss after processing this batch is:  0.18565545976161957\n",
      "The representation loss after processing this batch is:  0.0026859603822231293\n",
      "\n",
      "The classification loss after processing this batch is:  0.15293151140213013\n",
      "The representation loss after processing this batch is:  0.0028548911213874817\n",
      "\n",
      "The classification loss after processing this batch is:  0.16102474927902222\n",
      "The representation loss after processing this batch is:  0.002756185829639435\n",
      "\n",
      "The classification loss after processing this batch is:  0.07643373310565948\n",
      "The representation loss after processing this batch is:  0.0027140602469444275\n",
      "\n",
      "The classification loss after processing this batch is:  0.12581786513328552\n",
      "The representation loss after processing this batch is:  0.002463005483150482\n",
      "\n",
      "The classification loss after processing this batch is:  0.14277856051921844\n",
      "The representation loss after processing this batch is:  0.002416573464870453\n",
      "\n",
      "The classification loss after processing this batch is:  0.08201734721660614\n",
      "The representation loss after processing this batch is:  0.002672642469406128\n",
      "\n",
      "The classification loss after processing this batch is:  0.02794829197227955\n",
      "The representation loss after processing this batch is:  0.002420276403427124\n",
      "\n",
      "The classification loss after processing this batch is:  0.2214299589395523\n",
      "The representation loss after processing this batch is:  0.0028018802404403687\n",
      "\n",
      "The classification loss after processing this batch is:  0.2742324769496918\n",
      "The representation loss after processing this batch is:  0.002497240900993347\n",
      "\n",
      "The classification loss after processing this batch is:  0.09299147129058838\n",
      "The representation loss after processing this batch is:  0.002620689570903778\n",
      "\n",
      "The classification loss after processing this batch is:  0.22452370822429657\n",
      "The representation loss after processing this batch is:  0.002643004059791565\n",
      "\n",
      "The classification loss after processing this batch is:  0.22455532848834991\n",
      "The representation loss after processing this batch is:  0.0028307586908340454\n",
      "\n",
      "The classification loss after processing this batch is:  0.29937872290611267\n",
      "The representation loss after processing this batch is:  0.0027530789375305176\n",
      "\n",
      "The classification loss after processing this batch is:  0.1434115469455719\n",
      "The representation loss after processing this batch is:  0.0027763769030570984\n",
      "\n",
      "The classification loss after processing this batch is:  0.09857676923274994\n",
      "The representation loss after processing this batch is:  0.0026930347084999084\n",
      "\n",
      "The classification loss after processing this batch is:  0.15540795028209686\n",
      "The representation loss after processing this batch is:  0.003085128962993622\n",
      "\n",
      "The classification loss after processing this batch is:  0.0749807208776474\n",
      "The representation loss after processing this batch is:  0.002803586423397064\n",
      "\n",
      "The classification loss after processing this batch is:  0.042237382382154465\n",
      "The representation loss after processing this batch is:  0.0026789531111717224\n",
      "\n",
      "The classification loss after processing this batch is:  0.06742794066667557\n",
      "The representation loss after processing this batch is:  0.0025115162134170532\n",
      "\n",
      "The classification loss after processing this batch is:  0.058374203741550446\n",
      "The representation loss after processing this batch is:  0.002776533365249634\n",
      "\n",
      "The classification loss after processing this batch is:  0.040732573717832565\n",
      "The representation loss after processing this batch is:  0.002643994987010956\n",
      "\n",
      "The classification loss after processing this batch is:  0.13255399465560913\n",
      "The representation loss after processing this batch is:  0.002621009945869446\n",
      "\n",
      "The classification loss after processing this batch is:  0.13094562292099\n",
      "The representation loss after processing this batch is:  0.0023796185851097107\n",
      "\n",
      "The classification loss after processing this batch is:  0.06018664687871933\n",
      "The representation loss after processing this batch is:  0.0027920082211494446\n",
      "\n",
      "The classification loss after processing this batch is:  0.10647699981927872\n",
      "The representation loss after processing this batch is:  0.002663262188434601\n",
      "\n",
      "The classification loss after processing this batch is:  0.10787096619606018\n",
      "The representation loss after processing this batch is:  0.0028332769870758057\n",
      "\n",
      "The classification loss after processing this batch is:  0.036357101052999496\n",
      "The representation loss after processing this batch is:  0.002763517200946808\n",
      "\n",
      "The classification loss after processing this batch is:  0.1840931624174118\n",
      "The representation loss after processing this batch is:  0.002711266279220581\n",
      "\n",
      "The classification loss after processing this batch is:  0.08543001860380173\n",
      "The representation loss after processing this batch is:  0.0025634542107582092\n",
      "\n",
      "The classification loss after processing this batch is:  0.24910429120063782\n",
      "The representation loss after processing this batch is:  0.00238606333732605\n",
      "\n",
      "The classification loss after processing this batch is:  0.12395703792572021\n",
      "The representation loss after processing this batch is:  0.0029931291937828064\n",
      "\n",
      "The classification loss after processing this batch is:  0.12836261093616486\n",
      "The representation loss after processing this batch is:  0.002365097403526306\n",
      "\n",
      "The classification loss after processing this batch is:  0.04462164267897606\n",
      "The representation loss after processing this batch is:  0.0025508180260658264\n",
      "\n",
      "The classification loss after processing this batch is:  0.04283212125301361\n",
      "The representation loss after processing this batch is:  0.0025173649191856384\n",
      "\n",
      "The classification loss after processing this batch is:  0.1467459499835968\n",
      "The representation loss after processing this batch is:  0.002569444477558136\n",
      "\n",
      "The classification loss after processing this batch is:  0.04199414327740669\n",
      "The representation loss after processing this batch is:  0.0028782710433006287\n",
      "\n",
      "The classification loss after processing this batch is:  0.11196938157081604\n",
      "The representation loss after processing this batch is:  0.002750590443611145\n",
      "\n",
      "The classification loss after processing this batch is:  0.08502128720283508\n",
      "The representation loss after processing this batch is:  0.0026480481028556824\n",
      "\n",
      "The classification loss after processing this batch is:  0.10659711807966232\n",
      "The representation loss after processing this batch is:  0.0028725266456604004\n",
      "\n",
      "The classification loss after processing this batch is:  0.1165381446480751\n",
      "The representation loss after processing this batch is:  0.0026346147060394287\n",
      "\n",
      "The classification loss after processing this batch is:  0.08978763222694397\n",
      "The representation loss after processing this batch is:  0.002725750207901001\n",
      "\n",
      "The classification loss after processing this batch is:  0.13945268094539642\n",
      "The representation loss after processing this batch is:  0.002811342477798462\n",
      "\n",
      "The classification loss after processing this batch is:  0.1470167189836502\n",
      "The representation loss after processing this batch is:  0.0024820715188980103\n",
      "\n",
      "The classification loss after processing this batch is:  0.13931162655353546\n",
      "The representation loss after processing this batch is:  0.0029070600867271423\n",
      "\n",
      "The classification loss after processing this batch is:  0.16732606291770935\n",
      "The representation loss after processing this batch is:  0.0027805641293525696\n",
      "\n",
      "The classification loss after processing this batch is:  0.19885660707950592\n",
      "The representation loss after processing this batch is:  0.002665676176548004\n",
      "\n",
      "The classification loss after processing this batch is:  0.12832289934158325\n",
      "The representation loss after processing this batch is:  0.0025091543793678284\n",
      "\n",
      "The classification loss after processing this batch is:  0.09736571460962296\n",
      "The representation loss after processing this batch is:  0.002629324793815613\n",
      "\n",
      "The classification loss after processing this batch is:  0.06578251719474792\n",
      "The representation loss after processing this batch is:  0.0025624483823776245\n",
      "\n",
      "The classification loss after processing this batch is:  0.07683134078979492\n",
      "The representation loss after processing this batch is:  0.0027944743633270264\n",
      "\n",
      "The classification loss after processing this batch is:  0.0665527880191803\n",
      "The representation loss after processing this batch is:  0.0027576014399528503\n",
      "\n",
      "The classification loss after processing this batch is:  0.0906107947230339\n",
      "The representation loss after processing this batch is:  0.002349305897951126\n",
      "\n",
      "The classification loss after processing this batch is:  0.07159952819347382\n",
      "The representation loss after processing this batch is:  0.0027310848236083984\n",
      "\n",
      "The classification loss after processing this batch is:  0.0965987890958786\n",
      "The representation loss after processing this batch is:  0.0028570741415023804\n",
      "\n",
      "The classification loss after processing this batch is:  0.06541038304567337\n",
      "The representation loss after processing this batch is:  0.0025778934359550476\n",
      "\n",
      "The classification loss after processing this batch is:  0.13220493495464325\n",
      "The representation loss after processing this batch is:  0.002588994801044464\n",
      "\n",
      "The classification loss after processing this batch is:  0.07636920362710953\n",
      "The representation loss after processing this batch is:  0.002820022404193878\n",
      "\n",
      "The classification loss after processing this batch is:  0.14015062153339386\n",
      "The representation loss after processing this batch is:  0.0026808828115463257\n",
      "\n",
      "The classification loss after processing this batch is:  0.1385229527950287\n",
      "The representation loss after processing this batch is:  0.0028182342648506165\n",
      "\n",
      "The classification loss after processing this batch is:  0.10126029700040817\n",
      "The representation loss after processing this batch is:  0.0028124749660491943\n",
      "\n",
      "The classification loss after processing this batch is:  0.08258175104856491\n",
      "The representation loss after processing this batch is:  0.002934783697128296\n",
      "\n",
      "The classification loss after processing this batch is:  0.1796816736459732\n",
      "The representation loss after processing this batch is:  0.002667248249053955\n",
      "\n",
      "The classification loss after processing this batch is:  0.06136263161897659\n",
      "The representation loss after processing this batch is:  0.0028197839856147766\n",
      "\n",
      "The classification loss after processing this batch is:  0.060995712876319885\n",
      "The representation loss after processing this batch is:  0.0025703907012939453\n",
      "\n",
      "The classification loss after processing this batch is:  0.08812280744314194\n",
      "The representation loss after processing this batch is:  0.0025215670466423035\n",
      "\n",
      "The classification loss after processing this batch is:  0.06462603062391281\n",
      "The representation loss after processing this batch is:  0.0025690943002700806\n",
      "\n",
      "The classification loss after processing this batch is:  0.17190201580524445\n",
      "The representation loss after processing this batch is:  0.0022343918681144714\n",
      "\n",
      "The classification loss after processing this batch is:  0.15831272304058075\n",
      "The representation loss after processing this batch is:  0.0025265589356422424\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.12733620405197144\n",
      "The representation loss after processing this batch is:  0.0030526146292686462\n",
      "\n",
      "The classification loss after processing this batch is:  0.08198550343513489\n",
      "The representation loss after processing this batch is:  0.0029657110571861267\n",
      "\n",
      "The classification loss after processing this batch is:  0.11152862757444382\n",
      "The representation loss after processing this batch is:  0.0026401877403259277\n",
      "\n",
      "The classification loss after processing this batch is:  0.22468629479408264\n",
      "The representation loss after processing this batch is:  0.0027177035808563232\n",
      "\n",
      "The classification loss after processing this batch is:  0.04163496568799019\n",
      "The representation loss after processing this batch is:  0.0026985108852386475\n",
      "\n",
      "The classification loss after processing this batch is:  0.08328161388635635\n",
      "The representation loss after processing this batch is:  0.0029375404119491577\n",
      "\n",
      "The classification loss after processing this batch is:  0.1619463711977005\n",
      "The representation loss after processing this batch is:  0.0024104490876197815\n",
      "\n",
      "The classification loss after processing this batch is:  0.32246893644332886\n",
      "The representation loss after processing this batch is:  0.00284373015165329\n",
      "\n",
      "The classification loss after processing this batch is:  0.07276593148708344\n",
      "The representation loss after processing this batch is:  0.0025652945041656494\n",
      "\n",
      "The classification loss after processing this batch is:  0.14383338391780853\n",
      "The representation loss after processing this batch is:  0.0022740140557289124\n",
      "\n",
      "The classification loss after processing this batch is:  0.07380077242851257\n",
      "The representation loss after processing this batch is:  0.0026323050260543823\n",
      "\n",
      "The classification loss after processing this batch is:  0.044575776904821396\n",
      "The representation loss after processing this batch is:  0.0028180554509162903\n",
      "\n",
      "The classification loss after processing this batch is:  0.10372737795114517\n",
      "The representation loss after processing this batch is:  0.0032201409339904785\n",
      "\n",
      "The classification loss after processing this batch is:  0.10759618878364563\n",
      "The representation loss after processing this batch is:  0.0036647170782089233\n",
      "\n",
      "The classification loss after processing this batch is:  0.05634421482682228\n",
      "The representation loss after processing this batch is:  0.003036532551050186\n",
      "\n",
      "The classification loss after processing this batch is:  0.04871777445077896\n",
      "The representation loss after processing this batch is:  0.002422712743282318\n",
      "\n",
      "The classification loss after processing this batch is:  0.1467888504266739\n",
      "The representation loss after processing this batch is:  0.0028282925486564636\n",
      "\n",
      "The classification loss after processing this batch is:  0.10432399809360504\n",
      "The representation loss after processing this batch is:  0.002666749060153961\n",
      "\n",
      "The classification loss after processing this batch is:  0.06894069164991379\n",
      "The representation loss after processing this batch is:  0.0024398863315582275\n",
      "\n",
      "The classification loss after processing this batch is:  0.06416087597608566\n",
      "The representation loss after processing this batch is:  0.0028280019760131836\n",
      "\n",
      "The classification loss after processing this batch is:  0.13731470704078674\n",
      "The representation loss after processing this batch is:  0.002666786313056946\n",
      "\n",
      "The classification loss after processing this batch is:  0.1467631757259369\n",
      "The representation loss after processing this batch is:  0.002692572772502899\n",
      "\n",
      "The classification loss after processing this batch is:  0.2152027189731598\n",
      "The representation loss after processing this batch is:  0.0023804455995559692\n",
      "\n",
      "The classification loss after processing this batch is:  0.10966111719608307\n",
      "The representation loss after processing this batch is:  0.0027068406343460083\n",
      "\n",
      "The classification loss after processing this batch is:  0.2225717157125473\n",
      "The representation loss after processing this batch is:  0.0025170892477035522\n",
      "\n",
      "The classification loss after processing this batch is:  0.0802534893155098\n",
      "The representation loss after processing this batch is:  0.0029140859842300415\n",
      "\n",
      "The classification loss after processing this batch is:  0.08889927715063095\n",
      "The representation loss after processing this batch is:  0.0031590014696121216\n",
      "\n",
      "The classification loss after processing this batch is:  0.06784112006425858\n",
      "The representation loss after processing this batch is:  0.0025879591703414917\n",
      "\n",
      "The classification loss after processing this batch is:  0.062130410224199295\n",
      "The representation loss after processing this batch is:  0.0025521814823150635\n",
      "\n",
      "The classification loss after processing this batch is:  0.16539102792739868\n",
      "The representation loss after processing this batch is:  0.002491109073162079\n",
      "\n",
      "The classification loss after processing this batch is:  0.07882644236087799\n",
      "The representation loss after processing this batch is:  0.0029352903366088867\n",
      "\n",
      "The classification loss after processing this batch is:  0.04560225084424019\n",
      "The representation loss after processing this batch is:  0.00259958952665329\n",
      "\n",
      "The classification loss after processing this batch is:  0.04976174980401993\n",
      "The representation loss after processing this batch is:  0.0032364651560783386\n",
      "\n",
      "The classification loss after processing this batch is:  0.026300707831978798\n",
      "The representation loss after processing this batch is:  0.003048844635486603\n",
      "\n",
      "The classification loss after processing this batch is:  0.047760289162397385\n",
      "The representation loss after processing this batch is:  0.0034753605723381042\n",
      "\n",
      "The classification loss after processing this batch is:  0.07228501886129379\n",
      "The representation loss after processing this batch is:  0.0029278993606567383\n",
      "\n",
      "The classification loss after processing this batch is:  0.05056963488459587\n",
      "The representation loss after processing this batch is:  0.0029611438512802124\n",
      "\n",
      "The classification loss after processing this batch is:  0.01458804588764906\n",
      "The representation loss after processing this batch is:  0.0028206706047058105\n",
      "\n",
      "The classification loss after processing this batch is:  0.04286570101976395\n",
      "The representation loss after processing this batch is:  0.0032130107283592224\n",
      "\n",
      "The classification loss after processing this batch is:  0.07284365594387054\n",
      "The representation loss after processing this batch is:  0.0035780370235443115\n",
      "\n",
      "The classification loss after processing this batch is:  0.013667162507772446\n",
      "The representation loss after processing this batch is:  0.0036703944206237793\n",
      "\n",
      "The classification loss after processing this batch is:  0.025787686929106712\n",
      "The representation loss after processing this batch is:  0.0031328126788139343\n",
      "\n",
      "The classification loss after processing this batch is:  0.1776120662689209\n",
      "The representation loss after processing this batch is:  0.0029792487621307373\n",
      "\n",
      "The classification loss after processing this batch is:  0.035807229578495026\n",
      "The representation loss after processing this batch is:  0.003155156970024109\n",
      "\n",
      "The classification loss after processing this batch is:  0.018443576991558075\n",
      "The representation loss after processing this batch is:  0.0029310882091522217\n",
      "\n",
      "The classification loss after processing this batch is:  0.03801732882857323\n",
      "The representation loss after processing this batch is:  0.003407120704650879\n",
      "\n",
      "The classification loss after processing this batch is:  0.02425076998770237\n",
      "The representation loss after processing this batch is:  0.002935275435447693\n",
      "\n",
      "The classification loss after processing this batch is:  0.020100537687540054\n",
      "The representation loss after processing this batch is:  0.002889014780521393\n",
      "\n",
      "The classification loss after processing this batch is:  0.014303573407232761\n",
      "The representation loss after processing this batch is:  0.0032607465982437134\n",
      "\n",
      "The classification loss after processing this batch is:  0.014885441400110722\n",
      "The representation loss after processing this batch is:  0.0035355761647224426\n",
      "\n",
      "The classification loss after processing this batch is:  0.3573475480079651\n",
      "The representation loss after processing this batch is:  0.0037078410387039185\n",
      "\n",
      "The classification loss after processing this batch is:  0.2838033437728882\n",
      "The representation loss after processing this batch is:  0.003408871591091156\n",
      "\n",
      "The classification loss after processing this batch is:  0.20402908325195312\n",
      "The representation loss after processing this batch is:  0.003904677927494049\n",
      "\n",
      "The classification loss after processing this batch is:  0.04530324786901474\n",
      "The representation loss after processing this batch is:  0.0029181912541389465\n",
      "\n",
      "The classification loss after processing this batch is:  0.012814577668905258\n",
      "The representation loss after processing this batch is:  0.00341980904340744\n",
      "\n",
      "The classification loss after processing this batch is:  0.01392156258225441\n",
      "The representation loss after processing this batch is:  0.002476312220096588\n",
      "\n",
      "The classification loss after processing this batch is:  0.08666925132274628\n",
      "The representation loss after processing this batch is:  0.0025948435068130493\n",
      "\n",
      "The classification loss after processing this batch is:  0.3498023450374603\n",
      "The representation loss after processing this batch is:  0.003011062741279602\n",
      "\n",
      "The classification loss after processing this batch is:  0.05857144668698311\n",
      "The representation loss after processing this batch is:  0.0028564929962158203\n",
      "\n",
      "The classification loss after processing this batch is:  0.03703327849507332\n",
      "The representation loss after processing this batch is:  0.003326632082462311\n",
      "\n",
      "The classification loss after processing this batch is:  0.03953215107321739\n",
      "The representation loss after processing this batch is:  0.003296174108982086\n",
      "\n",
      "The classification loss after processing this batch is:  0.04110543802380562\n",
      "The representation loss after processing this batch is:  0.003956049680709839\n",
      "\n",
      "The classification loss after processing this batch is:  0.10211841762065887\n",
      "The representation loss after processing this batch is:  0.002402670681476593\n",
      "\n",
      "The classification loss after processing this batch is:  0.03863108158111572\n",
      "The representation loss after processing this batch is:  0.0024164095520973206\n",
      "\n",
      "The classification loss after processing this batch is:  0.1125098317861557\n",
      "The representation loss after processing this batch is:  0.0025684386491775513\n",
      "\n",
      "The classification loss after processing this batch is:  0.11541951447725296\n",
      "The representation loss after processing this batch is:  0.002486191689968109\n",
      "\n",
      "The classification loss after processing this batch is:  0.1608753502368927\n",
      "The representation loss after processing this batch is:  0.002719566226005554\n",
      "\n",
      "The classification loss after processing this batch is:  0.04487008973956108\n",
      "The representation loss after processing this batch is:  0.002899765968322754\n",
      "\n",
      "The classification loss after processing this batch is:  0.07847963273525238\n",
      "The representation loss after processing this batch is:  0.003070913255214691\n",
      "\n",
      "The classification loss after processing this batch is:  0.07691506296396255\n",
      "The representation loss after processing this batch is:  0.002489738166332245\n",
      "\n",
      "The classification loss after processing this batch is:  0.10440007597208023\n",
      "The representation loss after processing this batch is:  0.0024418234825134277\n",
      "\n",
      "The classification loss after processing this batch is:  0.08914913982152939\n",
      "The representation loss after processing this batch is:  0.002487786114215851\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14128758013248444\n",
      "The representation loss after processing this batch is:  0.002291761338710785\n",
      "\n",
      "The classification loss after processing this batch is:  0.08403275907039642\n",
      "The representation loss after processing this batch is:  0.002551622688770294\n",
      "\n",
      "The classification loss after processing this batch is:  0.1055244579911232\n",
      "The representation loss after processing this batch is:  0.0029335543513298035\n",
      "\n",
      "The classification loss after processing this batch is:  0.052535805851221085\n",
      "The representation loss after processing this batch is:  0.0026495084166526794\n",
      "\n",
      "The classification loss after processing this batch is:  0.24109159409999847\n",
      "The representation loss after processing this batch is:  0.002712596207857132\n",
      "\n",
      "The classification loss after processing this batch is:  0.13604862987995148\n",
      "The representation loss after processing this batch is:  0.0026824474334716797\n",
      "\n",
      "The classification loss after processing this batch is:  0.14580221474170685\n",
      "The representation loss after processing this batch is:  0.002586551010608673\n",
      "\n",
      "The classification loss after processing this batch is:  0.21863700449466705\n",
      "The representation loss after processing this batch is:  0.0032524578273296356\n",
      "\n",
      "The classification loss after processing this batch is:  0.13947702944278717\n",
      "The representation loss after processing this batch is:  0.002963051199913025\n",
      "\n",
      "The classification loss after processing this batch is:  0.07159343361854553\n",
      "The representation loss after processing this batch is:  0.0027934685349464417\n",
      "\n",
      "The classification loss after processing this batch is:  0.2252630591392517\n",
      "The representation loss after processing this batch is:  0.0035110637545585632\n",
      "\n",
      "The classification loss after processing this batch is:  0.1166347786784172\n",
      "The representation loss after processing this batch is:  0.0029279813170433044\n",
      "\n",
      "The classification loss after processing this batch is:  0.2952035963535309\n",
      "The representation loss after processing this batch is:  0.0027677491307258606\n",
      "\n",
      "The classification loss after processing this batch is:  0.082516148686409\n",
      "The representation loss after processing this batch is:  0.0024351179599761963\n",
      "\n",
      "The classification loss after processing this batch is:  0.052628856152296066\n",
      "The representation loss after processing this batch is:  0.0025165528059005737\n",
      "\n",
      "The classification loss after processing this batch is:  0.08172188699245453\n",
      "The representation loss after processing this batch is:  0.002405501902103424\n",
      "\n",
      "The classification loss after processing this batch is:  0.1072915568947792\n",
      "The representation loss after processing this batch is:  0.00244072824716568\n",
      "\n",
      "The classification loss after processing this batch is:  0.065611332654953\n",
      "The representation loss after processing this batch is:  0.0025331154465675354\n",
      "\n",
      "The classification loss after processing this batch is:  0.05683429166674614\n",
      "The representation loss after processing this batch is:  0.0026269927620887756\n",
      "\n",
      "The classification loss after processing this batch is:  0.04929722473025322\n",
      "The representation loss after processing this batch is:  0.0028169527649879456\n",
      "\n",
      "The classification loss after processing this batch is:  0.040042694658041\n",
      "The representation loss after processing this batch is:  0.0024786703288555145\n",
      "\n",
      "The classification loss after processing this batch is:  0.06336601823568344\n",
      "The representation loss after processing this batch is:  0.0027539506554603577\n",
      "\n",
      "The classification loss after processing this batch is:  0.16471248865127563\n",
      "The representation loss after processing this batch is:  0.002795204520225525\n",
      "\n",
      "The classification loss after processing this batch is:  0.0683889240026474\n",
      "The representation loss after processing this batch is:  0.0030891820788383484\n",
      "\n",
      "The classification loss after processing this batch is:  0.11646461486816406\n",
      "The representation loss after processing this batch is:  0.002230696380138397\n",
      "\n",
      "The classification loss after processing this batch is:  0.04865293949842453\n",
      "The representation loss after processing this batch is:  0.002706870436668396\n",
      "\n",
      "The classification loss after processing this batch is:  0.04445880278944969\n",
      "The representation loss after processing this batch is:  0.002658843994140625\n",
      "\n",
      "The classification loss after processing this batch is:  0.11614084243774414\n",
      "The representation loss after processing this batch is:  0.0027368441224098206\n",
      "\n",
      "The classification loss after processing this batch is:  0.03911970555782318\n",
      "The representation loss after processing this batch is:  0.0028235092759132385\n",
      "\n",
      "The classification loss after processing this batch is:  0.045376360416412354\n",
      "The representation loss after processing this batch is:  0.0026168227195739746\n",
      "\n",
      "The classification loss after processing this batch is:  0.1527508795261383\n",
      "The representation loss after processing this batch is:  0.0029028356075286865\n",
      "\n",
      "The classification loss after processing this batch is:  0.08254655450582504\n",
      "The representation loss after processing this batch is:  0.00266227126121521\n",
      "\n",
      "The classification loss after processing this batch is:  0.09080453962087631\n",
      "The representation loss after processing this batch is:  0.002338167279958725\n",
      "\n",
      "The classification loss after processing this batch is:  0.13181351125240326\n",
      "The representation loss after processing this batch is:  0.002437867224216461\n",
      "\n",
      "The classification loss after processing this batch is:  0.09500005841255188\n",
      "The representation loss after processing this batch is:  0.0025392770767211914\n",
      "\n",
      "The classification loss after processing this batch is:  0.1124006137251854\n",
      "The representation loss after processing this batch is:  0.0023221001029014587\n",
      "\n",
      "The classification loss after processing this batch is:  0.19356600940227509\n",
      "The representation loss after processing this batch is:  0.0025630630552768707\n",
      "\n",
      "The classification loss after processing this batch is:  0.05392610654234886\n",
      "The representation loss after processing this batch is:  0.0026446282863616943\n",
      "\n",
      "The classification loss after processing this batch is:  0.11404545605182648\n",
      "The representation loss after processing this batch is:  0.002731330692768097\n",
      "\n",
      "The classification loss after processing this batch is:  0.06519737094640732\n",
      "The representation loss after processing this batch is:  0.0024054720997810364\n",
      "\n",
      "The classification loss after processing this batch is:  0.10300734639167786\n",
      "The representation loss after processing this batch is:  0.0027301236987113953\n",
      "\n",
      "The classification loss after processing this batch is:  0.09215988218784332\n",
      "The representation loss after processing this batch is:  0.0029608607292175293\n",
      "\n",
      "The classification loss after processing this batch is:  0.04981527850031853\n",
      "The representation loss after processing this batch is:  0.0027009695768356323\n",
      "\n",
      "The classification loss after processing this batch is:  0.10116177052259445\n",
      "The representation loss after processing this batch is:  0.0026605650782585144\n",
      "\n",
      "The classification loss after processing this batch is:  0.09596563875675201\n",
      "The representation loss after processing this batch is:  0.002775520086288452\n",
      "\n",
      "The classification loss after processing this batch is:  0.0974443331360817\n",
      "The representation loss after processing this batch is:  0.0026219040155410767\n",
      "\n",
      "The classification loss after processing this batch is:  0.1442677527666092\n",
      "The representation loss after processing this batch is:  0.00240962952375412\n",
      "\n",
      "The classification loss after processing this batch is:  0.08052144944667816\n",
      "The representation loss after processing this batch is:  0.0030984580516815186\n",
      "\n",
      "The classification loss after processing this batch is:  0.1422736942768097\n",
      "The representation loss after processing this batch is:  0.002597987651824951\n",
      "\n",
      "The classification loss after processing this batch is:  0.07586883008480072\n",
      "The representation loss after processing this batch is:  0.002558484673500061\n",
      "\n",
      "The classification loss after processing this batch is:  0.0456123985350132\n",
      "The representation loss after processing this batch is:  0.0024650990962982178\n",
      "\n",
      "The classification loss after processing this batch is:  0.1316482275724411\n",
      "The representation loss after processing this batch is:  0.0026532337069511414\n",
      "\n",
      "The classification loss after processing this batch is:  0.11358833312988281\n",
      "The representation loss after processing this batch is:  0.0026206448674201965\n",
      "\n",
      "The classification loss after processing this batch is:  0.07240708917379379\n",
      "The representation loss after processing this batch is:  0.0025505051016807556\n",
      "\n",
      "The classification loss after processing this batch is:  0.07393574714660645\n",
      "The representation loss after processing this batch is:  0.0024849995970726013\n",
      "\n",
      "The classification loss after processing this batch is:  0.05193038284778595\n",
      "The representation loss after processing this batch is:  0.002393074333667755\n",
      "\n",
      "The classification loss after processing this batch is:  0.09009434282779694\n",
      "The representation loss after processing this batch is:  0.0026702433824539185\n",
      "\n",
      "The classification loss after processing this batch is:  0.1250346451997757\n",
      "The representation loss after processing this batch is:  0.002276793122291565\n",
      "\n",
      "The classification loss after processing this batch is:  0.054669152945280075\n",
      "The representation loss after processing this batch is:  0.002328746020793915\n",
      "\n",
      "The classification loss after processing this batch is:  0.15282514691352844\n",
      "The representation loss after processing this batch is:  0.0027811527252197266\n",
      "\n",
      "The classification loss after processing this batch is:  0.10289303958415985\n",
      "The representation loss after processing this batch is:  0.0023645125329494476\n",
      "\n",
      "The classification loss after processing this batch is:  0.07179544121026993\n",
      "The representation loss after processing this batch is:  0.002573668956756592\n",
      "\n",
      "The classification loss after processing this batch is:  0.07664120942354202\n",
      "The representation loss after processing this batch is:  0.0022800713777542114\n",
      "\n",
      "The classification loss after processing this batch is:  0.06571701914072037\n",
      "The representation loss after processing this batch is:  0.0028574392199516296\n",
      "\n",
      "The classification loss after processing this batch is:  0.08987186849117279\n",
      "The representation loss after processing this batch is:  0.0021803006529808044\n",
      "\n",
      "The classification loss after processing this batch is:  0.1540980488061905\n",
      "The representation loss after processing this batch is:  0.0026123151183128357\n",
      "\n",
      "The classification loss after processing this batch is:  0.05741678923368454\n",
      "The representation loss after processing this batch is:  0.0024864524602890015\n",
      "\n",
      "The classification loss after processing this batch is:  0.245758518576622\n",
      "The representation loss after processing this batch is:  0.002533547580242157\n",
      "\n",
      "The classification loss after processing this batch is:  0.10814832150936127\n",
      "The representation loss after processing this batch is:  0.0025564394891262054\n",
      "\n",
      "The classification loss after processing this batch is:  0.07761529833078384\n",
      "The representation loss after processing this batch is:  0.003135859966278076\n",
      "\n",
      "The classification loss after processing this batch is:  0.08585985004901886\n",
      "The representation loss after processing this batch is:  0.002603299915790558\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08128724247217178\n",
      "The representation loss after processing this batch is:  0.0028260648250579834\n",
      "\n",
      "The classification loss after processing this batch is:  0.21373039484024048\n",
      "The representation loss after processing this batch is:  0.002913929522037506\n",
      "\n",
      "The classification loss after processing this batch is:  0.10680422186851501\n",
      "The representation loss after processing this batch is:  0.002588331699371338\n",
      "\n",
      "The classification loss after processing this batch is:  0.1243610829114914\n",
      "The representation loss after processing this batch is:  0.002255752682685852\n",
      "\n",
      "The classification loss after processing this batch is:  0.21889559924602509\n",
      "The representation loss after processing this batch is:  0.0025384798645973206\n",
      "\n",
      "The classification loss after processing this batch is:  0.10052672028541565\n",
      "The representation loss after processing this batch is:  0.00247027724981308\n",
      "\n",
      "The classification loss after processing this batch is:  0.042796485126018524\n",
      "The representation loss after processing this batch is:  0.0026462897658348083\n",
      "\n",
      "The classification loss after processing this batch is:  0.12285912036895752\n",
      "The representation loss after processing this batch is:  0.002581823617219925\n",
      "\n",
      "The classification loss after processing this batch is:  0.13042095303535461\n",
      "The representation loss after processing this batch is:  0.002369530498981476\n",
      "\n",
      "The classification loss after processing this batch is:  0.12509456276893616\n",
      "The representation loss after processing this batch is:  0.0026996582746505737\n",
      "\n",
      "The classification loss after processing this batch is:  0.05203866958618164\n",
      "The representation loss after processing this batch is:  0.002284526824951172\n",
      "\n",
      "The classification loss after processing this batch is:  0.1258101761341095\n",
      "The representation loss after processing this batch is:  0.00236714631319046\n",
      "\n",
      "The classification loss after processing this batch is:  0.12788976728916168\n",
      "The representation loss after processing this batch is:  0.00243164598941803\n",
      "\n",
      "The classification loss after processing this batch is:  0.162997305393219\n",
      "The representation loss after processing this batch is:  0.002812609076499939\n",
      "\n",
      "The classification loss after processing this batch is:  0.15098871290683746\n",
      "The representation loss after processing this batch is:  0.0024797990918159485\n",
      "\n",
      "The classification loss after processing this batch is:  0.12317883968353271\n",
      "The representation loss after processing this batch is:  0.0028827637434005737\n",
      "\n",
      "The classification loss after processing this batch is:  0.1143798977136612\n",
      "The representation loss after processing this batch is:  0.003022916615009308\n",
      "\n",
      "The classification loss after processing this batch is:  0.06177319586277008\n",
      "The representation loss after processing this batch is:  0.0029539093375205994\n",
      "\n",
      "The classification loss after processing this batch is:  0.07768425345420837\n",
      "The representation loss after processing this batch is:  0.002610921859741211\n",
      "\n",
      "The classification loss after processing this batch is:  0.04005990922451019\n",
      "The representation loss after processing this batch is:  0.0025881752371788025\n",
      "\n",
      "The classification loss after processing this batch is:  0.1344180554151535\n",
      "The representation loss after processing this batch is:  0.0027559325098991394\n",
      "\n",
      "The classification loss after processing this batch is:  0.06651116162538528\n",
      "The representation loss after processing this batch is:  0.002875208854675293\n",
      "\n",
      "The classification loss after processing this batch is:  0.21074822545051575\n",
      "The representation loss after processing this batch is:  0.0030302628874778748\n",
      "\n",
      "The classification loss after processing this batch is:  0.21674378216266632\n",
      "The representation loss after processing this batch is:  0.002798013389110565\n",
      "\n",
      "The classification loss after processing this batch is:  0.0809338316321373\n",
      "The representation loss after processing this batch is:  0.002864360809326172\n",
      "\n",
      "The classification loss after processing this batch is:  0.0824856236577034\n",
      "The representation loss after processing this batch is:  0.0028382688760757446\n",
      "\n",
      "The classification loss after processing this batch is:  0.10961831361055374\n",
      "The representation loss after processing this batch is:  0.0023346953094005585\n",
      "\n",
      "The classification loss after processing this batch is:  0.0364873930811882\n",
      "The representation loss after processing this batch is:  0.0027356818318367004\n",
      "\n",
      "The classification loss after processing this batch is:  0.052058883011341095\n",
      "The representation loss after processing this batch is:  0.002662166953086853\n",
      "\n",
      "The classification loss after processing this batch is:  0.13208527863025665\n",
      "The representation loss after processing this batch is:  0.0024458616971969604\n",
      "\n",
      "The classification loss after processing this batch is:  0.0660465657711029\n",
      "The representation loss after processing this batch is:  0.0030959323048591614\n",
      "\n",
      "The classification loss after processing this batch is:  0.08624418824911118\n",
      "The representation loss after processing this batch is:  0.0027313008904457092\n",
      "\n",
      "The classification loss after processing this batch is:  0.20148301124572754\n",
      "The representation loss after processing this batch is:  0.00319855660200119\n",
      "\n",
      "The classification loss after processing this batch is:  0.19700361788272858\n",
      "The representation loss after processing this batch is:  0.002536296844482422\n",
      "\n",
      "The classification loss after processing this batch is:  0.0962926372885704\n",
      "The representation loss after processing this batch is:  0.0026812776923179626\n",
      "\n",
      "The classification loss after processing this batch is:  0.19550000131130219\n",
      "The representation loss after processing this batch is:  0.0028875023126602173\n",
      "\n",
      "The classification loss after processing this batch is:  0.12469732016324997\n",
      "The representation loss after processing this batch is:  0.002482399344444275\n",
      "\n",
      "The classification loss after processing this batch is:  0.0601607970893383\n",
      "The representation loss after processing this batch is:  0.0025975704193115234\n",
      "\n",
      "The classification loss after processing this batch is:  0.143525630235672\n",
      "The representation loss after processing this batch is:  0.0024324730038642883\n",
      "\n",
      "The classification loss after processing this batch is:  0.33528146147727966\n",
      "The representation loss after processing this batch is:  0.0029492825269699097\n",
      "\n",
      "The classification loss after processing this batch is:  0.13297604024410248\n",
      "The representation loss after processing this batch is:  0.0030589699745178223\n",
      "\n",
      "The classification loss after processing this batch is:  0.10268200188875198\n",
      "The representation loss after processing this batch is:  0.00288255512714386\n",
      "\n",
      "The classification loss after processing this batch is:  0.05780567228794098\n",
      "The representation loss after processing this batch is:  0.0028902068734169006\n",
      "\n",
      "The classification loss after processing this batch is:  0.06344764679670334\n",
      "The representation loss after processing this batch is:  0.002814352512359619\n",
      "\n",
      "The classification loss after processing this batch is:  0.10836800187826157\n",
      "The representation loss after processing this batch is:  0.00282297283411026\n",
      "\n",
      "The classification loss after processing this batch is:  0.0920608788728714\n",
      "The representation loss after processing this batch is:  0.0028268396854400635\n",
      "\n",
      "The classification loss after processing this batch is:  0.1034839078783989\n",
      "The representation loss after processing this batch is:  0.002568379044532776\n",
      "\n",
      "The classification loss after processing this batch is:  0.10226687043905258\n",
      "The representation loss after processing this batch is:  0.0026771649718284607\n",
      "\n",
      "The classification loss after processing this batch is:  0.1986108124256134\n",
      "The representation loss after processing this batch is:  0.0029156655073165894\n",
      "\n",
      "The classification loss after processing this batch is:  0.06234749034047127\n",
      "The representation loss after processing this batch is:  0.002341143786907196\n",
      "\n",
      "The classification loss after processing this batch is:  0.11110169440507889\n",
      "The representation loss after processing this batch is:  0.0022982731461524963\n",
      "\n",
      "The classification loss after processing this batch is:  0.0890904888510704\n",
      "The representation loss after processing this batch is:  0.0022771283984184265\n",
      "\n",
      "The classification loss after processing this batch is:  0.11133436113595963\n",
      "The representation loss after processing this batch is:  0.0025241822004318237\n",
      "\n",
      "The classification loss after processing this batch is:  0.08417662233114243\n",
      "The representation loss after processing this batch is:  0.002537958323955536\n",
      "\n",
      "The classification loss after processing this batch is:  0.15766943991184235\n",
      "The representation loss after processing this batch is:  0.002631343901157379\n",
      "\n",
      "The classification loss after processing this batch is:  0.13303238153457642\n",
      "The representation loss after processing this batch is:  0.0026000216603279114\n",
      "\n",
      "The classification loss after processing this batch is:  0.13934937119483948\n",
      "The representation loss after processing this batch is:  0.0024983808398246765\n",
      "\n",
      "The classification loss after processing this batch is:  0.06519939005374908\n",
      "The representation loss after processing this batch is:  0.0027129948139190674\n",
      "\n",
      "The classification loss after processing this batch is:  0.1998552829027176\n",
      "The representation loss after processing this batch is:  0.002614140510559082\n",
      "\n",
      "The classification loss after processing this batch is:  0.1488962173461914\n",
      "The representation loss after processing this batch is:  0.002779930830001831\n",
      "\n",
      "The classification loss after processing this batch is:  0.15785010159015656\n",
      "The representation loss after processing this batch is:  0.0027302801609039307\n",
      "\n",
      "The classification loss after processing this batch is:  0.0705086886882782\n",
      "The representation loss after processing this batch is:  0.002904057502746582\n",
      "\n",
      "The classification loss after processing this batch is:  0.08559329062700272\n",
      "The representation loss after processing this batch is:  0.003255397081375122\n",
      "\n",
      "The classification loss after processing this batch is:  0.23067528009414673\n",
      "The representation loss after processing this batch is:  0.002660095691680908\n",
      "\n",
      "The classification loss after processing this batch is:  0.2097688466310501\n",
      "The representation loss after processing this batch is:  0.0024496987462043762\n",
      "\n",
      "The classification loss after processing this batch is:  0.223544180393219\n",
      "The representation loss after processing this batch is:  0.0029329583048820496\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.29447758197784424\n",
      "The representation loss after processing this batch is:  0.002568468451499939\n",
      "\n",
      "The classification loss after processing this batch is:  0.2178432196378708\n",
      "The representation loss after processing this batch is:  0.002335689961910248\n",
      "\n",
      "The classification loss after processing this batch is:  0.05458138883113861\n",
      "The representation loss after processing this batch is:  0.0025583356618881226\n",
      "\n",
      "The classification loss after processing this batch is:  0.06295032799243927\n",
      "The representation loss after processing this batch is:  0.00251585990190506\n",
      "\n",
      "The classification loss after processing this batch is:  0.07943398505449295\n",
      "The representation loss after processing this batch is:  0.0028217285871505737\n",
      "\n",
      "The classification loss after processing this batch is:  0.11222053319215775\n",
      "The representation loss after processing this batch is:  0.0033938437700271606\n",
      "\n",
      "The classification loss after processing this batch is:  0.03600924089550972\n",
      "The representation loss after processing this batch is:  0.002885580062866211\n",
      "\n",
      "The classification loss after processing this batch is:  0.1595548838376999\n",
      "The representation loss after processing this batch is:  0.0034928396344184875\n",
      "\n",
      "The classification loss after processing this batch is:  0.13772889971733093\n",
      "The representation loss after processing this batch is:  0.002502039074897766\n",
      "\n",
      "The classification loss after processing this batch is:  0.12563291192054749\n",
      "The representation loss after processing this batch is:  0.0027062296867370605\n",
      "\n",
      "The classification loss after processing this batch is:  0.18062946200370789\n",
      "The representation loss after processing this batch is:  0.002641245722770691\n",
      "\n",
      "The classification loss after processing this batch is:  0.08973803371191025\n",
      "The representation loss after processing this batch is:  0.0028668344020843506\n",
      "\n",
      "The classification loss after processing this batch is:  0.12920717895030975\n",
      "The representation loss after processing this batch is:  0.003340296447277069\n",
      "\n",
      "The classification loss after processing this batch is:  0.14806826412677765\n",
      "The representation loss after processing this batch is:  0.003012239933013916\n",
      "\n",
      "The classification loss after processing this batch is:  0.10249383002519608\n",
      "The representation loss after processing this batch is:  0.00309685617685318\n",
      "\n",
      "The classification loss after processing this batch is:  0.10655426234006882\n",
      "The representation loss after processing this batch is:  0.0023807063698768616\n",
      "\n",
      "The classification loss after processing this batch is:  0.05356023833155632\n",
      "The representation loss after processing this batch is:  0.002535678446292877\n",
      "\n",
      "The classification loss after processing this batch is:  0.036825623363256454\n",
      "The representation loss after processing this batch is:  0.002653971314430237\n",
      "\n",
      "The classification loss after processing this batch is:  0.07042907923460007\n",
      "The representation loss after processing this batch is:  0.002445824444293976\n",
      "\n",
      "The classification loss after processing this batch is:  0.057385556399822235\n",
      "The representation loss after processing this batch is:  0.0024530217051506042\n",
      "\n",
      "The classification loss after processing this batch is:  0.07546573132276535\n",
      "The representation loss after processing this batch is:  0.0021662935614585876\n",
      "\n",
      "The classification loss after processing this batch is:  0.10272730141878128\n",
      "The representation loss after processing this batch is:  0.0024794116616249084\n",
      "\n",
      "The classification loss after processing this batch is:  0.10447893291711807\n",
      "The representation loss after processing this batch is:  0.00249432772397995\n",
      "\n",
      "The classification loss after processing this batch is:  0.3339053988456726\n",
      "The representation loss after processing this batch is:  0.002835407853126526\n",
      "\n",
      "The classification loss after processing this batch is:  0.20291036367416382\n",
      "The representation loss after processing this batch is:  0.0028640776872634888\n",
      "\n",
      "The classification loss after processing this batch is:  0.08129853755235672\n",
      "The representation loss after processing this batch is:  0.0025086253881454468\n",
      "\n",
      "The classification loss after processing this batch is:  0.06785304844379425\n",
      "The representation loss after processing this batch is:  0.002719663083553314\n",
      "\n",
      "The classification loss after processing this batch is:  0.0559818297624588\n",
      "The representation loss after processing this batch is:  0.0027500614523887634\n",
      "\n",
      "The classification loss after processing this batch is:  0.06243380531668663\n",
      "The representation loss after processing this batch is:  0.00264093279838562\n",
      "\n",
      "The classification loss after processing this batch is:  0.024563448503613472\n",
      "The representation loss after processing this batch is:  0.0028219521045684814\n",
      "\n",
      "The classification loss after processing this batch is:  0.07662621140480042\n",
      "The representation loss after processing this batch is:  0.0026859641075134277\n",
      "\n",
      "The classification loss after processing this batch is:  0.0866868644952774\n",
      "The representation loss after processing this batch is:  0.0023729726672172546\n",
      "\n",
      "The classification loss after processing this batch is:  0.201520174741745\n",
      "The representation loss after processing this batch is:  0.002714700996875763\n",
      "\n",
      "The classification loss after processing this batch is:  0.10208065062761307\n",
      "The representation loss after processing this batch is:  0.002406701445579529\n",
      "\n",
      "The classification loss after processing this batch is:  0.054117798805236816\n",
      "The representation loss after processing this batch is:  0.0025911927223205566\n",
      "\n",
      "The classification loss after processing this batch is:  0.04109525680541992\n",
      "The representation loss after processing this batch is:  0.0026034563779830933\n",
      "\n",
      "The classification loss after processing this batch is:  0.2280898094177246\n",
      "The representation loss after processing this batch is:  0.0025944598019123077\n",
      "\n",
      "The classification loss after processing this batch is:  0.07255151122808456\n",
      "The representation loss after processing this batch is:  0.002751879394054413\n",
      "\n",
      "The classification loss after processing this batch is:  0.06925894320011139\n",
      "The representation loss after processing this batch is:  0.002520337700843811\n",
      "\n",
      "The classification loss after processing this batch is:  0.08619969338178635\n",
      "The representation loss after processing this batch is:  0.00279148668050766\n",
      "\n",
      "The classification loss after processing this batch is:  0.09081515669822693\n",
      "The representation loss after processing this batch is:  0.0022151321172714233\n",
      "\n",
      "The classification loss after processing this batch is:  0.04127360135316849\n",
      "The representation loss after processing this batch is:  0.002446301281452179\n",
      "\n",
      "The classification loss after processing this batch is:  0.09610103070735931\n",
      "The representation loss after processing this batch is:  0.002446696162223816\n",
      "\n",
      "The classification loss after processing this batch is:  0.06420903652906418\n",
      "The representation loss after processing this batch is:  0.002531610429286957\n",
      "\n",
      "The classification loss after processing this batch is:  0.07241801917552948\n",
      "The representation loss after processing this batch is:  0.002539888024330139\n",
      "\n",
      "The classification loss after processing this batch is:  0.1434272676706314\n",
      "The representation loss after processing this batch is:  0.00241958349943161\n",
      "\n",
      "The classification loss after processing this batch is:  0.15089252591133118\n",
      "The representation loss after processing this batch is:  0.0026717409491539\n",
      "\n",
      "The classification loss after processing this batch is:  0.1467265784740448\n",
      "The representation loss after processing this batch is:  0.0024572983384132385\n",
      "\n",
      "The classification loss after processing this batch is:  0.14590904116630554\n",
      "The representation loss after processing this batch is:  0.002476908266544342\n",
      "\n",
      "The classification loss after processing this batch is:  0.07065322250127792\n",
      "The representation loss after processing this batch is:  0.002541191875934601\n",
      "\n",
      "The classification loss after processing this batch is:  0.13714195787906647\n",
      "The representation loss after processing this batch is:  0.0026763901114463806\n",
      "\n",
      "The classification loss after processing this batch is:  0.07234729826450348\n",
      "The representation loss after processing this batch is:  0.0030809417366981506\n",
      "\n",
      "The classification loss after processing this batch is:  0.11519238352775574\n",
      "The representation loss after processing this batch is:  0.0026235580444335938\n",
      "\n",
      "The classification loss after processing this batch is:  0.05455958470702171\n",
      "The representation loss after processing this batch is:  0.002380587160587311\n",
      "\n",
      "The classification loss after processing this batch is:  0.14721587300300598\n",
      "The representation loss after processing this batch is:  0.002427339553833008\n",
      "\n",
      "The classification loss after processing this batch is:  0.06738560646772385\n",
      "The representation loss after processing this batch is:  0.002733945846557617\n",
      "\n",
      "The classification loss after processing this batch is:  0.08819151669740677\n",
      "The representation loss after processing this batch is:  0.0023083165287971497\n",
      "\n",
      "The classification loss after processing this batch is:  0.09976741671562195\n",
      "The representation loss after processing this batch is:  0.0024281516671180725\n",
      "\n",
      "The classification loss after processing this batch is:  0.08802025765180588\n",
      "The representation loss after processing this batch is:  0.002463020384311676\n",
      "\n",
      "The classification loss after processing this batch is:  0.12988567352294922\n",
      "The representation loss after processing this batch is:  0.002424076199531555\n",
      "\n",
      "The classification loss after processing this batch is:  0.09359092265367508\n",
      "The representation loss after processing this batch is:  0.0022293701767921448\n",
      "\n",
      "The classification loss after processing this batch is:  0.1668030470609665\n",
      "The representation loss after processing this batch is:  0.0024467110633850098\n",
      "\n",
      "The classification loss after processing this batch is:  0.1589297503232956\n",
      "The representation loss after processing this batch is:  0.0025415122509002686\n",
      "\n",
      "The classification loss after processing this batch is:  0.2425142377614975\n",
      "The representation loss after processing this batch is:  0.0024598538875579834\n",
      "\n",
      "The classification loss after processing this batch is:  0.1667492836713791\n",
      "The representation loss after processing this batch is:  0.002280745655298233\n",
      "\n",
      "The classification loss after processing this batch is:  0.06994367390871048\n",
      "The representation loss after processing this batch is:  0.0026280879974365234\n",
      "\n",
      "The classification loss after processing this batch is:  0.15490251779556274\n",
      "The representation loss after processing this batch is:  0.002676934003829956\n",
      "\n",
      "The classification loss after processing this batch is:  0.08976886421442032\n",
      "The representation loss after processing this batch is:  0.002709902822971344\n",
      "\n",
      "The classification loss after processing this batch is:  0.07602618634700775\n",
      "The representation loss after processing this batch is:  0.002894800156354904\n",
      "\n",
      "The classification loss after processing this batch is:  0.1735650897026062\n",
      "The representation loss after processing this batch is:  0.003106221556663513\n",
      "\n",
      "The classification loss after processing this batch is:  0.16344305872917175\n",
      "The representation loss after processing this batch is:  0.0028529316186904907\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.27584514021873474\n",
      "The representation loss after processing this batch is:  0.002650037407875061\n",
      "\n",
      "The classification loss after processing this batch is:  0.1257491409778595\n",
      "The representation loss after processing this batch is:  0.0027930736541748047\n",
      "\n",
      "The classification loss after processing this batch is:  0.06066256761550903\n",
      "The representation loss after processing this batch is:  0.0027150958776474\n",
      "\n",
      "The classification loss after processing this batch is:  0.0766424611210823\n",
      "The representation loss after processing this batch is:  0.0026855021715164185\n",
      "\n",
      "The classification loss after processing this batch is:  0.1715063750743866\n",
      "The representation loss after processing this batch is:  0.0022832341492176056\n",
      "\n",
      "The classification loss after processing this batch is:  0.09025048464536667\n",
      "The representation loss after processing this batch is:  0.0026520565152168274\n",
      "\n",
      "The classification loss after processing this batch is:  0.09205319732427597\n",
      "The representation loss after processing this batch is:  0.002306416630744934\n",
      "\n",
      "The classification loss after processing this batch is:  0.07739557325839996\n",
      "The representation loss after processing this batch is:  0.0027307868003845215\n",
      "\n",
      "The classification loss after processing this batch is:  0.029751647263765335\n",
      "The representation loss after processing this batch is:  0.002533629536628723\n",
      "\n",
      "The classification loss after processing this batch is:  0.11625229567289352\n",
      "The representation loss after processing this batch is:  0.0028378181159496307\n",
      "\n",
      "The classification loss after processing this batch is:  0.12016800045967102\n",
      "The representation loss after processing this batch is:  0.0030438266694545746\n",
      "\n",
      "The classification loss after processing this batch is:  0.1580839455127716\n",
      "The representation loss after processing this batch is:  0.0025061815977096558\n",
      "\n",
      "The classification loss after processing this batch is:  0.14495064318180084\n",
      "The representation loss after processing this batch is:  0.0022172555327415466\n",
      "\n",
      "The classification loss after processing this batch is:  0.11303817480802536\n",
      "The representation loss after processing this batch is:  0.0026119276881217957\n",
      "\n",
      "The classification loss after processing this batch is:  0.1271549016237259\n",
      "The representation loss after processing this batch is:  0.0026771798729896545\n",
      "\n",
      "The classification loss after processing this batch is:  0.11518499255180359\n",
      "The representation loss after processing this batch is:  0.0025103017687797546\n",
      "\n",
      "The classification loss after processing this batch is:  0.11146803200244904\n",
      "The representation loss after processing this batch is:  0.0029412508010864258\n",
      "\n",
      "The classification loss after processing this batch is:  0.13370920717716217\n",
      "The representation loss after processing this batch is:  0.0027671754360198975\n",
      "\n",
      "The classification loss after processing this batch is:  0.1293458193540573\n",
      "The representation loss after processing this batch is:  0.0030287951231002808\n",
      "\n",
      "The classification loss after processing this batch is:  0.1190284714102745\n",
      "The representation loss after processing this batch is:  0.002417050302028656\n",
      "\n",
      "The classification loss after processing this batch is:  0.19716672599315643\n",
      "The representation loss after processing this batch is:  0.0024998821318149567\n",
      "\n",
      "The classification loss after processing this batch is:  0.16611672937870026\n",
      "The representation loss after processing this batch is:  0.0027526840567588806\n",
      "\n",
      "The classification loss after processing this batch is:  0.06251917034387589\n",
      "The representation loss after processing this batch is:  0.002336353063583374\n",
      "\n",
      "The classification loss after processing this batch is:  0.1088339164853096\n",
      "The representation loss after processing this batch is:  0.0029748454689979553\n",
      "\n",
      "The classification loss after processing this batch is:  0.11739856749773026\n",
      "The representation loss after processing this batch is:  0.00255710631608963\n",
      "\n",
      "The classification loss after processing this batch is:  0.10802602767944336\n",
      "The representation loss after processing this batch is:  0.0026320740580558777\n",
      "\n",
      "The classification loss after processing this batch is:  0.15022335946559906\n",
      "The representation loss after processing this batch is:  0.002986401319503784\n",
      "\n",
      "The classification loss after processing this batch is:  0.24099601805210114\n",
      "The representation loss after processing this batch is:  0.002914413809776306\n",
      "\n",
      "The classification loss after processing this batch is:  0.2336377203464508\n",
      "The representation loss after processing this batch is:  0.0031956881284713745\n",
      "\n",
      "The classification loss after processing this batch is:  0.12422985583543777\n",
      "The representation loss after processing this batch is:  0.0027632415294647217\n",
      "\n",
      "The classification loss after processing this batch is:  0.11534548550844193\n",
      "The representation loss after processing this batch is:  0.0025984644889831543\n",
      "\n",
      "The classification loss after processing this batch is:  0.07499199360609055\n",
      "The representation loss after processing this batch is:  0.002997882664203644\n",
      "\n",
      "The classification loss after processing this batch is:  0.052138667553663254\n",
      "The representation loss after processing this batch is:  0.002694748342037201\n",
      "\n",
      "The classification loss after processing this batch is:  0.16044291853904724\n",
      "The representation loss after processing this batch is:  0.002784721553325653\n",
      "\n",
      "The classification loss after processing this batch is:  0.11387193948030472\n",
      "The representation loss after processing this batch is:  0.0025086551904678345\n",
      "\n",
      "The classification loss after processing this batch is:  0.0796792283654213\n",
      "The representation loss after processing this batch is:  0.0024160780012607574\n",
      "\n",
      "The classification loss after processing this batch is:  0.1102420911192894\n",
      "The representation loss after processing this batch is:  0.002735137939453125\n",
      "\n",
      "The classification loss after processing this batch is:  0.10564837604761124\n",
      "The representation loss after processing this batch is:  0.0029662996530532837\n",
      "\n",
      "The classification loss after processing this batch is:  0.17831555008888245\n",
      "The representation loss after processing this batch is:  0.0024981871247291565\n",
      "\n",
      "The classification loss after processing this batch is:  0.11425162851810455\n",
      "The representation loss after processing this batch is:  0.0026234090328216553\n",
      "\n",
      "The classification loss after processing this batch is:  0.07841084897518158\n",
      "The representation loss after processing this batch is:  0.002504698932170868\n",
      "\n",
      "The classification loss after processing this batch is:  0.04079628735780716\n",
      "The representation loss after processing this batch is:  0.0025737807154655457\n",
      "\n",
      "The classification loss after processing this batch is:  0.1052384078502655\n",
      "The representation loss after processing this batch is:  0.0023929812014102936\n",
      "\n",
      "The classification loss after processing this batch is:  0.09144452214241028\n",
      "The representation loss after processing this batch is:  0.0023345835506916046\n",
      "\n",
      "The classification loss after processing this batch is:  0.4012545347213745\n",
      "The representation loss after processing this batch is:  0.0027944818139076233\n",
      "\n",
      "The classification loss after processing this batch is:  0.08762278407812119\n",
      "The representation loss after processing this batch is:  0.002470768988132477\n",
      "\n",
      "The classification loss after processing this batch is:  0.19517360627651215\n",
      "The representation loss after processing this batch is:  0.0024497881531715393\n",
      "\n",
      "The classification loss after processing this batch is:  0.2565716505050659\n",
      "The representation loss after processing this batch is:  0.0026523061096668243\n",
      "\n",
      "The classification loss after processing this batch is:  0.07111676037311554\n",
      "The representation loss after processing this batch is:  0.0026654452085494995\n",
      "\n",
      "The classification loss after processing this batch is:  0.2071489691734314\n",
      "The representation loss after processing this batch is:  0.003133624792098999\n",
      "\n",
      "The classification loss after processing this batch is:  0.11788071691989899\n",
      "The representation loss after processing this batch is:  0.0027052387595176697\n",
      "\n",
      "The classification loss after processing this batch is:  0.18881693482398987\n",
      "The representation loss after processing this batch is:  0.0025329627096652985\n",
      "\n",
      "The classification loss after processing this batch is:  0.04514984413981438\n",
      "The representation loss after processing this batch is:  0.0023268908262252808\n",
      "\n",
      "The classification loss after processing this batch is:  0.06896597892045975\n",
      "The representation loss after processing this batch is:  0.00269366055727005\n",
      "\n",
      "The classification loss after processing this batch is:  0.05054766684770584\n",
      "The representation loss after processing this batch is:  0.002842813730239868\n",
      "\n",
      "The classification loss after processing this batch is:  0.03577905520796776\n",
      "The representation loss after processing this batch is:  0.0025263726711273193\n",
      "\n",
      "The classification loss after processing this batch is:  0.08632418513298035\n",
      "The representation loss after processing this batch is:  0.0026887506246566772\n",
      "\n",
      "The classification loss after processing this batch is:  0.058540549129247665\n",
      "The representation loss after processing this batch is:  0.0023867040872573853\n",
      "\n",
      "The classification loss after processing this batch is:  0.13033534586429596\n",
      "The representation loss after processing this batch is:  0.002913430333137512\n",
      "\n",
      "The classification loss after processing this batch is:  0.05925494804978371\n",
      "The representation loss after processing this batch is:  0.002923719584941864\n",
      "\n",
      "The classification loss after processing this batch is:  0.07405965030193329\n",
      "The representation loss after processing this batch is:  0.0023407191038131714\n",
      "\n",
      "The classification loss after processing this batch is:  0.09474054723978043\n",
      "The representation loss after processing this batch is:  0.0024409033358097076\n",
      "\n",
      "The classification loss after processing this batch is:  0.03966156765818596\n",
      "The representation loss after processing this batch is:  0.0023438632488250732\n",
      "\n",
      "The classification loss after processing this batch is:  0.12345001101493835\n",
      "The representation loss after processing this batch is:  0.002636738121509552\n",
      "\n",
      "The classification loss after processing this batch is:  0.11497186869382858\n",
      "The representation loss after processing this batch is:  0.0027362704277038574\n",
      "\n",
      "The classification loss after processing this batch is:  0.20751838386058807\n",
      "The representation loss after processing this batch is:  0.0030311793088912964\n",
      "\n",
      "The classification loss after processing this batch is:  0.0873182937502861\n",
      "The representation loss after processing this batch is:  0.002411719411611557\n",
      "\n",
      "The classification loss after processing this batch is:  0.06971453130245209\n",
      "The representation loss after processing this batch is:  0.0022388771176338196\n",
      "\n",
      "The classification loss after processing this batch is:  0.19109296798706055\n",
      "The representation loss after processing this batch is:  0.002798892557621002\n",
      "\n",
      "The classification loss after processing this batch is:  0.1407594531774521\n",
      "The representation loss after processing this batch is:  0.0025809109210968018\n",
      "\n",
      "The classification loss after processing this batch is:  0.12615588307380676\n",
      "The representation loss after processing this batch is:  0.0027598440647125244\n",
      "\n",
      "The classification loss after processing this batch is:  0.042795922607183456\n",
      "The representation loss after processing this batch is:  0.002545386552810669\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.09501292556524277\n",
      "The representation loss after processing this batch is:  0.0025720372796058655\n",
      "\n",
      "The classification loss after processing this batch is:  0.0993780791759491\n",
      "The representation loss after processing this batch is:  0.0026519671082496643\n",
      "\n",
      "The classification loss after processing this batch is:  0.12001089006662369\n",
      "The representation loss after processing this batch is:  0.0031508803367614746\n",
      "\n",
      "The classification loss after processing this batch is:  0.1115707978606224\n",
      "The representation loss after processing this batch is:  0.002984382212162018\n",
      "\n",
      "The classification loss after processing this batch is:  0.07738122344017029\n",
      "The representation loss after processing this batch is:  0.0031937062740325928\n",
      "\n",
      "The classification loss after processing this batch is:  0.13627077639102936\n",
      "The representation loss after processing this batch is:  0.0030769482254981995\n",
      "\n",
      "The classification loss after processing this batch is:  0.21410922706127167\n",
      "The representation loss after processing this batch is:  0.002496689558029175\n",
      "\n",
      "The classification loss after processing this batch is:  0.10651933401823044\n",
      "The representation loss after processing this batch is:  0.0031547769904136658\n",
      "\n",
      "The classification loss after processing this batch is:  0.12703414261341095\n",
      "The representation loss after processing this batch is:  0.0024918243288993835\n",
      "\n",
      "The classification loss after processing this batch is:  0.05667632073163986\n",
      "The representation loss after processing this batch is:  0.002464599907398224\n",
      "\n",
      "The classification loss after processing this batch is:  0.1872178018093109\n",
      "The representation loss after processing this batch is:  0.002454333007335663\n",
      "\n",
      "The classification loss after processing this batch is:  0.05445798859000206\n",
      "The representation loss after processing this batch is:  0.0025383010506629944\n",
      "\n",
      "The classification loss after processing this batch is:  0.11929968744516373\n",
      "The representation loss after processing this batch is:  0.0027170106768608093\n",
      "\n",
      "The classification loss after processing this batch is:  0.08094442635774612\n",
      "The representation loss after processing this batch is:  0.0027596652507781982\n",
      "\n",
      "The classification loss after processing this batch is:  0.1008821576833725\n",
      "The representation loss after processing this batch is:  0.002640359103679657\n",
      "\n",
      "The classification loss after processing this batch is:  0.12663999199867249\n",
      "The representation loss after processing this batch is:  0.002690449357032776\n",
      "\n",
      "The classification loss after processing this batch is:  0.14295831322669983\n",
      "The representation loss after processing this batch is:  0.0029763057827949524\n",
      "\n",
      "The classification loss after processing this batch is:  0.1125936284661293\n",
      "The representation loss after processing this batch is:  0.002722613513469696\n",
      "\n",
      "The classification loss after processing this batch is:  0.12516070902347565\n",
      "The representation loss after processing this batch is:  0.0024058781564235687\n",
      "\n",
      "The classification loss after processing this batch is:  0.15767616033554077\n",
      "The representation loss after processing this batch is:  0.0029441043734550476\n",
      "\n",
      "The classification loss after processing this batch is:  0.11174715310335159\n",
      "The representation loss after processing this batch is:  0.0025563091039657593\n",
      "\n",
      "The classification loss after processing this batch is:  0.10377330332994461\n",
      "The representation loss after processing this batch is:  0.002595283091068268\n",
      "\n",
      "The classification loss after processing this batch is:  0.04943795129656792\n",
      "The representation loss after processing this batch is:  0.002974189817905426\n",
      "\n",
      "The classification loss after processing this batch is:  0.06983684748411179\n",
      "The representation loss after processing this batch is:  0.002738591283559799\n",
      "\n",
      "The classification loss after processing this batch is:  0.045053303241729736\n",
      "The representation loss after processing this batch is:  0.002535458654165268\n",
      "\n",
      "The classification loss after processing this batch is:  0.04909331724047661\n",
      "The representation loss after processing this batch is:  0.002477288246154785\n",
      "\n",
      "The classification loss after processing this batch is:  0.056299012154340744\n",
      "The representation loss after processing this batch is:  0.0026967674493789673\n",
      "\n",
      "The classification loss after processing this batch is:  0.03794928640127182\n",
      "The representation loss after processing this batch is:  0.0028997063636779785\n",
      "\n",
      "The classification loss after processing this batch is:  0.11506155133247375\n",
      "The representation loss after processing this batch is:  0.002504289150238037\n",
      "\n",
      "The classification loss after processing this batch is:  0.07855835556983948\n",
      "The representation loss after processing this batch is:  0.0023116692900657654\n",
      "\n",
      "The classification loss after processing this batch is:  0.11400101333856583\n",
      "The representation loss after processing this batch is:  0.00253257155418396\n",
      "\n",
      "The classification loss after processing this batch is:  0.05514250695705414\n",
      "The representation loss after processing this batch is:  0.002700895071029663\n",
      "\n",
      "The classification loss after processing this batch is:  0.15963178873062134\n",
      "The representation loss after processing this batch is:  0.002532579004764557\n",
      "\n",
      "The classification loss after processing this batch is:  0.14756466448307037\n",
      "The representation loss after processing this batch is:  0.0025825798511505127\n",
      "\n",
      "The classification loss after processing this batch is:  0.1007428839802742\n",
      "The representation loss after processing this batch is:  0.0025097057223320007\n",
      "\n",
      "The classification loss after processing this batch is:  0.11494985967874527\n",
      "The representation loss after processing this batch is:  0.002813383936882019\n",
      "\n",
      "The classification loss after processing this batch is:  0.09935785830020905\n",
      "The representation loss after processing this batch is:  0.0028831064701080322\n",
      "\n",
      "The classification loss after processing this batch is:  0.03460448607802391\n",
      "The representation loss after processing this batch is:  0.002467326819896698\n",
      "\n",
      "The classification loss after processing this batch is:  0.06670637428760529\n",
      "The representation loss after processing this batch is:  0.002566106617450714\n",
      "\n",
      "The classification loss after processing this batch is:  0.07108358293771744\n",
      "The representation loss after processing this batch is:  0.0023118332028388977\n",
      "\n",
      "The classification loss after processing this batch is:  0.20745442807674408\n",
      "The representation loss after processing this batch is:  0.0027423202991485596\n",
      "\n",
      "The classification loss after processing this batch is:  0.14956261217594147\n",
      "The representation loss after processing this batch is:  0.0024362951517105103\n",
      "\n",
      "The classification loss after processing this batch is:  0.14590096473693848\n",
      "The representation loss after processing this batch is:  0.003292299807071686\n",
      "\n",
      "The classification loss after processing this batch is:  0.1620030403137207\n",
      "The representation loss after processing this batch is:  0.002568945288658142\n",
      "\n",
      "The classification loss after processing this batch is:  0.16525514423847198\n",
      "The representation loss after processing this batch is:  0.002817906439304352\n",
      "\n",
      "The classification loss after processing this batch is:  0.18334166705608368\n",
      "The representation loss after processing this batch is:  0.0023318901658058167\n",
      "\n",
      "The classification loss after processing this batch is:  0.2448699176311493\n",
      "The representation loss after processing this batch is:  0.002546437084674835\n",
      "\n",
      "The classification loss after processing this batch is:  0.1615578830242157\n",
      "The representation loss after processing this batch is:  0.0024657659232616425\n",
      "\n",
      "The classification loss after processing this batch is:  0.09173426777124405\n",
      "The representation loss after processing this batch is:  0.0022340193390846252\n",
      "\n",
      "The classification loss after processing this batch is:  0.08075102418661118\n",
      "The representation loss after processing this batch is:  0.0026228800415992737\n",
      "\n",
      "The classification loss after processing this batch is:  0.05011327937245369\n",
      "The representation loss after processing this batch is:  0.002356991171836853\n",
      "\n",
      "The classification loss after processing this batch is:  0.05729777365922928\n",
      "The representation loss after processing this batch is:  0.0025671347975730896\n",
      "\n",
      "The classification loss after processing this batch is:  0.06195501238107681\n",
      "The representation loss after processing this batch is:  0.003087155520915985\n",
      "\n",
      "The classification loss after processing this batch is:  0.1162521094083786\n",
      "The representation loss after processing this batch is:  0.0023729950189590454\n",
      "\n",
      "The classification loss after processing this batch is:  0.06759048998355865\n",
      "The representation loss after processing this batch is:  0.0026779621839523315\n",
      "\n",
      "The classification loss after processing this batch is:  0.1577448844909668\n",
      "The representation loss after processing this batch is:  0.0024515055119991302\n",
      "\n",
      "The classification loss after processing this batch is:  0.13154719769954681\n",
      "The representation loss after processing this batch is:  0.002812117338180542\n",
      "\n",
      "The classification loss after processing this batch is:  0.16252025961875916\n",
      "The representation loss after processing this batch is:  0.002484269440174103\n",
      "\n",
      "The classification loss after processing this batch is:  0.11031404137611389\n",
      "The representation loss after processing this batch is:  0.0024243444204330444\n",
      "\n",
      "The classification loss after processing this batch is:  0.1599886566400528\n",
      "The representation loss after processing this batch is:  0.002451743930578232\n",
      "\n",
      "The classification loss after processing this batch is:  0.12137860804796219\n",
      "The representation loss after processing this batch is:  0.002436019480228424\n",
      "\n",
      "The classification loss after processing this batch is:  0.07736492156982422\n",
      "The representation loss after processing this batch is:  0.002552323043346405\n",
      "\n",
      "The classification loss after processing this batch is:  0.1751069873571396\n",
      "The representation loss after processing this batch is:  0.002466455101966858\n",
      "\n",
      "The classification loss after processing this batch is:  0.04326995834708214\n",
      "The representation loss after processing this batch is:  0.0023636594414711\n",
      "\n",
      "The classification loss after processing this batch is:  0.04184512048959732\n",
      "The representation loss after processing this batch is:  0.0022704750299453735\n",
      "\n",
      "The classification loss after processing this batch is:  0.09827160835266113\n",
      "The representation loss after processing this batch is:  0.002900227904319763\n",
      "\n",
      "The classification loss after processing this batch is:  0.1431186944246292\n",
      "The representation loss after processing this batch is:  0.002656497061252594\n",
      "\n",
      "The classification loss after processing this batch is:  0.10990002006292343\n",
      "The representation loss after processing this batch is:  0.002882547676563263\n",
      "\n",
      "The classification loss after processing this batch is:  0.0628269836306572\n",
      "The representation loss after processing this batch is:  0.0029387101531028748\n",
      "\n",
      "The classification loss after processing this batch is:  0.10787007957696915\n",
      "The representation loss after processing this batch is:  0.0029895231127738953\n",
      "\n",
      "The classification loss after processing this batch is:  0.08978906273841858\n",
      "The representation loss after processing this batch is:  0.0026835426688194275\n",
      "\n",
      "The classification loss after processing this batch is:  0.18340322375297546\n",
      "The representation loss after processing this batch is:  0.00252629816532135\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.04540523514151573\n",
      "The representation loss after processing this batch is:  0.002417348325252533\n",
      "\n",
      "The classification loss after processing this batch is:  0.04864276945590973\n",
      "The representation loss after processing this batch is:  0.002780415117740631\n",
      "\n",
      "The classification loss after processing this batch is:  0.12884080410003662\n",
      "The representation loss after processing this batch is:  0.003346644341945648\n",
      "\n",
      "The classification loss after processing this batch is:  0.11151052266359329\n",
      "The representation loss after processing this batch is:  0.002821706235408783\n",
      "\n",
      "The classification loss after processing this batch is:  0.08645562082529068\n",
      "The representation loss after processing this batch is:  0.0030220821499824524\n",
      "\n",
      "The classification loss after processing this batch is:  0.06728940457105637\n",
      "The representation loss after processing this batch is:  0.002605125308036804\n",
      "\n",
      "The classification loss after processing this batch is:  0.1407885104417801\n",
      "The representation loss after processing this batch is:  0.0029456913471221924\n",
      "\n",
      "The classification loss after processing this batch is:  0.1599169373512268\n",
      "The representation loss after processing this batch is:  0.002948194742202759\n",
      "\n",
      "The classification loss after processing this batch is:  0.18647535145282745\n",
      "The representation loss after processing this batch is:  0.002544313669204712\n",
      "\n",
      "The classification loss after processing this batch is:  0.12589769065380096\n",
      "The representation loss after processing this batch is:  0.0030281394720077515\n",
      "\n",
      "The classification loss after processing this batch is:  0.04030853882431984\n",
      "The representation loss after processing this batch is:  0.0025327131152153015\n",
      "\n",
      "The classification loss after processing this batch is:  0.05703108385205269\n",
      "The representation loss after processing this batch is:  0.0023433007299900055\n",
      "\n",
      "The classification loss after processing this batch is:  0.15637879073619843\n",
      "The representation loss after processing this batch is:  0.0029569044709205627\n",
      "\n",
      "The classification loss after processing this batch is:  0.2017776370048523\n",
      "The representation loss after processing this batch is:  0.003100752830505371\n",
      "\n",
      "The classification loss after processing this batch is:  0.2197166085243225\n",
      "The representation loss after processing this batch is:  0.0030946433544158936\n",
      "\n",
      "The classification loss after processing this batch is:  0.22119280695915222\n",
      "The representation loss after processing this batch is:  0.0026953890919685364\n",
      "\n",
      "The classification loss after processing this batch is:  0.07250417768955231\n",
      "The representation loss after processing this batch is:  0.0024066604673862457\n",
      "\n",
      "The classification loss after processing this batch is:  0.15358252823352814\n",
      "The representation loss after processing this batch is:  0.002402976155281067\n",
      "\n",
      "The classification loss after processing this batch is:  0.08892334252595901\n",
      "The representation loss after processing this batch is:  0.002495303750038147\n",
      "\n",
      "The classification loss after processing this batch is:  0.09231828898191452\n",
      "The representation loss after processing this batch is:  0.0026093050837516785\n",
      "\n",
      "The classification loss after processing this batch is:  0.05706978216767311\n",
      "The representation loss after processing this batch is:  0.0025294646620750427\n",
      "\n",
      "The classification loss after processing this batch is:  0.15911231935024261\n",
      "The representation loss after processing this batch is:  0.0023207738995552063\n",
      "\n",
      "The classification loss after processing this batch is:  0.09472779184579849\n",
      "The representation loss after processing this batch is:  0.002405993640422821\n",
      "\n",
      "The classification loss after processing this batch is:  0.11703184992074966\n",
      "The representation loss after processing this batch is:  0.0023380666971206665\n",
      "\n",
      "The classification loss after processing this batch is:  0.12755833566188812\n",
      "The representation loss after processing this batch is:  0.0025299638509750366\n",
      "\n",
      "The classification loss after processing this batch is:  0.04587214067578316\n",
      "The representation loss after processing this batch is:  0.002733983099460602\n",
      "\n",
      "The classification loss after processing this batch is:  0.10056813806295395\n",
      "The representation loss after processing this batch is:  0.002781122922897339\n",
      "\n",
      "The classification loss after processing this batch is:  0.12596122920513153\n",
      "The representation loss after processing this batch is:  0.0025602206587791443\n",
      "\n",
      "The classification loss after processing this batch is:  0.09180048108100891\n",
      "The representation loss after processing this batch is:  0.002683691680431366\n",
      "\n",
      "The classification loss after processing this batch is:  0.053810980170965195\n",
      "The representation loss after processing this batch is:  0.002951785922050476\n",
      "\n",
      "The classification loss after processing this batch is:  0.07248703390359879\n",
      "The representation loss after processing this batch is:  0.0023127198219299316\n",
      "\n",
      "The classification loss after processing this batch is:  0.20866669714450836\n",
      "The representation loss after processing this batch is:  0.0030845552682876587\n",
      "\n",
      "The classification loss after processing this batch is:  0.14754590392112732\n",
      "The representation loss after processing this batch is:  0.002541579306125641\n",
      "\n",
      "The classification loss after processing this batch is:  0.10236319154500961\n",
      "The representation loss after processing this batch is:  0.0024250969290733337\n",
      "\n",
      "The classification loss after processing this batch is:  0.08568031340837479\n",
      "The representation loss after processing this batch is:  0.0023157522082328796\n",
      "\n",
      "The classification loss after processing this batch is:  0.07503847032785416\n",
      "The representation loss after processing this batch is:  0.0026201829314231873\n",
      "\n",
      "The classification loss after processing this batch is:  0.0874803215265274\n",
      "The representation loss after processing this batch is:  0.0023471154272556305\n",
      "\n",
      "The classification loss after processing this batch is:  0.10456348955631256\n",
      "The representation loss after processing this batch is:  0.002619147300720215\n",
      "\n",
      "The classification loss after processing this batch is:  0.11106304079294205\n",
      "The representation loss after processing this batch is:  0.0026374533772468567\n",
      "\n",
      "The classification loss after processing this batch is:  0.11201545596122742\n",
      "The representation loss after processing this batch is:  0.0031729787588119507\n",
      "\n",
      "The classification loss after processing this batch is:  0.07591211795806885\n",
      "The representation loss after processing this batch is:  0.0028420165181159973\n",
      "\n",
      "The classification loss after processing this batch is:  0.1452476680278778\n",
      "The representation loss after processing this batch is:  0.002395670861005783\n",
      "\n",
      "The classification loss after processing this batch is:  0.16948217153549194\n",
      "The representation loss after processing this batch is:  0.0024497881531715393\n",
      "\n",
      "The classification loss after processing this batch is:  0.03970915824174881\n",
      "The representation loss after processing this batch is:  0.00259370356798172\n",
      "\n",
      "The classification loss after processing this batch is:  0.05829019472002983\n",
      "The representation loss after processing this batch is:  0.0023182593286037445\n",
      "\n",
      "The classification loss after processing this batch is:  0.15224680304527283\n",
      "The representation loss after processing this batch is:  0.00244208425283432\n",
      "\n",
      "The classification loss after processing this batch is:  0.14490316808223724\n",
      "The representation loss after processing this batch is:  0.002792373299598694\n",
      "\n",
      "The classification loss after processing this batch is:  0.1001829206943512\n",
      "The representation loss after processing this batch is:  0.002624921500682831\n",
      "\n",
      "The classification loss after processing this batch is:  0.19421672821044922\n",
      "The representation loss after processing this batch is:  0.0025976374745368958\n",
      "\n",
      "The classification loss after processing this batch is:  0.1459020972251892\n",
      "The representation loss after processing this batch is:  0.002982214093208313\n",
      "\n",
      "The classification loss after processing this batch is:  0.18876606225967407\n",
      "The representation loss after processing this batch is:  0.0027434229850769043\n",
      "\n",
      "The classification loss after processing this batch is:  0.09688125550746918\n",
      "The representation loss after processing this batch is:  0.002869322896003723\n",
      "\n",
      "The classification loss after processing this batch is:  0.15513691306114197\n",
      "The representation loss after processing this batch is:  0.0024582073092460632\n",
      "\n",
      "The classification loss after processing this batch is:  0.08476168662309647\n",
      "The representation loss after processing this batch is:  0.0036590173840522766\n",
      "\n",
      "The classification loss after processing this batch is:  0.08371949195861816\n",
      "The representation loss after processing this batch is:  0.0025552064180374146\n",
      "\n",
      "The classification loss after processing this batch is:  0.10099029541015625\n",
      "The representation loss after processing this batch is:  0.0026358067989349365\n",
      "\n",
      "The classification loss after processing this batch is:  0.09212277084589005\n",
      "The representation loss after processing this batch is:  0.002211757004261017\n",
      "\n",
      "The classification loss after processing this batch is:  0.10786224901676178\n",
      "The representation loss after processing this batch is:  0.0025026723742485046\n",
      "\n",
      "The classification loss after processing this batch is:  0.09576709568500519\n",
      "The representation loss after processing this batch is:  0.0025974735617637634\n",
      "\n",
      "The classification loss after processing this batch is:  0.1626393347978592\n",
      "The representation loss after processing this batch is:  0.0025843530893325806\n",
      "\n",
      "The classification loss after processing this batch is:  0.06497617810964584\n",
      "The representation loss after processing this batch is:  0.0029026344418525696\n",
      "\n",
      "The classification loss after processing this batch is:  0.06391409784555435\n",
      "The representation loss after processing this batch is:  0.0028928443789482117\n",
      "\n",
      "The classification loss after processing this batch is:  0.13269838690757751\n",
      "The representation loss after processing this batch is:  0.0029061883687973022\n",
      "\n",
      "The classification loss after processing this batch is:  0.07037853449583054\n",
      "The representation loss after processing this batch is:  0.002576597034931183\n",
      "\n",
      "The classification loss after processing this batch is:  0.07148922234773636\n",
      "The representation loss after processing this batch is:  0.0027393177151679993\n",
      "\n",
      "The classification loss after processing this batch is:  0.058310333639383316\n",
      "The representation loss after processing this batch is:  0.0026131868362426758\n",
      "\n",
      "The classification loss after processing this batch is:  0.12066200375556946\n",
      "The representation loss after processing this batch is:  0.002277679741382599\n",
      "\n",
      "The classification loss after processing this batch is:  0.1632108837366104\n",
      "The representation loss after processing this batch is:  0.0029940828680992126\n",
      "\n",
      "The classification loss after processing this batch is:  0.16871759295463562\n",
      "The representation loss after processing this batch is:  0.0035539716482162476\n",
      "\n",
      "The classification loss after processing this batch is:  0.12601837515830994\n",
      "The representation loss after processing this batch is:  0.00314997136592865\n",
      "\n",
      "The classification loss after processing this batch is:  0.09239190071821213\n",
      "The representation loss after processing this batch is:  0.00263763964176178\n",
      "\n",
      "The classification loss after processing this batch is:  0.08842937648296356\n",
      "The representation loss after processing this batch is:  0.0026577934622764587\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1423593908548355\n",
      "The representation loss after processing this batch is:  0.002338908612728119\n",
      "\n",
      "The classification loss after processing this batch is:  0.06208622455596924\n",
      "The representation loss after processing this batch is:  0.0026545077562332153\n",
      "\n",
      "The classification loss after processing this batch is:  0.05382774770259857\n",
      "The representation loss after processing this batch is:  0.002659425139427185\n",
      "\n",
      "The classification loss after processing this batch is:  0.04216299578547478\n",
      "The representation loss after processing this batch is:  0.0025812536478042603\n",
      "\n",
      "The classification loss after processing this batch is:  0.16459490358829498\n",
      "The representation loss after processing this batch is:  0.0030301660299301147\n",
      "\n",
      "The classification loss after processing this batch is:  0.14334988594055176\n",
      "The representation loss after processing this batch is:  0.0027656778693199158\n",
      "\n",
      "The classification loss after processing this batch is:  0.142250195145607\n",
      "The representation loss after processing this batch is:  0.0025016218423843384\n",
      "\n",
      "The classification loss after processing this batch is:  0.13601188361644745\n",
      "The representation loss after processing this batch is:  0.003373973071575165\n",
      "\n",
      "The classification loss after processing this batch is:  0.11347421258687973\n",
      "The representation loss after processing this batch is:  0.0028290972113609314\n",
      "\n",
      "The classification loss after processing this batch is:  0.1302967369556427\n",
      "The representation loss after processing this batch is:  0.002764657139778137\n",
      "\n",
      "The classification loss after processing this batch is:  0.08559242635965347\n",
      "The representation loss after processing this batch is:  0.0027033984661102295\n",
      "\n",
      "The classification loss after processing this batch is:  0.2680503726005554\n",
      "The representation loss after processing this batch is:  0.0032867789268493652\n",
      "\n",
      "The classification loss after processing this batch is:  0.13965003192424774\n",
      "The representation loss after processing this batch is:  0.002853021025657654\n",
      "\n",
      "The classification loss after processing this batch is:  0.21450696885585785\n",
      "The representation loss after processing this batch is:  0.0031960606575012207\n",
      "\n",
      "The classification loss after processing this batch is:  0.07895410060882568\n",
      "The representation loss after processing this batch is:  0.002408258616924286\n",
      "\n",
      "The classification loss after processing this batch is:  0.05799579620361328\n",
      "The representation loss after processing this batch is:  0.0025874823331832886\n",
      "\n",
      "The classification loss after processing this batch is:  0.17906223237514496\n",
      "The representation loss after processing this batch is:  0.0024977773427963257\n",
      "\n",
      "The classification loss after processing this batch is:  0.14395637810230255\n",
      "The representation loss after processing this batch is:  0.002890251576900482\n",
      "\n",
      "The classification loss after processing this batch is:  0.241001695394516\n",
      "The representation loss after processing this batch is:  0.002581864595413208\n",
      "\n",
      "The classification loss after processing this batch is:  0.16224482655525208\n",
      "The representation loss after processing this batch is:  0.0033403784036636353\n",
      "\n",
      "The classification loss after processing this batch is:  0.14430440962314606\n",
      "The representation loss after processing this batch is:  0.00333259254693985\n",
      "\n",
      "The classification loss after processing this batch is:  0.12823250889778137\n",
      "The representation loss after processing this batch is:  0.002758413553237915\n",
      "\n",
      "The classification loss after processing this batch is:  0.04924044385552406\n",
      "The representation loss after processing this batch is:  0.0024817585945129395\n",
      "\n",
      "The classification loss after processing this batch is:  0.08843312412500381\n",
      "The representation loss after processing this batch is:  0.002423606812953949\n",
      "\n",
      "The classification loss after processing this batch is:  0.0991198942065239\n",
      "The representation loss after processing this batch is:  0.002528466284275055\n",
      "\n",
      "The classification loss after processing this batch is:  0.061117734760046005\n",
      "The representation loss after processing this batch is:  0.002639003098011017\n",
      "\n",
      "The classification loss after processing this batch is:  0.12221647799015045\n",
      "The representation loss after processing this batch is:  0.0023714378476142883\n",
      "\n",
      "The classification loss after processing this batch is:  0.19591975212097168\n",
      "The representation loss after processing this batch is:  0.002581477165222168\n",
      "\n",
      "The classification loss after processing this batch is:  0.12860311567783356\n",
      "The representation loss after processing this batch is:  0.0022748447954654694\n",
      "\n",
      "The classification loss after processing this batch is:  0.08606774359941483\n",
      "The representation loss after processing this batch is:  0.0026508867740631104\n",
      "\n",
      "The classification loss after processing this batch is:  0.09407629817724228\n",
      "The representation loss after processing this batch is:  0.0026965588331222534\n",
      "\n",
      "The classification loss after processing this batch is:  0.06074066087603569\n",
      "The representation loss after processing this batch is:  0.002788953483104706\n",
      "\n",
      "The classification loss after processing this batch is:  0.09981322288513184\n",
      "The representation loss after processing this batch is:  0.00295364111661911\n",
      "\n",
      "The classification loss after processing this batch is:  0.05048440396785736\n",
      "The representation loss after processing this batch is:  0.0028983578085899353\n",
      "\n",
      "The classification loss after processing this batch is:  0.12260257452726364\n",
      "The representation loss after processing this batch is:  0.002336263656616211\n",
      "\n",
      "The classification loss after processing this batch is:  0.12268868088722229\n",
      "The representation loss after processing this batch is:  0.0027577579021453857\n",
      "\n",
      "The classification loss after processing this batch is:  0.042948950082063675\n",
      "The representation loss after processing this batch is:  0.002697281539440155\n",
      "\n",
      "The classification loss after processing this batch is:  0.2090606540441513\n",
      "The representation loss after processing this batch is:  0.002302415668964386\n",
      "\n",
      "The classification loss after processing this batch is:  0.09103457629680634\n",
      "The representation loss after processing this batch is:  0.0024308189749717712\n",
      "\n",
      "The classification loss after processing this batch is:  0.08840438723564148\n",
      "The representation loss after processing this batch is:  0.0024960264563560486\n",
      "\n",
      "The classification loss after processing this batch is:  0.05615184083580971\n",
      "The representation loss after processing this batch is:  0.002843134105205536\n",
      "\n",
      "The classification loss after processing this batch is:  0.0641765370965004\n",
      "The representation loss after processing this batch is:  0.002633810043334961\n",
      "\n",
      "The classification loss after processing this batch is:  0.060204457491636276\n",
      "The representation loss after processing this batch is:  0.002566330134868622\n",
      "\n",
      "The classification loss after processing this batch is:  0.34581640362739563\n",
      "The representation loss after processing this batch is:  0.0023458637297153473\n",
      "\n",
      "The classification loss after processing this batch is:  0.10568860918283463\n",
      "The representation loss after processing this batch is:  0.0028244629502296448\n",
      "\n",
      "The classification loss after processing this batch is:  0.14978283643722534\n",
      "The representation loss after processing this batch is:  0.0023465827107429504\n",
      "\n",
      "The classification loss after processing this batch is:  0.0708964616060257\n",
      "The representation loss after processing this batch is:  0.0023623183369636536\n",
      "\n",
      "The classification loss after processing this batch is:  0.10773196071386337\n",
      "The representation loss after processing this batch is:  0.0026804283261299133\n",
      "\n",
      "The classification loss after processing this batch is:  0.050496093928813934\n",
      "The representation loss after processing this batch is:  0.002545449882745743\n",
      "\n",
      "The classification loss after processing this batch is:  0.07385967671871185\n",
      "The representation loss after processing this batch is:  0.00266256183385849\n",
      "\n",
      "The classification loss after processing this batch is:  0.17147427797317505\n",
      "The representation loss after processing this batch is:  0.00267212837934494\n",
      "\n",
      "The classification loss after processing this batch is:  0.10467557609081268\n",
      "The representation loss after processing this batch is:  0.003247864544391632\n",
      "\n",
      "The classification loss after processing this batch is:  0.14065366983413696\n",
      "The representation loss after processing this batch is:  0.0029064342379570007\n",
      "\n",
      "The classification loss after processing this batch is:  0.08550553768873215\n",
      "The representation loss after processing this batch is:  0.002370983362197876\n",
      "\n",
      "The classification loss after processing this batch is:  0.1882239282131195\n",
      "The representation loss after processing this batch is:  0.0025709718465805054\n",
      "\n",
      "The classification loss after processing this batch is:  0.1167416051030159\n",
      "The representation loss after processing this batch is:  0.002769552171230316\n",
      "\n",
      "The classification loss after processing this batch is:  0.19223769009113312\n",
      "The representation loss after processing this batch is:  0.002672813832759857\n",
      "\n",
      "The classification loss after processing this batch is:  0.08050063997507095\n",
      "The representation loss after processing this batch is:  0.002778969705104828\n",
      "\n",
      "The classification loss after processing this batch is:  0.08606380969285965\n",
      "The representation loss after processing this batch is:  0.0031247511506080627\n",
      "\n",
      "The classification loss after processing this batch is:  0.03656323626637459\n",
      "The representation loss after processing this batch is:  0.0025865063071250916\n",
      "\n",
      "The classification loss after processing this batch is:  0.18527838587760925\n",
      "The representation loss after processing this batch is:  0.0026236996054649353\n",
      "\n",
      "The classification loss after processing this batch is:  0.241190567612648\n",
      "The representation loss after processing this batch is:  0.0029386132955551147\n",
      "\n",
      "The classification loss after processing this batch is:  0.10408642888069153\n",
      "The representation loss after processing this batch is:  0.0026434510946273804\n",
      "\n",
      "The classification loss after processing this batch is:  0.1658225655555725\n",
      "The representation loss after processing this batch is:  0.003209248185157776\n",
      "\n",
      "The classification loss after processing this batch is:  0.14988262951374054\n",
      "The representation loss after processing this batch is:  0.0028831474483013153\n",
      "\n",
      "The classification loss after processing this batch is:  0.14994798600673676\n",
      "The representation loss after processing this batch is:  0.00267203152179718\n",
      "\n",
      "The classification loss after processing this batch is:  0.058724574744701385\n",
      "The representation loss after processing this batch is:  0.0025728046894073486\n",
      "\n",
      "The classification loss after processing this batch is:  0.1005726009607315\n",
      "The representation loss after processing this batch is:  0.0025625601410865784\n",
      "\n",
      "The classification loss after processing this batch is:  0.13586373627185822\n",
      "The representation loss after processing this batch is:  0.0028947368264198303\n",
      "\n",
      "The classification loss after processing this batch is:  0.09354054927825928\n",
      "The representation loss after processing this batch is:  0.0027334392070770264\n",
      "\n",
      "The classification loss after processing this batch is:  0.03490731865167618\n",
      "The representation loss after processing this batch is:  0.002791173756122589\n",
      "\n",
      "The classification loss after processing this batch is:  0.06702542304992676\n",
      "The representation loss after processing this batch is:  0.002914510667324066\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.07443905621767044\n",
      "The representation loss after processing this batch is:  0.002820543944835663\n",
      "\n",
      "The classification loss after processing this batch is:  0.10530062019824982\n",
      "The representation loss after processing this batch is:  0.002387743443250656\n",
      "\n",
      "The classification loss after processing this batch is:  0.1446559876203537\n",
      "The representation loss after processing this batch is:  0.0025532320141792297\n",
      "\n",
      "The classification loss after processing this batch is:  0.08649662882089615\n",
      "The representation loss after processing this batch is:  0.0024054907262325287\n",
      "\n",
      "The classification loss after processing this batch is:  0.10903619229793549\n",
      "The representation loss after processing this batch is:  0.00295131653547287\n",
      "\n",
      "The classification loss after processing this batch is:  0.1611485332250595\n",
      "The representation loss after processing this batch is:  0.002680473029613495\n",
      "\n",
      "The classification loss after processing this batch is:  0.11695133149623871\n",
      "The representation loss after processing this batch is:  0.0032672137022018433\n",
      "\n",
      "The classification loss after processing this batch is:  0.08152899146080017\n",
      "The representation loss after processing this batch is:  0.0026765912771224976\n",
      "\n",
      "The classification loss after processing this batch is:  0.14407943189144135\n",
      "The representation loss after processing this batch is:  0.002748161554336548\n",
      "\n",
      "The classification loss after processing this batch is:  0.12579649686813354\n",
      "The representation loss after processing this batch is:  0.0030600428581237793\n",
      "\n",
      "The classification loss after processing this batch is:  0.13204622268676758\n",
      "The representation loss after processing this batch is:  0.002754583954811096\n",
      "\n",
      "The classification loss after processing this batch is:  0.09130527079105377\n",
      "The representation loss after processing this batch is:  0.0024340450763702393\n",
      "\n",
      "The classification loss after processing this batch is:  0.08274160325527191\n",
      "The representation loss after processing this batch is:  0.002497740089893341\n",
      "\n",
      "The classification loss after processing this batch is:  0.08197745680809021\n",
      "The representation loss after processing this batch is:  0.0026226788759231567\n",
      "\n",
      "The classification loss after processing this batch is:  0.09873687475919724\n",
      "The representation loss after processing this batch is:  0.002632077783346176\n",
      "\n",
      "The classification loss after processing this batch is:  0.1641497015953064\n",
      "The representation loss after processing this batch is:  0.002668343484401703\n",
      "\n",
      "The classification loss after processing this batch is:  0.25349342823028564\n",
      "The representation loss after processing this batch is:  0.0027144700288772583\n",
      "\n",
      "The classification loss after processing this batch is:  0.13060112297534943\n",
      "The representation loss after processing this batch is:  0.0024060383439064026\n",
      "\n",
      "The classification loss after processing this batch is:  0.10964153707027435\n",
      "The representation loss after processing this batch is:  0.0026098117232322693\n",
      "\n",
      "The classification loss after processing this batch is:  0.09983982145786285\n",
      "The representation loss after processing this batch is:  0.0024483390152454376\n",
      "\n",
      "The classification loss after processing this batch is:  0.14083151519298553\n",
      "The representation loss after processing this batch is:  0.0024859271943569183\n",
      "\n",
      "The classification loss after processing this batch is:  0.17604747414588928\n",
      "The representation loss after processing this batch is:  0.0027495548129081726\n",
      "\n",
      "The classification loss after processing this batch is:  0.1291680783033371\n",
      "The representation loss after processing this batch is:  0.0025398172438144684\n",
      "\n",
      "The classification loss after processing this batch is:  0.3284226655960083\n",
      "The representation loss after processing this batch is:  0.00266353040933609\n",
      "\n",
      "The classification loss after processing this batch is:  0.14850784838199615\n",
      "The representation loss after processing this batch is:  0.0024431943893432617\n",
      "\n",
      "The classification loss after processing this batch is:  0.06372073292732239\n",
      "The representation loss after processing this batch is:  0.0032311975955963135\n",
      "\n",
      "The classification loss after processing this batch is:  0.09949679672718048\n",
      "The representation loss after processing this batch is:  0.0028195567429065704\n",
      "\n",
      "The classification loss after processing this batch is:  0.07640078663825989\n",
      "The representation loss after processing this batch is:  0.002646826207637787\n",
      "\n",
      "The classification loss after processing this batch is:  0.14273704588413239\n",
      "The representation loss after processing this batch is:  0.002734161913394928\n",
      "\n",
      "The classification loss after processing this batch is:  0.1056254655122757\n",
      "The representation loss after processing this batch is:  0.0024277977645397186\n",
      "\n",
      "The classification loss after processing this batch is:  0.10395970195531845\n",
      "The representation loss after processing this batch is:  0.0024965256452560425\n",
      "\n",
      "The classification loss after processing this batch is:  0.08778894692659378\n",
      "The representation loss after processing this batch is:  0.0026620179414749146\n",
      "\n",
      "The classification loss after processing this batch is:  0.13094177842140198\n",
      "The representation loss after processing this batch is:  0.002481520175933838\n",
      "\n",
      "The classification loss after processing this batch is:  0.1651575267314911\n",
      "The representation loss after processing this batch is:  0.002352781593799591\n",
      "\n",
      "The classification loss after processing this batch is:  0.19165746867656708\n",
      "The representation loss after processing this batch is:  0.0026733577251434326\n",
      "\n",
      "The classification loss after processing this batch is:  0.11262417584657669\n",
      "The representation loss after processing this batch is:  0.0026113465428352356\n",
      "\n",
      "The classification loss after processing this batch is:  0.040183912962675095\n",
      "The representation loss after processing this batch is:  0.003014206886291504\n",
      "\n",
      "The classification loss after processing this batch is:  0.027814174070954323\n",
      "The representation loss after processing this batch is:  0.0027300789952278137\n",
      "\n",
      "The classification loss after processing this batch is:  0.11328811198472977\n",
      "The representation loss after processing this batch is:  0.003102131187915802\n",
      "\n",
      "The classification loss after processing this batch is:  0.05958501622080803\n",
      "The representation loss after processing this batch is:  0.003717869520187378\n",
      "\n",
      "The classification loss after processing this batch is:  0.1461637020111084\n",
      "The representation loss after processing this batch is:  0.0027691274881362915\n",
      "\n",
      "The classification loss after processing this batch is:  0.1231737807393074\n",
      "The representation loss after processing this batch is:  0.0028383731842041016\n",
      "\n",
      "The classification loss after processing this batch is:  0.18296696245670319\n",
      "The representation loss after processing this batch is:  0.0024697110056877136\n",
      "\n",
      "The classification loss after processing this batch is:  0.04198117181658745\n",
      "The representation loss after processing this batch is:  0.0027059167623519897\n",
      "\n",
      "The classification loss after processing this batch is:  0.12102702260017395\n",
      "The representation loss after processing this batch is:  0.002660885453224182\n",
      "\n",
      "The classification loss after processing this batch is:  0.13468138873577118\n",
      "The representation loss after processing this batch is:  0.0029037222266197205\n",
      "\n",
      "The classification loss after processing this batch is:  0.17203982174396515\n",
      "The representation loss after processing this batch is:  0.002841755747795105\n",
      "\n",
      "The classification loss after processing this batch is:  0.08900538086891174\n",
      "The representation loss after processing this batch is:  0.0029073134064674377\n",
      "\n",
      "The classification loss after processing this batch is:  0.06306184083223343\n",
      "The representation loss after processing this batch is:  0.0022766850888729095\n",
      "\n",
      "The classification loss after processing this batch is:  0.11185187846422195\n",
      "The representation loss after processing this batch is:  0.0028127655386924744\n",
      "\n",
      "The classification loss after processing this batch is:  0.07866325974464417\n",
      "The representation loss after processing this batch is:  0.0024783089756965637\n",
      "\n",
      "The classification loss after processing this batch is:  0.0958072617650032\n",
      "The representation loss after processing this batch is:  0.002489738166332245\n",
      "\n",
      "The classification loss after processing this batch is:  0.14234624803066254\n",
      "The representation loss after processing this batch is:  0.0025170817971229553\n",
      "\n",
      "The classification loss after processing this batch is:  0.08164575695991516\n",
      "The representation loss after processing this batch is:  0.002613462507724762\n",
      "\n",
      "The classification loss after processing this batch is:  0.026152372360229492\n",
      "The representation loss after processing this batch is:  0.0024307668209075928\n",
      "\n",
      "The classification loss after processing this batch is:  0.07539144158363342\n",
      "The representation loss after processing this batch is:  0.0028708577156066895\n",
      "\n",
      "The classification loss after processing this batch is:  0.03190021589398384\n",
      "The representation loss after processing this batch is:  0.0029170215129852295\n",
      "\n",
      "The classification loss after processing this batch is:  0.09835480153560638\n",
      "The representation loss after processing this batch is:  0.0026322752237319946\n",
      "\n",
      "The classification loss after processing this batch is:  0.06158408150076866\n",
      "The representation loss after processing this batch is:  0.0026961565017700195\n",
      "\n",
      "The classification loss after processing this batch is:  0.05465923994779587\n",
      "The representation loss after processing this batch is:  0.0025004148483276367\n",
      "\n",
      "The classification loss after processing this batch is:  0.09157195687294006\n",
      "The representation loss after processing this batch is:  0.003029845654964447\n",
      "\n",
      "The classification loss after processing this batch is:  0.06409471482038498\n",
      "The representation loss after processing this batch is:  0.002686440944671631\n",
      "\n",
      "The classification loss after processing this batch is:  0.04416532814502716\n",
      "The representation loss after processing this batch is:  0.0027404725551605225\n",
      "\n",
      "The classification loss after processing this batch is:  0.08618315309286118\n",
      "The representation loss after processing this batch is:  0.0025516673922538757\n",
      "\n",
      "The classification loss after processing this batch is:  0.053713925182819366\n",
      "The representation loss after processing this batch is:  0.0026094168424606323\n",
      "\n",
      "The classification loss after processing this batch is:  0.040837693959474564\n",
      "The representation loss after processing this batch is:  0.002638101577758789\n",
      "\n",
      "The classification loss after processing this batch is:  0.09282254427671432\n",
      "The representation loss after processing this batch is:  0.0026886537671089172\n",
      "\n",
      "The classification loss after processing this batch is:  0.1267104595899582\n",
      "The representation loss after processing this batch is:  0.002901405096054077\n",
      "\n",
      "The classification loss after processing this batch is:  0.054779402911663055\n",
      "The representation loss after processing this batch is:  0.0029402822256088257\n",
      "\n",
      "The classification loss after processing this batch is:  0.18419891595840454\n",
      "The representation loss after processing this batch is:  0.002757847309112549\n",
      "\n",
      "The classification loss after processing this batch is:  0.045888856053352356\n",
      "The representation loss after processing this batch is:  0.002578042447566986\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.11900988221168518\n",
      "The representation loss after processing this batch is:  0.002379782497882843\n",
      "\n",
      "The classification loss after processing this batch is:  0.12590567767620087\n",
      "The representation loss after processing this batch is:  0.0029976442456245422\n",
      "\n",
      "The classification loss after processing this batch is:  0.06310998648405075\n",
      "The representation loss after processing this batch is:  0.003120027482509613\n",
      "\n",
      "The classification loss after processing this batch is:  0.1685180366039276\n",
      "The representation loss after processing this batch is:  0.0026760101318359375\n",
      "\n",
      "The classification loss after processing this batch is:  0.15329155325889587\n",
      "The representation loss after processing this batch is:  0.00239621102809906\n",
      "\n",
      "The classification loss after processing this batch is:  0.15471114218235016\n",
      "The representation loss after processing this batch is:  0.0025981664657592773\n",
      "\n",
      "The classification loss after processing this batch is:  0.14316298067569733\n",
      "The representation loss after processing this batch is:  0.002550937235355377\n",
      "\n",
      "The classification loss after processing this batch is:  0.07134462147951126\n",
      "The representation loss after processing this batch is:  0.0029020681977272034\n",
      "\n",
      "The classification loss after processing this batch is:  0.09287242591381073\n",
      "The representation loss after processing this batch is:  0.002299882471561432\n",
      "\n",
      "The classification loss after processing this batch is:  0.10586199164390564\n",
      "The representation loss after processing this batch is:  0.0026883259415626526\n",
      "\n",
      "The classification loss after processing this batch is:  0.14991417527198792\n",
      "The representation loss after processing this batch is:  0.0024848058819770813\n",
      "\n",
      "The classification loss after processing this batch is:  0.14784838259220123\n",
      "The representation loss after processing this batch is:  0.0024909302592277527\n",
      "\n",
      "The classification loss after processing this batch is:  0.05869089439511299\n",
      "The representation loss after processing this batch is:  0.002363927662372589\n",
      "\n",
      "The classification loss after processing this batch is:  0.07137545943260193\n",
      "The representation loss after processing this batch is:  0.00250118225812912\n",
      "\n",
      "The classification loss after processing this batch is:  0.18428081274032593\n",
      "The representation loss after processing this batch is:  0.0021991506218910217\n",
      "\n",
      "The classification loss after processing this batch is:  0.062499262392520905\n",
      "The representation loss after processing this batch is:  0.0025747865438461304\n",
      "\n",
      "The classification loss after processing this batch is:  0.11467845737934113\n",
      "The representation loss after processing this batch is:  0.002634502947330475\n",
      "\n",
      "The classification loss after processing this batch is:  0.12877541780471802\n",
      "The representation loss after processing this batch is:  0.002532385289669037\n",
      "\n",
      "The classification loss after processing this batch is:  0.06779416650533676\n",
      "The representation loss after processing this batch is:  0.0030058398842811584\n",
      "\n",
      "The classification loss after processing this batch is:  0.0459330789744854\n",
      "The representation loss after processing this batch is:  0.0029039904475212097\n",
      "\n",
      "The classification loss after processing this batch is:  0.10478609055280685\n",
      "The representation loss after processing this batch is:  0.002665489912033081\n",
      "\n",
      "The classification loss after processing this batch is:  0.14318762719631195\n",
      "The representation loss after processing this batch is:  0.002589792013168335\n",
      "\n",
      "The classification loss after processing this batch is:  0.15042026340961456\n",
      "The representation loss after processing this batch is:  0.002727881073951721\n",
      "\n",
      "The classification loss after processing this batch is:  0.2075532227754593\n",
      "The representation loss after processing this batch is:  0.0030728429555892944\n",
      "\n",
      "The classification loss after processing this batch is:  0.12061037868261337\n",
      "The representation loss after processing this batch is:  0.002692379057407379\n",
      "\n",
      "The classification loss after processing this batch is:  0.1392507404088974\n",
      "The representation loss after processing this batch is:  0.0021756067872047424\n",
      "\n",
      "The classification loss after processing this batch is:  0.09593874961137772\n",
      "The representation loss after processing this batch is:  0.002904072403907776\n",
      "\n",
      "The classification loss after processing this batch is:  0.05101359635591507\n",
      "The representation loss after processing this batch is:  0.002734065055847168\n",
      "\n",
      "The classification loss after processing this batch is:  0.06168244779109955\n",
      "The representation loss after processing this batch is:  0.0025766491889953613\n",
      "\n",
      "The classification loss after processing this batch is:  0.07523015141487122\n",
      "The representation loss after processing this batch is:  0.002659521996974945\n",
      "\n",
      "The classification loss after processing this batch is:  0.10376159101724625\n",
      "The representation loss after processing this batch is:  0.0027730539441108704\n",
      "\n",
      "The classification loss after processing this batch is:  0.08795522898435593\n",
      "The representation loss after processing this batch is:  0.002731822431087494\n",
      "\n",
      "The classification loss after processing this batch is:  0.11566648632287979\n",
      "The representation loss after processing this batch is:  0.003081582486629486\n",
      "\n",
      "The classification loss after processing this batch is:  0.13325431942939758\n",
      "The representation loss after processing this batch is:  0.002968616783618927\n",
      "\n",
      "The classification loss after processing this batch is:  0.08687219768762589\n",
      "The representation loss after processing this batch is:  0.0029456019401550293\n",
      "\n",
      "The classification loss after processing this batch is:  0.15648667514324188\n",
      "The representation loss after processing this batch is:  0.0027904659509658813\n",
      "\n",
      "The classification loss after processing this batch is:  0.16391578316688538\n",
      "The representation loss after processing this batch is:  0.002566590905189514\n",
      "\n",
      "The classification loss after processing this batch is:  0.17678925395011902\n",
      "The representation loss after processing this batch is:  0.0026529058814048767\n",
      "\n",
      "The classification loss after processing this batch is:  0.07487768679857254\n",
      "The representation loss after processing this batch is:  0.0029306188225746155\n",
      "\n",
      "The classification loss after processing this batch is:  0.07029552757740021\n",
      "The representation loss after processing this batch is:  0.0025182217359542847\n",
      "\n",
      "The classification loss after processing this batch is:  0.2031666785478592\n",
      "The representation loss after processing this batch is:  0.002521812915802002\n",
      "\n",
      "The classification loss after processing this batch is:  0.1816256195306778\n",
      "The representation loss after processing this batch is:  0.002482794225215912\n",
      "\n",
      "The classification loss after processing this batch is:  0.1358833760023117\n",
      "The representation loss after processing this batch is:  0.0026831701397895813\n",
      "\n",
      "The classification loss after processing this batch is:  0.11032059788703918\n",
      "The representation loss after processing this batch is:  0.002565048635005951\n",
      "\n",
      "The classification loss after processing this batch is:  0.1306506097316742\n",
      "The representation loss after processing this batch is:  0.0025435686111450195\n",
      "\n",
      "The classification loss after processing this batch is:  0.23033219575881958\n",
      "The representation loss after processing this batch is:  0.0024040937423706055\n",
      "\n",
      "The classification loss after processing this batch is:  0.19278673827648163\n",
      "The representation loss after processing this batch is:  0.0024534985423088074\n",
      "\n",
      "The classification loss after processing this batch is:  0.1846066564321518\n",
      "The representation loss after processing this batch is:  0.002682700753211975\n",
      "\n",
      "The classification loss after processing this batch is:  0.1653042733669281\n",
      "The representation loss after processing this batch is:  0.002524077892303467\n",
      "\n",
      "The classification loss after processing this batch is:  0.07832492142915726\n",
      "The representation loss after processing this batch is:  0.0030064657330513\n",
      "\n",
      "The classification loss after processing this batch is:  0.058515287935733795\n",
      "The representation loss after processing this batch is:  0.0026000887155532837\n",
      "\n",
      "The classification loss after processing this batch is:  0.1288568377494812\n",
      "The representation loss after processing this batch is:  0.0027052760124206543\n",
      "\n",
      "The classification loss after processing this batch is:  0.09797978401184082\n",
      "The representation loss after processing this batch is:  0.0024767816066741943\n",
      "\n",
      "The classification loss after processing this batch is:  0.05711502954363823\n",
      "The representation loss after processing this batch is:  0.002342008054256439\n",
      "\n",
      "The classification loss after processing this batch is:  0.049811020493507385\n",
      "The representation loss after processing this batch is:  0.002630777657032013\n",
      "\n",
      "The classification loss after processing this batch is:  0.0985557809472084\n",
      "The representation loss after processing this batch is:  0.002529039978981018\n",
      "\n",
      "The classification loss after processing this batch is:  0.10594408214092255\n",
      "The representation loss after processing this batch is:  0.002737268805503845\n",
      "\n",
      "The classification loss after processing this batch is:  0.0630970224738121\n",
      "The representation loss after processing this batch is:  0.00281340628862381\n",
      "\n",
      "The classification loss after processing this batch is:  0.09347691386938095\n",
      "The representation loss after processing this batch is:  0.002389073371887207\n",
      "\n",
      "The classification loss after processing this batch is:  0.0783601626753807\n",
      "The representation loss after processing this batch is:  0.002703990787267685\n",
      "\n",
      "The classification loss after processing this batch is:  0.16856636106967926\n",
      "The representation loss after processing this batch is:  0.002590559422969818\n",
      "\n",
      "The classification loss after processing this batch is:  0.09754204750061035\n",
      "The representation loss after processing this batch is:  0.0025079697370529175\n",
      "\n",
      "The classification loss after processing this batch is:  0.1518474519252777\n",
      "The representation loss after processing this batch is:  0.0027607008814811707\n",
      "\n",
      "The classification loss after processing this batch is:  0.04332278296351433\n",
      "The representation loss after processing this batch is:  0.002552613615989685\n",
      "\n",
      "The classification loss after processing this batch is:  0.048388127237558365\n",
      "The representation loss after processing this batch is:  0.002944536507129669\n",
      "\n",
      "The classification loss after processing this batch is:  0.12366099655628204\n",
      "The representation loss after processing this batch is:  0.002467341721057892\n",
      "\n",
      "The classification loss after processing this batch is:  0.15949124097824097\n",
      "The representation loss after processing this batch is:  0.002595420926809311\n",
      "\n",
      "The classification loss after processing this batch is:  0.09462138265371323\n",
      "The representation loss after processing this batch is:  0.0026064440608024597\n",
      "\n",
      "The classification loss after processing this batch is:  0.05277855321764946\n",
      "The representation loss after processing this batch is:  0.0024360306560993195\n",
      "\n",
      "The classification loss after processing this batch is:  0.1039150059223175\n",
      "The representation loss after processing this batch is:  0.002276696264743805\n",
      "\n",
      "The classification loss after processing this batch is:  0.023120220750570297\n",
      "The representation loss after processing this batch is:  0.0028245002031326294\n",
      "\n",
      "The classification loss after processing this batch is:  0.15823136270046234\n",
      "The representation loss after processing this batch is:  0.0025451555848121643\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10812535136938095\n",
      "The representation loss after processing this batch is:  0.0028452202677726746\n",
      "\n",
      "The classification loss after processing this batch is:  0.07801339030265808\n",
      "The representation loss after processing this batch is:  0.0025711655616760254\n",
      "\n",
      "The classification loss after processing this batch is:  0.09045741707086563\n",
      "The representation loss after processing this batch is:  0.0027889981865882874\n",
      "\n",
      "The classification loss after processing this batch is:  0.09375901520252228\n",
      "The representation loss after processing this batch is:  0.0027194172143936157\n",
      "\n",
      "The classification loss after processing this batch is:  0.04086051508784294\n",
      "The representation loss after processing this batch is:  0.0025976896286010742\n",
      "\n",
      "The classification loss after processing this batch is:  0.23347164690494537\n",
      "The representation loss after processing this batch is:  0.0025243237614631653\n",
      "\n",
      "The classification loss after processing this batch is:  0.21551138162612915\n",
      "The representation loss after processing this batch is:  0.0025910213589668274\n",
      "\n",
      "The classification loss after processing this batch is:  0.1586514264345169\n",
      "The representation loss after processing this batch is:  0.0025087445974349976\n",
      "\n",
      "The classification loss after processing this batch is:  0.15972599387168884\n",
      "The representation loss after processing this batch is:  0.002405840903520584\n",
      "\n",
      "The classification loss after processing this batch is:  0.09341347217559814\n",
      "The representation loss after processing this batch is:  0.0025385916233062744\n",
      "\n",
      "The classification loss after processing this batch is:  0.07739800959825516\n",
      "The representation loss after processing this batch is:  0.002387329936027527\n",
      "\n",
      "The classification loss after processing this batch is:  0.1877487450838089\n",
      "The representation loss after processing this batch is:  0.002542823553085327\n",
      "\n",
      "The classification loss after processing this batch is:  0.10784778743982315\n",
      "The representation loss after processing this batch is:  0.0024187788367271423\n",
      "\n",
      "The classification loss after processing this batch is:  0.16892728209495544\n",
      "The representation loss after processing this batch is:  0.0025367848575115204\n",
      "\n",
      "The classification loss after processing this batch is:  0.0882076844573021\n",
      "The representation loss after processing this batch is:  0.0027204230427742004\n",
      "\n",
      "The classification loss after processing this batch is:  0.15969282388687134\n",
      "The representation loss after processing this batch is:  0.00236472487449646\n",
      "\n",
      "The classification loss after processing this batch is:  0.07208769768476486\n",
      "The representation loss after processing this batch is:  0.0024366825819015503\n",
      "\n",
      "The classification loss after processing this batch is:  0.07628412544727325\n",
      "The representation loss after processing this batch is:  0.0028197243809700012\n",
      "\n",
      "The classification loss after processing this batch is:  0.11299461871385574\n",
      "The representation loss after processing this batch is:  0.002549871802330017\n",
      "\n",
      "The classification loss after processing this batch is:  0.046236567199230194\n",
      "The representation loss after processing this batch is:  0.002642124891281128\n",
      "\n",
      "The classification loss after processing this batch is:  0.03170021250844002\n",
      "The representation loss after processing this batch is:  0.0026373714208602905\n",
      "\n",
      "The classification loss after processing this batch is:  0.08127520978450775\n",
      "The representation loss after processing this batch is:  0.0025250613689422607\n",
      "\n",
      "The classification loss after processing this batch is:  0.22016525268554688\n",
      "The representation loss after processing this batch is:  0.0026050135493278503\n",
      "\n",
      "The classification loss after processing this batch is:  0.031550150364637375\n",
      "The representation loss after processing this batch is:  0.0027100667357444763\n",
      "\n",
      "The classification loss after processing this batch is:  0.06067764014005661\n",
      "The representation loss after processing this batch is:  0.0024858899414539337\n",
      "\n",
      "The classification loss after processing this batch is:  0.12452831864356995\n",
      "The representation loss after processing this batch is:  0.0024614855647087097\n",
      "\n",
      "The classification loss after processing this batch is:  0.16360647976398468\n",
      "The representation loss after processing this batch is:  0.0024755895137786865\n",
      "\n",
      "The classification loss after processing this batch is:  0.09361767768859863\n",
      "The representation loss after processing this batch is:  0.0026732683181762695\n",
      "\n",
      "The classification loss after processing this batch is:  0.16901209950447083\n",
      "The representation loss after processing this batch is:  0.002402614802122116\n",
      "\n",
      "The classification loss after processing this batch is:  0.07744591683149338\n",
      "The representation loss after processing this batch is:  0.0029411986470222473\n",
      "\n",
      "The classification loss after processing this batch is:  0.0371328741312027\n",
      "The representation loss after processing this batch is:  0.0023865997791290283\n",
      "\n",
      "The classification loss after processing this batch is:  0.036489199846982956\n",
      "The representation loss after processing this batch is:  0.002958528697490692\n",
      "\n",
      "The classification loss after processing this batch is:  0.14502808451652527\n",
      "The representation loss after processing this batch is:  0.0028605684638023376\n",
      "\n",
      "The classification loss after processing this batch is:  0.12386144697666168\n",
      "The representation loss after processing this batch is:  0.0027346834540367126\n",
      "\n",
      "The classification loss after processing this batch is:  0.07891850173473358\n",
      "The representation loss after processing this batch is:  0.003040395677089691\n",
      "\n",
      "The classification loss after processing this batch is:  0.13887269794940948\n",
      "The representation loss after processing this batch is:  0.002711564302444458\n",
      "\n",
      "The classification loss after processing this batch is:  0.07241319119930267\n",
      "The representation loss after processing this batch is:  0.0027457550168037415\n",
      "\n",
      "The classification loss after processing this batch is:  0.08549678325653076\n",
      "The representation loss after processing this batch is:  0.0025546327233314514\n",
      "\n",
      "The classification loss after processing this batch is:  0.10194660723209381\n",
      "The representation loss after processing this batch is:  0.002800978720188141\n",
      "\n",
      "The classification loss after processing this batch is:  0.12518945336341858\n",
      "The representation loss after processing this batch is:  0.0027019083499908447\n",
      "\n",
      "The classification loss after processing this batch is:  0.13049417734146118\n",
      "The representation loss after processing this batch is:  0.0030912011861801147\n",
      "\n",
      "The classification loss after processing this batch is:  0.26648053526878357\n",
      "The representation loss after processing this batch is:  0.002261735498905182\n",
      "\n",
      "The classification loss after processing this batch is:  0.16178086400032043\n",
      "The representation loss after processing this batch is:  0.0024247020483016968\n",
      "\n",
      "The classification loss after processing this batch is:  0.11714724451303482\n",
      "The representation loss after processing this batch is:  0.0027535036206245422\n",
      "\n",
      "The classification loss after processing this batch is:  0.11675801128149033\n",
      "The representation loss after processing this batch is:  0.0028541386127471924\n",
      "\n",
      "The classification loss after processing this batch is:  0.036957137286663055\n",
      "The representation loss after processing this batch is:  0.002588994801044464\n",
      "\n",
      "The classification loss after processing this batch is:  0.08625444769859314\n",
      "The representation loss after processing this batch is:  0.0029854588210582733\n",
      "\n",
      "The classification loss after processing this batch is:  0.06666205078363419\n",
      "The representation loss after processing this batch is:  0.002798929810523987\n",
      "\n",
      "The classification loss after processing this batch is:  0.12984567880630493\n",
      "The representation loss after processing this batch is:  0.0025197379291057587\n",
      "\n",
      "The classification loss after processing this batch is:  0.11652081459760666\n",
      "The representation loss after processing this batch is:  0.0023046210408210754\n",
      "\n",
      "The classification loss after processing this batch is:  0.08709030598402023\n",
      "The representation loss after processing this batch is:  0.0022892430424690247\n",
      "\n",
      "The classification loss after processing this batch is:  0.11164958775043488\n",
      "The representation loss after processing this batch is:  0.002567186951637268\n",
      "\n",
      "The classification loss after processing this batch is:  0.14416055381298065\n",
      "The representation loss after processing this batch is:  0.0023849010467529297\n",
      "\n",
      "The classification loss after processing this batch is:  0.1143115982413292\n",
      "The representation loss after processing this batch is:  0.0025953054428100586\n",
      "\n",
      "The classification loss after processing this batch is:  0.20282647013664246\n",
      "The representation loss after processing this batch is:  0.002829417586326599\n",
      "\n",
      "The classification loss after processing this batch is:  0.06832930445671082\n",
      "The representation loss after processing this batch is:  0.002728857100009918\n",
      "\n",
      "The classification loss after processing this batch is:  0.09749463200569153\n",
      "The representation loss after processing this batch is:  0.002297542989253998\n",
      "\n",
      "The classification loss after processing this batch is:  0.08261991292238235\n",
      "The representation loss after processing this batch is:  0.002637997269630432\n",
      "\n",
      "The classification loss after processing this batch is:  0.20358259975910187\n",
      "The representation loss after processing this batch is:  0.0027627870440483093\n",
      "\n",
      "The classification loss after processing this batch is:  0.17756204307079315\n",
      "The representation loss after processing this batch is:  0.002951599657535553\n",
      "\n",
      "The classification loss after processing this batch is:  0.0441359281539917\n",
      "The representation loss after processing this batch is:  0.0025194287300109863\n",
      "\n",
      "The classification loss after processing this batch is:  0.06504951417446136\n",
      "The representation loss after processing this batch is:  0.002740025520324707\n",
      "\n",
      "The classification loss after processing this batch is:  0.22650578618049622\n",
      "The representation loss after processing this batch is:  0.0024391263723373413\n",
      "\n",
      "The classification loss after processing this batch is:  0.06627541035413742\n",
      "The representation loss after processing this batch is:  0.0025996416807174683\n",
      "\n",
      "The classification loss after processing this batch is:  0.06158086284995079\n",
      "The representation loss after processing this batch is:  0.0026566386222839355\n",
      "\n",
      "The classification loss after processing this batch is:  0.11092448234558105\n",
      "The representation loss after processing this batch is:  0.0025138258934020996\n",
      "\n",
      "The classification loss after processing this batch is:  0.08685624599456787\n",
      "The representation loss after processing this batch is:  0.002604253590106964\n",
      "\n",
      "The classification loss after processing this batch is:  0.18637390434741974\n",
      "The representation loss after processing this batch is:  0.0030215755105018616\n",
      "\n",
      "The classification loss after processing this batch is:  0.11862974613904953\n",
      "The representation loss after processing this batch is:  0.0029749125242233276\n",
      "\n",
      "The classification loss after processing this batch is:  0.14487843215465546\n",
      "The representation loss after processing this batch is:  0.003247573971748352\n",
      "\n",
      "The classification loss after processing this batch is:  0.1231658011674881\n",
      "The representation loss after processing this batch is:  0.0025011226534843445\n",
      "\n",
      "The classification loss after processing this batch is:  0.15715265274047852\n",
      "The representation loss after processing this batch is:  0.0022722743451595306\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.04159216210246086\n",
      "The representation loss after processing this batch is:  0.002438157796859741\n",
      "\n",
      "The classification loss after processing this batch is:  0.046774525195360184\n",
      "The representation loss after processing this batch is:  0.002456091344356537\n",
      "\n",
      "The classification loss after processing this batch is:  0.06509849429130554\n",
      "The representation loss after processing this batch is:  0.0025055594742298126\n",
      "\n",
      "The classification loss after processing this batch is:  0.05460728704929352\n",
      "The representation loss after processing this batch is:  0.002707570791244507\n",
      "\n",
      "The classification loss after processing this batch is:  0.08994493633508682\n",
      "The representation loss after processing this batch is:  0.002729792147874832\n",
      "\n",
      "The classification loss after processing this batch is:  0.05956106632947922\n",
      "The representation loss after processing this batch is:  0.0023849010467529297\n",
      "\n",
      "The classification loss after processing this batch is:  0.07186023890972137\n",
      "The representation loss after processing this batch is:  0.0022875741124153137\n",
      "\n",
      "The classification loss after processing this batch is:  0.1279754936695099\n",
      "The representation loss after processing this batch is:  0.0025843828916549683\n",
      "\n",
      "The classification loss after processing this batch is:  0.15411312878131866\n",
      "The representation loss after processing this batch is:  0.002757541835308075\n",
      "\n",
      "The classification loss after processing this batch is:  0.14749284088611603\n",
      "The representation loss after processing this batch is:  0.002461608499288559\n",
      "\n",
      "The classification loss after processing this batch is:  0.14381474256515503\n",
      "The representation loss after processing this batch is:  0.0027731433510780334\n",
      "\n",
      "The classification loss after processing this batch is:  0.15795806050300598\n",
      "The representation loss after processing this batch is:  0.0023664385080337524\n",
      "\n",
      "The classification loss after processing this batch is:  0.07207703590393066\n",
      "The representation loss after processing this batch is:  0.002435840666294098\n",
      "\n",
      "The classification loss after processing this batch is:  0.1367805153131485\n",
      "The representation loss after processing this batch is:  0.002664215862751007\n",
      "\n",
      "The classification loss after processing this batch is:  0.22920770943164825\n",
      "The representation loss after processing this batch is:  0.0026663318276405334\n",
      "\n",
      "The classification loss after processing this batch is:  0.09230952709913254\n",
      "The representation loss after processing this batch is:  0.00245511531829834\n",
      "\n",
      "The classification loss after processing this batch is:  0.1418759673833847\n",
      "The representation loss after processing this batch is:  0.0023678913712501526\n",
      "\n",
      "The classification loss after processing this batch is:  0.15122108161449432\n",
      "The representation loss after processing this batch is:  0.0023960769176483154\n",
      "\n",
      "The classification loss after processing this batch is:  0.12665489315986633\n",
      "The representation loss after processing this batch is:  0.0023183301091194153\n",
      "\n",
      "The classification loss after processing this batch is:  0.07284197956323624\n",
      "The representation loss after processing this batch is:  0.0026181936264038086\n",
      "\n",
      "The classification loss after processing this batch is:  0.06952977925539017\n",
      "The representation loss after processing this batch is:  0.002532191574573517\n",
      "\n",
      "The classification loss after processing this batch is:  0.09498030692338943\n",
      "The representation loss after processing this batch is:  0.002376072108745575\n",
      "\n",
      "The classification loss after processing this batch is:  0.04853781685233116\n",
      "The representation loss after processing this batch is:  0.002629600465297699\n",
      "\n",
      "The classification loss after processing this batch is:  0.03084494359791279\n",
      "The representation loss after processing this batch is:  0.0024553686380386353\n",
      "\n",
      "The classification loss after processing this batch is:  0.12333161383867264\n",
      "The representation loss after processing this batch is:  0.003024876117706299\n",
      "\n",
      "The classification loss after processing this batch is:  0.04119675233960152\n",
      "The representation loss after processing this batch is:  0.003020547330379486\n",
      "\n",
      "The classification loss after processing this batch is:  0.19003671407699585\n",
      "The representation loss after processing this batch is:  0.002984173595905304\n",
      "\n",
      "The classification loss after processing this batch is:  0.11075370758771896\n",
      "The representation loss after processing this batch is:  0.002588033676147461\n",
      "\n",
      "The classification loss after processing this batch is:  0.1785544604063034\n",
      "The representation loss after processing this batch is:  0.0027300789952278137\n",
      "\n",
      "The classification loss after processing this batch is:  0.3175971210002899\n",
      "The representation loss after processing this batch is:  0.0021602027118206024\n",
      "\n",
      "The classification loss after processing this batch is:  0.12626810371875763\n",
      "The representation loss after processing this batch is:  0.0024331510066986084\n",
      "\n",
      "The classification loss after processing this batch is:  0.038859374821186066\n",
      "The representation loss after processing this batch is:  0.0025501996278762817\n",
      "\n",
      "The classification loss after processing this batch is:  0.07318618893623352\n",
      "The representation loss after processing this batch is:  0.0028981640934944153\n",
      "\n",
      "The classification loss after processing this batch is:  0.05195683240890503\n",
      "The representation loss after processing this batch is:  0.0028047412633895874\n",
      "\n",
      "The classification loss after processing this batch is:  0.06258692592382431\n",
      "The representation loss after processing this batch is:  0.00268670916557312\n",
      "\n",
      "The classification loss after processing this batch is:  0.07175889611244202\n",
      "The representation loss after processing this batch is:  0.0023922212421894073\n",
      "\n",
      "The classification loss after processing this batch is:  0.1711323857307434\n",
      "The representation loss after processing this batch is:  0.0024731047451496124\n",
      "\n",
      "The classification loss after processing this batch is:  0.13937172293663025\n",
      "The representation loss after processing this batch is:  0.002623472362756729\n",
      "\n",
      "The classification loss after processing this batch is:  0.12582683563232422\n",
      "The representation loss after processing this batch is:  0.0031859949231147766\n",
      "\n",
      "The classification loss after processing this batch is:  0.211344376206398\n",
      "The representation loss after processing this batch is:  0.003356441855430603\n",
      "\n",
      "The classification loss after processing this batch is:  0.09028077125549316\n",
      "The representation loss after processing this batch is:  0.0026347339153289795\n",
      "\n",
      "The classification loss after processing this batch is:  0.1061614379286766\n",
      "The representation loss after processing this batch is:  0.0026287324726581573\n",
      "\n",
      "The classification loss after processing this batch is:  0.1668654829263687\n",
      "The representation loss after processing this batch is:  0.0025392621755599976\n",
      "\n",
      "The classification loss after processing this batch is:  0.10319997370243073\n",
      "The representation loss after processing this batch is:  0.0029974952340126038\n",
      "\n",
      "The classification loss after processing this batch is:  0.13742873072624207\n",
      "The representation loss after processing this batch is:  0.0037555992603302\n",
      "\n",
      "The classification loss after processing this batch is:  0.06112867221236229\n",
      "The representation loss after processing this batch is:  0.0026812665164470673\n",
      "\n",
      "The classification loss after processing this batch is:  0.14654676616191864\n",
      "The representation loss after processing this batch is:  0.002975448966026306\n",
      "\n",
      "The classification loss after processing this batch is:  0.1392877995967865\n",
      "The representation loss after processing this batch is:  0.003152802586555481\n",
      "\n",
      "The classification loss after processing this batch is:  0.08737924695014954\n",
      "The representation loss after processing this batch is:  0.003283478319644928\n",
      "\n",
      "The classification loss after processing this batch is:  0.1312563121318817\n",
      "The representation loss after processing this batch is:  0.0027293264865875244\n",
      "\n",
      "The classification loss after processing this batch is:  0.14252907037734985\n",
      "The representation loss after processing this batch is:  0.0023354068398475647\n",
      "\n",
      "The classification loss after processing this batch is:  0.11533045023679733\n",
      "The representation loss after processing this batch is:  0.002401590347290039\n",
      "\n",
      "The classification loss after processing this batch is:  0.12235743552446365\n",
      "The representation loss after processing this batch is:  0.002529144287109375\n",
      "\n",
      "The classification loss after processing this batch is:  0.0949537381529808\n",
      "The representation loss after processing this batch is:  0.002817712724208832\n",
      "\n",
      "The classification loss after processing this batch is:  0.02838006801903248\n",
      "The representation loss after processing this batch is:  0.0025860369205474854\n",
      "\n",
      "The classification loss after processing this batch is:  0.11592673510313034\n",
      "The representation loss after processing this batch is:  0.002684943377971649\n",
      "\n",
      "The classification loss after processing this batch is:  0.05172520503401756\n",
      "The representation loss after processing this batch is:  0.0028863176703453064\n",
      "\n",
      "The classification loss after processing this batch is:  0.23490643501281738\n",
      "The representation loss after processing this batch is:  0.002556905150413513\n",
      "\n",
      "The classification loss after processing this batch is:  0.05146521329879761\n",
      "The representation loss after processing this batch is:  0.0029036477208137512\n",
      "\n",
      "The classification loss after processing this batch is:  0.09505556523799896\n",
      "The representation loss after processing this batch is:  0.002517104148864746\n",
      "\n",
      "The classification loss after processing this batch is:  0.15765166282653809\n",
      "The representation loss after processing this batch is:  0.002822786569595337\n",
      "\n",
      "The classification loss after processing this batch is:  0.1102948859333992\n",
      "The representation loss after processing this batch is:  0.002798326313495636\n",
      "\n",
      "The classification loss after processing this batch is:  0.12790605425834656\n",
      "The representation loss after processing this batch is:  0.0025223195552825928\n",
      "\n",
      "The classification loss after processing this batch is:  0.07619159668684006\n",
      "The representation loss after processing this batch is:  0.0024916082620620728\n",
      "\n",
      "The classification loss after processing this batch is:  0.06016353517770767\n",
      "The representation loss after processing this batch is:  0.0024461261928081512\n",
      "\n",
      "The classification loss after processing this batch is:  0.08432256430387497\n",
      "The representation loss after processing this batch is:  0.00236453115940094\n",
      "\n",
      "The classification loss after processing this batch is:  0.17275327444076538\n",
      "The representation loss after processing this batch is:  0.0028039216995239258\n",
      "\n",
      "The classification loss after processing this batch is:  0.18131861090660095\n",
      "The representation loss after processing this batch is:  0.0025472119450569153\n",
      "\n",
      "The classification loss after processing this batch is:  0.14725670218467712\n",
      "The representation loss after processing this batch is:  0.0021033845841884613\n",
      "\n",
      "The classification loss after processing this batch is:  0.13036386668682098\n",
      "The representation loss after processing this batch is:  0.0024627074599266052\n",
      "\n",
      "The classification loss after processing this batch is:  0.22291140258312225\n",
      "The representation loss after processing this batch is:  0.00255763903260231\n",
      "\n",
      "The classification loss after processing this batch is:  0.0957324281334877\n",
      "The representation loss after processing this batch is:  0.0028131455183029175\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.20286209881305695\n",
      "The representation loss after processing this batch is:  0.0028227418661117554\n",
      "\n",
      "The classification loss after processing this batch is:  0.09958114475011826\n",
      "The representation loss after processing this batch is:  0.002776794135570526\n",
      "\n",
      "The classification loss after processing this batch is:  0.05565835162997246\n",
      "The representation loss after processing this batch is:  0.0026476383209228516\n",
      "\n",
      "The classification loss after processing this batch is:  0.04015107825398445\n",
      "The representation loss after processing this batch is:  0.002447180449962616\n",
      "\n",
      "The classification loss after processing this batch is:  0.05267653986811638\n",
      "The representation loss after processing this batch is:  0.002506531774997711\n",
      "\n",
      "The classification loss after processing this batch is:  0.18651704490184784\n",
      "The representation loss after processing this batch is:  0.002652183175086975\n",
      "\n",
      "The classification loss after processing this batch is:  0.06036371365189552\n",
      "The representation loss after processing this batch is:  0.002723380923271179\n",
      "\n",
      "The classification loss after processing this batch is:  0.12471172213554382\n",
      "The representation loss after processing this batch is:  0.0027164220809936523\n",
      "\n",
      "The classification loss after processing this batch is:  0.12084147334098816\n",
      "The representation loss after processing this batch is:  0.0028667673468589783\n",
      "\n",
      "The classification loss after processing this batch is:  0.08321212977170944\n",
      "The representation loss after processing this batch is:  0.002722717821598053\n",
      "\n",
      "The classification loss after processing this batch is:  0.05376093089580536\n",
      "The representation loss after processing this batch is:  0.0024449899792671204\n",
      "\n",
      "The classification loss after processing this batch is:  0.14926694333553314\n",
      "The representation loss after processing this batch is:  0.0024271756410598755\n",
      "\n",
      "The classification loss after processing this batch is:  0.1902306228876114\n",
      "The representation loss after processing this batch is:  0.002562806010246277\n",
      "\n",
      "The classification loss after processing this batch is:  0.15386530756950378\n",
      "The representation loss after processing this batch is:  0.0027952268719673157\n",
      "\n",
      "The classification loss after processing this batch is:  0.07576920837163925\n",
      "The representation loss after processing this batch is:  0.002497538924217224\n",
      "\n",
      "The classification loss after processing this batch is:  0.20307619869709015\n",
      "The representation loss after processing this batch is:  0.0024668611586093903\n",
      "\n",
      "The classification loss after processing this batch is:  0.05905822291970253\n",
      "The representation loss after processing this batch is:  0.0022077150642871857\n",
      "\n",
      "The classification loss after processing this batch is:  0.15272431075572968\n",
      "The representation loss after processing this batch is:  0.0024522095918655396\n",
      "\n",
      "The classification loss after processing this batch is:  0.15497484803199768\n",
      "The representation loss after processing this batch is:  0.002924211323261261\n",
      "\n",
      "The classification loss after processing this batch is:  0.11211172491312027\n",
      "The representation loss after processing this batch is:  0.0024716556072235107\n",
      "\n",
      "The classification loss after processing this batch is:  0.1486971527338028\n",
      "The representation loss after processing this batch is:  0.0028010010719299316\n",
      "\n",
      "The classification loss after processing this batch is:  0.11481054127216339\n",
      "The representation loss after processing this batch is:  0.0030447915196418762\n",
      "\n",
      "The classification loss after processing this batch is:  0.16412077844142914\n",
      "The representation loss after processing this batch is:  0.0025799646973609924\n",
      "\n",
      "The classification loss after processing this batch is:  0.2439345419406891\n",
      "The representation loss after processing this batch is:  0.0028055012226104736\n",
      "\n",
      "The classification loss after processing this batch is:  0.17039944231510162\n",
      "The representation loss after processing this batch is:  0.00259244441986084\n",
      "\n",
      "The classification loss after processing this batch is:  0.10116289556026459\n",
      "The representation loss after processing this batch is:  0.0026710331439971924\n",
      "\n",
      "The classification loss after processing this batch is:  0.07297325134277344\n",
      "The representation loss after processing this batch is:  0.0030594095587730408\n",
      "\n",
      "The classification loss after processing this batch is:  0.14784713089466095\n",
      "The representation loss after processing this batch is:  0.002346836030483246\n",
      "\n",
      "The classification loss after processing this batch is:  0.12313628941774368\n",
      "The representation loss after processing this batch is:  0.002421945333480835\n",
      "\n",
      "The classification loss after processing this batch is:  0.027430979534983635\n",
      "The representation loss after processing this batch is:  0.0024226680397987366\n",
      "\n",
      "The classification loss after processing this batch is:  0.11727762222290039\n",
      "The representation loss after processing this batch is:  0.0023727864027023315\n",
      "\n",
      "The classification loss after processing this batch is:  0.27726808190345764\n",
      "The representation loss after processing this batch is:  0.00295136496424675\n",
      "\n",
      "The classification loss after processing this batch is:  0.27252885699272156\n",
      "The representation loss after processing this batch is:  0.0028084293007850647\n",
      "\n",
      "The classification loss after processing this batch is:  0.21828457713127136\n",
      "The representation loss after processing this batch is:  0.0024938061833381653\n",
      "\n",
      "The classification loss after processing this batch is:  0.18510708212852478\n",
      "The representation loss after processing this batch is:  0.0025186799466609955\n",
      "\n",
      "The classification loss after processing this batch is:  0.05120532587170601\n",
      "The representation loss after processing this batch is:  0.002421189099550247\n",
      "\n",
      "The classification loss after processing this batch is:  0.16064119338989258\n",
      "The representation loss after processing this batch is:  0.002593427896499634\n",
      "\n",
      "The classification loss after processing this batch is:  0.13729803264141083\n",
      "The representation loss after processing this batch is:  0.0026779770851135254\n",
      "\n",
      "The classification loss after processing this batch is:  0.2132982313632965\n",
      "The representation loss after processing this batch is:  0.002856336534023285\n",
      "\n",
      "The classification loss after processing this batch is:  0.11800290644168854\n",
      "The representation loss after processing this batch is:  0.0027548447251319885\n",
      "\n",
      "The classification loss after processing this batch is:  0.08972581475973129\n",
      "The representation loss after processing this batch is:  0.0031019598245620728\n",
      "\n",
      "The classification loss after processing this batch is:  0.07140327990055084\n",
      "The representation loss after processing this batch is:  0.0027262642979621887\n",
      "\n",
      "The classification loss after processing this batch is:  0.11572591960430145\n",
      "The representation loss after processing this batch is:  0.0025596842169761658\n",
      "\n",
      "The classification loss after processing this batch is:  0.17108197510242462\n",
      "The representation loss after processing this batch is:  0.0028828829526901245\n",
      "\n",
      "The classification loss after processing this batch is:  0.13798055052757263\n",
      "The representation loss after processing this batch is:  0.0024592503905296326\n",
      "\n",
      "The classification loss after processing this batch is:  0.06258714944124222\n",
      "The representation loss after processing this batch is:  0.002307601273059845\n",
      "\n",
      "The classification loss after processing this batch is:  0.25800344347953796\n",
      "The representation loss after processing this batch is:  0.0031252168118953705\n",
      "\n",
      "The classification loss after processing this batch is:  0.3323017656803131\n",
      "The representation loss after processing this batch is:  0.0031420476734638214\n",
      "\n",
      "The classification loss after processing this batch is:  0.18580466508865356\n",
      "The representation loss after processing this batch is:  0.0028560087084770203\n",
      "\n",
      "The classification loss after processing this batch is:  0.09937863051891327\n",
      "The representation loss after processing this batch is:  0.0029619932174682617\n",
      "\n",
      "The classification loss after processing this batch is:  0.09924852102994919\n",
      "The representation loss after processing this batch is:  0.0026514828205108643\n",
      "\n",
      "The classification loss after processing this batch is:  0.07167807966470718\n",
      "The representation loss after processing this batch is:  0.0027795881032943726\n",
      "\n",
      "The classification loss after processing this batch is:  0.22864462435245514\n",
      "The representation loss after processing this batch is:  0.002577386796474457\n",
      "\n",
      "The classification loss after processing this batch is:  0.14520423114299774\n",
      "The representation loss after processing this batch is:  0.0030980482697486877\n",
      "\n",
      "The classification loss after processing this batch is:  0.12071888148784637\n",
      "The representation loss after processing this batch is:  0.0032074376940727234\n",
      "\n",
      "The classification loss after processing this batch is:  0.22026804089546204\n",
      "The representation loss after processing this batch is:  0.0025972649455070496\n",
      "\n",
      "The classification loss after processing this batch is:  0.02825555019080639\n",
      "The representation loss after processing this batch is:  0.0025578588247299194\n",
      "\n",
      "The classification loss after processing this batch is:  0.03730526939034462\n",
      "The representation loss after processing this batch is:  0.0027616918087005615\n",
      "\n",
      "The classification loss after processing this batch is:  0.08439428359270096\n",
      "The representation loss after processing this batch is:  0.0027126744389533997\n",
      "\n",
      "The classification loss after processing this batch is:  0.12217599898576736\n",
      "The representation loss after processing this batch is:  0.0023090168833732605\n",
      "\n",
      "The classification loss after processing this batch is:  0.14990343153476715\n",
      "The representation loss after processing this batch is:  0.0026231706142425537\n",
      "\n",
      "The classification loss after processing this batch is:  0.09465229511260986\n",
      "The representation loss after processing this batch is:  0.002688273787498474\n",
      "\n",
      "The classification loss after processing this batch is:  0.11605939269065857\n",
      "The representation loss after processing this batch is:  0.002688303589820862\n",
      "\n",
      "The classification loss after processing this batch is:  0.036313388496637344\n",
      "The representation loss after processing this batch is:  0.0025158971548080444\n",
      "\n",
      "The classification loss after processing this batch is:  0.08669231086969376\n",
      "The representation loss after processing this batch is:  0.0023546814918518066\n",
      "\n",
      "The classification loss after processing this batch is:  0.06807329505681992\n",
      "The representation loss after processing this batch is:  0.0027373135089874268\n",
      "\n",
      "The classification loss after processing this batch is:  0.0585191436111927\n",
      "The representation loss after processing this batch is:  0.002906233072280884\n",
      "\n",
      "The classification loss after processing this batch is:  0.08644802123308182\n",
      "The representation loss after processing this batch is:  0.0024874769151210785\n",
      "\n",
      "The classification loss after processing this batch is:  0.12646836042404175\n",
      "The representation loss after processing this batch is:  0.0024387016892433167\n",
      "\n",
      "The classification loss after processing this batch is:  0.1670016646385193\n",
      "The representation loss after processing this batch is:  0.002726525068283081\n",
      "\n",
      "The classification loss after processing this batch is:  0.03964376449584961\n",
      "The representation loss after processing this batch is:  0.002423655241727829\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.05101462081074715\n",
      "The representation loss after processing this batch is:  0.0026129037141799927\n",
      "\n",
      "The classification loss after processing this batch is:  0.07155691087245941\n",
      "The representation loss after processing this batch is:  0.0030061453580856323\n",
      "\n",
      "The classification loss after processing this batch is:  0.13922065496444702\n",
      "The representation loss after processing this batch is:  0.0027713365852832794\n",
      "\n",
      "The classification loss after processing this batch is:  0.06453357636928558\n",
      "The representation loss after processing this batch is:  0.00337798148393631\n",
      "\n",
      "The classification loss after processing this batch is:  0.1331022083759308\n",
      "The representation loss after processing this batch is:  0.002958826720714569\n",
      "\n",
      "The classification loss after processing this batch is:  0.16378775238990784\n",
      "The representation loss after processing this batch is:  0.002678077667951584\n",
      "\n",
      "The classification loss after processing this batch is:  0.1391734927892685\n",
      "The representation loss after processing this batch is:  0.002886541187763214\n",
      "\n",
      "The classification loss after processing this batch is:  0.16308018565177917\n",
      "The representation loss after processing this batch is:  0.0027100220322608948\n",
      "\n",
      "The classification loss after processing this batch is:  0.06763450056314468\n",
      "The representation loss after processing this batch is:  0.002691827714443207\n",
      "\n",
      "The classification loss after processing this batch is:  0.11401661485433578\n",
      "The representation loss after processing this batch is:  0.00244208425283432\n",
      "\n",
      "The classification loss after processing this batch is:  0.13566388189792633\n",
      "The representation loss after processing this batch is:  0.0024240612983703613\n",
      "\n",
      "The classification loss after processing this batch is:  0.07096054404973984\n",
      "The representation loss after processing this batch is:  0.0026240721344947815\n",
      "\n",
      "The classification loss after processing this batch is:  0.02370590716600418\n",
      "The representation loss after processing this batch is:  0.002430953085422516\n",
      "\n",
      "The classification loss after processing this batch is:  0.22427526116371155\n",
      "The representation loss after processing this batch is:  0.002728693187236786\n",
      "\n",
      "The classification loss after processing this batch is:  0.26877060532569885\n",
      "The representation loss after processing this batch is:  0.0025066621601581573\n",
      "\n",
      "The classification loss after processing this batch is:  0.08588294684886932\n",
      "The representation loss after processing this batch is:  0.0025723427534103394\n",
      "\n",
      "The classification loss after processing this batch is:  0.22115764021873474\n",
      "The representation loss after processing this batch is:  0.0026401206851005554\n",
      "\n",
      "The classification loss after processing this batch is:  0.21197302639484406\n",
      "The representation loss after processing this batch is:  0.0027544423937797546\n",
      "\n",
      "The classification loss after processing this batch is:  0.29096323251724243\n",
      "The representation loss after processing this batch is:  0.0027514472603797913\n",
      "\n",
      "The classification loss after processing this batch is:  0.13771842420101166\n",
      "The representation loss after processing this batch is:  0.002691134810447693\n",
      "\n",
      "The classification loss after processing this batch is:  0.09543432295322418\n",
      "The representation loss after processing this batch is:  0.002644568681716919\n",
      "\n",
      "The classification loss after processing this batch is:  0.1383635550737381\n",
      "The representation loss after processing this batch is:  0.0029992684721946716\n",
      "\n",
      "The classification loss after processing this batch is:  0.06447569280862808\n",
      "The representation loss after processing this batch is:  0.002756550908088684\n",
      "\n",
      "The classification loss after processing this batch is:  0.039801571518182755\n",
      "The representation loss after processing this batch is:  0.002627655863761902\n",
      "\n",
      "The classification loss after processing this batch is:  0.06364839524030685\n",
      "The representation loss after processing this batch is:  0.0024598389863967896\n",
      "\n",
      "The classification loss after processing this batch is:  0.0559086874127388\n",
      "The representation loss after processing this batch is:  0.0027539432048797607\n",
      "\n",
      "The classification loss after processing this batch is:  0.034976761788129807\n",
      "The representation loss after processing this batch is:  0.0025741979479789734\n",
      "\n",
      "The classification loss after processing this batch is:  0.1219143494963646\n",
      "The representation loss after processing this batch is:  0.0025944747030735016\n",
      "\n",
      "The classification loss after processing this batch is:  0.11738595366477966\n",
      "The representation loss after processing this batch is:  0.0023934394121170044\n",
      "\n",
      "The classification loss after processing this batch is:  0.058862194418907166\n",
      "The representation loss after processing this batch is:  0.00273992121219635\n",
      "\n",
      "The classification loss after processing this batch is:  0.10327522456645966\n",
      "The representation loss after processing this batch is:  0.002586051821708679\n",
      "\n",
      "The classification loss after processing this batch is:  0.09890295565128326\n",
      "The representation loss after processing this batch is:  0.0027674436569213867\n",
      "\n",
      "The classification loss after processing this batch is:  0.03400826454162598\n",
      "The representation loss after processing this batch is:  0.002781316637992859\n",
      "\n",
      "The classification loss after processing this batch is:  0.17349883913993835\n",
      "The representation loss after processing this batch is:  0.0026877298951148987\n",
      "\n",
      "The classification loss after processing this batch is:  0.07427644729614258\n",
      "The representation loss after processing this batch is:  0.002527661621570587\n",
      "\n",
      "The classification loss after processing this batch is:  0.245217427611351\n",
      "The representation loss after processing this batch is:  0.0023290663957595825\n",
      "\n",
      "The classification loss after processing this batch is:  0.11156852543354034\n",
      "The representation loss after processing this batch is:  0.0028848201036453247\n",
      "\n",
      "The classification loss after processing this batch is:  0.11200132966041565\n",
      "The representation loss after processing this batch is:  0.002339862287044525\n",
      "\n",
      "The classification loss after processing this batch is:  0.04080085828900337\n",
      "The representation loss after processing this batch is:  0.0025181248784065247\n",
      "\n",
      "The classification loss after processing this batch is:  0.03608306124806404\n",
      "The representation loss after processing this batch is:  0.002522289752960205\n",
      "\n",
      "The classification loss after processing this batch is:  0.1472669541835785\n",
      "The representation loss after processing this batch is:  0.002578325569629669\n",
      "\n",
      "The classification loss after processing this batch is:  0.03640584647655487\n",
      "The representation loss after processing this batch is:  0.002873562276363373\n",
      "\n",
      "The classification loss after processing this batch is:  0.09619360417127609\n",
      "The representation loss after processing this batch is:  0.002740710973739624\n",
      "\n",
      "The classification loss after processing this batch is:  0.0766487792134285\n",
      "The representation loss after processing this batch is:  0.002649664878845215\n",
      "\n",
      "The classification loss after processing this batch is:  0.08879794180393219\n",
      "The representation loss after processing this batch is:  0.002870112657546997\n",
      "\n",
      "The classification loss after processing this batch is:  0.10774333029985428\n",
      "The representation loss after processing this batch is:  0.0026773810386657715\n",
      "\n",
      "The classification loss after processing this batch is:  0.08268465846776962\n",
      "The representation loss after processing this batch is:  0.0026941969990730286\n",
      "\n",
      "The classification loss after processing this batch is:  0.12718842923641205\n",
      "The representation loss after processing this batch is:  0.002782277762889862\n",
      "\n",
      "The classification loss after processing this batch is:  0.14322544634342194\n",
      "The representation loss after processing this batch is:  0.0025167912244796753\n",
      "\n",
      "The classification loss after processing this batch is:  0.13689742982387543\n",
      "The representation loss after processing this batch is:  0.0028635039925575256\n",
      "\n",
      "The classification loss after processing this batch is:  0.16014732420444489\n",
      "The representation loss after processing this batch is:  0.0026848837733268738\n",
      "\n",
      "The classification loss after processing this batch is:  0.19012750685214996\n",
      "The representation loss after processing this batch is:  0.0027070343494415283\n",
      "\n",
      "The classification loss after processing this batch is:  0.11992757022380829\n",
      "The representation loss after processing this batch is:  0.0025394707918167114\n",
      "\n",
      "The classification loss after processing this batch is:  0.09114599972963333\n",
      "The representation loss after processing this batch is:  0.002545878291130066\n",
      "\n",
      "The classification loss after processing this batch is:  0.061955925077199936\n",
      "The representation loss after processing this batch is:  0.002543993294239044\n",
      "\n",
      "The classification loss after processing this batch is:  0.07342351227998734\n",
      "The representation loss after processing this batch is:  0.002690650522708893\n",
      "\n",
      "The classification loss after processing this batch is:  0.06084894761443138\n",
      "The representation loss after processing this batch is:  0.0027506202459335327\n",
      "\n",
      "The classification loss after processing this batch is:  0.0851588025689125\n",
      "The representation loss after processing this batch is:  0.0022995732724666595\n",
      "\n",
      "The classification loss after processing this batch is:  0.07186897099018097\n",
      "The representation loss after processing this batch is:  0.0026768967509269714\n",
      "\n",
      "The classification loss after processing this batch is:  0.08831632882356644\n",
      "The representation loss after processing this batch is:  0.002860158681869507\n",
      "\n",
      "The classification loss after processing this batch is:  0.058903492987155914\n",
      "The representation loss after processing this batch is:  0.0025508105754852295\n",
      "\n",
      "The classification loss after processing this batch is:  0.1333933025598526\n",
      "The representation loss after processing this batch is:  0.0025184080004692078\n",
      "\n",
      "The classification loss after processing this batch is:  0.06851055473089218\n",
      "The representation loss after processing this batch is:  0.002839423716068268\n",
      "\n",
      "The classification loss after processing this batch is:  0.1384439766407013\n",
      "The representation loss after processing this batch is:  0.0026074424386024475\n",
      "\n",
      "The classification loss after processing this batch is:  0.12697812914848328\n",
      "The representation loss after processing this batch is:  0.002820901572704315\n",
      "\n",
      "The classification loss after processing this batch is:  0.09275422990322113\n",
      "The representation loss after processing this batch is:  0.0027470067143440247\n",
      "\n",
      "The classification loss after processing this batch is:  0.08020850270986557\n",
      "The representation loss after processing this batch is:  0.0028300508856773376\n",
      "\n",
      "The classification loss after processing this batch is:  0.1754557490348816\n",
      "The representation loss after processing this batch is:  0.0026843026280403137\n",
      "\n",
      "The classification loss after processing this batch is:  0.055716730654239655\n",
      "The representation loss after processing this batch is:  0.0027607083320617676\n",
      "\n",
      "The classification loss after processing this batch is:  0.05378514528274536\n",
      "The representation loss after processing this batch is:  0.0025288909673690796\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.0826498344540596\n",
      "The representation loss after processing this batch is:  0.00246284157037735\n",
      "\n",
      "The classification loss after processing this batch is:  0.05648045614361763\n",
      "The representation loss after processing this batch is:  0.0025380179286003113\n",
      "\n",
      "The classification loss after processing this batch is:  0.15870675444602966\n",
      "The representation loss after processing this batch is:  0.0022352375090122223\n",
      "\n",
      "The classification loss after processing this batch is:  0.1480688452720642\n",
      "The representation loss after processing this batch is:  0.002469174563884735\n",
      "\n",
      "The classification loss after processing this batch is:  0.11360753327608109\n",
      "The representation loss after processing this batch is:  0.0030393078923225403\n",
      "\n",
      "The classification loss after processing this batch is:  0.07639899104833603\n",
      "The representation loss after processing this batch is:  0.002937518060207367\n",
      "\n",
      "The classification loss after processing this batch is:  0.10882660746574402\n",
      "The representation loss after processing this batch is:  0.0026003196835517883\n",
      "\n",
      "The classification loss after processing this batch is:  0.21563299000263214\n",
      "The representation loss after processing this batch is:  0.0026709139347076416\n",
      "\n",
      "The classification loss after processing this batch is:  0.03704703226685524\n",
      "The representation loss after processing this batch is:  0.0027136802673339844\n",
      "\n",
      "The classification loss after processing this batch is:  0.07281407713890076\n",
      "The representation loss after processing this batch is:  0.002882331609725952\n",
      "\n",
      "The classification loss after processing this batch is:  0.15670372545719147\n",
      "The representation loss after processing this batch is:  0.002375096082687378\n",
      "\n",
      "The classification loss after processing this batch is:  0.29087623953819275\n",
      "The representation loss after processing this batch is:  0.002767398953437805\n",
      "\n",
      "The classification loss after processing this batch is:  0.07373059540987015\n",
      "The representation loss after processing this batch is:  0.0024761036038398743\n",
      "\n",
      "The classification loss after processing this batch is:  0.13677161931991577\n",
      "The representation loss after processing this batch is:  0.0022425130009651184\n",
      "\n",
      "The classification loss after processing this batch is:  0.06711377948522568\n",
      "The representation loss after processing this batch is:  0.002583235502243042\n",
      "\n",
      "The classification loss after processing this batch is:  0.04198533669114113\n",
      "The representation loss after processing this batch is:  0.0027972757816314697\n",
      "\n",
      "The classification loss after processing this batch is:  0.09998147934675217\n",
      "The representation loss after processing this batch is:  0.003184989094734192\n",
      "\n",
      "The classification loss after processing this batch is:  0.10364066809415817\n",
      "The representation loss after processing this batch is:  0.0035503506660461426\n",
      "\n",
      "The classification loss after processing this batch is:  0.052391450852155685\n",
      "The representation loss after processing this batch is:  0.0029967576265335083\n",
      "\n",
      "The classification loss after processing this batch is:  0.047027040272951126\n",
      "The representation loss after processing this batch is:  0.0023657232522964478\n",
      "\n",
      "The classification loss after processing this batch is:  0.13360710442066193\n",
      "The representation loss after processing this batch is:  0.002798374742269516\n",
      "\n",
      "The classification loss after processing this batch is:  0.09241048991680145\n",
      "The representation loss after processing this batch is:  0.0026417747139930725\n",
      "\n",
      "The classification loss after processing this batch is:  0.06658884137868881\n",
      "The representation loss after processing this batch is:  0.0023883357644081116\n",
      "\n",
      "The classification loss after processing this batch is:  0.05846044048666954\n",
      "The representation loss after processing this batch is:  0.0028451085090637207\n",
      "\n",
      "The classification loss after processing this batch is:  0.1329595148563385\n",
      "The representation loss after processing this batch is:  0.0025874823331832886\n",
      "\n",
      "The classification loss after processing this batch is:  0.13744156062602997\n",
      "The representation loss after processing this batch is:  0.002723991870880127\n",
      "\n",
      "The classification loss after processing this batch is:  0.20955295860767365\n",
      "The representation loss after processing this batch is:  0.002319231629371643\n",
      "\n",
      "The classification loss after processing this batch is:  0.10639194399118423\n",
      "The representation loss after processing this batch is:  0.002680569887161255\n",
      "\n",
      "The classification loss after processing this batch is:  0.20223930478096008\n",
      "The representation loss after processing this batch is:  0.0025139078497886658\n",
      "\n",
      "The classification loss after processing this batch is:  0.07248194515705109\n",
      "The representation loss after processing this batch is:  0.0029446110129356384\n",
      "\n",
      "The classification loss after processing this batch is:  0.08075583726167679\n",
      "The representation loss after processing this batch is:  0.003077685832977295\n",
      "\n",
      "The classification loss after processing this batch is:  0.05960815027356148\n",
      "The representation loss after processing this batch is:  0.002539902925491333\n",
      "\n",
      "The classification loss after processing this batch is:  0.053210046142339706\n",
      "The representation loss after processing this batch is:  0.0024844855070114136\n",
      "\n",
      "The classification loss after processing this batch is:  0.15619990229606628\n",
      "The representation loss after processing this batch is:  0.002436775714159012\n",
      "\n",
      "The classification loss after processing this batch is:  0.07459141314029694\n",
      "The representation loss after processing this batch is:  0.0028580129146575928\n",
      "\n",
      "The classification loss after processing this batch is:  0.04426764324307442\n",
      "The representation loss after processing this batch is:  0.002532169222831726\n",
      "\n",
      "The classification loss after processing this batch is:  0.04561755806207657\n",
      "The representation loss after processing this batch is:  0.0032232478260993958\n",
      "\n",
      "The classification loss after processing this batch is:  0.023716533556580544\n",
      "The representation loss after processing this batch is:  0.00304335355758667\n",
      "\n",
      "The classification loss after processing this batch is:  0.051560092717409134\n",
      "The representation loss after processing this batch is:  0.003436170518398285\n",
      "\n",
      "The classification loss after processing this batch is:  0.06460431963205338\n",
      "The representation loss after processing this batch is:  0.002871014177799225\n",
      "\n",
      "The classification loss after processing this batch is:  0.043413516134023666\n",
      "The representation loss after processing this batch is:  0.002904072403907776\n",
      "\n",
      "The classification loss after processing this batch is:  0.012866481207311153\n",
      "The representation loss after processing this batch is:  0.002797916531562805\n",
      "\n",
      "The classification loss after processing this batch is:  0.03687550500035286\n",
      "The representation loss after processing this batch is:  0.0031498223543167114\n",
      "\n",
      "The classification loss after processing this batch is:  0.07506664097309113\n",
      "The representation loss after processing this batch is:  0.0035837069153785706\n",
      "\n",
      "The classification loss after processing this batch is:  0.011973905377089977\n",
      "The representation loss after processing this batch is:  0.0035919472575187683\n",
      "\n",
      "The classification loss after processing this batch is:  0.025288479402661324\n",
      "The representation loss after processing this batch is:  0.0030708536505699158\n",
      "\n",
      "The classification loss after processing this batch is:  0.171306774020195\n",
      "The representation loss after processing this batch is:  0.0029389262199401855\n",
      "\n",
      "The classification loss after processing this batch is:  0.03164670616388321\n",
      "The representation loss after processing this batch is:  0.003102131187915802\n",
      "\n",
      "The classification loss after processing this batch is:  0.015137982554733753\n",
      "The representation loss after processing this batch is:  0.0028482824563980103\n",
      "\n",
      "The classification loss after processing this batch is:  0.02966366522014141\n",
      "The representation loss after processing this batch is:  0.003310978412628174\n",
      "\n",
      "The classification loss after processing this batch is:  0.019737759605050087\n",
      "The representation loss after processing this batch is:  0.0029766038060188293\n",
      "\n",
      "The classification loss after processing this batch is:  0.01675141602754593\n",
      "The representation loss after processing this batch is:  0.0028255730867385864\n",
      "\n",
      "The classification loss after processing this batch is:  0.011458070948719978\n",
      "The representation loss after processing this batch is:  0.0032381415367126465\n",
      "\n",
      "The classification loss after processing this batch is:  0.012385932728648186\n",
      "The representation loss after processing this batch is:  0.0035230517387390137\n",
      "\n",
      "The classification loss after processing this batch is:  0.3562689423561096\n",
      "The representation loss after processing this batch is:  0.003630012273788452\n",
      "\n",
      "The classification loss after processing this batch is:  0.26806068420410156\n",
      "The representation loss after processing this batch is:  0.003420107066631317\n",
      "\n",
      "The classification loss after processing this batch is:  0.1855180561542511\n",
      "The representation loss after processing this batch is:  0.003867410123348236\n",
      "\n",
      "The classification loss after processing this batch is:  0.04144448786973953\n",
      "The representation loss after processing this batch is:  0.0029092207551002502\n",
      "\n",
      "The classification loss after processing this batch is:  0.011033455841243267\n",
      "The representation loss after processing this batch is:  0.003440156579017639\n",
      "\n",
      "The classification loss after processing this batch is:  0.011997182853519917\n",
      "The representation loss after processing this batch is:  0.002427719533443451\n",
      "\n",
      "The classification loss after processing this batch is:  0.08456102013587952\n",
      "The representation loss after processing this batch is:  0.0025785714387893677\n",
      "\n",
      "The classification loss after processing this batch is:  0.33033058047294617\n",
      "The representation loss after processing this batch is:  0.0029482319951057434\n",
      "\n",
      "The classification loss after processing this batch is:  0.050575144588947296\n",
      "The representation loss after processing this batch is:  0.0028046220541000366\n",
      "\n",
      "The classification loss after processing this batch is:  0.02993830107152462\n",
      "The representation loss after processing this batch is:  0.003371313214302063\n",
      "\n",
      "The classification loss after processing this batch is:  0.03704961761832237\n",
      "The representation loss after processing this batch is:  0.0032500773668289185\n",
      "\n",
      "The classification loss after processing this batch is:  0.03964487090706825\n",
      "The representation loss after processing this batch is:  0.003887549042701721\n",
      "\n",
      "The classification loss after processing this batch is:  0.10097608715295792\n",
      "The representation loss after processing this batch is:  0.0023887529969215393\n",
      "\n",
      "The classification loss after processing this batch is:  0.03307270258665085\n",
      "The representation loss after processing this batch is:  0.002442985773086548\n",
      "\n",
      "The classification loss after processing this batch is:  0.11190757900476456\n",
      "The representation loss after processing this batch is:  0.0024695992469787598\n",
      "\n",
      "The classification loss after processing this batch is:  0.11370429396629333\n",
      "The representation loss after processing this batch is:  0.002439826726913452\n",
      "\n",
      "The classification loss after processing this batch is:  0.154756560921669\n",
      "The representation loss after processing this batch is:  0.002670273184776306\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.03902873024344444\n",
      "The representation loss after processing this batch is:  0.0028392747044563293\n",
      "\n",
      "The classification loss after processing this batch is:  0.06864854693412781\n",
      "The representation loss after processing this batch is:  0.003049299120903015\n",
      "\n",
      "The classification loss after processing this batch is:  0.07441528141498566\n",
      "The representation loss after processing this batch is:  0.002440504729747772\n",
      "\n",
      "The classification loss after processing this batch is:  0.09810538589954376\n",
      "The representation loss after processing this batch is:  0.0024282261729240417\n",
      "\n",
      "The classification loss after processing this batch is:  0.08142553269863129\n",
      "The representation loss after processing this batch is:  0.002429276704788208\n",
      "\n",
      "The classification loss after processing this batch is:  0.1364542692899704\n",
      "The representation loss after processing this batch is:  0.002315431833267212\n",
      "\n",
      "The classification loss after processing this batch is:  0.08011102676391602\n",
      "The representation loss after processing this batch is:  0.0024874545633792877\n",
      "\n",
      "The classification loss after processing this batch is:  0.09890180081129074\n",
      "The representation loss after processing this batch is:  0.002939261496067047\n",
      "\n",
      "The classification loss after processing this batch is:  0.04571909084916115\n",
      "The representation loss after processing this batch is:  0.002642303705215454\n",
      "\n",
      "The classification loss after processing this batch is:  0.22639870643615723\n",
      "The representation loss after processing this batch is:  0.0026882998645305634\n",
      "\n",
      "The classification loss after processing this batch is:  0.1253259927034378\n",
      "The representation loss after processing this batch is:  0.0026279911398887634\n",
      "\n",
      "The classification loss after processing this batch is:  0.13783438503742218\n",
      "The representation loss after processing this batch is:  0.002581309527158737\n",
      "\n",
      "The classification loss after processing this batch is:  0.20480352640151978\n",
      "The representation loss after processing this batch is:  0.0032679662108421326\n",
      "\n",
      "The classification loss after processing this batch is:  0.12917466461658478\n",
      "The representation loss after processing this batch is:  0.002891331911087036\n",
      "\n",
      "The classification loss after processing this batch is:  0.06632924824953079\n",
      "The representation loss after processing this batch is:  0.0027518272399902344\n",
      "\n",
      "The classification loss after processing this batch is:  0.218583881855011\n",
      "The representation loss after processing this batch is:  0.0034530386328697205\n",
      "\n",
      "The classification loss after processing this batch is:  0.10620545595884323\n",
      "The representation loss after processing this batch is:  0.002891525626182556\n",
      "\n",
      "The classification loss after processing this batch is:  0.29367324709892273\n",
      "The representation loss after processing this batch is:  0.0028002113103866577\n",
      "\n",
      "The classification loss after processing this batch is:  0.07301446795463562\n",
      "The representation loss after processing this batch is:  0.002403348684310913\n",
      "\n",
      "The classification loss after processing this batch is:  0.0442860908806324\n",
      "The representation loss after processing this batch is:  0.002491481602191925\n",
      "\n",
      "The classification loss after processing this batch is:  0.07624182850122452\n",
      "The representation loss after processing this batch is:  0.002390623092651367\n",
      "\n",
      "The classification loss after processing this batch is:  0.09129304438829422\n",
      "The representation loss after processing this batch is:  0.002469286322593689\n",
      "\n",
      "The classification loss after processing this batch is:  0.053952932357788086\n",
      "The representation loss after processing this batch is:  0.002513110637664795\n",
      "\n",
      "The classification loss after processing this batch is:  0.054158229380846024\n",
      "The representation loss after processing this batch is:  0.002649255096912384\n",
      "\n",
      "The classification loss after processing this batch is:  0.046248748898506165\n",
      "The representation loss after processing this batch is:  0.002705097198486328\n",
      "\n",
      "The classification loss after processing this batch is:  0.036432985216379166\n",
      "The representation loss after processing this batch is:  0.0024578310549259186\n",
      "\n",
      "The classification loss after processing this batch is:  0.060506679117679596\n",
      "The representation loss after processing this batch is:  0.0027399063110351562\n",
      "\n",
      "The classification loss after processing this batch is:  0.15239156782627106\n",
      "The representation loss after processing this batch is:  0.002721250057220459\n",
      "\n",
      "The classification loss after processing this batch is:  0.06047435104846954\n",
      "The representation loss after processing this batch is:  0.003053322434425354\n",
      "\n",
      "The classification loss after processing this batch is:  0.10259048640727997\n",
      "The representation loss after processing this batch is:  0.0022417455911636353\n",
      "\n",
      "The classification loss after processing this batch is:  0.04366667568683624\n",
      "The representation loss after processing this batch is:  0.002666972577571869\n",
      "\n",
      "The classification loss after processing this batch is:  0.03598812595009804\n",
      "The representation loss after processing this batch is:  0.0026669204235076904\n",
      "\n",
      "The classification loss after processing this batch is:  0.11360261589288712\n",
      "The representation loss after processing this batch is:  0.002673625946044922\n",
      "\n",
      "The classification loss after processing this batch is:  0.03811099752783775\n",
      "The representation loss after processing this batch is:  0.002732507884502411\n",
      "\n",
      "The classification loss after processing this batch is:  0.03971407935023308\n",
      "The representation loss after processing this batch is:  0.0025754347443580627\n",
      "\n",
      "The classification loss after processing this batch is:  0.14069658517837524\n",
      "The representation loss after processing this batch is:  0.0027955472469329834\n",
      "\n",
      "The classification loss after processing this batch is:  0.07257100939750671\n",
      "The representation loss after processing this batch is:  0.0026176422834396362\n",
      "\n",
      "The classification loss after processing this batch is:  0.08731496334075928\n",
      "The representation loss after processing this batch is:  0.0022823624312877655\n",
      "\n",
      "The classification loss after processing this batch is:  0.1312781274318695\n",
      "The representation loss after processing this batch is:  0.002419501543045044\n",
      "\n",
      "The classification loss after processing this batch is:  0.09184245765209198\n",
      "The representation loss after processing this batch is:  0.0024839192628860474\n",
      "\n",
      "The classification loss after processing this batch is:  0.10424475371837616\n",
      "The representation loss after processing this batch is:  0.002283204346895218\n",
      "\n",
      "The classification loss after processing this batch is:  0.18753193318843842\n",
      "The representation loss after processing this batch is:  0.0025504380464553833\n",
      "\n",
      "The classification loss after processing this batch is:  0.04944970831274986\n",
      "The representation loss after processing this batch is:  0.002587743103504181\n",
      "\n",
      "The classification loss after processing this batch is:  0.1075081005692482\n",
      "The representation loss after processing this batch is:  0.002585366368293762\n",
      "\n",
      "The classification loss after processing this batch is:  0.057185035198926926\n",
      "The representation loss after processing this batch is:  0.0023913607001304626\n",
      "\n",
      "The classification loss after processing this batch is:  0.10012728720903397\n",
      "The representation loss after processing this batch is:  0.002687208354473114\n",
      "\n",
      "The classification loss after processing this batch is:  0.08276398479938507\n",
      "The representation loss after processing this batch is:  0.0028980448842048645\n",
      "\n",
      "The classification loss after processing this batch is:  0.045451972633600235\n",
      "The representation loss after processing this batch is:  0.0026528164744377136\n",
      "\n",
      "The classification loss after processing this batch is:  0.10095294564962387\n",
      "The representation loss after processing this batch is:  0.0025919154286384583\n",
      "\n",
      "The classification loss after processing this batch is:  0.08998803049325943\n",
      "The representation loss after processing this batch is:  0.0028183013200759888\n",
      "\n",
      "The classification loss after processing this batch is:  0.08836192637681961\n",
      "The representation loss after processing this batch is:  0.002613939344882965\n",
      "\n",
      "The classification loss after processing this batch is:  0.13675767183303833\n",
      "The representation loss after processing this batch is:  0.002343103289604187\n",
      "\n",
      "The classification loss after processing this batch is:  0.07931771129369736\n",
      "The representation loss after processing this batch is:  0.0029829666018486023\n",
      "\n",
      "The classification loss after processing this batch is:  0.1383790671825409\n",
      "The representation loss after processing this batch is:  0.002506926655769348\n",
      "\n",
      "The classification loss after processing this batch is:  0.07329514622688293\n",
      "The representation loss after processing this batch is:  0.002472691237926483\n",
      "\n",
      "The classification loss after processing this batch is:  0.039785344153642654\n",
      "The representation loss after processing this batch is:  0.002500224858522415\n",
      "\n",
      "The classification loss after processing this batch is:  0.12108400464057922\n",
      "The representation loss after processing this batch is:  0.0026456713676452637\n",
      "\n",
      "The classification loss after processing this batch is:  0.10364241898059845\n",
      "The representation loss after processing this batch is:  0.0025709569454193115\n",
      "\n",
      "The classification loss after processing this batch is:  0.06590946018695831\n",
      "The representation loss after processing this batch is:  0.0025307759642601013\n",
      "\n",
      "The classification loss after processing this batch is:  0.06900428980588913\n",
      "The representation loss after processing this batch is:  0.002450212836265564\n",
      "\n",
      "The classification loss after processing this batch is:  0.044395074248313904\n",
      "The representation loss after processing this batch is:  0.002374976873397827\n",
      "\n",
      "The classification loss after processing this batch is:  0.07902076095342636\n",
      "The representation loss after processing this batch is:  0.0026638731360435486\n",
      "\n",
      "The classification loss after processing this batch is:  0.11371965706348419\n",
      "The representation loss after processing this batch is:  0.00227230042219162\n",
      "\n",
      "The classification loss after processing this batch is:  0.05340924113988876\n",
      "The representation loss after processing this batch is:  0.0023267343640327454\n",
      "\n",
      "The classification loss after processing this batch is:  0.13876906037330627\n",
      "The representation loss after processing this batch is:  0.0027806349098682404\n",
      "\n",
      "The classification loss after processing this batch is:  0.09424688667058945\n",
      "The representation loss after processing this batch is:  0.0023220330476760864\n",
      "\n",
      "The classification loss after processing this batch is:  0.06427314877510071\n",
      "The representation loss after processing this batch is:  0.002558670938014984\n",
      "\n",
      "The classification loss after processing this batch is:  0.07096501439809799\n",
      "The representation loss after processing this batch is:  0.002217203378677368\n",
      "\n",
      "The classification loss after processing this batch is:  0.06376445293426514\n",
      "The representation loss after processing this batch is:  0.0027574896812438965\n",
      "\n",
      "The classification loss after processing this batch is:  0.08407007157802582\n",
      "The representation loss after processing this batch is:  0.0021790824830532074\n",
      "\n",
      "The classification loss after processing this batch is:  0.15226218104362488\n",
      "The representation loss after processing this batch is:  0.002556942403316498\n",
      "\n",
      "The classification loss after processing this batch is:  0.05064033716917038\n",
      "The representation loss after processing this batch is:  0.0024646520614624023\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.23807837069034576\n",
      "The representation loss after processing this batch is:  0.00247819721698761\n",
      "\n",
      "The classification loss after processing this batch is:  0.1041257455945015\n",
      "The representation loss after processing this batch is:  0.002495173364877701\n",
      "\n",
      "The classification loss after processing this batch is:  0.07070476561784744\n",
      "The representation loss after processing this batch is:  0.003081768751144409\n",
      "\n",
      "The classification loss after processing this batch is:  0.07720685750246048\n",
      "The representation loss after processing this batch is:  0.0026270896196365356\n",
      "\n",
      "The classification loss after processing this batch is:  0.06964258849620819\n",
      "The representation loss after processing this batch is:  0.0028683170676231384\n",
      "\n",
      "The classification loss after processing this batch is:  0.20355485379695892\n",
      "The representation loss after processing this batch is:  0.002871669828891754\n",
      "\n",
      "The classification loss after processing this batch is:  0.10180449485778809\n",
      "The representation loss after processing this batch is:  0.0025311484932899475\n",
      "\n",
      "The classification loss after processing this batch is:  0.12823157012462616\n",
      "The representation loss after processing this batch is:  0.0022201985120773315\n",
      "\n",
      "The classification loss after processing this batch is:  0.20380844175815582\n",
      "The representation loss after processing this batch is:  0.002450503408908844\n",
      "\n",
      "The classification loss after processing this batch is:  0.09480012953281403\n",
      "The representation loss after processing this batch is:  0.0023761317133903503\n",
      "\n",
      "The classification loss after processing this batch is:  0.041345205157995224\n",
      "The representation loss after processing this batch is:  0.002596147358417511\n",
      "\n",
      "The classification loss after processing this batch is:  0.11518359184265137\n",
      "The representation loss after processing this batch is:  0.0025819391012191772\n",
      "\n",
      "The classification loss after processing this batch is:  0.11856634169816971\n",
      "The representation loss after processing this batch is:  0.0023672282695770264\n",
      "\n",
      "The classification loss after processing this batch is:  0.12158193439245224\n",
      "The representation loss after processing this batch is:  0.0026371031999588013\n",
      "\n",
      "The classification loss after processing this batch is:  0.04871075972914696\n",
      "The representation loss after processing this batch is:  0.0022420063614845276\n",
      "\n",
      "The classification loss after processing this batch is:  0.11522365361452103\n",
      "The representation loss after processing this batch is:  0.0023245513439178467\n",
      "\n",
      "The classification loss after processing this batch is:  0.12417414784431458\n",
      "The representation loss after processing this batch is:  0.002428412437438965\n",
      "\n",
      "The classification loss after processing this batch is:  0.15070682764053345\n",
      "The representation loss after processing this batch is:  0.0027295276522636414\n",
      "\n",
      "The classification loss after processing this batch is:  0.1394629329442978\n",
      "The representation loss after processing this batch is:  0.002481020987033844\n",
      "\n",
      "The classification loss after processing this batch is:  0.10583548247814178\n",
      "The representation loss after processing this batch is:  0.0028022751212120056\n",
      "\n",
      "The classification loss after processing this batch is:  0.10348732769489288\n",
      "The representation loss after processing this batch is:  0.002970300614833832\n",
      "\n",
      "The classification loss after processing this batch is:  0.05660383775830269\n",
      "The representation loss after processing this batch is:  0.002954728901386261\n",
      "\n",
      "The classification loss after processing this batch is:  0.07362072914838791\n",
      "The representation loss after processing this batch is:  0.002571411430835724\n",
      "\n",
      "The classification loss after processing this batch is:  0.0388048030436039\n",
      "The representation loss after processing this batch is:  0.0025732964277267456\n",
      "\n",
      "The classification loss after processing this batch is:  0.12755705416202545\n",
      "The representation loss after processing this batch is:  0.0027120932936668396\n",
      "\n",
      "The classification loss after processing this batch is:  0.05979828163981438\n",
      "The representation loss after processing this batch is:  0.0027737990021705627\n",
      "\n",
      "The classification loss after processing this batch is:  0.20044870674610138\n",
      "The representation loss after processing this batch is:  0.002958439290523529\n",
      "\n",
      "The classification loss after processing this batch is:  0.2156166136264801\n",
      "The representation loss after processing this batch is:  0.002680942416191101\n",
      "\n",
      "The classification loss after processing this batch is:  0.07521375268697739\n",
      "The representation loss after processing this batch is:  0.0028577372431755066\n",
      "\n",
      "The classification loss after processing this batch is:  0.07672417163848877\n",
      "The representation loss after processing this batch is:  0.0027767345309257507\n",
      "\n",
      "The classification loss after processing this batch is:  0.1013568788766861\n",
      "The representation loss after processing this batch is:  0.002283550798892975\n",
      "\n",
      "The classification loss after processing this batch is:  0.03441769257187843\n",
      "The representation loss after processing this batch is:  0.0026640519499778748\n",
      "\n",
      "The classification loss after processing this batch is:  0.04923021420836449\n",
      "The representation loss after processing this batch is:  0.0026555135846138\n",
      "\n",
      "The classification loss after processing this batch is:  0.13185739517211914\n",
      "The representation loss after processing this batch is:  0.0023991912603378296\n",
      "\n",
      "The classification loss after processing this batch is:  0.06132074072957039\n",
      "The representation loss after processing this batch is:  0.0029933080077171326\n",
      "\n",
      "The classification loss after processing this batch is:  0.07806015014648438\n",
      "The representation loss after processing this batch is:  0.0026578158140182495\n",
      "\n",
      "The classification loss after processing this batch is:  0.18381842970848083\n",
      "The representation loss after processing this batch is:  0.003132961690425873\n",
      "\n",
      "The classification loss after processing this batch is:  0.19628126919269562\n",
      "The representation loss after processing this batch is:  0.0024771802127361298\n",
      "\n",
      "The classification loss after processing this batch is:  0.09242992103099823\n",
      "The representation loss after processing this batch is:  0.002612762153148651\n",
      "\n",
      "The classification loss after processing this batch is:  0.18344593048095703\n",
      "The representation loss after processing this batch is:  0.002848595380783081\n",
      "\n",
      "The classification loss after processing this batch is:  0.1304595023393631\n",
      "The representation loss after processing this batch is:  0.0024476051330566406\n",
      "\n",
      "The classification loss after processing this batch is:  0.06015675887465477\n",
      "The representation loss after processing this batch is:  0.0025168508291244507\n",
      "\n",
      "The classification loss after processing this batch is:  0.12925797700881958\n",
      "The representation loss after processing this batch is:  0.002354159951210022\n",
      "\n",
      "The classification loss after processing this batch is:  0.32483676075935364\n",
      "The representation loss after processing this batch is:  0.0029203370213508606\n",
      "\n",
      "The classification loss after processing this batch is:  0.13524892926216125\n",
      "The representation loss after processing this batch is:  0.0031403638422489166\n",
      "\n",
      "The classification loss after processing this batch is:  0.09112388640642166\n",
      "The representation loss after processing this batch is:  0.002857007086277008\n",
      "\n",
      "The classification loss after processing this batch is:  0.0502212829887867\n",
      "The representation loss after processing this batch is:  0.0028282925486564636\n",
      "\n",
      "The classification loss after processing this batch is:  0.06163419783115387\n",
      "The representation loss after processing this batch is:  0.002795480191707611\n",
      "\n",
      "The classification loss after processing this batch is:  0.10002028942108154\n",
      "The representation loss after processing this batch is:  0.0028326213359832764\n",
      "\n",
      "The classification loss after processing this batch is:  0.08837490528821945\n",
      "The representation loss after processing this batch is:  0.002773001790046692\n",
      "\n",
      "The classification loss after processing this batch is:  0.08895788341760635\n",
      "The representation loss after processing this batch is:  0.0025193952023983\n",
      "\n",
      "The classification loss after processing this batch is:  0.09951412677764893\n",
      "The representation loss after processing this batch is:  0.0026502758264541626\n",
      "\n",
      "The classification loss after processing this batch is:  0.1868768036365509\n",
      "The representation loss after processing this batch is:  0.002877339720726013\n",
      "\n",
      "The classification loss after processing this batch is:  0.05817734822630882\n",
      "The representation loss after processing this batch is:  0.0023856498301029205\n",
      "\n",
      "The classification loss after processing this batch is:  0.10751596093177795\n",
      "The representation loss after processing this batch is:  0.0022489354014396667\n",
      "\n",
      "The classification loss after processing this batch is:  0.08071441203355789\n",
      "The representation loss after processing this batch is:  0.0022953376173973083\n",
      "\n",
      "The classification loss after processing this batch is:  0.11023791879415512\n",
      "The representation loss after processing this batch is:  0.0025028809905052185\n",
      "\n",
      "The classification loss after processing this batch is:  0.08312930166721344\n",
      "The representation loss after processing this batch is:  0.0025337785482406616\n",
      "\n",
      "The classification loss after processing this batch is:  0.15872858464717865\n",
      "The representation loss after processing this batch is:  0.0025498121976852417\n",
      "\n",
      "The classification loss after processing this batch is:  0.12551209330558777\n",
      "The representation loss after processing this batch is:  0.002541378140449524\n",
      "\n",
      "The classification loss after processing this batch is:  0.13631318509578705\n",
      "The representation loss after processing this batch is:  0.0024765171110630035\n",
      "\n",
      "The classification loss after processing this batch is:  0.0595182329416275\n",
      "The representation loss after processing this batch is:  0.0026909038424491882\n",
      "\n",
      "The classification loss after processing this batch is:  0.19495394825935364\n",
      "The representation loss after processing this batch is:  0.0025538206100463867\n",
      "\n",
      "The classification loss after processing this batch is:  0.1441057175397873\n",
      "The representation loss after processing this batch is:  0.002772308886051178\n",
      "\n",
      "The classification loss after processing this batch is:  0.1497645378112793\n",
      "The representation loss after processing this batch is:  0.002755582332611084\n",
      "\n",
      "The classification loss after processing this batch is:  0.0630049929022789\n",
      "The representation loss after processing this batch is:  0.002902098000049591\n",
      "\n",
      "The classification loss after processing this batch is:  0.08065994083881378\n",
      "The representation loss after processing this batch is:  0.0031395703554153442\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.22271201014518738\n",
      "The representation loss after processing this batch is:  0.0026467740535736084\n",
      "\n",
      "The classification loss after processing this batch is:  0.1958409994840622\n",
      "The representation loss after processing this batch is:  0.0023836754262447357\n",
      "\n",
      "The classification loss after processing this batch is:  0.22019796073436737\n",
      "The representation loss after processing this batch is:  0.0029038116335868835\n",
      "\n",
      "The classification loss after processing this batch is:  0.2807518541812897\n",
      "The representation loss after processing this batch is:  0.0025270432233810425\n",
      "\n",
      "The classification loss after processing this batch is:  0.2005276083946228\n",
      "The representation loss after processing this batch is:  0.002322159707546234\n",
      "\n",
      "The classification loss after processing this batch is:  0.051728177815675735\n",
      "The representation loss after processing this batch is:  0.0025586336851119995\n",
      "\n",
      "The classification loss after processing this batch is:  0.05170193687081337\n",
      "The representation loss after processing this batch is:  0.0024265795946121216\n",
      "\n",
      "The classification loss after processing this batch is:  0.0784740149974823\n",
      "The representation loss after processing this batch is:  0.0027527809143066406\n",
      "\n",
      "The classification loss after processing this batch is:  0.10661161690950394\n",
      "The representation loss after processing this batch is:  0.0033779963850975037\n",
      "\n",
      "The classification loss after processing this batch is:  0.03342055529356003\n",
      "The representation loss after processing this batch is:  0.002848103642463684\n",
      "\n",
      "The classification loss after processing this batch is:  0.15297356247901917\n",
      "The representation loss after processing this batch is:  0.0035144835710525513\n",
      "\n",
      "The classification loss after processing this batch is:  0.12470131367444992\n",
      "The representation loss after processing this batch is:  0.0024542659521102905\n",
      "\n",
      "The classification loss after processing this batch is:  0.1174108013510704\n",
      "The representation loss after processing this batch is:  0.0026479773223400116\n",
      "\n",
      "The classification loss after processing this batch is:  0.16591720283031464\n",
      "The representation loss after processing this batch is:  0.0026028230786323547\n",
      "\n",
      "The classification loss after processing this batch is:  0.08383370190858841\n",
      "The representation loss after processing this batch is:  0.0028446242213249207\n",
      "\n",
      "The classification loss after processing this batch is:  0.11473550647497177\n",
      "The representation loss after processing this batch is:  0.0032228603959083557\n",
      "\n",
      "The classification loss after processing this batch is:  0.13738733530044556\n",
      "The representation loss after processing this batch is:  0.002977930009365082\n",
      "\n",
      "The classification loss after processing this batch is:  0.09498922526836395\n",
      "The representation loss after processing this batch is:  0.0030409619212150574\n",
      "\n",
      "The classification loss after processing this batch is:  0.09550988674163818\n",
      "The representation loss after processing this batch is:  0.002354539930820465\n",
      "\n",
      "The classification loss after processing this batch is:  0.04723762348294258\n",
      "The representation loss after processing this batch is:  0.0025012120604515076\n",
      "\n",
      "The classification loss after processing this batch is:  0.03057468682527542\n",
      "The representation loss after processing this batch is:  0.002607695758342743\n",
      "\n",
      "The classification loss after processing this batch is:  0.06809835880994797\n",
      "The representation loss after processing this batch is:  0.0023827925324440002\n",
      "\n",
      "The classification loss after processing this batch is:  0.05484764650464058\n",
      "The representation loss after processing this batch is:  0.0024567879736423492\n",
      "\n",
      "The classification loss after processing this batch is:  0.07172708958387375\n",
      "The representation loss after processing this batch is:  0.002145592123270035\n",
      "\n",
      "The classification loss after processing this batch is:  0.09687056392431259\n",
      "The representation loss after processing this batch is:  0.002467215061187744\n",
      "\n",
      "The classification loss after processing this batch is:  0.0986361876130104\n",
      "The representation loss after processing this batch is:  0.002459973096847534\n",
      "\n",
      "The classification loss after processing this batch is:  0.3330870270729065\n",
      "The representation loss after processing this batch is:  0.002830132842063904\n",
      "\n",
      "The classification loss after processing this batch is:  0.20341365039348602\n",
      "The representation loss after processing this batch is:  0.002764761447906494\n",
      "\n",
      "The classification loss after processing this batch is:  0.07547669112682343\n",
      "The representation loss after processing this batch is:  0.0025305747985839844\n",
      "\n",
      "The classification loss after processing this batch is:  0.0634438544511795\n",
      "The representation loss after processing this batch is:  0.0027175769209861755\n",
      "\n",
      "The classification loss after processing this batch is:  0.05075683072209358\n",
      "The representation loss after processing this batch is:  0.002649731934070587\n",
      "\n",
      "The classification loss after processing this batch is:  0.05198883265256882\n",
      "The representation loss after processing this batch is:  0.002584584057331085\n",
      "\n",
      "The classification loss after processing this batch is:  0.02369692362844944\n",
      "The representation loss after processing this batch is:  0.0027724802494049072\n",
      "\n",
      "The classification loss after processing this batch is:  0.07020197063684464\n",
      "The representation loss after processing this batch is:  0.0026951581239700317\n",
      "\n",
      "The classification loss after processing this batch is:  0.07678399980068207\n",
      "The representation loss after processing this batch is:  0.002306230366230011\n",
      "\n",
      "The classification loss after processing this batch is:  0.19537658989429474\n",
      "The representation loss after processing this batch is:  0.002626262605190277\n",
      "\n",
      "The classification loss after processing this batch is:  0.10212589055299759\n",
      "The representation loss after processing this batch is:  0.0023978427052497864\n",
      "\n",
      "The classification loss after processing this batch is:  0.0515933595597744\n",
      "The representation loss after processing this batch is:  0.0025472790002822876\n",
      "\n",
      "The classification loss after processing this batch is:  0.038231249898672104\n",
      "The representation loss after processing this batch is:  0.0025306642055511475\n",
      "\n",
      "The classification loss after processing this batch is:  0.2218298316001892\n",
      "The representation loss after processing this batch is:  0.0025220662355422974\n",
      "\n",
      "The classification loss after processing this batch is:  0.06911559402942657\n",
      "The representation loss after processing this batch is:  0.0026921480894088745\n",
      "\n",
      "The classification loss after processing this batch is:  0.06489247828722\n",
      "The representation loss after processing this batch is:  0.002473175525665283\n",
      "\n",
      "The classification loss after processing this batch is:  0.07998975366353989\n",
      "The representation loss after processing this batch is:  0.0027481168508529663\n",
      "\n",
      "The classification loss after processing this batch is:  0.08339635282754898\n",
      "The representation loss after processing this batch is:  0.002218112349510193\n",
      "\n",
      "The classification loss after processing this batch is:  0.035320933908224106\n",
      "The representation loss after processing this batch is:  0.0024143680930137634\n",
      "\n",
      "The classification loss after processing this batch is:  0.09019626677036285\n",
      "The representation loss after processing this batch is:  0.0024076849222183228\n",
      "\n",
      "The classification loss after processing this batch is:  0.05908259004354477\n",
      "The representation loss after processing this batch is:  0.002543836832046509\n",
      "\n",
      "The classification loss after processing this batch is:  0.0666557252407074\n",
      "The representation loss after processing this batch is:  0.0024987831711769104\n",
      "\n",
      "The classification loss after processing this batch is:  0.13424727320671082\n",
      "The representation loss after processing this batch is:  0.002315714955329895\n",
      "\n",
      "The classification loss after processing this batch is:  0.1452222764492035\n",
      "The representation loss after processing this batch is:  0.0025643855333328247\n",
      "\n",
      "The classification loss after processing this batch is:  0.14174017310142517\n",
      "The representation loss after processing this batch is:  0.002427421510219574\n",
      "\n",
      "The classification loss after processing this batch is:  0.13808797299861908\n",
      "The representation loss after processing this batch is:  0.0024749040603637695\n",
      "\n",
      "The classification loss after processing this batch is:  0.06727658212184906\n",
      "The representation loss after processing this batch is:  0.002498246729373932\n",
      "\n",
      "The classification loss after processing this batch is:  0.13157983124256134\n",
      "The representation loss after processing this batch is:  0.002654746174812317\n",
      "\n",
      "The classification loss after processing this batch is:  0.064266137778759\n",
      "The representation loss after processing this batch is:  0.0030069276690483093\n",
      "\n",
      "The classification loss after processing this batch is:  0.10894586890935898\n",
      "The representation loss after processing this batch is:  0.002559985965490341\n",
      "\n",
      "The classification loss after processing this batch is:  0.04782119765877724\n",
      "The representation loss after processing this batch is:  0.0023385658860206604\n",
      "\n",
      "The classification loss after processing this batch is:  0.1425464153289795\n",
      "The representation loss after processing this batch is:  0.0024121180176734924\n",
      "\n",
      "The classification loss after processing this batch is:  0.06208942085504532\n",
      "The representation loss after processing this batch is:  0.0026899203658103943\n",
      "\n",
      "The classification loss after processing this batch is:  0.07987168431282043\n",
      "The representation loss after processing this batch is:  0.0023138821125030518\n",
      "\n",
      "The classification loss after processing this batch is:  0.09447216242551804\n",
      "The representation loss after processing this batch is:  0.0023581907153129578\n",
      "\n",
      "The classification loss after processing this batch is:  0.08427275717258453\n",
      "The representation loss after processing this batch is:  0.002472624182701111\n",
      "\n",
      "The classification loss after processing this batch is:  0.12362769991159439\n",
      "The representation loss after processing this batch is:  0.0023804381489753723\n",
      "\n",
      "The classification loss after processing this batch is:  0.08613134920597076\n",
      "The representation loss after processing this batch is:  0.002212192863225937\n",
      "\n",
      "The classification loss after processing this batch is:  0.15792915225028992\n",
      "The representation loss after processing this batch is:  0.0023675858974456787\n",
      "\n",
      "The classification loss after processing this batch is:  0.14991092681884766\n",
      "The representation loss after processing this batch is:  0.002468504011631012\n",
      "\n",
      "The classification loss after processing this batch is:  0.21913957595825195\n",
      "The representation loss after processing this batch is:  0.0023719482123851776\n",
      "\n",
      "The classification loss after processing this batch is:  0.1566106528043747\n",
      "The representation loss after processing this batch is:  0.0022684596478939056\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.06755700707435608\n",
      "The representation loss after processing this batch is:  0.002606809139251709\n",
      "\n",
      "The classification loss after processing this batch is:  0.15135887265205383\n",
      "The representation loss after processing this batch is:  0.002677030861377716\n",
      "\n",
      "The classification loss after processing this batch is:  0.07964403182268143\n",
      "The representation loss after processing this batch is:  0.002697855234146118\n",
      "\n",
      "The classification loss after processing this batch is:  0.0702427551150322\n",
      "The representation loss after processing this batch is:  0.0028417035937309265\n",
      "\n",
      "The classification loss after processing this batch is:  0.17032240331172943\n",
      "The representation loss after processing this batch is:  0.0031189918518066406\n",
      "\n",
      "The classification loss after processing this batch is:  0.14849430322647095\n",
      "The representation loss after processing this batch is:  0.002791769802570343\n",
      "\n",
      "The classification loss after processing this batch is:  0.2594950795173645\n",
      "The representation loss after processing this batch is:  0.002634957432746887\n",
      "\n",
      "The classification loss after processing this batch is:  0.1217992752790451\n",
      "The representation loss after processing this batch is:  0.002733483910560608\n",
      "\n",
      "The classification loss after processing this batch is:  0.055803846567869186\n",
      "The representation loss after processing this batch is:  0.0026886537671089172\n",
      "\n",
      "The classification loss after processing this batch is:  0.07069998234510422\n",
      "The representation loss after processing this batch is:  0.0026358142495155334\n",
      "\n",
      "The classification loss after processing this batch is:  0.1622319221496582\n",
      "The representation loss after processing this batch is:  0.002240285277366638\n",
      "\n",
      "The classification loss after processing this batch is:  0.08604227006435394\n",
      "The representation loss after processing this batch is:  0.0026078373193740845\n",
      "\n",
      "The classification loss after processing this batch is:  0.08718172460794449\n",
      "The representation loss after processing this batch is:  0.0022820979356765747\n",
      "\n",
      "The classification loss after processing this batch is:  0.06672284007072449\n",
      "The representation loss after processing this batch is:  0.0026554688811302185\n",
      "\n",
      "The classification loss after processing this batch is:  0.026377372443675995\n",
      "The representation loss after processing this batch is:  0.002493247389793396\n",
      "\n",
      "The classification loss after processing this batch is:  0.1122845783829689\n",
      "The representation loss after processing this batch is:  0.0027996301651000977\n",
      "\n",
      "The classification loss after processing this batch is:  0.1133083775639534\n",
      "The representation loss after processing this batch is:  0.002981618046760559\n",
      "\n",
      "The classification loss after processing this batch is:  0.15391530096530914\n",
      "The representation loss after processing this batch is:  0.002436399459838867\n",
      "\n",
      "The classification loss after processing this batch is:  0.14170955121517181\n",
      "The representation loss after processing this batch is:  0.0021833963692188263\n",
      "\n",
      "The classification loss after processing this batch is:  0.10076389461755753\n",
      "The representation loss after processing this batch is:  0.002618037164211273\n",
      "\n",
      "The classification loss after processing this batch is:  0.12169822305440903\n",
      "The representation loss after processing this batch is:  0.002672351896762848\n",
      "\n",
      "The classification loss after processing this batch is:  0.10939385741949081\n",
      "The representation loss after processing this batch is:  0.002476342022418976\n",
      "\n",
      "The classification loss after processing this batch is:  0.10220597684383392\n",
      "The representation loss after processing this batch is:  0.002900168299674988\n",
      "\n",
      "The classification loss after processing this batch is:  0.1275816112756729\n",
      "The representation loss after processing this batch is:  0.002656012773513794\n",
      "\n",
      "The classification loss after processing this batch is:  0.11891750246286392\n",
      "The representation loss after processing this batch is:  0.0029656216502189636\n",
      "\n",
      "The classification loss after processing this batch is:  0.12058879435062408\n",
      "The representation loss after processing this batch is:  0.002395033836364746\n",
      "\n",
      "The classification loss after processing this batch is:  0.19784240424633026\n",
      "The representation loss after processing this batch is:  0.0024465397000312805\n",
      "\n",
      "The classification loss after processing this batch is:  0.1569482684135437\n",
      "The representation loss after processing this batch is:  0.0027095600962638855\n",
      "\n",
      "The classification loss after processing this batch is:  0.05801808461546898\n",
      "The representation loss after processing this batch is:  0.0022765696048736572\n",
      "\n",
      "The classification loss after processing this batch is:  0.10035362839698792\n",
      "The representation loss after processing this batch is:  0.0028826892375946045\n",
      "\n",
      "The classification loss after processing this batch is:  0.10819194465875626\n",
      "The representation loss after processing this batch is:  0.0024936646223068237\n",
      "\n",
      "The classification loss after processing this batch is:  0.09580980986356735\n",
      "The representation loss after processing this batch is:  0.0025546997785568237\n",
      "\n",
      "The classification loss after processing this batch is:  0.13890226185321808\n",
      "The representation loss after processing this batch is:  0.0029220134019851685\n",
      "\n",
      "The classification loss after processing this batch is:  0.22780539095401764\n",
      "The representation loss after processing this batch is:  0.0028861239552497864\n",
      "\n",
      "The classification loss after processing this batch is:  0.22303920984268188\n",
      "The representation loss after processing this batch is:  0.003080323338508606\n",
      "\n",
      "The classification loss after processing this batch is:  0.11454665660858154\n",
      "The representation loss after processing this batch is:  0.0027294978499412537\n",
      "\n",
      "The classification loss after processing this batch is:  0.11476217210292816\n",
      "The representation loss after processing this batch is:  0.0025711655616760254\n",
      "\n",
      "The classification loss after processing this batch is:  0.07447343319654465\n",
      "The representation loss after processing this batch is:  0.0029440000653266907\n",
      "\n",
      "The classification loss after processing this batch is:  0.050211746245622635\n",
      "The representation loss after processing this batch is:  0.002657569944858551\n",
      "\n",
      "The classification loss after processing this batch is:  0.14747601747512817\n",
      "The representation loss after processing this batch is:  0.00270838662981987\n",
      "\n",
      "The classification loss after processing this batch is:  0.10096156597137451\n",
      "The representation loss after processing this batch is:  0.002533458173274994\n",
      "\n",
      "The classification loss after processing this batch is:  0.07363413274288177\n",
      "The representation loss after processing this batch is:  0.00238669291138649\n",
      "\n",
      "The classification loss after processing this batch is:  0.10209577530622482\n",
      "The representation loss after processing this batch is:  0.002679377794265747\n",
      "\n",
      "The classification loss after processing this batch is:  0.10099086165428162\n",
      "The representation loss after processing this batch is:  0.0029078498482704163\n",
      "\n",
      "The classification loss after processing this batch is:  0.16827724874019623\n",
      "The representation loss after processing this batch is:  0.002464696764945984\n",
      "\n",
      "The classification loss after processing this batch is:  0.1088600605726242\n",
      "The representation loss after processing this batch is:  0.0025860369205474854\n",
      "\n",
      "The classification loss after processing this batch is:  0.07316825538873672\n",
      "The representation loss after processing this batch is:  0.002457655966281891\n",
      "\n",
      "The classification loss after processing this batch is:  0.03549032285809517\n",
      "The representation loss after processing this batch is:  0.002471916377544403\n",
      "\n",
      "The classification loss after processing this batch is:  0.10290050506591797\n",
      "The representation loss after processing this batch is:  0.0023145489394664764\n",
      "\n",
      "The classification loss after processing this batch is:  0.08895407617092133\n",
      "The representation loss after processing this batch is:  0.0022565387189388275\n",
      "\n",
      "The classification loss after processing this batch is:  0.3848457634449005\n",
      "The representation loss after processing this batch is:  0.0027421265840530396\n",
      "\n",
      "The classification loss after processing this batch is:  0.07893581688404083\n",
      "The representation loss after processing this batch is:  0.00244797021150589\n",
      "\n",
      "The classification loss after processing this batch is:  0.1859986037015915\n",
      "The representation loss after processing this batch is:  0.002419300377368927\n",
      "\n",
      "The classification loss after processing this batch is:  0.2507212460041046\n",
      "The representation loss after processing this batch is:  0.0026312656700611115\n",
      "\n",
      "The classification loss after processing this batch is:  0.06674646586179733\n",
      "The representation loss after processing this batch is:  0.0026812031865119934\n",
      "\n",
      "The classification loss after processing this batch is:  0.19589558243751526\n",
      "The representation loss after processing this batch is:  0.0030957385897636414\n",
      "\n",
      "The classification loss after processing this batch is:  0.11592219769954681\n",
      "The representation loss after processing this batch is:  0.002743951976299286\n",
      "\n",
      "The classification loss after processing this batch is:  0.18275731801986694\n",
      "The representation loss after processing this batch is:  0.002484489232301712\n",
      "\n",
      "The classification loss after processing this batch is:  0.039822742342948914\n",
      "The representation loss after processing this batch is:  0.002293407917022705\n",
      "\n",
      "The classification loss after processing this batch is:  0.06490828096866608\n",
      "The representation loss after processing this batch is:  0.002644643187522888\n",
      "\n",
      "The classification loss after processing this batch is:  0.045457664877176285\n",
      "The representation loss after processing this batch is:  0.002774469554424286\n",
      "\n",
      "The classification loss after processing this batch is:  0.031076550483703613\n",
      "The representation loss after processing this batch is:  0.0025751441717147827\n",
      "\n",
      "The classification loss after processing this batch is:  0.07891321927309036\n",
      "The representation loss after processing this batch is:  0.0026273876428604126\n",
      "\n",
      "The classification loss after processing this batch is:  0.05061539262533188\n",
      "The representation loss after processing this batch is:  0.0023353025317192078\n",
      "\n",
      "The classification loss after processing this batch is:  0.1258348673582077\n",
      "The representation loss after processing this batch is:  0.002840787172317505\n",
      "\n",
      "The classification loss after processing this batch is:  0.053407590836286545\n",
      "The representation loss after processing this batch is:  0.0028444677591323853\n",
      "\n",
      "The classification loss after processing this batch is:  0.0657752975821495\n",
      "The representation loss after processing this batch is:  0.002306513488292694\n",
      "\n",
      "The classification loss after processing this batch is:  0.09271003305912018\n",
      "The representation loss after processing this batch is:  0.002384290099143982\n",
      "\n",
      "The classification loss after processing this batch is:  0.03643552586436272\n",
      "The representation loss after processing this batch is:  0.0023365318775177\n",
      "\n",
      "The classification loss after processing this batch is:  0.12748858332633972\n",
      "The representation loss after processing this batch is:  0.0026077479124069214\n",
      "\n",
      "The classification loss after processing this batch is:  0.10786212980747223\n",
      "The representation loss after processing this batch is:  0.002610519528388977\n",
      "\n",
      "The classification loss after processing this batch is:  0.20638206601142883\n",
      "The representation loss after processing this batch is:  0.002933889627456665\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.07629876583814621\n",
      "The representation loss after processing this batch is:  0.002378799021244049\n",
      "\n",
      "The classification loss after processing this batch is:  0.06611614674329758\n",
      "The representation loss after processing this batch is:  0.0022197552025318146\n",
      "\n",
      "The classification loss after processing this batch is:  0.18282102048397064\n",
      "The representation loss after processing this batch is:  0.0028472766280174255\n",
      "\n",
      "The classification loss after processing this batch is:  0.13369342684745789\n",
      "The representation loss after processing this batch is:  0.0025561079382896423\n",
      "\n",
      "The classification loss after processing this batch is:  0.12156211584806442\n",
      "The representation loss after processing this batch is:  0.002747185528278351\n",
      "\n",
      "The classification loss after processing this batch is:  0.03951100632548332\n",
      "The representation loss after processing this batch is:  0.0024898946285247803\n",
      "\n",
      "The classification loss after processing this batch is:  0.08921850472688675\n",
      "The representation loss after processing this batch is:  0.0025639608502388\n",
      "\n",
      "The classification loss after processing this batch is:  0.09236560761928558\n",
      "The representation loss after processing this batch is:  0.002621803432703018\n",
      "\n",
      "The classification loss after processing this batch is:  0.10695728659629822\n",
      "The representation loss after processing this batch is:  0.0031097233295440674\n",
      "\n",
      "The classification loss after processing this batch is:  0.10055352747440338\n",
      "The representation loss after processing this batch is:  0.002919532358646393\n",
      "\n",
      "The classification loss after processing this batch is:  0.07321938872337341\n",
      "The representation loss after processing this batch is:  0.003137245774269104\n",
      "\n",
      "The classification loss after processing this batch is:  0.12342774868011475\n",
      "The representation loss after processing this batch is:  0.0030969828367233276\n",
      "\n",
      "The classification loss after processing this batch is:  0.21013745665550232\n",
      "The representation loss after processing this batch is:  0.0025136172771453857\n",
      "\n",
      "The classification loss after processing this batch is:  0.09260238707065582\n",
      "The representation loss after processing this batch is:  0.003059566020965576\n",
      "\n",
      "The classification loss after processing this batch is:  0.11679787188768387\n",
      "The representation loss after processing this batch is:  0.0024584010243415833\n",
      "\n",
      "The classification loss after processing this batch is:  0.054118022322654724\n",
      "The representation loss after processing this batch is:  0.002397976815700531\n",
      "\n",
      "The classification loss after processing this batch is:  0.18816886842250824\n",
      "The representation loss after processing this batch is:  0.0024056360125541687\n",
      "\n",
      "The classification loss after processing this batch is:  0.05372067168354988\n",
      "The representation loss after processing this batch is:  0.0024658143520355225\n",
      "\n",
      "The classification loss after processing this batch is:  0.11478710919618607\n",
      "The representation loss after processing this batch is:  0.002649553120136261\n",
      "\n",
      "The classification loss after processing this batch is:  0.07422933727502823\n",
      "The representation loss after processing this batch is:  0.0027654841542243958\n",
      "\n",
      "The classification loss after processing this batch is:  0.09717094898223877\n",
      "The representation loss after processing this batch is:  0.0025995299220085144\n",
      "\n",
      "The classification loss after processing this batch is:  0.12212168425321579\n",
      "The representation loss after processing this batch is:  0.0026361793279647827\n",
      "\n",
      "The classification loss after processing this batch is:  0.13448424637317657\n",
      "The representation loss after processing this batch is:  0.002963721752166748\n",
      "\n",
      "The classification loss after processing this batch is:  0.10773618519306183\n",
      "The representation loss after processing this batch is:  0.0027547255158424377\n",
      "\n",
      "The classification loss after processing this batch is:  0.11704191565513611\n",
      "The representation loss after processing this batch is:  0.0024045519530773163\n",
      "\n",
      "The classification loss after processing this batch is:  0.14459916949272156\n",
      "The representation loss after processing this batch is:  0.002877071499824524\n",
      "\n",
      "The classification loss after processing this batch is:  0.10164368152618408\n",
      "The representation loss after processing this batch is:  0.0024965032935142517\n",
      "\n",
      "The classification loss after processing this batch is:  0.09783487766981125\n",
      "The representation loss after processing this batch is:  0.002531707286834717\n",
      "\n",
      "The classification loss after processing this batch is:  0.041728805750608444\n",
      "The representation loss after processing this batch is:  0.002971462905406952\n",
      "\n",
      "The classification loss after processing this batch is:  0.06800402700901031\n",
      "The representation loss after processing this batch is:  0.0026722028851509094\n",
      "\n",
      "The classification loss after processing this batch is:  0.04209263622760773\n",
      "The representation loss after processing this batch is:  0.0025027841329574585\n",
      "\n",
      "The classification loss after processing this batch is:  0.04938093200325966\n",
      "The representation loss after processing this batch is:  0.002434767782688141\n",
      "\n",
      "The classification loss after processing this batch is:  0.054104454815387726\n",
      "The representation loss after processing this batch is:  0.0026477351784706116\n",
      "\n",
      "The classification loss after processing this batch is:  0.03474684804677963\n",
      "The representation loss after processing this batch is:  0.002905905246734619\n",
      "\n",
      "The classification loss after processing this batch is:  0.10673845559358597\n",
      "The representation loss after processing this batch is:  0.0024284571409225464\n",
      "\n",
      "The classification loss after processing this batch is:  0.07101628929376602\n",
      "The representation loss after processing this batch is:  0.0022936202585697174\n",
      "\n",
      "The classification loss after processing this batch is:  0.10911925137042999\n",
      "The representation loss after processing this batch is:  0.002502620220184326\n",
      "\n",
      "The classification loss after processing this batch is:  0.05248326435685158\n",
      "The representation loss after processing this batch is:  0.0027155354619026184\n",
      "\n",
      "The classification loss after processing this batch is:  0.1533089280128479\n",
      "The representation loss after processing this batch is:  0.0024916864931583405\n",
      "\n",
      "The classification loss after processing this batch is:  0.1397056132555008\n",
      "The representation loss after processing this batch is:  0.002568192780017853\n",
      "\n",
      "The classification loss after processing this batch is:  0.09299947321414948\n",
      "The representation loss after processing this batch is:  0.0025297850370407104\n",
      "\n",
      "The classification loss after processing this batch is:  0.10608837008476257\n",
      "The representation loss after processing this batch is:  0.0027978047728538513\n",
      "\n",
      "The classification loss after processing this batch is:  0.09147524833679199\n",
      "The representation loss after processing this batch is:  0.00283648818731308\n",
      "\n",
      "The classification loss after processing this batch is:  0.0318877138197422\n",
      "The representation loss after processing this batch is:  0.0024154111742973328\n",
      "\n",
      "The classification loss after processing this batch is:  0.06330008059740067\n",
      "The representation loss after processing this batch is:  0.002563789486885071\n",
      "\n",
      "The classification loss after processing this batch is:  0.06461465358734131\n",
      "The representation loss after processing this batch is:  0.0022661685943603516\n",
      "\n",
      "The classification loss after processing this batch is:  0.2044876366853714\n",
      "The representation loss after processing this batch is:  0.0027247294783592224\n",
      "\n",
      "The classification loss after processing this batch is:  0.14588651061058044\n",
      "The representation loss after processing this batch is:  0.002410203218460083\n",
      "\n",
      "The classification loss after processing this batch is:  0.1388172209262848\n",
      "The representation loss after processing this batch is:  0.003280855715274811\n",
      "\n",
      "The classification loss after processing this batch is:  0.15332330763339996\n",
      "The representation loss after processing this batch is:  0.002544090151786804\n",
      "\n",
      "The classification loss after processing this batch is:  0.15740391612052917\n",
      "The representation loss after processing this batch is:  0.002808399498462677\n",
      "\n",
      "The classification loss after processing this batch is:  0.17995767295360565\n",
      "The representation loss after processing this batch is:  0.0023103132843971252\n",
      "\n",
      "The classification loss after processing this batch is:  0.23511025309562683\n",
      "The representation loss after processing this batch is:  0.0025158897042274475\n",
      "\n",
      "The classification loss after processing this batch is:  0.15413901209831238\n",
      "The representation loss after processing this batch is:  0.002472091466188431\n",
      "\n",
      "The classification loss after processing this batch is:  0.08937668055295944\n",
      "The representation loss after processing this batch is:  0.002174466848373413\n",
      "\n",
      "The classification loss after processing this batch is:  0.07624146342277527\n",
      "The representation loss after processing this batch is:  0.0025694146752357483\n",
      "\n",
      "The classification loss after processing this batch is:  0.04558848589658737\n",
      "The representation loss after processing this batch is:  0.0023396238684654236\n",
      "\n",
      "The classification loss after processing this batch is:  0.058915797621011734\n",
      "The representation loss after processing this batch is:  0.00251847505569458\n",
      "\n",
      "The classification loss after processing this batch is:  0.05446207895874977\n",
      "The representation loss after processing this batch is:  0.003050483763217926\n",
      "\n",
      "The classification loss after processing this batch is:  0.11357875913381577\n",
      "The representation loss after processing this batch is:  0.0023116469383239746\n",
      "\n",
      "The classification loss after processing this batch is:  0.06366810947656631\n",
      "The representation loss after processing this batch is:  0.0026402920484542847\n",
      "\n",
      "The classification loss after processing this batch is:  0.15345481038093567\n",
      "The representation loss after processing this batch is:  0.0024409741163253784\n",
      "\n",
      "The classification loss after processing this batch is:  0.1248270645737648\n",
      "The representation loss after processing this batch is:  0.002731308341026306\n",
      "\n",
      "The classification loss after processing this batch is:  0.1592651754617691\n",
      "The representation loss after processing this batch is:  0.0024302899837493896\n",
      "\n",
      "The classification loss after processing this batch is:  0.10413144528865814\n",
      "The representation loss after processing this batch is:  0.002370990812778473\n",
      "\n",
      "The classification loss after processing this batch is:  0.1485862135887146\n",
      "The representation loss after processing this batch is:  0.0024308599531650543\n",
      "\n",
      "The classification loss after processing this batch is:  0.11415057629346848\n",
      "The representation loss after processing this batch is:  0.0023975521326065063\n",
      "\n",
      "The classification loss after processing this batch is:  0.07442238926887512\n",
      "The representation loss after processing this batch is:  0.0025203973054885864\n",
      "\n",
      "The classification loss after processing this batch is:  0.1728181391954422\n",
      "The representation loss after processing this batch is:  0.0024590790271759033\n",
      "\n",
      "The classification loss after processing this batch is:  0.03924693912267685\n",
      "The representation loss after processing this batch is:  0.0023232251405715942\n",
      "\n",
      "The classification loss after processing this batch is:  0.03848160803318024\n",
      "The representation loss after processing this batch is:  0.002251826226711273\n",
      "\n",
      "The classification loss after processing this batch is:  0.09733424335718155\n",
      "The representation loss after processing this batch is:  0.0028879716992378235\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1421886831521988\n",
      "The representation loss after processing this batch is:  0.0026756152510643005\n",
      "\n",
      "The classification loss after processing this batch is:  0.10472991317510605\n",
      "The representation loss after processing this batch is:  0.0028274357318878174\n",
      "\n",
      "The classification loss after processing this batch is:  0.05900418013334274\n",
      "The representation loss after processing this batch is:  0.0029089003801345825\n",
      "\n",
      "The classification loss after processing this batch is:  0.10282261669635773\n",
      "The representation loss after processing this batch is:  0.0029433593153953552\n",
      "\n",
      "The classification loss after processing this batch is:  0.08353287726640701\n",
      "The representation loss after processing this batch is:  0.00260259211063385\n",
      "\n",
      "The classification loss after processing this batch is:  0.17421914637088776\n",
      "The representation loss after processing this batch is:  0.0025357455015182495\n",
      "\n",
      "The classification loss after processing this batch is:  0.04512763023376465\n",
      "The representation loss after processing this batch is:  0.002330563962459564\n",
      "\n",
      "The classification loss after processing this batch is:  0.04635907709598541\n",
      "The representation loss after processing this batch is:  0.0027796775102615356\n",
      "\n",
      "The classification loss after processing this batch is:  0.12759535014629364\n",
      "The representation loss after processing this batch is:  0.0033168718218803406\n",
      "\n",
      "The classification loss after processing this batch is:  0.10538531839847565\n",
      "The representation loss after processing this batch is:  0.002756446599960327\n",
      "\n",
      "The classification loss after processing this batch is:  0.08147893846035004\n",
      "The representation loss after processing this batch is:  0.0029740557074546814\n",
      "\n",
      "The classification loss after processing this batch is:  0.0656084194779396\n",
      "The representation loss after processing this batch is:  0.0025403201580047607\n",
      "\n",
      "The classification loss after processing this batch is:  0.13739675283432007\n",
      "The representation loss after processing this batch is:  0.0028945952653884888\n",
      "\n",
      "The classification loss after processing this batch is:  0.153630331158638\n",
      "The representation loss after processing this batch is:  0.0028580576181411743\n",
      "\n",
      "The classification loss after processing this batch is:  0.18334262073040009\n",
      "The representation loss after processing this batch is:  0.002488277852535248\n",
      "\n",
      "The classification loss after processing this batch is:  0.11625595390796661\n",
      "The representation loss after processing this batch is:  0.0030185505747795105\n",
      "\n",
      "The classification loss after processing this batch is:  0.03546977415680885\n",
      "The representation loss after processing this batch is:  0.0025621727108955383\n",
      "\n",
      "The classification loss after processing this batch is:  0.05532876029610634\n",
      "The representation loss after processing this batch is:  0.002345271408557892\n",
      "\n",
      "The classification loss after processing this batch is:  0.14224500954151154\n",
      "The representation loss after processing this batch is:  0.0028767138719558716\n",
      "\n",
      "The classification loss after processing this batch is:  0.18559245765209198\n",
      "The representation loss after processing this batch is:  0.003064163029193878\n",
      "\n",
      "The classification loss after processing this batch is:  0.21817182004451752\n",
      "The representation loss after processing this batch is:  0.003045611083507538\n",
      "\n",
      "The classification loss after processing this batch is:  0.21270284056663513\n",
      "The representation loss after processing this batch is:  0.002612020820379257\n",
      "\n",
      "The classification loss after processing this batch is:  0.06615576148033142\n",
      "The representation loss after processing this batch is:  0.0023765042424201965\n",
      "\n",
      "The classification loss after processing this batch is:  0.13837219774723053\n",
      "The representation loss after processing this batch is:  0.0023624449968338013\n",
      "\n",
      "The classification loss after processing this batch is:  0.08324553072452545\n",
      "The representation loss after processing this batch is:  0.002526812255382538\n",
      "\n",
      "The classification loss after processing this batch is:  0.08101736754179001\n",
      "The representation loss after processing this batch is:  0.002596527338027954\n",
      "\n",
      "The classification loss after processing this batch is:  0.04980337619781494\n",
      "The representation loss after processing this batch is:  0.002512037754058838\n",
      "\n",
      "The classification loss after processing this batch is:  0.15671519935131073\n",
      "The representation loss after processing this batch is:  0.002327747642993927\n",
      "\n",
      "The classification loss after processing this batch is:  0.08188537508249283\n",
      "The representation loss after processing this batch is:  0.0023695528507232666\n",
      "\n",
      "The classification loss after processing this batch is:  0.11186892539262772\n",
      "The representation loss after processing this batch is:  0.0023515820503234863\n",
      "\n",
      "The classification loss after processing this batch is:  0.12417181581258774\n",
      "The representation loss after processing this batch is:  0.002549000084400177\n",
      "\n",
      "The classification loss after processing this batch is:  0.042373791337013245\n",
      "The representation loss after processing this batch is:  0.0026984363794326782\n",
      "\n",
      "The classification loss after processing this batch is:  0.1017194613814354\n",
      "The representation loss after processing this batch is:  0.0027538686990737915\n",
      "\n",
      "The classification loss after processing this batch is:  0.11209047585725784\n",
      "The representation loss after processing this batch is:  0.0025325044989585876\n",
      "\n",
      "The classification loss after processing this batch is:  0.08678216487169266\n",
      "The representation loss after processing this batch is:  0.0026226192712783813\n",
      "\n",
      "The classification loss after processing this batch is:  0.04944496601819992\n",
      "The representation loss after processing this batch is:  0.0029015913605690002\n",
      "\n",
      "The classification loss after processing this batch is:  0.06849738955497742\n",
      "The representation loss after processing this batch is:  0.0023170411586761475\n",
      "\n",
      "The classification loss after processing this batch is:  0.20390036702156067\n",
      "The representation loss after processing this batch is:  0.003105156123638153\n",
      "\n",
      "The classification loss after processing this batch is:  0.14068029820919037\n",
      "The representation loss after processing this batch is:  0.002477295696735382\n",
      "\n",
      "The classification loss after processing this batch is:  0.09539809823036194\n",
      "The representation loss after processing this batch is:  0.002396203577518463\n",
      "\n",
      "The classification loss after processing this batch is:  0.07640722393989563\n",
      "The representation loss after processing this batch is:  0.002249550074338913\n",
      "\n",
      "The classification loss after processing this batch is:  0.06705412268638611\n",
      "The representation loss after processing this batch is:  0.002591557800769806\n",
      "\n",
      "The classification loss after processing this batch is:  0.08238326758146286\n",
      "The representation loss after processing this batch is:  0.0023445934057235718\n",
      "\n",
      "The classification loss after processing this batch is:  0.10490674525499344\n",
      "The representation loss after processing this batch is:  0.0025533363223075867\n",
      "\n",
      "The classification loss after processing this batch is:  0.10689763724803925\n",
      "The representation loss after processing this batch is:  0.0026365742087364197\n",
      "\n",
      "The classification loss after processing this batch is:  0.09950421005487442\n",
      "The representation loss after processing this batch is:  0.0031738877296447754\n",
      "\n",
      "The classification loss after processing this batch is:  0.07225339859724045\n",
      "The representation loss after processing this batch is:  0.0027633532881736755\n",
      "\n",
      "The classification loss after processing this batch is:  0.13192778825759888\n",
      "The representation loss after processing this batch is:  0.0023467056453227997\n",
      "\n",
      "The classification loss after processing this batch is:  0.15506936609745026\n",
      "The representation loss after processing this batch is:  0.0024359673261642456\n",
      "\n",
      "The classification loss after processing this batch is:  0.034685153514146805\n",
      "The representation loss after processing this batch is:  0.0025895535945892334\n",
      "\n",
      "The classification loss after processing this batch is:  0.051511507481336594\n",
      "The representation loss after processing this batch is:  0.0023080892860889435\n",
      "\n",
      "The classification loss after processing this batch is:  0.14474771916866302\n",
      "The representation loss after processing this batch is:  0.002408340573310852\n",
      "\n",
      "The classification loss after processing this batch is:  0.1431579291820526\n",
      "The representation loss after processing this batch is:  0.0027570798993110657\n",
      "\n",
      "The classification loss after processing this batch is:  0.10166456550359726\n",
      "The representation loss after processing this batch is:  0.0025736987590789795\n",
      "\n",
      "The classification loss after processing this batch is:  0.1714751422405243\n",
      "The representation loss after processing this batch is:  0.002533562481403351\n",
      "\n",
      "The classification loss after processing this batch is:  0.14514221251010895\n",
      "The representation loss after processing this batch is:  0.0029615461826324463\n",
      "\n",
      "The classification loss after processing this batch is:  0.18448464572429657\n",
      "The representation loss after processing this batch is:  0.002694465219974518\n",
      "\n",
      "The classification loss after processing this batch is:  0.09017756581306458\n",
      "The representation loss after processing this batch is:  0.0028169527649879456\n",
      "\n",
      "The classification loss after processing this batch is:  0.15126687288284302\n",
      "The representation loss after processing this batch is:  0.0024583935737609863\n",
      "\n",
      "The classification loss after processing this batch is:  0.07843136787414551\n",
      "The representation loss after processing this batch is:  0.0036802738904953003\n",
      "\n",
      "The classification loss after processing this batch is:  0.07763634622097015\n",
      "The representation loss after processing this batch is:  0.002520322799682617\n",
      "\n",
      "The classification loss after processing this batch is:  0.09142889827489853\n",
      "The representation loss after processing this batch is:  0.002625763416290283\n",
      "\n",
      "The classification loss after processing this batch is:  0.08861566334962845\n",
      "The representation loss after processing this batch is:  0.002171330153942108\n",
      "\n",
      "The classification loss after processing this batch is:  0.09931568056344986\n",
      "The representation loss after processing this batch is:  0.0025116056203842163\n",
      "\n",
      "The classification loss after processing this batch is:  0.09229960292577744\n",
      "The representation loss after processing this batch is:  0.0025973916053771973\n",
      "\n",
      "The classification loss after processing this batch is:  0.16063877940177917\n",
      "The representation loss after processing this batch is:  0.0025079548358917236\n",
      "\n",
      "The classification loss after processing this batch is:  0.05772542953491211\n",
      "The representation loss after processing this batch is:  0.002836190164089203\n",
      "\n",
      "The classification loss after processing this batch is:  0.060324594378471375\n",
      "The representation loss after processing this batch is:  0.0028783828020095825\n",
      "\n",
      "The classification loss after processing this batch is:  0.12642137706279755\n",
      "The representation loss after processing this batch is:  0.002905227243900299\n",
      "\n",
      "The classification loss after processing this batch is:  0.06863036751747131\n",
      "The representation loss after processing this batch is:  0.002594470977783203\n",
      "\n",
      "The classification loss after processing this batch is:  0.06573864817619324\n",
      "The representation loss after processing this batch is:  0.0027647167444229126\n",
      "\n",
      "The classification loss after processing this batch is:  0.05777866765856743\n",
      "The representation loss after processing this batch is:  0.002596043050289154\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.11933598667383194\n",
      "The representation loss after processing this batch is:  0.0022488385438919067\n",
      "\n",
      "The classification loss after processing this batch is:  0.16141359508037567\n",
      "The representation loss after processing this batch is:  0.0029893890023231506\n",
      "\n",
      "The classification loss after processing this batch is:  0.15823812782764435\n",
      "The representation loss after processing this batch is:  0.0035487711429595947\n",
      "\n",
      "The classification loss after processing this batch is:  0.10919816046953201\n",
      "The representation loss after processing this batch is:  0.003008238971233368\n",
      "\n",
      "The classification loss after processing this batch is:  0.08565422147512436\n",
      "The representation loss after processing this batch is:  0.002540096640586853\n",
      "\n",
      "The classification loss after processing this batch is:  0.08635123074054718\n",
      "The representation loss after processing this batch is:  0.0026026293635368347\n",
      "\n",
      "The classification loss after processing this batch is:  0.14518648386001587\n",
      "The representation loss after processing this batch is:  0.0022963136434555054\n",
      "\n",
      "The classification loss after processing this batch is:  0.05612008646130562\n",
      "The representation loss after processing this batch is:  0.002612091600894928\n",
      "\n",
      "The classification loss after processing this batch is:  0.05324796959757805\n",
      "The representation loss after processing this batch is:  0.002643868327140808\n",
      "\n",
      "The classification loss after processing this batch is:  0.03838660940527916\n",
      "The representation loss after processing this batch is:  0.002566128969192505\n",
      "\n",
      "The classification loss after processing this batch is:  0.15215344727039337\n",
      "The representation loss after processing this batch is:  0.002969954162836075\n",
      "\n",
      "The classification loss after processing this batch is:  0.14105580747127533\n",
      "The representation loss after processing this batch is:  0.0027463510632514954\n",
      "\n",
      "The classification loss after processing this batch is:  0.14272476732730865\n",
      "The representation loss after processing this batch is:  0.002504691481590271\n",
      "\n",
      "The classification loss after processing this batch is:  0.13430164754390717\n",
      "The representation loss after processing this batch is:  0.003367587924003601\n",
      "\n",
      "The classification loss after processing this batch is:  0.1085929200053215\n",
      "The representation loss after processing this batch is:  0.0028155967593193054\n",
      "\n",
      "The classification loss after processing this batch is:  0.12952907383441925\n",
      "The representation loss after processing this batch is:  0.0027514323592185974\n",
      "\n",
      "The classification loss after processing this batch is:  0.07891988754272461\n",
      "The representation loss after processing this batch is:  0.002665773034095764\n",
      "\n",
      "The classification loss after processing this batch is:  0.2518925964832306\n",
      "The representation loss after processing this batch is:  0.003207191824913025\n",
      "\n",
      "The classification loss after processing this batch is:  0.13929347693920135\n",
      "The representation loss after processing this batch is:  0.0028114020824432373\n",
      "\n",
      "The classification loss after processing this batch is:  0.20732387900352478\n",
      "The representation loss after processing this batch is:  0.0031721889972686768\n",
      "\n",
      "The classification loss after processing this batch is:  0.07652030140161514\n",
      "The representation loss after processing this batch is:  0.002437904477119446\n",
      "\n",
      "The classification loss after processing this batch is:  0.05445293337106705\n",
      "The representation loss after processing this batch is:  0.0025741681456565857\n",
      "\n",
      "The classification loss after processing this batch is:  0.1767055243253708\n",
      "The representation loss after processing this batch is:  0.0024964064359664917\n",
      "\n",
      "The classification loss after processing this batch is:  0.1341318041086197\n",
      "The representation loss after processing this batch is:  0.002792656421661377\n",
      "\n",
      "The classification loss after processing this batch is:  0.23328641057014465\n",
      "The representation loss after processing this batch is:  0.002559185028076172\n",
      "\n",
      "The classification loss after processing this batch is:  0.15969260036945343\n",
      "The representation loss after processing this batch is:  0.003289155662059784\n",
      "\n",
      "The classification loss after processing this batch is:  0.13635970652103424\n",
      "The representation loss after processing this batch is:  0.0033347979187965393\n",
      "\n",
      "The classification loss after processing this batch is:  0.12594106793403625\n",
      "The representation loss after processing this batch is:  0.0027453675866127014\n",
      "\n",
      "The classification loss after processing this batch is:  0.04459787905216217\n",
      "The representation loss after processing this batch is:  0.0024661943316459656\n",
      "\n",
      "The classification loss after processing this batch is:  0.07955358177423477\n",
      "The representation loss after processing this batch is:  0.0024161264300346375\n",
      "\n",
      "The classification loss after processing this batch is:  0.09669603407382965\n",
      "The representation loss after processing this batch is:  0.0024796724319458008\n",
      "\n",
      "The classification loss after processing this batch is:  0.05594872683286667\n",
      "The representation loss after processing this batch is:  0.002637028694152832\n",
      "\n",
      "The classification loss after processing this batch is:  0.11988110095262527\n",
      "The representation loss after processing this batch is:  0.0023597851395606995\n",
      "\n",
      "The classification loss after processing this batch is:  0.19472479820251465\n",
      "The representation loss after processing this batch is:  0.00254908949136734\n",
      "\n",
      "The classification loss after processing this batch is:  0.12177227437496185\n",
      "The representation loss after processing this batch is:  0.0022415891289711\n",
      "\n",
      "The classification loss after processing this batch is:  0.0824044868350029\n",
      "The representation loss after processing this batch is:  0.002620406448841095\n",
      "\n",
      "The classification loss after processing this batch is:  0.08527601510286331\n",
      "The representation loss after processing this batch is:  0.002589084208011627\n",
      "\n",
      "The classification loss after processing this batch is:  0.057592928409576416\n",
      "The representation loss after processing this batch is:  0.0027156099677085876\n",
      "\n",
      "The classification loss after processing this batch is:  0.09276267141103745\n",
      "The representation loss after processing this batch is:  0.0029935240745544434\n",
      "\n",
      "The classification loss after processing this batch is:  0.04788315296173096\n",
      "The representation loss after processing this batch is:  0.0028153881430625916\n",
      "\n",
      "The classification loss after processing this batch is:  0.1177646815776825\n",
      "The representation loss after processing this batch is:  0.0023151859641075134\n",
      "\n",
      "The classification loss after processing this batch is:  0.11879841983318329\n",
      "The representation loss after processing this batch is:  0.0027362406253814697\n",
      "\n",
      "The classification loss after processing this batch is:  0.03873283043503761\n",
      "The representation loss after processing this batch is:  0.0027022361755371094\n",
      "\n",
      "The classification loss after processing this batch is:  0.20449499785900116\n",
      "The representation loss after processing this batch is:  0.0022921599447727203\n",
      "\n",
      "The classification loss after processing this batch is:  0.08162245154380798\n",
      "The representation loss after processing this batch is:  0.0023972615599632263\n",
      "\n",
      "The classification loss after processing this batch is:  0.07863304018974304\n",
      "The representation loss after processing this batch is:  0.002475269138813019\n",
      "\n",
      "The classification loss after processing this batch is:  0.04692818596959114\n",
      "The representation loss after processing this batch is:  0.0027779042720794678\n",
      "\n",
      "The classification loss after processing this batch is:  0.06138145923614502\n",
      "The representation loss after processing this batch is:  0.0026480630040168762\n",
      "\n",
      "The classification loss after processing this batch is:  0.05543123930692673\n",
      "The representation loss after processing this batch is:  0.0025277361273765564\n",
      "\n",
      "The classification loss after processing this batch is:  0.31836840510368347\n",
      "The representation loss after processing this batch is:  0.0023010969161987305\n",
      "\n",
      "The classification loss after processing this batch is:  0.09259428083896637\n",
      "The representation loss after processing this batch is:  0.0027395114302635193\n",
      "\n",
      "The classification loss after processing this batch is:  0.1395116001367569\n",
      "The representation loss after processing this batch is:  0.0022769495844841003\n",
      "\n",
      "The classification loss after processing this batch is:  0.05903792381286621\n",
      "The representation loss after processing this batch is:  0.0023084133863449097\n",
      "\n",
      "The classification loss after processing this batch is:  0.09583499282598495\n",
      "The representation loss after processing this batch is:  0.0025792494416236877\n",
      "\n",
      "The classification loss after processing this batch is:  0.044349655508995056\n",
      "The representation loss after processing this batch is:  0.002500053495168686\n",
      "\n",
      "The classification loss after processing this batch is:  0.07319628447294235\n",
      "The representation loss after processing this batch is:  0.0026066936552524567\n",
      "\n",
      "The classification loss after processing this batch is:  0.16013604402542114\n",
      "The representation loss after processing this batch is:  0.002612777054309845\n",
      "\n",
      "The classification loss after processing this batch is:  0.09711062163114548\n",
      "The representation loss after processing this batch is:  0.0032326802611351013\n",
      "\n",
      "The classification loss after processing this batch is:  0.1374765932559967\n",
      "The representation loss after processing this batch is:  0.0028290264308452606\n",
      "\n",
      "The classification loss after processing this batch is:  0.0841076448559761\n",
      "The representation loss after processing this batch is:  0.0023497194051742554\n",
      "\n",
      "The classification loss after processing this batch is:  0.17780926823616028\n",
      "The representation loss after processing this batch is:  0.002502627670764923\n",
      "\n",
      "The classification loss after processing this batch is:  0.11503484100103378\n",
      "The representation loss after processing this batch is:  0.0027845725417137146\n",
      "\n",
      "The classification loss after processing this batch is:  0.18039605021476746\n",
      "The representation loss after processing this batch is:  0.0026760250329971313\n",
      "\n",
      "The classification loss after processing this batch is:  0.07156593352556229\n",
      "The representation loss after processing this batch is:  0.002736516296863556\n",
      "\n",
      "The classification loss after processing this batch is:  0.08303557336330414\n",
      "The representation loss after processing this batch is:  0.0030413568019866943\n",
      "\n",
      "The classification loss after processing this batch is:  0.032971613109111786\n",
      "The representation loss after processing this batch is:  0.0026001930236816406\n",
      "\n",
      "The classification loss after processing this batch is:  0.1720036119222641\n",
      "The representation loss after processing this batch is:  0.002536151558160782\n",
      "\n",
      "The classification loss after processing this batch is:  0.23063452541828156\n",
      "The representation loss after processing this batch is:  0.0029230117797851562\n",
      "\n",
      "The classification loss after processing this batch is:  0.09997919946908951\n",
      "The representation loss after processing this batch is:  0.0026206374168395996\n",
      "\n",
      "The classification loss after processing this batch is:  0.14975722134113312\n",
      "The representation loss after processing this batch is:  0.0031532198190689087\n",
      "\n",
      "The classification loss after processing this batch is:  0.1458396315574646\n",
      "The representation loss after processing this batch is:  0.002776753157377243\n",
      "\n",
      "The classification loss after processing this batch is:  0.13850830495357513\n",
      "The representation loss after processing this batch is:  0.002645455300807953\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.053075551986694336\n",
      "The representation loss after processing this batch is:  0.002555232495069504\n",
      "\n",
      "The classification loss after processing this batch is:  0.09159163385629654\n",
      "The representation loss after processing this batch is:  0.002508193254470825\n",
      "\n",
      "The classification loss after processing this batch is:  0.12690679728984833\n",
      "The representation loss after processing this batch is:  0.0028353258967399597\n",
      "\n",
      "The classification loss after processing this batch is:  0.08099357783794403\n",
      "The representation loss after processing this batch is:  0.002696394920349121\n",
      "\n",
      "The classification loss after processing this batch is:  0.03028283827006817\n",
      "The representation loss after processing this batch is:  0.0027215182781219482\n",
      "\n",
      "The classification loss after processing this batch is:  0.06079645827412605\n",
      "The representation loss after processing this batch is:  0.0028667226433753967\n",
      "\n",
      "The classification loss after processing this batch is:  0.06803246587514877\n",
      "The representation loss after processing this batch is:  0.002815641462802887\n",
      "\n",
      "The classification loss after processing this batch is:  0.10110141336917877\n",
      "The representation loss after processing this batch is:  0.002391599118709564\n",
      "\n",
      "The classification loss after processing this batch is:  0.13118606805801392\n",
      "The representation loss after processing this batch is:  0.0025191530585289\n",
      "\n",
      "The classification loss after processing this batch is:  0.07813691347837448\n",
      "The representation loss after processing this batch is:  0.002417568117380142\n",
      "\n",
      "The classification loss after processing this batch is:  0.09927023947238922\n",
      "The representation loss after processing this batch is:  0.002874508500099182\n",
      "\n",
      "The classification loss after processing this batch is:  0.15894247591495514\n",
      "The representation loss after processing this batch is:  0.002670370042324066\n",
      "\n",
      "The classification loss after processing this batch is:  0.10821103304624557\n",
      "The representation loss after processing this batch is:  0.003233790397644043\n",
      "\n",
      "The classification loss after processing this batch is:  0.08293136209249496\n",
      "The representation loss after processing this batch is:  0.0026141032576560974\n",
      "\n",
      "The classification loss after processing this batch is:  0.1294422745704651\n",
      "The representation loss after processing this batch is:  0.002711087465286255\n",
      "\n",
      "The classification loss after processing this batch is:  0.1142628863453865\n",
      "The representation loss after processing this batch is:  0.0030490458011627197\n",
      "\n",
      "The classification loss after processing this batch is:  0.12723730504512787\n",
      "The representation loss after processing this batch is:  0.0027922391891479492\n",
      "\n",
      "The classification loss after processing this batch is:  0.09127083420753479\n",
      "The representation loss after processing this batch is:  0.0024343542754650116\n",
      "\n",
      "The classification loss after processing this batch is:  0.0770786926150322\n",
      "The representation loss after processing this batch is:  0.002458147704601288\n",
      "\n",
      "The classification loss after processing this batch is:  0.07203158736228943\n",
      "The representation loss after processing this batch is:  0.0025602057576179504\n",
      "\n",
      "The classification loss after processing this batch is:  0.09286323189735413\n",
      "The representation loss after processing this batch is:  0.00257742777466774\n",
      "\n",
      "The classification loss after processing this batch is:  0.14783911406993866\n",
      "The representation loss after processing this batch is:  0.00265347957611084\n",
      "\n",
      "The classification loss after processing this batch is:  0.243329256772995\n",
      "The representation loss after processing this batch is:  0.0027029067277908325\n",
      "\n",
      "The classification loss after processing this batch is:  0.13620953261852264\n",
      "The representation loss after processing this batch is:  0.0023672766983509064\n",
      "\n",
      "The classification loss after processing this batch is:  0.0999375581741333\n",
      "The representation loss after processing this batch is:  0.0025954470038414\n",
      "\n",
      "The classification loss after processing this batch is:  0.09336134046316147\n",
      "The representation loss after processing this batch is:  0.002417035400867462\n",
      "\n",
      "The classification loss after processing this batch is:  0.14186042547225952\n",
      "The representation loss after processing this batch is:  0.002442058175802231\n",
      "\n",
      "The classification loss after processing this batch is:  0.1695038229227066\n",
      "The representation loss after processing this batch is:  0.0027154870331287384\n",
      "\n",
      "The classification loss after processing this batch is:  0.12888537347316742\n",
      "The representation loss after processing this batch is:  0.0024960264563560486\n",
      "\n",
      "The classification loss after processing this batch is:  0.3326937258243561\n",
      "The representation loss after processing this batch is:  0.0026403144001960754\n",
      "\n",
      "The classification loss after processing this batch is:  0.13404418528079987\n",
      "The representation loss after processing this batch is:  0.0024327486753463745\n",
      "\n",
      "The classification loss after processing this batch is:  0.062262121587991714\n",
      "The representation loss after processing this batch is:  0.0032042935490608215\n",
      "\n",
      "The classification loss after processing this batch is:  0.0922723263502121\n",
      "The representation loss after processing this batch is:  0.0027537457644939423\n",
      "\n",
      "The classification loss after processing this batch is:  0.0677114799618721\n",
      "The representation loss after processing this batch is:  0.0025868266820907593\n",
      "\n",
      "The classification loss after processing this batch is:  0.1317315548658371\n",
      "The representation loss after processing this batch is:  0.002741202712059021\n",
      "\n",
      "The classification loss after processing this batch is:  0.0983286201953888\n",
      "The representation loss after processing this batch is:  0.002414405345916748\n",
      "\n",
      "The classification loss after processing this batch is:  0.09756530076265335\n",
      "The representation loss after processing this batch is:  0.0024394840002059937\n",
      "\n",
      "The classification loss after processing this batch is:  0.07998369634151459\n",
      "The representation loss after processing this batch is:  0.00261765718460083\n",
      "\n",
      "The classification loss after processing this batch is:  0.12894435226917267\n",
      "The representation loss after processing this batch is:  0.0024242550134658813\n",
      "\n",
      "The classification loss after processing this batch is:  0.15874746441841125\n",
      "The representation loss after processing this batch is:  0.002306237816810608\n",
      "\n",
      "The classification loss after processing this batch is:  0.18778428435325623\n",
      "The representation loss after processing this batch is:  0.002664029598236084\n",
      "\n",
      "The classification loss after processing this batch is:  0.10871123522520065\n",
      "The representation loss after processing this batch is:  0.00256955623626709\n",
      "\n",
      "The classification loss after processing this batch is:  0.03766631707549095\n",
      "The representation loss after processing this batch is:  0.002938702702522278\n",
      "\n",
      "The classification loss after processing this batch is:  0.024976572021842003\n",
      "The representation loss after processing this batch is:  0.002708055078983307\n",
      "\n",
      "The classification loss after processing this batch is:  0.10241866111755371\n",
      "The representation loss after processing this batch is:  0.0030189529061317444\n",
      "\n",
      "The classification loss after processing this batch is:  0.05480414256453514\n",
      "The representation loss after processing this batch is:  0.0036292076110839844\n",
      "\n",
      "The classification loss after processing this batch is:  0.13408610224723816\n",
      "The representation loss after processing this batch is:  0.0027009323239326477\n",
      "\n",
      "The classification loss after processing this batch is:  0.12246903777122498\n",
      "The representation loss after processing this batch is:  0.0027543678879737854\n",
      "\n",
      "The classification loss after processing this batch is:  0.1824863702058792\n",
      "The representation loss after processing this batch is:  0.0024445578455924988\n",
      "\n",
      "The classification loss after processing this batch is:  0.03856921195983887\n",
      "The representation loss after processing this batch is:  0.0026629865169525146\n",
      "\n",
      "The classification loss after processing this batch is:  0.11014968901872635\n",
      "The representation loss after processing this batch is:  0.002651892602443695\n",
      "\n",
      "The classification loss after processing this batch is:  0.13050717115402222\n",
      "The representation loss after processing this batch is:  0.002855457365512848\n",
      "\n",
      "The classification loss after processing this batch is:  0.16389384865760803\n",
      "The representation loss after processing this batch is:  0.002742454409599304\n",
      "\n",
      "The classification loss after processing this batch is:  0.0804223045706749\n",
      "The representation loss after processing this batch is:  0.002796262502670288\n",
      "\n",
      "The classification loss after processing this batch is:  0.06246783956885338\n",
      "The representation loss after processing this batch is:  0.002204515039920807\n",
      "\n",
      "The classification loss after processing this batch is:  0.10556826740503311\n",
      "The representation loss after processing this batch is:  0.0027310550212860107\n",
      "\n",
      "The classification loss after processing this batch is:  0.07241371273994446\n",
      "The representation loss after processing this batch is:  0.0024550408124923706\n",
      "\n",
      "The classification loss after processing this batch is:  0.08790477365255356\n",
      "The representation loss after processing this batch is:  0.0023903250694274902\n",
      "\n",
      "The classification loss after processing this batch is:  0.1455504298210144\n",
      "The representation loss after processing this batch is:  0.0025061294436454773\n",
      "\n",
      "The classification loss after processing this batch is:  0.07674034684896469\n",
      "The representation loss after processing this batch is:  0.0025781765580177307\n",
      "\n",
      "The classification loss after processing this batch is:  0.02248256281018257\n",
      "The representation loss after processing this batch is:  0.0023850947618484497\n",
      "\n",
      "The classification loss after processing this batch is:  0.07345625013113022\n",
      "The representation loss after processing this batch is:  0.0028707534074783325\n",
      "\n",
      "The classification loss after processing this batch is:  0.02864149399101734\n",
      "The representation loss after processing this batch is:  0.002908185124397278\n",
      "\n",
      "The classification loss after processing this batch is:  0.09049776196479797\n",
      "The representation loss after processing this batch is:  0.002596437931060791\n",
      "\n",
      "The classification loss after processing this batch is:  0.05481778085231781\n",
      "The representation loss after processing this batch is:  0.002696715295314789\n",
      "\n",
      "The classification loss after processing this batch is:  0.049854476004838943\n",
      "The representation loss after processing this batch is:  0.0024609342217445374\n",
      "\n",
      "The classification loss after processing this batch is:  0.08552338182926178\n",
      "The representation loss after processing this batch is:  0.0029401779174804688\n",
      "\n",
      "The classification loss after processing this batch is:  0.056748632341623306\n",
      "The representation loss after processing this batch is:  0.002658464014530182\n",
      "\n",
      "The classification loss after processing this batch is:  0.04006991162896156\n",
      "The representation loss after processing this batch is:  0.0027134642004966736\n",
      "\n",
      "The classification loss after processing this batch is:  0.08018273860216141\n",
      "The representation loss after processing this batch is:  0.0025053247809410095\n",
      "\n",
      "The classification loss after processing this batch is:  0.048152826726436615\n",
      "The representation loss after processing this batch is:  0.002596423029899597\n",
      "\n",
      "The classification loss after processing this batch is:  0.03464403375983238\n",
      "The representation loss after processing this batch is:  0.0026037245988845825\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08663664013147354\n",
      "The representation loss after processing this batch is:  0.0026812180876731873\n",
      "\n",
      "The classification loss after processing this batch is:  0.1198195070028305\n",
      "The representation loss after processing this batch is:  0.0028656795620918274\n",
      "\n",
      "The classification loss after processing this batch is:  0.05053018406033516\n",
      "The representation loss after processing this batch is:  0.002850733697414398\n",
      "\n",
      "The classification loss after processing this batch is:  0.17340323328971863\n",
      "The representation loss after processing this batch is:  0.002682983875274658\n",
      "\n",
      "The classification loss after processing this batch is:  0.040068887174129486\n",
      "The representation loss after processing this batch is:  0.002510368824005127\n",
      "\n",
      "The classification loss after processing this batch is:  0.11652267724275589\n",
      "The representation loss after processing this batch is:  0.0023838095366954803\n",
      "\n",
      "The classification loss after processing this batch is:  0.12731364369392395\n",
      "The representation loss after processing this batch is:  0.0029642581939697266\n",
      "\n",
      "The classification loss after processing this batch is:  0.056303318589925766\n",
      "The representation loss after processing this batch is:  0.003055773675441742\n",
      "\n",
      "The classification loss after processing this batch is:  0.16181640326976776\n",
      "The representation loss after processing this batch is:  0.002611018717288971\n",
      "\n",
      "The classification loss after processing this batch is:  0.14564640820026398\n",
      "The representation loss after processing this batch is:  0.0023731961846351624\n",
      "\n",
      "The classification loss after processing this batch is:  0.15364184975624084\n",
      "The representation loss after processing this batch is:  0.002519935369491577\n",
      "\n",
      "The classification loss after processing this batch is:  0.1424339860677719\n",
      "The representation loss after processing this batch is:  0.0025452226400375366\n",
      "\n",
      "The classification loss after processing this batch is:  0.06705614924430847\n",
      "The representation loss after processing this batch is:  0.002853304147720337\n",
      "\n",
      "The classification loss after processing this batch is:  0.0888645350933075\n",
      "The representation loss after processing this batch is:  0.0023076310753822327\n",
      "\n",
      "The classification loss after processing this batch is:  0.10499989241361618\n",
      "The representation loss after processing this batch is:  0.002632550895214081\n",
      "\n",
      "The classification loss after processing this batch is:  0.13713420927524567\n",
      "The representation loss after processing this batch is:  0.0024981722235679626\n",
      "\n",
      "The classification loss after processing this batch is:  0.14604006707668304\n",
      "The representation loss after processing this batch is:  0.002442307770252228\n",
      "\n",
      "The classification loss after processing this batch is:  0.0580376572906971\n",
      "The representation loss after processing this batch is:  0.0023458972573280334\n",
      "\n",
      "The classification loss after processing this batch is:  0.062067270278930664\n",
      "The representation loss after processing this batch is:  0.0025115162134170532\n",
      "\n",
      "The classification loss after processing this batch is:  0.18101882934570312\n",
      "The representation loss after processing this batch is:  0.0021857768297195435\n",
      "\n",
      "The classification loss after processing this batch is:  0.05762725695967674\n",
      "The representation loss after processing this batch is:  0.0025456324219703674\n",
      "\n",
      "The classification loss after processing this batch is:  0.10984532535076141\n",
      "The representation loss after processing this batch is:  0.0025820359587669373\n",
      "\n",
      "The classification loss after processing this batch is:  0.12988132238388062\n",
      "The representation loss after processing this batch is:  0.0025461241602897644\n",
      "\n",
      "The classification loss after processing this batch is:  0.060771092772483826\n",
      "The representation loss after processing this batch is:  0.0029280483722686768\n",
      "\n",
      "The classification loss after processing this batch is:  0.040276654064655304\n",
      "The representation loss after processing this batch is:  0.00289134681224823\n",
      "\n",
      "The classification loss after processing this batch is:  0.0962219312787056\n",
      "The representation loss after processing this batch is:  0.002631373703479767\n",
      "\n",
      "The classification loss after processing this batch is:  0.14302292466163635\n",
      "The representation loss after processing this batch is:  0.002550363540649414\n",
      "\n",
      "The classification loss after processing this batch is:  0.1495949923992157\n",
      "The representation loss after processing this batch is:  0.0026621483266353607\n",
      "\n",
      "The classification loss after processing this batch is:  0.203745037317276\n",
      "The representation loss after processing this batch is:  0.003002393990755081\n",
      "\n",
      "The classification loss after processing this batch is:  0.12316258251667023\n",
      "The representation loss after processing this batch is:  0.002641931176185608\n",
      "\n",
      "The classification loss after processing this batch is:  0.13571813702583313\n",
      "The representation loss after processing this batch is:  0.002176828682422638\n",
      "\n",
      "The classification loss after processing this batch is:  0.0889953002333641\n",
      "The representation loss after processing this batch is:  0.002834007143974304\n",
      "\n",
      "The classification loss after processing this batch is:  0.04752322658896446\n",
      "The representation loss after processing this batch is:  0.0026773810386657715\n",
      "\n",
      "The classification loss after processing this batch is:  0.053702984005212784\n",
      "The representation loss after processing this batch is:  0.0025625936686992645\n",
      "\n",
      "The classification loss after processing this batch is:  0.06672647595405579\n",
      "The representation loss after processing this batch is:  0.0025796815752983093\n",
      "\n",
      "The classification loss after processing this batch is:  0.10101095587015152\n",
      "The representation loss after processing this batch is:  0.002686411142349243\n",
      "\n",
      "The classification loss after processing this batch is:  0.08429040759801865\n",
      "The representation loss after processing this batch is:  0.002687111496925354\n",
      "\n",
      "The classification loss after processing this batch is:  0.11434593051671982\n",
      "The representation loss after processing this batch is:  0.0029922202229499817\n",
      "\n",
      "The classification loss after processing this batch is:  0.13066332042217255\n",
      "The representation loss after processing this batch is:  0.0029182136058807373\n",
      "\n",
      "The classification loss after processing this batch is:  0.08542277663946152\n",
      "The representation loss after processing this batch is:  0.002932511270046234\n",
      "\n",
      "The classification loss after processing this batch is:  0.15329571068286896\n",
      "The representation loss after processing this batch is:  0.002796843647956848\n",
      "\n",
      "The classification loss after processing this batch is:  0.15963846445083618\n",
      "The representation loss after processing this batch is:  0.002601616084575653\n",
      "\n",
      "The classification loss after processing this batch is:  0.16599006950855255\n",
      "The representation loss after processing this batch is:  0.002640247344970703\n",
      "\n",
      "The classification loss after processing this batch is:  0.06890329718589783\n",
      "The representation loss after processing this batch is:  0.002873621881008148\n",
      "\n",
      "The classification loss after processing this batch is:  0.06336892396211624\n",
      "The representation loss after processing this batch is:  0.00252397358417511\n",
      "\n",
      "The classification loss after processing this batch is:  0.19534610211849213\n",
      "The representation loss after processing this batch is:  0.002494044601917267\n",
      "\n",
      "The classification loss after processing this batch is:  0.16110244393348694\n",
      "The representation loss after processing this batch is:  0.0024846792221069336\n",
      "\n",
      "The classification loss after processing this batch is:  0.12109699100255966\n",
      "The representation loss after processing this batch is:  0.0026472583413124084\n",
      "\n",
      "The classification loss after processing this batch is:  0.10646084696054459\n",
      "The representation loss after processing this batch is:  0.0025470778346061707\n",
      "\n",
      "The classification loss after processing this batch is:  0.1256534308195114\n",
      "The representation loss after processing this batch is:  0.002522207796573639\n",
      "\n",
      "The classification loss after processing this batch is:  0.23064875602722168\n",
      "The representation loss after processing this batch is:  0.0023479387164115906\n",
      "\n",
      "The classification loss after processing this batch is:  0.1931682974100113\n",
      "The representation loss after processing this batch is:  0.0024040937423706055\n",
      "\n",
      "The classification loss after processing this batch is:  0.18448448181152344\n",
      "The representation loss after processing this batch is:  0.0026707127690315247\n",
      "\n",
      "The classification loss after processing this batch is:  0.15715105831623077\n",
      "The representation loss after processing this batch is:  0.002459801733493805\n",
      "\n",
      "The classification loss after processing this batch is:  0.07202863693237305\n",
      "The representation loss after processing this batch is:  0.002940654754638672\n",
      "\n",
      "The classification loss after processing this batch is:  0.053607597947120667\n",
      "The representation loss after processing this batch is:  0.0026413127779960632\n",
      "\n",
      "The classification loss after processing this batch is:  0.1221577376127243\n",
      "The representation loss after processing this batch is:  0.002625279128551483\n",
      "\n",
      "The classification loss after processing this batch is:  0.08813856542110443\n",
      "The representation loss after processing this batch is:  0.002457171678543091\n",
      "\n",
      "The classification loss after processing this batch is:  0.05549466609954834\n",
      "The representation loss after processing this batch is:  0.0023392140865325928\n",
      "\n",
      "The classification loss after processing this batch is:  0.04426587373018265\n",
      "The representation loss after processing this batch is:  0.002628955990076065\n",
      "\n",
      "The classification loss after processing this batch is:  0.09681075066328049\n",
      "The representation loss after processing this batch is:  0.002468906342983246\n",
      "\n",
      "The classification loss after processing this batch is:  0.09948493540287018\n",
      "The representation loss after processing this batch is:  0.002679266035556793\n",
      "\n",
      "The classification loss after processing this batch is:  0.055242910981178284\n",
      "The representation loss after processing this batch is:  0.002788018435239792\n",
      "\n",
      "The classification loss after processing this batch is:  0.09007883816957474\n",
      "The representation loss after processing this batch is:  0.0023515447974205017\n",
      "\n",
      "The classification loss after processing this batch is:  0.07472845166921616\n",
      "The representation loss after processing this batch is:  0.0026558637619018555\n",
      "\n",
      "The classification loss after processing this batch is:  0.16459843516349792\n",
      "The representation loss after processing this batch is:  0.002503231167793274\n",
      "\n",
      "The classification loss after processing this batch is:  0.0918901339173317\n",
      "The representation loss after processing this batch is:  0.0025273337960243225\n",
      "\n",
      "The classification loss after processing this batch is:  0.14813145995140076\n",
      "The representation loss after processing this batch is:  0.0027718767523765564\n",
      "\n",
      "The classification loss after processing this batch is:  0.0372837670147419\n",
      "The representation loss after processing this batch is:  0.0025070011615753174\n",
      "\n",
      "The classification loss after processing this batch is:  0.04656485468149185\n",
      "The representation loss after processing this batch is:  0.00295354425907135\n",
      "\n",
      "The classification loss after processing this batch is:  0.12652215361595154\n",
      "The representation loss after processing this batch is:  0.002458445727825165\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.15041427314281464\n",
      "The representation loss after processing this batch is:  0.0025570355355739594\n",
      "\n",
      "The classification loss after processing this batch is:  0.08674431592226028\n",
      "The representation loss after processing this batch is:  0.0026069656014442444\n",
      "\n",
      "The classification loss after processing this batch is:  0.050071168690919876\n",
      "The representation loss after processing this batch is:  0.0023760460317134857\n",
      "\n",
      "The classification loss after processing this batch is:  0.09994978457689285\n",
      "The representation loss after processing this batch is:  0.002303473651409149\n",
      "\n",
      "The classification loss after processing this batch is:  0.02250322513282299\n",
      "The representation loss after processing this batch is:  0.002757452428340912\n",
      "\n",
      "The classification loss after processing this batch is:  0.14919815957546234\n",
      "The representation loss after processing this batch is:  0.002487495541572571\n",
      "\n",
      "The classification loss after processing this batch is:  0.0919172465801239\n",
      "The representation loss after processing this batch is:  0.0028071328997612\n",
      "\n",
      "The classification loss after processing this batch is:  0.07844733446836472\n",
      "The representation loss after processing this batch is:  0.002511143684387207\n",
      "\n",
      "The classification loss after processing this batch is:  0.08359849452972412\n",
      "The representation loss after processing this batch is:  0.0027794167399406433\n",
      "\n",
      "The classification loss after processing this batch is:  0.08721493929624557\n",
      "The representation loss after processing this batch is:  0.0026756152510643005\n",
      "\n",
      "The classification loss after processing this batch is:  0.03759009763598442\n",
      "The representation loss after processing this batch is:  0.002555370330810547\n",
      "\n",
      "The classification loss after processing this batch is:  0.21698322892189026\n",
      "The representation loss after processing this batch is:  0.002537459135055542\n",
      "\n",
      "The classification loss after processing this batch is:  0.21938498318195343\n",
      "The representation loss after processing this batch is:  0.0025746971368789673\n",
      "\n",
      "The classification loss after processing this batch is:  0.15732704102993011\n",
      "The representation loss after processing this batch is:  0.0024754032492637634\n",
      "\n",
      "The classification loss after processing this batch is:  0.14926818013191223\n",
      "The representation loss after processing this batch is:  0.0023644790053367615\n",
      "\n",
      "The classification loss after processing this batch is:  0.09270753711462021\n",
      "The representation loss after processing this batch is:  0.0024797841906547546\n",
      "\n",
      "The classification loss after processing this batch is:  0.06504784524440765\n",
      "The representation loss after processing this batch is:  0.0023482665419578552\n",
      "\n",
      "The classification loss after processing this batch is:  0.17450879514217377\n",
      "The representation loss after processing this batch is:  0.0025331005454063416\n",
      "\n",
      "The classification loss after processing this batch is:  0.10758309066295624\n",
      "The representation loss after processing this batch is:  0.0024120956659317017\n",
      "\n",
      "The classification loss after processing this batch is:  0.16213062405586243\n",
      "The representation loss after processing this batch is:  0.002514280378818512\n",
      "\n",
      "The classification loss after processing this batch is:  0.08502013236284256\n",
      "The representation loss after processing this batch is:  0.0026974529027938843\n",
      "\n",
      "The classification loss after processing this batch is:  0.15318985283374786\n",
      "The representation loss after processing this batch is:  0.002344045788049698\n",
      "\n",
      "The classification loss after processing this batch is:  0.06436797231435776\n",
      "The representation loss after processing this batch is:  0.002387985587120056\n",
      "\n",
      "The classification loss after processing this batch is:  0.0717397928237915\n",
      "The representation loss after processing this batch is:  0.00274629145860672\n",
      "\n",
      "The classification loss after processing this batch is:  0.102593794465065\n",
      "The representation loss after processing this batch is:  0.0025345757603645325\n",
      "\n",
      "The classification loss after processing this batch is:  0.0437019020318985\n",
      "The representation loss after processing this batch is:  0.0026049166917800903\n",
      "\n",
      "The classification loss after processing this batch is:  0.027746638283133507\n",
      "The representation loss after processing this batch is:  0.0026050806045532227\n",
      "\n",
      "The classification loss after processing this batch is:  0.07320324331521988\n",
      "The representation loss after processing this batch is:  0.0024910271167755127\n",
      "\n",
      "The classification loss after processing this batch is:  0.2123042196035385\n",
      "The representation loss after processing this batch is:  0.002542242407798767\n",
      "\n",
      "The classification loss after processing this batch is:  0.02816009148955345\n",
      "The representation loss after processing this batch is:  0.0026483386754989624\n",
      "\n",
      "The classification loss after processing this batch is:  0.05624425411224365\n",
      "The representation loss after processing this batch is:  0.0024500861763954163\n",
      "\n",
      "The classification loss after processing this batch is:  0.1128256618976593\n",
      "The representation loss after processing this batch is:  0.0024637654423713684\n",
      "\n",
      "The classification loss after processing this batch is:  0.16621504724025726\n",
      "The representation loss after processing this batch is:  0.0024288445711135864\n",
      "\n",
      "The classification loss after processing this batch is:  0.08844912797212601\n",
      "The representation loss after processing this batch is:  0.0026530325412750244\n",
      "\n",
      "The classification loss after processing this batch is:  0.15741315484046936\n",
      "The representation loss after processing this batch is:  0.002365726977586746\n",
      "\n",
      "The classification loss after processing this batch is:  0.07196925580501556\n",
      "The representation loss after processing this batch is:  0.0029399245977401733\n",
      "\n",
      "The classification loss after processing this batch is:  0.03135980665683746\n",
      "The representation loss after processing this batch is:  0.0024024732410907745\n",
      "\n",
      "The classification loss after processing this batch is:  0.03263525292277336\n",
      "The representation loss after processing this batch is:  0.0028471052646636963\n",
      "\n",
      "The classification loss after processing this batch is:  0.14681516587734222\n",
      "The representation loss after processing this batch is:  0.002789027988910675\n",
      "\n",
      "The classification loss after processing this batch is:  0.11997424811124802\n",
      "The representation loss after processing this batch is:  0.002690926194190979\n",
      "\n",
      "The classification loss after processing this batch is:  0.08027071505784988\n",
      "The representation loss after processing this batch is:  0.003000214695930481\n",
      "\n",
      "The classification loss after processing this batch is:  0.14108949899673462\n",
      "The representation loss after processing this batch is:  0.002660803496837616\n",
      "\n",
      "The classification loss after processing this batch is:  0.06288688629865646\n",
      "The representation loss after processing this batch is:  0.0027659907937049866\n",
      "\n",
      "The classification loss after processing this batch is:  0.08032537251710892\n",
      "The representation loss after processing this batch is:  0.0025017783045768738\n",
      "\n",
      "The classification loss after processing this batch is:  0.09883223474025726\n",
      "The representation loss after processing this batch is:  0.0027306824922561646\n",
      "\n",
      "The classification loss after processing this batch is:  0.11442819237709045\n",
      "The representation loss after processing this batch is:  0.002625301480293274\n",
      "\n",
      "The classification loss after processing this batch is:  0.1200718879699707\n",
      "The representation loss after processing this batch is:  0.0030614733695983887\n",
      "\n",
      "The classification loss after processing this batch is:  0.2648365795612335\n",
      "The representation loss after processing this batch is:  0.002233065664768219\n",
      "\n",
      "The classification loss after processing this batch is:  0.15140600502490997\n",
      "The representation loss after processing this batch is:  0.002442657947540283\n",
      "\n",
      "The classification loss after processing this batch is:  0.1080765500664711\n",
      "The representation loss after processing this batch is:  0.0027229562401771545\n",
      "\n",
      "The classification loss after processing this batch is:  0.11075708270072937\n",
      "The representation loss after processing this batch is:  0.0028092041611671448\n",
      "\n",
      "The classification loss after processing this batch is:  0.03681856766343117\n",
      "The representation loss after processing this batch is:  0.0026060566306114197\n",
      "\n",
      "The classification loss after processing this batch is:  0.0786849781870842\n",
      "The representation loss after processing this batch is:  0.002940300852060318\n",
      "\n",
      "The classification loss after processing this batch is:  0.05983031541109085\n",
      "The representation loss after processing this batch is:  0.002829819917678833\n",
      "\n",
      "The classification loss after processing this batch is:  0.13172681629657745\n",
      "The representation loss after processing this batch is:  0.0024650320410728455\n",
      "\n",
      "The classification loss after processing this batch is:  0.11003490537405014\n",
      "The representation loss after processing this batch is:  0.002245292067527771\n",
      "\n",
      "The classification loss after processing this batch is:  0.08666319400072098\n",
      "The representation loss after processing this batch is:  0.0022715553641319275\n",
      "\n",
      "The classification loss after processing this batch is:  0.10619830340147018\n",
      "The representation loss after processing this batch is:  0.0025505945086479187\n",
      "\n",
      "The classification loss after processing this batch is:  0.13517819344997406\n",
      "The representation loss after processing this batch is:  0.0023224949836730957\n",
      "\n",
      "The classification loss after processing this batch is:  0.10600150376558304\n",
      "The representation loss after processing this batch is:  0.0025522559881210327\n",
      "\n",
      "The classification loss after processing this batch is:  0.1889984905719757\n",
      "The representation loss after processing this batch is:  0.002829253673553467\n",
      "\n",
      "The classification loss after processing this batch is:  0.06353741139173508\n",
      "The representation loss after processing this batch is:  0.0026768669486045837\n",
      "\n",
      "The classification loss after processing this batch is:  0.08802960067987442\n",
      "The representation loss after processing this batch is:  0.002276558429002762\n",
      "\n",
      "The classification loss after processing this batch is:  0.08000507950782776\n",
      "The representation loss after processing this batch is:  0.002619519829750061\n",
      "\n",
      "The classification loss after processing this batch is:  0.1931072175502777\n",
      "The representation loss after processing this batch is:  0.002711080014705658\n",
      "\n",
      "The classification loss after processing this batch is:  0.1741953343153\n",
      "The representation loss after processing this batch is:  0.002966754138469696\n",
      "\n",
      "The classification loss after processing this batch is:  0.04277021065354347\n",
      "The representation loss after processing this batch is:  0.0024610161781311035\n",
      "\n",
      "The classification loss after processing this batch is:  0.06373224407434464\n",
      "The representation loss after processing this batch is:  0.002664037048816681\n",
      "\n",
      "The classification loss after processing this batch is:  0.21767665445804596\n",
      "The representation loss after processing this batch is:  0.0024221986532211304\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.06226114183664322\n",
      "The representation loss after processing this batch is:  0.002610638737678528\n",
      "\n",
      "The classification loss after processing this batch is:  0.05938144773244858\n",
      "The representation loss after processing this batch is:  0.002588145434856415\n",
      "\n",
      "The classification loss after processing this batch is:  0.10006657987833023\n",
      "The representation loss after processing this batch is:  0.00248873233795166\n",
      "\n",
      "The classification loss after processing this batch is:  0.08368737995624542\n",
      "The representation loss after processing this batch is:  0.002521596848964691\n",
      "\n",
      "The classification loss after processing this batch is:  0.1809244602918625\n",
      "The representation loss after processing this batch is:  0.0030030831694602966\n",
      "\n",
      "The classification loss after processing this batch is:  0.11398383229970932\n",
      "The representation loss after processing this batch is:  0.002932600677013397\n",
      "\n",
      "The classification loss after processing this batch is:  0.13766445219516754\n",
      "The representation loss after processing this batch is:  0.0033615007996559143\n",
      "\n",
      "The classification loss after processing this batch is:  0.11613409221172333\n",
      "The representation loss after processing this batch is:  0.0024785101413726807\n",
      "\n",
      "The classification loss after processing this batch is:  0.15514568984508514\n",
      "The representation loss after processing this batch is:  0.0022379495203495026\n",
      "\n",
      "The classification loss after processing this batch is:  0.03865579143166542\n",
      "The representation loss after processing this batch is:  0.0023918524384498596\n",
      "\n",
      "The classification loss after processing this batch is:  0.04135160148143768\n",
      "The representation loss after processing this batch is:  0.0024440065026283264\n",
      "\n",
      "The classification loss after processing this batch is:  0.062048595398664474\n",
      "The representation loss after processing this batch is:  0.0024597421288490295\n",
      "\n",
      "The classification loss after processing this batch is:  0.04965836927294731\n",
      "The representation loss after processing this batch is:  0.0027160272002220154\n",
      "\n",
      "The classification loss after processing this batch is:  0.08365677297115326\n",
      "The representation loss after processing this batch is:  0.002680160105228424\n",
      "\n",
      "The classification loss after processing this batch is:  0.05468656122684479\n",
      "The representation loss after processing this batch is:  0.002327568829059601\n",
      "\n",
      "The classification loss after processing this batch is:  0.06959562003612518\n",
      "The representation loss after processing this batch is:  0.002262406051158905\n",
      "\n",
      "The classification loss after processing this batch is:  0.12994737923145294\n",
      "The representation loss after processing this batch is:  0.0025121867656707764\n",
      "\n",
      "The classification loss after processing this batch is:  0.14512580633163452\n",
      "The representation loss after processing this batch is:  0.002748250961303711\n",
      "\n",
      "The classification loss after processing this batch is:  0.13789387047290802\n",
      "The representation loss after processing this batch is:  0.002433229237794876\n",
      "\n",
      "The classification loss after processing this batch is:  0.12881287932395935\n",
      "The representation loss after processing this batch is:  0.0027277395129203796\n",
      "\n",
      "The classification loss after processing this batch is:  0.14916004240512848\n",
      "The representation loss after processing this batch is:  0.00231257826089859\n",
      "\n",
      "The classification loss after processing this batch is:  0.0639529898762703\n",
      "The representation loss after processing this batch is:  0.0024160370230674744\n",
      "\n",
      "The classification loss after processing this batch is:  0.12776347994804382\n",
      "The representation loss after processing this batch is:  0.002581387758255005\n",
      "\n",
      "The classification loss after processing this batch is:  0.22099876403808594\n",
      "The representation loss after processing this batch is:  0.002644971013069153\n",
      "\n",
      "The classification loss after processing this batch is:  0.08889339864253998\n",
      "The representation loss after processing this batch is:  0.002419903874397278\n",
      "\n",
      "The classification loss after processing this batch is:  0.13063670694828033\n",
      "The representation loss after processing this batch is:  0.0023331232368946075\n",
      "\n",
      "The classification loss after processing this batch is:  0.13856805860996246\n",
      "The representation loss after processing this batch is:  0.0023685917258262634\n",
      "\n",
      "The classification loss after processing this batch is:  0.12320583313703537\n",
      "The representation loss after processing this batch is:  0.002297785133123398\n",
      "\n",
      "The classification loss after processing this batch is:  0.07009295374155045\n",
      "The representation loss after processing this batch is:  0.002557806670665741\n",
      "\n",
      "The classification loss after processing this batch is:  0.06813617050647736\n",
      "The representation loss after processing this batch is:  0.002481617033481598\n",
      "\n",
      "The classification loss after processing this batch is:  0.09031108766794205\n",
      "The representation loss after processing this batch is:  0.0023280009627342224\n",
      "\n",
      "The classification loss after processing this batch is:  0.04316301271319389\n",
      "The representation loss after processing this batch is:  0.0025915205478668213\n",
      "\n",
      "The classification loss after processing this batch is:  0.02863701991736889\n",
      "The representation loss after processing this batch is:  0.002386622130870819\n",
      "\n",
      "The classification loss after processing this batch is:  0.10806575417518616\n",
      "The representation loss after processing this batch is:  0.0030089467763900757\n",
      "\n",
      "The classification loss after processing this batch is:  0.03585101664066315\n",
      "The representation loss after processing this batch is:  0.0030296891927719116\n",
      "\n",
      "The classification loss after processing this batch is:  0.19144456088542938\n",
      "The representation loss after processing this batch is:  0.002937525510787964\n",
      "\n",
      "The classification loss after processing this batch is:  0.10650181025266647\n",
      "The representation loss after processing this batch is:  0.002551332116127014\n",
      "\n",
      "The classification loss after processing this batch is:  0.17490698397159576\n",
      "The representation loss after processing this batch is:  0.002681650221347809\n",
      "\n",
      "The classification loss after processing this batch is:  0.3028462827205658\n",
      "The representation loss after processing this batch is:  0.0021394677460193634\n",
      "\n",
      "The classification loss after processing this batch is:  0.11557932943105698\n",
      "The representation loss after processing this batch is:  0.002409946173429489\n",
      "\n",
      "The classification loss after processing this batch is:  0.03537260740995407\n",
      "The representation loss after processing this batch is:  0.0025322511792182922\n",
      "\n",
      "The classification loss after processing this batch is:  0.06232428923249245\n",
      "The representation loss after processing this batch is:  0.0028676986694335938\n",
      "\n",
      "The classification loss after processing this batch is:  0.048381462693214417\n",
      "The representation loss after processing this batch is:  0.0027981698513031006\n",
      "\n",
      "The classification loss after processing this batch is:  0.05723859742283821\n",
      "The representation loss after processing this batch is:  0.0026767998933792114\n",
      "\n",
      "The classification loss after processing this batch is:  0.06894242018461227\n",
      "The representation loss after processing this batch is:  0.002317611128091812\n",
      "\n",
      "The classification loss after processing this batch is:  0.16830681264400482\n",
      "The representation loss after processing this batch is:  0.0024204999208450317\n",
      "\n",
      "The classification loss after processing this batch is:  0.13676786422729492\n",
      "The representation loss after processing this batch is:  0.002569582313299179\n",
      "\n",
      "The classification loss after processing this batch is:  0.11782314628362656\n",
      "The representation loss after processing this batch is:  0.0032188966870307922\n",
      "\n",
      "The classification loss after processing this batch is:  0.20386327803134918\n",
      "The representation loss after processing this batch is:  0.003334835171699524\n",
      "\n",
      "The classification loss after processing this batch is:  0.08632884919643402\n",
      "The representation loss after processing this batch is:  0.0025947988033294678\n",
      "\n",
      "The classification loss after processing this batch is:  0.10173598676919937\n",
      "The representation loss after processing this batch is:  0.002540305256843567\n",
      "\n",
      "The classification loss after processing this batch is:  0.15795111656188965\n",
      "The representation loss after processing this batch is:  0.0025054067373275757\n",
      "\n",
      "The classification loss after processing this batch is:  0.09584907442331314\n",
      "The representation loss after processing this batch is:  0.002915792167186737\n",
      "\n",
      "The classification loss after processing this batch is:  0.13764594495296478\n",
      "The representation loss after processing this batch is:  0.003721371293067932\n",
      "\n",
      "The classification loss after processing this batch is:  0.059176966547966\n",
      "The representation loss after processing this batch is:  0.0026180557906627655\n",
      "\n",
      "The classification loss after processing this batch is:  0.13452483713626862\n",
      "The representation loss after processing this batch is:  0.002963423728942871\n",
      "\n",
      "The classification loss after processing this batch is:  0.13247042894363403\n",
      "The representation loss after processing this batch is:  0.0030733421444892883\n",
      "\n",
      "The classification loss after processing this batch is:  0.08067280799150467\n",
      "The representation loss after processing this batch is:  0.003267452120780945\n",
      "\n",
      "The classification loss after processing this batch is:  0.12017503380775452\n",
      "The representation loss after processing this batch is:  0.0026734843850135803\n",
      "\n",
      "The classification loss after processing this batch is:  0.1358458548784256\n",
      "The representation loss after processing this batch is:  0.0022989846765995026\n",
      "\n",
      "The classification loss after processing this batch is:  0.10587654262781143\n",
      "The representation loss after processing this batch is:  0.0024394765496253967\n",
      "\n",
      "The classification loss after processing this batch is:  0.11616755276918411\n",
      "The representation loss after processing this batch is:  0.002473771572113037\n",
      "\n",
      "The classification loss after processing this batch is:  0.08523748070001602\n",
      "The representation loss after processing this batch is:  0.0027983486652374268\n",
      "\n",
      "The classification loss after processing this batch is:  0.024908943101763725\n",
      "The representation loss after processing this batch is:  0.002583608031272888\n",
      "\n",
      "The classification loss after processing this batch is:  0.10955531895160675\n",
      "The representation loss after processing this batch is:  0.0026403144001960754\n",
      "\n",
      "The classification loss after processing this batch is:  0.044254567474126816\n",
      "The representation loss after processing this batch is:  0.002854295074939728\n",
      "\n",
      "The classification loss after processing this batch is:  0.23908910155296326\n",
      "The representation loss after processing this batch is:  0.0025225356221199036\n",
      "\n",
      "The classification loss after processing this batch is:  0.04660454019904137\n",
      "The representation loss after processing this batch is:  0.0027809441089630127\n",
      "\n",
      "The classification loss after processing this batch is:  0.08971476554870605\n",
      "The representation loss after processing this batch is:  0.002471834421157837\n",
      "\n",
      "The classification loss after processing this batch is:  0.15597988665103912\n",
      "The representation loss after processing this batch is:  0.0028645917773246765\n",
      "\n",
      "The classification loss after processing this batch is:  0.1023518517613411\n",
      "The representation loss after processing this batch is:  0.002786979079246521\n",
      "\n",
      "The classification loss after processing this batch is:  0.11961059272289276\n",
      "The representation loss after processing this batch is:  0.0024753957986831665\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.07093831896781921\n",
      "The representation loss after processing this batch is:  0.002493038773536682\n",
      "\n",
      "The classification loss after processing this batch is:  0.05163690820336342\n",
      "The representation loss after processing this batch is:  0.0024223066866397858\n",
      "\n",
      "The classification loss after processing this batch is:  0.0835525244474411\n",
      "The representation loss after processing this batch is:  0.0023491978645324707\n",
      "\n",
      "The classification loss after processing this batch is:  0.17086003720760345\n",
      "The representation loss after processing this batch is:  0.0028384774923324585\n",
      "\n",
      "The classification loss after processing this batch is:  0.17943722009658813\n",
      "The representation loss after processing this batch is:  0.0025552362203598022\n",
      "\n",
      "The classification loss after processing this batch is:  0.1382216513156891\n",
      "The representation loss after processing this batch is:  0.0020701810717582703\n",
      "\n",
      "The classification loss after processing this batch is:  0.12281978875398636\n",
      "The representation loss after processing this batch is:  0.002424798905849457\n",
      "\n",
      "The classification loss after processing this batch is:  0.21336539089679718\n",
      "The representation loss after processing this batch is:  0.0025224462151527405\n",
      "\n",
      "The classification loss after processing this batch is:  0.08981657773256302\n",
      "The representation loss after processing this batch is:  0.0028160884976387024\n",
      "\n",
      "The classification loss after processing this batch is:  0.19656744599342346\n",
      "The representation loss after processing this batch is:  0.0028457120060920715\n",
      "\n",
      "The classification loss after processing this batch is:  0.1026521548628807\n",
      "The representation loss after processing this batch is:  0.002807244658470154\n",
      "\n",
      "The classification loss after processing this batch is:  0.05224592611193657\n",
      "The representation loss after processing this batch is:  0.002584502100944519\n",
      "\n",
      "The classification loss after processing this batch is:  0.03692140430212021\n",
      "The representation loss after processing this batch is:  0.0024507269263267517\n",
      "\n",
      "The classification loss after processing this batch is:  0.049649905413389206\n",
      "The representation loss after processing this batch is:  0.0025060027837753296\n",
      "\n",
      "The classification loss after processing this batch is:  0.17661792039871216\n",
      "The representation loss after processing this batch is:  0.0026268213987350464\n",
      "\n",
      "The classification loss after processing this batch is:  0.05486049875617027\n",
      "The representation loss after processing this batch is:  0.0027024373412132263\n",
      "\n",
      "The classification loss after processing this batch is:  0.12382610142230988\n",
      "The representation loss after processing this batch is:  0.002683669328689575\n",
      "\n",
      "The classification loss after processing this batch is:  0.10971076786518097\n",
      "The representation loss after processing this batch is:  0.002828560769557953\n",
      "\n",
      "The classification loss after processing this batch is:  0.07715194672346115\n",
      "The representation loss after processing this batch is:  0.0026962682604789734\n",
      "\n",
      "The classification loss after processing this batch is:  0.04690586030483246\n",
      "The representation loss after processing this batch is:  0.002405300736427307\n",
      "\n",
      "The classification loss after processing this batch is:  0.14583055675029755\n",
      "The representation loss after processing this batch is:  0.0024234652519226074\n",
      "\n",
      "The classification loss after processing this batch is:  0.18431635200977325\n",
      "The representation loss after processing this batch is:  0.0025757476687431335\n",
      "\n",
      "The classification loss after processing this batch is:  0.13947796821594238\n",
      "The representation loss after processing this batch is:  0.0027935951948165894\n",
      "\n",
      "The classification loss after processing this batch is:  0.07570687681436539\n",
      "The representation loss after processing this batch is:  0.002500563859939575\n",
      "\n",
      "The classification loss after processing this batch is:  0.19674693048000336\n",
      "The representation loss after processing this batch is:  0.0024396441876888275\n",
      "\n",
      "The classification loss after processing this batch is:  0.051363300532102585\n",
      "The representation loss after processing this batch is:  0.00219692662358284\n",
      "\n",
      "The classification loss after processing this batch is:  0.14640237390995026\n",
      "The representation loss after processing this batch is:  0.0024433769285678864\n",
      "\n",
      "The classification loss after processing this batch is:  0.15216164290905\n",
      "The representation loss after processing this batch is:  0.002867467701435089\n",
      "\n",
      "The classification loss after processing this batch is:  0.10848218947649002\n",
      "The representation loss after processing this batch is:  0.0024294331669807434\n",
      "\n",
      "The classification loss after processing this batch is:  0.14676210284233093\n",
      "The representation loss after processing this batch is:  0.002739161252975464\n",
      "\n",
      "The classification loss after processing this batch is:  0.1074417382478714\n",
      "The representation loss after processing this batch is:  0.0029771998524665833\n",
      "\n",
      "The classification loss after processing this batch is:  0.1656654328107834\n",
      "The representation loss after processing this batch is:  0.0025431811809539795\n",
      "\n",
      "The classification loss after processing this batch is:  0.24255050718784332\n",
      "The representation loss after processing this batch is:  0.002789616584777832\n",
      "\n",
      "The classification loss after processing this batch is:  0.16237354278564453\n",
      "The representation loss after processing this batch is:  0.0025230422616004944\n",
      "\n",
      "The classification loss after processing this batch is:  0.100487619638443\n",
      "The representation loss after processing this batch is:  0.0026183277368545532\n",
      "\n",
      "The classification loss after processing this batch is:  0.07351195067167282\n",
      "The representation loss after processing this batch is:  0.0030531957745552063\n",
      "\n",
      "The classification loss after processing this batch is:  0.13231521844863892\n",
      "The representation loss after processing this batch is:  0.002359822392463684\n",
      "\n",
      "The classification loss after processing this batch is:  0.11821047216653824\n",
      "The representation loss after processing this batch is:  0.002344578504562378\n",
      "\n",
      "The classification loss after processing this batch is:  0.024941332638263702\n",
      "The representation loss after processing this batch is:  0.0023897960782051086\n",
      "\n",
      "The classification loss after processing this batch is:  0.11358292400836945\n",
      "The representation loss after processing this batch is:  0.002344392240047455\n",
      "\n",
      "The classification loss after processing this batch is:  0.2598415017127991\n",
      "The representation loss after processing this batch is:  0.002899724990129471\n",
      "\n",
      "The classification loss after processing this batch is:  0.2650202214717865\n",
      "The representation loss after processing this batch is:  0.0027153491973876953\n",
      "\n",
      "The classification loss after processing this batch is:  0.212432861328125\n",
      "The representation loss after processing this batch is:  0.0024358294904232025\n",
      "\n",
      "The classification loss after processing this batch is:  0.18263565003871918\n",
      "The representation loss after processing this batch is:  0.0024707093834877014\n",
      "\n",
      "The classification loss after processing this batch is:  0.04305637627840042\n",
      "The representation loss after processing this batch is:  0.002407524734735489\n",
      "\n",
      "The classification loss after processing this batch is:  0.1628364622592926\n",
      "The representation loss after processing this batch is:  0.002576567232608795\n",
      "\n",
      "The classification loss after processing this batch is:  0.1380901336669922\n",
      "The representation loss after processing this batch is:  0.0026983991265296936\n",
      "\n",
      "The classification loss after processing this batch is:  0.2118319422006607\n",
      "The representation loss after processing this batch is:  0.0027780383825302124\n",
      "\n",
      "The classification loss after processing this batch is:  0.11337172985076904\n",
      "The representation loss after processing this batch is:  0.002681232988834381\n",
      "\n",
      "The classification loss after processing this batch is:  0.08076487481594086\n",
      "The representation loss after processing this batch is:  0.003082059323787689\n",
      "\n",
      "The classification loss after processing this batch is:  0.06447405368089676\n",
      "The representation loss after processing this batch is:  0.0027058422565460205\n",
      "\n",
      "The classification loss after processing this batch is:  0.11179561913013458\n",
      "The representation loss after processing this batch is:  0.002528548240661621\n",
      "\n",
      "The classification loss after processing this batch is:  0.1747450828552246\n",
      "The representation loss after processing this batch is:  0.0027644112706184387\n",
      "\n",
      "The classification loss after processing this batch is:  0.13314853608608246\n",
      "The representation loss after processing this batch is:  0.0024273470044136047\n",
      "\n",
      "The classification loss after processing this batch is:  0.054464954882860184\n",
      "The representation loss after processing this batch is:  0.002294350415468216\n",
      "\n",
      "The classification loss after processing this batch is:  0.24853117763996124\n",
      "The representation loss after processing this batch is:  0.003102719783782959\n",
      "\n",
      "The classification loss after processing this batch is:  0.3282566964626312\n",
      "The representation loss after processing this batch is:  0.0030907951295375824\n",
      "\n",
      "The classification loss after processing this batch is:  0.18160904943943024\n",
      "The representation loss after processing this batch is:  0.0028680041432380676\n",
      "\n",
      "The classification loss after processing this batch is:  0.09148983657360077\n",
      "The representation loss after processing this batch is:  0.0029153972864151\n",
      "\n",
      "The classification loss after processing this batch is:  0.09434548020362854\n",
      "The representation loss after processing this batch is:  0.0026274994015693665\n",
      "\n",
      "The classification loss after processing this batch is:  0.06681255996227264\n",
      "The representation loss after processing this batch is:  0.0027788281440734863\n",
      "\n",
      "The classification loss after processing this batch is:  0.22009950876235962\n",
      "The representation loss after processing this batch is:  0.0025154873728752136\n",
      "\n",
      "The classification loss after processing this batch is:  0.13140344619750977\n",
      "The representation loss after processing this batch is:  0.0030196085572242737\n",
      "\n",
      "The classification loss after processing this batch is:  0.11038661003112793\n",
      "The representation loss after processing this batch is:  0.0031284019351005554\n",
      "\n",
      "The classification loss after processing this batch is:  0.20399054884910583\n",
      "The representation loss after processing this batch is:  0.002602599561214447\n",
      "\n",
      "The classification loss after processing this batch is:  0.025273354724049568\n",
      "The representation loss after processing this batch is:  0.002557821571826935\n",
      "\n",
      "The classification loss after processing this batch is:  0.03425115719437599\n",
      "The representation loss after processing this batch is:  0.0027305111289024353\n",
      "\n",
      "The classification loss after processing this batch is:  0.07819513231515884\n",
      "The representation loss after processing this batch is:  0.0027016401290893555\n",
      "\n",
      "The classification loss after processing this batch is:  0.10844788700342178\n",
      "The representation loss after processing this batch is:  0.0023006051778793335\n",
      "\n",
      "The classification loss after processing this batch is:  0.14238841831684113\n",
      "The representation loss after processing this batch is:  0.0025758743286132812\n",
      "\n",
      "The classification loss after processing this batch is:  0.09422003477811813\n",
      "The representation loss after processing this batch is:  0.0027082115411758423\n",
      "\n",
      "The classification loss after processing this batch is:  0.11113085597753525\n",
      "The representation loss after processing this batch is:  0.0026215165853500366\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.03292369842529297\n",
      "The representation loss after processing this batch is:  0.0024984702467918396\n",
      "\n",
      "The classification loss after processing this batch is:  0.08288252353668213\n",
      "The representation loss after processing this batch is:  0.0023472532629966736\n",
      "\n",
      "The classification loss after processing this batch is:  0.062383972108364105\n",
      "The representation loss after processing this batch is:  0.0027515962719917297\n",
      "\n",
      "The classification loss after processing this batch is:  0.05157174542546272\n",
      "The representation loss after processing this batch is:  0.0029365718364715576\n",
      "\n",
      "The classification loss after processing this batch is:  0.07832244783639908\n",
      "The representation loss after processing this batch is:  0.0024574510753154755\n",
      "\n",
      "The classification loss after processing this batch is:  0.11222299933433533\n",
      "The representation loss after processing this batch is:  0.0024078339338302612\n",
      "\n",
      "The classification loss after processing this batch is:  0.15506310760974884\n",
      "The representation loss after processing this batch is:  0.0026694834232330322\n",
      "\n",
      "The classification loss after processing this batch is:  0.03804561123251915\n",
      "The representation loss after processing this batch is:  0.002409171313047409\n",
      "\n",
      "The classification loss after processing this batch is:  0.04743243753910065\n",
      "The representation loss after processing this batch is:  0.0026250258088111877\n",
      "\n",
      "The classification loss after processing this batch is:  0.06648153811693192\n",
      "The representation loss after processing this batch is:  0.0029867589473724365\n",
      "\n",
      "The classification loss after processing this batch is:  0.12947726249694824\n",
      "The representation loss after processing this batch is:  0.0027516894042491913\n",
      "\n",
      "The classification loss after processing this batch is:  0.05645476654171944\n",
      "The representation loss after processing this batch is:  0.003361925482749939\n",
      "\n",
      "The classification loss after processing this batch is:  0.12629321217536926\n",
      "The representation loss after processing this batch is:  0.002871565520763397\n",
      "\n",
      "The classification loss after processing this batch is:  0.16130200028419495\n",
      "The representation loss after processing this batch is:  0.002625688910484314\n",
      "\n",
      "The classification loss after processing this batch is:  0.1316147744655609\n",
      "The representation loss after processing this batch is:  0.002870798110961914\n",
      "\n",
      "The classification loss after processing this batch is:  0.16001130640506744\n",
      "The representation loss after processing this batch is:  0.0026779547333717346\n",
      "\n",
      "The classification loss after processing this batch is:  0.06052057817578316\n",
      "The representation loss after processing this batch is:  0.0026983171701431274\n",
      "\n",
      "The classification loss after processing this batch is:  0.10257831960916519\n",
      "The representation loss after processing this batch is:  0.0024116337299346924\n",
      "\n",
      "The classification loss after processing this batch is:  0.13481777906417847\n",
      "The representation loss after processing this batch is:  0.0023998022079467773\n",
      "\n",
      "The classification loss after processing this batch is:  0.06340046972036362\n",
      "The representation loss after processing this batch is:  0.0026080161333084106\n",
      "\n",
      "The classification loss after processing this batch is:  0.02175445482134819\n",
      "The representation loss after processing this batch is:  0.002381160855293274\n",
      "\n",
      "The classification loss after processing this batch is:  0.22626358270645142\n",
      "The representation loss after processing this batch is:  0.002650529146194458\n",
      "\n",
      "The classification loss after processing this batch is:  0.2658892571926117\n",
      "The representation loss after processing this batch is:  0.002461690455675125\n",
      "\n",
      "The classification loss after processing this batch is:  0.07567674666643143\n",
      "The representation loss after processing this batch is:  0.0025179609656333923\n",
      "\n",
      "The classification loss after processing this batch is:  0.22320938110351562\n",
      "The representation loss after processing this batch is:  0.002594374120235443\n",
      "\n",
      "The classification loss after processing this batch is:  0.2002309411764145\n",
      "The representation loss after processing this batch is:  0.0026936009526252747\n",
      "\n",
      "The classification loss after processing this batch is:  0.26788637042045593\n",
      "The representation loss after processing this batch is:  0.0026944130659103394\n",
      "\n",
      "The classification loss after processing this batch is:  0.12344380468130112\n",
      "The representation loss after processing this batch is:  0.0026667192578315735\n",
      "\n",
      "The classification loss after processing this batch is:  0.09103146940469742\n",
      "The representation loss after processing this batch is:  0.002618543803691864\n",
      "\n",
      "The classification loss after processing this batch is:  0.13082118332386017\n",
      "The representation loss after processing this batch is:  0.00292254239320755\n",
      "\n",
      "The classification loss after processing this batch is:  0.05740780755877495\n",
      "The representation loss after processing this batch is:  0.00272214412689209\n",
      "\n",
      "The classification loss after processing this batch is:  0.03654131665825844\n",
      "The representation loss after processing this batch is:  0.002581387758255005\n",
      "\n",
      "The classification loss after processing this batch is:  0.06103029102087021\n",
      "The representation loss after processing this batch is:  0.002417229115962982\n",
      "\n",
      "The classification loss after processing this batch is:  0.050771888345479965\n",
      "The representation loss after processing this batch is:  0.002723902463912964\n",
      "\n",
      "The classification loss after processing this batch is:  0.03060721978545189\n",
      "The representation loss after processing this batch is:  0.002574346959590912\n",
      "\n",
      "The classification loss after processing this batch is:  0.11964341253042221\n",
      "The representation loss after processing this batch is:  0.0025706514716148376\n",
      "\n",
      "The classification loss after processing this batch is:  0.110860675573349\n",
      "The representation loss after processing this batch is:  0.00238616019487381\n",
      "\n",
      "The classification loss after processing this batch is:  0.055197641253471375\n",
      "The representation loss after processing this batch is:  0.0026861876249313354\n",
      "\n",
      "The classification loss after processing this batch is:  0.1046065017580986\n",
      "The representation loss after processing this batch is:  0.0025428086519241333\n",
      "\n",
      "The classification loss after processing this batch is:  0.0918869748711586\n",
      "The representation loss after processing this batch is:  0.002719983458518982\n",
      "\n",
      "The classification loss after processing this batch is:  0.03158440440893173\n",
      "The representation loss after processing this batch is:  0.0027818605303764343\n",
      "\n",
      "The classification loss after processing this batch is:  0.16191153228282928\n",
      "The representation loss after processing this batch is:  0.0026780590415000916\n",
      "\n",
      "The classification loss after processing this batch is:  0.06568722426891327\n",
      "The representation loss after processing this batch is:  0.0024515539407730103\n",
      "\n",
      "The classification loss after processing this batch is:  0.2434224784374237\n",
      "The representation loss after processing this batch is:  0.0022847652435302734\n",
      "\n",
      "The classification loss after processing this batch is:  0.09924610704183578\n",
      "The representation loss after processing this batch is:  0.002800874412059784\n",
      "\n",
      "The classification loss after processing this batch is:  0.09992056339979172\n",
      "The representation loss after processing this batch is:  0.0022898539900779724\n",
      "\n",
      "The classification loss after processing this batch is:  0.036483000963926315\n",
      "The representation loss after processing this batch is:  0.002432793378829956\n",
      "\n",
      "The classification loss after processing this batch is:  0.033530496060848236\n",
      "The representation loss after processing this batch is:  0.0024660006165504456\n",
      "\n",
      "The classification loss after processing this batch is:  0.13464213907718658\n",
      "The representation loss after processing this batch is:  0.00255487859249115\n",
      "\n",
      "The classification loss after processing this batch is:  0.031728748232126236\n",
      "The representation loss after processing this batch is:  0.0028979629278182983\n",
      "\n",
      "The classification loss after processing this batch is:  0.08282672613859177\n",
      "The representation loss after processing this batch is:  0.0026839599013328552\n",
      "\n",
      "The classification loss after processing this batch is:  0.07069817930459976\n",
      "The representation loss after processing this batch is:  0.0026656389236450195\n",
      "\n",
      "The classification loss after processing this batch is:  0.08581995964050293\n",
      "The representation loss after processing this batch is:  0.0028016939759254456\n",
      "\n",
      "The classification loss after processing this batch is:  0.10277826339006424\n",
      "The representation loss after processing this batch is:  0.0026800036430358887\n",
      "\n",
      "The classification loss after processing this batch is:  0.07594119012355804\n",
      "The representation loss after processing this batch is:  0.00266081839799881\n",
      "\n",
      "The classification loss after processing this batch is:  0.12050970643758774\n",
      "The representation loss after processing this batch is:  0.0027645155787467957\n",
      "\n",
      "The classification loss after processing this batch is:  0.1289479285478592\n",
      "The representation loss after processing this batch is:  0.0025484487414360046\n",
      "\n",
      "The classification loss after processing this batch is:  0.12745524942874908\n",
      "The representation loss after processing this batch is:  0.002884417772293091\n",
      "\n",
      "The classification loss after processing this batch is:  0.15387749671936035\n",
      "The representation loss after processing this batch is:  0.0026169568300247192\n",
      "\n",
      "The classification loss after processing this batch is:  0.17916101217269897\n",
      "The representation loss after processing this batch is:  0.002660982310771942\n",
      "\n",
      "The classification loss after processing this batch is:  0.11825087666511536\n",
      "The representation loss after processing this batch is:  0.0024932250380516052\n",
      "\n",
      "The classification loss after processing this batch is:  0.08766063302755356\n",
      "The representation loss after processing this batch is:  0.0024878457188606262\n",
      "\n",
      "The classification loss after processing this batch is:  0.05678346008062363\n",
      "The representation loss after processing this batch is:  0.002513699233531952\n",
      "\n",
      "The classification loss after processing this batch is:  0.06788010895252228\n",
      "The representation loss after processing this batch is:  0.002650737762451172\n",
      "\n",
      "The classification loss after processing this batch is:  0.05732572451233864\n",
      "The representation loss after processing this batch is:  0.002693876624107361\n",
      "\n",
      "The classification loss after processing this batch is:  0.08098115772008896\n",
      "The representation loss after processing this batch is:  0.0022766217589378357\n",
      "\n",
      "The classification loss after processing this batch is:  0.06455448269844055\n",
      "The representation loss after processing this batch is:  0.0025807470083236694\n",
      "\n",
      "The classification loss after processing this batch is:  0.08338866382837296\n",
      "The representation loss after processing this batch is:  0.002832673490047455\n",
      "\n",
      "The classification loss after processing this batch is:  0.056281644850969315\n",
      "The representation loss after processing this batch is:  0.0025296583771705627\n",
      "\n",
      "The classification loss after processing this batch is:  0.13039876520633698\n",
      "The representation loss after processing this batch is:  0.0024680420756340027\n",
      "\n",
      "The classification loss after processing this batch is:  0.06236644089221954\n",
      "The representation loss after processing this batch is:  0.0028225481510162354\n",
      "\n",
      "The classification loss after processing this batch is:  0.13583610951900482\n",
      "The representation loss after processing this batch is:  0.0025806650519371033\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.12484029680490494\n",
      "The representation loss after processing this batch is:  0.0027267485857009888\n",
      "\n",
      "The classification loss after processing this batch is:  0.08703544735908508\n",
      "The representation loss after processing this batch is:  0.002704247832298279\n",
      "\n",
      "The classification loss after processing this batch is:  0.07558592408895493\n",
      "The representation loss after processing this batch is:  0.002731703221797943\n",
      "\n",
      "The classification loss after processing this batch is:  0.16741977632045746\n",
      "The representation loss after processing this batch is:  0.002695523202419281\n",
      "\n",
      "The classification loss after processing this batch is:  0.05023945868015289\n",
      "The representation loss after processing this batch is:  0.002722330391407013\n",
      "\n",
      "The classification loss after processing this batch is:  0.05191904678940773\n",
      "The representation loss after processing this batch is:  0.002495609223842621\n",
      "\n",
      "The classification loss after processing this batch is:  0.07606007158756256\n",
      "The representation loss after processing this batch is:  0.0024499595165252686\n",
      "\n",
      "The classification loss after processing this batch is:  0.052270229905843735\n",
      "The representation loss after processing this batch is:  0.0024966076016426086\n",
      "\n",
      "The classification loss after processing this batch is:  0.1477561891078949\n",
      "The representation loss after processing this batch is:  0.002229467034339905\n",
      "\n",
      "The classification loss after processing this batch is:  0.13898271322250366\n",
      "The representation loss after processing this batch is:  0.002408154308795929\n",
      "\n",
      "The classification loss after processing this batch is:  0.10306556522846222\n",
      "The representation loss after processing this batch is:  0.0029970332980155945\n",
      "\n",
      "The classification loss after processing this batch is:  0.07201360166072845\n",
      "The representation loss after processing this batch is:  0.00286305695772171\n",
      "\n",
      "The classification loss after processing this batch is:  0.10284378379583359\n",
      "The representation loss after processing this batch is:  0.0025904998183250427\n",
      "\n",
      "The classification loss after processing this batch is:  0.20917581021785736\n",
      "The representation loss after processing this batch is:  0.002642706036567688\n",
      "\n",
      "The classification loss after processing this batch is:  0.033546414226293564\n",
      "The representation loss after processing this batch is:  0.0026781782507896423\n",
      "\n",
      "The classification loss after processing this batch is:  0.06597016006708145\n",
      "The representation loss after processing this batch is:  0.0028738752007484436\n",
      "\n",
      "The classification loss after processing this batch is:  0.15170270204544067\n",
      "The representation loss after processing this batch is:  0.0023255720734596252\n",
      "\n",
      "The classification loss after processing this batch is:  0.2769814729690552\n",
      "The representation loss after processing this batch is:  0.002727590501308441\n",
      "\n",
      "The classification loss after processing this batch is:  0.07321596145629883\n",
      "The representation loss after processing this batch is:  0.002454899251461029\n",
      "\n",
      "The classification loss after processing this batch is:  0.13193748891353607\n",
      "The representation loss after processing this batch is:  0.0022235214710235596\n",
      "\n",
      "The classification loss after processing this batch is:  0.06194698065519333\n",
      "The representation loss after processing this batch is:  0.002560853958129883\n",
      "\n",
      "The classification loss after processing this batch is:  0.039703480899333954\n",
      "The representation loss after processing this batch is:  0.0027720853686332703\n",
      "\n",
      "The classification loss after processing this batch is:  0.0922684445977211\n",
      "The representation loss after processing this batch is:  0.003136970102787018\n",
      "\n",
      "The classification loss after processing this batch is:  0.09740763157606125\n",
      "The representation loss after processing this batch is:  0.003506861627101898\n",
      "\n",
      "The classification loss after processing this batch is:  0.05257868766784668\n",
      "The representation loss after processing this batch is:  0.003008447587490082\n",
      "\n",
      "The classification loss after processing this batch is:  0.04658227041363716\n",
      "The representation loss after processing this batch is:  0.0023706406354904175\n",
      "\n",
      "The classification loss after processing this batch is:  0.12741313874721527\n",
      "The representation loss after processing this batch is:  0.0027698688209056854\n",
      "\n",
      "The classification loss after processing this batch is:  0.08340707421302795\n",
      "The representation loss after processing this batch is:  0.002649448812007904\n",
      "\n",
      "The classification loss after processing this batch is:  0.06217664107680321\n",
      "The representation loss after processing this batch is:  0.002334997057914734\n",
      "\n",
      "The classification loss after processing this batch is:  0.05382615700364113\n",
      "The representation loss after processing this batch is:  0.0028016194701194763\n",
      "\n",
      "The classification loss after processing this batch is:  0.1329193264245987\n",
      "The representation loss after processing this batch is:  0.0025109946727752686\n",
      "\n",
      "The classification loss after processing this batch is:  0.12079044431447983\n",
      "The representation loss after processing this batch is:  0.002707049250602722\n",
      "\n",
      "The classification loss after processing this batch is:  0.20493276417255402\n",
      "The representation loss after processing this batch is:  0.0023153871297836304\n",
      "\n",
      "The classification loss after processing this batch is:  0.10084309428930283\n",
      "The representation loss after processing this batch is:  0.0026074498891830444\n",
      "\n",
      "The classification loss after processing this batch is:  0.18495656549930573\n",
      "The representation loss after processing this batch is:  0.0024534910917282104\n",
      "\n",
      "The classification loss after processing this batch is:  0.06761716306209564\n",
      "The representation loss after processing this batch is:  0.002933815121650696\n",
      "\n",
      "The classification loss after processing this batch is:  0.07967280596494675\n",
      "The representation loss after processing this batch is:  0.003033451735973358\n",
      "\n",
      "The classification loss after processing this batch is:  0.05290398746728897\n",
      "The representation loss after processing this batch is:  0.002476505935192108\n",
      "\n",
      "The classification loss after processing this batch is:  0.0505538173019886\n",
      "The representation loss after processing this batch is:  0.002484455704689026\n",
      "\n",
      "The classification loss after processing this batch is:  0.1471453607082367\n",
      "The representation loss after processing this batch is:  0.002389725297689438\n",
      "\n",
      "The classification loss after processing this batch is:  0.06845030933618546\n",
      "The representation loss after processing this batch is:  0.0028158053755760193\n",
      "\n",
      "The classification loss after processing this batch is:  0.039274293929338455\n",
      "The representation loss after processing this batch is:  0.0025273337960243225\n",
      "\n",
      "The classification loss after processing this batch is:  0.04623522609472275\n",
      "The representation loss after processing this batch is:  0.0031863972544670105\n",
      "\n",
      "The classification loss after processing this batch is:  0.021005455404520035\n",
      "The representation loss after processing this batch is:  0.002978898584842682\n",
      "\n",
      "The classification loss after processing this batch is:  0.05082443729043007\n",
      "The representation loss after processing this batch is:  0.0033820345997810364\n",
      "\n",
      "The classification loss after processing this batch is:  0.060097359120845795\n",
      "The representation loss after processing this batch is:  0.0028120800852775574\n",
      "\n",
      "The classification loss after processing this batch is:  0.03788537532091141\n",
      "The representation loss after processing this batch is:  0.002840571105480194\n",
      "\n",
      "The classification loss after processing this batch is:  0.010685324668884277\n",
      "The representation loss after processing this batch is:  0.0027333423495292664\n",
      "\n",
      "The classification loss after processing this batch is:  0.03211448714137077\n",
      "The representation loss after processing this batch is:  0.0030746161937713623\n",
      "\n",
      "The classification loss after processing this batch is:  0.07279278337955475\n",
      "The representation loss after processing this batch is:  0.0035781338810920715\n",
      "\n",
      "The classification loss after processing this batch is:  0.010519369505345821\n",
      "The representation loss after processing this batch is:  0.0034251585602760315\n",
      "\n",
      "The classification loss after processing this batch is:  0.02382761612534523\n",
      "The representation loss after processing this batch is:  0.0030430033802986145\n",
      "\n",
      "The classification loss after processing this batch is:  0.17045868933200836\n",
      "The representation loss after processing this batch is:  0.0028913691639900208\n",
      "\n",
      "The classification loss after processing this batch is:  0.03125380724668503\n",
      "The representation loss after processing this batch is:  0.0030633509159088135\n",
      "\n",
      "The classification loss after processing this batch is:  0.014025712385773659\n",
      "The representation loss after processing this batch is:  0.0028208717703819275\n",
      "\n",
      "The classification loss after processing this batch is:  0.024210119619965553\n",
      "The representation loss after processing this batch is:  0.0032374486327171326\n",
      "\n",
      "The classification loss after processing this batch is:  0.017294757068157196\n",
      "The representation loss after processing this batch is:  0.0029629170894622803\n",
      "\n",
      "The classification loss after processing this batch is:  0.013886841014027596\n",
      "The representation loss after processing this batch is:  0.0027620717883110046\n",
      "\n",
      "The classification loss after processing this batch is:  0.009765060618519783\n",
      "The representation loss after processing this batch is:  0.0032280907034873962\n",
      "\n",
      "The classification loss after processing this batch is:  0.011129784397780895\n",
      "The representation loss after processing this batch is:  0.0034410133957862854\n",
      "\n",
      "The classification loss after processing this batch is:  0.3295353651046753\n",
      "The representation loss after processing this batch is:  0.003621205687522888\n",
      "\n",
      "The classification loss after processing this batch is:  0.2665533721446991\n",
      "The representation loss after processing this batch is:  0.0033857151865959167\n",
      "\n",
      "The classification loss after processing this batch is:  0.18173016607761383\n",
      "The representation loss after processing this batch is:  0.0038273632526397705\n",
      "\n",
      "The classification loss after processing this batch is:  0.04114357754588127\n",
      "The representation loss after processing this batch is:  0.002886049449443817\n",
      "\n",
      "The classification loss after processing this batch is:  0.009629487991333008\n",
      "The representation loss after processing this batch is:  0.0034616664052009583\n",
      "\n",
      "The classification loss after processing this batch is:  0.010385234840214252\n",
      "The representation loss after processing this batch is:  0.0024217814207077026\n",
      "\n",
      "The classification loss after processing this batch is:  0.08882776647806168\n",
      "The representation loss after processing this batch is:  0.002569742500782013\n",
      "\n",
      "The classification loss after processing this batch is:  0.33750253915786743\n",
      "The representation loss after processing this batch is:  0.0029593780636787415\n",
      "\n",
      "The classification loss after processing this batch is:  0.048150576651096344\n",
      "The representation loss after processing this batch is:  0.0027812793850898743\n",
      "\n",
      "The classification loss after processing this batch is:  0.026414688676595688\n",
      "The representation loss after processing this batch is:  0.003242604434490204\n",
      "\n",
      "The classification loss after processing this batch is:  0.032396912574768066\n",
      "The representation loss after processing this batch is:  0.0032122135162353516\n",
      "\n",
      "The classification loss after processing this batch is:  0.038721125572919846\n",
      "The representation loss after processing this batch is:  0.003840409219264984\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.09908507019281387\n",
      "The representation loss after processing this batch is:  0.002362877130508423\n",
      "\n",
      "The classification loss after processing this batch is:  0.030756648629903793\n",
      "The representation loss after processing this batch is:  0.0024535730481147766\n",
      "\n",
      "The classification loss after processing this batch is:  0.10738921910524368\n",
      "The representation loss after processing this batch is:  0.002430148422718048\n",
      "\n",
      "The classification loss after processing this batch is:  0.11067534238100052\n",
      "The representation loss after processing this batch is:  0.0024326369166374207\n",
      "\n",
      "The classification loss after processing this batch is:  0.14885520935058594\n",
      "The representation loss after processing this batch is:  0.0026638656854629517\n",
      "\n",
      "The classification loss after processing this batch is:  0.0378752201795578\n",
      "The representation loss after processing this batch is:  0.0028323978185653687\n",
      "\n",
      "The classification loss after processing this batch is:  0.0669013187289238\n",
      "The representation loss after processing this batch is:  0.0030219629406929016\n",
      "\n",
      "The classification loss after processing this batch is:  0.06612017750740051\n",
      "The representation loss after processing this batch is:  0.002432525157928467\n",
      "\n",
      "The classification loss after processing this batch is:  0.0894165188074112\n",
      "The representation loss after processing this batch is:  0.002394169569015503\n",
      "\n",
      "The classification loss after processing this batch is:  0.0778522863984108\n",
      "The representation loss after processing this batch is:  0.0023544877767562866\n",
      "\n",
      "The classification loss after processing this batch is:  0.12612377107143402\n",
      "The representation loss after processing this batch is:  0.0023504048585891724\n",
      "\n",
      "The classification loss after processing this batch is:  0.0789223164319992\n",
      "The representation loss after processing this batch is:  0.0024435557425022125\n",
      "\n",
      "The classification loss after processing this batch is:  0.09484734386205673\n",
      "The representation loss after processing this batch is:  0.00289154052734375\n",
      "\n",
      "The classification loss after processing this batch is:  0.04063167795538902\n",
      "The representation loss after processing this batch is:  0.002638101577758789\n",
      "\n",
      "The classification loss after processing this batch is:  0.21425892412662506\n",
      "The representation loss after processing this batch is:  0.002645086497068405\n",
      "\n",
      "The classification loss after processing this batch is:  0.12305600196123123\n",
      "The representation loss after processing this batch is:  0.0025546476244926453\n",
      "\n",
      "The classification loss after processing this batch is:  0.12711627781391144\n",
      "The representation loss after processing this batch is:  0.002554122358560562\n",
      "\n",
      "The classification loss after processing this batch is:  0.18666397035121918\n",
      "The representation loss after processing this batch is:  0.003267768770456314\n",
      "\n",
      "The classification loss after processing this batch is:  0.11757681518793106\n",
      "The representation loss after processing this batch is:  0.0028090178966522217\n",
      "\n",
      "The classification loss after processing this batch is:  0.06767155975103378\n",
      "The representation loss after processing this batch is:  0.002685386687517166\n",
      "\n",
      "The classification loss after processing this batch is:  0.21697358787059784\n",
      "The representation loss after processing this batch is:  0.0032768473029136658\n",
      "\n",
      "The classification loss after processing this batch is:  0.10361934453248978\n",
      "The representation loss after processing this batch is:  0.0028109773993492126\n",
      "\n",
      "The classification loss after processing this batch is:  0.29011648893356323\n",
      "The representation loss after processing this batch is:  0.0027706697583198547\n",
      "\n",
      "The classification loss after processing this batch is:  0.06288502365350723\n",
      "The representation loss after processing this batch is:  0.002362079918384552\n",
      "\n",
      "The classification loss after processing this batch is:  0.0422089584171772\n",
      "The representation loss after processing this batch is:  0.002458415925502777\n",
      "\n",
      "The classification loss after processing this batch is:  0.06843174993991852\n",
      "The representation loss after processing this batch is:  0.0023525282740592957\n",
      "\n",
      "The classification loss after processing this batch is:  0.08942092955112457\n",
      "The representation loss after processing this batch is:  0.002463545650243759\n",
      "\n",
      "The classification loss after processing this batch is:  0.047333527356386185\n",
      "The representation loss after processing this batch is:  0.002513207495212555\n",
      "\n",
      "The classification loss after processing this batch is:  0.053472552448511124\n",
      "The representation loss after processing this batch is:  0.0025909319519996643\n",
      "\n",
      "The classification loss after processing this batch is:  0.04220849648118019\n",
      "The representation loss after processing this batch is:  0.002567589282989502\n",
      "\n",
      "The classification loss after processing this batch is:  0.034649383276700974\n",
      "The representation loss after processing this batch is:  0.0024544447660446167\n",
      "\n",
      "The classification loss after processing this batch is:  0.0567280650138855\n",
      "The representation loss after processing this batch is:  0.0026919767260551453\n",
      "\n",
      "The classification loss after processing this batch is:  0.14457912743091583\n",
      "The representation loss after processing this batch is:  0.002651795744895935\n",
      "\n",
      "The classification loss after processing this batch is:  0.060280945152044296\n",
      "The representation loss after processing this batch is:  0.0030825957655906677\n",
      "\n",
      "The classification loss after processing this batch is:  0.09424592554569244\n",
      "The representation loss after processing this batch is:  0.002244032919406891\n",
      "\n",
      "The classification loss after processing this batch is:  0.038873180747032166\n",
      "The representation loss after processing this batch is:  0.0026235952973365784\n",
      "\n",
      "The classification loss after processing this batch is:  0.03132486343383789\n",
      "The representation loss after processing this batch is:  0.0026290789246559143\n",
      "\n",
      "The classification loss after processing this batch is:  0.10823698341846466\n",
      "The representation loss after processing this batch is:  0.002653568983078003\n",
      "\n",
      "The classification loss after processing this batch is:  0.03331403806805611\n",
      "The representation loss after processing this batch is:  0.0026901885867118835\n",
      "\n",
      "The classification loss after processing this batch is:  0.03763127326965332\n",
      "The representation loss after processing this batch is:  0.0025088489055633545\n",
      "\n",
      "The classification loss after processing this batch is:  0.130572110414505\n",
      "The representation loss after processing this batch is:  0.0027564242482185364\n",
      "\n",
      "The classification loss after processing this batch is:  0.07347226142883301\n",
      "The representation loss after processing this batch is:  0.002631738781929016\n",
      "\n",
      "The classification loss after processing this batch is:  0.08371105790138245\n",
      "The representation loss after processing this batch is:  0.0022484734654426575\n",
      "\n",
      "The classification loss after processing this batch is:  0.1364576667547226\n",
      "The representation loss after processing this batch is:  0.0023718103766441345\n",
      "\n",
      "The classification loss after processing this batch is:  0.09302902966737747\n",
      "The representation loss after processing this batch is:  0.00241677463054657\n",
      "\n",
      "The classification loss after processing this batch is:  0.10416444391012192\n",
      "The representation loss after processing this batch is:  0.002277649939060211\n",
      "\n",
      "The classification loss after processing this batch is:  0.1866016536951065\n",
      "The representation loss after processing this batch is:  0.002528097480535507\n",
      "\n",
      "The classification loss after processing this batch is:  0.04517974331974983\n",
      "The representation loss after processing this batch is:  0.002571389079093933\n",
      "\n",
      "The classification loss after processing this batch is:  0.1053907573223114\n",
      "The representation loss after processing this batch is:  0.0025658905506134033\n",
      "\n",
      "The classification loss after processing this batch is:  0.0498788096010685\n",
      "The representation loss after processing this batch is:  0.0023389607667922974\n",
      "\n",
      "The classification loss after processing this batch is:  0.0956258699297905\n",
      "The representation loss after processing this batch is:  0.0026619508862495422\n",
      "\n",
      "The classification loss after processing this batch is:  0.07896363735198975\n",
      "The representation loss after processing this batch is:  0.002878740429878235\n",
      "\n",
      "The classification loss after processing this batch is:  0.042748745530843735\n",
      "The representation loss after processing this batch is:  0.0025931745767593384\n",
      "\n",
      "The classification loss after processing this batch is:  0.10082841664552689\n",
      "The representation loss after processing this batch is:  0.0025540217757225037\n",
      "\n",
      "The classification loss after processing this batch is:  0.08640538156032562\n",
      "The representation loss after processing this batch is:  0.0028487518429756165\n",
      "\n",
      "The classification loss after processing this batch is:  0.08104430884122849\n",
      "The representation loss after processing this batch is:  0.002510286867618561\n",
      "\n",
      "The classification loss after processing this batch is:  0.13245142996311188\n",
      "The representation loss after processing this batch is:  0.002293705940246582\n",
      "\n",
      "The classification loss after processing this batch is:  0.08039309084415436\n",
      "The representation loss after processing this batch is:  0.0028979554772377014\n",
      "\n",
      "The classification loss after processing this batch is:  0.13681001961231232\n",
      "The representation loss after processing this batch is:  0.002447284758090973\n",
      "\n",
      "The classification loss after processing this batch is:  0.07128258049488068\n",
      "The representation loss after processing this batch is:  0.002381734549999237\n",
      "\n",
      "The classification loss after processing this batch is:  0.03561098501086235\n",
      "The representation loss after processing this batch is:  0.002485070377588272\n",
      "\n",
      "The classification loss after processing this batch is:  0.11872859299182892\n",
      "The representation loss after processing this batch is:  0.0026183947920799255\n",
      "\n",
      "The classification loss after processing this batch is:  0.09274797141551971\n",
      "The representation loss after processing this batch is:  0.0025128796696662903\n",
      "\n",
      "The classification loss after processing this batch is:  0.05779488757252693\n",
      "The representation loss after processing this batch is:  0.0025092139840126038\n",
      "\n",
      "The classification loss after processing this batch is:  0.0646294429898262\n",
      "The representation loss after processing this batch is:  0.0024511367082595825\n",
      "\n",
      "The classification loss after processing this batch is:  0.042189888656139374\n",
      "The representation loss after processing this batch is:  0.002366378903388977\n",
      "\n",
      "The classification loss after processing this batch is:  0.0721728578209877\n",
      "The representation loss after processing this batch is:  0.0026377663016319275\n",
      "\n",
      "The classification loss after processing this batch is:  0.10585101693868637\n",
      "The representation loss after processing this batch is:  0.002273235470056534\n",
      "\n",
      "The classification loss after processing this batch is:  0.051898788660764694\n",
      "The representation loss after processing this batch is:  0.0023085549473762512\n",
      "\n",
      "The classification loss after processing this batch is:  0.13214688003063202\n",
      "The representation loss after processing this batch is:  0.0027573928236961365\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08953959494829178\n",
      "The representation loss after processing this batch is:  0.0022912994027137756\n",
      "\n",
      "The classification loss after processing this batch is:  0.05646903067827225\n",
      "The representation loss after processing this batch is:  0.002530328929424286\n",
      "\n",
      "The classification loss after processing this batch is:  0.07071411609649658\n",
      "The representation loss after processing this batch is:  0.0021675825119018555\n",
      "\n",
      "The classification loss after processing this batch is:  0.061507683247327805\n",
      "The representation loss after processing this batch is:  0.002702943980693817\n",
      "\n",
      "The classification loss after processing this batch is:  0.0768626481294632\n",
      "The representation loss after processing this batch is:  0.002169061452150345\n",
      "\n",
      "The classification loss after processing this batch is:  0.14536990225315094\n",
      "The representation loss after processing this batch is:  0.0025251731276512146\n",
      "\n",
      "The classification loss after processing this batch is:  0.045222871005535126\n",
      "The representation loss after processing this batch is:  0.002400048077106476\n",
      "\n",
      "The classification loss after processing this batch is:  0.23233911395072937\n",
      "The representation loss after processing this batch is:  0.002474449574947357\n",
      "\n",
      "The classification loss after processing this batch is:  0.0977238193154335\n",
      "The representation loss after processing this batch is:  0.002482503652572632\n",
      "\n",
      "The classification loss after processing this batch is:  0.06382422149181366\n",
      "The representation loss after processing this batch is:  0.0030622556805610657\n",
      "\n",
      "The classification loss after processing this batch is:  0.07019872963428497\n",
      "The representation loss after processing this batch is:  0.0026356130838394165\n",
      "\n",
      "The classification loss after processing this batch is:  0.06446604430675507\n",
      "The representation loss after processing this batch is:  0.0028669163584709167\n",
      "\n",
      "The classification loss after processing this batch is:  0.1926857829093933\n",
      "The representation loss after processing this batch is:  0.00274793803691864\n",
      "\n",
      "The classification loss after processing this batch is:  0.10056616365909576\n",
      "The representation loss after processing this batch is:  0.002478480339050293\n",
      "\n",
      "The classification loss after processing this batch is:  0.13228900730609894\n",
      "The representation loss after processing this batch is:  0.0021972283720970154\n",
      "\n",
      "The classification loss after processing this batch is:  0.18897175788879395\n",
      "The representation loss after processing this batch is:  0.0023554563522338867\n",
      "\n",
      "The classification loss after processing this batch is:  0.08979996293783188\n",
      "The representation loss after processing this batch is:  0.002331741154193878\n",
      "\n",
      "The classification loss after processing this batch is:  0.03695707023143768\n",
      "The representation loss after processing this batch is:  0.002542652189731598\n",
      "\n",
      "The classification loss after processing this batch is:  0.10747174918651581\n",
      "The representation loss after processing this batch is:  0.0025442689657211304\n",
      "\n",
      "The classification loss after processing this batch is:  0.10607554018497467\n",
      "The representation loss after processing this batch is:  0.0023410990834236145\n",
      "\n",
      "The classification loss after processing this batch is:  0.11736487597227097\n",
      "The representation loss after processing this batch is:  0.00261089950799942\n",
      "\n",
      "The classification loss after processing this batch is:  0.04720533639192581\n",
      "The representation loss after processing this batch is:  0.0022503361105918884\n",
      "\n",
      "The classification loss after processing this batch is:  0.10922719538211823\n",
      "The representation loss after processing this batch is:  0.002304382622241974\n",
      "\n",
      "The classification loss after processing this batch is:  0.12299031764268875\n",
      "The representation loss after processing this batch is:  0.0024178624153137207\n",
      "\n",
      "The classification loss after processing this batch is:  0.13896384835243225\n",
      "The representation loss after processing this batch is:  0.0027047395706176758\n",
      "\n",
      "The classification loss after processing this batch is:  0.13285855948925018\n",
      "The representation loss after processing this batch is:  0.0024636462330818176\n",
      "\n",
      "The classification loss after processing this batch is:  0.09720813482999802\n",
      "The representation loss after processing this batch is:  0.0028184354305267334\n",
      "\n",
      "The classification loss after processing this batch is:  0.09495032578706741\n",
      "The representation loss after processing this batch is:  0.002962253987789154\n",
      "\n",
      "The classification loss after processing this batch is:  0.050709862262010574\n",
      "The representation loss after processing this batch is:  0.0029029250144958496\n",
      "\n",
      "The classification loss after processing this batch is:  0.07026645541191101\n",
      "The representation loss after processing this batch is:  0.0025294050574302673\n",
      "\n",
      "The classification loss after processing this batch is:  0.03614313155412674\n",
      "The representation loss after processing this batch is:  0.002531491219997406\n",
      "\n",
      "The classification loss after processing this batch is:  0.12271950393915176\n",
      "The representation loss after processing this batch is:  0.002681344747543335\n",
      "\n",
      "The classification loss after processing this batch is:  0.05661505088210106\n",
      "The representation loss after processing this batch is:  0.0027501732110977173\n",
      "\n",
      "The classification loss after processing this batch is:  0.19288983941078186\n",
      "The representation loss after processing this batch is:  0.002907194197177887\n",
      "\n",
      "The classification loss after processing this batch is:  0.20821605622768402\n",
      "The representation loss after processing this batch is:  0.002641521394252777\n",
      "\n",
      "The classification loss after processing this batch is:  0.07054592669010162\n",
      "The representation loss after processing this batch is:  0.0027812570333480835\n",
      "\n",
      "The classification loss after processing this batch is:  0.06881009787321091\n",
      "The representation loss after processing this batch is:  0.0027787163853645325\n",
      "\n",
      "The classification loss after processing this batch is:  0.09850622713565826\n",
      "The representation loss after processing this batch is:  0.0022833868861198425\n",
      "\n",
      "The classification loss after processing this batch is:  0.029638119041919708\n",
      "The representation loss after processing this batch is:  0.0026156827807426453\n",
      "\n",
      "The classification loss after processing this batch is:  0.048677168786525726\n",
      "The representation loss after processing this batch is:  0.0026246309280395508\n",
      "\n",
      "The classification loss after processing this batch is:  0.12722931802272797\n",
      "The representation loss after processing this batch is:  0.002357393503189087\n",
      "\n",
      "The classification loss after processing this batch is:  0.05580836907029152\n",
      "The representation loss after processing this batch is:  0.002927340567111969\n",
      "\n",
      "The classification loss after processing this batch is:  0.07238118350505829\n",
      "The representation loss after processing this batch is:  0.002643473446369171\n",
      "\n",
      "The classification loss after processing this batch is:  0.17360781133174896\n",
      "The representation loss after processing this batch is:  0.003051772713661194\n",
      "\n",
      "The classification loss after processing this batch is:  0.19311998784542084\n",
      "The representation loss after processing this batch is:  0.002446502447128296\n",
      "\n",
      "The classification loss after processing this batch is:  0.08374397456645966\n",
      "The representation loss after processing this batch is:  0.002592310309410095\n",
      "\n",
      "The classification loss after processing this batch is:  0.1740889549255371\n",
      "The representation loss after processing this batch is:  0.002792760729789734\n",
      "\n",
      "The classification loss after processing this batch is:  0.13191720843315125\n",
      "The representation loss after processing this batch is:  0.00240982323884964\n",
      "\n",
      "The classification loss after processing this batch is:  0.05751285329461098\n",
      "The representation loss after processing this batch is:  0.0023691505193710327\n",
      "\n",
      "The classification loss after processing this batch is:  0.12553197145462036\n",
      "The representation loss after processing this batch is:  0.0023413747549057007\n",
      "\n",
      "The classification loss after processing this batch is:  0.31189021468162537\n",
      "The representation loss after processing this batch is:  0.0028725937008857727\n",
      "\n",
      "The classification loss after processing this batch is:  0.12804272770881653\n",
      "The representation loss after processing this batch is:  0.003072846680879593\n",
      "\n",
      "The classification loss after processing this batch is:  0.07871751487255096\n",
      "The representation loss after processing this batch is:  0.002871476113796234\n",
      "\n",
      "The classification loss after processing this batch is:  0.046000074595212936\n",
      "The representation loss after processing this batch is:  0.00277584046125412\n",
      "\n",
      "The classification loss after processing this batch is:  0.06005009263753891\n",
      "The representation loss after processing this batch is:  0.002695314586162567\n",
      "\n",
      "The classification loss after processing this batch is:  0.09566959738731384\n",
      "The representation loss after processing this batch is:  0.002812787890434265\n",
      "\n",
      "The classification loss after processing this batch is:  0.08675897866487503\n",
      "The representation loss after processing this batch is:  0.002741292119026184\n",
      "\n",
      "The classification loss after processing this batch is:  0.08662333339452744\n",
      "The representation loss after processing this batch is:  0.0024603642523288727\n",
      "\n",
      "The classification loss after processing this batch is:  0.09511501342058182\n",
      "The representation loss after processing this batch is:  0.0026059746742248535\n",
      "\n",
      "The classification loss after processing this batch is:  0.17850083112716675\n",
      "The representation loss after processing this batch is:  0.0028058961033821106\n",
      "\n",
      "The classification loss after processing this batch is:  0.05495816841721535\n",
      "The representation loss after processing this batch is:  0.002390660345554352\n",
      "\n",
      "The classification loss after processing this batch is:  0.1092914342880249\n",
      "The representation loss after processing this batch is:  0.002215951681137085\n",
      "\n",
      "The classification loss after processing this batch is:  0.07821939885616302\n",
      "The representation loss after processing this batch is:  0.0022885948419570923\n",
      "\n",
      "The classification loss after processing this batch is:  0.11179422587156296\n",
      "The representation loss after processing this batch is:  0.0025153905153274536\n",
      "\n",
      "The classification loss after processing this batch is:  0.0827152207493782\n",
      "The representation loss after processing this batch is:  0.0025337636470794678\n",
      "\n",
      "The classification loss after processing this batch is:  0.15033571422100067\n",
      "The representation loss after processing this batch is:  0.002537764608860016\n",
      "\n",
      "The classification loss after processing this batch is:  0.1166352704167366\n",
      "The representation loss after processing this batch is:  0.0025077909231185913\n",
      "\n",
      "The classification loss after processing this batch is:  0.13262388110160828\n",
      "The representation loss after processing this batch is:  0.0024473369121551514\n",
      "\n",
      "The classification loss after processing this batch is:  0.06067220866680145\n",
      "The representation loss after processing this batch is:  0.002629518508911133\n",
      "\n",
      "The classification loss after processing this batch is:  0.19143204391002655\n",
      "The representation loss after processing this batch is:  0.002552144229412079\n",
      "\n",
      "The classification loss after processing this batch is:  0.13953904807567596\n",
      "The representation loss after processing this batch is:  0.0027487948536872864\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14610685408115387\n",
      "The representation loss after processing this batch is:  0.002728566527366638\n",
      "\n",
      "The classification loss after processing this batch is:  0.060108207166194916\n",
      "The representation loss after processing this batch is:  0.002894282341003418\n",
      "\n",
      "The classification loss after processing this batch is:  0.07655873149633408\n",
      "The representation loss after processing this batch is:  0.0030583664774894714\n",
      "\n",
      "The classification loss after processing this batch is:  0.21399466693401337\n",
      "The representation loss after processing this batch is:  0.0026016011834144592\n",
      "\n",
      "The classification loss after processing this batch is:  0.1859215795993805\n",
      "The representation loss after processing this batch is:  0.0023169629275798798\n",
      "\n",
      "The classification loss after processing this batch is:  0.21483562886714935\n",
      "The representation loss after processing this batch is:  0.002863839268684387\n",
      "\n",
      "The classification loss after processing this batch is:  0.2687079608440399\n",
      "The representation loss after processing this batch is:  0.0025108829140663147\n",
      "\n",
      "The classification loss after processing this batch is:  0.19152693450450897\n",
      "The representation loss after processing this batch is:  0.002271391451358795\n",
      "\n",
      "The classification loss after processing this batch is:  0.04853690415620804\n",
      "The representation loss after processing this batch is:  0.002512045204639435\n",
      "\n",
      "The classification loss after processing this batch is:  0.04942677915096283\n",
      "The representation loss after processing this batch is:  0.002387039363384247\n",
      "\n",
      "The classification loss after processing this batch is:  0.07417688518762589\n",
      "The representation loss after processing this batch is:  0.0026781708002090454\n",
      "\n",
      "The classification loss after processing this batch is:  0.09688472002744675\n",
      "The representation loss after processing this batch is:  0.0033808350563049316\n",
      "\n",
      "The classification loss after processing this batch is:  0.032228000462055206\n",
      "The representation loss after processing this batch is:  0.002822175621986389\n",
      "\n",
      "The classification loss after processing this batch is:  0.1453143060207367\n",
      "The representation loss after processing this batch is:  0.003519974648952484\n",
      "\n",
      "The classification loss after processing this batch is:  0.1224268302321434\n",
      "The representation loss after processing this batch is:  0.0024436265230178833\n",
      "\n",
      "The classification loss after processing this batch is:  0.10783987492322922\n",
      "The representation loss after processing this batch is:  0.002574671059846878\n",
      "\n",
      "The classification loss after processing this batch is:  0.15535633265972137\n",
      "The representation loss after processing this batch is:  0.002548418939113617\n",
      "\n",
      "The classification loss after processing this batch is:  0.08228909224271774\n",
      "The representation loss after processing this batch is:  0.0027773678302764893\n",
      "\n",
      "The classification loss after processing this batch is:  0.10456664860248566\n",
      "The representation loss after processing this batch is:  0.0031907185912132263\n",
      "\n",
      "The classification loss after processing this batch is:  0.1312892735004425\n",
      "The representation loss after processing this batch is:  0.00298299640417099\n",
      "\n",
      "The classification loss after processing this batch is:  0.09150543808937073\n",
      "The representation loss after processing this batch is:  0.00301390141248703\n",
      "\n",
      "The classification loss after processing this batch is:  0.09196502715349197\n",
      "The representation loss after processing this batch is:  0.0023275986313819885\n",
      "\n",
      "The classification loss after processing this batch is:  0.042394496500492096\n",
      "The representation loss after processing this batch is:  0.002502530813217163\n",
      "\n",
      "The classification loss after processing this batch is:  0.024984819814562798\n",
      "The representation loss after processing this batch is:  0.0025641247630119324\n",
      "\n",
      "The classification loss after processing this batch is:  0.06501194089651108\n",
      "The representation loss after processing this batch is:  0.002348862588405609\n",
      "\n",
      "The classification loss after processing this batch is:  0.05087076872587204\n",
      "The representation loss after processing this batch is:  0.0024386681616306305\n",
      "\n",
      "The classification loss after processing this batch is:  0.06595031917095184\n",
      "The representation loss after processing this batch is:  0.0021441057324409485\n",
      "\n",
      "The classification loss after processing this batch is:  0.09292875975370407\n",
      "The representation loss after processing this batch is:  0.002478383481502533\n",
      "\n",
      "The classification loss after processing this batch is:  0.09523700922727585\n",
      "The representation loss after processing this batch is:  0.0024649351835250854\n",
      "\n",
      "The classification loss after processing this batch is:  0.33056116104125977\n",
      "The representation loss after processing this batch is:  0.002840273082256317\n",
      "\n",
      "The classification loss after processing this batch is:  0.19933655858039856\n",
      "The representation loss after processing this batch is:  0.002728782594203949\n",
      "\n",
      "The classification loss after processing this batch is:  0.06656767427921295\n",
      "The representation loss after processing this batch is:  0.0025374293327331543\n",
      "\n",
      "The classification loss after processing this batch is:  0.05639182776212692\n",
      "The representation loss after processing this batch is:  0.002706654369831085\n",
      "\n",
      "The classification loss after processing this batch is:  0.04886739328503609\n",
      "The representation loss after processing this batch is:  0.0025744661688804626\n",
      "\n",
      "The classification loss after processing this batch is:  0.04458996281027794\n",
      "The representation loss after processing this batch is:  0.0025787651538848877\n",
      "\n",
      "The classification loss after processing this batch is:  0.021444793790578842\n",
      "The representation loss after processing this batch is:  0.0027428343892097473\n",
      "\n",
      "The classification loss after processing this batch is:  0.06100520119071007\n",
      "The representation loss after processing this batch is:  0.002700038254261017\n",
      "\n",
      "The classification loss after processing this batch is:  0.06953232735395432\n",
      "The representation loss after processing this batch is:  0.002243936061859131\n",
      "\n",
      "The classification loss after processing this batch is:  0.18501491844654083\n",
      "The representation loss after processing this batch is:  0.00254647433757782\n",
      "\n",
      "The classification loss after processing this batch is:  0.10099644213914871\n",
      "The representation loss after processing this batch is:  0.002353079617023468\n",
      "\n",
      "The classification loss after processing this batch is:  0.04868602752685547\n",
      "The representation loss after processing this batch is:  0.00251692533493042\n",
      "\n",
      "The classification loss after processing this batch is:  0.0361982025206089\n",
      "The representation loss after processing this batch is:  0.002480536699295044\n",
      "\n",
      "The classification loss after processing this batch is:  0.210892915725708\n",
      "The representation loss after processing this batch is:  0.0024664849042892456\n",
      "\n",
      "The classification loss after processing this batch is:  0.06439925730228424\n",
      "The representation loss after processing this batch is:  0.002676442265510559\n",
      "\n",
      "The classification loss after processing this batch is:  0.06025385111570358\n",
      "The representation loss after processing this batch is:  0.002449318766593933\n",
      "\n",
      "The classification loss after processing this batch is:  0.07615355402231216\n",
      "The representation loss after processing this batch is:  0.0026854723691940308\n",
      "\n",
      "The classification loss after processing this batch is:  0.07830896973609924\n",
      "The representation loss after processing this batch is:  0.002198547124862671\n",
      "\n",
      "The classification loss after processing this batch is:  0.030976930633187294\n",
      "The representation loss after processing this batch is:  0.0023700594902038574\n",
      "\n",
      "The classification loss after processing this batch is:  0.08151605725288391\n",
      "The representation loss after processing this batch is:  0.0024210065603256226\n",
      "\n",
      "The classification loss after processing this batch is:  0.05730697140097618\n",
      "The representation loss after processing this batch is:  0.0024870112538337708\n",
      "\n",
      "The classification loss after processing this batch is:  0.062104545533657074\n",
      "The representation loss after processing this batch is:  0.0024680569767951965\n",
      "\n",
      "The classification loss after processing this batch is:  0.126103937625885\n",
      "The representation loss after processing this batch is:  0.0022699832916259766\n",
      "\n",
      "The classification loss after processing this batch is:  0.1375768929719925\n",
      "The representation loss after processing this batch is:  0.002506166696548462\n",
      "\n",
      "The classification loss after processing this batch is:  0.1408601850271225\n",
      "The representation loss after processing this batch is:  0.002430647611618042\n",
      "\n",
      "The classification loss after processing this batch is:  0.13117475807666779\n",
      "The representation loss after processing this batch is:  0.002480454742908478\n",
      "\n",
      "The classification loss after processing this batch is:  0.06537486612796783\n",
      "The representation loss after processing this batch is:  0.0025107935070991516\n",
      "\n",
      "The classification loss after processing this batch is:  0.12525290250778198\n",
      "The representation loss after processing this batch is:  0.002630196511745453\n",
      "\n",
      "The classification loss after processing this batch is:  0.059379253536462784\n",
      "The representation loss after processing this batch is:  0.0028932541608810425\n",
      "\n",
      "The classification loss after processing this batch is:  0.10009251534938812\n",
      "The representation loss after processing this batch is:  0.002545353025197983\n",
      "\n",
      "The classification loss after processing this batch is:  0.04362799599766731\n",
      "The representation loss after processing this batch is:  0.002334214746952057\n",
      "\n",
      "The classification loss after processing this batch is:  0.14105600118637085\n",
      "The representation loss after processing this batch is:  0.002420194447040558\n",
      "\n",
      "The classification loss after processing this batch is:  0.056482721120119095\n",
      "The representation loss after processing this batch is:  0.0026548728346824646\n",
      "\n",
      "The classification loss after processing this batch is:  0.07277728617191315\n",
      "The representation loss after processing this batch is:  0.002312473952770233\n",
      "\n",
      "The classification loss after processing this batch is:  0.0923214703798294\n",
      "The representation loss after processing this batch is:  0.0023004263639450073\n",
      "\n",
      "The classification loss after processing this batch is:  0.07795733958482742\n",
      "The representation loss after processing this batch is:  0.002481803297996521\n",
      "\n",
      "The classification loss after processing this batch is:  0.11956951022148132\n",
      "The representation loss after processing this batch is:  0.002342328429222107\n",
      "\n",
      "The classification loss after processing this batch is:  0.08094239979982376\n",
      "The representation loss after processing this batch is:  0.0021854303777217865\n",
      "\n",
      "The classification loss after processing this batch is:  0.15199358761310577\n",
      "The representation loss after processing this batch is:  0.002316746860742569\n",
      "\n",
      "The classification loss after processing this batch is:  0.14771832525730133\n",
      "The representation loss after processing this batch is:  0.0024222135543823242\n",
      "\n",
      "The classification loss after processing this batch is:  0.21032875776290894\n",
      "The representation loss after processing this batch is:  0.002331092953681946\n",
      "\n",
      "The classification loss after processing this batch is:  0.1510259211063385\n",
      "The representation loss after processing this batch is:  0.002279214560985565\n",
      "\n",
      "The classification loss after processing this batch is:  0.06369668245315552\n",
      "The representation loss after processing this batch is:  0.0025939494371414185\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14997166395187378\n",
      "The representation loss after processing this batch is:  0.002678222954273224\n",
      "\n",
      "The classification loss after processing this batch is:  0.07188592106103897\n",
      "The representation loss after processing this batch is:  0.0027185529470443726\n",
      "\n",
      "The classification loss after processing this batch is:  0.06530449539422989\n",
      "The representation loss after processing this batch is:  0.0027978084981441498\n",
      "\n",
      "The classification loss after processing this batch is:  0.1676710695028305\n",
      "The representation loss after processing this batch is:  0.003126196563243866\n",
      "\n",
      "The classification loss after processing this batch is:  0.13993456959724426\n",
      "The representation loss after processing this batch is:  0.0027514994144439697\n",
      "\n",
      "The classification loss after processing this batch is:  0.24683554470539093\n",
      "The representation loss after processing this batch is:  0.0026350468397140503\n",
      "\n",
      "The classification loss after processing this batch is:  0.11321084201335907\n",
      "The representation loss after processing this batch is:  0.0026836171746253967\n",
      "\n",
      "The classification loss after processing this batch is:  0.050023023039102554\n",
      "The representation loss after processing this batch is:  0.0026112794876098633\n",
      "\n",
      "The classification loss after processing this batch is:  0.0692264512181282\n",
      "The representation loss after processing this batch is:  0.0026047751307487488\n",
      "\n",
      "The classification loss after processing this batch is:  0.15630339086055756\n",
      "The representation loss after processing this batch is:  0.002182498574256897\n",
      "\n",
      "The classification loss after processing this batch is:  0.08377277106046677\n",
      "The representation loss after processing this batch is:  0.00255487859249115\n",
      "\n",
      "The classification loss after processing this batch is:  0.0801507756114006\n",
      "The representation loss after processing this batch is:  0.0022656098008155823\n",
      "\n",
      "The classification loss after processing this batch is:  0.06483236700296402\n",
      "The representation loss after processing this batch is:  0.0025872141122817993\n",
      "\n",
      "The classification loss after processing this batch is:  0.02421944960951805\n",
      "The representation loss after processing this batch is:  0.0024648532271385193\n",
      "\n",
      "The classification loss after processing this batch is:  0.10248249024152756\n",
      "The representation loss after processing this batch is:  0.0027245432138442993\n",
      "\n",
      "The classification loss after processing this batch is:  0.10676218569278717\n",
      "The representation loss after processing this batch is:  0.002949994057416916\n",
      "\n",
      "The classification loss after processing this batch is:  0.15134011209011078\n",
      "The representation loss after processing this batch is:  0.00244884192943573\n",
      "\n",
      "The classification loss after processing this batch is:  0.13167931139469147\n",
      "The representation loss after processing this batch is:  0.002178192138671875\n",
      "\n",
      "The classification loss after processing this batch is:  0.09298066049814224\n",
      "The representation loss after processing this batch is:  0.0025970712304115295\n",
      "\n",
      "The classification loss after processing this batch is:  0.12003355473279953\n",
      "The representation loss after processing this batch is:  0.00264083594083786\n",
      "\n",
      "The classification loss after processing this batch is:  0.10578686743974686\n",
      "The representation loss after processing this batch is:  0.0024551264941692352\n",
      "\n",
      "The classification loss after processing this batch is:  0.09591972082853317\n",
      "The representation loss after processing this batch is:  0.0028909817337989807\n",
      "\n",
      "The classification loss after processing this batch is:  0.11936428397893906\n",
      "The representation loss after processing this batch is:  0.002634584903717041\n",
      "\n",
      "The classification loss after processing this batch is:  0.11038515716791153\n",
      "The representation loss after processing this batch is:  0.0029451027512550354\n",
      "\n",
      "The classification loss after processing this batch is:  0.12515395879745483\n",
      "The representation loss after processing this batch is:  0.0024109184741973877\n",
      "\n",
      "The classification loss after processing this batch is:  0.1987607628107071\n",
      "The representation loss after processing this batch is:  0.0024315454065799713\n",
      "\n",
      "The classification loss after processing this batch is:  0.1489904373884201\n",
      "The representation loss after processing this batch is:  0.002669617533683777\n",
      "\n",
      "The classification loss after processing this batch is:  0.05985959619283676\n",
      "The representation loss after processing this batch is:  0.0022346898913383484\n",
      "\n",
      "The classification loss after processing this batch is:  0.09978895634412766\n",
      "The representation loss after processing this batch is:  0.0028589703142642975\n",
      "\n",
      "The classification loss after processing this batch is:  0.10055027157068253\n",
      "The representation loss after processing this batch is:  0.0024657025933265686\n",
      "\n",
      "The classification loss after processing this batch is:  0.09195184707641602\n",
      "The representation loss after processing this batch is:  0.0024926848709583282\n",
      "\n",
      "The classification loss after processing this batch is:  0.13100777566432953\n",
      "The representation loss after processing this batch is:  0.00287473201751709\n",
      "\n",
      "The classification loss after processing this batch is:  0.22263380885124207\n",
      "The representation loss after processing this batch is:  0.00287637859582901\n",
      "\n",
      "The classification loss after processing this batch is:  0.21143551170825958\n",
      "The representation loss after processing this batch is:  0.0030201226472854614\n",
      "\n",
      "The classification loss after processing this batch is:  0.11070714145898819\n",
      "The representation loss after processing this batch is:  0.0026910677552223206\n",
      "\n",
      "The classification loss after processing this batch is:  0.11478444933891296\n",
      "The representation loss after processing this batch is:  0.0024881288409233093\n",
      "\n",
      "The classification loss after processing this batch is:  0.07262597233057022\n",
      "The representation loss after processing this batch is:  0.0029153749346733093\n",
      "\n",
      "The classification loss after processing this batch is:  0.04694122448563576\n",
      "The representation loss after processing this batch is:  0.0026214420795440674\n",
      "\n",
      "The classification loss after processing this batch is:  0.13393622636795044\n",
      "The representation loss after processing this batch is:  0.002657715231180191\n",
      "\n",
      "The classification loss after processing this batch is:  0.0874629020690918\n",
      "The representation loss after processing this batch is:  0.0025053322315216064\n",
      "\n",
      "The classification loss after processing this batch is:  0.07254791259765625\n",
      "The representation loss after processing this batch is:  0.0023803114891052246\n",
      "\n",
      "The classification loss after processing this batch is:  0.09172752499580383\n",
      "The representation loss after processing this batch is:  0.002581290900707245\n",
      "\n",
      "The classification loss after processing this batch is:  0.09707776457071304\n",
      "The representation loss after processing this batch is:  0.0028488412499427795\n",
      "\n",
      "The classification loss after processing this batch is:  0.16610918939113617\n",
      "The representation loss after processing this batch is:  0.0024098530411720276\n",
      "\n",
      "The classification loss after processing this batch is:  0.10594873130321503\n",
      "The representation loss after processing this batch is:  0.0026182010769844055\n",
      "\n",
      "The classification loss after processing this batch is:  0.0669797733426094\n",
      "The representation loss after processing this batch is:  0.002395845949649811\n",
      "\n",
      "The classification loss after processing this batch is:  0.031005743891000748\n",
      "The representation loss after processing this batch is:  0.002392992377281189\n",
      "\n",
      "The classification loss after processing this batch is:  0.09914948046207428\n",
      "The representation loss after processing this batch is:  0.0022524669766426086\n",
      "\n",
      "The classification loss after processing this batch is:  0.08678105473518372\n",
      "The representation loss after processing this batch is:  0.0022347085177898407\n",
      "\n",
      "The classification loss after processing this batch is:  0.37601155042648315\n",
      "The representation loss after processing this batch is:  0.0027143582701683044\n",
      "\n",
      "The classification loss after processing this batch is:  0.07779032737016678\n",
      "The representation loss after processing this batch is:  0.0023709312081336975\n",
      "\n",
      "The classification loss after processing this batch is:  0.17331448197364807\n",
      "The representation loss after processing this batch is:  0.002431236207485199\n",
      "\n",
      "The classification loss after processing this batch is:  0.24225471913814545\n",
      "The representation loss after processing this batch is:  0.0026273727416992188\n",
      "\n",
      "The classification loss after processing this batch is:  0.06163693219423294\n",
      "The representation loss after processing this batch is:  0.002672716975212097\n",
      "\n",
      "The classification loss after processing this batch is:  0.1811506599187851\n",
      "The representation loss after processing this batch is:  0.0030712857842445374\n",
      "\n",
      "The classification loss after processing this batch is:  0.11104673892259598\n",
      "The representation loss after processing this batch is:  0.002700917422771454\n",
      "\n",
      "The classification loss after processing this batch is:  0.17291420698165894\n",
      "The representation loss after processing this batch is:  0.0024319998919963837\n",
      "\n",
      "The classification loss after processing this batch is:  0.03648260608315468\n",
      "The representation loss after processing this batch is:  0.0022978633642196655\n",
      "\n",
      "The classification loss after processing this batch is:  0.06585205346345901\n",
      "The representation loss after processing this batch is:  0.002615034580230713\n",
      "\n",
      "The classification loss after processing this batch is:  0.04247978702187538\n",
      "The representation loss after processing this batch is:  0.0027461498975753784\n",
      "\n",
      "The classification loss after processing this batch is:  0.027051789686083794\n",
      "The representation loss after processing this batch is:  0.0026016682386398315\n",
      "\n",
      "The classification loss after processing this batch is:  0.07387612015008926\n",
      "The representation loss after processing this batch is:  0.002611219882965088\n",
      "\n",
      "The classification loss after processing this batch is:  0.04215254634618759\n",
      "The representation loss after processing this batch is:  0.0022922977805137634\n",
      "\n",
      "The classification loss after processing this batch is:  0.12170100212097168\n",
      "The representation loss after processing this batch is:  0.002781599760055542\n",
      "\n",
      "The classification loss after processing this batch is:  0.04739755764603615\n",
      "The representation loss after processing this batch is:  0.00288526713848114\n",
      "\n",
      "The classification loss after processing this batch is:  0.06306609511375427\n",
      "The representation loss after processing this batch is:  0.0023305118083953857\n",
      "\n",
      "The classification loss after processing this batch is:  0.08631622791290283\n",
      "The representation loss after processing this batch is:  0.0023473650217056274\n",
      "\n",
      "The classification loss after processing this batch is:  0.031669918447732925\n",
      "The representation loss after processing this batch is:  0.0023588761687278748\n",
      "\n",
      "The classification loss after processing this batch is:  0.12348129600286484\n",
      "The representation loss after processing this batch is:  0.0025876611471176147\n",
      "\n",
      "The classification loss after processing this batch is:  0.10256246477365494\n",
      "The representation loss after processing this batch is:  0.002603106200695038\n",
      "\n",
      "The classification loss after processing this batch is:  0.2033652663230896\n",
      "The representation loss after processing this batch is:  0.0028951838612556458\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.06990217417478561\n",
      "The representation loss after processing this batch is:  0.0023744404315948486\n",
      "\n",
      "The classification loss after processing this batch is:  0.0621863417327404\n",
      "The representation loss after processing this batch is:  0.002220381051301956\n",
      "\n",
      "The classification loss after processing this batch is:  0.1727634072303772\n",
      "The representation loss after processing this batch is:  0.0028804168105125427\n",
      "\n",
      "The classification loss after processing this batch is:  0.13366125524044037\n",
      "The representation loss after processing this batch is:  0.0025465860962867737\n",
      "\n",
      "The classification loss after processing this batch is:  0.109422467648983\n",
      "The representation loss after processing this batch is:  0.002716958522796631\n",
      "\n",
      "The classification loss after processing this batch is:  0.03580766171216965\n",
      "The representation loss after processing this batch is:  0.0024620741605758667\n",
      "\n",
      "The classification loss after processing this batch is:  0.08536861091852188\n",
      "The representation loss after processing this batch is:  0.002567470073699951\n",
      "\n",
      "The classification loss after processing this batch is:  0.08662295341491699\n",
      "The representation loss after processing this batch is:  0.002561792731285095\n",
      "\n",
      "The classification loss after processing this batch is:  0.0991142988204956\n",
      "The representation loss after processing this batch is:  0.0030830204486846924\n",
      "\n",
      "The classification loss after processing this batch is:  0.09377463907003403\n",
      "The representation loss after processing this batch is:  0.00285349041223526\n",
      "\n",
      "The classification loss after processing this batch is:  0.06676309555768967\n",
      "The representation loss after processing this batch is:  0.0031257569789886475\n",
      "\n",
      "The classification loss after processing this batch is:  0.11523918807506561\n",
      "The representation loss after processing this batch is:  0.003089204430580139\n",
      "\n",
      "The classification loss after processing this batch is:  0.20321203768253326\n",
      "The representation loss after processing this batch is:  0.0024830996990203857\n",
      "\n",
      "The classification loss after processing this batch is:  0.08196663856506348\n",
      "The representation loss after processing this batch is:  0.003060169517993927\n",
      "\n",
      "The classification loss after processing this batch is:  0.11102358996868134\n",
      "The representation loss after processing this batch is:  0.0024786368012428284\n",
      "\n",
      "The classification loss after processing this batch is:  0.049663059413433075\n",
      "The representation loss after processing this batch is:  0.002388007938861847\n",
      "\n",
      "The classification loss after processing this batch is:  0.18215033411979675\n",
      "The representation loss after processing this batch is:  0.0023902207612991333\n",
      "\n",
      "The classification loss after processing this batch is:  0.05478636547923088\n",
      "The representation loss after processing this batch is:  0.0024724081158638\n",
      "\n",
      "The classification loss after processing this batch is:  0.11423448473215103\n",
      "The representation loss after processing this batch is:  0.0026301294565200806\n",
      "\n",
      "The classification loss after processing this batch is:  0.0683755949139595\n",
      "The representation loss after processing this batch is:  0.0027887150645256042\n",
      "\n",
      "The classification loss after processing this batch is:  0.09623869508504868\n",
      "The representation loss after processing this batch is:  0.0025974884629249573\n",
      "\n",
      "The classification loss after processing this batch is:  0.11804988235235214\n",
      "The representation loss after processing this batch is:  0.002626366913318634\n",
      "\n",
      "The classification loss after processing this batch is:  0.12576594948768616\n",
      "The representation loss after processing this batch is:  0.0029882267117500305\n",
      "\n",
      "The classification loss after processing this batch is:  0.10385354608297348\n",
      "The representation loss after processing this batch is:  0.002718791365623474\n",
      "\n",
      "The classification loss after processing this batch is:  0.11259867250919342\n",
      "The representation loss after processing this batch is:  0.0023995712399482727\n",
      "\n",
      "The classification loss after processing this batch is:  0.13862162828445435\n",
      "The representation loss after processing this batch is:  0.002811431884765625\n",
      "\n",
      "The classification loss after processing this batch is:  0.0937313586473465\n",
      "The representation loss after processing this batch is:  0.0024458691477775574\n",
      "\n",
      "The classification loss after processing this batch is:  0.09258931130170822\n",
      "The representation loss after processing this batch is:  0.00250871479511261\n",
      "\n",
      "The classification loss after processing this batch is:  0.04038465768098831\n",
      "The representation loss after processing this batch is:  0.0029318928718566895\n",
      "\n",
      "The classification loss after processing this batch is:  0.06403850764036179\n",
      "The representation loss after processing this batch is:  0.0025864169001579285\n",
      "\n",
      "The classification loss after processing this batch is:  0.041339825838804245\n",
      "The representation loss after processing this batch is:  0.0024757608771324158\n",
      "\n",
      "The classification loss after processing this batch is:  0.04989826679229736\n",
      "The representation loss after processing this batch is:  0.002420686185359955\n",
      "\n",
      "The classification loss after processing this batch is:  0.05036360025405884\n",
      "The representation loss after processing this batch is:  0.002572871744632721\n",
      "\n",
      "The classification loss after processing this batch is:  0.03130161017179489\n",
      "The representation loss after processing this batch is:  0.0028841719031333923\n",
      "\n",
      "The classification loss after processing this batch is:  0.1004350557923317\n",
      "The representation loss after processing this batch is:  0.0023559853434562683\n",
      "\n",
      "The classification loss after processing this batch is:  0.06669481843709946\n",
      "The representation loss after processing this batch is:  0.0022321343421936035\n",
      "\n",
      "The classification loss after processing this batch is:  0.10177501291036606\n",
      "The representation loss after processing this batch is:  0.0024759024381637573\n",
      "\n",
      "The classification loss after processing this batch is:  0.045522116124629974\n",
      "The representation loss after processing this batch is:  0.0026817843317985535\n",
      "\n",
      "The classification loss after processing this batch is:  0.1501060426235199\n",
      "The representation loss after processing this batch is:  0.0024428293108940125\n",
      "\n",
      "The classification loss after processing this batch is:  0.1357748657464981\n",
      "The representation loss after processing this batch is:  0.0025580450892448425\n",
      "\n",
      "The classification loss after processing this batch is:  0.0909840315580368\n",
      "The representation loss after processing this batch is:  0.002506367862224579\n",
      "\n",
      "The classification loss after processing this batch is:  0.09746956080198288\n",
      "The representation loss after processing this batch is:  0.0027744323015213013\n",
      "\n",
      "The classification loss after processing this batch is:  0.09134631603956223\n",
      "The representation loss after processing this batch is:  0.002768009901046753\n",
      "\n",
      "The classification loss after processing this batch is:  0.027525408193469048\n",
      "The representation loss after processing this batch is:  0.0023595988750457764\n",
      "\n",
      "The classification loss after processing this batch is:  0.06273258477449417\n",
      "The representation loss after processing this batch is:  0.002547256648540497\n",
      "\n",
      "The classification loss after processing this batch is:  0.056897856295108795\n",
      "The representation loss after processing this batch is:  0.0022481903433799744\n",
      "\n",
      "The classification loss after processing this batch is:  0.20194891095161438\n",
      "The representation loss after processing this batch is:  0.002728968858718872\n",
      "\n",
      "The classification loss after processing this batch is:  0.14059048891067505\n",
      "The representation loss after processing this batch is:  0.002386622130870819\n",
      "\n",
      "The classification loss after processing this batch is:  0.13372142612934113\n",
      "The representation loss after processing this batch is:  0.003300964832305908\n",
      "\n",
      "The classification loss after processing this batch is:  0.14135827124118805\n",
      "The representation loss after processing this batch is:  0.002540990710258484\n",
      "\n",
      "The classification loss after processing this batch is:  0.1534491628408432\n",
      "The representation loss after processing this batch is:  0.0027923211455345154\n",
      "\n",
      "The classification loss after processing this batch is:  0.1747797429561615\n",
      "The representation loss after processing this batch is:  0.002296037971973419\n",
      "\n",
      "The classification loss after processing this batch is:  0.22729995846748352\n",
      "The representation loss after processing this batch is:  0.002483028918504715\n",
      "\n",
      "The classification loss after processing this batch is:  0.14381805062294006\n",
      "The representation loss after processing this batch is:  0.00244169682264328\n",
      "\n",
      "The classification loss after processing this batch is:  0.08725332468748093\n",
      "The representation loss after processing this batch is:  0.0021136924624443054\n",
      "\n",
      "The classification loss after processing this batch is:  0.07518896460533142\n",
      "The representation loss after processing this batch is:  0.0025860443711280823\n",
      "\n",
      "The classification loss after processing this batch is:  0.037407271564006805\n",
      "The representation loss after processing this batch is:  0.002331957221031189\n",
      "\n",
      "The classification loss after processing this batch is:  0.05584178864955902\n",
      "The representation loss after processing this batch is:  0.0024599581956863403\n",
      "\n",
      "The classification loss after processing this batch is:  0.04857417568564415\n",
      "The representation loss after processing this batch is:  0.0030523017048835754\n",
      "\n",
      "The classification loss after processing this batch is:  0.10913700610399246\n",
      "The representation loss after processing this batch is:  0.0022679120302200317\n",
      "\n",
      "The classification loss after processing this batch is:  0.06017889454960823\n",
      "The representation loss after processing this batch is:  0.0025976449251174927\n",
      "\n",
      "The classification loss after processing this batch is:  0.15371674299240112\n",
      "The representation loss after processing this batch is:  0.002443350851535797\n",
      "\n",
      "The classification loss after processing this batch is:  0.11369872093200684\n",
      "The representation loss after processing this batch is:  0.0026906654238700867\n",
      "\n",
      "The classification loss after processing this batch is:  0.14999768137931824\n",
      "The representation loss after processing this batch is:  0.0024504773318767548\n",
      "\n",
      "The classification loss after processing this batch is:  0.09771202504634857\n",
      "The representation loss after processing this batch is:  0.002330876886844635\n",
      "\n",
      "The classification loss after processing this batch is:  0.14209847152233124\n",
      "The representation loss after processing this batch is:  0.0024409927427768707\n",
      "\n",
      "The classification loss after processing this batch is:  0.10525668412446976\n",
      "The representation loss after processing this batch is:  0.0023621171712875366\n",
      "\n",
      "The classification loss after processing this batch is:  0.06683393567800522\n",
      "The representation loss after processing this batch is:  0.0024887993931770325\n",
      "\n",
      "The classification loss after processing this batch is:  0.16294343769550323\n",
      "The representation loss after processing this batch is:  0.0024266093969345093\n",
      "\n",
      "The classification loss after processing this batch is:  0.03551473468542099\n",
      "The representation loss after processing this batch is:  0.0023103952407836914\n",
      "\n",
      "The classification loss after processing this batch is:  0.03353572636842728\n",
      "The representation loss after processing this batch is:  0.002246551215648651\n",
      "\n",
      "The classification loss after processing this batch is:  0.0892472118139267\n",
      "The representation loss after processing this batch is:  0.0028576478362083435\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.13263027369976044\n",
      "The representation loss after processing this batch is:  0.002651005983352661\n",
      "\n",
      "The classification loss after processing this batch is:  0.09990047663450241\n",
      "The representation loss after processing this batch is:  0.0028012841939926147\n",
      "\n",
      "The classification loss after processing this batch is:  0.05499209836125374\n",
      "The representation loss after processing this batch is:  0.0028652623295783997\n",
      "\n",
      "The classification loss after processing this batch is:  0.09847304970026016\n",
      "The representation loss after processing this batch is:  0.0028920844197273254\n",
      "\n",
      "The classification loss after processing this batch is:  0.08112803101539612\n",
      "The representation loss after processing this batch is:  0.002596229314804077\n",
      "\n",
      "The classification loss after processing this batch is:  0.16053564846515656\n",
      "The representation loss after processing this batch is:  0.0025064945220947266\n",
      "\n",
      "The classification loss after processing this batch is:  0.043453898280858994\n",
      "The representation loss after processing this batch is:  0.0022984594106674194\n",
      "\n",
      "The classification loss after processing this batch is:  0.0442098043859005\n",
      "The representation loss after processing this batch is:  0.0027500763535499573\n",
      "\n",
      "The classification loss after processing this batch is:  0.12268727272748947\n",
      "The representation loss after processing this batch is:  0.0033138543367385864\n",
      "\n",
      "The classification loss after processing this batch is:  0.10438324511051178\n",
      "The representation loss after processing this batch is:  0.0027105212211608887\n",
      "\n",
      "The classification loss after processing this batch is:  0.07356004416942596\n",
      "The representation loss after processing this batch is:  0.0029461830854415894\n",
      "\n",
      "The classification loss after processing this batch is:  0.0595136322081089\n",
      "The representation loss after processing this batch is:  0.002455085515975952\n",
      "\n",
      "The classification loss after processing this batch is:  0.12578482925891876\n",
      "The representation loss after processing this batch is:  0.0028099417686462402\n",
      "\n",
      "The classification loss after processing this batch is:  0.14180737733840942\n",
      "The representation loss after processing this batch is:  0.0028410404920578003\n",
      "\n",
      "The classification loss after processing this batch is:  0.17718766629695892\n",
      "The representation loss after processing this batch is:  0.002460673451423645\n",
      "\n",
      "The classification loss after processing this batch is:  0.10339591652154922\n",
      "The representation loss after processing this batch is:  0.0030294805765151978\n",
      "\n",
      "The classification loss after processing this batch is:  0.03139694407582283\n",
      "The representation loss after processing this batch is:  0.0025725439190864563\n",
      "\n",
      "The classification loss after processing this batch is:  0.05233830586075783\n",
      "The representation loss after processing this batch is:  0.002328716218471527\n",
      "\n",
      "The classification loss after processing this batch is:  0.13031211495399475\n",
      "The representation loss after processing this batch is:  0.0028118714690208435\n",
      "\n",
      "The classification loss after processing this batch is:  0.1721898466348648\n",
      "The representation loss after processing this batch is:  0.0030700713396072388\n",
      "\n",
      "The classification loss after processing this batch is:  0.20774364471435547\n",
      "The representation loss after processing this batch is:  0.0030060410499572754\n",
      "\n",
      "The classification loss after processing this batch is:  0.204848974943161\n",
      "The representation loss after processing this batch is:  0.0025697126984596252\n",
      "\n",
      "The classification loss after processing this batch is:  0.062424976378679276\n",
      "The representation loss after processing this batch is:  0.0023209750652313232\n",
      "\n",
      "The classification loss after processing this batch is:  0.13067840039730072\n",
      "The representation loss after processing this batch is:  0.0023795366287231445\n",
      "\n",
      "The classification loss after processing this batch is:  0.0766395702958107\n",
      "The representation loss after processing this batch is:  0.0025336742401123047\n",
      "\n",
      "The classification loss after processing this batch is:  0.0750880092382431\n",
      "The representation loss after processing this batch is:  0.0025655999779701233\n",
      "\n",
      "The classification loss after processing this batch is:  0.041795723140239716\n",
      "The representation loss after processing this batch is:  0.00250793993473053\n",
      "\n",
      "The classification loss after processing this batch is:  0.15169286727905273\n",
      "The representation loss after processing this batch is:  0.002324916422367096\n",
      "\n",
      "The classification loss after processing this batch is:  0.06968121230602264\n",
      "The representation loss after processing this batch is:  0.002363063395023346\n",
      "\n",
      "The classification loss after processing this batch is:  0.10458449274301529\n",
      "The representation loss after processing this batch is:  0.0023266300559043884\n",
      "\n",
      "The classification loss after processing this batch is:  0.1172509491443634\n",
      "The representation loss after processing this batch is:  0.002559967339038849\n",
      "\n",
      "The classification loss after processing this batch is:  0.03769487515091896\n",
      "The representation loss after processing this batch is:  0.002683497965335846\n",
      "\n",
      "The classification loss after processing this batch is:  0.10015349835157394\n",
      "The representation loss after processing this batch is:  0.0027129873633384705\n",
      "\n",
      "The classification loss after processing this batch is:  0.09834977984428406\n",
      "The representation loss after processing this batch is:  0.0024982988834381104\n",
      "\n",
      "The classification loss after processing this batch is:  0.08069254457950592\n",
      "The representation loss after processing this batch is:  0.0025590360164642334\n",
      "\n",
      "The classification loss after processing this batch is:  0.04510512575507164\n",
      "The representation loss after processing this batch is:  0.002845354378223419\n",
      "\n",
      "The classification loss after processing this batch is:  0.06609862297773361\n",
      "The representation loss after processing this batch is:  0.002336665987968445\n",
      "\n",
      "The classification loss after processing this batch is:  0.20206664502620697\n",
      "The representation loss after processing this batch is:  0.003099285066127777\n",
      "\n",
      "The classification loss after processing this batch is:  0.1345718502998352\n",
      "The representation loss after processing this batch is:  0.0024462714791297913\n",
      "\n",
      "The classification loss after processing this batch is:  0.08841351419687271\n",
      "The representation loss after processing this batch is:  0.002376250922679901\n",
      "\n",
      "The classification loss after processing this batch is:  0.06929910182952881\n",
      "The representation loss after processing this batch is:  0.002200428396463394\n",
      "\n",
      "The classification loss after processing this batch is:  0.06147218868136406\n",
      "The representation loss after processing this batch is:  0.002569541335105896\n",
      "\n",
      "The classification loss after processing this batch is:  0.07661128044128418\n",
      "The representation loss after processing this batch is:  0.002329528331756592\n",
      "\n",
      "The classification loss after processing this batch is:  0.10427374392747879\n",
      "The representation loss after processing this batch is:  0.0024656355381011963\n",
      "\n",
      "The classification loss after processing this batch is:  0.10057831555604935\n",
      "The representation loss after processing this batch is:  0.002609439194202423\n",
      "\n",
      "The classification loss after processing this batch is:  0.09199442714452744\n",
      "The representation loss after processing this batch is:  0.003162488341331482\n",
      "\n",
      "The classification loss after processing this batch is:  0.06416073441505432\n",
      "The representation loss after processing this batch is:  0.0027569159865379333\n",
      "\n",
      "The classification loss after processing this batch is:  0.12890523672103882\n",
      "The representation loss after processing this batch is:  0.002314932644367218\n",
      "\n",
      "The classification loss after processing this batch is:  0.14327844977378845\n",
      "The representation loss after processing this batch is:  0.0023770779371261597\n",
      "\n",
      "The classification loss after processing this batch is:  0.03334793075919151\n",
      "The representation loss after processing this batch is:  0.002567186951637268\n",
      "\n",
      "The classification loss after processing this batch is:  0.049600109457969666\n",
      "The representation loss after processing this batch is:  0.0022927336394786835\n",
      "\n",
      "The classification loss after processing this batch is:  0.140670046210289\n",
      "The representation loss after processing this batch is:  0.0023887231945991516\n",
      "\n",
      "The classification loss after processing this batch is:  0.14076878130435944\n",
      "The representation loss after processing this batch is:  0.0027052387595176697\n",
      "\n",
      "The classification loss after processing this batch is:  0.09573705494403839\n",
      "The representation loss after processing this batch is:  0.0025490373373031616\n",
      "\n",
      "The classification loss after processing this batch is:  0.16015031933784485\n",
      "The representation loss after processing this batch is:  0.0025153011083602905\n",
      "\n",
      "The classification loss after processing this batch is:  0.1396600753068924\n",
      "The representation loss after processing this batch is:  0.002920091152191162\n",
      "\n",
      "The classification loss after processing this batch is:  0.17360919713974\n",
      "The representation loss after processing this batch is:  0.002654850482940674\n",
      "\n",
      "The classification loss after processing this batch is:  0.08728343993425369\n",
      "The representation loss after processing this batch is:  0.0027652382850646973\n",
      "\n",
      "The classification loss after processing this batch is:  0.15471982955932617\n",
      "The representation loss after processing this batch is:  0.0024529844522476196\n",
      "\n",
      "The classification loss after processing this batch is:  0.07304779440164566\n",
      "The representation loss after processing this batch is:  0.0036583319306373596\n",
      "\n",
      "The classification loss after processing this batch is:  0.07716973125934601\n",
      "The representation loss after processing this batch is:  0.002491503953933716\n",
      "\n",
      "The classification loss after processing this batch is:  0.08539816737174988\n",
      "The representation loss after processing this batch is:  0.0025996193289756775\n",
      "\n",
      "The classification loss after processing this batch is:  0.0864388570189476\n",
      "The representation loss after processing this batch is:  0.0021461546421051025\n",
      "\n",
      "The classification loss after processing this batch is:  0.09676887094974518\n",
      "The representation loss after processing this batch is:  0.002494432032108307\n",
      "\n",
      "The classification loss after processing this batch is:  0.08934903889894485\n",
      "The representation loss after processing this batch is:  0.0025719180703163147\n",
      "\n",
      "The classification loss after processing this batch is:  0.1535695344209671\n",
      "The representation loss after processing this batch is:  0.0024426206946372986\n",
      "\n",
      "The classification loss after processing this batch is:  0.05203995853662491\n",
      "The representation loss after processing this batch is:  0.0027893781661987305\n",
      "\n",
      "The classification loss after processing this batch is:  0.05712612718343735\n",
      "The representation loss after processing this batch is:  0.0028054192662239075\n",
      "\n",
      "The classification loss after processing this batch is:  0.123374342918396\n",
      "The representation loss after processing this batch is:  0.002889677882194519\n",
      "\n",
      "The classification loss after processing this batch is:  0.06580183655023575\n",
      "The representation loss after processing this batch is:  0.002567693591117859\n",
      "\n",
      "The classification loss after processing this batch is:  0.06113561615347862\n",
      "The representation loss after processing this batch is:  0.002760551869869232\n",
      "\n",
      "The classification loss after processing this batch is:  0.057615455240011215\n",
      "The representation loss after processing this batch is:  0.0025892406702041626\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.12384164333343506\n",
      "The representation loss after processing this batch is:  0.0022121891379356384\n",
      "\n",
      "The classification loss after processing this batch is:  0.16055122017860413\n",
      "The representation loss after processing this batch is:  0.0029141977429389954\n",
      "\n",
      "The classification loss after processing this batch is:  0.14849349856376648\n",
      "The representation loss after processing this batch is:  0.003530949354171753\n",
      "\n",
      "The classification loss after processing this batch is:  0.10061876475811005\n",
      "The representation loss after processing this batch is:  0.002949446439743042\n",
      "\n",
      "The classification loss after processing this batch is:  0.08082915842533112\n",
      "The representation loss after processing this batch is:  0.0025003403425216675\n",
      "\n",
      "The classification loss after processing this batch is:  0.07857794314622879\n",
      "The representation loss after processing this batch is:  0.0025968775153160095\n",
      "\n",
      "The classification loss after processing this batch is:  0.14442263543605804\n",
      "The representation loss after processing this batch is:  0.002276122570037842\n",
      "\n",
      "The classification loss after processing this batch is:  0.05115717276930809\n",
      "The representation loss after processing this batch is:  0.0025878921151161194\n",
      "\n",
      "The classification loss after processing this batch is:  0.0515093095600605\n",
      "The representation loss after processing this batch is:  0.002627231180667877\n",
      "\n",
      "The classification loss after processing this batch is:  0.03674710541963577\n",
      "The representation loss after processing this batch is:  0.0025722160935401917\n",
      "\n",
      "The classification loss after processing this batch is:  0.14482884109020233\n",
      "The representation loss after processing this batch is:  0.0029727518558502197\n",
      "\n",
      "The classification loss after processing this batch is:  0.1403757929801941\n",
      "The representation loss after processing this batch is:  0.0026872605085372925\n",
      "\n",
      "The classification loss after processing this batch is:  0.14305275678634644\n",
      "The representation loss after processing this batch is:  0.0025103092193603516\n",
      "\n",
      "The classification loss after processing this batch is:  0.1327226459980011\n",
      "The representation loss after processing this batch is:  0.0033324509859085083\n",
      "\n",
      "The classification loss after processing this batch is:  0.10596215724945068\n",
      "The representation loss after processing this batch is:  0.0027503743767738342\n",
      "\n",
      "The classification loss after processing this batch is:  0.12476644665002823\n",
      "The representation loss after processing this batch is:  0.0027457326650619507\n",
      "\n",
      "The classification loss after processing this batch is:  0.076095350086689\n",
      "The representation loss after processing this batch is:  0.0026285648345947266\n",
      "\n",
      "The classification loss after processing this batch is:  0.24838776886463165\n",
      "The representation loss after processing this batch is:  0.0031664371490478516\n",
      "\n",
      "The classification loss after processing this batch is:  0.12985509634017944\n",
      "The representation loss after processing this batch is:  0.002788268029689789\n",
      "\n",
      "The classification loss after processing this batch is:  0.20522013306617737\n",
      "The representation loss after processing this batch is:  0.003127582371234894\n",
      "\n",
      "The classification loss after processing this batch is:  0.074001245200634\n",
      "The representation loss after processing this batch is:  0.002407848834991455\n",
      "\n",
      "The classification loss after processing this batch is:  0.05502529814839363\n",
      "The representation loss after processing this batch is:  0.0025415048003196716\n",
      "\n",
      "The classification loss after processing this batch is:  0.17019988596439362\n",
      "The representation loss after processing this batch is:  0.002496182918548584\n",
      "\n",
      "The classification loss after processing this batch is:  0.1307104378938675\n",
      "The representation loss after processing this batch is:  0.002771325409412384\n",
      "\n",
      "The classification loss after processing this batch is:  0.22365453839302063\n",
      "The representation loss after processing this batch is:  0.0025192201137542725\n",
      "\n",
      "The classification loss after processing this batch is:  0.14598049223423004\n",
      "The representation loss after processing this batch is:  0.003253467381000519\n",
      "\n",
      "The classification loss after processing this batch is:  0.12862901389598846\n",
      "The representation loss after processing this batch is:  0.0033154115080833435\n",
      "\n",
      "The classification loss after processing this batch is:  0.12567196786403656\n",
      "The representation loss after processing this batch is:  0.002751588821411133\n",
      "\n",
      "The classification loss after processing this batch is:  0.04267660155892372\n",
      "The representation loss after processing this batch is:  0.0024662762880325317\n",
      "\n",
      "The classification loss after processing this batch is:  0.07114680111408234\n",
      "The representation loss after processing this batch is:  0.0024014264345169067\n",
      "\n",
      "The classification loss after processing this batch is:  0.08865872770547867\n",
      "The representation loss after processing this batch is:  0.0024744197726249695\n",
      "\n",
      "The classification loss after processing this batch is:  0.053885772824287415\n",
      "The representation loss after processing this batch is:  0.002604946494102478\n",
      "\n",
      "The classification loss after processing this batch is:  0.11676670610904694\n",
      "The representation loss after processing this batch is:  0.0023504868149757385\n",
      "\n",
      "The classification loss after processing this batch is:  0.1889413744211197\n",
      "The representation loss after processing this batch is:  0.0025100409984588623\n",
      "\n",
      "The classification loss after processing this batch is:  0.11492223292589188\n",
      "The representation loss after processing this batch is:  0.0022157318890094757\n",
      "\n",
      "The classification loss after processing this batch is:  0.07742083072662354\n",
      "The representation loss after processing this batch is:  0.002574026584625244\n",
      "\n",
      "The classification loss after processing this batch is:  0.08074367046356201\n",
      "The representation loss after processing this batch is:  0.0025663599371910095\n",
      "\n",
      "The classification loss after processing this batch is:  0.05601630359888077\n",
      "The representation loss after processing this batch is:  0.002716474235057831\n",
      "\n",
      "The classification loss after processing this batch is:  0.08688568323850632\n",
      "The representation loss after processing this batch is:  0.0029597505927085876\n",
      "\n",
      "The classification loss after processing this batch is:  0.04599474370479584\n",
      "The representation loss after processing this batch is:  0.00275970995426178\n",
      "\n",
      "The classification loss after processing this batch is:  0.11282067745923996\n",
      "The representation loss after processing this batch is:  0.0022784247994422913\n",
      "\n",
      "The classification loss after processing this batch is:  0.10998915135860443\n",
      "The representation loss after processing this batch is:  0.0026593655347824097\n",
      "\n",
      "The classification loss after processing this batch is:  0.03591546043753624\n",
      "The representation loss after processing this batch is:  0.0026933997869491577\n",
      "\n",
      "The classification loss after processing this batch is:  0.20426829159259796\n",
      "The representation loss after processing this batch is:  0.0022364407777786255\n",
      "\n",
      "The classification loss after processing this batch is:  0.07524481415748596\n",
      "The representation loss after processing this batch is:  0.002366885542869568\n",
      "\n",
      "The classification loss after processing this batch is:  0.07130587100982666\n",
      "The representation loss after processing this batch is:  0.002428106963634491\n",
      "\n",
      "The classification loss after processing this batch is:  0.04206540808081627\n",
      "The representation loss after processing this batch is:  0.0027228668332099915\n",
      "\n",
      "The classification loss after processing this batch is:  0.060939181596040726\n",
      "The representation loss after processing this batch is:  0.0026590898633003235\n",
      "\n",
      "The classification loss after processing this batch is:  0.053935591131448746\n",
      "The representation loss after processing this batch is:  0.0024952366948127747\n",
      "\n",
      "The classification loss after processing this batch is:  0.30810222029685974\n",
      "The representation loss after processing this batch is:  0.0022808238863945007\n",
      "\n",
      "The classification loss after processing this batch is:  0.0875115618109703\n",
      "The representation loss after processing this batch is:  0.0027442052960395813\n",
      "\n",
      "The classification loss after processing this batch is:  0.13091863691806793\n",
      "The representation loss after processing this batch is:  0.0022785887122154236\n",
      "\n",
      "The classification loss after processing this batch is:  0.05296718701720238\n",
      "The representation loss after processing this batch is:  0.0023325085639953613\n",
      "\n",
      "The classification loss after processing this batch is:  0.09074542671442032\n",
      "The representation loss after processing this batch is:  0.0025062263011932373\n",
      "\n",
      "The classification loss after processing this batch is:  0.04085123538970947\n",
      "The representation loss after processing this batch is:  0.002461664378643036\n",
      "\n",
      "The classification loss after processing this batch is:  0.0717596635222435\n",
      "The representation loss after processing this batch is:  0.002576984465122223\n",
      "\n",
      "The classification loss after processing this batch is:  0.14953012764453888\n",
      "The representation loss after processing this batch is:  0.002574518322944641\n",
      "\n",
      "The classification loss after processing this batch is:  0.09107472002506256\n",
      "The representation loss after processing this batch is:  0.0031963810324668884\n",
      "\n",
      "The classification loss after processing this batch is:  0.13344095647335052\n",
      "The representation loss after processing this batch is:  0.002785898745059967\n",
      "\n",
      "The classification loss after processing this batch is:  0.08098573982715607\n",
      "The representation loss after processing this batch is:  0.0023345500230789185\n",
      "\n",
      "The classification loss after processing this batch is:  0.17007564008235931\n",
      "The representation loss after processing this batch is:  0.0024823397397994995\n",
      "\n",
      "The classification loss after processing this batch is:  0.11196926981210709\n",
      "The representation loss after processing this batch is:  0.0027750208973884583\n",
      "\n",
      "The classification loss after processing this batch is:  0.16930872201919556\n",
      "The representation loss after processing this batch is:  0.002641044557094574\n",
      "\n",
      "The classification loss after processing this batch is:  0.06609884649515152\n",
      "The representation loss after processing this batch is:  0.0026953741908073425\n",
      "\n",
      "The classification loss after processing this batch is:  0.07650182396173477\n",
      "The representation loss after processing this batch is:  0.0029850080609321594\n",
      "\n",
      "The classification loss after processing this batch is:  0.030355246737599373\n",
      "The representation loss after processing this batch is:  0.0026102215051651\n",
      "\n",
      "The classification loss after processing this batch is:  0.16213451325893402\n",
      "The representation loss after processing this batch is:  0.002476833760738373\n",
      "\n",
      "The classification loss after processing this batch is:  0.22137585282325745\n",
      "The representation loss after processing this batch is:  0.0029034018516540527\n",
      "\n",
      "The classification loss after processing this batch is:  0.09460143744945526\n",
      "The representation loss after processing this batch is:  0.0026371553540229797\n",
      "\n",
      "The classification loss after processing this batch is:  0.14221909642219543\n",
      "The representation loss after processing this batch is:  0.0031514987349510193\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.13931605219841003\n",
      "The representation loss after processing this batch is:  0.0027159377932548523\n",
      "\n",
      "The classification loss after processing this batch is:  0.13377028703689575\n",
      "The representation loss after processing this batch is:  0.002625018358230591\n",
      "\n",
      "The classification loss after processing this batch is:  0.05060598626732826\n",
      "The representation loss after processing this batch is:  0.002587363123893738\n",
      "\n",
      "The classification loss after processing this batch is:  0.08177773654460907\n",
      "The representation loss after processing this batch is:  0.002503626048564911\n",
      "\n",
      "The classification loss after processing this batch is:  0.12101288884878159\n",
      "The representation loss after processing this batch is:  0.002858266234397888\n",
      "\n",
      "The classification loss after processing this batch is:  0.07160428166389465\n",
      "The representation loss after processing this batch is:  0.0026731789112091064\n",
      "\n",
      "The classification loss after processing this batch is:  0.026998719200491905\n",
      "The representation loss after processing this batch is:  0.0026885271072387695\n",
      "\n",
      "The classification loss after processing this batch is:  0.05607895180583\n",
      "The representation loss after processing this batch is:  0.0027935728430747986\n",
      "\n",
      "The classification loss after processing this batch is:  0.06504081934690475\n",
      "The representation loss after processing this batch is:  0.0027611032128334045\n",
      "\n",
      "The classification loss after processing this batch is:  0.09684743732213974\n",
      "The representation loss after processing this batch is:  0.0023695267736911774\n",
      "\n",
      "The classification loss after processing this batch is:  0.1227359026670456\n",
      "The representation loss after processing this batch is:  0.002493336796760559\n",
      "\n",
      "The classification loss after processing this batch is:  0.07477246969938278\n",
      "The representation loss after processing this batch is:  0.0024506859481334686\n",
      "\n",
      "The classification loss after processing this batch is:  0.08946108818054199\n",
      "The representation loss after processing this batch is:  0.002873428165912628\n",
      "\n",
      "The classification loss after processing this batch is:  0.15075275301933289\n",
      "The representation loss after processing this batch is:  0.002688005566596985\n",
      "\n",
      "The classification loss after processing this batch is:  0.10443452000617981\n",
      "The representation loss after processing this batch is:  0.003195755183696747\n",
      "\n",
      "The classification loss after processing this batch is:  0.08132919669151306\n",
      "The representation loss after processing this batch is:  0.0025955885648727417\n",
      "\n",
      "The classification loss after processing this batch is:  0.12273495644330978\n",
      "The representation loss after processing this batch is:  0.002653859555721283\n",
      "\n",
      "The classification loss after processing this batch is:  0.1080486923456192\n",
      "The representation loss after processing this batch is:  0.003032781183719635\n",
      "\n",
      "The classification loss after processing this batch is:  0.1198824942111969\n",
      "The representation loss after processing this batch is:  0.0028228312730789185\n",
      "\n",
      "The classification loss after processing this batch is:  0.09553108364343643\n",
      "The representation loss after processing this batch is:  0.0024541467428207397\n",
      "\n",
      "The classification loss after processing this batch is:  0.06867311894893646\n",
      "The representation loss after processing this batch is:  0.0024662241339683533\n",
      "\n",
      "The classification loss after processing this batch is:  0.06454572081565857\n",
      "The representation loss after processing this batch is:  0.0025122985243797302\n",
      "\n",
      "The classification loss after processing this batch is:  0.09211466461420059\n",
      "The representation loss after processing this batch is:  0.0024769268929958344\n",
      "\n",
      "The classification loss after processing this batch is:  0.13892799615859985\n",
      "The representation loss after processing this batch is:  0.0026307180523872375\n",
      "\n",
      "The classification loss after processing this batch is:  0.23325110971927643\n",
      "The representation loss after processing this batch is:  0.002673424780368805\n",
      "\n",
      "The classification loss after processing this batch is:  0.14095737040042877\n",
      "The representation loss after processing this batch is:  0.0023583583533763885\n",
      "\n",
      "The classification loss after processing this batch is:  0.09229706227779388\n",
      "The representation loss after processing this batch is:  0.002562224864959717\n",
      "\n",
      "The classification loss after processing this batch is:  0.08933918923139572\n",
      "The representation loss after processing this batch is:  0.00240948423743248\n",
      "\n",
      "The classification loss after processing this batch is:  0.13892072439193726\n",
      "The representation loss after processing this batch is:  0.00238737091422081\n",
      "\n",
      "The classification loss after processing this batch is:  0.1695813238620758\n",
      "The representation loss after processing this batch is:  0.002650771290063858\n",
      "\n",
      "The classification loss after processing this batch is:  0.12509648501873016\n",
      "The representation loss after processing this batch is:  0.002462126314640045\n",
      "\n",
      "The classification loss after processing this batch is:  0.3274129629135132\n",
      "The representation loss after processing this batch is:  0.002611786127090454\n",
      "\n",
      "The classification loss after processing this batch is:  0.12728188931941986\n",
      "The representation loss after processing this batch is:  0.0024414658546447754\n",
      "\n",
      "The classification loss after processing this batch is:  0.06129497289657593\n",
      "The representation loss after processing this batch is:  0.0031998157501220703\n",
      "\n",
      "The classification loss after processing this batch is:  0.08355692028999329\n",
      "The representation loss after processing this batch is:  0.002737518399953842\n",
      "\n",
      "The classification loss after processing this batch is:  0.06300658732652664\n",
      "The representation loss after processing this batch is:  0.002539627254009247\n",
      "\n",
      "The classification loss after processing this batch is:  0.12086296081542969\n",
      "The representation loss after processing this batch is:  0.002735435962677002\n",
      "\n",
      "The classification loss after processing this batch is:  0.08930066227912903\n",
      "The representation loss after processing this batch is:  0.0024123787879943848\n",
      "\n",
      "The classification loss after processing this batch is:  0.08887410908937454\n",
      "The representation loss after processing this batch is:  0.0024208202958106995\n",
      "\n",
      "The classification loss after processing this batch is:  0.07315956801176071\n",
      "The representation loss after processing this batch is:  0.0025943145155906677\n",
      "\n",
      "The classification loss after processing this batch is:  0.12284661829471588\n",
      "The representation loss after processing this batch is:  0.002388469874858856\n",
      "\n",
      "The classification loss after processing this batch is:  0.15389810502529144\n",
      "The representation loss after processing this batch is:  0.002249293029308319\n",
      "\n",
      "The classification loss after processing this batch is:  0.18452240526676178\n",
      "The representation loss after processing this batch is:  0.0026385560631752014\n",
      "\n",
      "The classification loss after processing this batch is:  0.09753306210041046\n",
      "The representation loss after processing this batch is:  0.0025945156812667847\n",
      "\n",
      "The classification loss after processing this batch is:  0.034126922488212585\n",
      "The representation loss after processing this batch is:  0.002887248992919922\n",
      "\n",
      "The classification loss after processing this batch is:  0.023029888048768044\n",
      "The representation loss after processing this batch is:  0.0027243420481681824\n",
      "\n",
      "The classification loss after processing this batch is:  0.09482265263795853\n",
      "The representation loss after processing this batch is:  0.0030020475387573242\n",
      "\n",
      "The classification loss after processing this batch is:  0.05151401460170746\n",
      "The representation loss after processing this batch is:  0.003588438034057617\n",
      "\n",
      "The classification loss after processing this batch is:  0.12270291894674301\n",
      "The representation loss after processing this batch is:  0.002701893448829651\n",
      "\n",
      "The classification loss after processing this batch is:  0.12134066969156265\n",
      "The representation loss after processing this batch is:  0.002688102424144745\n",
      "\n",
      "The classification loss after processing this batch is:  0.18487101793289185\n",
      "The representation loss after processing this batch is:  0.002446986734867096\n",
      "\n",
      "The classification loss after processing this batch is:  0.036028869450092316\n",
      "The representation loss after processing this batch is:  0.00266382098197937\n",
      "\n",
      "The classification loss after processing this batch is:  0.09779013693332672\n",
      "The representation loss after processing this batch is:  0.0026302188634872437\n",
      "\n",
      "The classification loss after processing this batch is:  0.1283373236656189\n",
      "The representation loss after processing this batch is:  0.002879507839679718\n",
      "\n",
      "The classification loss after processing this batch is:  0.155003160238266\n",
      "The representation loss after processing this batch is:  0.002720370888710022\n",
      "\n",
      "The classification loss after processing this batch is:  0.07190413773059845\n",
      "The representation loss after processing this batch is:  0.0027469322085380554\n",
      "\n",
      "The classification loss after processing this batch is:  0.06086014211177826\n",
      "The representation loss after processing this batch is:  0.0021339356899261475\n",
      "\n",
      "The classification loss after processing this batch is:  0.10098147392272949\n",
      "The representation loss after processing this batch is:  0.0026803985238075256\n",
      "\n",
      "The classification loss after processing this batch is:  0.06858094781637192\n",
      "The representation loss after processing this batch is:  0.0024947822093963623\n",
      "\n",
      "The classification loss after processing this batch is:  0.0795871764421463\n",
      "The representation loss after processing this batch is:  0.0023618116974830627\n",
      "\n",
      "The classification loss after processing this batch is:  0.145985946059227\n",
      "The representation loss after processing this batch is:  0.0025046467781066895\n",
      "\n",
      "The classification loss after processing this batch is:  0.07606945186853409\n",
      "The representation loss after processing this batch is:  0.0025903135538101196\n",
      "\n",
      "The classification loss after processing this batch is:  0.020075345411896706\n",
      "The representation loss after processing this batch is:  0.0023737847805023193\n",
      "\n",
      "The classification loss after processing this batch is:  0.06963670253753662\n",
      "The representation loss after processing this batch is:  0.002885393798351288\n",
      "\n",
      "The classification loss after processing this batch is:  0.025535663589835167\n",
      "The representation loss after processing this batch is:  0.002896718680858612\n",
      "\n",
      "The classification loss after processing this batch is:  0.08277156949043274\n",
      "The representation loss after processing this batch is:  0.0025543421506881714\n",
      "\n",
      "The classification loss after processing this batch is:  0.04958129674196243\n",
      "The representation loss after processing this batch is:  0.0026983916759490967\n",
      "\n",
      "The classification loss after processing this batch is:  0.04532919079065323\n",
      "The representation loss after processing this batch is:  0.002419590950012207\n",
      "\n",
      "The classification loss after processing this batch is:  0.07763198763132095\n",
      "The representation loss after processing this batch is:  0.002892032265663147\n",
      "\n",
      "The classification loss after processing this batch is:  0.051041558384895325\n",
      "The representation loss after processing this batch is:  0.0026267170906066895\n",
      "\n",
      "The classification loss after processing this batch is:  0.036916572600603104\n",
      "The representation loss after processing this batch is:  0.002692773938179016\n",
      "\n",
      "The classification loss after processing this batch is:  0.0759451761841774\n",
      "The representation loss after processing this batch is:  0.002501167356967926\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.04814552515745163\n",
      "The representation loss after processing this batch is:  0.0025609955191612244\n",
      "\n",
      "The classification loss after processing this batch is:  0.031233763322234154\n",
      "The representation loss after processing this batch is:  0.002596259117126465\n",
      "\n",
      "The classification loss after processing this batch is:  0.0792488306760788\n",
      "The representation loss after processing this batch is:  0.002686716616153717\n",
      "\n",
      "The classification loss after processing this batch is:  0.11591580510139465\n",
      "The representation loss after processing this batch is:  0.0028220713138580322\n",
      "\n",
      "The classification loss after processing this batch is:  0.04900897294282913\n",
      "The representation loss after processing this batch is:  0.0028383955359458923\n",
      "\n",
      "The classification loss after processing this batch is:  0.16473837196826935\n",
      "The representation loss after processing this batch is:  0.002635054290294647\n",
      "\n",
      "The classification loss after processing this batch is:  0.0373314768075943\n",
      "The representation loss after processing this batch is:  0.00246565043926239\n",
      "\n",
      "The classification loss after processing this batch is:  0.11341904103755951\n",
      "The representation loss after processing this batch is:  0.0024091005325317383\n",
      "\n",
      "The classification loss after processing this batch is:  0.12434044480323792\n",
      "The representation loss after processing this batch is:  0.002908550202846527\n",
      "\n",
      "The classification loss after processing this batch is:  0.05152054503560066\n",
      "The representation loss after processing this batch is:  0.0030171647667884827\n",
      "\n",
      "The classification loss after processing this batch is:  0.15589012205600739\n",
      "The representation loss after processing this batch is:  0.0025496706366539\n",
      "\n",
      "The classification loss after processing this batch is:  0.14041031897068024\n",
      "The representation loss after processing this batch is:  0.0023914724588394165\n",
      "\n",
      "The classification loss after processing this batch is:  0.14817017316818237\n",
      "The representation loss after processing this batch is:  0.0025330781936645508\n",
      "\n",
      "The classification loss after processing this batch is:  0.14325657486915588\n",
      "The representation loss after processing this batch is:  0.0025372132658958435\n",
      "\n",
      "The classification loss after processing this batch is:  0.06392070651054382\n",
      "The representation loss after processing this batch is:  0.0028033703565597534\n",
      "\n",
      "The classification loss after processing this batch is:  0.09239505976438522\n",
      "The representation loss after processing this batch is:  0.002304956316947937\n",
      "\n",
      "The classification loss after processing this batch is:  0.10965163260698318\n",
      "The representation loss after processing this batch is:  0.0025705695152282715\n",
      "\n",
      "The classification loss after processing this batch is:  0.1286899745464325\n",
      "The representation loss after processing this batch is:  0.0024995729327201843\n",
      "\n",
      "The classification loss after processing this batch is:  0.14644557237625122\n",
      "The representation loss after processing this batch is:  0.0024162381887435913\n",
      "\n",
      "The classification loss after processing this batch is:  0.05202185735106468\n",
      "The representation loss after processing this batch is:  0.0023538991808891296\n",
      "\n",
      "The classification loss after processing this batch is:  0.060320496559143066\n",
      "The representation loss after processing this batch is:  0.002499982714653015\n",
      "\n",
      "The classification loss after processing this batch is:  0.18478593230247498\n",
      "The representation loss after processing this batch is:  0.0021723955869674683\n",
      "\n",
      "The classification loss after processing this batch is:  0.04927422106266022\n",
      "The representation loss after processing this batch is:  0.0025265440344810486\n",
      "\n",
      "The classification loss after processing this batch is:  0.10047919303178787\n",
      "The representation loss after processing this batch is:  0.0025191530585289\n",
      "\n",
      "The classification loss after processing this batch is:  0.12190044671297073\n",
      "The representation loss after processing this batch is:  0.0025375932455062866\n",
      "\n",
      "The classification loss after processing this batch is:  0.05745704472064972\n",
      "The representation loss after processing this batch is:  0.0029081180691719055\n",
      "\n",
      "The classification loss after processing this batch is:  0.03558235988020897\n",
      "The representation loss after processing this batch is:  0.0029487237334251404\n",
      "\n",
      "The classification loss after processing this batch is:  0.09190020710229874\n",
      "The representation loss after processing this batch is:  0.0026172176003456116\n",
      "\n",
      "The classification loss after processing this batch is:  0.14210514724254608\n",
      "The representation loss after processing this batch is:  0.0025596879422664642\n",
      "\n",
      "The classification loss after processing this batch is:  0.1444074511528015\n",
      "The representation loss after processing this batch is:  0.0025814324617385864\n",
      "\n",
      "The classification loss after processing this batch is:  0.195250004529953\n",
      "The representation loss after processing this batch is:  0.002984151244163513\n",
      "\n",
      "The classification loss after processing this batch is:  0.12456879764795303\n",
      "The representation loss after processing this batch is:  0.002602800726890564\n",
      "\n",
      "The classification loss after processing this batch is:  0.13581083714962006\n",
      "The representation loss after processing this batch is:  0.002233833074569702\n",
      "\n",
      "The classification loss after processing this batch is:  0.08535728603601456\n",
      "The representation loss after processing this batch is:  0.00282982736825943\n",
      "\n",
      "The classification loss after processing this batch is:  0.04768816754221916\n",
      "The representation loss after processing this batch is:  0.002646222710609436\n",
      "\n",
      "The classification loss after processing this batch is:  0.052343644201755524\n",
      "The representation loss after processing this batch is:  0.0025591105222702026\n",
      "\n",
      "The classification loss after processing this batch is:  0.0649116262793541\n",
      "The representation loss after processing this batch is:  0.0025683343410491943\n",
      "\n",
      "The classification loss after processing this batch is:  0.09980316460132599\n",
      "The representation loss after processing this batch is:  0.002634890377521515\n",
      "\n",
      "The classification loss after processing this batch is:  0.08435352891683578\n",
      "The representation loss after processing this batch is:  0.0026409104466438293\n",
      "\n",
      "The classification loss after processing this batch is:  0.11524883657693863\n",
      "The representation loss after processing this batch is:  0.0029549896717071533\n",
      "\n",
      "The classification loss after processing this batch is:  0.13012897968292236\n",
      "The representation loss after processing this batch is:  0.002877064049243927\n",
      "\n",
      "The classification loss after processing this batch is:  0.08228885382413864\n",
      "The representation loss after processing this batch is:  0.0029162317514419556\n",
      "\n",
      "The classification loss after processing this batch is:  0.1502293050289154\n",
      "The representation loss after processing this batch is:  0.0027816444635391235\n",
      "\n",
      "The classification loss after processing this batch is:  0.15009351074695587\n",
      "The representation loss after processing this batch is:  0.0025993958115577698\n",
      "\n",
      "The classification loss after processing this batch is:  0.1573505997657776\n",
      "The representation loss after processing this batch is:  0.0026484355330467224\n",
      "\n",
      "The classification loss after processing this batch is:  0.06492417305707932\n",
      "The representation loss after processing this batch is:  0.002869538962841034\n",
      "\n",
      "The classification loss after processing this batch is:  0.06060440093278885\n",
      "The representation loss after processing this batch is:  0.0025162845849990845\n",
      "\n",
      "The classification loss after processing this batch is:  0.19309954345226288\n",
      "The representation loss after processing this batch is:  0.0024517104029655457\n",
      "\n",
      "The classification loss after processing this batch is:  0.15315386652946472\n",
      "The representation loss after processing this batch is:  0.0024664998054504395\n",
      "\n",
      "The classification loss after processing this batch is:  0.11724432557821274\n",
      "The representation loss after processing this batch is:  0.0025888681411743164\n",
      "\n",
      "The classification loss after processing this batch is:  0.10326133668422699\n",
      "The representation loss after processing this batch is:  0.002504885196685791\n",
      "\n",
      "The classification loss after processing this batch is:  0.12041809409856796\n",
      "The representation loss after processing this batch is:  0.002491682767868042\n",
      "\n",
      "The classification loss after processing this batch is:  0.23043452203273773\n",
      "The representation loss after processing this batch is:  0.0022853612899780273\n",
      "\n",
      "The classification loss after processing this batch is:  0.18725189566612244\n",
      "The representation loss after processing this batch is:  0.0023941248655319214\n",
      "\n",
      "The classification loss after processing this batch is:  0.1845439374446869\n",
      "The representation loss after processing this batch is:  0.0026439279317855835\n",
      "\n",
      "The classification loss after processing this batch is:  0.1529374122619629\n",
      "The representation loss after processing this batch is:  0.0024090036749839783\n",
      "\n",
      "The classification loss after processing this batch is:  0.0667739138007164\n",
      "The representation loss after processing this batch is:  0.0029398873448371887\n",
      "\n",
      "The classification loss after processing this batch is:  0.051374759525060654\n",
      "The representation loss after processing this batch is:  0.002663359045982361\n",
      "\n",
      "The classification loss after processing this batch is:  0.11245568096637726\n",
      "The representation loss after processing this batch is:  0.0025466643273830414\n",
      "\n",
      "The classification loss after processing this batch is:  0.08242002129554749\n",
      "The representation loss after processing this batch is:  0.0024651288986206055\n",
      "\n",
      "The classification loss after processing this batch is:  0.05381936952471733\n",
      "The representation loss after processing this batch is:  0.00233256071805954\n",
      "\n",
      "The classification loss after processing this batch is:  0.04021497443318367\n",
      "The representation loss after processing this batch is:  0.0025835074484348297\n",
      "\n",
      "The classification loss after processing this batch is:  0.0948508158326149\n",
      "The representation loss after processing this batch is:  0.0024357736110687256\n",
      "\n",
      "The classification loss after processing this batch is:  0.09307318180799484\n",
      "The representation loss after processing this batch is:  0.0026545152068138123\n",
      "\n",
      "The classification loss after processing this batch is:  0.05156455188989639\n",
      "The representation loss after processing this batch is:  0.0027365349233150482\n",
      "\n",
      "The classification loss after processing this batch is:  0.0885421484708786\n",
      "The representation loss after processing this batch is:  0.0023032650351524353\n",
      "\n",
      "The classification loss after processing this batch is:  0.07276264578104019\n",
      "The representation loss after processing this batch is:  0.0026020780205726624\n",
      "\n",
      "The classification loss after processing this batch is:  0.16480706632137299\n",
      "The representation loss after processing this batch is:  0.0024657398462295532\n",
      "\n",
      "The classification loss after processing this batch is:  0.09050176292657852\n",
      "The representation loss after processing this batch is:  0.002510868012905121\n",
      "\n",
      "The classification loss after processing this batch is:  0.14462091028690338\n",
      "The representation loss after processing this batch is:  0.0026934966444969177\n",
      "\n",
      "The classification loss after processing this batch is:  0.03350454568862915\n",
      "The representation loss after processing this batch is:  0.0024924278259277344\n",
      "\n",
      "The classification loss after processing this batch is:  0.04247361794114113\n",
      "The representation loss after processing this batch is:  0.002845674753189087\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.12643907964229584\n",
      "The representation loss after processing this batch is:  0.002400226891040802\n",
      "\n",
      "The classification loss after processing this batch is:  0.14474867284297943\n",
      "The representation loss after processing this batch is:  0.0025222450494766235\n",
      "\n",
      "The classification loss after processing this batch is:  0.08244065195322037\n",
      "The representation loss after processing this batch is:  0.00261901319026947\n",
      "\n",
      "The classification loss after processing this batch is:  0.04724924638867378\n",
      "The representation loss after processing this batch is:  0.0023401565849781036\n",
      "\n",
      "The classification loss after processing this batch is:  0.0970756933093071\n",
      "The representation loss after processing this batch is:  0.0023243799805641174\n",
      "\n",
      "The classification loss after processing this batch is:  0.021246394142508507\n",
      "The representation loss after processing this batch is:  0.0027252286672592163\n",
      "\n",
      "The classification loss after processing this batch is:  0.14522795379161835\n",
      "The representation loss after processing this batch is:  0.002431914210319519\n",
      "\n",
      "The classification loss after processing this batch is:  0.08660759776830673\n",
      "The representation loss after processing this batch is:  0.002759866416454315\n",
      "\n",
      "The classification loss after processing this batch is:  0.0758085548877716\n",
      "The representation loss after processing this batch is:  0.002444334328174591\n",
      "\n",
      "The classification loss after processing this batch is:  0.083334781229496\n",
      "The representation loss after processing this batch is:  0.0027490630745887756\n",
      "\n",
      "The classification loss after processing this batch is:  0.08595895767211914\n",
      "The representation loss after processing this batch is:  0.002640925347805023\n",
      "\n",
      "The classification loss after processing this batch is:  0.03705936670303345\n",
      "The representation loss after processing this batch is:  0.0025093257427215576\n",
      "\n",
      "The classification loss after processing this batch is:  0.2078656554222107\n",
      "The representation loss after processing this batch is:  0.0025562047958374023\n",
      "\n",
      "The classification loss after processing this batch is:  0.2216767817735672\n",
      "The representation loss after processing this batch is:  0.0025369077920913696\n",
      "\n",
      "The classification loss after processing this batch is:  0.1550142914056778\n",
      "The representation loss after processing this batch is:  0.0025211721658706665\n",
      "\n",
      "The classification loss after processing this batch is:  0.1469971388578415\n",
      "The representation loss after processing this batch is:  0.002354361116886139\n",
      "\n",
      "The classification loss after processing this batch is:  0.0890042632818222\n",
      "The representation loss after processing this batch is:  0.002396106719970703\n",
      "\n",
      "The classification loss after processing this batch is:  0.06081694737076759\n",
      "The representation loss after processing this batch is:  0.0023243576288223267\n",
      "\n",
      "The classification loss after processing this batch is:  0.1693556308746338\n",
      "The representation loss after processing this batch is:  0.0025139078497886658\n",
      "\n",
      "The classification loss after processing this batch is:  0.1089344322681427\n",
      "The representation loss after processing this batch is:  0.002394147217273712\n",
      "\n",
      "The classification loss after processing this batch is:  0.1586277335882187\n",
      "The representation loss after processing this batch is:  0.002468876540660858\n",
      "\n",
      "The classification loss after processing this batch is:  0.07681574672460556\n",
      "The representation loss after processing this batch is:  0.002677120268344879\n",
      "\n",
      "The classification loss after processing this batch is:  0.15078547596931458\n",
      "The representation loss after processing this batch is:  0.002354312688112259\n",
      "\n",
      "The classification loss after processing this batch is:  0.06047385185956955\n",
      "The representation loss after processing this batch is:  0.0023496150970458984\n",
      "\n",
      "The classification loss after processing this batch is:  0.06942971795797348\n",
      "The representation loss after processing this batch is:  0.002714298665523529\n",
      "\n",
      "The classification loss after processing this batch is:  0.09628652781248093\n",
      "The representation loss after processing this batch is:  0.002525128424167633\n",
      "\n",
      "The classification loss after processing this batch is:  0.04074939712882042\n",
      "The representation loss after processing this batch is:  0.002603784203529358\n",
      "\n",
      "The classification loss after processing this batch is:  0.02582201175391674\n",
      "The representation loss after processing this batch is:  0.0025549009442329407\n",
      "\n",
      "The classification loss after processing this batch is:  0.06977806240320206\n",
      "The representation loss after processing this batch is:  0.002451561391353607\n",
      "\n",
      "The classification loss after processing this batch is:  0.21204546093940735\n",
      "The representation loss after processing this batch is:  0.002493716776371002\n",
      "\n",
      "The classification loss after processing this batch is:  0.025996053591370583\n",
      "The representation loss after processing this batch is:  0.0026235803961753845\n",
      "\n",
      "The classification loss after processing this batch is:  0.05453961715102196\n",
      "The representation loss after processing this batch is:  0.002436801791191101\n",
      "\n",
      "The classification loss after processing this batch is:  0.11015541851520538\n",
      "The representation loss after processing this batch is:  0.0024247467517852783\n",
      "\n",
      "The classification loss after processing this batch is:  0.17038938403129578\n",
      "The representation loss after processing this batch is:  0.0024006515741348267\n",
      "\n",
      "The classification loss after processing this batch is:  0.08649064600467682\n",
      "The representation loss after processing this batch is:  0.002638973295688629\n",
      "\n",
      "The classification loss after processing this batch is:  0.14862124621868134\n",
      "The representation loss after processing this batch is:  0.0023157447576522827\n",
      "\n",
      "The classification loss after processing this batch is:  0.06709422916173935\n",
      "The representation loss after processing this batch is:  0.002938471734523773\n",
      "\n",
      "The classification loss after processing this batch is:  0.029106322675943375\n",
      "The representation loss after processing this batch is:  0.002392500638961792\n",
      "\n",
      "The classification loss after processing this batch is:  0.028995012864470482\n",
      "The representation loss after processing this batch is:  0.0027386024594306946\n",
      "\n",
      "The classification loss after processing this batch is:  0.14159710705280304\n",
      "The representation loss after processing this batch is:  0.0027145519852638245\n",
      "\n",
      "The classification loss after processing this batch is:  0.11173414438962936\n",
      "The representation loss after processing this batch is:  0.002680465579032898\n",
      "\n",
      "The classification loss after processing this batch is:  0.075484998524189\n",
      "The representation loss after processing this batch is:  0.0029636621475219727\n",
      "\n",
      "The classification loss after processing this batch is:  0.1419200599193573\n",
      "The representation loss after processing this batch is:  0.002584300935268402\n",
      "\n",
      "The classification loss after processing this batch is:  0.05640774965286255\n",
      "The representation loss after processing this batch is:  0.0027054399251937866\n",
      "\n",
      "The classification loss after processing this batch is:  0.07808560878038406\n",
      "The representation loss after processing this batch is:  0.002454206347465515\n",
      "\n",
      "The classification loss after processing this batch is:  0.0930006131529808\n",
      "The representation loss after processing this batch is:  0.002668417990207672\n",
      "\n",
      "The classification loss after processing this batch is:  0.10822484642267227\n",
      "The representation loss after processing this batch is:  0.002592511475086212\n",
      "\n",
      "The classification loss after processing this batch is:  0.11643649637699127\n",
      "The representation loss after processing this batch is:  0.003056846559047699\n",
      "\n",
      "The classification loss after processing this batch is:  0.2665989100933075\n",
      "The representation loss after processing this batch is:  0.002190619707107544\n",
      "\n",
      "The classification loss after processing this batch is:  0.1439010351896286\n",
      "The representation loss after processing this batch is:  0.002376355230808258\n",
      "\n",
      "The classification loss after processing this batch is:  0.10203579813241959\n",
      "The representation loss after processing this batch is:  0.002688467502593994\n",
      "\n",
      "The classification loss after processing this batch is:  0.10383142530918121\n",
      "The representation loss after processing this batch is:  0.0028028562664985657\n",
      "\n",
      "The classification loss after processing this batch is:  0.03674851357936859\n",
      "The representation loss after processing this batch is:  0.0025621429085731506\n",
      "\n",
      "The classification loss after processing this batch is:  0.07479185611009598\n",
      "The representation loss after processing this batch is:  0.002951785922050476\n",
      "\n",
      "The classification loss after processing this batch is:  0.058659594506025314\n",
      "The representation loss after processing this batch is:  0.002773076295852661\n",
      "\n",
      "The classification loss after processing this batch is:  0.13964079320430756\n",
      "The representation loss after processing this batch is:  0.0024417489767074585\n",
      "\n",
      "The classification loss after processing this batch is:  0.10493502765893936\n",
      "The representation loss after processing this batch is:  0.00222691148519516\n",
      "\n",
      "The classification loss after processing this batch is:  0.08620022237300873\n",
      "The representation loss after processing this batch is:  0.0022170692682266235\n",
      "\n",
      "The classification loss after processing this batch is:  0.10175123065710068\n",
      "The representation loss after processing this batch is:  0.0025201737880706787\n",
      "\n",
      "The classification loss after processing this batch is:  0.13421712815761566\n",
      "The representation loss after processing this batch is:  0.002288132905960083\n",
      "\n",
      "The classification loss after processing this batch is:  0.10200242698192596\n",
      "The representation loss after processing this batch is:  0.0025501251220703125\n",
      "\n",
      "The classification loss after processing this batch is:  0.18489186465740204\n",
      "The representation loss after processing this batch is:  0.002803005278110504\n",
      "\n",
      "The classification loss after processing this batch is:  0.05813998356461525\n",
      "The representation loss after processing this batch is:  0.002665102481842041\n",
      "\n",
      "The classification loss after processing this batch is:  0.07826459407806396\n",
      "The representation loss after processing this batch is:  0.002230897545814514\n",
      "\n",
      "The classification loss after processing this batch is:  0.07676836848258972\n",
      "The representation loss after processing this batch is:  0.002599090337753296\n",
      "\n",
      "The classification loss after processing this batch is:  0.1861819475889206\n",
      "The representation loss after processing this batch is:  0.0026553571224212646\n",
      "\n",
      "The classification loss after processing this batch is:  0.16903024911880493\n",
      "The representation loss after processing this batch is:  0.002947494387626648\n",
      "\n",
      "The classification loss after processing this batch is:  0.038556139916181564\n",
      "The representation loss after processing this batch is:  0.0024160221219062805\n",
      "\n",
      "The classification loss after processing this batch is:  0.0657808929681778\n",
      "The representation loss after processing this batch is:  0.0026182234287261963\n",
      "\n",
      "The classification loss after processing this batch is:  0.20909519493579865\n",
      "The representation loss after processing this batch is:  0.002420566976070404\n",
      "\n",
      "The classification loss after processing this batch is:  0.060204993933439255\n",
      "The representation loss after processing this batch is:  0.002598501741886139\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.05675504729151726\n",
      "The representation loss after processing this batch is:  0.002547629177570343\n",
      "\n",
      "The classification loss after processing this batch is:  0.09668431431055069\n",
      "The representation loss after processing this batch is:  0.002455689013004303\n",
      "\n",
      "The classification loss after processing this batch is:  0.07888112962245941\n",
      "The representation loss after processing this batch is:  0.002499498426914215\n",
      "\n",
      "The classification loss after processing this batch is:  0.16758495569229126\n",
      "The representation loss after processing this batch is:  0.002979166805744171\n",
      "\n",
      "The classification loss after processing this batch is:  0.10689065605401993\n",
      "The representation loss after processing this batch is:  0.0028828904032707214\n",
      "\n",
      "The classification loss after processing this batch is:  0.13212470710277557\n",
      "The representation loss after processing this batch is:  0.003357313573360443\n",
      "\n",
      "The classification loss after processing this batch is:  0.11283869296312332\n",
      "The representation loss after processing this batch is:  0.002468310296535492\n",
      "\n",
      "The classification loss after processing this batch is:  0.15305429697036743\n",
      "The representation loss after processing this batch is:  0.0022257864475250244\n",
      "\n",
      "The classification loss after processing this batch is:  0.03440523147583008\n",
      "The representation loss after processing this batch is:  0.002387203276157379\n",
      "\n",
      "The classification loss after processing this batch is:  0.03914421796798706\n",
      "The representation loss after processing this batch is:  0.0024578124284744263\n",
      "\n",
      "The classification loss after processing this batch is:  0.05725712701678276\n",
      "The representation loss after processing this batch is:  0.0024250000715255737\n",
      "\n",
      "The classification loss after processing this batch is:  0.044650156050920486\n",
      "The representation loss after processing this batch is:  0.002731636166572571\n",
      "\n",
      "The classification loss after processing this batch is:  0.08307422697544098\n",
      "The representation loss after processing this batch is:  0.0026513077318668365\n",
      "\n",
      "The classification loss after processing this batch is:  0.05223257467150688\n",
      "The representation loss after processing this batch is:  0.0023088976740837097\n",
      "\n",
      "The classification loss after processing this batch is:  0.06509734690189362\n",
      "The representation loss after processing this batch is:  0.0022419504821300507\n",
      "\n",
      "The classification loss after processing this batch is:  0.12544341385364532\n",
      "The representation loss after processing this batch is:  0.0024721696972846985\n",
      "\n",
      "The classification loss after processing this batch is:  0.13559801876544952\n",
      "The representation loss after processing this batch is:  0.0027379319071769714\n",
      "\n",
      "The classification loss after processing this batch is:  0.13079066574573517\n",
      "The representation loss after processing this batch is:  0.002416495233774185\n",
      "\n",
      "The classification loss after processing this batch is:  0.11840393394231796\n",
      "The representation loss after processing this batch is:  0.0026740282773971558\n",
      "\n",
      "The classification loss after processing this batch is:  0.14274778962135315\n",
      "The representation loss after processing this batch is:  0.0022815950214862823\n",
      "\n",
      "The classification loss after processing this batch is:  0.057256415486335754\n",
      "The representation loss after processing this batch is:  0.002416059374809265\n",
      "\n",
      "The classification loss after processing this batch is:  0.120211161673069\n",
      "The representation loss after processing this batch is:  0.0025501400232315063\n",
      "\n",
      "The classification loss after processing this batch is:  0.22088812291622162\n",
      "The representation loss after processing this batch is:  0.0026049986481666565\n",
      "\n",
      "The classification loss after processing this batch is:  0.09049592167139053\n",
      "The representation loss after processing this batch is:  0.002386055886745453\n",
      "\n",
      "The classification loss after processing this batch is:  0.11511889100074768\n",
      "The representation loss after processing this batch is:  0.0022993534803390503\n",
      "\n",
      "The classification loss after processing this batch is:  0.13332520425319672\n",
      "The representation loss after processing this batch is:  0.0023335441946983337\n",
      "\n",
      "The classification loss after processing this batch is:  0.11800461262464523\n",
      "The representation loss after processing this batch is:  0.00230591744184494\n",
      "\n",
      "The classification loss after processing this batch is:  0.06636190414428711\n",
      "The representation loss after processing this batch is:  0.0025320127606391907\n",
      "\n",
      "The classification loss after processing this batch is:  0.06923726201057434\n",
      "The representation loss after processing this batch is:  0.0024609044194221497\n",
      "\n",
      "The classification loss after processing this batch is:  0.08505096286535263\n",
      "The representation loss after processing this batch is:  0.0023024603724479675\n",
      "\n",
      "The classification loss after processing this batch is:  0.03768826276063919\n",
      "The representation loss after processing this batch is:  0.0025545284152030945\n",
      "\n",
      "The classification loss after processing this batch is:  0.0262564979493618\n",
      "The representation loss after processing this batch is:  0.002358280122280121\n",
      "\n",
      "The classification loss after processing this batch is:  0.09779476374387741\n",
      "The representation loss after processing this batch is:  0.0029517188668251038\n",
      "\n",
      "The classification loss after processing this batch is:  0.03246442601084709\n",
      "The representation loss after processing this batch is:  0.0030287355184555054\n",
      "\n",
      "The classification loss after processing this batch is:  0.1825794279575348\n",
      "The representation loss after processing this batch is:  0.0029395967721939087\n",
      "\n",
      "The classification loss after processing this batch is:  0.10343869030475616\n",
      "The representation loss after processing this batch is:  0.0025436654686927795\n",
      "\n",
      "The classification loss after processing this batch is:  0.17110493779182434\n",
      "The representation loss after processing this batch is:  0.002667821943759918\n",
      "\n",
      "The classification loss after processing this batch is:  0.3013118505477905\n",
      "The representation loss after processing this batch is:  0.0021467842161655426\n",
      "\n",
      "The classification loss after processing this batch is:  0.10968206077814102\n",
      "The representation loss after processing this batch is:  0.0023713186383247375\n",
      "\n",
      "The classification loss after processing this batch is:  0.03242170810699463\n",
      "The representation loss after processing this batch is:  0.0025493502616882324\n",
      "\n",
      "The classification loss after processing this batch is:  0.058980558067560196\n",
      "The representation loss after processing this batch is:  0.0028329938650131226\n",
      "\n",
      "The classification loss after processing this batch is:  0.045002151280641556\n",
      "The representation loss after processing this batch is:  0.0028003156185150146\n",
      "\n",
      "The classification loss after processing this batch is:  0.053041648119688034\n",
      "The representation loss after processing this batch is:  0.0026912540197372437\n",
      "\n",
      "The classification loss after processing this batch is:  0.06524132937192917\n",
      "The representation loss after processing this batch is:  0.0022691339254379272\n",
      "\n",
      "The classification loss after processing this batch is:  0.1675916612148285\n",
      "The representation loss after processing this batch is:  0.0023827701807022095\n",
      "\n",
      "The classification loss after processing this batch is:  0.13008959591388702\n",
      "The representation loss after processing this batch is:  0.002540603280067444\n",
      "\n",
      "The classification loss after processing this batch is:  0.10549262166023254\n",
      "The representation loss after processing this batch is:  0.003197111189365387\n",
      "\n",
      "The classification loss after processing this batch is:  0.19478586316108704\n",
      "The representation loss after processing this batch is:  0.0033130422234535217\n",
      "\n",
      "The classification loss after processing this batch is:  0.0782674178481102\n",
      "The representation loss after processing this batch is:  0.0025585144758224487\n",
      "\n",
      "The classification loss after processing this batch is:  0.09527125209569931\n",
      "The representation loss after processing this batch is:  0.0025275349617004395\n",
      "\n",
      "The classification loss after processing this batch is:  0.1557696908712387\n",
      "The representation loss after processing this batch is:  0.0024897269904613495\n",
      "\n",
      "The classification loss after processing this batch is:  0.087986521422863\n",
      "The representation loss after processing this batch is:  0.0029036998748779297\n",
      "\n",
      "The classification loss after processing this batch is:  0.1401723027229309\n",
      "The representation loss after processing this batch is:  0.003704465925693512\n",
      "\n",
      "The classification loss after processing this batch is:  0.05909346416592598\n",
      "The representation loss after processing this batch is:  0.0026102103292942047\n",
      "\n",
      "The classification loss after processing this batch is:  0.12700900435447693\n",
      "The representation loss after processing this batch is:  0.0029669106006622314\n",
      "\n",
      "The classification loss after processing this batch is:  0.12555566430091858\n",
      "The representation loss after processing this batch is:  0.003078307956457138\n",
      "\n",
      "The classification loss after processing this batch is:  0.07720036059617996\n",
      "The representation loss after processing this batch is:  0.0031955018639564514\n",
      "\n",
      "The classification loss after processing this batch is:  0.11407225579023361\n",
      "The representation loss after processing this batch is:  0.002607099711894989\n",
      "\n",
      "The classification loss after processing this batch is:  0.13441172242164612\n",
      "The representation loss after processing this batch is:  0.0022696182131767273\n",
      "\n",
      "The classification loss after processing this batch is:  0.10069692134857178\n",
      "The representation loss after processing this batch is:  0.002449728548526764\n",
      "\n",
      "The classification loss after processing this batch is:  0.11458427459001541\n",
      "The representation loss after processing this batch is:  0.002444714307785034\n",
      "\n",
      "The classification loss after processing this batch is:  0.07900631427764893\n",
      "The representation loss after processing this batch is:  0.0028202608227729797\n",
      "\n",
      "The classification loss after processing this batch is:  0.022496787831187248\n",
      "The representation loss after processing this batch is:  0.002584323287010193\n",
      "\n",
      "The classification loss after processing this batch is:  0.10331261903047562\n",
      "The representation loss after processing this batch is:  0.0026198402047157288\n",
      "\n",
      "The classification loss after processing this batch is:  0.04016817361116409\n",
      "The representation loss after processing this batch is:  0.002847813069820404\n",
      "\n",
      "The classification loss after processing this batch is:  0.24247558414936066\n",
      "The representation loss after processing this batch is:  0.0024713054299354553\n",
      "\n",
      "The classification loss after processing this batch is:  0.043147001415491104\n",
      "The representation loss after processing this batch is:  0.002719007432460785\n",
      "\n",
      "The classification loss after processing this batch is:  0.08760930597782135\n",
      "The representation loss after processing this batch is:  0.0024326592683792114\n",
      "\n",
      "The classification loss after processing this batch is:  0.15538723766803741\n",
      "The representation loss after processing this batch is:  0.002859868109226227\n",
      "\n",
      "The classification loss after processing this batch is:  0.09883119910955429\n",
      "The representation loss after processing this batch is:  0.0027156472206115723\n",
      "\n",
      "The classification loss after processing this batch is:  0.11067500710487366\n",
      "The representation loss after processing this batch is:  0.0024456679821014404\n",
      "\n",
      "The classification loss after processing this batch is:  0.063569575548172\n",
      "The representation loss after processing this batch is:  0.0024829283356666565\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.0468454509973526\n",
      "The representation loss after processing this batch is:  0.002424299716949463\n",
      "\n",
      "The classification loss after processing this batch is:  0.08080554753541946\n",
      "The representation loss after processing this batch is:  0.0023404136300086975\n",
      "\n",
      "The classification loss after processing this batch is:  0.17199741303920746\n",
      "The representation loss after processing this batch is:  0.0028889551758766174\n",
      "\n",
      "The classification loss after processing this batch is:  0.17363442480564117\n",
      "The representation loss after processing this batch is:  0.0025551170110702515\n",
      "\n",
      "The classification loss after processing this batch is:  0.13146662712097168\n",
      "The representation loss after processing this batch is:  0.002047695219516754\n",
      "\n",
      "The classification loss after processing this batch is:  0.11956501007080078\n",
      "The representation loss after processing this batch is:  0.002408072352409363\n",
      "\n",
      "The classification loss after processing this batch is:  0.2065410315990448\n",
      "The representation loss after processing this batch is:  0.00248543918132782\n",
      "\n",
      "The classification loss after processing this batch is:  0.08517523109912872\n",
      "The representation loss after processing this batch is:  0.002788364887237549\n",
      "\n",
      "The classification loss after processing this batch is:  0.19609659910202026\n",
      "The representation loss after processing this batch is:  0.002805851399898529\n",
      "\n",
      "The classification loss after processing this batch is:  0.10416937619447708\n",
      "The representation loss after processing this batch is:  0.002824537456035614\n",
      "\n",
      "The classification loss after processing this batch is:  0.050051458179950714\n",
      "The representation loss after processing this batch is:  0.0025512799620628357\n",
      "\n",
      "The classification loss after processing this batch is:  0.034583911299705505\n",
      "The representation loss after processing this batch is:  0.002449050545692444\n",
      "\n",
      "The classification loss after processing this batch is:  0.049952294677495956\n",
      "The representation loss after processing this batch is:  0.0024952441453933716\n",
      "\n",
      "The classification loss after processing this batch is:  0.16838768124580383\n",
      "The representation loss after processing this batch is:  0.002623356878757477\n",
      "\n",
      "The classification loss after processing this batch is:  0.049899760633707047\n",
      "The representation loss after processing this batch is:  0.002653665840625763\n",
      "\n",
      "The classification loss after processing this batch is:  0.12135376781225204\n",
      "The representation loss after processing this batch is:  0.0026863515377044678\n",
      "\n",
      "The classification loss after processing this batch is:  0.10104256123304367\n",
      "The representation loss after processing this batch is:  0.0027788951992988586\n",
      "\n",
      "The classification loss after processing this batch is:  0.07309933006763458\n",
      "The representation loss after processing this batch is:  0.002673707902431488\n",
      "\n",
      "The classification loss after processing this batch is:  0.042013924568891525\n",
      "The representation loss after processing this batch is:  0.0024241656064987183\n",
      "\n",
      "The classification loss after processing this batch is:  0.13855919241905212\n",
      "The representation loss after processing this batch is:  0.0024186596274375916\n",
      "\n",
      "The classification loss after processing this batch is:  0.17886731028556824\n",
      "The representation loss after processing this batch is:  0.0025908276438713074\n",
      "\n",
      "The classification loss after processing this batch is:  0.13105572760105133\n",
      "The representation loss after processing this batch is:  0.0027702972292900085\n",
      "\n",
      "The classification loss after processing this batch is:  0.07690351456403732\n",
      "The representation loss after processing this batch is:  0.002495989203453064\n",
      "\n",
      "The classification loss after processing this batch is:  0.19198928773403168\n",
      "The representation loss after processing this batch is:  0.0023979023098945618\n",
      "\n",
      "The classification loss after processing this batch is:  0.04752211645245552\n",
      "The representation loss after processing this batch is:  0.0021867454051971436\n",
      "\n",
      "The classification loss after processing this batch is:  0.14830747246742249\n",
      "The representation loss after processing this batch is:  0.0024024546146392822\n",
      "\n",
      "The classification loss after processing this batch is:  0.15362271666526794\n",
      "The representation loss after processing this batch is:  0.002856440842151642\n",
      "\n",
      "The classification loss after processing this batch is:  0.10858751833438873\n",
      "The representation loss after processing this batch is:  0.0024054870009422302\n",
      "\n",
      "The classification loss after processing this batch is:  0.1451103389263153\n",
      "The representation loss after processing this batch is:  0.002697765827178955\n",
      "\n",
      "The classification loss after processing this batch is:  0.1013072058558464\n",
      "The representation loss after processing this batch is:  0.0029687657952308655\n",
      "\n",
      "The classification loss after processing this batch is:  0.15629717707633972\n",
      "The representation loss after processing this batch is:  0.00249394029378891\n",
      "\n",
      "The classification loss after processing this batch is:  0.23777757585048676\n",
      "The representation loss after processing this batch is:  0.002798132598400116\n",
      "\n",
      "The classification loss after processing this batch is:  0.1570321023464203\n",
      "The representation loss after processing this batch is:  0.0024949312210083008\n",
      "\n",
      "The classification loss after processing this batch is:  0.10033100098371506\n",
      "The representation loss after processing this batch is:  0.002590782940387726\n",
      "\n",
      "The classification loss after processing this batch is:  0.07147637009620667\n",
      "The representation loss after processing this batch is:  0.0030096471309661865\n",
      "\n",
      "The classification loss after processing this batch is:  0.12751469016075134\n",
      "The representation loss after processing this batch is:  0.002332337200641632\n",
      "\n",
      "The classification loss after processing this batch is:  0.11353028565645218\n",
      "The representation loss after processing this batch is:  0.002290777862071991\n",
      "\n",
      "The classification loss after processing this batch is:  0.022680584341287613\n",
      "The representation loss after processing this batch is:  0.0023450851440429688\n",
      "\n",
      "The classification loss after processing this batch is:  0.10793336480855942\n",
      "The representation loss after processing this batch is:  0.002298343926668167\n",
      "\n",
      "The classification loss after processing this batch is:  0.2587478756904602\n",
      "The representation loss after processing this batch is:  0.0028502829372882843\n",
      "\n",
      "The classification loss after processing this batch is:  0.24955838918685913\n",
      "The representation loss after processing this batch is:  0.0026924461126327515\n",
      "\n",
      "The classification loss after processing this batch is:  0.20934727787971497\n",
      "The representation loss after processing this batch is:  0.0024161189794540405\n",
      "\n",
      "The classification loss after processing this batch is:  0.18183621764183044\n",
      "The representation loss after processing this batch is:  0.002413269132375717\n",
      "\n",
      "The classification loss after processing this batch is:  0.04143694415688515\n",
      "The representation loss after processing this batch is:  0.002432122826576233\n",
      "\n",
      "The classification loss after processing this batch is:  0.16465257108211517\n",
      "The representation loss after processing this batch is:  0.002558678388595581\n",
      "\n",
      "The classification loss after processing this batch is:  0.12655743956565857\n",
      "The representation loss after processing this batch is:  0.0026785507798194885\n",
      "\n",
      "The classification loss after processing this batch is:  0.21421289443969727\n",
      "The representation loss after processing this batch is:  0.0027555450797080994\n",
      "\n",
      "The classification loss after processing this batch is:  0.10947930067777634\n",
      "The representation loss after processing this batch is:  0.0026414915919303894\n",
      "\n",
      "The classification loss after processing this batch is:  0.07177160680294037\n",
      "The representation loss after processing this batch is:  0.003066122531890869\n",
      "\n",
      "The classification loss after processing this batch is:  0.05839279666543007\n",
      "The representation loss after processing this batch is:  0.002705104649066925\n",
      "\n",
      "The classification loss after processing this batch is:  0.10303027927875519\n",
      "The representation loss after processing this batch is:  0.0024504512548446655\n",
      "\n",
      "The classification loss after processing this batch is:  0.17116884887218475\n",
      "The representation loss after processing this batch is:  0.0027226880192756653\n",
      "\n",
      "The classification loss after processing this batch is:  0.12433800101280212\n",
      "The representation loss after processing this batch is:  0.0024221837520599365\n",
      "\n",
      "The classification loss after processing this batch is:  0.05023575201630592\n",
      "The representation loss after processing this batch is:  0.002271149307489395\n",
      "\n",
      "The classification loss after processing this batch is:  0.24508723616600037\n",
      "The representation loss after processing this batch is:  0.0030881427228450775\n",
      "\n",
      "The classification loss after processing this batch is:  0.31987401843070984\n",
      "The representation loss after processing this batch is:  0.0030417069792747498\n",
      "\n",
      "The classification loss after processing this batch is:  0.1714077740907669\n",
      "The representation loss after processing this batch is:  0.002853207290172577\n",
      "\n",
      "The classification loss after processing this batch is:  0.08184347301721573\n",
      "The representation loss after processing this batch is:  0.0028473585844039917\n",
      "\n",
      "The classification loss after processing this batch is:  0.08920811116695404\n",
      "The representation loss after processing this batch is:  0.002604074776172638\n",
      "\n",
      "The classification loss after processing this batch is:  0.06017361208796501\n",
      "The representation loss after processing this batch is:  0.002780601382255554\n",
      "\n",
      "The classification loss after processing this batch is:  0.21924394369125366\n",
      "The representation loss after processing this batch is:  0.0024865269660949707\n",
      "\n",
      "The classification loss after processing this batch is:  0.13121086359024048\n",
      "The representation loss after processing this batch is:  0.0030071213841438293\n",
      "\n",
      "The classification loss after processing this batch is:  0.10844092816114426\n",
      "The representation loss after processing this batch is:  0.0030865445733070374\n",
      "\n",
      "The classification loss after processing this batch is:  0.19998224079608917\n",
      "The representation loss after processing this batch is:  0.0025661587715148926\n",
      "\n",
      "The classification loss after processing this batch is:  0.024149369448423386\n",
      "The representation loss after processing this batch is:  0.002548500895500183\n",
      "\n",
      "The classification loss after processing this batch is:  0.031445614993572235\n",
      "The representation loss after processing this batch is:  0.0027536973357200623\n",
      "\n",
      "The classification loss after processing this batch is:  0.073384128510952\n",
      "The representation loss after processing this batch is:  0.002713635563850403\n",
      "\n",
      "The classification loss after processing this batch is:  0.09726087749004364\n",
      "The representation loss after processing this batch is:  0.0022983960807323456\n",
      "\n",
      "The classification loss after processing this batch is:  0.13981233537197113\n",
      "The representation loss after processing this batch is:  0.0025610774755477905\n",
      "\n",
      "The classification loss after processing this batch is:  0.09435375779867172\n",
      "The representation loss after processing this batch is:  0.0026979222893714905\n",
      "\n",
      "The classification loss after processing this batch is:  0.11347690969705582\n",
      "The representation loss after processing this batch is:  0.002553597092628479\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.03161447495222092\n",
      "The representation loss after processing this batch is:  0.0024306774139404297\n",
      "\n",
      "The classification loss after processing this batch is:  0.07691330462694168\n",
      "The representation loss after processing this batch is:  0.0023519620299339294\n",
      "\n",
      "The classification loss after processing this batch is:  0.061740245670080185\n",
      "The representation loss after processing this batch is:  0.00269269198179245\n",
      "\n",
      "The classification loss after processing this batch is:  0.04654129594564438\n",
      "The representation loss after processing this batch is:  0.0029136911034584045\n",
      "\n",
      "The classification loss after processing this batch is:  0.07395102083683014\n",
      "The representation loss after processing this batch is:  0.0024058185517787933\n",
      "\n",
      "The classification loss after processing this batch is:  0.10325843840837479\n",
      "The representation loss after processing this batch is:  0.0023729652166366577\n",
      "\n",
      "The classification loss after processing this batch is:  0.14692454040050507\n",
      "The representation loss after processing this batch is:  0.002586863934993744\n",
      "\n",
      "The classification loss after processing this batch is:  0.035589855164289474\n",
      "The representation loss after processing this batch is:  0.0024130158126354218\n",
      "\n",
      "The classification loss after processing this batch is:  0.04450028017163277\n",
      "The representation loss after processing this batch is:  0.002651490271091461\n",
      "\n",
      "The classification loss after processing this batch is:  0.06591854989528656\n",
      "The representation loss after processing this batch is:  0.0029000788927078247\n",
      "\n",
      "The classification loss after processing this batch is:  0.12092574685811996\n",
      "The representation loss after processing this batch is:  0.0027147382497787476\n",
      "\n",
      "The classification loss after processing this batch is:  0.04936204105615616\n",
      "The representation loss after processing this batch is:  0.003360748291015625\n",
      "\n",
      "The classification loss after processing this batch is:  0.1292610764503479\n",
      "The representation loss after processing this batch is:  0.0028737783432006836\n",
      "\n",
      "The classification loss after processing this batch is:  0.16243623197078705\n",
      "The representation loss after processing this batch is:  0.0025758519768714905\n",
      "\n",
      "The classification loss after processing this batch is:  0.12421897053718567\n",
      "The representation loss after processing this batch is:  0.0028156936168670654\n",
      "\n",
      "The classification loss after processing this batch is:  0.16443070769309998\n",
      "The representation loss after processing this batch is:  0.002660393714904785\n",
      "\n",
      "The classification loss after processing this batch is:  0.062410276383161545\n",
      "The representation loss after processing this batch is:  0.00267145037651062\n",
      "\n",
      "The classification loss after processing this batch is:  0.09344077855348587\n",
      "The representation loss after processing this batch is:  0.0023939013481140137\n",
      "\n",
      "The classification loss after processing this batch is:  0.1353813260793686\n",
      "The representation loss after processing this batch is:  0.002387918531894684\n",
      "\n",
      "The classification loss after processing this batch is:  0.05724214017391205\n",
      "The representation loss after processing this batch is:  0.0026022791862487793\n",
      "\n",
      "The classification loss after processing this batch is:  0.018937300890684128\n",
      "The representation loss after processing this batch is:  0.0023589730262756348\n",
      "\n",
      "The classification loss after processing this batch is:  0.22489207983016968\n",
      "The representation loss after processing this batch is:  0.002593807876110077\n",
      "\n",
      "The classification loss after processing this batch is:  0.25810930132865906\n",
      "The representation loss after processing this batch is:  0.0024710670113563538\n",
      "\n",
      "The classification loss after processing this batch is:  0.06873724609613419\n",
      "The representation loss after processing this batch is:  0.002452842891216278\n",
      "\n",
      "The classification loss after processing this batch is:  0.22310543060302734\n",
      "The representation loss after processing this batch is:  0.0025408416986465454\n",
      "\n",
      "The classification loss after processing this batch is:  0.19168634712696075\n",
      "The representation loss after processing this batch is:  0.002668224275112152\n",
      "\n",
      "The classification loss after processing this batch is:  0.24654272198677063\n",
      "The representation loss after processing this batch is:  0.002656787633895874\n",
      "\n",
      "The classification loss after processing this batch is:  0.116923026740551\n",
      "The representation loss after processing this batch is:  0.0026381462812423706\n",
      "\n",
      "The classification loss after processing this batch is:  0.08207037299871445\n",
      "The representation loss after processing this batch is:  0.0026034116744995117\n",
      "\n",
      "The classification loss after processing this batch is:  0.12184340506792068\n",
      "The representation loss after processing this batch is:  0.002903848886489868\n",
      "\n",
      "The classification loss after processing this batch is:  0.05482771247625351\n",
      "The representation loss after processing this batch is:  0.0026993751525878906\n",
      "\n",
      "The classification loss after processing this batch is:  0.03393668681383133\n",
      "The representation loss after processing this batch is:  0.0025833845138549805\n",
      "\n",
      "The classification loss after processing this batch is:  0.054733481258153915\n",
      "The representation loss after processing this batch is:  0.002391122281551361\n",
      "\n",
      "The classification loss after processing this batch is:  0.04885121062397957\n",
      "The representation loss after processing this batch is:  0.002695508301258087\n",
      "\n",
      "The classification loss after processing this batch is:  0.027418101206421852\n",
      "The representation loss after processing this batch is:  0.0025874152779579163\n",
      "\n",
      "The classification loss after processing this batch is:  0.11431853473186493\n",
      "The representation loss after processing this batch is:  0.002593524754047394\n",
      "\n",
      "The classification loss after processing this batch is:  0.10099726170301437\n",
      "The representation loss after processing this batch is:  0.0024043098092079163\n",
      "\n",
      "The classification loss after processing this batch is:  0.055169351398944855\n",
      "The representation loss after processing this batch is:  0.002655811607837677\n",
      "\n",
      "The classification loss after processing this batch is:  0.10347094386816025\n",
      "The representation loss after processing this batch is:  0.0024917572736740112\n",
      "\n",
      "The classification loss after processing this batch is:  0.0871862843632698\n",
      "The representation loss after processing this batch is:  0.002730228006839752\n",
      "\n",
      "The classification loss after processing this batch is:  0.02970128133893013\n",
      "The representation loss after processing this batch is:  0.002785824239253998\n",
      "\n",
      "The classification loss after processing this batch is:  0.15594042837619781\n",
      "The representation loss after processing this batch is:  0.0026696771383285522\n",
      "\n",
      "The classification loss after processing this batch is:  0.058929987251758575\n",
      "The representation loss after processing this batch is:  0.0024019256234169006\n",
      "\n",
      "The classification loss after processing this batch is:  0.24157916009426117\n",
      "The representation loss after processing this batch is:  0.0022523701190948486\n",
      "\n",
      "The classification loss after processing this batch is:  0.09155858308076859\n",
      "The representation loss after processing this batch is:  0.002750784158706665\n",
      "\n",
      "The classification loss after processing this batch is:  0.09999627619981766\n",
      "The representation loss after processing this batch is:  0.0022830478847026825\n",
      "\n",
      "The classification loss after processing this batch is:  0.03285694867372513\n",
      "The representation loss after processing this batch is:  0.002414897084236145\n",
      "\n",
      "The classification loss after processing this batch is:  0.029888328164815903\n",
      "The representation loss after processing this batch is:  0.0024691224098205566\n",
      "\n",
      "The classification loss after processing this batch is:  0.12585024535655975\n",
      "The representation loss after processing this batch is:  0.002571888267993927\n",
      "\n",
      "The classification loss after processing this batch is:  0.02807765081524849\n",
      "The representation loss after processing this batch is:  0.0029309839010238647\n",
      "\n",
      "The classification loss after processing this batch is:  0.07383348792791367\n",
      "The representation loss after processing this batch is:  0.0026531219482421875\n",
      "\n",
      "The classification loss after processing this batch is:  0.06917355954647064\n",
      "The representation loss after processing this batch is:  0.0026583969593048096\n",
      "\n",
      "The classification loss after processing this batch is:  0.08071977645158768\n",
      "The representation loss after processing this batch is:  0.002780824899673462\n",
      "\n",
      "The classification loss after processing this batch is:  0.09794938564300537\n",
      "The representation loss after processing this batch is:  0.0026628226041793823\n",
      "\n",
      "The classification loss after processing this batch is:  0.07011423259973526\n",
      "The representation loss after processing this batch is:  0.002632908523082733\n",
      "\n",
      "The classification loss after processing this batch is:  0.11411120742559433\n",
      "The representation loss after processing this batch is:  0.0027601271867752075\n",
      "\n",
      "The classification loss after processing this batch is:  0.12211708724498749\n",
      "The representation loss after processing this batch is:  0.0025393515825271606\n",
      "\n",
      "The classification loss after processing this batch is:  0.12536944448947906\n",
      "The representation loss after processing this batch is:  0.0028615817427635193\n",
      "\n",
      "The classification loss after processing this batch is:  0.1438993513584137\n",
      "The representation loss after processing this batch is:  0.0025371387600898743\n",
      "\n",
      "The classification loss after processing this batch is:  0.17183075845241547\n",
      "The representation loss after processing this batch is:  0.002640165388584137\n",
      "\n",
      "The classification loss after processing this batch is:  0.11826734989881516\n",
      "The representation loss after processing this batch is:  0.002450317144393921\n",
      "\n",
      "The classification loss after processing this batch is:  0.0826505497097969\n",
      "The representation loss after processing this batch is:  0.0024333447217941284\n",
      "\n",
      "The classification loss after processing this batch is:  0.05262717232108116\n",
      "The representation loss after processing this batch is:  0.0024935975670814514\n",
      "\n",
      "The classification loss after processing this batch is:  0.06301295012235641\n",
      "The representation loss after processing this batch is:  0.002576202154159546\n",
      "\n",
      "The classification loss after processing this batch is:  0.054160576313734055\n",
      "The representation loss after processing this batch is:  0.0026574358344078064\n",
      "\n",
      "The classification loss after processing this batch is:  0.07313323765993118\n",
      "The representation loss after processing this batch is:  0.0022616758942604065\n",
      "\n",
      "The classification loss after processing this batch is:  0.05720158666372299\n",
      "The representation loss after processing this batch is:  0.0025778934359550476\n",
      "\n",
      "The classification loss after processing this batch is:  0.0775013417005539\n",
      "The representation loss after processing this batch is:  0.002776309847831726\n",
      "\n",
      "The classification loss after processing this batch is:  0.05500691756606102\n",
      "The representation loss after processing this batch is:  0.002498410642147064\n",
      "\n",
      "The classification loss after processing this batch is:  0.1278422772884369\n",
      "The representation loss after processing this batch is:  0.002395153045654297\n",
      "\n",
      "The classification loss after processing this batch is:  0.057283878326416016\n",
      "The representation loss after processing this batch is:  0.0028343871235847473\n",
      "\n",
      "The classification loss after processing this batch is:  0.13786612451076508\n",
      "The representation loss after processing this batch is:  0.0025303438305854797\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.12175362557172775\n",
      "The representation loss after processing this batch is:  0.002678804099559784\n",
      "\n",
      "The classification loss after processing this batch is:  0.0840134471654892\n",
      "The representation loss after processing this batch is:  0.0026537254452705383\n",
      "\n",
      "The classification loss after processing this batch is:  0.0768619105219841\n",
      "The representation loss after processing this batch is:  0.0026607587933540344\n",
      "\n",
      "The classification loss after processing this batch is:  0.16062532365322113\n",
      "The representation loss after processing this batch is:  0.002692177891731262\n",
      "\n",
      "The classification loss after processing this batch is:  0.04573941230773926\n",
      "The representation loss after processing this batch is:  0.0026679784059524536\n",
      "\n",
      "The classification loss after processing this batch is:  0.05122392997145653\n",
      "The representation loss after processing this batch is:  0.002476423978805542\n",
      "\n",
      "The classification loss after processing this batch is:  0.07259797304868698\n",
      "The representation loss after processing this batch is:  0.002438783645629883\n",
      "\n",
      "The classification loss after processing this batch is:  0.04746755585074425\n",
      "The representation loss after processing this batch is:  0.00249481201171875\n",
      "\n",
      "The classification loss after processing this batch is:  0.13897138833999634\n",
      "The representation loss after processing this batch is:  0.002248793840408325\n",
      "\n",
      "The classification loss after processing this batch is:  0.12901657819747925\n",
      "The representation loss after processing this batch is:  0.0023798495531082153\n",
      "\n",
      "The classification loss after processing this batch is:  0.09692119061946869\n",
      "The representation loss after processing this batch is:  0.0029788464307785034\n",
      "\n",
      "The classification loss after processing this batch is:  0.06769438832998276\n",
      "The representation loss after processing this batch is:  0.0028273165225982666\n",
      "\n",
      "The classification loss after processing this batch is:  0.10006216168403625\n",
      "The representation loss after processing this batch is:  0.0025652945041656494\n",
      "\n",
      "The classification loss after processing this batch is:  0.19761469960212708\n",
      "The representation loss after processing this batch is:  0.0026404038071632385\n",
      "\n",
      "The classification loss after processing this batch is:  0.032919660210609436\n",
      "The representation loss after processing this batch is:  0.00263889878988266\n",
      "\n",
      "The classification loss after processing this batch is:  0.059850454330444336\n",
      "The representation loss after processing this batch is:  0.0028911754488945007\n",
      "\n",
      "The classification loss after processing this batch is:  0.14049170911312103\n",
      "The representation loss after processing this batch is:  0.002307020127773285\n",
      "\n",
      "The classification loss after processing this batch is:  0.26327869296073914\n",
      "The representation loss after processing this batch is:  0.002679198980331421\n",
      "\n",
      "The classification loss after processing this batch is:  0.07369790971279144\n",
      "The representation loss after processing this batch is:  0.002432495355606079\n",
      "\n",
      "The classification loss after processing this batch is:  0.1255902498960495\n",
      "The representation loss after processing this batch is:  0.0022050514817237854\n",
      "\n",
      "The classification loss after processing this batch is:  0.0578538253903389\n",
      "The representation loss after processing this batch is:  0.002565637230873108\n",
      "\n",
      "The classification loss after processing this batch is:  0.035055357962846756\n",
      "The representation loss after processing this batch is:  0.00278259813785553\n",
      "\n",
      "The classification loss after processing this batch is:  0.09242429584264755\n",
      "The representation loss after processing this batch is:  0.0031080618500709534\n",
      "\n",
      "The classification loss after processing this batch is:  0.09410357475280762\n",
      "The representation loss after processing this batch is:  0.003497600555419922\n",
      "\n",
      "The classification loss after processing this batch is:  0.04666685312986374\n",
      "The representation loss after processing this batch is:  0.0030150115489959717\n",
      "\n",
      "The classification loss after processing this batch is:  0.04203159734606743\n",
      "The representation loss after processing this batch is:  0.0024028420448303223\n",
      "\n",
      "The classification loss after processing this batch is:  0.12301989644765854\n",
      "The representation loss after processing this batch is:  0.002733830362558365\n",
      "\n",
      "The classification loss after processing this batch is:  0.07895602285861969\n",
      "The representation loss after processing this batch is:  0.0026482269167900085\n",
      "\n",
      "The classification loss after processing this batch is:  0.05517008528113365\n",
      "The representation loss after processing this batch is:  0.0022909343242645264\n",
      "\n",
      "The classification loss after processing this batch is:  0.05064651742577553\n",
      "The representation loss after processing this batch is:  0.002739451825618744\n",
      "\n",
      "The classification loss after processing this batch is:  0.1296509951353073\n",
      "The representation loss after processing this batch is:  0.0024604275822639465\n",
      "\n",
      "The classification loss after processing this batch is:  0.11192280799150467\n",
      "The representation loss after processing this batch is:  0.0027191415429115295\n",
      "\n",
      "The classification loss after processing this batch is:  0.20241931080818176\n",
      "The representation loss after processing this batch is:  0.0023135244846343994\n",
      "\n",
      "The classification loss after processing this batch is:  0.10336858779191971\n",
      "The representation loss after processing this batch is:  0.0025710389018058777\n",
      "\n",
      "The classification loss after processing this batch is:  0.1736880987882614\n",
      "The representation loss after processing this batch is:  0.0023913756012916565\n",
      "\n",
      "The classification loss after processing this batch is:  0.06724648177623749\n",
      "The representation loss after processing this batch is:  0.0029271021485328674\n",
      "\n",
      "The classification loss after processing this batch is:  0.07528816163539886\n",
      "The representation loss after processing this batch is:  0.003004133701324463\n",
      "\n",
      "The classification loss after processing this batch is:  0.05024515837430954\n",
      "The representation loss after processing this batch is:  0.002443872392177582\n",
      "\n",
      "The classification loss after processing this batch is:  0.05038725957274437\n",
      "The representation loss after processing this batch is:  0.0024843737483024597\n",
      "\n",
      "The classification loss after processing this batch is:  0.13942284882068634\n",
      "The representation loss after processing this batch is:  0.002374563366174698\n",
      "\n",
      "The classification loss after processing this batch is:  0.06368212401866913\n",
      "The representation loss after processing this batch is:  0.002800464630126953\n",
      "\n",
      "The classification loss after processing this batch is:  0.03484169766306877\n",
      "The representation loss after processing this batch is:  0.00254223495721817\n",
      "\n",
      "The classification loss after processing this batch is:  0.045702014118433\n",
      "The representation loss after processing this batch is:  0.0031779110431671143\n",
      "\n",
      "The classification loss after processing this batch is:  0.019017089158296585\n",
      "The representation loss after processing this batch is:  0.0029514506459236145\n",
      "\n",
      "The classification loss after processing this batch is:  0.050274547189474106\n",
      "The representation loss after processing this batch is:  0.0033957138657569885\n",
      "\n",
      "The classification loss after processing this batch is:  0.05182322487235069\n",
      "The representation loss after processing this batch is:  0.0028077736496925354\n",
      "\n",
      "The classification loss after processing this batch is:  0.034678418189287186\n",
      "The representation loss after processing this batch is:  0.0028405115008354187\n",
      "\n",
      "The classification loss after processing this batch is:  0.009350832551717758\n",
      "The representation loss after processing this batch is:  0.0026976242661476135\n",
      "\n",
      "The classification loss after processing this batch is:  0.027317892760038376\n",
      "The representation loss after processing this batch is:  0.003050990402698517\n",
      "\n",
      "The classification loss after processing this batch is:  0.06834287941455841\n",
      "The representation loss after processing this batch is:  0.0035241320729255676\n",
      "\n",
      "The classification loss after processing this batch is:  0.009253541938960552\n",
      "The representation loss after processing this batch is:  0.0034086108207702637\n",
      "\n",
      "The classification loss after processing this batch is:  0.0207676962018013\n",
      "The representation loss after processing this batch is:  0.003001078963279724\n",
      "\n",
      "The classification loss after processing this batch is:  0.17122797667980194\n",
      "The representation loss after processing this batch is:  0.002897985279560089\n",
      "\n",
      "The classification loss after processing this batch is:  0.02832808531820774\n",
      "The representation loss after processing this batch is:  0.003029666841030121\n",
      "\n",
      "The classification loss after processing this batch is:  0.012278055772185326\n",
      "The representation loss after processing this batch is:  0.002772808074951172\n",
      "\n",
      "The classification loss after processing this batch is:  0.019587818533182144\n",
      "The representation loss after processing this batch is:  0.0032116547226905823\n",
      "\n",
      "The classification loss after processing this batch is:  0.01531143207103014\n",
      "The representation loss after processing this batch is:  0.0029761046171188354\n",
      "\n",
      "The classification loss after processing this batch is:  0.011983855627477169\n",
      "The representation loss after processing this batch is:  0.0027302131056785583\n",
      "\n",
      "The classification loss after processing this batch is:  0.007871834561228752\n",
      "The representation loss after processing this batch is:  0.003198176622390747\n",
      "\n",
      "The classification loss after processing this batch is:  0.009829242713749409\n",
      "The representation loss after processing this batch is:  0.003397934138774872\n",
      "\n",
      "The classification loss after processing this batch is:  0.3268525302410126\n",
      "The representation loss after processing this batch is:  0.0036413073539733887\n",
      "\n",
      "The classification loss after processing this batch is:  0.2728674113750458\n",
      "The representation loss after processing this batch is:  0.0033459067344665527\n",
      "\n",
      "The classification loss after processing this batch is:  0.17663155496120453\n",
      "The representation loss after processing this batch is:  0.00380108505487442\n",
      "\n",
      "The classification loss after processing this batch is:  0.04073099419474602\n",
      "The representation loss after processing this batch is:  0.0028803646564483643\n",
      "\n",
      "The classification loss after processing this batch is:  0.008871825411915779\n",
      "The representation loss after processing this batch is:  0.0033654794096946716\n",
      "\n",
      "The classification loss after processing this batch is:  0.009423676878213882\n",
      "The representation loss after processing this batch is:  0.0024106651544570923\n",
      "\n",
      "The classification loss after processing this batch is:  0.08388573676347733\n",
      "The representation loss after processing this batch is:  0.0025861933827400208\n",
      "\n",
      "The classification loss after processing this batch is:  0.33584874868392944\n",
      "The representation loss after processing this batch is:  0.00292389839887619\n",
      "\n",
      "The classification loss after processing this batch is:  0.044018249958753586\n",
      "The representation loss after processing this batch is:  0.0027688518166542053\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.025107573717832565\n",
      "The representation loss after processing this batch is:  0.003191515803337097\n",
      "\n",
      "The classification loss after processing this batch is:  0.029798444360494614\n",
      "The representation loss after processing this batch is:  0.003238297998905182\n",
      "\n",
      "The classification loss after processing this batch is:  0.03727249428629875\n",
      "The representation loss after processing this batch is:  0.003818199038505554\n",
      "\n",
      "Done training..\n",
      "=*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*=\n"
     ]
    }
   ],
   "source": [
    "modelMM = NeuralModel()\n",
    "model = train_model(modelMM, training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_data):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "\n",
    "    for batch in test_data:\n",
    "        batch_images, batch_labels = batch\n",
    "\n",
    "        batch_images = batch_images.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        predictions = model(batch_images)\n",
    "       \n",
    "        predictions = predictions.data.max(1, keepdim=True)[1]\n",
    "       \n",
    "        correct += predictions.eq(batch_labels.data.view_as(predictions)).sum()\n",
    "       \n",
    "\n",
    "    accuracy = float(correct.item() / len(test_data.dataset))\n",
    "    \n",
    "    print(\"The classifier accuracy is: \", 100 * accuracy)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier accuracy is:  95.83\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9583"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64)\n",
    "test_model(modelMM, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.3\tTest Accuracy = 5148 / 10000 = 0.5148\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1)\n",
    "acc, _ = test_attack(modelMM, device, test_loader, epsilon=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
