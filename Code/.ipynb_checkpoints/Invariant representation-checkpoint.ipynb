{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import data_loader\n",
    "from classifier_attacks import test_attack\n",
    "import pickle\n",
    "from utils.viewer import show_batch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.mmd import MMD_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = data_loader.get_data()\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_channels = 8\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(1, num_channels, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(num_channels, eps=1e-05, momentum=0.5, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_channels, eps=1e-05, momentum=0.5, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(num_channels, num_channels, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(num_channels, eps=1e-05, momentum=0.5, affine=True),\n",
    "            nn.ReLU(inplace=True)\n",
    "\n",
    "        )\n",
    "        self.fc1 = nn.Linear(num_channels * 4 ** 2, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        convolved = self.conv(x)\n",
    "        after_fc1 = self.fc1(convolved.view(convolved.size(0), -1))\n",
    "        output = self.fc2(after_fc1)\n",
    "        return output\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \n",
    "        convolved = self.conv(x)\n",
    "        code = self.fc1(convolved.view(convolved.size(0), -1))\n",
    "        \n",
    "        return code\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=512)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=512)\n",
    "\n",
    "first_batch = next(iter(train_loader))\n",
    "first_images, first_labels = first_batch \n",
    "\n",
    "print(first_images.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = NeuralModel()\n",
    "#train_model(model, train_loader)\n",
    "#test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = torch.utils.data.DataLoader(test_set, batch_size=1)\n",
    "# train_loader = torch.utils.data.DataLoader(train_set, batch_size=1)\n",
    "# #acc, adv_examples = test_attack(model, device, train_loader, epsilon=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(adv_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('models/train_adv_examples.pkl', 'wb') as f:\n",
    "#     pickle.dump(adv_examples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/train_adv_examples.pkl', 'rb') as f:\n",
    "    adv_examples = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels =[]\n",
    "adv_labels = [] \n",
    "adv_images =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in adv_examples:\n",
    "    true_l, adv_l, adv_img = example\n",
    "    \n",
    "    true_labels.append(true_l)\n",
    "    adv_labels.append(adv_l)\n",
    "    adv_images.append(adv_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = torch.Tensor(true_labels).long()\n",
    "adv_images = torch.Tensor(adv_images).reshape(-1,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "b_size = 60\n",
    "training_data = []\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=b_size)\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_iter = iter(train_loader)\n",
    "\n",
    "for b in range (0, len(train_loader)*b_size, b_size):\n",
    "    batch_images, batch_labels = next(train_loader_iter)\n",
    "    training_data.append((batch_images, adv_images[b: b+b_size], true_labels[b: b+b_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "60\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 0, 2, 7, 1, 8, 6, 4, 1, 6, 3, 4, 1, 9, 1, 3, 3, 8, 5, 4, 7, 7, 4, 2,\n",
      "        8, 5, 8, 6, 9, 3, 4, 6, 1, 9, 9, 6, 0, 3, 7, 2, 8, 2, 9, 4, 4, 6, 4, 9,\n",
      "        7, 0, 9, 2, 7, 5, 1, 5, 9, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "training_data_iter = iter(training_data)\n",
    "b1 = next(training_data_iter)\n",
    "b1 = next(training_data_iter)\n",
    "b1 = next(training_data_iter)\n",
    "a,b,c = b1\n",
    "\n",
    "print(len(a))\n",
    "print(len(b))\n",
    "print(len(c))\n",
    "\n",
    "show_batch(a)\n",
    "show_batch(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    n_epochs = 10\n",
    "    model.train()\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    print(\"training ...\")\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch in train_data:\n",
    "            batch_images, adv_images, batch_labels = batch\n",
    "\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            adv_images = adv_images.to(device)\n",
    "            \n",
    "            batch_output = model(batch_images)\n",
    "            \n",
    "            latent_1 = model.encode(batch_images)\n",
    "            latent_2 = model.encode(adv_images)\n",
    "            \n",
    "            down_stream_loss = criterion(batch_output, batch_labels)\n",
    "            representation_loss = MMD_Loss(latent_1, latent_2)\n",
    "            \n",
    "            total_loss = down_stream_loss + 100*representation_loss\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(\"The classification loss after processing this batch is: \", down_stream_loss.item())\n",
    "            print(\"The representation loss after processing this batch is: \", representation_loss.item())\n",
    "            print(\"\")\n",
    "            \n",
    "    print(\"Done training..\")\n",
    "    print(\"=*=\"*20)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MMD_Loss(x, y):\n",
    "    \n",
    "    alpha =1\n",
    "    B=b_size\n",
    "\n",
    "    x = x.view(x.size(0), x.size(1) * 1)\n",
    "    y = y.view(y.size(0), y.size(1) * 1)\n",
    "\n",
    "    xx, yy, zz = torch.mm(x,x.t()), torch.mm(y,y.t()), torch.mm(x,y.t())\n",
    "\n",
    "    rx = (xx.diag().unsqueeze(0).expand_as(xx))\n",
    "    ry = (yy.diag().unsqueeze(0).expand_as(yy))\n",
    "\n",
    "    K = torch.exp(- alpha * (rx.t() + rx - 2*xx))\n",
    "    L = torch.exp(- alpha * (ry.t() + ry - 2*yy))\n",
    "    P = torch.exp(- alpha * (rx.t() + ry - 2*zz))\n",
    "\n",
    "    beta = (1./(B*(B-1)))\n",
    "    gamma = (2./(B*B)) \n",
    "\n",
    "    return beta * (torch.sum(K)+torch.sum(L)) - gamma * torch.sum(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ...\n",
      "The classification loss after processing this batch is:  2.30633807182312\n",
      "The representation loss after processing this batch is:  0.03597879409790039\n",
      "\n",
      "The classification loss after processing this batch is:  2.339465856552124\n",
      "The representation loss after processing this batch is:  0.032785892486572266\n",
      "\n",
      "The classification loss after processing this batch is:  2.3406877517700195\n",
      "The representation loss after processing this batch is:  0.030658245086669922\n",
      "\n",
      "The classification loss after processing this batch is:  2.32474422454834\n",
      "The representation loss after processing this batch is:  0.026526331901550293\n",
      "\n",
      "The classification loss after processing this batch is:  2.3288662433624268\n",
      "The representation loss after processing this batch is:  0.031468987464904785\n",
      "\n",
      "The classification loss after processing this batch is:  2.33137845993042\n",
      "The representation loss after processing this batch is:  0.030362963676452637\n",
      "\n",
      "The classification loss after processing this batch is:  2.365344762802124\n",
      "The representation loss after processing this batch is:  0.026575088500976562\n",
      "\n",
      "The classification loss after processing this batch is:  2.3224174976348877\n",
      "The representation loss after processing this batch is:  0.026257038116455078\n",
      "\n",
      "The classification loss after processing this batch is:  2.3121109008789062\n",
      "The representation loss after processing this batch is:  0.025606989860534668\n",
      "\n",
      "The classification loss after processing this batch is:  2.327397346496582\n",
      "The representation loss after processing this batch is:  0.0236051082611084\n",
      "\n",
      "The classification loss after processing this batch is:  2.290853977203369\n",
      "The representation loss after processing this batch is:  0.02580958604812622\n",
      "\n",
      "The classification loss after processing this batch is:  2.356187582015991\n",
      "The representation loss after processing this batch is:  0.022092461585998535\n",
      "\n",
      "The classification loss after processing this batch is:  2.3179664611816406\n",
      "The representation loss after processing this batch is:  0.02407938241958618\n",
      "\n",
      "The classification loss after processing this batch is:  2.3166892528533936\n",
      "The representation loss after processing this batch is:  0.02449500560760498\n",
      "\n",
      "The classification loss after processing this batch is:  2.314990997314453\n",
      "The representation loss after processing this batch is:  0.024276673793792725\n",
      "\n",
      "The classification loss after processing this batch is:  2.3198494911193848\n",
      "The representation loss after processing this batch is:  0.021005213260650635\n",
      "\n",
      "The classification loss after processing this batch is:  2.2907536029815674\n",
      "The representation loss after processing this batch is:  0.01991283893585205\n",
      "\n",
      "The classification loss after processing this batch is:  2.3112690448760986\n",
      "The representation loss after processing this batch is:  0.021414637565612793\n",
      "\n",
      "The classification loss after processing this batch is:  2.3271946907043457\n",
      "The representation loss after processing this batch is:  0.020437777042388916\n",
      "\n",
      "The classification loss after processing this batch is:  2.3392248153686523\n",
      "The representation loss after processing this batch is:  0.01947575807571411\n",
      "\n",
      "The classification loss after processing this batch is:  2.3328206539154053\n",
      "The representation loss after processing this batch is:  0.021739184856414795\n",
      "\n",
      "The classification loss after processing this batch is:  2.298888921737671\n",
      "The representation loss after processing this batch is:  0.021193504333496094\n",
      "\n",
      "The classification loss after processing this batch is:  2.3149173259735107\n",
      "The representation loss after processing this batch is:  0.0196189284324646\n",
      "\n",
      "The classification loss after processing this batch is:  2.3028318881988525\n",
      "The representation loss after processing this batch is:  0.021795153617858887\n",
      "\n",
      "The classification loss after processing this batch is:  2.2806437015533447\n",
      "The representation loss after processing this batch is:  0.021502315998077393\n",
      "\n",
      "The classification loss after processing this batch is:  2.2914812564849854\n",
      "The representation loss after processing this batch is:  0.020976781845092773\n",
      "\n",
      "The classification loss after processing this batch is:  2.2962403297424316\n",
      "The representation loss after processing this batch is:  0.019922614097595215\n",
      "\n",
      "The classification loss after processing this batch is:  2.294854164123535\n",
      "The representation loss after processing this batch is:  0.01987522840499878\n",
      "\n",
      "The classification loss after processing this batch is:  2.2976462841033936\n",
      "The representation loss after processing this batch is:  0.0190240740776062\n",
      "\n",
      "The classification loss after processing this batch is:  2.2754065990448\n",
      "The representation loss after processing this batch is:  0.018177449703216553\n",
      "\n",
      "The classification loss after processing this batch is:  2.268286943435669\n",
      "The representation loss after processing this batch is:  0.02292013168334961\n",
      "\n",
      "The classification loss after processing this batch is:  2.2939581871032715\n",
      "The representation loss after processing this batch is:  0.02030390501022339\n",
      "\n",
      "The classification loss after processing this batch is:  2.2712693214416504\n",
      "The representation loss after processing this batch is:  0.016527295112609863\n",
      "\n",
      "The classification loss after processing this batch is:  2.2877466678619385\n",
      "The representation loss after processing this batch is:  0.019316911697387695\n",
      "\n",
      "The classification loss after processing this batch is:  2.291071891784668\n",
      "The representation loss after processing this batch is:  0.016651928424835205\n",
      "\n",
      "The classification loss after processing this batch is:  2.2554078102111816\n",
      "The representation loss after processing this batch is:  0.01618891954421997\n",
      "\n",
      "The classification loss after processing this batch is:  2.259207010269165\n",
      "The representation loss after processing this batch is:  0.016598939895629883\n",
      "\n",
      "The classification loss after processing this batch is:  2.2419118881225586\n",
      "The representation loss after processing this batch is:  0.017875373363494873\n",
      "\n",
      "The classification loss after processing this batch is:  2.256267786026001\n",
      "The representation loss after processing this batch is:  0.014942049980163574\n",
      "\n",
      "The classification loss after processing this batch is:  2.2713682651519775\n",
      "The representation loss after processing this batch is:  0.01886087656021118\n",
      "\n",
      "The classification loss after processing this batch is:  2.3125734329223633\n",
      "The representation loss after processing this batch is:  0.015336751937866211\n",
      "\n",
      "The classification loss after processing this batch is:  2.266242265701294\n",
      "The representation loss after processing this batch is:  0.018814146518707275\n",
      "\n",
      "The classification loss after processing this batch is:  2.2355246543884277\n",
      "The representation loss after processing this batch is:  0.018858492374420166\n",
      "\n",
      "The classification loss after processing this batch is:  2.240135908126831\n",
      "The representation loss after processing this batch is:  0.013673216104507446\n",
      "\n",
      "The classification loss after processing this batch is:  2.258148670196533\n",
      "The representation loss after processing this batch is:  0.01534336805343628\n",
      "\n",
      "The classification loss after processing this batch is:  2.2619259357452393\n",
      "The representation loss after processing this batch is:  0.014343172311782837\n",
      "\n",
      "The classification loss after processing this batch is:  2.2524235248565674\n",
      "The representation loss after processing this batch is:  0.015272408723831177\n",
      "\n",
      "The classification loss after processing this batch is:  2.2739479541778564\n",
      "The representation loss after processing this batch is:  0.014882117509841919\n",
      "\n",
      "The classification loss after processing this batch is:  2.2095649242401123\n",
      "The representation loss after processing this batch is:  0.018196970224380493\n",
      "\n",
      "The classification loss after processing this batch is:  2.2256388664245605\n",
      "The representation loss after processing this batch is:  0.014842838048934937\n",
      "\n",
      "The classification loss after processing this batch is:  2.224778175354004\n",
      "The representation loss after processing this batch is:  0.018247604370117188\n",
      "\n",
      "The classification loss after processing this batch is:  2.2484426498413086\n",
      "The representation loss after processing this batch is:  0.016819238662719727\n",
      "\n",
      "The classification loss after processing this batch is:  2.2124061584472656\n",
      "The representation loss after processing this batch is:  0.01703396439552307\n",
      "\n",
      "The classification loss after processing this batch is:  2.2404861450195312\n",
      "The representation loss after processing this batch is:  0.014388024806976318\n",
      "\n",
      "The classification loss after processing this batch is:  2.2007651329040527\n",
      "The representation loss after processing this batch is:  0.015097320079803467\n",
      "\n",
      "The classification loss after processing this batch is:  2.2343647480010986\n",
      "The representation loss after processing this batch is:  0.01559332013130188\n",
      "\n",
      "The classification loss after processing this batch is:  2.2267253398895264\n",
      "The representation loss after processing this batch is:  0.012942343950271606\n",
      "\n",
      "The classification loss after processing this batch is:  2.2233035564422607\n",
      "The representation loss after processing this batch is:  0.01380091905593872\n",
      "\n",
      "The classification loss after processing this batch is:  2.21423077583313\n",
      "The representation loss after processing this batch is:  0.012449026107788086\n",
      "\n",
      "The classification loss after processing this batch is:  2.1925179958343506\n",
      "The representation loss after processing this batch is:  0.011683404445648193\n",
      "\n",
      "The classification loss after processing this batch is:  2.1714744567871094\n",
      "The representation loss after processing this batch is:  0.013346999883651733\n",
      "\n",
      "The classification loss after processing this batch is:  2.150792360305786\n",
      "The representation loss after processing this batch is:  0.012257635593414307\n",
      "\n",
      "The classification loss after processing this batch is:  2.1462907791137695\n",
      "The representation loss after processing this batch is:  0.013146847486495972\n",
      "\n",
      "The classification loss after processing this batch is:  2.2209174633026123\n",
      "The representation loss after processing this batch is:  0.015685319900512695\n",
      "\n",
      "The classification loss after processing this batch is:  2.2129547595977783\n",
      "The representation loss after processing this batch is:  0.012531012296676636\n",
      "\n",
      "The classification loss after processing this batch is:  2.2247154712677\n",
      "The representation loss after processing this batch is:  0.01418420672416687\n",
      "\n",
      "The classification loss after processing this batch is:  2.180170774459839\n",
      "The representation loss after processing this batch is:  0.012119978666305542\n",
      "\n",
      "The classification loss after processing this batch is:  2.1783554553985596\n",
      "The representation loss after processing this batch is:  0.012630373239517212\n",
      "\n",
      "The classification loss after processing this batch is:  2.1971967220306396\n",
      "The representation loss after processing this batch is:  0.012725502252578735\n",
      "\n",
      "The classification loss after processing this batch is:  2.177398920059204\n",
      "The representation loss after processing this batch is:  0.013115286827087402\n",
      "\n",
      "The classification loss after processing this batch is:  2.141737222671509\n",
      "The representation loss after processing this batch is:  0.011797279119491577\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  2.117210626602173\n",
      "The representation loss after processing this batch is:  0.011369109153747559\n",
      "\n",
      "The classification loss after processing this batch is:  2.1304943561553955\n",
      "The representation loss after processing this batch is:  0.01316782832145691\n",
      "\n",
      "The classification loss after processing this batch is:  2.1801860332489014\n",
      "The representation loss after processing this batch is:  0.013217777013778687\n",
      "\n",
      "The classification loss after processing this batch is:  2.126214027404785\n",
      "The representation loss after processing this batch is:  0.01138317584991455\n",
      "\n",
      "The classification loss after processing this batch is:  2.117854118347168\n",
      "The representation loss after processing this batch is:  0.010838627815246582\n",
      "\n",
      "The classification loss after processing this batch is:  2.1322505474090576\n",
      "The representation loss after processing this batch is:  0.011089980602264404\n",
      "\n",
      "The classification loss after processing this batch is:  2.168306827545166\n",
      "The representation loss after processing this batch is:  0.011086910963058472\n",
      "\n",
      "The classification loss after processing this batch is:  2.1308929920196533\n",
      "The representation loss after processing this batch is:  0.010661959648132324\n",
      "\n",
      "The classification loss after processing this batch is:  2.097114324569702\n",
      "The representation loss after processing this batch is:  0.014945954084396362\n",
      "\n",
      "The classification loss after processing this batch is:  2.1211328506469727\n",
      "The representation loss after processing this batch is:  0.012278854846954346\n",
      "\n",
      "The classification loss after processing this batch is:  2.054096221923828\n",
      "The representation loss after processing this batch is:  0.01447838544845581\n",
      "\n",
      "The classification loss after processing this batch is:  2.139176845550537\n",
      "The representation loss after processing this batch is:  0.013882428407669067\n",
      "\n",
      "The classification loss after processing this batch is:  2.0773682594299316\n",
      "The representation loss after processing this batch is:  0.010523378849029541\n",
      "\n",
      "The classification loss after processing this batch is:  2.0955421924591064\n",
      "The representation loss after processing this batch is:  0.011891990900039673\n",
      "\n",
      "The classification loss after processing this batch is:  2.1094629764556885\n",
      "The representation loss after processing this batch is:  0.011193990707397461\n",
      "\n",
      "The classification loss after processing this batch is:  2.127089023590088\n",
      "The representation loss after processing this batch is:  0.011013418436050415\n",
      "\n",
      "The classification loss after processing this batch is:  2.086735486984253\n",
      "The representation loss after processing this batch is:  0.012532919645309448\n",
      "\n",
      "The classification loss after processing this batch is:  2.0982472896575928\n",
      "The representation loss after processing this batch is:  0.011646687984466553\n",
      "\n",
      "The classification loss after processing this batch is:  2.0818755626678467\n",
      "The representation loss after processing this batch is:  0.010157406330108643\n",
      "\n",
      "The classification loss after processing this batch is:  2.114736318588257\n",
      "The representation loss after processing this batch is:  0.011394530534744263\n",
      "\n",
      "The classification loss after processing this batch is:  2.044980525970459\n",
      "The representation loss after processing this batch is:  0.010834097862243652\n",
      "\n",
      "The classification loss after processing this batch is:  2.0767340660095215\n",
      "The representation loss after processing this batch is:  0.010604619979858398\n",
      "\n",
      "The classification loss after processing this batch is:  2.0584802627563477\n",
      "The representation loss after processing this batch is:  0.009687095880508423\n",
      "\n",
      "The classification loss after processing this batch is:  2.0417654514312744\n",
      "The representation loss after processing this batch is:  0.010201364755630493\n",
      "\n",
      "The classification loss after processing this batch is:  2.109834671020508\n",
      "The representation loss after processing this batch is:  0.012124419212341309\n",
      "\n",
      "The classification loss after processing this batch is:  2.05179500579834\n",
      "The representation loss after processing this batch is:  0.011743485927581787\n",
      "\n",
      "The classification loss after processing this batch is:  2.1001944541931152\n",
      "The representation loss after processing this batch is:  0.013574212789535522\n",
      "\n",
      "The classification loss after processing this batch is:  2.0434038639068604\n",
      "The representation loss after processing this batch is:  0.011490166187286377\n",
      "\n",
      "The classification loss after processing this batch is:  2.093482732772827\n",
      "The representation loss after processing this batch is:  0.009835898876190186\n",
      "\n",
      "The classification loss after processing this batch is:  2.0773062705993652\n",
      "The representation loss after processing this batch is:  0.00908467173576355\n",
      "\n",
      "The classification loss after processing this batch is:  2.038233995437622\n",
      "The representation loss after processing this batch is:  0.010022014379501343\n",
      "\n",
      "The classification loss after processing this batch is:  2.092168092727661\n",
      "The representation loss after processing this batch is:  0.009523779153823853\n",
      "\n",
      "The classification loss after processing this batch is:  2.106325149536133\n",
      "The representation loss after processing this batch is:  0.00961989164352417\n",
      "\n",
      "The classification loss after processing this batch is:  2.0812246799468994\n",
      "The representation loss after processing this batch is:  0.010116904973983765\n",
      "\n",
      "The classification loss after processing this batch is:  2.01761794090271\n",
      "The representation loss after processing this batch is:  0.00917130708694458\n",
      "\n",
      "The classification loss after processing this batch is:  2.037998676300049\n",
      "The representation loss after processing this batch is:  0.010762840509414673\n",
      "\n",
      "The classification loss after processing this batch is:  2.0951998233795166\n",
      "The representation loss after processing this batch is:  0.00882411003112793\n",
      "\n",
      "The classification loss after processing this batch is:  2.027930974960327\n",
      "The representation loss after processing this batch is:  0.009259283542633057\n",
      "\n",
      "The classification loss after processing this batch is:  2.0194101333618164\n",
      "The representation loss after processing this batch is:  0.009830489754676819\n",
      "\n",
      "The classification loss after processing this batch is:  1.9238860607147217\n",
      "The representation loss after processing this batch is:  0.010255694389343262\n",
      "\n",
      "The classification loss after processing this batch is:  1.9519418478012085\n",
      "The representation loss after processing this batch is:  0.01348423957824707\n",
      "\n",
      "The classification loss after processing this batch is:  2.0006964206695557\n",
      "The representation loss after processing this batch is:  0.01376083493232727\n",
      "\n",
      "The classification loss after processing this batch is:  2.0212011337280273\n",
      "The representation loss after processing this batch is:  0.011736899614334106\n",
      "\n",
      "The classification loss after processing this batch is:  2.015730857849121\n",
      "The representation loss after processing this batch is:  0.00941157341003418\n",
      "\n",
      "The classification loss after processing this batch is:  1.998574137687683\n",
      "The representation loss after processing this batch is:  0.009180709719657898\n",
      "\n",
      "The classification loss after processing this batch is:  1.911230206489563\n",
      "The representation loss after processing this batch is:  0.010462671518325806\n",
      "\n",
      "The classification loss after processing this batch is:  1.9766864776611328\n",
      "The representation loss after processing this batch is:  0.010766983032226562\n",
      "\n",
      "The classification loss after processing this batch is:  1.959086298942566\n",
      "The representation loss after processing this batch is:  0.009576991200447083\n",
      "\n",
      "The classification loss after processing this batch is:  1.9893900156021118\n",
      "The representation loss after processing this batch is:  0.010091215372085571\n",
      "\n",
      "The classification loss after processing this batch is:  2.0488574504852295\n",
      "The representation loss after processing this batch is:  0.01096808910369873\n",
      "\n",
      "The classification loss after processing this batch is:  2.0141098499298096\n",
      "The representation loss after processing this batch is:  0.010867208242416382\n",
      "\n",
      "The classification loss after processing this batch is:  1.924609661102295\n",
      "The representation loss after processing this batch is:  0.010183826088905334\n",
      "\n",
      "The classification loss after processing this batch is:  2.018993616104126\n",
      "The representation loss after processing this batch is:  0.009736508131027222\n",
      "\n",
      "The classification loss after processing this batch is:  1.9450360536575317\n",
      "The representation loss after processing this batch is:  0.010762989521026611\n",
      "\n",
      "The classification loss after processing this batch is:  1.9810513257980347\n",
      "The representation loss after processing this batch is:  0.011529535055160522\n",
      "\n",
      "The classification loss after processing this batch is:  1.8998548984527588\n",
      "The representation loss after processing this batch is:  0.011599242687225342\n",
      "\n",
      "The classification loss after processing this batch is:  2.0594770908355713\n",
      "The representation loss after processing this batch is:  0.008812859654426575\n",
      "\n",
      "The classification loss after processing this batch is:  2.0376524925231934\n",
      "The representation loss after processing this batch is:  0.008414208889007568\n",
      "\n",
      "The classification loss after processing this batch is:  2.0578978061676025\n",
      "The representation loss after processing this batch is:  0.008993029594421387\n",
      "\n",
      "The classification loss after processing this batch is:  1.95033597946167\n",
      "The representation loss after processing this batch is:  0.008704841136932373\n",
      "\n",
      "The classification loss after processing this batch is:  1.9563628435134888\n",
      "The representation loss after processing this batch is:  0.009182244539260864\n",
      "\n",
      "The classification loss after processing this batch is:  1.9454385042190552\n",
      "The representation loss after processing this batch is:  0.007779344916343689\n",
      "\n",
      "The classification loss after processing this batch is:  1.9248251914978027\n",
      "The representation loss after processing this batch is:  0.009431421756744385\n",
      "\n",
      "The classification loss after processing this batch is:  1.8949756622314453\n",
      "The representation loss after processing this batch is:  0.007629185914993286\n",
      "\n",
      "The classification loss after processing this batch is:  1.859881043434143\n",
      "The representation loss after processing this batch is:  0.010661408305168152\n",
      "\n",
      "The classification loss after processing this batch is:  2.0262348651885986\n",
      "The representation loss after processing this batch is:  0.01111990213394165\n",
      "\n",
      "The classification loss after processing this batch is:  1.9532687664031982\n",
      "The representation loss after processing this batch is:  0.008725926280021667\n",
      "\n",
      "The classification loss after processing this batch is:  1.9670182466506958\n",
      "The representation loss after processing this batch is:  0.00865107774734497\n",
      "\n",
      "The classification loss after processing this batch is:  1.9287761449813843\n",
      "The representation loss after processing this batch is:  0.008194133639335632\n",
      "\n",
      "The classification loss after processing this batch is:  2.062405586242676\n",
      "The representation loss after processing this batch is:  0.008463114500045776\n",
      "\n",
      "The classification loss after processing this batch is:  2.000857353210449\n",
      "The representation loss after processing this batch is:  0.008239984512329102\n",
      "\n",
      "The classification loss after processing this batch is:  1.926547884941101\n",
      "The representation loss after processing this batch is:  0.007446199655532837\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  1.9878733158111572\n",
      "The representation loss after processing this batch is:  0.007864400744438171\n",
      "\n",
      "The classification loss after processing this batch is:  1.9259285926818848\n",
      "The representation loss after processing this batch is:  0.007792085409164429\n",
      "\n",
      "The classification loss after processing this batch is:  1.9253575801849365\n",
      "The representation loss after processing this batch is:  0.0070341527462005615\n",
      "\n",
      "The classification loss after processing this batch is:  1.9822783470153809\n",
      "The representation loss after processing this batch is:  0.008275911211967468\n",
      "\n",
      "The classification loss after processing this batch is:  1.9796065092086792\n",
      "The representation loss after processing this batch is:  0.0076579749584198\n",
      "\n",
      "The classification loss after processing this batch is:  1.8200223445892334\n",
      "The representation loss after processing this batch is:  0.007386267185211182\n",
      "\n",
      "The classification loss after processing this batch is:  1.8119276762008667\n",
      "The representation loss after processing this batch is:  0.00906306505203247\n",
      "\n",
      "The classification loss after processing this batch is:  1.7510993480682373\n",
      "The representation loss after processing this batch is:  0.008947014808654785\n",
      "\n",
      "The classification loss after processing this batch is:  1.8748787641525269\n",
      "The representation loss after processing this batch is:  0.01102285087108612\n",
      "\n",
      "The classification loss after processing this batch is:  1.8948205709457397\n",
      "The representation loss after processing this batch is:  0.009986937046051025\n",
      "\n",
      "The classification loss after processing this batch is:  1.7339704036712646\n",
      "The representation loss after processing this batch is:  0.00952981412410736\n",
      "\n",
      "The classification loss after processing this batch is:  1.8836935758590698\n",
      "The representation loss after processing this batch is:  0.011159613728523254\n",
      "\n",
      "The classification loss after processing this batch is:  1.8913915157318115\n",
      "The representation loss after processing this batch is:  0.007352545857429504\n",
      "\n",
      "The classification loss after processing this batch is:  1.9142998456954956\n",
      "The representation loss after processing this batch is:  0.007851317524909973\n",
      "\n",
      "The classification loss after processing this batch is:  1.7764418125152588\n",
      "The representation loss after processing this batch is:  0.0084705650806427\n",
      "\n",
      "The classification loss after processing this batch is:  1.7902156114578247\n",
      "The representation loss after processing this batch is:  0.009380370378494263\n",
      "\n",
      "The classification loss after processing this batch is:  1.9043065309524536\n",
      "The representation loss after processing this batch is:  0.011388435959815979\n",
      "\n",
      "The classification loss after processing this batch is:  1.8909509181976318\n",
      "The representation loss after processing this batch is:  0.008853092789649963\n",
      "\n",
      "The classification loss after processing this batch is:  1.6500868797302246\n",
      "The representation loss after processing this batch is:  0.009264469146728516\n",
      "\n",
      "The classification loss after processing this batch is:  1.7737047672271729\n",
      "The representation loss after processing this batch is:  0.00651414692401886\n",
      "\n",
      "The classification loss after processing this batch is:  1.7851417064666748\n",
      "The representation loss after processing this batch is:  0.008366897702217102\n",
      "\n",
      "The classification loss after processing this batch is:  1.7754327058792114\n",
      "The representation loss after processing this batch is:  0.007628932595252991\n",
      "\n",
      "The classification loss after processing this batch is:  1.8418906927108765\n",
      "The representation loss after processing this batch is:  0.01077522337436676\n",
      "\n",
      "The classification loss after processing this batch is:  1.7332172393798828\n",
      "The representation loss after processing this batch is:  0.007062047719955444\n",
      "\n",
      "The classification loss after processing this batch is:  1.8391329050064087\n",
      "The representation loss after processing this batch is:  0.007670372724533081\n",
      "\n",
      "The classification loss after processing this batch is:  1.6344550848007202\n",
      "The representation loss after processing this batch is:  0.007949098944664001\n",
      "\n",
      "The classification loss after processing this batch is:  1.8348803520202637\n",
      "The representation loss after processing this batch is:  0.008080735802650452\n",
      "\n",
      "The classification loss after processing this batch is:  1.8483012914657593\n",
      "The representation loss after processing this batch is:  0.008026465773582458\n",
      "\n",
      "The classification loss after processing this batch is:  1.8403319120407104\n",
      "The representation loss after processing this batch is:  0.008052751421928406\n",
      "\n",
      "The classification loss after processing this batch is:  1.6594574451446533\n",
      "The representation loss after processing this batch is:  0.00617624819278717\n",
      "\n",
      "The classification loss after processing this batch is:  1.7562634944915771\n",
      "The representation loss after processing this batch is:  0.006698131561279297\n",
      "\n",
      "The classification loss after processing this batch is:  1.805435061454773\n",
      "The representation loss after processing this batch is:  0.00766204297542572\n",
      "\n",
      "The classification loss after processing this batch is:  1.8018028736114502\n",
      "The representation loss after processing this batch is:  0.0060402750968933105\n",
      "\n",
      "The classification loss after processing this batch is:  1.7245292663574219\n",
      "The representation loss after processing this batch is:  0.0076560378074646\n",
      "\n",
      "The classification loss after processing this batch is:  1.8017560243606567\n",
      "The representation loss after processing this batch is:  0.007857173681259155\n",
      "\n",
      "The classification loss after processing this batch is:  1.7319138050079346\n",
      "The representation loss after processing this batch is:  0.007945433259010315\n",
      "\n",
      "The classification loss after processing this batch is:  1.8473763465881348\n",
      "The representation loss after processing this batch is:  0.008168473839759827\n",
      "\n",
      "The classification loss after processing this batch is:  1.6637022495269775\n",
      "The representation loss after processing this batch is:  0.006951481103897095\n",
      "\n",
      "The classification loss after processing this batch is:  1.7752305269241333\n",
      "The representation loss after processing this batch is:  0.007137119770050049\n",
      "\n",
      "The classification loss after processing this batch is:  1.6846367120742798\n",
      "The representation loss after processing this batch is:  0.00739210844039917\n",
      "\n",
      "The classification loss after processing this batch is:  1.6923964023590088\n",
      "The representation loss after processing this batch is:  0.005781516432762146\n",
      "\n",
      "The classification loss after processing this batch is:  1.688447117805481\n",
      "The representation loss after processing this batch is:  0.007183894515037537\n",
      "\n",
      "The classification loss after processing this batch is:  1.6907511949539185\n",
      "The representation loss after processing this batch is:  0.006987348198890686\n",
      "\n",
      "The classification loss after processing this batch is:  1.785030484199524\n",
      "The representation loss after processing this batch is:  0.007747098803520203\n",
      "\n",
      "The classification loss after processing this batch is:  1.6807390451431274\n",
      "The representation loss after processing this batch is:  0.006910651922225952\n",
      "\n",
      "The classification loss after processing this batch is:  1.624181866645813\n",
      "The representation loss after processing this batch is:  0.007049694657325745\n",
      "\n",
      "The classification loss after processing this batch is:  1.826172947883606\n",
      "The representation loss after processing this batch is:  0.00692439079284668\n",
      "\n",
      "The classification loss after processing this batch is:  1.6302069425582886\n",
      "The representation loss after processing this batch is:  0.007296115159988403\n",
      "\n",
      "The classification loss after processing this batch is:  1.6675862073898315\n",
      "The representation loss after processing this batch is:  0.006580576300621033\n",
      "\n",
      "The classification loss after processing this batch is:  1.7075484991073608\n",
      "The representation loss after processing this batch is:  0.006413713097572327\n",
      "\n",
      "The classification loss after processing this batch is:  1.7971572875976562\n",
      "The representation loss after processing this batch is:  0.006165668368339539\n",
      "\n",
      "The classification loss after processing this batch is:  1.8053733110427856\n",
      "The representation loss after processing this batch is:  0.006263986229896545\n",
      "\n",
      "The classification loss after processing this batch is:  1.7341996431350708\n",
      "The representation loss after processing this batch is:  0.006379485130310059\n",
      "\n",
      "The classification loss after processing this batch is:  1.6641242504119873\n",
      "The representation loss after processing this batch is:  0.007094904780387878\n",
      "\n",
      "The classification loss after processing this batch is:  1.6457120180130005\n",
      "The representation loss after processing this batch is:  0.007037118077278137\n",
      "\n",
      "The classification loss after processing this batch is:  1.6771190166473389\n",
      "The representation loss after processing this batch is:  0.007610604166984558\n",
      "\n",
      "The classification loss after processing this batch is:  1.7453292608261108\n",
      "The representation loss after processing this batch is:  0.006864309310913086\n",
      "\n",
      "The classification loss after processing this batch is:  1.6943416595458984\n",
      "The representation loss after processing this batch is:  0.006355755031108856\n",
      "\n",
      "The classification loss after processing this batch is:  1.7463175058364868\n",
      "The representation loss after processing this batch is:  0.0072328150272369385\n",
      "\n",
      "The classification loss after processing this batch is:  1.6116771697998047\n",
      "The representation loss after processing this batch is:  0.0061900317668914795\n",
      "\n",
      "The classification loss after processing this batch is:  1.6984916925430298\n",
      "The representation loss after processing this batch is:  0.006398215889930725\n",
      "\n",
      "The classification loss after processing this batch is:  1.7065393924713135\n",
      "The representation loss after processing this batch is:  0.005669757723808289\n",
      "\n",
      "The classification loss after processing this batch is:  1.7607852220535278\n",
      "The representation loss after processing this batch is:  0.007126718759536743\n",
      "\n",
      "The classification loss after processing this batch is:  1.666717767715454\n",
      "The representation loss after processing this batch is:  0.005786500871181488\n",
      "\n",
      "The classification loss after processing this batch is:  1.7047079801559448\n",
      "The representation loss after processing this batch is:  0.0073975324630737305\n",
      "\n",
      "The classification loss after processing this batch is:  1.6989878416061401\n",
      "The representation loss after processing this batch is:  0.006464309990406036\n",
      "\n",
      "The classification loss after processing this batch is:  1.6142922639846802\n",
      "The representation loss after processing this batch is:  0.0065360963344573975\n",
      "\n",
      "The classification loss after processing this batch is:  1.6372665166854858\n",
      "The representation loss after processing this batch is:  0.006366394460201263\n",
      "\n",
      "The classification loss after processing this batch is:  1.5939165353775024\n",
      "The representation loss after processing this batch is:  0.006555177271366119\n",
      "\n",
      "The classification loss after processing this batch is:  1.485707402229309\n",
      "The representation loss after processing this batch is:  0.007378377020359039\n",
      "\n",
      "The classification loss after processing this batch is:  1.525992751121521\n",
      "The representation loss after processing this batch is:  0.008456014096736908\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  1.4778211116790771\n",
      "The representation loss after processing this batch is:  0.007263533771038055\n",
      "\n",
      "The classification loss after processing this batch is:  1.8031286001205444\n",
      "The representation loss after processing this batch is:  0.006485268473625183\n",
      "\n",
      "The classification loss after processing this batch is:  1.6711746454238892\n",
      "The representation loss after processing this batch is:  0.0070176273584365845\n",
      "\n",
      "The classification loss after processing this batch is:  1.7177609205245972\n",
      "The representation loss after processing this batch is:  0.006086036562919617\n",
      "\n",
      "The classification loss after processing this batch is:  1.7124649286270142\n",
      "The representation loss after processing this batch is:  0.005749933421611786\n",
      "\n",
      "The classification loss after processing this batch is:  1.6732443571090698\n",
      "The representation loss after processing this batch is:  0.006818369030952454\n",
      "\n",
      "The classification loss after processing this batch is:  1.6216436624526978\n",
      "The representation loss after processing this batch is:  0.005862079560756683\n",
      "\n",
      "The classification loss after processing this batch is:  1.5122599601745605\n",
      "The representation loss after processing this batch is:  0.006653092801570892\n",
      "\n",
      "The classification loss after processing this batch is:  1.7107186317443848\n",
      "The representation loss after processing this batch is:  0.005762211978435516\n",
      "\n",
      "The classification loss after processing this batch is:  1.5059179067611694\n",
      "The representation loss after processing this batch is:  0.007165536284446716\n",
      "\n",
      "The classification loss after processing this batch is:  1.394079327583313\n",
      "The representation loss after processing this batch is:  0.005208410322666168\n",
      "\n",
      "The classification loss after processing this batch is:  1.4326204061508179\n",
      "The representation loss after processing this batch is:  0.00596589595079422\n",
      "\n",
      "The classification loss after processing this batch is:  1.4493985176086426\n",
      "The representation loss after processing this batch is:  0.006981372833251953\n",
      "\n",
      "The classification loss after processing this batch is:  1.5837491750717163\n",
      "The representation loss after processing this batch is:  0.007022082805633545\n",
      "\n",
      "The classification loss after processing this batch is:  1.508897066116333\n",
      "The representation loss after processing this batch is:  0.007004164159297943\n",
      "\n",
      "The classification loss after processing this batch is:  1.4855437278747559\n",
      "The representation loss after processing this batch is:  0.006723351776599884\n",
      "\n",
      "The classification loss after processing this batch is:  1.4599108695983887\n",
      "The representation loss after processing this batch is:  0.006040990352630615\n",
      "\n",
      "The classification loss after processing this batch is:  1.4850192070007324\n",
      "The representation loss after processing this batch is:  0.006387926638126373\n",
      "\n",
      "The classification loss after processing this batch is:  1.5630816221237183\n",
      "The representation loss after processing this batch is:  0.006152510643005371\n",
      "\n",
      "The classification loss after processing this batch is:  1.5495890378952026\n",
      "The representation loss after processing this batch is:  0.005672641098499298\n",
      "\n",
      "The classification loss after processing this batch is:  1.4865105152130127\n",
      "The representation loss after processing this batch is:  0.005993783473968506\n",
      "\n",
      "The classification loss after processing this batch is:  1.4727935791015625\n",
      "The representation loss after processing this batch is:  0.005834117531776428\n",
      "\n",
      "The classification loss after processing this batch is:  1.5287549495697021\n",
      "The representation loss after processing this batch is:  0.006174050271511078\n",
      "\n",
      "The classification loss after processing this batch is:  1.4762083292007446\n",
      "The representation loss after processing this batch is:  0.005894675850868225\n",
      "\n",
      "The classification loss after processing this batch is:  1.6060961484909058\n",
      "The representation loss after processing this batch is:  0.006186790764331818\n",
      "\n",
      "The classification loss after processing this batch is:  1.6902844905853271\n",
      "The representation loss after processing this batch is:  0.006690651178359985\n",
      "\n",
      "The classification loss after processing this batch is:  1.4027043581008911\n",
      "The representation loss after processing this batch is:  0.005853906273841858\n",
      "\n",
      "The classification loss after processing this batch is:  1.4197567701339722\n",
      "The representation loss after processing this batch is:  0.006454072892665863\n",
      "\n",
      "The classification loss after processing this batch is:  1.4950851202011108\n",
      "The representation loss after processing this batch is:  0.007233560085296631\n",
      "\n",
      "The classification loss after processing this batch is:  1.5052344799041748\n",
      "The representation loss after processing this batch is:  0.0076368749141693115\n",
      "\n",
      "The classification loss after processing this batch is:  1.5166957378387451\n",
      "The representation loss after processing this batch is:  0.007688701152801514\n",
      "\n",
      "The classification loss after processing this batch is:  1.4603396654129028\n",
      "The representation loss after processing this batch is:  0.0074120089411735535\n",
      "\n",
      "The classification loss after processing this batch is:  1.4240195751190186\n",
      "The representation loss after processing this batch is:  0.007110923528671265\n",
      "\n",
      "The classification loss after processing this batch is:  1.4475243091583252\n",
      "The representation loss after processing this batch is:  0.0061478763818740845\n",
      "\n",
      "The classification loss after processing this batch is:  1.3817800283432007\n",
      "The representation loss after processing this batch is:  0.005505502223968506\n",
      "\n",
      "The classification loss after processing this batch is:  1.3939350843429565\n",
      "The representation loss after processing this batch is:  0.006581813097000122\n",
      "\n",
      "The classification loss after processing this batch is:  1.3278096914291382\n",
      "The representation loss after processing this batch is:  0.006779566407203674\n",
      "\n",
      "The classification loss after processing this batch is:  1.4119460582733154\n",
      "The representation loss after processing this batch is:  0.005857400596141815\n",
      "\n",
      "The classification loss after processing this batch is:  1.269856333732605\n",
      "The representation loss after processing this batch is:  0.005893334746360779\n",
      "\n",
      "The classification loss after processing this batch is:  1.2857245206832886\n",
      "The representation loss after processing this batch is:  0.0059729814529418945\n",
      "\n",
      "The classification loss after processing this batch is:  1.2977854013442993\n",
      "The representation loss after processing this batch is:  0.006911583244800568\n",
      "\n",
      "The classification loss after processing this batch is:  1.2564421892166138\n",
      "The representation loss after processing this batch is:  0.008039258420467377\n",
      "\n",
      "The classification loss after processing this batch is:  1.3905794620513916\n",
      "The representation loss after processing this batch is:  0.005840860307216644\n",
      "\n",
      "The classification loss after processing this batch is:  1.2133629322052002\n",
      "The representation loss after processing this batch is:  0.005521096289157867\n",
      "\n",
      "The classification loss after processing this batch is:  1.3270374536514282\n",
      "The representation loss after processing this batch is:  0.006200432777404785\n",
      "\n",
      "The classification loss after processing this batch is:  1.2376692295074463\n",
      "The representation loss after processing this batch is:  0.005083687603473663\n",
      "\n",
      "The classification loss after processing this batch is:  1.2813361883163452\n",
      "The representation loss after processing this batch is:  0.005540147423744202\n",
      "\n",
      "The classification loss after processing this batch is:  1.38532555103302\n",
      "The representation loss after processing this batch is:  0.005205601453781128\n",
      "\n",
      "The classification loss after processing this batch is:  1.6456482410430908\n",
      "The representation loss after processing this batch is:  0.0058462172746658325\n",
      "\n",
      "The classification loss after processing this batch is:  1.363376498222351\n",
      "The representation loss after processing this batch is:  0.006423242390155792\n",
      "\n",
      "The classification loss after processing this batch is:  1.4208446741104126\n",
      "The representation loss after processing this batch is:  0.005487501621246338\n",
      "\n",
      "The classification loss after processing this batch is:  1.316137671470642\n",
      "The representation loss after processing this batch is:  0.0055281370878219604\n",
      "\n",
      "The classification loss after processing this batch is:  1.3259235620498657\n",
      "The representation loss after processing this batch is:  0.005450807511806488\n",
      "\n",
      "The classification loss after processing this batch is:  1.6399494409561157\n",
      "The representation loss after processing this batch is:  0.005539000034332275\n",
      "\n",
      "The classification loss after processing this batch is:  1.3424479961395264\n",
      "The representation loss after processing this batch is:  0.005970552563667297\n",
      "\n",
      "The classification loss after processing this batch is:  1.4169776439666748\n",
      "The representation loss after processing this batch is:  0.005886003375053406\n",
      "\n",
      "The classification loss after processing this batch is:  1.2830523252487183\n",
      "The representation loss after processing this batch is:  0.0051072388887405396\n",
      "\n",
      "The classification loss after processing this batch is:  1.2195936441421509\n",
      "The representation loss after processing this batch is:  0.006592564284801483\n",
      "\n",
      "The classification loss after processing this batch is:  1.2351276874542236\n",
      "The representation loss after processing this batch is:  0.006742507219314575\n",
      "\n",
      "The classification loss after processing this batch is:  1.1910197734832764\n",
      "The representation loss after processing this batch is:  0.006432369351387024\n",
      "\n",
      "The classification loss after processing this batch is:  1.202211618423462\n",
      "The representation loss after processing this batch is:  0.006311558187007904\n",
      "\n",
      "The classification loss after processing this batch is:  1.099639892578125\n",
      "The representation loss after processing this batch is:  0.0054672881960868835\n",
      "\n",
      "The classification loss after processing this batch is:  1.14326810836792\n",
      "The representation loss after processing this batch is:  0.00610930472612381\n",
      "\n",
      "The classification loss after processing this batch is:  1.2644708156585693\n",
      "The representation loss after processing this batch is:  0.006230868399143219\n",
      "\n",
      "The classification loss after processing this batch is:  1.1835557222366333\n",
      "The representation loss after processing this batch is:  0.0058773234486579895\n",
      "\n",
      "The classification loss after processing this batch is:  1.381988286972046\n",
      "The representation loss after processing this batch is:  0.0066527798771858215\n",
      "\n",
      "The classification loss after processing this batch is:  1.432396650314331\n",
      "The representation loss after processing this batch is:  0.006869286298751831\n",
      "\n",
      "The classification loss after processing this batch is:  1.262020230293274\n",
      "The representation loss after processing this batch is:  0.006013400852680206\n",
      "\n",
      "The classification loss after processing this batch is:  1.3059033155441284\n",
      "The representation loss after processing this batch is:  0.006662294268608093\n",
      "\n",
      "The classification loss after processing this batch is:  1.2503904104232788\n",
      "The representation loss after processing this batch is:  0.006546497344970703\n",
      "\n",
      "The classification loss after processing this batch is:  1.2740439176559448\n",
      "The representation loss after processing this batch is:  0.006704643368721008\n",
      "\n",
      "The classification loss after processing this batch is:  1.2247365713119507\n",
      "The representation loss after processing this batch is:  0.005177758634090424\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  1.3739407062530518\n",
      "The representation loss after processing this batch is:  0.006046086549758911\n",
      "\n",
      "The classification loss after processing this batch is:  1.2111951112747192\n",
      "The representation loss after processing this batch is:  0.004762977361679077\n",
      "\n",
      "The classification loss after processing this batch is:  1.1905438899993896\n",
      "The representation loss after processing this batch is:  0.005802221596240997\n",
      "\n",
      "The classification loss after processing this batch is:  1.1955208778381348\n",
      "The representation loss after processing this batch is:  0.005600534379482269\n",
      "\n",
      "The classification loss after processing this batch is:  1.129170536994934\n",
      "The representation loss after processing this batch is:  0.005655229091644287\n",
      "\n",
      "The classification loss after processing this batch is:  1.2585207223892212\n",
      "The representation loss after processing this batch is:  0.006140612065792084\n",
      "\n",
      "The classification loss after processing this batch is:  1.3655916452407837\n",
      "The representation loss after processing this batch is:  0.007214181125164032\n",
      "\n",
      "The classification loss after processing this batch is:  1.114402413368225\n",
      "The representation loss after processing this batch is:  0.006036713719367981\n",
      "\n",
      "The classification loss after processing this batch is:  1.2568519115447998\n",
      "The representation loss after processing this batch is:  0.006635092198848724\n",
      "\n",
      "The classification loss after processing this batch is:  1.212504506111145\n",
      "The representation loss after processing this batch is:  0.006189227104187012\n",
      "\n",
      "The classification loss after processing this batch is:  1.2130827903747559\n",
      "The representation loss after processing this batch is:  0.006436541676521301\n",
      "\n",
      "The classification loss after processing this batch is:  1.15766179561615\n",
      "The representation loss after processing this batch is:  0.007681220769882202\n",
      "\n",
      "The classification loss after processing this batch is:  1.101399540901184\n",
      "The representation loss after processing this batch is:  0.006495557725429535\n",
      "\n",
      "The classification loss after processing this batch is:  1.1389228105545044\n",
      "The representation loss after processing this batch is:  0.005394883453845978\n",
      "\n",
      "The classification loss after processing this batch is:  1.2095580101013184\n",
      "The representation loss after processing this batch is:  0.005562633275985718\n",
      "\n",
      "The classification loss after processing this batch is:  1.0886400938034058\n",
      "The representation loss after processing this batch is:  0.006040453910827637\n",
      "\n",
      "The classification loss after processing this batch is:  1.0098702907562256\n",
      "The representation loss after processing this batch is:  0.006111957132816315\n",
      "\n",
      "The classification loss after processing this batch is:  1.0122822523117065\n",
      "The representation loss after processing this batch is:  0.005572564899921417\n",
      "\n",
      "The classification loss after processing this batch is:  1.0432839393615723\n",
      "The representation loss after processing this batch is:  0.005562238395214081\n",
      "\n",
      "The classification loss after processing this batch is:  1.0741323232650757\n",
      "The representation loss after processing this batch is:  0.006574109196662903\n",
      "\n",
      "The classification loss after processing this batch is:  1.2455623149871826\n",
      "The representation loss after processing this batch is:  0.005906939506530762\n",
      "\n",
      "The classification loss after processing this batch is:  1.241219401359558\n",
      "The representation loss after processing this batch is:  0.006338819861412048\n",
      "\n",
      "The classification loss after processing this batch is:  1.2275903224945068\n",
      "The representation loss after processing this batch is:  0.005424201488494873\n",
      "\n",
      "The classification loss after processing this batch is:  0.9780064821243286\n",
      "The representation loss after processing this batch is:  0.006308436393737793\n",
      "\n",
      "The classification loss after processing this batch is:  1.159056305885315\n",
      "The representation loss after processing this batch is:  0.006391800940036774\n",
      "\n",
      "The classification loss after processing this batch is:  1.099732518196106\n",
      "The representation loss after processing this batch is:  0.006160445511341095\n",
      "\n",
      "The classification loss after processing this batch is:  1.0992767810821533\n",
      "The representation loss after processing this batch is:  0.0065652430057525635\n",
      "\n",
      "The classification loss after processing this batch is:  1.1041969060897827\n",
      "The representation loss after processing this batch is:  0.005780935287475586\n",
      "\n",
      "The classification loss after processing this batch is:  0.991873562335968\n",
      "The representation loss after processing this batch is:  0.005317419767379761\n",
      "\n",
      "The classification loss after processing this batch is:  1.030758261680603\n",
      "The representation loss after processing this batch is:  0.006162047386169434\n",
      "\n",
      "The classification loss after processing this batch is:  1.0516517162322998\n",
      "The representation loss after processing this batch is:  0.0056062862277030945\n",
      "\n",
      "The classification loss after processing this batch is:  1.2041351795196533\n",
      "The representation loss after processing this batch is:  0.005870431661605835\n",
      "\n",
      "The classification loss after processing this batch is:  1.1711430549621582\n",
      "The representation loss after processing this batch is:  0.006280355155467987\n",
      "\n",
      "The classification loss after processing this batch is:  1.1750423908233643\n",
      "The representation loss after processing this batch is:  0.0053807832300662994\n",
      "\n",
      "The classification loss after processing this batch is:  1.169063687324524\n",
      "The representation loss after processing this batch is:  0.005925402045249939\n",
      "\n",
      "The classification loss after processing this batch is:  1.0564168691635132\n",
      "The representation loss after processing this batch is:  0.005055949091911316\n",
      "\n",
      "The classification loss after processing this batch is:  1.0868083238601685\n",
      "The representation loss after processing this batch is:  0.005304545164108276\n",
      "\n",
      "The classification loss after processing this batch is:  0.9566939473152161\n",
      "The representation loss after processing this batch is:  0.004827022552490234\n",
      "\n",
      "The classification loss after processing this batch is:  1.0347113609313965\n",
      "The representation loss after processing this batch is:  0.00487557053565979\n",
      "\n",
      "The classification loss after processing this batch is:  1.0805350542068481\n",
      "The representation loss after processing this batch is:  0.005325585603713989\n",
      "\n",
      "The classification loss after processing this batch is:  1.143980860710144\n",
      "The representation loss after processing this batch is:  0.00596967339515686\n",
      "\n",
      "The classification loss after processing this batch is:  0.9043446183204651\n",
      "The representation loss after processing this batch is:  0.005556456744670868\n",
      "\n",
      "The classification loss after processing this batch is:  0.9295739531517029\n",
      "The representation loss after processing this batch is:  0.005774397403001785\n",
      "\n",
      "The classification loss after processing this batch is:  0.8768576383590698\n",
      "The representation loss after processing this batch is:  0.0047968849539756775\n",
      "\n",
      "The classification loss after processing this batch is:  0.9758985042572021\n",
      "The representation loss after processing this batch is:  0.005200840532779694\n",
      "\n",
      "The classification loss after processing this batch is:  1.0109813213348389\n",
      "The representation loss after processing this batch is:  0.005478348582983017\n",
      "\n",
      "The classification loss after processing this batch is:  1.0099070072174072\n",
      "The representation loss after processing this batch is:  0.006985098123550415\n",
      "\n",
      "The classification loss after processing this batch is:  1.1607874631881714\n",
      "The representation loss after processing this batch is:  0.006589151918888092\n",
      "\n",
      "The classification loss after processing this batch is:  1.045383095741272\n",
      "The representation loss after processing this batch is:  0.006104305386543274\n",
      "\n",
      "The classification loss after processing this batch is:  1.0493841171264648\n",
      "The representation loss after processing this batch is:  0.005286388099193573\n",
      "\n",
      "The classification loss after processing this batch is:  1.2557015419006348\n",
      "The representation loss after processing this batch is:  0.0055865272879600525\n",
      "\n",
      "The classification loss after processing this batch is:  0.9844341278076172\n",
      "The representation loss after processing this batch is:  0.0044373683631420135\n",
      "\n",
      "The classification loss after processing this batch is:  1.0705437660217285\n",
      "The representation loss after processing this batch is:  0.005426064133644104\n",
      "\n",
      "The classification loss after processing this batch is:  0.9221117496490479\n",
      "The representation loss after processing this batch is:  0.0061759352684021\n",
      "\n",
      "The classification loss after processing this batch is:  0.9156327843666077\n",
      "The representation loss after processing this batch is:  0.00499502569437027\n",
      "\n",
      "The classification loss after processing this batch is:  0.9240034222602844\n",
      "The representation loss after processing this batch is:  0.005318529903888702\n",
      "\n",
      "The classification loss after processing this batch is:  1.0760884284973145\n",
      "The representation loss after processing this batch is:  0.00625263899564743\n",
      "\n",
      "The classification loss after processing this batch is:  0.897303581237793\n",
      "The representation loss after processing this batch is:  0.0049934834241867065\n",
      "\n",
      "The classification loss after processing this batch is:  0.894000768661499\n",
      "The representation loss after processing this batch is:  0.005628757178783417\n",
      "\n",
      "The classification loss after processing this batch is:  1.0517364740371704\n",
      "The representation loss after processing this batch is:  0.0051635317504405975\n",
      "\n",
      "The classification loss after processing this batch is:  0.9560754299163818\n",
      "The representation loss after processing this batch is:  0.006631128489971161\n",
      "\n",
      "The classification loss after processing this batch is:  1.0747647285461426\n",
      "The representation loss after processing this batch is:  0.005428235977888107\n",
      "\n",
      "The classification loss after processing this batch is:  1.0406475067138672\n",
      "The representation loss after processing this batch is:  0.005801118910312653\n",
      "\n",
      "The classification loss after processing this batch is:  1.1464142799377441\n",
      "The representation loss after processing this batch is:  0.005242697894573212\n",
      "\n",
      "The classification loss after processing this batch is:  0.9902212023735046\n",
      "The representation loss after processing this batch is:  0.005823813378810883\n",
      "\n",
      "The classification loss after processing this batch is:  0.7815386056900024\n",
      "The representation loss after processing this batch is:  0.005661770701408386\n",
      "\n",
      "The classification loss after processing this batch is:  0.8358870148658752\n",
      "The representation loss after processing this batch is:  0.005084589123725891\n",
      "\n",
      "The classification loss after processing this batch is:  0.8383066058158875\n",
      "The representation loss after processing this batch is:  0.005992282181978226\n",
      "\n",
      "The classification loss after processing this batch is:  0.8025272488594055\n",
      "The representation loss after processing this batch is:  0.005899697542190552\n",
      "\n",
      "The classification loss after processing this batch is:  0.9588967561721802\n",
      "The representation loss after processing this batch is:  0.006012760102748871\n",
      "\n",
      "The classification loss after processing this batch is:  0.9838938117027283\n",
      "The representation loss after processing this batch is:  0.005747877061367035\n",
      "\n",
      "The classification loss after processing this batch is:  0.9656491875648499\n",
      "The representation loss after processing this batch is:  0.005221091210842133\n",
      "\n",
      "The classification loss after processing this batch is:  0.888639509677887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.005485787987709045\n",
      "\n",
      "The classification loss after processing this batch is:  0.9476682543754578\n",
      "The representation loss after processing this batch is:  0.00612892210483551\n",
      "\n",
      "The classification loss after processing this batch is:  0.8281425833702087\n",
      "The representation loss after processing this batch is:  0.005917340517044067\n",
      "\n",
      "The classification loss after processing this batch is:  0.9434033632278442\n",
      "The representation loss after processing this batch is:  0.005988799035549164\n",
      "\n",
      "The classification loss after processing this batch is:  0.8612644672393799\n",
      "The representation loss after processing this batch is:  0.004856124520301819\n",
      "\n",
      "The classification loss after processing this batch is:  0.7991098165512085\n",
      "The representation loss after processing this batch is:  0.006291583180427551\n",
      "\n",
      "The classification loss after processing this batch is:  0.8912028074264526\n",
      "The representation loss after processing this batch is:  0.007170833647251129\n",
      "\n",
      "The classification loss after processing this batch is:  0.7635177969932556\n",
      "The representation loss after processing this batch is:  0.0055105239152908325\n",
      "\n",
      "The classification loss after processing this batch is:  0.8422532677650452\n",
      "The representation loss after processing this batch is:  0.005874723196029663\n",
      "\n",
      "The classification loss after processing this batch is:  0.8668593764305115\n",
      "The representation loss after processing this batch is:  0.0065142251551151276\n",
      "\n",
      "The classification loss after processing this batch is:  1.0190224647521973\n",
      "The representation loss after processing this batch is:  0.00694042444229126\n",
      "\n",
      "The classification loss after processing this batch is:  0.9322389364242554\n",
      "The representation loss after processing this batch is:  0.00654718279838562\n",
      "\n",
      "The classification loss after processing this batch is:  1.0063700675964355\n",
      "The representation loss after processing this batch is:  0.005949497222900391\n",
      "\n",
      "The classification loss after processing this batch is:  1.0878335237503052\n",
      "The representation loss after processing this batch is:  0.005751684308052063\n",
      "\n",
      "The classification loss after processing this batch is:  0.7898528575897217\n",
      "The representation loss after processing this batch is:  0.006168991327285767\n",
      "\n",
      "The classification loss after processing this batch is:  0.919188380241394\n",
      "The representation loss after processing this batch is:  0.005273826420307159\n",
      "\n",
      "The classification loss after processing this batch is:  1.119300365447998\n",
      "The representation loss after processing this batch is:  0.00555044412612915\n",
      "\n",
      "The classification loss after processing this batch is:  1.1078048944473267\n",
      "The representation loss after processing this batch is:  0.005812250077724457\n",
      "\n",
      "The classification loss after processing this batch is:  1.1736295223236084\n",
      "The representation loss after processing this batch is:  0.005052536725997925\n",
      "\n",
      "The classification loss after processing this batch is:  1.093882441520691\n",
      "The representation loss after processing this batch is:  0.004841417074203491\n",
      "\n",
      "The classification loss after processing this batch is:  0.9155025482177734\n",
      "The representation loss after processing this batch is:  0.004777699708938599\n",
      "\n",
      "The classification loss after processing this batch is:  0.9399731159210205\n",
      "The representation loss after processing this batch is:  0.004612930119037628\n",
      "\n",
      "The classification loss after processing this batch is:  0.9190492033958435\n",
      "The representation loss after processing this batch is:  0.0044872090220451355\n",
      "\n",
      "The classification loss after processing this batch is:  0.8712078928947449\n",
      "The representation loss after processing this batch is:  0.004721790552139282\n",
      "\n",
      "The classification loss after processing this batch is:  0.8245447874069214\n",
      "The representation loss after processing this batch is:  0.00498536229133606\n",
      "\n",
      "The classification loss after processing this batch is:  0.8983140587806702\n",
      "The representation loss after processing this batch is:  0.005157940089702606\n",
      "\n",
      "The classification loss after processing this batch is:  0.9835681915283203\n",
      "The representation loss after processing this batch is:  0.005397234112024307\n",
      "\n",
      "The classification loss after processing this batch is:  0.8602693676948547\n",
      "The representation loss after processing this batch is:  0.0050217583775520325\n",
      "\n",
      "The classification loss after processing this batch is:  0.8862663507461548\n",
      "The representation loss after processing this batch is:  0.005350738763809204\n",
      "\n",
      "The classification loss after processing this batch is:  0.8233129382133484\n",
      "The representation loss after processing this batch is:  0.005727693438529968\n",
      "\n",
      "The classification loss after processing this batch is:  0.8406206369400024\n",
      "The representation loss after processing this batch is:  0.005464266985654831\n",
      "\n",
      "The classification loss after processing this batch is:  0.7763038277626038\n",
      "The representation loss after processing this batch is:  0.006035514175891876\n",
      "\n",
      "The classification loss after processing this batch is:  0.8888716101646423\n",
      "The representation loss after processing this batch is:  0.00605861097574234\n",
      "\n",
      "The classification loss after processing this batch is:  0.737626850605011\n",
      "The representation loss after processing this batch is:  0.006416574120521545\n",
      "\n",
      "The classification loss after processing this batch is:  0.81219482421875\n",
      "The representation loss after processing this batch is:  0.006008245050907135\n",
      "\n",
      "The classification loss after processing this batch is:  0.8554375767707825\n",
      "The representation loss after processing this batch is:  0.005911208689212799\n",
      "\n",
      "The classification loss after processing this batch is:  0.9083781838417053\n",
      "The representation loss after processing this batch is:  0.005708090960979462\n",
      "\n",
      "The classification loss after processing this batch is:  0.8957892060279846\n",
      "The representation loss after processing this batch is:  0.005731865763664246\n",
      "\n",
      "The classification loss after processing this batch is:  0.8523008227348328\n",
      "The representation loss after processing this batch is:  0.005274120718240738\n",
      "\n",
      "The classification loss after processing this batch is:  0.8094392418861389\n",
      "The representation loss after processing this batch is:  0.005455587059259415\n",
      "\n",
      "The classification loss after processing this batch is:  0.7416315078735352\n",
      "The representation loss after processing this batch is:  0.005092766135931015\n",
      "\n",
      "The classification loss after processing this batch is:  0.8077627420425415\n",
      "The representation loss after processing this batch is:  0.00574842095375061\n",
      "\n",
      "The classification loss after processing this batch is:  0.854320228099823\n",
      "The representation loss after processing this batch is:  0.005296926945447922\n",
      "\n",
      "The classification loss after processing this batch is:  0.8573876619338989\n",
      "The representation loss after processing this batch is:  0.005739361047744751\n",
      "\n",
      "The classification loss after processing this batch is:  0.6770754456520081\n",
      "The representation loss after processing this batch is:  0.005591891705989838\n",
      "\n",
      "The classification loss after processing this batch is:  0.904293954372406\n",
      "The representation loss after processing this batch is:  0.005193550139665604\n",
      "\n",
      "The classification loss after processing this batch is:  0.9797406792640686\n",
      "The representation loss after processing this batch is:  0.005099274218082428\n",
      "\n",
      "The classification loss after processing this batch is:  0.7914904952049255\n",
      "The representation loss after processing this batch is:  0.0053766146302223206\n",
      "\n",
      "The classification loss after processing this batch is:  0.9136537313461304\n",
      "The representation loss after processing this batch is:  0.005083613097667694\n",
      "\n",
      "The classification loss after processing this batch is:  0.863427996635437\n",
      "The representation loss after processing this batch is:  0.005164444446563721\n",
      "\n",
      "The classification loss after processing this batch is:  0.8953276872634888\n",
      "The representation loss after processing this batch is:  0.005220372229814529\n",
      "\n",
      "The classification loss after processing this batch is:  0.7788150310516357\n",
      "The representation loss after processing this batch is:  0.004935789853334427\n",
      "\n",
      "The classification loss after processing this batch is:  0.8639166355133057\n",
      "The representation loss after processing this batch is:  0.00477730855345726\n",
      "\n",
      "The classification loss after processing this batch is:  0.8440290689468384\n",
      "The representation loss after processing this batch is:  0.00497199222445488\n",
      "\n",
      "The classification loss after processing this batch is:  0.9607541561126709\n",
      "The representation loss after processing this batch is:  0.006153080612421036\n",
      "\n",
      "The classification loss after processing this batch is:  0.7745205163955688\n",
      "The representation loss after processing this batch is:  0.00581447035074234\n",
      "\n",
      "The classification loss after processing this batch is:  0.8653997778892517\n",
      "The representation loss after processing this batch is:  0.005927704274654388\n",
      "\n",
      "The classification loss after processing this batch is:  0.823346734046936\n",
      "The representation loss after processing this batch is:  0.0068160369992256165\n",
      "\n",
      "The classification loss after processing this batch is:  0.7998484969139099\n",
      "The representation loss after processing this batch is:  0.0051848553121089935\n",
      "\n",
      "The classification loss after processing this batch is:  0.687801718711853\n",
      "The representation loss after processing this batch is:  0.004873231053352356\n",
      "\n",
      "The classification loss after processing this batch is:  0.7524159550666809\n",
      "The representation loss after processing this batch is:  0.0052513256669044495\n",
      "\n",
      "The classification loss after processing this batch is:  0.7554264068603516\n",
      "The representation loss after processing this batch is:  0.00569630041718483\n",
      "\n",
      "The classification loss after processing this batch is:  0.7218452095985413\n",
      "The representation loss after processing this batch is:  0.005381044000387192\n",
      "\n",
      "The classification loss after processing this batch is:  0.8752602934837341\n",
      "The representation loss after processing this batch is:  0.004872903227806091\n",
      "\n",
      "The classification loss after processing this batch is:  0.7436413168907166\n",
      "The representation loss after processing this batch is:  0.0055124834179878235\n",
      "\n",
      "The classification loss after processing this batch is:  0.6605285406112671\n",
      "The representation loss after processing this batch is:  0.005886584520339966\n",
      "\n",
      "The classification loss after processing this batch is:  0.7392885684967041\n",
      "The representation loss after processing this batch is:  0.0059046149253845215\n",
      "\n",
      "The classification loss after processing this batch is:  0.6126846671104431\n",
      "The representation loss after processing this batch is:  0.006043754518032074\n",
      "\n",
      "The classification loss after processing this batch is:  0.721350908279419\n",
      "The representation loss after processing this batch is:  0.005208954215049744\n",
      "\n",
      "The classification loss after processing this batch is:  0.7599425911903381\n",
      "The representation loss after processing this batch is:  0.005500614643096924\n",
      "\n",
      "The classification loss after processing this batch is:  0.5596217513084412\n",
      "The representation loss after processing this batch is:  0.0052093639969825745\n",
      "\n",
      "The classification loss after processing this batch is:  0.686614990234375\n",
      "The representation loss after processing this batch is:  0.005447395145893097\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.697551429271698\n",
      "The representation loss after processing this batch is:  0.007944338023662567\n",
      "\n",
      "The classification loss after processing this batch is:  0.7793151140213013\n",
      "The representation loss after processing this batch is:  0.006173163652420044\n",
      "\n",
      "The classification loss after processing this batch is:  0.7546444535255432\n",
      "The representation loss after processing this batch is:  0.005929891020059586\n",
      "\n",
      "The classification loss after processing this batch is:  0.7198747396469116\n",
      "The representation loss after processing this batch is:  0.005457237362861633\n",
      "\n",
      "The classification loss after processing this batch is:  0.6250513792037964\n",
      "The representation loss after processing this batch is:  0.005712270736694336\n",
      "\n",
      "The classification loss after processing this batch is:  0.7687021493911743\n",
      "The representation loss after processing this batch is:  0.004873484373092651\n",
      "\n",
      "The classification loss after processing this batch is:  0.7404242753982544\n",
      "The representation loss after processing this batch is:  0.004809945821762085\n",
      "\n",
      "The classification loss after processing this batch is:  0.7021257281303406\n",
      "The representation loss after processing this batch is:  0.005570314824581146\n",
      "\n",
      "The classification loss after processing this batch is:  0.6714503765106201\n",
      "The representation loss after processing this batch is:  0.0057433247566223145\n",
      "\n",
      "The classification loss after processing this batch is:  0.9178630709648132\n",
      "The representation loss after processing this batch is:  0.0054385848343372345\n",
      "\n",
      "The classification loss after processing this batch is:  0.8395317196846008\n",
      "The representation loss after processing this batch is:  0.00580964982509613\n",
      "\n",
      "The classification loss after processing this batch is:  0.7001279592514038\n",
      "The representation loss after processing this batch is:  0.005932249128818512\n",
      "\n",
      "The classification loss after processing this batch is:  0.7064208984375\n",
      "The representation loss after processing this batch is:  0.006582006812095642\n",
      "\n",
      "The classification loss after processing this batch is:  0.8483070135116577\n",
      "The representation loss after processing this batch is:  0.005362093448638916\n",
      "\n",
      "The classification loss after processing this batch is:  0.7083193063735962\n",
      "The representation loss after processing this batch is:  0.005385790020227432\n",
      "\n",
      "The classification loss after processing this batch is:  0.9476045966148376\n",
      "The representation loss after processing this batch is:  0.005497850477695465\n",
      "\n",
      "The classification loss after processing this batch is:  0.7493418455123901\n",
      "The representation loss after processing this batch is:  0.005975008010864258\n",
      "\n",
      "The classification loss after processing this batch is:  0.8841724991798401\n",
      "The representation loss after processing this batch is:  0.006572440266609192\n",
      "\n",
      "The classification loss after processing this batch is:  0.7804685235023499\n",
      "The representation loss after processing this batch is:  0.005286552011966705\n",
      "\n",
      "The classification loss after processing this batch is:  0.6968939304351807\n",
      "The representation loss after processing this batch is:  0.005696214735507965\n",
      "\n",
      "The classification loss after processing this batch is:  0.6665833592414856\n",
      "The representation loss after processing this batch is:  0.004658244550228119\n",
      "\n",
      "The classification loss after processing this batch is:  0.8756922483444214\n",
      "The representation loss after processing this batch is:  0.005616672337055206\n",
      "\n",
      "The classification loss after processing this batch is:  0.9038099646568298\n",
      "The representation loss after processing this batch is:  0.0049941278994083405\n",
      "\n",
      "The classification loss after processing this batch is:  0.9977379441261292\n",
      "The representation loss after processing this batch is:  0.005575932562351227\n",
      "\n",
      "The classification loss after processing this batch is:  0.7743034958839417\n",
      "The representation loss after processing this batch is:  0.005681395530700684\n",
      "\n",
      "The classification loss after processing this batch is:  0.7171598672866821\n",
      "The representation loss after processing this batch is:  0.005164653062820435\n",
      "\n",
      "The classification loss after processing this batch is:  0.6006958484649658\n",
      "The representation loss after processing this batch is:  0.004870232194662094\n",
      "\n",
      "The classification loss after processing this batch is:  0.6691270470619202\n",
      "The representation loss after processing this batch is:  0.006436541676521301\n",
      "\n",
      "The classification loss after processing this batch is:  0.6863133311271667\n",
      "The representation loss after processing this batch is:  0.005493145436048508\n",
      "\n",
      "The classification loss after processing this batch is:  0.5699729323387146\n",
      "The representation loss after processing this batch is:  0.005500424653291702\n",
      "\n",
      "The classification loss after processing this batch is:  0.7425631284713745\n",
      "The representation loss after processing this batch is:  0.005102619528770447\n",
      "\n",
      "The classification loss after processing this batch is:  0.8542937636375427\n",
      "The representation loss after processing this batch is:  0.006092585623264313\n",
      "\n",
      "The classification loss after processing this batch is:  0.7345182299613953\n",
      "The representation loss after processing this batch is:  0.004977226257324219\n",
      "\n",
      "The classification loss after processing this batch is:  0.7864137291908264\n",
      "The representation loss after processing this batch is:  0.006235986948013306\n",
      "\n",
      "The classification loss after processing this batch is:  0.6593230962753296\n",
      "The representation loss after processing this batch is:  0.006089009344577789\n",
      "\n",
      "The classification loss after processing this batch is:  0.6628981232643127\n",
      "The representation loss after processing this batch is:  0.0046769678592681885\n",
      "\n",
      "The classification loss after processing this batch is:  0.6674641966819763\n",
      "The representation loss after processing this batch is:  0.005690284073352814\n",
      "\n",
      "The classification loss after processing this batch is:  0.5940274000167847\n",
      "The representation loss after processing this batch is:  0.005304284393787384\n",
      "\n",
      "The classification loss after processing this batch is:  0.6007977724075317\n",
      "The representation loss after processing this batch is:  0.004931032657623291\n",
      "\n",
      "The classification loss after processing this batch is:  0.7790578007698059\n",
      "The representation loss after processing this batch is:  0.004366680979728699\n",
      "\n",
      "The classification loss after processing this batch is:  0.6304519772529602\n",
      "The representation loss after processing this batch is:  0.005249790847301483\n",
      "\n",
      "The classification loss after processing this batch is:  0.7644872069358826\n",
      "The representation loss after processing this batch is:  0.004523329436779022\n",
      "\n",
      "The classification loss after processing this batch is:  0.7543939352035522\n",
      "The representation loss after processing this batch is:  0.005471091717481613\n",
      "\n",
      "The classification loss after processing this batch is:  0.5754346251487732\n",
      "The representation loss after processing this batch is:  0.0049517713487148285\n",
      "\n",
      "The classification loss after processing this batch is:  0.648882269859314\n",
      "The representation loss after processing this batch is:  0.004956461489200592\n",
      "\n",
      "The classification loss after processing this batch is:  0.7295170426368713\n",
      "The representation loss after processing this batch is:  0.005057960748672485\n",
      "\n",
      "The classification loss after processing this batch is:  0.7014514207839966\n",
      "The representation loss after processing this batch is:  0.0047562867403030396\n",
      "\n",
      "The classification loss after processing this batch is:  0.9604852795600891\n",
      "The representation loss after processing this batch is:  0.004799902439117432\n",
      "\n",
      "The classification loss after processing this batch is:  0.844978392124176\n",
      "The representation loss after processing this batch is:  0.00548543781042099\n",
      "\n",
      "The classification loss after processing this batch is:  0.7906457185745239\n",
      "The representation loss after processing this batch is:  0.005534552037715912\n",
      "\n",
      "The classification loss after processing this batch is:  0.7053353190422058\n",
      "The representation loss after processing this batch is:  0.004845630377531052\n",
      "\n",
      "The classification loss after processing this batch is:  0.7124327421188354\n",
      "The representation loss after processing this batch is:  0.0048825703561306\n",
      "\n",
      "The classification loss after processing this batch is:  0.7323259711265564\n",
      "The representation loss after processing this batch is:  0.004212096333503723\n",
      "\n",
      "The classification loss after processing this batch is:  0.8087093234062195\n",
      "The representation loss after processing this batch is:  0.0048766061663627625\n",
      "\n",
      "The classification loss after processing this batch is:  0.7237270474433899\n",
      "The representation loss after processing this batch is:  0.005551252514123917\n",
      "\n",
      "The classification loss after processing this batch is:  0.8882541060447693\n",
      "The representation loss after processing this batch is:  0.005828432738780975\n",
      "\n",
      "The classification loss after processing this batch is:  0.7678793668746948\n",
      "The representation loss after processing this batch is:  0.005476865917444229\n",
      "\n",
      "The classification loss after processing this batch is:  0.6714980006217957\n",
      "The representation loss after processing this batch is:  0.004600539803504944\n",
      "\n",
      "The classification loss after processing this batch is:  0.8326542973518372\n",
      "The representation loss after processing this batch is:  0.005115944892168045\n",
      "\n",
      "The classification loss after processing this batch is:  0.6749833822250366\n",
      "The representation loss after processing this batch is:  0.004919648170471191\n",
      "\n",
      "The classification loss after processing this batch is:  0.5477340817451477\n",
      "The representation loss after processing this batch is:  0.005239047110080719\n",
      "\n",
      "The classification loss after processing this batch is:  0.6224830746650696\n",
      "The representation loss after processing this batch is:  0.005166478455066681\n",
      "\n",
      "The classification loss after processing this batch is:  0.6038997173309326\n",
      "The representation loss after processing this batch is:  0.006175711750984192\n",
      "\n",
      "The classification loss after processing this batch is:  0.6238011717796326\n",
      "The representation loss after processing this batch is:  0.0060280971229076385\n",
      "\n",
      "The classification loss after processing this batch is:  0.6840670108795166\n",
      "The representation loss after processing this batch is:  0.004365615546703339\n",
      "\n",
      "The classification loss after processing this batch is:  0.9736763834953308\n",
      "The representation loss after processing this batch is:  0.005606386810541153\n",
      "\n",
      "The classification loss after processing this batch is:  0.6327224969863892\n",
      "The representation loss after processing this batch is:  0.005859255790710449\n",
      "\n",
      "The classification loss after processing this batch is:  0.8682777285575867\n",
      "The representation loss after processing this batch is:  0.005464144051074982\n",
      "\n",
      "The classification loss after processing this batch is:  0.8408867716789246\n",
      "The representation loss after processing this batch is:  0.005553163588047028\n",
      "\n",
      "The classification loss after processing this batch is:  0.7507838606834412\n",
      "The representation loss after processing this batch is:  0.006709851324558258\n",
      "\n",
      "The classification loss after processing this batch is:  0.6156835556030273\n",
      "The representation loss after processing this batch is:  0.005302950739860535\n",
      "\n",
      "The classification loss after processing this batch is:  0.9454094767570496\n",
      "The representation loss after processing this batch is:  0.004830222576856613\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.9146539568901062\n",
      "The representation loss after processing this batch is:  0.005222603678703308\n",
      "\n",
      "The classification loss after processing this batch is:  0.6995447874069214\n",
      "The representation loss after processing this batch is:  0.00580471009016037\n",
      "\n",
      "The classification loss after processing this batch is:  0.5291481018066406\n",
      "The representation loss after processing this batch is:  0.005479961633682251\n",
      "\n",
      "The classification loss after processing this batch is:  0.6638204455375671\n",
      "The representation loss after processing this batch is:  0.005886424332857132\n",
      "\n",
      "The classification loss after processing this batch is:  0.7104552388191223\n",
      "The representation loss after processing this batch is:  0.006012178957462311\n",
      "\n",
      "The classification loss after processing this batch is:  0.7333201169967651\n",
      "The representation loss after processing this batch is:  0.0048302821815013885\n",
      "\n",
      "The classification loss after processing this batch is:  0.8329423069953918\n",
      "The representation loss after processing this batch is:  0.0052412934601306915\n",
      "\n",
      "The classification loss after processing this batch is:  0.6989637017250061\n",
      "The representation loss after processing this batch is:  0.0048016756772994995\n",
      "\n",
      "The classification loss after processing this batch is:  0.7374889850616455\n",
      "The representation loss after processing this batch is:  0.006100233644247055\n",
      "\n",
      "The classification loss after processing this batch is:  0.7325565218925476\n",
      "The representation loss after processing this batch is:  0.006403334438800812\n",
      "\n",
      "The classification loss after processing this batch is:  0.6641978621482849\n",
      "The representation loss after processing this batch is:  0.0065715983510017395\n",
      "\n",
      "The classification loss after processing this batch is:  0.7085595726966858\n",
      "The representation loss after processing this batch is:  0.0052345506846904755\n",
      "\n",
      "The classification loss after processing this batch is:  0.9019144177436829\n",
      "The representation loss after processing this batch is:  0.005566753447055817\n",
      "\n",
      "The classification loss after processing this batch is:  0.7140114903450012\n",
      "The representation loss after processing this batch is:  0.005985923111438751\n",
      "\n",
      "The classification loss after processing this batch is:  0.6408275365829468\n",
      "The representation loss after processing this batch is:  0.005534917116165161\n",
      "\n",
      "The classification loss after processing this batch is:  0.6304339170455933\n",
      "The representation loss after processing this batch is:  0.005376558750867844\n",
      "\n",
      "The classification loss after processing this batch is:  0.5726563930511475\n",
      "The representation loss after processing this batch is:  0.004320390522480011\n",
      "\n",
      "The classification loss after processing this batch is:  0.49963393807411194\n",
      "The representation loss after processing this batch is:  0.004681922495365143\n",
      "\n",
      "The classification loss after processing this batch is:  0.6276448369026184\n",
      "The representation loss after processing this batch is:  0.004724420607089996\n",
      "\n",
      "The classification loss after processing this batch is:  0.8719236850738525\n",
      "The representation loss after processing this batch is:  0.004586402326822281\n",
      "\n",
      "The classification loss after processing this batch is:  0.8096240162849426\n",
      "The representation loss after processing this batch is:  0.005150996148586273\n",
      "\n",
      "The classification loss after processing this batch is:  0.7811397314071655\n",
      "The representation loss after processing this batch is:  0.00425228476524353\n",
      "\n",
      "The classification loss after processing this batch is:  0.6539127826690674\n",
      "The representation loss after processing this batch is:  0.005313903093338013\n",
      "\n",
      "The classification loss after processing this batch is:  0.6442249417304993\n",
      "The representation loss after processing this batch is:  0.005152411758899689\n",
      "\n",
      "The classification loss after processing this batch is:  0.6762681603431702\n",
      "The representation loss after processing this batch is:  0.004436329007148743\n",
      "\n",
      "The classification loss after processing this batch is:  0.8337851762771606\n",
      "The representation loss after processing this batch is:  0.005182143300771713\n",
      "\n",
      "The classification loss after processing this batch is:  0.716831624507904\n",
      "The representation loss after processing this batch is:  0.005120683461427689\n",
      "\n",
      "The classification loss after processing this batch is:  0.7360250949859619\n",
      "The representation loss after processing this batch is:  0.004880182445049286\n",
      "\n",
      "The classification loss after processing this batch is:  0.6334632039070129\n",
      "The representation loss after processing this batch is:  0.004490718245506287\n",
      "\n",
      "The classification loss after processing this batch is:  0.49799904227256775\n",
      "The representation loss after processing this batch is:  0.00514347106218338\n",
      "\n",
      "The classification loss after processing this batch is:  0.7043823003768921\n",
      "The representation loss after processing this batch is:  0.005629289895296097\n",
      "\n",
      "The classification loss after processing this batch is:  0.6111658215522766\n",
      "The representation loss after processing this batch is:  0.004472803324460983\n",
      "\n",
      "The classification loss after processing this batch is:  0.7950661778450012\n",
      "The representation loss after processing this batch is:  0.005365770310163498\n",
      "\n",
      "The classification loss after processing this batch is:  0.7824475765228271\n",
      "The representation loss after processing this batch is:  0.003989223390817642\n",
      "\n",
      "The classification loss after processing this batch is:  0.8598645329475403\n",
      "The representation loss after processing this batch is:  0.0045766159892082214\n",
      "\n",
      "The classification loss after processing this batch is:  0.8888711333274841\n",
      "The representation loss after processing this batch is:  0.005137786269187927\n",
      "\n",
      "The classification loss after processing this batch is:  0.8044192790985107\n",
      "The representation loss after processing this batch is:  0.004424571990966797\n",
      "\n",
      "The classification loss after processing this batch is:  0.7949715256690979\n",
      "The representation loss after processing this batch is:  0.003978721797466278\n",
      "\n",
      "The classification loss after processing this batch is:  0.8484367728233337\n",
      "The representation loss after processing this batch is:  0.004099339246749878\n",
      "\n",
      "The classification loss after processing this batch is:  0.7848656177520752\n",
      "The representation loss after processing this batch is:  0.004059143364429474\n",
      "\n",
      "The classification loss after processing this batch is:  0.6040995717048645\n",
      "The representation loss after processing this batch is:  0.004947073757648468\n",
      "\n",
      "The classification loss after processing this batch is:  0.4709324836730957\n",
      "The representation loss after processing this batch is:  0.00519469752907753\n",
      "\n",
      "The classification loss after processing this batch is:  0.6110068559646606\n",
      "The representation loss after processing this batch is:  0.005091596394777298\n",
      "\n",
      "The classification loss after processing this batch is:  0.5106176733970642\n",
      "The representation loss after processing this batch is:  0.00782456248998642\n",
      "\n",
      "The classification loss after processing this batch is:  0.6788204908370972\n",
      "The representation loss after processing this batch is:  0.005250692367553711\n",
      "\n",
      "The classification loss after processing this batch is:  0.5257550477981567\n",
      "The representation loss after processing this batch is:  0.005205914378166199\n",
      "\n",
      "The classification loss after processing this batch is:  0.6955273747444153\n",
      "The representation loss after processing this batch is:  0.004827812314033508\n",
      "\n",
      "The classification loss after processing this batch is:  0.44473347067832947\n",
      "The representation loss after processing this batch is:  0.005446337163448334\n",
      "\n",
      "The classification loss after processing this batch is:  0.7894316911697388\n",
      "The representation loss after processing this batch is:  0.004845373332500458\n",
      "\n",
      "The classification loss after processing this batch is:  0.5982950329780579\n",
      "The representation loss after processing this batch is:  0.0050539374351501465\n",
      "\n",
      "The classification loss after processing this batch is:  0.6239227056503296\n",
      "The representation loss after processing this batch is:  0.005346678197383881\n",
      "\n",
      "The classification loss after processing this batch is:  0.7513177394866943\n",
      "The representation loss after processing this batch is:  0.005172699689865112\n",
      "\n",
      "The classification loss after processing this batch is:  0.5812906622886658\n",
      "The representation loss after processing this batch is:  0.004699427634477615\n",
      "\n",
      "The classification loss after processing this batch is:  0.5772724151611328\n",
      "The representation loss after processing this batch is:  0.004294309765100479\n",
      "\n",
      "The classification loss after processing this batch is:  0.5931875109672546\n",
      "The representation loss after processing this batch is:  0.005463078618049622\n",
      "\n",
      "The classification loss after processing this batch is:  0.5927830338478088\n",
      "The representation loss after processing this batch is:  0.0051723383367061615\n",
      "\n",
      "The classification loss after processing this batch is:  0.47416824102401733\n",
      "The representation loss after processing this batch is:  0.004485204815864563\n",
      "\n",
      "The classification loss after processing this batch is:  0.5159606337547302\n",
      "The representation loss after processing this batch is:  0.005936898291110992\n",
      "\n",
      "The classification loss after processing this batch is:  0.44128164649009705\n",
      "The representation loss after processing this batch is:  0.005803413689136505\n",
      "\n",
      "The classification loss after processing this batch is:  0.4990883767604828\n",
      "The representation loss after processing this batch is:  0.005260184407234192\n",
      "\n",
      "The classification loss after processing this batch is:  0.5024153590202332\n",
      "The representation loss after processing this batch is:  0.005391653627157211\n",
      "\n",
      "The classification loss after processing this batch is:  0.676125168800354\n",
      "The representation loss after processing this batch is:  0.005099017173051834\n",
      "\n",
      "The classification loss after processing this batch is:  0.4345955550670624\n",
      "The representation loss after processing this batch is:  0.005010142922401428\n",
      "\n",
      "The classification loss after processing this batch is:  0.49908921122550964\n",
      "The representation loss after processing this batch is:  0.005239032208919525\n",
      "\n",
      "The classification loss after processing this batch is:  0.5843117833137512\n",
      "The representation loss after processing this batch is:  0.005914635956287384\n",
      "\n",
      "The classification loss after processing this batch is:  0.6444951295852661\n",
      "The representation loss after processing this batch is:  0.004717882722616196\n",
      "\n",
      "The classification loss after processing this batch is:  0.7061582207679749\n",
      "The representation loss after processing this batch is:  0.004652433097362518\n",
      "\n",
      "The classification loss after processing this batch is:  0.4956352412700653\n",
      "The representation loss after processing this batch is:  0.004921145737171173\n",
      "\n",
      "The classification loss after processing this batch is:  0.44636669754981995\n",
      "The representation loss after processing this batch is:  0.00508064404129982\n",
      "\n",
      "The classification loss after processing this batch is:  0.4472300112247467\n",
      "The representation loss after processing this batch is:  0.005077064037322998\n",
      "\n",
      "The classification loss after processing this batch is:  0.5505901575088501\n",
      "The representation loss after processing this batch is:  0.005180560052394867\n",
      "\n",
      "The classification loss after processing this batch is:  0.6033477187156677\n",
      "The representation loss after processing this batch is:  0.005228444933891296\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.5169594287872314\n",
      "The representation loss after processing this batch is:  0.004680365324020386\n",
      "\n",
      "The classification loss after processing this batch is:  0.6756897568702698\n",
      "The representation loss after processing this batch is:  0.004693042486906052\n",
      "\n",
      "The classification loss after processing this batch is:  0.5018997192382812\n",
      "The representation loss after processing this batch is:  0.004425276070833206\n",
      "\n",
      "The classification loss after processing this batch is:  0.5921527743339539\n",
      "The representation loss after processing this batch is:  0.004796437919139862\n",
      "\n",
      "The classification loss after processing this batch is:  0.7309637069702148\n",
      "The representation loss after processing this batch is:  0.004758436232805252\n",
      "\n",
      "The classification loss after processing this batch is:  0.5693251490592957\n",
      "The representation loss after processing this batch is:  0.004615291953086853\n",
      "\n",
      "The classification loss after processing this batch is:  0.8515544533729553\n",
      "The representation loss after processing this batch is:  0.004972122609615326\n",
      "\n",
      "The classification loss after processing this batch is:  0.6203567981719971\n",
      "The representation loss after processing this batch is:  0.004275377839803696\n",
      "\n",
      "The classification loss after processing this batch is:  0.6322911977767944\n",
      "The representation loss after processing this batch is:  0.005118705332279205\n",
      "\n",
      "The classification loss after processing this batch is:  0.5830360651016235\n",
      "The representation loss after processing this batch is:  0.004865482449531555\n",
      "\n",
      "The classification loss after processing this batch is:  0.6468499898910522\n",
      "The representation loss after processing this batch is:  0.005790699273347855\n",
      "\n",
      "The classification loss after processing this batch is:  0.5888993144035339\n",
      "The representation loss after processing this batch is:  0.004605982452630997\n",
      "\n",
      "The classification loss after processing this batch is:  0.6424458622932434\n",
      "The representation loss after processing this batch is:  0.0049141570925712585\n",
      "\n",
      "The classification loss after processing this batch is:  0.6771052479743958\n",
      "The representation loss after processing this batch is:  0.0050113387405872345\n",
      "\n",
      "The classification loss after processing this batch is:  0.5602292418479919\n",
      "The representation loss after processing this batch is:  0.005404241383075714\n",
      "\n",
      "The classification loss after processing this batch is:  0.5012208819389343\n",
      "The representation loss after processing this batch is:  0.004484772682189941\n",
      "\n",
      "The classification loss after processing this batch is:  0.5583018660545349\n",
      "The representation loss after processing this batch is:  0.004749234765768051\n",
      "\n",
      "The classification loss after processing this batch is:  0.5944388508796692\n",
      "The representation loss after processing this batch is:  0.0046563781797885895\n",
      "\n",
      "The classification loss after processing this batch is:  0.5426796674728394\n",
      "The representation loss after processing this batch is:  0.004872437566518784\n",
      "\n",
      "The classification loss after processing this batch is:  0.6341070532798767\n",
      "The representation loss after processing this batch is:  0.004934355616569519\n",
      "\n",
      "The classification loss after processing this batch is:  0.6120089888572693\n",
      "The representation loss after processing this batch is:  0.0043426863849163055\n",
      "\n",
      "The classification loss after processing this batch is:  0.4242876470088959\n",
      "The representation loss after processing this batch is:  0.005347918719053268\n",
      "\n",
      "The classification loss after processing this batch is:  0.4701778292655945\n",
      "The representation loss after processing this batch is:  0.0056750960648059845\n",
      "\n",
      "The classification loss after processing this batch is:  0.49965307116508484\n",
      "The representation loss after processing this batch is:  0.00507722795009613\n",
      "\n",
      "The classification loss after processing this batch is:  0.4812433421611786\n",
      "The representation loss after processing this batch is:  0.005682304501533508\n",
      "\n",
      "The classification loss after processing this batch is:  0.5699602961540222\n",
      "The representation loss after processing this batch is:  0.005772214382886887\n",
      "\n",
      "The classification loss after processing this batch is:  0.6068121790885925\n",
      "The representation loss after processing this batch is:  0.0055947452783584595\n",
      "\n",
      "The classification loss after processing this batch is:  0.5361988544464111\n",
      "The representation loss after processing this batch is:  0.005087435245513916\n",
      "\n",
      "The classification loss after processing this batch is:  0.5875850915908813\n",
      "The representation loss after processing this batch is:  0.0041033439338207245\n",
      "\n",
      "The classification loss after processing this batch is:  0.5734215974807739\n",
      "The representation loss after processing this batch is:  0.004669118672609329\n",
      "\n",
      "The classification loss after processing this batch is:  0.3811804950237274\n",
      "The representation loss after processing this batch is:  0.005798026919364929\n",
      "\n",
      "The classification loss after processing this batch is:  0.5082927942276001\n",
      "The representation loss after processing this batch is:  0.004619646817445755\n",
      "\n",
      "The classification loss after processing this batch is:  0.5420899987220764\n",
      "The representation loss after processing this batch is:  0.004558451473712921\n",
      "\n",
      "The classification loss after processing this batch is:  0.5943393707275391\n",
      "The representation loss after processing this batch is:  0.004746634513139725\n",
      "\n",
      "The classification loss after processing this batch is:  0.5323374271392822\n",
      "The representation loss after processing this batch is:  0.004821479320526123\n",
      "\n",
      "The classification loss after processing this batch is:  0.5785799622535706\n",
      "The representation loss after processing this batch is:  0.005551628768444061\n",
      "\n",
      "The classification loss after processing this batch is:  0.5308030843734741\n",
      "The representation loss after processing this batch is:  0.005557172000408173\n",
      "\n",
      "The classification loss after processing this batch is:  0.5059565901756287\n",
      "The representation loss after processing this batch is:  0.005003161728382111\n",
      "\n",
      "The classification loss after processing this batch is:  0.6571432948112488\n",
      "The representation loss after processing this batch is:  0.004903826862573624\n",
      "\n",
      "The classification loss after processing this batch is:  0.576253354549408\n",
      "The representation loss after processing this batch is:  0.0041696056723594666\n",
      "\n",
      "The classification loss after processing this batch is:  0.5477396845817566\n",
      "The representation loss after processing this batch is:  0.005942225456237793\n",
      "\n",
      "The classification loss after processing this batch is:  0.4198226034641266\n",
      "The representation loss after processing this batch is:  0.005318723618984222\n",
      "\n",
      "The classification loss after processing this batch is:  0.4240112006664276\n",
      "The representation loss after processing this batch is:  0.005671873688697815\n",
      "\n",
      "The classification loss after processing this batch is:  0.6128323674201965\n",
      "The representation loss after processing this batch is:  0.005045507103204727\n",
      "\n",
      "The classification loss after processing this batch is:  0.6476010680198669\n",
      "The representation loss after processing this batch is:  0.004505503922700882\n",
      "\n",
      "The classification loss after processing this batch is:  0.6182655096054077\n",
      "The representation loss after processing this batch is:  0.004661422222852707\n",
      "\n",
      "The classification loss after processing this batch is:  0.5677465796470642\n",
      "The representation loss after processing this batch is:  0.00481007993221283\n",
      "\n",
      "The classification loss after processing this batch is:  0.6457416415214539\n",
      "The representation loss after processing this batch is:  0.005115162581205368\n",
      "\n",
      "The classification loss after processing this batch is:  0.6568737030029297\n",
      "The representation loss after processing this batch is:  0.0039683133363723755\n",
      "\n",
      "The classification loss after processing this batch is:  0.6996005773544312\n",
      "The representation loss after processing this batch is:  0.004792213439941406\n",
      "\n",
      "The classification loss after processing this batch is:  0.693615734577179\n",
      "The representation loss after processing this batch is:  0.004869140684604645\n",
      "\n",
      "The classification loss after processing this batch is:  0.6438429355621338\n",
      "The representation loss after processing this batch is:  0.005122076719999313\n",
      "\n",
      "The classification loss after processing this batch is:  0.5523083806037903\n",
      "The representation loss after processing this batch is:  0.005867309868335724\n",
      "\n",
      "The classification loss after processing this batch is:  0.36544591188430786\n",
      "The representation loss after processing this batch is:  0.005350634455680847\n",
      "\n",
      "The classification loss after processing this batch is:  0.48172393441200256\n",
      "The representation loss after processing this batch is:  0.005688413977622986\n",
      "\n",
      "The classification loss after processing this batch is:  0.5673351883888245\n",
      "The representation loss after processing this batch is:  0.004761748015880585\n",
      "\n",
      "The classification loss after processing this batch is:  0.48009929060935974\n",
      "The representation loss after processing this batch is:  0.004488609731197357\n",
      "\n",
      "The classification loss after processing this batch is:  0.5870800614356995\n",
      "The representation loss after processing this batch is:  0.004881851375102997\n",
      "\n",
      "The classification loss after processing this batch is:  0.5401656627655029\n",
      "The representation loss after processing this batch is:  0.004360906779766083\n",
      "\n",
      "The classification loss after processing this batch is:  0.4535900354385376\n",
      "The representation loss after processing this batch is:  0.004780720919370651\n",
      "\n",
      "The classification loss after processing this batch is:  0.46974506974220276\n",
      "The representation loss after processing this batch is:  0.005272094160318375\n",
      "\n",
      "The classification loss after processing this batch is:  0.47181236743927\n",
      "The representation loss after processing this batch is:  0.003948841243982315\n",
      "\n",
      "The classification loss after processing this batch is:  0.5344177484512329\n",
      "The representation loss after processing this batch is:  0.004608578979969025\n",
      "\n",
      "The classification loss after processing this batch is:  0.5641066431999207\n",
      "The representation loss after processing this batch is:  0.00502265989780426\n",
      "\n",
      "The classification loss after processing this batch is:  0.586144745349884\n",
      "The representation loss after processing this batch is:  0.00583716481924057\n",
      "\n",
      "The classification loss after processing this batch is:  0.45868587493896484\n",
      "The representation loss after processing this batch is:  0.006702981889247894\n",
      "\n",
      "The classification loss after processing this batch is:  0.40833213925361633\n",
      "The representation loss after processing this batch is:  0.004763573408126831\n",
      "\n",
      "The classification loss after processing this batch is:  0.4681161940097809\n",
      "The representation loss after processing this batch is:  0.005296871066093445\n",
      "\n",
      "The classification loss after processing this batch is:  0.5182852745056152\n",
      "The representation loss after processing this batch is:  0.004206530749797821\n",
      "\n",
      "The classification loss after processing this batch is:  0.7218426465988159\n",
      "The representation loss after processing this batch is:  0.00436754897236824\n",
      "\n",
      "The classification loss after processing this batch is:  0.5524914860725403\n",
      "The representation loss after processing this batch is:  0.004314757883548737\n",
      "\n",
      "The classification loss after processing this batch is:  0.34447920322418213\n",
      "The representation loss after processing this batch is:  0.004718393087387085\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.5426982045173645\n",
      "The representation loss after processing this batch is:  0.004638202488422394\n",
      "\n",
      "The classification loss after processing this batch is:  0.33623746037483215\n",
      "The representation loss after processing this batch is:  0.0049504488706588745\n",
      "\n",
      "The classification loss after processing this batch is:  0.5204216837882996\n",
      "The representation loss after processing this batch is:  0.004348907619714737\n",
      "\n",
      "The classification loss after processing this batch is:  0.42484351992607117\n",
      "The representation loss after processing this batch is:  0.005338624119758606\n",
      "\n",
      "The classification loss after processing this batch is:  0.3591752350330353\n",
      "The representation loss after processing this batch is:  0.004316404461860657\n",
      "\n",
      "The classification loss after processing this batch is:  0.3778323829174042\n",
      "The representation loss after processing this batch is:  0.004446081817150116\n",
      "\n",
      "The classification loss after processing this batch is:  0.4754568040370941\n",
      "The representation loss after processing this batch is:  0.004681870341300964\n",
      "\n",
      "The classification loss after processing this batch is:  0.4329211413860321\n",
      "The representation loss after processing this batch is:  0.0045138075947761536\n",
      "\n",
      "The classification loss after processing this batch is:  0.6455524563789368\n",
      "The representation loss after processing this batch is:  0.0044653937220573425\n",
      "\n",
      "The classification loss after processing this batch is:  0.7610272765159607\n",
      "The representation loss after processing this batch is:  0.004213474690914154\n",
      "\n",
      "The classification loss after processing this batch is:  0.5515074133872986\n",
      "The representation loss after processing this batch is:  0.004882149398326874\n",
      "\n",
      "The classification loss after processing this batch is:  0.6690975427627563\n",
      "The representation loss after processing this batch is:  0.0046353451907634735\n",
      "\n",
      "The classification loss after processing this batch is:  0.594791829586029\n",
      "The representation loss after processing this batch is:  0.004780251532793045\n",
      "\n",
      "The classification loss after processing this batch is:  0.512072741985321\n",
      "The representation loss after processing this batch is:  0.004453122615814209\n",
      "\n",
      "The classification loss after processing this batch is:  0.5877532958984375\n",
      "The representation loss after processing this batch is:  0.0046029239892959595\n",
      "\n",
      "The classification loss after processing this batch is:  0.4728362262248993\n",
      "The representation loss after processing this batch is:  0.004650510847568512\n",
      "\n",
      "The classification loss after processing this batch is:  0.6035168170928955\n",
      "The representation loss after processing this batch is:  0.004873000085353851\n",
      "\n",
      "The classification loss after processing this batch is:  0.5675716400146484\n",
      "The representation loss after processing this batch is:  0.004956573247909546\n",
      "\n",
      "The classification loss after processing this batch is:  0.5463176369667053\n",
      "The representation loss after processing this batch is:  0.004259880632162094\n",
      "\n",
      "The classification loss after processing this batch is:  0.6673954129219055\n",
      "The representation loss after processing this batch is:  0.004878096282482147\n",
      "\n",
      "The classification loss after processing this batch is:  0.5726862549781799\n",
      "The representation loss after processing this batch is:  0.0046754926443099976\n",
      "\n",
      "The classification loss after processing this batch is:  0.6134291291236877\n",
      "The representation loss after processing this batch is:  0.004545960575342178\n",
      "\n",
      "The classification loss after processing this batch is:  0.5033900737762451\n",
      "The representation loss after processing this batch is:  0.005203157663345337\n",
      "\n",
      "The classification loss after processing this batch is:  0.446368545293808\n",
      "The representation loss after processing this batch is:  0.004899993538856506\n",
      "\n",
      "The classification loss after processing this batch is:  0.505614161491394\n",
      "The representation loss after processing this batch is:  0.004441436380147934\n",
      "\n",
      "The classification loss after processing this batch is:  0.5046622157096863\n",
      "The representation loss after processing this batch is:  0.004803307354450226\n",
      "\n",
      "The classification loss after processing this batch is:  0.33719995617866516\n",
      "The representation loss after processing this batch is:  0.004359640181064606\n",
      "\n",
      "The classification loss after processing this batch is:  0.4974566400051117\n",
      "The representation loss after processing this batch is:  0.004386443644762039\n",
      "\n",
      "The classification loss after processing this batch is:  0.6622278094291687\n",
      "The representation loss after processing this batch is:  0.004059351980686188\n",
      "\n",
      "The classification loss after processing this batch is:  0.5061137080192566\n",
      "The representation loss after processing this batch is:  0.004059683531522751\n",
      "\n",
      "The classification loss after processing this batch is:  0.504777729511261\n",
      "The representation loss after processing this batch is:  0.004416525363922119\n",
      "\n",
      "The classification loss after processing this batch is:  0.6644046306610107\n",
      "The representation loss after processing this batch is:  0.004276026040315628\n",
      "\n",
      "The classification loss after processing this batch is:  0.42232242226600647\n",
      "The representation loss after processing this batch is:  0.004823774099349976\n",
      "\n",
      "The classification loss after processing this batch is:  0.4295145869255066\n",
      "The representation loss after processing this batch is:  0.004676710814237595\n",
      "\n",
      "The classification loss after processing this batch is:  0.45640262961387634\n",
      "The representation loss after processing this batch is:  0.004735976457595825\n",
      "\n",
      "The classification loss after processing this batch is:  0.4256618916988373\n",
      "The representation loss after processing this batch is:  0.005354657769203186\n",
      "\n",
      "The classification loss after processing this batch is:  0.4756591022014618\n",
      "The representation loss after processing this batch is:  0.005127616226673126\n",
      "\n",
      "The classification loss after processing this batch is:  0.49883559346199036\n",
      "The representation loss after processing this batch is:  0.0053766146302223206\n",
      "\n",
      "The classification loss after processing this batch is:  0.48160186409950256\n",
      "The representation loss after processing this batch is:  0.004251938313245773\n",
      "\n",
      "The classification loss after processing this batch is:  0.5490772128105164\n",
      "The representation loss after processing this batch is:  0.004952598363161087\n",
      "\n",
      "The classification loss after processing this batch is:  0.4687947630882263\n",
      "The representation loss after processing this batch is:  0.004652701318264008\n",
      "\n",
      "The classification loss after processing this batch is:  0.48933255672454834\n",
      "The representation loss after processing this batch is:  0.005190912634134293\n",
      "\n",
      "The classification loss after processing this batch is:  0.7097645401954651\n",
      "The representation loss after processing this batch is:  0.00477958470582962\n",
      "\n",
      "The classification loss after processing this batch is:  0.6552740931510925\n",
      "The representation loss after processing this batch is:  0.005093421787023544\n",
      "\n",
      "The classification loss after processing this batch is:  0.6491000056266785\n",
      "The representation loss after processing this batch is:  0.004330415278673172\n",
      "\n",
      "The classification loss after processing this batch is:  0.6497777104377747\n",
      "The representation loss after processing this batch is:  0.004585184156894684\n",
      "\n",
      "The classification loss after processing this batch is:  0.5961139798164368\n",
      "The representation loss after processing this batch is:  0.004625663161277771\n",
      "\n",
      "The classification loss after processing this batch is:  0.6307675838470459\n",
      "The representation loss after processing this batch is:  0.004542134702205658\n",
      "\n",
      "The classification loss after processing this batch is:  0.3028941750526428\n",
      "The representation loss after processing this batch is:  0.005463391542434692\n",
      "\n",
      "The classification loss after processing this batch is:  0.5163408517837524\n",
      "The representation loss after processing this batch is:  0.006724588572978973\n",
      "\n",
      "The classification loss after processing this batch is:  0.46583107113838196\n",
      "The representation loss after processing this batch is:  0.006373167037963867\n",
      "\n",
      "The classification loss after processing this batch is:  0.41843611001968384\n",
      "The representation loss after processing this batch is:  0.005821853876113892\n",
      "\n",
      "The classification loss after processing this batch is:  0.5552818179130554\n",
      "The representation loss after processing this batch is:  0.003980040550231934\n",
      "\n",
      "The classification loss after processing this batch is:  0.5361934304237366\n",
      "The representation loss after processing this batch is:  0.004701875150203705\n",
      "\n",
      "The classification loss after processing this batch is:  0.4600835144519806\n",
      "The representation loss after processing this batch is:  0.004897270351648331\n",
      "\n",
      "The classification loss after processing this batch is:  0.5976313948631287\n",
      "The representation loss after processing this batch is:  0.004329260438680649\n",
      "\n",
      "The classification loss after processing this batch is:  0.5614365935325623\n",
      "The representation loss after processing this batch is:  0.00466812402009964\n",
      "\n",
      "The classification loss after processing this batch is:  0.696271538734436\n",
      "The representation loss after processing this batch is:  0.004411831498146057\n",
      "\n",
      "The classification loss after processing this batch is:  0.5977419018745422\n",
      "The representation loss after processing this batch is:  0.005677051842212677\n",
      "\n",
      "The classification loss after processing this batch is:  0.5933013558387756\n",
      "The representation loss after processing this batch is:  0.0036889947950839996\n",
      "\n",
      "The classification loss after processing this batch is:  0.47298166155815125\n",
      "The representation loss after processing this batch is:  0.004724785685539246\n",
      "\n",
      "The classification loss after processing this batch is:  0.5171448588371277\n",
      "The representation loss after processing this batch is:  0.004890773445367813\n",
      "\n",
      "The classification loss after processing this batch is:  0.6711791157722473\n",
      "The representation loss after processing this batch is:  0.005517967045307159\n",
      "\n",
      "The classification loss after processing this batch is:  0.31277281045913696\n",
      "The representation loss after processing this batch is:  0.003858529031276703\n",
      "\n",
      "The classification loss after processing this batch is:  0.3794071078300476\n",
      "The representation loss after processing this batch is:  0.004478525370359421\n",
      "\n",
      "The classification loss after processing this batch is:  0.6450058221817017\n",
      "The representation loss after processing this batch is:  0.004298247396945953\n",
      "\n",
      "The classification loss after processing this batch is:  0.38081324100494385\n",
      "The representation loss after processing this batch is:  0.004257500171661377\n",
      "\n",
      "The classification loss after processing this batch is:  0.5100756287574768\n",
      "The representation loss after processing this batch is:  0.003964338451623917\n",
      "\n",
      "The classification loss after processing this batch is:  0.49243444204330444\n",
      "The representation loss after processing this batch is:  0.00501878559589386\n",
      "\n",
      "The classification loss after processing this batch is:  0.48273640871047974\n",
      "The representation loss after processing this batch is:  0.005286127328872681\n",
      "\n",
      "The classification loss after processing this batch is:  0.6493469476699829\n",
      "The representation loss after processing this batch is:  0.00547250360250473\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.6222082376480103\n",
      "The representation loss after processing this batch is:  0.004914984107017517\n",
      "\n",
      "The classification loss after processing this batch is:  0.6430426836013794\n",
      "The representation loss after processing this batch is:  0.00535767525434494\n",
      "\n",
      "The classification loss after processing this batch is:  0.4149971604347229\n",
      "The representation loss after processing this batch is:  0.004055570811033249\n",
      "\n",
      "The classification loss after processing this batch is:  0.5620461702346802\n",
      "The representation loss after processing this batch is:  0.003985077142715454\n",
      "\n",
      "The classification loss after processing this batch is:  0.3402356803417206\n",
      "The representation loss after processing this batch is:  0.004542626440525055\n",
      "\n",
      "The classification loss after processing this batch is:  0.3307223916053772\n",
      "The representation loss after processing this batch is:  0.004242047667503357\n",
      "\n",
      "The classification loss after processing this batch is:  0.3994433283805847\n",
      "The representation loss after processing this batch is:  0.004098091274499893\n",
      "\n",
      "The classification loss after processing this batch is:  0.31288275122642517\n",
      "The representation loss after processing this batch is:  0.003968559205532074\n",
      "\n",
      "The classification loss after processing this batch is:  0.5142034292221069\n",
      "The representation loss after processing this batch is:  0.00425419956445694\n",
      "\n",
      "The classification loss after processing this batch is:  0.3207322061061859\n",
      "The representation loss after processing this batch is:  0.00381363183259964\n",
      "\n",
      "The classification loss after processing this batch is:  0.4616983234882355\n",
      "The representation loss after processing this batch is:  0.004451710730791092\n",
      "\n",
      "The classification loss after processing this batch is:  0.4477512240409851\n",
      "The representation loss after processing this batch is:  0.004367906600236893\n",
      "\n",
      "The classification loss after processing this batch is:  0.5199917554855347\n",
      "The representation loss after processing this batch is:  0.005509637296199799\n",
      "\n",
      "The classification loss after processing this batch is:  0.5501030087471008\n",
      "The representation loss after processing this batch is:  0.004148688167333603\n",
      "\n",
      "The classification loss after processing this batch is:  0.3936600387096405\n",
      "The representation loss after processing this batch is:  0.004925191402435303\n",
      "\n",
      "The classification loss after processing this batch is:  0.5273083448410034\n",
      "The representation loss after processing this batch is:  0.004598621279001236\n",
      "\n",
      "The classification loss after processing this batch is:  0.473174512386322\n",
      "The representation loss after processing this batch is:  0.0046788714826107025\n",
      "\n",
      "The classification loss after processing this batch is:  0.5358089804649353\n",
      "The representation loss after processing this batch is:  0.004707671701908112\n",
      "\n",
      "The classification loss after processing this batch is:  0.6715673804283142\n",
      "The representation loss after processing this batch is:  0.00530262291431427\n",
      "\n",
      "The classification loss after processing this batch is:  0.5415969491004944\n",
      "The representation loss after processing this batch is:  0.004072174429893494\n",
      "\n",
      "The classification loss after processing this batch is:  0.5517030358314514\n",
      "The representation loss after processing this batch is:  0.0038262754678726196\n",
      "\n",
      "The classification loss after processing this batch is:  0.49966293573379517\n",
      "The representation loss after processing this batch is:  0.004295177757740021\n",
      "\n",
      "The classification loss after processing this batch is:  0.538969874382019\n",
      "The representation loss after processing this batch is:  0.0048353709280490875\n",
      "\n",
      "The classification loss after processing this batch is:  0.4727545976638794\n",
      "The representation loss after processing this batch is:  0.004673819988965988\n",
      "\n",
      "The classification loss after processing this batch is:  0.34997665882110596\n",
      "The representation loss after processing this batch is:  0.003644324839115143\n",
      "\n",
      "The classification loss after processing this batch is:  0.34507104754447937\n",
      "The representation loss after processing this batch is:  0.004301108419895172\n",
      "\n",
      "The classification loss after processing this batch is:  0.41490617394447327\n",
      "The representation loss after processing this batch is:  0.004282012581825256\n",
      "\n",
      "The classification loss after processing this batch is:  0.29490435123443604\n",
      "The representation loss after processing this batch is:  0.004394441843032837\n",
      "\n",
      "The classification loss after processing this batch is:  0.5230440497398376\n",
      "The representation loss after processing this batch is:  0.004817299544811249\n",
      "\n",
      "The classification loss after processing this batch is:  0.3950459063053131\n",
      "The representation loss after processing this batch is:  0.004880361258983612\n",
      "\n",
      "The classification loss after processing this batch is:  0.60298091173172\n",
      "The representation loss after processing this batch is:  0.005021374672651291\n",
      "\n",
      "The classification loss after processing this batch is:  0.4638976454734802\n",
      "The representation loss after processing this batch is:  0.004750259220600128\n",
      "\n",
      "The classification loss after processing this batch is:  0.4580543339252472\n",
      "The representation loss after processing this batch is:  0.004923615604639053\n",
      "\n",
      "The classification loss after processing this batch is:  0.6243824362754822\n",
      "The representation loss after processing this batch is:  0.0041741542518138885\n",
      "\n",
      "The classification loss after processing this batch is:  0.5149151086807251\n",
      "The representation loss after processing this batch is:  0.003916457295417786\n",
      "\n",
      "The classification loss after processing this batch is:  0.3785666823387146\n",
      "The representation loss after processing this batch is:  0.004136625677347183\n",
      "\n",
      "The classification loss after processing this batch is:  0.3317461609840393\n",
      "The representation loss after processing this batch is:  0.0048067569732666016\n",
      "\n",
      "The classification loss after processing this batch is:  0.38598963618278503\n",
      "The representation loss after processing this batch is:  0.004923075437545776\n",
      "\n",
      "The classification loss after processing this batch is:  0.34119653701782227\n",
      "The representation loss after processing this batch is:  0.004860997200012207\n",
      "\n",
      "The classification loss after processing this batch is:  0.4294221103191376\n",
      "The representation loss after processing this batch is:  0.0036899708211421967\n",
      "\n",
      "The classification loss after processing this batch is:  0.6478044390678406\n",
      "The representation loss after processing this batch is:  0.00530654564499855\n",
      "\n",
      "The classification loss after processing this batch is:  0.6340274810791016\n",
      "The representation loss after processing this batch is:  0.004255734384059906\n",
      "\n",
      "The classification loss after processing this batch is:  0.3648996949195862\n",
      "The representation loss after processing this batch is:  0.004948422312736511\n",
      "\n",
      "The classification loss after processing this batch is:  0.5454139709472656\n",
      "The representation loss after processing this batch is:  0.004699446260929108\n",
      "\n",
      "The classification loss after processing this batch is:  0.3242610991001129\n",
      "The representation loss after processing this batch is:  0.004270344972610474\n",
      "\n",
      "The classification loss after processing this batch is:  0.4815842807292938\n",
      "The representation loss after processing this batch is:  0.004379991441965103\n",
      "\n",
      "The classification loss after processing this batch is:  0.567108690738678\n",
      "The representation loss after processing this batch is:  0.0042602866888046265\n",
      "\n",
      "The classification loss after processing this batch is:  0.4961203932762146\n",
      "The representation loss after processing this batch is:  0.005736343562602997\n",
      "\n",
      "The classification loss after processing this batch is:  0.462259978055954\n",
      "The representation loss after processing this batch is:  0.006523583084344864\n",
      "\n",
      "The classification loss after processing this batch is:  0.3856945335865021\n",
      "The representation loss after processing this batch is:  0.0057581327855587006\n",
      "\n",
      "The classification loss after processing this batch is:  0.5352105498313904\n",
      "The representation loss after processing this batch is:  0.0053966231644153595\n",
      "\n",
      "The classification loss after processing this batch is:  0.4956665635108948\n",
      "The representation loss after processing this batch is:  0.005483034998178482\n",
      "\n",
      "The classification loss after processing this batch is:  0.46505528688430786\n",
      "The representation loss after processing this batch is:  0.0052681565284729\n",
      "\n",
      "The classification loss after processing this batch is:  0.4116329252719879\n",
      "The representation loss after processing this batch is:  0.0045824721455574036\n",
      "\n",
      "The classification loss after processing this batch is:  0.5790546536445618\n",
      "The representation loss after processing this batch is:  0.004096359014511108\n",
      "\n",
      "The classification loss after processing this batch is:  0.5640836358070374\n",
      "The representation loss after processing this batch is:  0.003703989088535309\n",
      "\n",
      "The classification loss after processing this batch is:  0.48428693413734436\n",
      "The representation loss after processing this batch is:  0.004240389913320541\n",
      "\n",
      "The classification loss after processing this batch is:  0.3399629592895508\n",
      "The representation loss after processing this batch is:  0.005203999578952789\n",
      "\n",
      "The classification loss after processing this batch is:  0.2943643033504486\n",
      "The representation loss after processing this batch is:  0.005420893430709839\n",
      "\n",
      "The classification loss after processing this batch is:  0.4681799113750458\n",
      "The representation loss after processing this batch is:  0.004878688603639603\n",
      "\n",
      "The classification loss after processing this batch is:  0.4006592035293579\n",
      "The representation loss after processing this batch is:  0.004366949200630188\n",
      "\n",
      "The classification loss after processing this batch is:  0.5359300971031189\n",
      "The representation loss after processing this batch is:  0.004181113094091415\n",
      "\n",
      "The classification loss after processing this batch is:  0.31454887986183167\n",
      "The representation loss after processing this batch is:  0.004876025021076202\n",
      "\n",
      "The classification loss after processing this batch is:  0.4032256305217743\n",
      "The representation loss after processing this batch is:  0.004071619361639023\n",
      "\n",
      "The classification loss after processing this batch is:  0.5201340913772583\n",
      "The representation loss after processing this batch is:  0.004793010652065277\n",
      "\n",
      "The classification loss after processing this batch is:  0.38810551166534424\n",
      "The representation loss after processing this batch is:  0.003978073596954346\n",
      "\n",
      "The classification loss after processing this batch is:  0.5864180326461792\n",
      "The representation loss after processing this batch is:  0.0042778849601745605\n",
      "\n",
      "The classification loss after processing this batch is:  0.34692275524139404\n",
      "The representation loss after processing this batch is:  0.004630982875823975\n",
      "\n",
      "The classification loss after processing this batch is:  0.4251691699028015\n",
      "The representation loss after processing this batch is:  0.0037667974829673767\n",
      "\n",
      "The classification loss after processing this batch is:  0.36141374707221985\n",
      "The representation loss after processing this batch is:  0.004207346588373184\n",
      "\n",
      "The classification loss after processing this batch is:  0.45363089442253113\n",
      "The representation loss after processing this batch is:  0.005894303321838379\n",
      "\n",
      "The classification loss after processing this batch is:  0.4493623375892639\n",
      "The representation loss after processing this batch is:  0.005134850740432739\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.5430710315704346\n",
      "The representation loss after processing this batch is:  0.0039057880640029907\n",
      "\n",
      "The classification loss after processing this batch is:  0.5559712052345276\n",
      "The representation loss after processing this batch is:  0.0041638389229774475\n",
      "\n",
      "The classification loss after processing this batch is:  0.6539608240127563\n",
      "The representation loss after processing this batch is:  0.003906548023223877\n",
      "\n",
      "The classification loss after processing this batch is:  0.43829458951950073\n",
      "The representation loss after processing this batch is:  0.00491960346698761\n",
      "\n",
      "The classification loss after processing this batch is:  0.5672507882118225\n",
      "The representation loss after processing this batch is:  0.004580393433570862\n",
      "\n",
      "The classification loss after processing this batch is:  0.42387136816978455\n",
      "The representation loss after processing this batch is:  0.004272282123565674\n",
      "\n",
      "The classification loss after processing this batch is:  0.38754525780677795\n",
      "The representation loss after processing this batch is:  0.004256904125213623\n",
      "\n",
      "The classification loss after processing this batch is:  0.34107792377471924\n",
      "The representation loss after processing this batch is:  0.004368938505649567\n",
      "\n",
      "The classification loss after processing this batch is:  0.3363919258117676\n",
      "The representation loss after processing this batch is:  0.005320832133293152\n",
      "\n",
      "The classification loss after processing this batch is:  0.5928057432174683\n",
      "The representation loss after processing this batch is:  0.00473003089427948\n",
      "\n",
      "The classification loss after processing this batch is:  0.4223777651786804\n",
      "The representation loss after processing this batch is:  0.005367562174797058\n",
      "\n",
      "The classification loss after processing this batch is:  0.4477042555809021\n",
      "The representation loss after processing this batch is:  0.00461738184094429\n",
      "\n",
      "The classification loss after processing this batch is:  0.41868269443511963\n",
      "The representation loss after processing this batch is:  0.004842065274715424\n",
      "\n",
      "The classification loss after processing this batch is:  0.3986716866493225\n",
      "The representation loss after processing this batch is:  0.004304137080907822\n",
      "\n",
      "The classification loss after processing this batch is:  0.3136051893234253\n",
      "The representation loss after processing this batch is:  0.004434369504451752\n",
      "\n",
      "The classification loss after processing this batch is:  0.41015326976776123\n",
      "The representation loss after processing this batch is:  0.00391601026058197\n",
      "\n",
      "The classification loss after processing this batch is:  0.42390918731689453\n",
      "The representation loss after processing this batch is:  0.00423068180680275\n",
      "\n",
      "The classification loss after processing this batch is:  0.5056337118148804\n",
      "The representation loss after processing this batch is:  0.004285119473934174\n",
      "\n",
      "The classification loss after processing this batch is:  0.31802672147750854\n",
      "The representation loss after processing this batch is:  0.004282806068658829\n",
      "\n",
      "The classification loss after processing this batch is:  0.5397778749465942\n",
      "The representation loss after processing this batch is:  0.004035286605358124\n",
      "\n",
      "The classification loss after processing this batch is:  0.45911872386932373\n",
      "The representation loss after processing this batch is:  0.004014812409877777\n",
      "\n",
      "The classification loss after processing this batch is:  0.4056698977947235\n",
      "The representation loss after processing this batch is:  0.0037453845143318176\n",
      "\n",
      "The classification loss after processing this batch is:  0.3957916498184204\n",
      "The representation loss after processing this batch is:  0.004665501415729523\n",
      "\n",
      "The classification loss after processing this batch is:  0.3422113358974457\n",
      "The representation loss after processing this batch is:  0.003657236695289612\n",
      "\n",
      "The classification loss after processing this batch is:  0.36370936036109924\n",
      "The representation loss after processing this batch is:  0.004187222570180893\n",
      "\n",
      "The classification loss after processing this batch is:  0.3473879396915436\n",
      "The representation loss after processing this batch is:  0.0046303048729896545\n",
      "\n",
      "The classification loss after processing this batch is:  0.48247620463371277\n",
      "The representation loss after processing this batch is:  0.005005538463592529\n",
      "\n",
      "The classification loss after processing this batch is:  0.6180095076560974\n",
      "The representation loss after processing this batch is:  0.00541599839925766\n",
      "\n",
      "The classification loss after processing this batch is:  0.5336228609085083\n",
      "The representation loss after processing this batch is:  0.005218230187892914\n",
      "\n",
      "The classification loss after processing this batch is:  0.520095705986023\n",
      "The representation loss after processing this batch is:  0.004665881395339966\n",
      "\n",
      "The classification loss after processing this batch is:  0.48834341764450073\n",
      "The representation loss after processing this batch is:  0.004610240459442139\n",
      "\n",
      "The classification loss after processing this batch is:  0.6006908416748047\n",
      "The representation loss after processing this batch is:  0.0038809292018413544\n",
      "\n",
      "The classification loss after processing this batch is:  0.3870461881160736\n",
      "The representation loss after processing this batch is:  0.004255346953868866\n",
      "\n",
      "The classification loss after processing this batch is:  0.24985627830028534\n",
      "The representation loss after processing this batch is:  0.004102572798728943\n",
      "\n",
      "The classification loss after processing this batch is:  0.36113232374191284\n",
      "The representation loss after processing this batch is:  0.0038281232118606567\n",
      "\n",
      "The classification loss after processing this batch is:  0.6511356234550476\n",
      "The representation loss after processing this batch is:  0.0047727301716804504\n",
      "\n",
      "The classification loss after processing this batch is:  0.7114078998565674\n",
      "The representation loss after processing this batch is:  0.004139944911003113\n",
      "\n",
      "The classification loss after processing this batch is:  0.6419797539710999\n",
      "The representation loss after processing this batch is:  0.0039689429104328156\n",
      "\n",
      "The classification loss after processing this batch is:  0.4796787202358246\n",
      "The representation loss after processing this batch is:  0.004248250275850296\n",
      "\n",
      "The classification loss after processing this batch is:  0.43103936314582825\n",
      "The representation loss after processing this batch is:  0.004103995859622955\n",
      "\n",
      "The classification loss after processing this batch is:  0.3985403776168823\n",
      "The representation loss after processing this batch is:  0.003891807049512863\n",
      "\n",
      "The classification loss after processing this batch is:  0.39551660418510437\n",
      "The representation loss after processing this batch is:  0.005663387477397919\n",
      "\n",
      "The classification loss after processing this batch is:  0.46996182203292847\n",
      "The representation loss after processing this batch is:  0.004980910569429398\n",
      "\n",
      "The classification loss after processing this batch is:  0.393177330493927\n",
      "The representation loss after processing this batch is:  0.005455769598484039\n",
      "\n",
      "The classification loss after processing this batch is:  0.49171188473701477\n",
      "The representation loss after processing this batch is:  0.005264934152364731\n",
      "\n",
      "The classification loss after processing this batch is:  0.4331292510032654\n",
      "The representation loss after processing this batch is:  0.004768121987581253\n",
      "\n",
      "The classification loss after processing this batch is:  0.3774014711380005\n",
      "The representation loss after processing this batch is:  0.004228755831718445\n",
      "\n",
      "The classification loss after processing this batch is:  0.4322962462902069\n",
      "The representation loss after processing this batch is:  0.0048096925020217896\n",
      "\n",
      "The classification loss after processing this batch is:  0.3966964781284332\n",
      "The representation loss after processing this batch is:  0.004356034100055695\n",
      "\n",
      "The classification loss after processing this batch is:  0.40087369084358215\n",
      "The representation loss after processing this batch is:  0.0035873912274837494\n",
      "\n",
      "The classification loss after processing this batch is:  0.6397265791893005\n",
      "The representation loss after processing this batch is:  0.005008365958929062\n",
      "\n",
      "The classification loss after processing this batch is:  0.606290876865387\n",
      "The representation loss after processing this batch is:  0.0047623999416828156\n",
      "\n",
      "The classification loss after processing this batch is:  0.4656001329421997\n",
      "The representation loss after processing this batch is:  0.005206063389778137\n",
      "\n",
      "The classification loss after processing this batch is:  0.42201557755470276\n",
      "The representation loss after processing this batch is:  0.004487521946430206\n",
      "\n",
      "The classification loss after processing this batch is:  0.34685376286506653\n",
      "The representation loss after processing this batch is:  0.005184076726436615\n",
      "\n",
      "The classification loss after processing this batch is:  0.30884698033332825\n",
      "The representation loss after processing this batch is:  0.004693713039159775\n",
      "\n",
      "The classification loss after processing this batch is:  0.5363720059394836\n",
      "The representation loss after processing this batch is:  0.005037587136030197\n",
      "\n",
      "The classification loss after processing this batch is:  0.3872435688972473\n",
      "The representation loss after processing this batch is:  0.004135746508836746\n",
      "\n",
      "The classification loss after processing this batch is:  0.40741923451423645\n",
      "The representation loss after processing this batch is:  0.0044798702001571655\n",
      "\n",
      "The classification loss after processing this batch is:  0.4594913125038147\n",
      "The representation loss after processing this batch is:  0.0039957985281944275\n",
      "\n",
      "The classification loss after processing this batch is:  0.32284146547317505\n",
      "The representation loss after processing this batch is:  0.004463262856006622\n",
      "\n",
      "The classification loss after processing this batch is:  0.3707491457462311\n",
      "The representation loss after processing this batch is:  0.004606842994689941\n",
      "\n",
      "The classification loss after processing this batch is:  0.38044682145118713\n",
      "The representation loss after processing this batch is:  0.0039884187281131744\n",
      "\n",
      "The classification loss after processing this batch is:  0.5739797949790955\n",
      "The representation loss after processing this batch is:  0.0038748793303966522\n",
      "\n",
      "The classification loss after processing this batch is:  0.5062758326530457\n",
      "The representation loss after processing this batch is:  0.003921709954738617\n",
      "\n",
      "The classification loss after processing this batch is:  0.46687257289886475\n",
      "The representation loss after processing this batch is:  0.003958463668823242\n",
      "\n",
      "The classification loss after processing this batch is:  0.447051465511322\n",
      "The representation loss after processing this batch is:  0.004038799554109573\n",
      "\n",
      "The classification loss after processing this batch is:  0.2986205220222473\n",
      "The representation loss after processing this batch is:  0.004082664847373962\n",
      "\n",
      "The classification loss after processing this batch is:  0.320341557264328\n",
      "The representation loss after processing this batch is:  0.003699786961078644\n",
      "\n",
      "The classification loss after processing this batch is:  0.29263412952423096\n",
      "The representation loss after processing this batch is:  0.0041226670145988464\n",
      "\n",
      "The classification loss after processing this batch is:  0.3097552955150604\n",
      "The representation loss after processing this batch is:  0.004342213273048401\n",
      "\n",
      "The classification loss after processing this batch is:  0.40659913420677185\n",
      "The representation loss after processing this batch is:  0.0038735978305339813\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.3556356430053711\n",
      "The representation loss after processing this batch is:  0.003982823342084885\n",
      "\n",
      "The classification loss after processing this batch is:  0.4028100371360779\n",
      "The representation loss after processing this batch is:  0.004666775465011597\n",
      "\n",
      "The classification loss after processing this batch is:  0.26060089468955994\n",
      "The representation loss after processing this batch is:  0.0036420784890651703\n",
      "\n",
      "The classification loss after processing this batch is:  0.3168196380138397\n",
      "The representation loss after processing this batch is:  0.004635483026504517\n",
      "\n",
      "The classification loss after processing this batch is:  0.33350667357444763\n",
      "The representation loss after processing this batch is:  0.005186699330806732\n",
      "\n",
      "The classification loss after processing this batch is:  0.4640487730503082\n",
      "The representation loss after processing this batch is:  0.004620164632797241\n",
      "\n",
      "The classification loss after processing this batch is:  0.2832048833370209\n",
      "The representation loss after processing this batch is:  0.0051539987325668335\n",
      "\n",
      "The classification loss after processing this batch is:  0.7012965679168701\n",
      "The representation loss after processing this batch is:  0.004990309476852417\n",
      "\n",
      "The classification loss after processing this batch is:  0.564696192741394\n",
      "The representation loss after processing this batch is:  0.004935555160045624\n",
      "\n",
      "The classification loss after processing this batch is:  0.5467043519020081\n",
      "The representation loss after processing this batch is:  0.004522264003753662\n",
      "\n",
      "The classification loss after processing this batch is:  0.42881545424461365\n",
      "The representation loss after processing this batch is:  0.004388764500617981\n",
      "\n",
      "The classification loss after processing this batch is:  0.3091851472854614\n",
      "The representation loss after processing this batch is:  0.004453688859939575\n",
      "\n",
      "The classification loss after processing this batch is:  0.3684406280517578\n",
      "The representation loss after processing this batch is:  0.004657857120037079\n",
      "\n",
      "The classification loss after processing this batch is:  0.3739372789859772\n",
      "The representation loss after processing this batch is:  0.004468414932489395\n",
      "\n",
      "The classification loss after processing this batch is:  0.3076397478580475\n",
      "The representation loss after processing this batch is:  0.004026405513286591\n",
      "\n",
      "The classification loss after processing this batch is:  0.21981483697891235\n",
      "The representation loss after processing this batch is:  0.0035948902368545532\n",
      "\n",
      "The classification loss after processing this batch is:  0.40717965364456177\n",
      "The representation loss after processing this batch is:  0.0037462934851646423\n",
      "\n",
      "The classification loss after processing this batch is:  0.47084492444992065\n",
      "The representation loss after processing this batch is:  0.0040014199912548065\n",
      "\n",
      "The classification loss after processing this batch is:  0.46548140048980713\n",
      "The representation loss after processing this batch is:  0.004298318177461624\n",
      "\n",
      "The classification loss after processing this batch is:  0.46829748153686523\n",
      "The representation loss after processing this batch is:  0.00389094278216362\n",
      "\n",
      "The classification loss after processing this batch is:  0.5874952077865601\n",
      "The representation loss after processing this batch is:  0.00446067750453949\n",
      "\n",
      "The classification loss after processing this batch is:  0.6743385195732117\n",
      "The representation loss after processing this batch is:  0.004142202436923981\n",
      "\n",
      "The classification loss after processing this batch is:  0.48503243923187256\n",
      "The representation loss after processing this batch is:  0.004200488328933716\n",
      "\n",
      "The classification loss after processing this batch is:  0.3887788653373718\n",
      "The representation loss after processing this batch is:  0.0039372630417346954\n",
      "\n",
      "The classification loss after processing this batch is:  0.4928557574748993\n",
      "The representation loss after processing this batch is:  0.004383362829685211\n",
      "\n",
      "The classification loss after processing this batch is:  0.4210872948169708\n",
      "The representation loss after processing this batch is:  0.0041402652859687805\n",
      "\n",
      "The classification loss after processing this batch is:  0.44758519530296326\n",
      "The representation loss after processing this batch is:  0.004031416028738022\n",
      "\n",
      "The classification loss after processing this batch is:  0.3146919906139374\n",
      "The representation loss after processing this batch is:  0.003890667110681534\n",
      "\n",
      "The classification loss after processing this batch is:  0.3266439139842987\n",
      "The representation loss after processing this batch is:  0.0038850009441375732\n",
      "\n",
      "The classification loss after processing this batch is:  0.2685444951057434\n",
      "The representation loss after processing this batch is:  0.004620827734470367\n",
      "\n",
      "The classification loss after processing this batch is:  0.42697635293006897\n",
      "The representation loss after processing this batch is:  0.003917276859283447\n",
      "\n",
      "The classification loss after processing this batch is:  0.4884280860424042\n",
      "The representation loss after processing this batch is:  0.0039038769900798798\n",
      "\n",
      "The classification loss after processing this batch is:  0.3225562274456024\n",
      "The representation loss after processing this batch is:  0.004390832036733627\n",
      "\n",
      "The classification loss after processing this batch is:  0.3623930513858795\n",
      "The representation loss after processing this batch is:  0.004025153815746307\n",
      "\n",
      "The classification loss after processing this batch is:  0.43246379494667053\n",
      "The representation loss after processing this batch is:  0.004164844751358032\n",
      "\n",
      "The classification loss after processing this batch is:  0.2279246300458908\n",
      "The representation loss after processing this batch is:  0.004569746553897858\n",
      "\n",
      "The classification loss after processing this batch is:  0.4509866535663605\n",
      "The representation loss after processing this batch is:  0.003987573087215424\n",
      "\n",
      "The classification loss after processing this batch is:  0.3660942018032074\n",
      "The representation loss after processing this batch is:  0.00378451868891716\n",
      "\n",
      "The classification loss after processing this batch is:  0.5195938348770142\n",
      "The representation loss after processing this batch is:  0.003648698329925537\n",
      "\n",
      "The classification loss after processing this batch is:  0.5351490378379822\n",
      "The representation loss after processing this batch is:  0.004484310746192932\n",
      "\n",
      "The classification loss after processing this batch is:  0.5380111932754517\n",
      "The representation loss after processing this batch is:  0.0036842897534370422\n",
      "\n",
      "The classification loss after processing this batch is:  0.23830750584602356\n",
      "The representation loss after processing this batch is:  0.003742806613445282\n",
      "\n",
      "The classification loss after processing this batch is:  0.23840239644050598\n",
      "The representation loss after processing this batch is:  0.004215318709611893\n",
      "\n",
      "The classification loss after processing this batch is:  0.35865259170532227\n",
      "The representation loss after processing this batch is:  0.004324864596128464\n",
      "\n",
      "The classification loss after processing this batch is:  0.27863818407058716\n",
      "The representation loss after processing this batch is:  0.004985637962818146\n",
      "\n",
      "The classification loss after processing this batch is:  0.45294398069381714\n",
      "The representation loss after processing this batch is:  0.004817336797714233\n",
      "\n",
      "The classification loss after processing this batch is:  0.3338660001754761\n",
      "The representation loss after processing this batch is:  0.005571004003286362\n",
      "\n",
      "The classification loss after processing this batch is:  0.4274250864982605\n",
      "The representation loss after processing this batch is:  0.0042725615203380585\n",
      "\n",
      "The classification loss after processing this batch is:  0.46134090423583984\n",
      "The representation loss after processing this batch is:  0.0042966753244400024\n",
      "\n",
      "The classification loss after processing this batch is:  0.3406802713871002\n",
      "The representation loss after processing this batch is:  0.004237562417984009\n",
      "\n",
      "The classification loss after processing this batch is:  0.3143934905529022\n",
      "The representation loss after processing this batch is:  0.005278721451759338\n",
      "\n",
      "The classification loss after processing this batch is:  0.3960728347301483\n",
      "The representation loss after processing this batch is:  0.004262194037437439\n",
      "\n",
      "The classification loss after processing this batch is:  0.3781315088272095\n",
      "The representation loss after processing this batch is:  0.004221811890602112\n",
      "\n",
      "The classification loss after processing this batch is:  0.5471430420875549\n",
      "The representation loss after processing this batch is:  0.004902634769678116\n",
      "\n",
      "The classification loss after processing this batch is:  0.6103130578994751\n",
      "The representation loss after processing this batch is:  0.004453741014003754\n",
      "\n",
      "The classification loss after processing this batch is:  0.6182304620742798\n",
      "The representation loss after processing this batch is:  0.003856956958770752\n",
      "\n",
      "The classification loss after processing this batch is:  0.35771751403808594\n",
      "The representation loss after processing this batch is:  0.0039467960596084595\n",
      "\n",
      "The classification loss after processing this batch is:  0.29225102066993713\n",
      "The representation loss after processing this batch is:  0.004135742783546448\n",
      "\n",
      "The classification loss after processing this batch is:  0.3243914246559143\n",
      "The representation loss after processing this batch is:  0.0039675273001194\n",
      "\n",
      "The classification loss after processing this batch is:  0.28778061270713806\n",
      "The representation loss after processing this batch is:  0.004214651882648468\n",
      "\n",
      "The classification loss after processing this batch is:  0.41760390996932983\n",
      "The representation loss after processing this batch is:  0.0038233138620853424\n",
      "\n",
      "The classification loss after processing this batch is:  0.3554234206676483\n",
      "The representation loss after processing this batch is:  0.004167824983596802\n",
      "\n",
      "The classification loss after processing this batch is:  0.3981446921825409\n",
      "The representation loss after processing this batch is:  0.004624679684638977\n",
      "\n",
      "The classification loss after processing this batch is:  0.2912115752696991\n",
      "The representation loss after processing this batch is:  0.0043289922177791595\n",
      "\n",
      "The classification loss after processing this batch is:  0.38079458475112915\n",
      "The representation loss after processing this batch is:  0.0035810545086860657\n",
      "\n",
      "The classification loss after processing this batch is:  0.3288702368736267\n",
      "The representation loss after processing this batch is:  0.003976181149482727\n",
      "\n",
      "The classification loss after processing this batch is:  0.44260019063949585\n",
      "The representation loss after processing this batch is:  0.0037546157836914062\n",
      "\n",
      "The classification loss after processing this batch is:  0.3750976026058197\n",
      "The representation loss after processing this batch is:  0.00423504039645195\n",
      "\n",
      "The classification loss after processing this batch is:  0.34660106897354126\n",
      "The representation loss after processing this batch is:  0.0041226595640182495\n",
      "\n",
      "The classification loss after processing this batch is:  0.3745986521244049\n",
      "The representation loss after processing this batch is:  0.004172287881374359\n",
      "\n",
      "The classification loss after processing this batch is:  0.4528628885746002\n",
      "The representation loss after processing this batch is:  0.004625260829925537\n",
      "\n",
      "The classification loss after processing this batch is:  0.30927082896232605\n",
      "The representation loss after processing this batch is:  0.0038620978593826294\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.23296216130256653\n",
      "The representation loss after processing this batch is:  0.0038847848773002625\n",
      "\n",
      "The classification loss after processing this batch is:  0.3477749526500702\n",
      "The representation loss after processing this batch is:  0.00454210489988327\n",
      "\n",
      "The classification loss after processing this batch is:  0.3055764138698578\n",
      "The representation loss after processing this batch is:  0.003651157021522522\n",
      "\n",
      "The classification loss after processing this batch is:  0.5058057308197021\n",
      "The representation loss after processing this batch is:  0.0033433251082897186\n",
      "\n",
      "The classification loss after processing this batch is:  0.39890173077583313\n",
      "The representation loss after processing this batch is:  0.004579618573188782\n",
      "\n",
      "The classification loss after processing this batch is:  0.3670000731945038\n",
      "The representation loss after processing this batch is:  0.00548534095287323\n",
      "\n",
      "The classification loss after processing this batch is:  0.26684099435806274\n",
      "The representation loss after processing this batch is:  0.005035635083913803\n",
      "\n",
      "The classification loss after processing this batch is:  0.2957700788974762\n",
      "The representation loss after processing this batch is:  0.00423741340637207\n",
      "\n",
      "The classification loss after processing this batch is:  0.5364293456077576\n",
      "The representation loss after processing this batch is:  0.004119507968425751\n",
      "\n",
      "The classification loss after processing this batch is:  0.22101248800754547\n",
      "The representation loss after processing this batch is:  0.0043867602944374084\n",
      "\n",
      "The classification loss after processing this batch is:  0.33249539136886597\n",
      "The representation loss after processing this batch is:  0.004672974348068237\n",
      "\n",
      "The classification loss after processing this batch is:  0.3638501763343811\n",
      "The representation loss after processing this batch is:  0.003624536097049713\n",
      "\n",
      "The classification loss after processing this batch is:  0.4746206998825073\n",
      "The representation loss after processing this batch is:  0.005118098109960556\n",
      "\n",
      "The classification loss after processing this batch is:  0.338041216135025\n",
      "The representation loss after processing this batch is:  0.004021063446998596\n",
      "\n",
      "The classification loss after processing this batch is:  0.42565393447875977\n",
      "The representation loss after processing this batch is:  0.003686569631099701\n",
      "\n",
      "The classification loss after processing this batch is:  0.26350483298301697\n",
      "The representation loss after processing this batch is:  0.004696384072303772\n",
      "\n",
      "The classification loss after processing this batch is:  0.23315869271755219\n",
      "The representation loss after processing this batch is:  0.004442036151885986\n",
      "\n",
      "The classification loss after processing this batch is:  0.39716342091560364\n",
      "The representation loss after processing this batch is:  0.004979126155376434\n",
      "\n",
      "The classification loss after processing this batch is:  0.3021268844604492\n",
      "The representation loss after processing this batch is:  0.005433946847915649\n",
      "\n",
      "The classification loss after processing this batch is:  0.25341886281967163\n",
      "The representation loss after processing this batch is:  0.005021318793296814\n",
      "\n",
      "The classification loss after processing this batch is:  0.3338986337184906\n",
      "The representation loss after processing this batch is:  0.004308711737394333\n",
      "\n",
      "The classification loss after processing this batch is:  0.47409820556640625\n",
      "The representation loss after processing this batch is:  0.0044449009001255035\n",
      "\n",
      "The classification loss after processing this batch is:  0.4084053337574005\n",
      "The representation loss after processing this batch is:  0.004479534924030304\n",
      "\n",
      "The classification loss after processing this batch is:  0.33088749647140503\n",
      "The representation loss after processing this batch is:  0.003575921058654785\n",
      "\n",
      "The classification loss after processing this batch is:  0.3770361840724945\n",
      "The representation loss after processing this batch is:  0.003969743847846985\n",
      "\n",
      "The classification loss after processing this batch is:  0.4813247621059418\n",
      "The representation loss after processing this batch is:  0.004058927297592163\n",
      "\n",
      "The classification loss after processing this batch is:  0.44754505157470703\n",
      "The representation loss after processing this batch is:  0.004739303141832352\n",
      "\n",
      "The classification loss after processing this batch is:  0.4013971984386444\n",
      "The representation loss after processing this batch is:  0.0038793571293354034\n",
      "\n",
      "The classification loss after processing this batch is:  0.45231419801712036\n",
      "The representation loss after processing this batch is:  0.004210479557514191\n",
      "\n",
      "The classification loss after processing this batch is:  0.48207753896713257\n",
      "The representation loss after processing this batch is:  0.004743669182062149\n",
      "\n",
      "The classification loss after processing this batch is:  0.2949237525463104\n",
      "The representation loss after processing this batch is:  0.004370510578155518\n",
      "\n",
      "The classification loss after processing this batch is:  0.2800658643245697\n",
      "The representation loss after processing this batch is:  0.004555709660053253\n",
      "\n",
      "The classification loss after processing this batch is:  0.29855671525001526\n",
      "The representation loss after processing this batch is:  0.0042298175394535065\n",
      "\n",
      "The classification loss after processing this batch is:  0.3318709135055542\n",
      "The representation loss after processing this batch is:  0.003481552004814148\n",
      "\n",
      "The classification loss after processing this batch is:  0.3860393762588501\n",
      "The representation loss after processing this batch is:  0.004314623773097992\n",
      "\n",
      "The classification loss after processing this batch is:  0.3128848373889923\n",
      "The representation loss after processing this batch is:  0.004529416561126709\n",
      "\n",
      "The classification loss after processing this batch is:  0.1996651142835617\n",
      "The representation loss after processing this batch is:  0.0042847394943237305\n",
      "\n",
      "The classification loss after processing this batch is:  0.19222284853458405\n",
      "The representation loss after processing this batch is:  0.004642024636268616\n",
      "\n",
      "The classification loss after processing this batch is:  0.28390371799468994\n",
      "The representation loss after processing this batch is:  0.004328340291976929\n",
      "\n",
      "The classification loss after processing this batch is:  0.33347418904304504\n",
      "The representation loss after processing this batch is:  0.005194924771785736\n",
      "\n",
      "The classification loss after processing this batch is:  0.35261470079421997\n",
      "The representation loss after processing this batch is:  0.004356101155281067\n",
      "\n",
      "The classification loss after processing this batch is:  0.2521451413631439\n",
      "The representation loss after processing this batch is:  0.0038047805428504944\n",
      "\n",
      "The classification loss after processing this batch is:  0.23731327056884766\n",
      "The representation loss after processing this batch is:  0.0038863345980644226\n",
      "\n",
      "The classification loss after processing this batch is:  0.2941914200782776\n",
      "The representation loss after processing this batch is:  0.0052686408162117004\n",
      "\n",
      "The classification loss after processing this batch is:  0.25910449028015137\n",
      "The representation loss after processing this batch is:  0.005753330886363983\n",
      "\n",
      "The classification loss after processing this batch is:  0.20737546682357788\n",
      "The representation loss after processing this batch is:  0.006187707185745239\n",
      "\n",
      "The classification loss after processing this batch is:  0.24607671797275543\n",
      "The representation loss after processing this batch is:  0.00482824444770813\n",
      "\n",
      "The classification loss after processing this batch is:  0.40541741251945496\n",
      "The representation loss after processing this batch is:  0.004693977534770966\n",
      "\n",
      "The classification loss after processing this batch is:  0.2200758159160614\n",
      "The representation loss after processing this batch is:  0.004802152514457703\n",
      "\n",
      "The classification loss after processing this batch is:  0.16516992449760437\n",
      "The representation loss after processing this batch is:  0.004604794085025787\n",
      "\n",
      "The classification loss after processing this batch is:  0.2149309515953064\n",
      "The representation loss after processing this batch is:  0.0052269697189331055\n",
      "\n",
      "The classification loss after processing this batch is:  0.24586616456508636\n",
      "The representation loss after processing this batch is:  0.0045371875166893005\n",
      "\n",
      "The classification loss after processing this batch is:  0.1844661384820938\n",
      "The representation loss after processing this batch is:  0.004142507910728455\n",
      "\n",
      "The classification loss after processing this batch is:  0.2639186978340149\n",
      "The representation loss after processing this batch is:  0.004542849957942963\n",
      "\n",
      "The classification loss after processing this batch is:  0.2623100280761719\n",
      "The representation loss after processing this batch is:  0.004588514566421509\n",
      "\n",
      "The classification loss after processing this batch is:  0.6136370897293091\n",
      "The representation loss after processing this batch is:  0.0044679194688797\n",
      "\n",
      "The classification loss after processing this batch is:  0.5990980863571167\n",
      "The representation loss after processing this batch is:  0.004806645214557648\n",
      "\n",
      "The classification loss after processing this batch is:  0.45147228240966797\n",
      "The representation loss after processing this batch is:  0.004731655120849609\n",
      "\n",
      "The classification loss after processing this batch is:  0.2267703115940094\n",
      "The representation loss after processing this batch is:  0.004305683076381683\n",
      "\n",
      "The classification loss after processing this batch is:  0.18773037195205688\n",
      "The representation loss after processing this batch is:  0.004568830132484436\n",
      "\n",
      "The classification loss after processing this batch is:  0.22581404447555542\n",
      "The representation loss after processing this batch is:  0.0038838647305965424\n",
      "\n",
      "The classification loss after processing this batch is:  0.27411559224128723\n",
      "The representation loss after processing this batch is:  0.0035489797592163086\n",
      "\n",
      "The classification loss after processing this batch is:  0.5565151572227478\n",
      "The representation loss after processing this batch is:  0.004133008420467377\n",
      "\n",
      "The classification loss after processing this batch is:  0.2934223711490631\n",
      "The representation loss after processing this batch is:  0.0036927983164787292\n",
      "\n",
      "The classification loss after processing this batch is:  0.17764383554458618\n",
      "The representation loss after processing this batch is:  0.005351945757865906\n",
      "\n",
      "The classification loss after processing this batch is:  0.3494287133216858\n",
      "The representation loss after processing this batch is:  0.004310108721256256\n",
      "\n",
      "The classification loss after processing this batch is:  0.28174883127212524\n",
      "The representation loss after processing this batch is:  0.005393654108047485\n",
      "\n",
      "The classification loss after processing this batch is:  0.3790965974330902\n",
      "The representation loss after processing this batch is:  0.0037633925676345825\n",
      "\n",
      "The classification loss after processing this batch is:  0.26727861166000366\n",
      "The representation loss after processing this batch is:  0.00356350839138031\n",
      "\n",
      "The classification loss after processing this batch is:  0.35496485233306885\n",
      "The representation loss after processing this batch is:  0.0034834593534469604\n",
      "\n",
      "The classification loss after processing this batch is:  0.3049401342868805\n",
      "The representation loss after processing this batch is:  0.003934387117624283\n",
      "\n",
      "The classification loss after processing this batch is:  0.355540007352829\n",
      "The representation loss after processing this batch is:  0.0040442124009132385\n",
      "\n",
      "The classification loss after processing this batch is:  0.25011035799980164\n",
      "The representation loss after processing this batch is:  0.004379764199256897\n",
      "\n",
      "The classification loss after processing this batch is:  0.3614937365055084\n",
      "The representation loss after processing this batch is:  0.004749491810798645\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.26923903822898865\n",
      "The representation loss after processing this batch is:  0.003481917083263397\n",
      "\n",
      "The classification loss after processing this batch is:  0.40670570731163025\n",
      "The representation loss after processing this batch is:  0.0040700435638427734\n",
      "\n",
      "The classification loss after processing this batch is:  0.40058279037475586\n",
      "The representation loss after processing this batch is:  0.003781009465456009\n",
      "\n",
      "The classification loss after processing this batch is:  0.4441238045692444\n",
      "The representation loss after processing this batch is:  0.003821447491645813\n",
      "\n",
      "The classification loss after processing this batch is:  0.3499308228492737\n",
      "The representation loss after processing this batch is:  0.0043133459985256195\n",
      "\n",
      "The classification loss after processing this batch is:  0.4044044613838196\n",
      "The representation loss after processing this batch is:  0.004698228091001511\n",
      "\n",
      "The classification loss after processing this batch is:  0.2698432207107544\n",
      "The representation loss after processing this batch is:  0.003558225929737091\n",
      "\n",
      "The classification loss after processing this batch is:  0.6303132176399231\n",
      "The representation loss after processing this batch is:  0.003959890455007553\n",
      "\n",
      "The classification loss after processing this batch is:  0.4398473799228668\n",
      "The representation loss after processing this batch is:  0.0034250281751155853\n",
      "\n",
      "The classification loss after processing this batch is:  0.38246217370033264\n",
      "The representation loss after processing this batch is:  0.003804463893175125\n",
      "\n",
      "The classification loss after processing this batch is:  0.5144774317741394\n",
      "The representation loss after processing this batch is:  0.0042797960340976715\n",
      "\n",
      "The classification loss after processing this batch is:  0.4611382484436035\n",
      "The representation loss after processing this batch is:  0.00446426123380661\n",
      "\n",
      "The classification loss after processing this batch is:  0.2865281105041504\n",
      "The representation loss after processing this batch is:  0.004153087735176086\n",
      "\n",
      "The classification loss after processing this batch is:  0.4962061047554016\n",
      "The representation loss after processing this batch is:  0.004662230610847473\n",
      "\n",
      "The classification loss after processing this batch is:  0.4360283613204956\n",
      "The representation loss after processing this batch is:  0.004179932177066803\n",
      "\n",
      "The classification loss after processing this batch is:  0.5273747444152832\n",
      "The representation loss after processing this batch is:  0.003484223037958145\n",
      "\n",
      "The classification loss after processing this batch is:  0.2988784611225128\n",
      "The representation loss after processing this batch is:  0.0035610347986221313\n",
      "\n",
      "The classification loss after processing this batch is:  0.2868098318576813\n",
      "The representation loss after processing this batch is:  0.0040079206228256226\n",
      "\n",
      "The classification loss after processing this batch is:  0.30449169874191284\n",
      "The representation loss after processing this batch is:  0.0037615112960338593\n",
      "\n",
      "The classification loss after processing this batch is:  0.39812150597572327\n",
      "The representation loss after processing this batch is:  0.003576848655939102\n",
      "\n",
      "The classification loss after processing this batch is:  0.31387919187545776\n",
      "The representation loss after processing this batch is:  0.004076994955539703\n",
      "\n",
      "The classification loss after processing this batch is:  0.18383553624153137\n",
      "The representation loss after processing this batch is:  0.00448434054851532\n",
      "\n",
      "The classification loss after processing this batch is:  0.19525223970413208\n",
      "The representation loss after processing this batch is:  0.003925710916519165\n",
      "\n",
      "The classification loss after processing this batch is:  0.27013951539993286\n",
      "The representation loss after processing this batch is:  0.003788374364376068\n",
      "\n",
      "The classification loss after processing this batch is:  0.28197890520095825\n",
      "The representation loss after processing this batch is:  0.004951588809490204\n",
      "\n",
      "The classification loss after processing this batch is:  0.35931459069252014\n",
      "The representation loss after processing this batch is:  0.004402313381433487\n",
      "\n",
      "The classification loss after processing this batch is:  0.32711294293403625\n",
      "The representation loss after processing this batch is:  0.0054677799344062805\n",
      "\n",
      "The classification loss after processing this batch is:  0.25352585315704346\n",
      "The representation loss after processing this batch is:  0.004381582140922546\n",
      "\n",
      "The classification loss after processing this batch is:  0.19555935263633728\n",
      "The representation loss after processing this batch is:  0.004303261637687683\n",
      "\n",
      "The classification loss after processing this batch is:  0.26537591218948364\n",
      "The representation loss after processing this batch is:  0.0047139450907707214\n",
      "\n",
      "The classification loss after processing this batch is:  0.3040691912174225\n",
      "The representation loss after processing this batch is:  0.004031643271446228\n",
      "\n",
      "The classification loss after processing this batch is:  0.2104514092206955\n",
      "The representation loss after processing this batch is:  0.004225835204124451\n",
      "\n",
      "The classification loss after processing this batch is:  0.3092208504676819\n",
      "The representation loss after processing this batch is:  0.003837496042251587\n",
      "\n",
      "The classification loss after processing this batch is:  0.469473272562027\n",
      "The representation loss after processing this batch is:  0.004555348306894302\n",
      "\n",
      "The classification loss after processing this batch is:  0.31642574071884155\n",
      "The representation loss after processing this batch is:  0.004137419164180756\n",
      "\n",
      "The classification loss after processing this batch is:  0.3230780065059662\n",
      "The representation loss after processing this batch is:  0.0037138089537620544\n",
      "\n",
      "The classification loss after processing this batch is:  0.31969329714775085\n",
      "The representation loss after processing this batch is:  0.004082374274730682\n",
      "\n",
      "The classification loss after processing this batch is:  0.2555091083049774\n",
      "The representation loss after processing this batch is:  0.0037614330649375916\n",
      "\n",
      "The classification loss after processing this batch is:  0.3050731122493744\n",
      "The representation loss after processing this batch is:  0.0036419369280338287\n",
      "\n",
      "The classification loss after processing this batch is:  0.3908018469810486\n",
      "The representation loss after processing this batch is:  0.004393391311168671\n",
      "\n",
      "The classification loss after processing this batch is:  0.23026837408542633\n",
      "The representation loss after processing this batch is:  0.004485014826059341\n",
      "\n",
      "The classification loss after processing this batch is:  0.3046492636203766\n",
      "The representation loss after processing this batch is:  0.0037567615509033203\n",
      "\n",
      "The classification loss after processing this batch is:  0.2808837890625\n",
      "The representation loss after processing this batch is:  0.004436478018760681\n",
      "\n",
      "The classification loss after processing this batch is:  0.3614344596862793\n",
      "The representation loss after processing this batch is:  0.003173060715198517\n",
      "\n",
      "The classification loss after processing this batch is:  0.35451000928878784\n",
      "The representation loss after processing this batch is:  0.003987867385149002\n",
      "\n",
      "The classification loss after processing this batch is:  0.29787477850914\n",
      "The representation loss after processing this batch is:  0.004137501120567322\n",
      "\n",
      "The classification loss after processing this batch is:  0.2787688076496124\n",
      "The representation loss after processing this batch is:  0.004282914102077484\n",
      "\n",
      "The classification loss after processing this batch is:  0.3326627314090729\n",
      "The representation loss after processing this batch is:  0.004334732890129089\n",
      "\n",
      "The classification loss after processing this batch is:  0.341424822807312\n",
      "The representation loss after processing this batch is:  0.003991231322288513\n",
      "\n",
      "The classification loss after processing this batch is:  0.3485068678855896\n",
      "The representation loss after processing this batch is:  0.0038052722811698914\n",
      "\n",
      "The classification loss after processing this batch is:  0.2608776390552521\n",
      "The representation loss after processing this batch is:  0.004344522953033447\n",
      "\n",
      "The classification loss after processing this batch is:  0.35843953490257263\n",
      "The representation loss after processing this batch is:  0.003918197005987167\n",
      "\n",
      "The classification loss after processing this batch is:  0.25033581256866455\n",
      "The representation loss after processing this batch is:  0.0038019269704818726\n",
      "\n",
      "The classification loss after processing this batch is:  0.25314944982528687\n",
      "The representation loss after processing this batch is:  0.0035543888807296753\n",
      "\n",
      "The classification loss after processing this batch is:  0.39180660247802734\n",
      "The representation loss after processing this batch is:  0.003972459584474564\n",
      "\n",
      "The classification loss after processing this batch is:  0.356973797082901\n",
      "The representation loss after processing this batch is:  0.003961488604545593\n",
      "\n",
      "The classification loss after processing this batch is:  0.29616114497184753\n",
      "The representation loss after processing this batch is:  0.00383676216006279\n",
      "\n",
      "The classification loss after processing this batch is:  0.27217382192611694\n",
      "The representation loss after processing this batch is:  0.004089199006557465\n",
      "\n",
      "The classification loss after processing this batch is:  0.29658952355384827\n",
      "The representation loss after processing this batch is:  0.003518335521221161\n",
      "\n",
      "The classification loss after processing this batch is:  0.36914965510368347\n",
      "The representation loss after processing this batch is:  0.004060022532939911\n",
      "\n",
      "The classification loss after processing this batch is:  0.34415093064308167\n",
      "The representation loss after processing this batch is:  0.0035921186208724976\n",
      "\n",
      "The classification loss after processing this batch is:  0.2399447113275528\n",
      "The representation loss after processing this batch is:  0.0035648569464683533\n",
      "\n",
      "The classification loss after processing this batch is:  0.48399466276168823\n",
      "The representation loss after processing this batch is:  0.0039286017417907715\n",
      "\n",
      "The classification loss after processing this batch is:  0.32574737071990967\n",
      "The representation loss after processing this batch is:  0.00415990874171257\n",
      "\n",
      "The classification loss after processing this batch is:  0.3765171766281128\n",
      "The representation loss after processing this batch is:  0.0036792978644371033\n",
      "\n",
      "The classification loss after processing this batch is:  0.31879279017448425\n",
      "The representation loss after processing this batch is:  0.0029270872473716736\n",
      "\n",
      "The classification loss after processing this batch is:  0.2499653548002243\n",
      "The representation loss after processing this batch is:  0.004148639738559723\n",
      "\n",
      "The classification loss after processing this batch is:  0.31676551699638367\n",
      "The representation loss after processing this batch is:  0.003310609608888626\n",
      "\n",
      "The classification loss after processing this batch is:  0.31240013241767883\n",
      "The representation loss after processing this batch is:  0.0038927793502807617\n",
      "\n",
      "The classification loss after processing this batch is:  0.2965589761734009\n",
      "The representation loss after processing this batch is:  0.0034775175154209137\n",
      "\n",
      "The classification loss after processing this batch is:  0.5061838030815125\n",
      "The representation loss after processing this batch is:  0.003665320575237274\n",
      "\n",
      "The classification loss after processing this batch is:  0.31227731704711914\n",
      "The representation loss after processing this batch is:  0.0035816244781017303\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2924303710460663\n",
      "The representation loss after processing this batch is:  0.004931427538394928\n",
      "\n",
      "The classification loss after processing this batch is:  0.3548497259616852\n",
      "The representation loss after processing this batch is:  0.004218339920043945\n",
      "\n",
      "The classification loss after processing this batch is:  0.3063424229621887\n",
      "The representation loss after processing this batch is:  0.004599928855895996\n",
      "\n",
      "The classification loss after processing this batch is:  0.4547230303287506\n",
      "The representation loss after processing this batch is:  0.004399016499519348\n",
      "\n",
      "The classification loss after processing this batch is:  0.30752792954444885\n",
      "The representation loss after processing this batch is:  0.0036793500185012817\n",
      "\n",
      "The classification loss after processing this batch is:  0.3513754904270172\n",
      "The representation loss after processing this batch is:  0.0038115717470645905\n",
      "\n",
      "The classification loss after processing this batch is:  0.5862030386924744\n",
      "The representation loss after processing this batch is:  0.003864150494337082\n",
      "\n",
      "The classification loss after processing this batch is:  0.3818711042404175\n",
      "The representation loss after processing this batch is:  0.0036159567534923553\n",
      "\n",
      "The classification loss after processing this batch is:  0.27476978302001953\n",
      "The representation loss after processing this batch is:  0.004182733595371246\n",
      "\n",
      "The classification loss after processing this batch is:  0.4268709123134613\n",
      "The representation loss after processing this batch is:  0.0035592205822467804\n",
      "\n",
      "The classification loss after processing this batch is:  0.36566659808158875\n",
      "The representation loss after processing this batch is:  0.0038134045898914337\n",
      "\n",
      "The classification loss after processing this batch is:  0.3251153826713562\n",
      "The representation loss after processing this batch is:  0.0038396380841732025\n",
      "\n",
      "The classification loss after processing this batch is:  0.24202853441238403\n",
      "The representation loss after processing this batch is:  0.0035353824496269226\n",
      "\n",
      "The classification loss after processing this batch is:  0.32358404994010925\n",
      "The representation loss after processing this batch is:  0.0033394843339920044\n",
      "\n",
      "The classification loss after processing this batch is:  0.34982410073280334\n",
      "The representation loss after processing this batch is:  0.0041892752051353455\n",
      "\n",
      "The classification loss after processing this batch is:  0.3107925057411194\n",
      "The representation loss after processing this batch is:  0.004660964012145996\n",
      "\n",
      "The classification loss after processing this batch is:  0.4029441773891449\n",
      "The representation loss after processing this batch is:  0.003912828862667084\n",
      "\n",
      "The classification loss after processing this batch is:  0.38436105847358704\n",
      "The representation loss after processing this batch is:  0.003948099911212921\n",
      "\n",
      "The classification loss after processing this batch is:  0.4056382477283478\n",
      "The representation loss after processing this batch is:  0.004417814314365387\n",
      "\n",
      "The classification loss after processing this batch is:  0.3169163465499878\n",
      "The representation loss after processing this batch is:  0.004762366414070129\n",
      "\n",
      "The classification loss after processing this batch is:  0.2550465762615204\n",
      "The representation loss after processing this batch is:  0.0037192441523075104\n",
      "\n",
      "The classification loss after processing this batch is:  0.21488836407661438\n",
      "The representation loss after processing this batch is:  0.003437332808971405\n",
      "\n",
      "The classification loss after processing this batch is:  0.2831079065799713\n",
      "The representation loss after processing this batch is:  0.003915678709745407\n",
      "\n",
      "The classification loss after processing this batch is:  0.2611740529537201\n",
      "The representation loss after processing this batch is:  0.003881402313709259\n",
      "\n",
      "The classification loss after processing this batch is:  0.38283979892730713\n",
      "The representation loss after processing this batch is:  0.004240848124027252\n",
      "\n",
      "The classification loss after processing this batch is:  0.49741628766059875\n",
      "The representation loss after processing this batch is:  0.004209723323583603\n",
      "\n",
      "The classification loss after processing this batch is:  0.3185045123100281\n",
      "The representation loss after processing this batch is:  0.003906436264514923\n",
      "\n",
      "The classification loss after processing this batch is:  0.26984167098999023\n",
      "The representation loss after processing this batch is:  0.004319675266742706\n",
      "\n",
      "The classification loss after processing this batch is:  0.311335951089859\n",
      "The representation loss after processing this batch is:  0.0034351348876953125\n",
      "\n",
      "The classification loss after processing this batch is:  0.228107288479805\n",
      "The representation loss after processing this batch is:  0.004285681992769241\n",
      "\n",
      "The classification loss after processing this batch is:  0.19761060178279877\n",
      "The representation loss after processing this batch is:  0.0037060752511024475\n",
      "\n",
      "The classification loss after processing this batch is:  0.3388202488422394\n",
      "The representation loss after processing this batch is:  0.0034991130232810974\n",
      "\n",
      "The classification loss after processing this batch is:  0.3295232653617859\n",
      "The representation loss after processing this batch is:  0.005778171122074127\n",
      "\n",
      "The classification loss after processing this batch is:  0.2495185285806656\n",
      "The representation loss after processing this batch is:  0.00436021015048027\n",
      "\n",
      "The classification loss after processing this batch is:  0.4545130133628845\n",
      "The representation loss after processing this batch is:  0.005014948546886444\n",
      "\n",
      "The classification loss after processing this batch is:  0.405880868434906\n",
      "The representation loss after processing this batch is:  0.003382507711648941\n",
      "\n",
      "The classification loss after processing this batch is:  0.39070987701416016\n",
      "The representation loss after processing this batch is:  0.003967881202697754\n",
      "\n",
      "The classification loss after processing this batch is:  0.4599558413028717\n",
      "The representation loss after processing this batch is:  0.004002295434474945\n",
      "\n",
      "The classification loss after processing this batch is:  0.33344152569770813\n",
      "The representation loss after processing this batch is:  0.0037793107330799103\n",
      "\n",
      "The classification loss after processing this batch is:  0.24045486748218536\n",
      "The representation loss after processing this batch is:  0.0042597390711307526\n",
      "\n",
      "The classification loss after processing this batch is:  0.3779347836971283\n",
      "The representation loss after processing this batch is:  0.003730885684490204\n",
      "\n",
      "The classification loss after processing this batch is:  0.5766662359237671\n",
      "The representation loss after processing this batch is:  0.0054301917552948\n",
      "\n",
      "The classification loss after processing this batch is:  0.44086208939552307\n",
      "The representation loss after processing this batch is:  0.004902135580778122\n",
      "\n",
      "The classification loss after processing this batch is:  0.2844824194908142\n",
      "The representation loss after processing this batch is:  0.00514630600810051\n",
      "\n",
      "The classification loss after processing this batch is:  0.31977102160453796\n",
      "The representation loss after processing this batch is:  0.004756134003400803\n",
      "\n",
      "The classification loss after processing this batch is:  0.26996657252311707\n",
      "The representation loss after processing this batch is:  0.0049763023853302\n",
      "\n",
      "The classification loss after processing this batch is:  0.33920833468437195\n",
      "The representation loss after processing this batch is:  0.004304178059101105\n",
      "\n",
      "The classification loss after processing this batch is:  0.20081287622451782\n",
      "The representation loss after processing this batch is:  0.004087850451469421\n",
      "\n",
      "The classification loss after processing this batch is:  0.386192262172699\n",
      "The representation loss after processing this batch is:  0.0035240240395069122\n",
      "\n",
      "The classification loss after processing this batch is:  0.3021789789199829\n",
      "The representation loss after processing this batch is:  0.0035941749811172485\n",
      "\n",
      "The classification loss after processing this batch is:  0.48948347568511963\n",
      "The representation loss after processing this batch is:  0.0041028037667274475\n",
      "\n",
      "The classification loss after processing this batch is:  0.284705251455307\n",
      "The representation loss after processing this batch is:  0.004092387855052948\n",
      "\n",
      "The classification loss after processing this batch is:  0.34420496225357056\n",
      "The representation loss after processing this batch is:  0.003469809889793396\n",
      "\n",
      "The classification loss after processing this batch is:  0.37518322467803955\n",
      "The representation loss after processing this batch is:  0.0035219453275203705\n",
      "\n",
      "The classification loss after processing this batch is:  0.3663705289363861\n",
      "The representation loss after processing this batch is:  0.004142384976148605\n",
      "\n",
      "The classification loss after processing this batch is:  0.25384944677352905\n",
      "The representation loss after processing this batch is:  0.0038405880331993103\n",
      "\n",
      "The classification loss after processing this batch is:  0.3548721671104431\n",
      "The representation loss after processing this batch is:  0.004115208983421326\n",
      "\n",
      "The classification loss after processing this batch is:  0.3959540128707886\n",
      "The representation loss after processing this batch is:  0.0035988986492156982\n",
      "\n",
      "The classification loss after processing this batch is:  0.3596425950527191\n",
      "The representation loss after processing this batch is:  0.0034552551805973053\n",
      "\n",
      "The classification loss after processing this batch is:  0.36700084805488586\n",
      "The representation loss after processing this batch is:  0.0034792646765708923\n",
      "\n",
      "The classification loss after processing this batch is:  0.27076438069343567\n",
      "The representation loss after processing this batch is:  0.0039857253432273865\n",
      "\n",
      "The classification loss after processing this batch is:  0.4442470371723175\n",
      "The representation loss after processing this batch is:  0.004197236150503159\n",
      "\n",
      "The classification loss after processing this batch is:  0.3954964876174927\n",
      "The representation loss after processing this batch is:  0.003945671021938324\n",
      "\n",
      "The classification loss after processing this batch is:  0.23099413514137268\n",
      "The representation loss after processing this batch is:  0.0040788352489471436\n",
      "\n",
      "The classification loss after processing this batch is:  0.315597802400589\n",
      "The representation loss after processing this batch is:  0.004208102822303772\n",
      "\n",
      "The classification loss after processing this batch is:  0.5185429453849792\n",
      "The representation loss after processing this batch is:  0.004168357700109482\n",
      "\n",
      "The classification loss after processing this batch is:  0.44386324286460876\n",
      "The representation loss after processing this batch is:  0.0039029233157634735\n",
      "\n",
      "The classification loss after processing this batch is:  0.44997531175613403\n",
      "The representation loss after processing this batch is:  0.0048536136746406555\n",
      "\n",
      "The classification loss after processing this batch is:  0.5120307803153992\n",
      "The representation loss after processing this batch is:  0.003475755453109741\n",
      "\n",
      "The classification loss after processing this batch is:  0.39580264687538147\n",
      "The representation loss after processing this batch is:  0.0036288313567638397\n",
      "\n",
      "The classification loss after processing this batch is:  0.2487400323152542\n",
      "The representation loss after processing this batch is:  0.0032909810543060303\n",
      "\n",
      "The classification loss after processing this batch is:  0.23392923176288605\n",
      "The representation loss after processing this batch is:  0.00389663502573967\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2361430823802948\n",
      "The representation loss after processing this batch is:  0.00470917671918869\n",
      "\n",
      "The classification loss after processing this batch is:  0.3252646028995514\n",
      "The representation loss after processing this batch is:  0.005777508020401001\n",
      "\n",
      "The classification loss after processing this batch is:  0.18932898342609406\n",
      "The representation loss after processing this batch is:  0.004259705543518066\n",
      "\n",
      "The classification loss after processing this batch is:  0.38125142455101013\n",
      "The representation loss after processing this batch is:  0.005609676241874695\n",
      "\n",
      "The classification loss after processing this batch is:  0.3206542730331421\n",
      "The representation loss after processing this batch is:  0.004189983010292053\n",
      "\n",
      "The classification loss after processing this batch is:  0.3238731324672699\n",
      "The representation loss after processing this batch is:  0.003281891345977783\n",
      "\n",
      "The classification loss after processing this batch is:  0.42043399810791016\n",
      "The representation loss after processing this batch is:  0.0033823437988758087\n",
      "\n",
      "The classification loss after processing this batch is:  0.2842780351638794\n",
      "The representation loss after processing this batch is:  0.00470893457531929\n",
      "\n",
      "The classification loss after processing this batch is:  0.3656296133995056\n",
      "The representation loss after processing this batch is:  0.004825584590435028\n",
      "\n",
      "The classification loss after processing this batch is:  0.37968361377716064\n",
      "The representation loss after processing this batch is:  0.004632227122783661\n",
      "\n",
      "The classification loss after processing this batch is:  0.28075993061065674\n",
      "The representation loss after processing this batch is:  0.00422118604183197\n",
      "\n",
      "The classification loss after processing this batch is:  0.3302498459815979\n",
      "The representation loss after processing this batch is:  0.0031614750623703003\n",
      "\n",
      "The classification loss after processing this batch is:  0.2951970398426056\n",
      "The representation loss after processing this batch is:  0.003836441785097122\n",
      "\n",
      "The classification loss after processing this batch is:  0.21269559860229492\n",
      "The representation loss after processing this batch is:  0.0038547664880752563\n",
      "\n",
      "The classification loss after processing this batch is:  0.22287209331989288\n",
      "The representation loss after processing this batch is:  0.0033232346177101135\n",
      "\n",
      "The classification loss after processing this batch is:  0.27778133749961853\n",
      "The representation loss after processing this batch is:  0.003735017031431198\n",
      "\n",
      "The classification loss after processing this batch is:  0.34670695662498474\n",
      "The representation loss after processing this batch is:  0.0032294243574142456\n",
      "\n",
      "The classification loss after processing this batch is:  0.25896570086479187\n",
      "The representation loss after processing this batch is:  0.004047073423862457\n",
      "\n",
      "The classification loss after processing this batch is:  0.35901814699172974\n",
      "The representation loss after processing this batch is:  0.00404425710439682\n",
      "\n",
      "The classification loss after processing this batch is:  0.5738509893417358\n",
      "The representation loss after processing this batch is:  0.0038082972168922424\n",
      "\n",
      "The classification loss after processing this batch is:  0.45071935653686523\n",
      "The representation loss after processing this batch is:  0.004181232303380966\n",
      "\n",
      "The classification loss after processing this batch is:  0.22567081451416016\n",
      "The representation loss after processing this batch is:  0.003521956503391266\n",
      "\n",
      "The classification loss after processing this batch is:  0.2813723683357239\n",
      "The representation loss after processing this batch is:  0.004009947180747986\n",
      "\n",
      "The classification loss after processing this batch is:  0.3432565927505493\n",
      "The representation loss after processing this batch is:  0.0032980963587760925\n",
      "\n",
      "The classification loss after processing this batch is:  0.268778920173645\n",
      "The representation loss after processing this batch is:  0.0030119791626930237\n",
      "\n",
      "The classification loss after processing this batch is:  0.21774384379386902\n",
      "The representation loss after processing this batch is:  0.0037828683853149414\n",
      "\n",
      "The classification loss after processing this batch is:  0.28259995579719543\n",
      "The representation loss after processing this batch is:  0.004638854414224625\n",
      "\n",
      "The classification loss after processing this batch is:  0.30431124567985535\n",
      "The representation loss after processing this batch is:  0.0034664198756217957\n",
      "\n",
      "The classification loss after processing this batch is:  0.42782536149024963\n",
      "The representation loss after processing this batch is:  0.003819931298494339\n",
      "\n",
      "The classification loss after processing this batch is:  0.21907858550548553\n",
      "The representation loss after processing this batch is:  0.003690160810947418\n",
      "\n",
      "The classification loss after processing this batch is:  0.20671358704566956\n",
      "The representation loss after processing this batch is:  0.0036740675568580627\n",
      "\n",
      "The classification loss after processing this batch is:  0.23589201271533966\n",
      "The representation loss after processing this batch is:  0.003548257052898407\n",
      "\n",
      "The classification loss after processing this batch is:  0.4355010688304901\n",
      "The representation loss after processing this batch is:  0.0036898739635944366\n",
      "\n",
      "The classification loss after processing this batch is:  0.25380799174308777\n",
      "The representation loss after processing this batch is:  0.003954604268074036\n",
      "\n",
      "The classification loss after processing this batch is:  0.223629429936409\n",
      "The representation loss after processing this batch is:  0.003746502101421356\n",
      "\n",
      "The classification loss after processing this batch is:  0.41584596037864685\n",
      "The representation loss after processing this batch is:  0.0038520321249961853\n",
      "\n",
      "The classification loss after processing this batch is:  0.273038387298584\n",
      "The representation loss after processing this batch is:  0.0036588460206985474\n",
      "\n",
      "The classification loss after processing this batch is:  0.22301621735095978\n",
      "The representation loss after processing this batch is:  0.0037958770990371704\n",
      "\n",
      "The classification loss after processing this batch is:  0.33444908261299133\n",
      "The representation loss after processing this batch is:  0.0037639252841472626\n",
      "\n",
      "The classification loss after processing this batch is:  0.21303945779800415\n",
      "The representation loss after processing this batch is:  0.0034562498331069946\n",
      "\n",
      "The classification loss after processing this batch is:  0.27580592036247253\n",
      "The representation loss after processing this batch is:  0.003776703029870987\n",
      "\n",
      "The classification loss after processing this batch is:  0.3718110918998718\n",
      "The representation loss after processing this batch is:  0.003697093576192856\n",
      "\n",
      "The classification loss after processing this batch is:  0.4166069030761719\n",
      "The representation loss after processing this batch is:  0.003992617130279541\n",
      "\n",
      "The classification loss after processing this batch is:  0.33271679282188416\n",
      "The representation loss after processing this batch is:  0.0038475394248962402\n",
      "\n",
      "The classification loss after processing this batch is:  0.4436706006526947\n",
      "The representation loss after processing this batch is:  0.0036114342510700226\n",
      "\n",
      "The classification loss after processing this batch is:  0.3082346022129059\n",
      "The representation loss after processing this batch is:  0.003775034099817276\n",
      "\n",
      "The classification loss after processing this batch is:  0.33279168605804443\n",
      "The representation loss after processing this batch is:  0.004022121429443359\n",
      "\n",
      "The classification loss after processing this batch is:  0.2764628231525421\n",
      "The representation loss after processing this batch is:  0.004263564944267273\n",
      "\n",
      "The classification loss after processing this batch is:  0.3622571527957916\n",
      "The representation loss after processing this batch is:  0.004167664796113968\n",
      "\n",
      "The classification loss after processing this batch is:  0.25179141759872437\n",
      "The representation loss after processing this batch is:  0.0038922354578971863\n",
      "\n",
      "The classification loss after processing this batch is:  0.3363878130912781\n",
      "The representation loss after processing this batch is:  0.004008118063211441\n",
      "\n",
      "The classification loss after processing this batch is:  0.24954548478126526\n",
      "The representation loss after processing this batch is:  0.003986470401287079\n",
      "\n",
      "The classification loss after processing this batch is:  0.33799228072166443\n",
      "The representation loss after processing this batch is:  0.003633923828601837\n",
      "\n",
      "The classification loss after processing this batch is:  0.3037080764770508\n",
      "The representation loss after processing this batch is:  0.0033527016639709473\n",
      "\n",
      "The classification loss after processing this batch is:  0.34085509181022644\n",
      "The representation loss after processing this batch is:  0.0038220584392547607\n",
      "\n",
      "The classification loss after processing this batch is:  0.3215251863002777\n",
      "The representation loss after processing this batch is:  0.0037242621183395386\n",
      "\n",
      "The classification loss after processing this batch is:  0.3998473882675171\n",
      "The representation loss after processing this batch is:  0.003685310482978821\n",
      "\n",
      "The classification loss after processing this batch is:  0.381747841835022\n",
      "The representation loss after processing this batch is:  0.003358643501996994\n",
      "\n",
      "The classification loss after processing this batch is:  0.4793251156806946\n",
      "The representation loss after processing this batch is:  0.0033032968640327454\n",
      "\n",
      "The classification loss after processing this batch is:  0.5188745260238647\n",
      "The representation loss after processing this batch is:  0.003114446997642517\n",
      "\n",
      "The classification loss after processing this batch is:  0.4307052493095398\n",
      "The representation loss after processing this batch is:  0.0030285120010375977\n",
      "\n",
      "The classification loss after processing this batch is:  0.2811747193336487\n",
      "The representation loss after processing this batch is:  0.004328146576881409\n",
      "\n",
      "The classification loss after processing this batch is:  0.3187443017959595\n",
      "The representation loss after processing this batch is:  0.00453590601682663\n",
      "\n",
      "The classification loss after processing this batch is:  0.20084331929683685\n",
      "The representation loss after processing this batch is:  0.004088602960109711\n",
      "\n",
      "The classification loss after processing this batch is:  0.387544184923172\n",
      "The representation loss after processing this batch is:  0.003795590251684189\n",
      "\n",
      "The classification loss after processing this batch is:  0.4435712695121765\n",
      "The representation loss after processing this batch is:  0.0041780024766922\n",
      "\n",
      "The classification loss after processing this batch is:  0.5938350558280945\n",
      "The representation loss after processing this batch is:  0.0037884116172790527\n",
      "\n",
      "The classification loss after processing this batch is:  0.5798178911209106\n",
      "The representation loss after processing this batch is:  0.003234684467315674\n",
      "\n",
      "The classification loss after processing this batch is:  0.3631216585636139\n",
      "The representation loss after processing this batch is:  0.0037854164838790894\n",
      "\n",
      "The classification loss after processing this batch is:  0.2545364797115326\n",
      "The representation loss after processing this batch is:  0.0036500804126262665\n",
      "\n",
      "The classification loss after processing this batch is:  0.2630718946456909\n",
      "The representation loss after processing this batch is:  0.003798503428697586\n",
      "\n",
      "The classification loss after processing this batch is:  0.3933774530887604\n",
      "The representation loss after processing this batch is:  0.003194626420736313\n",
      "\n",
      "The classification loss after processing this batch is:  0.238981693983078\n",
      "The representation loss after processing this batch is:  0.004079937934875488\n",
      "\n",
      "The classification loss after processing this batch is:  0.20624922215938568\n",
      "The representation loss after processing this batch is:  0.0036930255591869354\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.26037314534187317\n",
      "The representation loss after processing this batch is:  0.003936924040317535\n",
      "\n",
      "The classification loss after processing this batch is:  0.12574054300785065\n",
      "The representation loss after processing this batch is:  0.004243314266204834\n",
      "\n",
      "The classification loss after processing this batch is:  0.29454299807548523\n",
      "The representation loss after processing this batch is:  0.0044998303055763245\n",
      "\n",
      "The classification loss after processing this batch is:  0.3152174651622772\n",
      "The representation loss after processing this batch is:  0.004256244748830795\n",
      "\n",
      "The classification loss after processing this batch is:  0.3472883105278015\n",
      "The representation loss after processing this batch is:  0.0039078183472156525\n",
      "\n",
      "The classification loss after processing this batch is:  0.29459384083747864\n",
      "The representation loss after processing this batch is:  0.0038834884762763977\n",
      "\n",
      "The classification loss after processing this batch is:  0.2920094430446625\n",
      "The representation loss after processing this batch is:  0.003550853580236435\n",
      "\n",
      "The classification loss after processing this batch is:  0.3743029832839966\n",
      "The representation loss after processing this batch is:  0.004299275577068329\n",
      "\n",
      "The classification loss after processing this batch is:  0.27463462948799133\n",
      "The representation loss after processing this batch is:  0.004158470779657364\n",
      "\n",
      "The classification loss after processing this batch is:  0.26040443778038025\n",
      "The representation loss after processing this batch is:  0.004191160202026367\n",
      "\n",
      "The classification loss after processing this batch is:  0.34844762086868286\n",
      "The representation loss after processing this batch is:  0.004026792943477631\n",
      "\n",
      "The classification loss after processing this batch is:  0.370701402425766\n",
      "The representation loss after processing this batch is:  0.0035698041319847107\n",
      "\n",
      "The classification loss after processing this batch is:  0.2726261019706726\n",
      "The representation loss after processing this batch is:  0.003436543047428131\n",
      "\n",
      "The classification loss after processing this batch is:  0.3936517834663391\n",
      "The representation loss after processing this batch is:  0.003688845783472061\n",
      "\n",
      "The classification loss after processing this batch is:  0.5371938943862915\n",
      "The representation loss after processing this batch is:  0.003905840218067169\n",
      "\n",
      "The classification loss after processing this batch is:  0.257170706987381\n",
      "The representation loss after processing this batch is:  0.0033154599368572235\n",
      "\n",
      "The classification loss after processing this batch is:  0.28732186555862427\n",
      "The representation loss after processing this batch is:  0.00419360026717186\n",
      "\n",
      "The classification loss after processing this batch is:  0.33208146691322327\n",
      "The representation loss after processing this batch is:  0.004489347338676453\n",
      "\n",
      "The classification loss after processing this batch is:  0.38389331102371216\n",
      "The representation loss after processing this batch is:  0.00401710718870163\n",
      "\n",
      "The classification loss after processing this batch is:  0.5129744410514832\n",
      "The representation loss after processing this batch is:  0.004295967519283295\n",
      "\n",
      "The classification loss after processing this batch is:  0.41157257556915283\n",
      "The representation loss after processing this batch is:  0.004413492977619171\n",
      "\n",
      "The classification loss after processing this batch is:  0.4847298562526703\n",
      "The representation loss after processing this batch is:  0.004659518599510193\n",
      "\n",
      "The classification loss after processing this batch is:  0.42600294947624207\n",
      "The representation loss after processing this batch is:  0.0043426454067230225\n",
      "\n",
      "The classification loss after processing this batch is:  0.3186388909816742\n",
      "The representation loss after processing this batch is:  0.0037058591842651367\n",
      "\n",
      "The classification loss after processing this batch is:  0.3054264783859253\n",
      "The representation loss after processing this batch is:  0.004548259079456329\n",
      "\n",
      "The classification loss after processing this batch is:  0.25178006291389465\n",
      "The representation loss after processing this batch is:  0.0037184804677963257\n",
      "\n",
      "The classification loss after processing this batch is:  0.34145689010620117\n",
      "The representation loss after processing this batch is:  0.004108607769012451\n",
      "\n",
      "The classification loss after processing this batch is:  0.3048446774482727\n",
      "The representation loss after processing this batch is:  0.00362483412027359\n",
      "\n",
      "The classification loss after processing this batch is:  0.217275932431221\n",
      "The representation loss after processing this batch is:  0.0035752803087234497\n",
      "\n",
      "The classification loss after processing this batch is:  0.23782587051391602\n",
      "The representation loss after processing this batch is:  0.003937624394893646\n",
      "\n",
      "The classification loss after processing this batch is:  0.25274962186813354\n",
      "The representation loss after processing this batch is:  0.004153206944465637\n",
      "\n",
      "The classification loss after processing this batch is:  0.3087991774082184\n",
      "The representation loss after processing this batch is:  0.0036038197576999664\n",
      "\n",
      "The classification loss after processing this batch is:  0.2219134420156479\n",
      "The representation loss after processing this batch is:  0.0036074742674827576\n",
      "\n",
      "The classification loss after processing this batch is:  0.3204648196697235\n",
      "The representation loss after processing this batch is:  0.0032883472740650177\n",
      "\n",
      "The classification loss after processing this batch is:  0.24076223373413086\n",
      "The representation loss after processing this batch is:  0.0032272785902023315\n",
      "\n",
      "The classification loss after processing this batch is:  0.26107877492904663\n",
      "The representation loss after processing this batch is:  0.002981029450893402\n",
      "\n",
      "The classification loss after processing this batch is:  0.29067233204841614\n",
      "The representation loss after processing this batch is:  0.003427814692258835\n",
      "\n",
      "The classification loss after processing this batch is:  0.7205950021743774\n",
      "The representation loss after processing this batch is:  0.0039137862622737885\n",
      "\n",
      "The classification loss after processing this batch is:  0.3126438856124878\n",
      "The representation loss after processing this batch is:  0.0033623799681663513\n",
      "\n",
      "The classification loss after processing this batch is:  0.47459709644317627\n",
      "The representation loss after processing this batch is:  0.0034656785428524017\n",
      "\n",
      "The classification loss after processing this batch is:  0.3935212194919586\n",
      "The representation loss after processing this batch is:  0.0034762658178806305\n",
      "\n",
      "The classification loss after processing this batch is:  0.32716575264930725\n",
      "The representation loss after processing this batch is:  0.004097007215023041\n",
      "\n",
      "The classification loss after processing this batch is:  0.5471542477607727\n",
      "The representation loss after processing this batch is:  0.003986690193414688\n",
      "\n",
      "The classification loss after processing this batch is:  0.34986215829849243\n",
      "The representation loss after processing this batch is:  0.003873903304338455\n",
      "\n",
      "The classification loss after processing this batch is:  0.42862945795059204\n",
      "The representation loss after processing this batch is:  0.0033916309475898743\n",
      "\n",
      "The classification loss after processing this batch is:  0.2157583236694336\n",
      "The representation loss after processing this batch is:  0.003624953329563141\n",
      "\n",
      "The classification loss after processing this batch is:  0.25012362003326416\n",
      "The representation loss after processing this batch is:  0.003609791398048401\n",
      "\n",
      "The classification loss after processing this batch is:  0.18810950219631195\n",
      "The representation loss after processing this batch is:  0.004459276795387268\n",
      "\n",
      "The classification loss after processing this batch is:  0.20451918244361877\n",
      "The representation loss after processing this batch is:  0.003924347460269928\n",
      "\n",
      "The classification loss after processing this batch is:  0.27534136176109314\n",
      "The representation loss after processing this batch is:  0.003591582179069519\n",
      "\n",
      "The classification loss after processing this batch is:  0.19895263016223907\n",
      "The representation loss after processing this batch is:  0.0035421662032604218\n",
      "\n",
      "The classification loss after processing this batch is:  0.25211068987846375\n",
      "The representation loss after processing this batch is:  0.003968223929405212\n",
      "\n",
      "The classification loss after processing this batch is:  0.281971275806427\n",
      "The representation loss after processing this batch is:  0.0041535645723342896\n",
      "\n",
      "The classification loss after processing this batch is:  0.24769578874111176\n",
      "The representation loss after processing this batch is:  0.0035785138607025146\n",
      "\n",
      "The classification loss after processing this batch is:  0.36624619364738464\n",
      "The representation loss after processing this batch is:  0.003209080547094345\n",
      "\n",
      "The classification loss after processing this batch is:  0.340353399515152\n",
      "The representation loss after processing this batch is:  0.004131697118282318\n",
      "\n",
      "The classification loss after processing this batch is:  0.2649037539958954\n",
      "The representation loss after processing this batch is:  0.003614138811826706\n",
      "\n",
      "The classification loss after processing this batch is:  0.30620309710502625\n",
      "The representation loss after processing this batch is:  0.004392892122268677\n",
      "\n",
      "The classification loss after processing this batch is:  0.3629823923110962\n",
      "The representation loss after processing this batch is:  0.004170827567577362\n",
      "\n",
      "The classification loss after processing this batch is:  0.290103018283844\n",
      "The representation loss after processing this batch is:  0.0036904141306877136\n",
      "\n",
      "The classification loss after processing this batch is:  0.2633381485939026\n",
      "The representation loss after processing this batch is:  0.003367070108652115\n",
      "\n",
      "The classification loss after processing this batch is:  0.4032873511314392\n",
      "The representation loss after processing this batch is:  0.003975827246904373\n",
      "\n",
      "The classification loss after processing this batch is:  0.3565569519996643\n",
      "The representation loss after processing this batch is:  0.0037937164306640625\n",
      "\n",
      "The classification loss after processing this batch is:  0.3052491843700409\n",
      "The representation loss after processing this batch is:  0.0034113116562366486\n",
      "\n",
      "The classification loss after processing this batch is:  0.24289964139461517\n",
      "The representation loss after processing this batch is:  0.003655664622783661\n",
      "\n",
      "The classification loss after processing this batch is:  0.3014356791973114\n",
      "The representation loss after processing this batch is:  0.004047177731990814\n",
      "\n",
      "The classification loss after processing this batch is:  0.3463183343410492\n",
      "The representation loss after processing this batch is:  0.0038188770413398743\n",
      "\n",
      "The classification loss after processing this batch is:  0.3350938856601715\n",
      "The representation loss after processing this batch is:  0.004662498831748962\n",
      "\n",
      "The classification loss after processing this batch is:  0.24017184972763062\n",
      "The representation loss after processing this batch is:  0.004852600395679474\n",
      "\n",
      "The classification loss after processing this batch is:  0.27798864245414734\n",
      "The representation loss after processing this batch is:  0.005343325436115265\n",
      "\n",
      "The classification loss after processing this batch is:  0.360514760017395\n",
      "The representation loss after processing this batch is:  0.004348196089267731\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.38354015350341797\n",
      "The representation loss after processing this batch is:  0.003667633980512619\n",
      "\n",
      "The classification loss after processing this batch is:  0.3152400851249695\n",
      "The representation loss after processing this batch is:  0.0049083903431892395\n",
      "\n",
      "The classification loss after processing this batch is:  0.2895349860191345\n",
      "The representation loss after processing this batch is:  0.004068169742822647\n",
      "\n",
      "The classification loss after processing this batch is:  0.2072213739156723\n",
      "The representation loss after processing this batch is:  0.0033680610358715057\n",
      "\n",
      "The classification loss after processing this batch is:  0.3815039396286011\n",
      "The representation loss after processing this batch is:  0.0036351382732391357\n",
      "\n",
      "The classification loss after processing this batch is:  0.2092307060956955\n",
      "The representation loss after processing this batch is:  0.003990650177001953\n",
      "\n",
      "The classification loss after processing this batch is:  0.21610060334205627\n",
      "The representation loss after processing this batch is:  0.0040520355105400085\n",
      "\n",
      "The classification loss after processing this batch is:  0.22383852303028107\n",
      "The representation loss after processing this batch is:  0.004165448248386383\n",
      "\n",
      "The classification loss after processing this batch is:  0.23574508726596832\n",
      "The representation loss after processing this batch is:  0.003993026912212372\n",
      "\n",
      "The classification loss after processing this batch is:  0.23545894026756287\n",
      "The representation loss after processing this batch is:  0.003961462527513504\n",
      "\n",
      "The classification loss after processing this batch is:  0.36850836873054504\n",
      "The representation loss after processing this batch is:  0.0042532384395599365\n",
      "\n",
      "The classification loss after processing this batch is:  0.31233376264572144\n",
      "The representation loss after processing this batch is:  0.004109054803848267\n",
      "\n",
      "The classification loss after processing this batch is:  0.33211657404899597\n",
      "The representation loss after processing this batch is:  0.00393310934305191\n",
      "\n",
      "The classification loss after processing this batch is:  0.29309189319610596\n",
      "The representation loss after processing this batch is:  0.004223525524139404\n",
      "\n",
      "The classification loss after processing this batch is:  0.25550517439842224\n",
      "The representation loss after processing this batch is:  0.003825932741165161\n",
      "\n",
      "The classification loss after processing this batch is:  0.23354728519916534\n",
      "The representation loss after processing this batch is:  0.0032196044921875\n",
      "\n",
      "The classification loss after processing this batch is:  0.26071855425834656\n",
      "The representation loss after processing this batch is:  0.0042335838079452515\n",
      "\n",
      "The classification loss after processing this batch is:  0.26718375086784363\n",
      "The representation loss after processing this batch is:  0.0036323145031929016\n",
      "\n",
      "The classification loss after processing this batch is:  0.1872902661561966\n",
      "The representation loss after processing this batch is:  0.003246098756790161\n",
      "\n",
      "The classification loss after processing this batch is:  0.16619454324245453\n",
      "The representation loss after processing this batch is:  0.003374345600605011\n",
      "\n",
      "The classification loss after processing this batch is:  0.2638261914253235\n",
      "The representation loss after processing this batch is:  0.003967825323343277\n",
      "\n",
      "The classification loss after processing this batch is:  0.2660153806209564\n",
      "The representation loss after processing this batch is:  0.0035625025629997253\n",
      "\n",
      "The classification loss after processing this batch is:  0.3689010739326477\n",
      "The representation loss after processing this batch is:  0.0037972256541252136\n",
      "\n",
      "The classification loss after processing this batch is:  0.34516462683677673\n",
      "The representation loss after processing this batch is:  0.0034087970852851868\n",
      "\n",
      "The classification loss after processing this batch is:  0.3420463502407074\n",
      "The representation loss after processing this batch is:  0.003898829221725464\n",
      "\n",
      "The classification loss after processing this batch is:  0.22367006540298462\n",
      "The representation loss after processing this batch is:  0.0035536959767341614\n",
      "\n",
      "The classification loss after processing this batch is:  0.3640201687812805\n",
      "The representation loss after processing this batch is:  0.003452591598033905\n",
      "\n",
      "The classification loss after processing this batch is:  0.29311397671699524\n",
      "The representation loss after processing this batch is:  0.0035090371966362\n",
      "\n",
      "The classification loss after processing this batch is:  0.24965687096118927\n",
      "The representation loss after processing this batch is:  0.0034501105546951294\n",
      "\n",
      "The classification loss after processing this batch is:  0.3459431827068329\n",
      "The representation loss after processing this batch is:  0.003667980432510376\n",
      "\n",
      "The classification loss after processing this batch is:  0.3582817018032074\n",
      "The representation loss after processing this batch is:  0.0040590837597846985\n",
      "\n",
      "The classification loss after processing this batch is:  0.17623120546340942\n",
      "The representation loss after processing this batch is:  0.0034541040658950806\n",
      "\n",
      "The classification loss after processing this batch is:  0.1950131356716156\n",
      "The representation loss after processing this batch is:  0.003653228282928467\n",
      "\n",
      "The classification loss after processing this batch is:  0.2074216902256012\n",
      "The representation loss after processing this batch is:  0.003226369619369507\n",
      "\n",
      "The classification loss after processing this batch is:  0.32082465291023254\n",
      "The representation loss after processing this batch is:  0.003870207816362381\n",
      "\n",
      "The classification loss after processing this batch is:  0.2752869427204132\n",
      "The representation loss after processing this batch is:  0.003509651869535446\n",
      "\n",
      "The classification loss after processing this batch is:  0.2923685312271118\n",
      "The representation loss after processing this batch is:  0.004260249435901642\n",
      "\n",
      "The classification loss after processing this batch is:  0.38317006826400757\n",
      "The representation loss after processing this batch is:  0.004271231591701508\n",
      "\n",
      "The classification loss after processing this batch is:  0.35629481077194214\n",
      "The representation loss after processing this batch is:  0.003971189260482788\n",
      "\n",
      "The classification loss after processing this batch is:  0.3439737856388092\n",
      "The representation loss after processing this batch is:  0.0034678280353546143\n",
      "\n",
      "The classification loss after processing this batch is:  0.4889052212238312\n",
      "The representation loss after processing this batch is:  0.0036226287484169006\n",
      "\n",
      "The classification loss after processing this batch is:  0.34974542260169983\n",
      "The representation loss after processing this batch is:  0.0033700689673423767\n",
      "\n",
      "The classification loss after processing this batch is:  0.3194350302219391\n",
      "The representation loss after processing this batch is:  0.0032475627958774567\n",
      "\n",
      "The classification loss after processing this batch is:  0.2231404334306717\n",
      "The representation loss after processing this batch is:  0.003665979951620102\n",
      "\n",
      "The classification loss after processing this batch is:  0.2145586609840393\n",
      "The representation loss after processing this batch is:  0.0034027546644210815\n",
      "\n",
      "The classification loss after processing this batch is:  0.19449618458747864\n",
      "The representation loss after processing this batch is:  0.0034785419702529907\n",
      "\n",
      "The classification loss after processing this batch is:  0.27153971791267395\n",
      "The representation loss after processing this batch is:  0.004778213798999786\n",
      "\n",
      "The classification loss after processing this batch is:  0.2539069950580597\n",
      "The representation loss after processing this batch is:  0.0036122500896453857\n",
      "\n",
      "The classification loss after processing this batch is:  0.25186577439308167\n",
      "The representation loss after processing this batch is:  0.003555901348590851\n",
      "\n",
      "The classification loss after processing this batch is:  0.3556259274482727\n",
      "The representation loss after processing this batch is:  0.00367780402302742\n",
      "\n",
      "The classification loss after processing this batch is:  0.2810538709163666\n",
      "The representation loss after processing this batch is:  0.004134312272071838\n",
      "\n",
      "The classification loss after processing this batch is:  0.36677315831184387\n",
      "The representation loss after processing this batch is:  0.00346340611577034\n",
      "\n",
      "The classification loss after processing this batch is:  0.28020814061164856\n",
      "The representation loss after processing this batch is:  0.0034179426729679108\n",
      "\n",
      "The classification loss after processing this batch is:  0.42150387167930603\n",
      "The representation loss after processing this batch is:  0.003211013972759247\n",
      "\n",
      "The classification loss after processing this batch is:  0.29926496744155884\n",
      "The representation loss after processing this batch is:  0.0042639076709747314\n",
      "\n",
      "The classification loss after processing this batch is:  0.1940319687128067\n",
      "The representation loss after processing this batch is:  0.003517545759677887\n",
      "\n",
      "The classification loss after processing this batch is:  0.2835811674594879\n",
      "The representation loss after processing this batch is:  0.0034731626510620117\n",
      "\n",
      "The classification loss after processing this batch is:  0.18741007149219513\n",
      "The representation loss after processing this batch is:  0.003573622554540634\n",
      "\n",
      "The classification loss after processing this batch is:  0.18150761723518372\n",
      "The representation loss after processing this batch is:  0.0037322379648685455\n",
      "\n",
      "The classification loss after processing this batch is:  0.28582319617271423\n",
      "The representation loss after processing this batch is:  0.0038099437952041626\n",
      "\n",
      "The classification loss after processing this batch is:  0.335992693901062\n",
      "The representation loss after processing this batch is:  0.0031651929020881653\n",
      "\n",
      "The classification loss after processing this batch is:  0.33840641379356384\n",
      "The representation loss after processing this batch is:  0.00387582927942276\n",
      "\n",
      "The classification loss after processing this batch is:  0.2534204125404358\n",
      "The representation loss after processing this batch is:  0.0036686137318611145\n",
      "\n",
      "The classification loss after processing this batch is:  0.27100542187690735\n",
      "The representation loss after processing this batch is:  0.004386186599731445\n",
      "\n",
      "The classification loss after processing this batch is:  0.19653111696243286\n",
      "The representation loss after processing this batch is:  0.0034608766436576843\n",
      "\n",
      "The classification loss after processing this batch is:  0.35362735390663147\n",
      "The representation loss after processing this batch is:  0.003663457930088043\n",
      "\n",
      "The classification loss after processing this batch is:  0.20967110991477966\n",
      "The representation loss after processing this batch is:  0.0030969753861427307\n",
      "\n",
      "The classification loss after processing this batch is:  0.16667811572551727\n",
      "The representation loss after processing this batch is:  0.0037818774580955505\n",
      "\n",
      "The classification loss after processing this batch is:  0.25507065653800964\n",
      "The representation loss after processing this batch is:  0.0047598183155059814\n",
      "\n",
      "The classification loss after processing this batch is:  0.2485821396112442\n",
      "The representation loss after processing this batch is:  0.0035571008920669556\n",
      "\n",
      "The classification loss after processing this batch is:  0.21861986815929413\n",
      "The representation loss after processing this batch is:  0.004305504262447357\n",
      "\n",
      "The classification loss after processing this batch is:  0.2251960188150406\n",
      "The representation loss after processing this batch is:  0.0027898214757442474\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.32207757234573364\n",
      "The representation loss after processing this batch is:  0.003845416009426117\n",
      "\n",
      "The classification loss after processing this batch is:  0.36432090401649475\n",
      "The representation loss after processing this batch is:  0.004337728023529053\n",
      "\n",
      "The classification loss after processing this batch is:  0.39513930678367615\n",
      "The representation loss after processing this batch is:  0.003682859241962433\n",
      "\n",
      "The classification loss after processing this batch is:  0.3546411395072937\n",
      "The representation loss after processing this batch is:  0.00414237380027771\n",
      "\n",
      "The classification loss after processing this batch is:  0.19801300764083862\n",
      "The representation loss after processing this batch is:  0.003637455403804779\n",
      "\n",
      "The classification loss after processing this batch is:  0.23359133303165436\n",
      "The representation loss after processing this batch is:  0.003329060971736908\n",
      "\n",
      "The classification loss after processing this batch is:  0.42022624611854553\n",
      "The representation loss after processing this batch is:  0.0038620829582214355\n",
      "\n",
      "The classification loss after processing this batch is:  0.4373280704021454\n",
      "The representation loss after processing this batch is:  0.004110068082809448\n",
      "\n",
      "The classification loss after processing this batch is:  0.42845889925956726\n",
      "The representation loss after processing this batch is:  0.004013784229755402\n",
      "\n",
      "The classification loss after processing this batch is:  0.4671991765499115\n",
      "The representation loss after processing this batch is:  0.00381571426987648\n",
      "\n",
      "The classification loss after processing this batch is:  0.27293482422828674\n",
      "The representation loss after processing this batch is:  0.003392767161130905\n",
      "\n",
      "The classification loss after processing this batch is:  0.3453502357006073\n",
      "The representation loss after processing this batch is:  0.003553532063961029\n",
      "\n",
      "The classification loss after processing this batch is:  0.26847076416015625\n",
      "The representation loss after processing this batch is:  0.0034030601382255554\n",
      "\n",
      "The classification loss after processing this batch is:  0.25793930888175964\n",
      "The representation loss after processing this batch is:  0.0034418627619743347\n",
      "\n",
      "The classification loss after processing this batch is:  0.21081562340259552\n",
      "The representation loss after processing this batch is:  0.003475382924079895\n",
      "\n",
      "The classification loss after processing this batch is:  0.24720638990402222\n",
      "The representation loss after processing this batch is:  0.003539435565471649\n",
      "\n",
      "The classification loss after processing this batch is:  0.32709088921546936\n",
      "The representation loss after processing this batch is:  0.0037414878606796265\n",
      "\n",
      "The classification loss after processing this batch is:  0.2689271867275238\n",
      "The representation loss after processing this batch is:  0.0037142597138881683\n",
      "\n",
      "The classification loss after processing this batch is:  0.2961638271808624\n",
      "The representation loss after processing this batch is:  0.004166394472122192\n",
      "\n",
      "The classification loss after processing this batch is:  0.1971457600593567\n",
      "The representation loss after processing this batch is:  0.0039957016706466675\n",
      "\n",
      "The classification loss after processing this batch is:  0.24866576492786407\n",
      "The representation loss after processing this batch is:  0.004018731415271759\n",
      "\n",
      "The classification loss after processing this batch is:  0.2383894920349121\n",
      "The representation loss after processing this batch is:  0.0041574761271476746\n",
      "\n",
      "The classification loss after processing this batch is:  0.2829699218273163\n",
      "The representation loss after processing this batch is:  0.003880169242620468\n",
      "\n",
      "The classification loss after processing this batch is:  0.18720079958438873\n",
      "The representation loss after processing this batch is:  0.004220806062221527\n",
      "\n",
      "The classification loss after processing this batch is:  0.22402150928974152\n",
      "The representation loss after processing this batch is:  0.003209814429283142\n",
      "\n",
      "The classification loss after processing this batch is:  0.2869778871536255\n",
      "The representation loss after processing this batch is:  0.0038423463702201843\n",
      "\n",
      "The classification loss after processing this batch is:  0.3306848406791687\n",
      "The representation loss after processing this batch is:  0.003520578145980835\n",
      "\n",
      "The classification loss after processing this batch is:  0.3030987083911896\n",
      "The representation loss after processing this batch is:  0.0033889412879943848\n",
      "\n",
      "The classification loss after processing this batch is:  0.2196798324584961\n",
      "The representation loss after processing this batch is:  0.003445148468017578\n",
      "\n",
      "The classification loss after processing this batch is:  0.18151940405368805\n",
      "The representation loss after processing this batch is:  0.0036514587700366974\n",
      "\n",
      "The classification loss after processing this batch is:  0.1794002801179886\n",
      "The representation loss after processing this batch is:  0.0033610202372074127\n",
      "\n",
      "The classification loss after processing this batch is:  0.2649969458580017\n",
      "The representation loss after processing this batch is:  0.004038158804178238\n",
      "\n",
      "The classification loss after processing this batch is:  0.3137548565864563\n",
      "The representation loss after processing this batch is:  0.003657326102256775\n",
      "\n",
      "The classification loss after processing this batch is:  0.3093882203102112\n",
      "The representation loss after processing this batch is:  0.0044706761837005615\n",
      "\n",
      "The classification loss after processing this batch is:  0.2099745124578476\n",
      "The representation loss after processing this batch is:  0.0032876357436180115\n",
      "\n",
      "The classification loss after processing this batch is:  0.3175211548805237\n",
      "The representation loss after processing this batch is:  0.003462575376033783\n",
      "\n",
      "The classification loss after processing this batch is:  0.41925284266471863\n",
      "The representation loss after processing this batch is:  0.0036506056785583496\n",
      "\n",
      "The classification loss after processing this batch is:  0.176564022898674\n",
      "The representation loss after processing this batch is:  0.0033069029450416565\n",
      "\n",
      "The classification loss after processing this batch is:  0.2518182694911957\n",
      "The representation loss after processing this batch is:  0.0033560767769813538\n",
      "\n",
      "The classification loss after processing this batch is:  0.34035709500312805\n",
      "The representation loss after processing this batch is:  0.0032474063336849213\n",
      "\n",
      "The classification loss after processing this batch is:  0.35880687832832336\n",
      "The representation loss after processing this batch is:  0.0037208572030067444\n",
      "\n",
      "The classification loss after processing this batch is:  0.25206220149993896\n",
      "The representation loss after processing this batch is:  0.003525875508785248\n",
      "\n",
      "The classification loss after processing this batch is:  0.40271490812301636\n",
      "The representation loss after processing this batch is:  0.0032574981451034546\n",
      "\n",
      "The classification loss after processing this batch is:  0.30856356024742126\n",
      "The representation loss after processing this batch is:  0.003501586616039276\n",
      "\n",
      "The classification loss after processing this batch is:  0.36722368001937866\n",
      "The representation loss after processing this batch is:  0.003745265305042267\n",
      "\n",
      "The classification loss after processing this batch is:  0.2642706334590912\n",
      "The representation loss after processing this batch is:  0.0040445104241371155\n",
      "\n",
      "The classification loss after processing this batch is:  0.3509417772293091\n",
      "The representation loss after processing this batch is:  0.0036472678184509277\n",
      "\n",
      "The classification loss after processing this batch is:  0.20995202660560608\n",
      "The representation loss after processing this batch is:  0.005537144839763641\n",
      "\n",
      "The classification loss after processing this batch is:  0.25159791111946106\n",
      "The representation loss after processing this batch is:  0.003272421658039093\n",
      "\n",
      "The classification loss after processing this batch is:  0.2217395305633545\n",
      "The representation loss after processing this batch is:  0.0032578185200691223\n",
      "\n",
      "The classification loss after processing this batch is:  0.23201794922351837\n",
      "The representation loss after processing this batch is:  0.0030849240720272064\n",
      "\n",
      "The classification loss after processing this batch is:  0.2691914141178131\n",
      "The representation loss after processing this batch is:  0.003448124974966049\n",
      "\n",
      "The classification loss after processing this batch is:  0.2585897445678711\n",
      "The representation loss after processing this batch is:  0.0036353617906570435\n",
      "\n",
      "The classification loss after processing this batch is:  0.3280830979347229\n",
      "The representation loss after processing this batch is:  0.003703732043504715\n",
      "\n",
      "The classification loss after processing this batch is:  0.19174012541770935\n",
      "The representation loss after processing this batch is:  0.003775268793106079\n",
      "\n",
      "The classification loss after processing this batch is:  0.2110450118780136\n",
      "The representation loss after processing this batch is:  0.003818988800048828\n",
      "\n",
      "The classification loss after processing this batch is:  0.2748691439628601\n",
      "The representation loss after processing this batch is:  0.004042796790599823\n",
      "\n",
      "The classification loss after processing this batch is:  0.17680390179157257\n",
      "The representation loss after processing this batch is:  0.003976516425609589\n",
      "\n",
      "The classification loss after processing this batch is:  0.24049854278564453\n",
      "The representation loss after processing this batch is:  0.0035044848918914795\n",
      "\n",
      "The classification loss after processing this batch is:  0.1920623779296875\n",
      "The representation loss after processing this batch is:  0.003681369125843048\n",
      "\n",
      "The classification loss after processing this batch is:  0.15680649876594543\n",
      "The representation loss after processing this batch is:  0.003202393651008606\n",
      "\n",
      "The classification loss after processing this batch is:  0.2493877410888672\n",
      "The representation loss after processing this batch is:  0.003910280764102936\n",
      "\n",
      "The classification loss after processing this batch is:  0.2921994626522064\n",
      "The representation loss after processing this batch is:  0.004983693361282349\n",
      "\n",
      "The classification loss after processing this batch is:  0.2881871461868286\n",
      "The representation loss after processing this batch is:  0.004420749843120575\n",
      "\n",
      "The classification loss after processing this batch is:  0.26196807622909546\n",
      "The representation loss after processing this batch is:  0.003813698887825012\n",
      "\n",
      "The classification loss after processing this batch is:  0.280384361743927\n",
      "The representation loss after processing this batch is:  0.003543555736541748\n",
      "\n",
      "The classification loss after processing this batch is:  0.21588163077831268\n",
      "The representation loss after processing this batch is:  0.00331047922372818\n",
      "\n",
      "The classification loss after processing this batch is:  0.21009735763072968\n",
      "The representation loss after processing this batch is:  0.0038377121090888977\n",
      "\n",
      "The classification loss after processing this batch is:  0.20880602300167084\n",
      "The representation loss after processing this batch is:  0.0034813061356544495\n",
      "\n",
      "The classification loss after processing this batch is:  0.19680579006671906\n",
      "The representation loss after processing this batch is:  0.003927189856767654\n",
      "\n",
      "The classification loss after processing this batch is:  0.2485821694135666\n",
      "The representation loss after processing this batch is:  0.00422731414437294\n",
      "\n",
      "The classification loss after processing this batch is:  0.36227282881736755\n",
      "The representation loss after processing this batch is:  0.0037228092551231384\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.3098735213279724\n",
      "The representation loss after processing this batch is:  0.003390960395336151\n",
      "\n",
      "The classification loss after processing this batch is:  0.21287666261196136\n",
      "The representation loss after processing this batch is:  0.0045369938015937805\n",
      "\n",
      "The classification loss after processing this batch is:  0.22606249153614044\n",
      "The representation loss after processing this batch is:  0.004210077226161957\n",
      "\n",
      "The classification loss after processing this batch is:  0.30811020731925964\n",
      "The representation loss after processing this batch is:  0.0036801956593990326\n",
      "\n",
      "The classification loss after processing this batch is:  0.25838151574134827\n",
      "The representation loss after processing this batch is:  0.0039510577917099\n",
      "\n",
      "The classification loss after processing this batch is:  0.4972422420978546\n",
      "The representation loss after processing this batch is:  0.003976479172706604\n",
      "\n",
      "The classification loss after processing this batch is:  0.25719624757766724\n",
      "The representation loss after processing this batch is:  0.0038676857948303223\n",
      "\n",
      "The classification loss after processing this batch is:  0.399755597114563\n",
      "The representation loss after processing this batch is:  0.00500866025686264\n",
      "\n",
      "The classification loss after processing this batch is:  0.2593577802181244\n",
      "The representation loss after processing this batch is:  0.003545813262462616\n",
      "\n",
      "The classification loss after processing this batch is:  0.2618461847305298\n",
      "The representation loss after processing this batch is:  0.003747709095478058\n",
      "\n",
      "The classification loss after processing this batch is:  0.24980807304382324\n",
      "The representation loss after processing this batch is:  0.0031636953353881836\n",
      "\n",
      "The classification loss after processing this batch is:  0.31788262724876404\n",
      "The representation loss after processing this batch is:  0.004209265112876892\n",
      "\n",
      "The classification loss after processing this batch is:  0.4169407784938812\n",
      "The representation loss after processing this batch is:  0.003350764513015747\n",
      "\n",
      "The classification loss after processing this batch is:  0.40051957964897156\n",
      "The representation loss after processing this batch is:  0.004269145429134369\n",
      "\n",
      "The classification loss after processing this batch is:  0.31578192114830017\n",
      "The representation loss after processing this batch is:  0.003896482288837433\n",
      "\n",
      "The classification loss after processing this batch is:  0.2766469419002533\n",
      "The representation loss after processing this batch is:  0.003687262535095215\n",
      "\n",
      "The classification loss after processing this batch is:  0.16320191323757172\n",
      "The representation loss after processing this batch is:  0.00398959219455719\n",
      "\n",
      "The classification loss after processing this batch is:  0.2622976005077362\n",
      "The representation loss after processing this batch is:  0.003657720983028412\n",
      "\n",
      "The classification loss after processing this batch is:  0.24060262739658356\n",
      "The representation loss after processing this batch is:  0.0033517442643642426\n",
      "\n",
      "The classification loss after processing this batch is:  0.1776546686887741\n",
      "The representation loss after processing this batch is:  0.0037195533514022827\n",
      "\n",
      "The classification loss after processing this batch is:  0.259497731924057\n",
      "The representation loss after processing this batch is:  0.0033465176820755005\n",
      "\n",
      "The classification loss after processing this batch is:  0.3932023048400879\n",
      "The representation loss after processing this batch is:  0.003715425729751587\n",
      "\n",
      "The classification loss after processing this batch is:  0.2982729375362396\n",
      "The representation loss after processing this batch is:  0.003138858824968338\n",
      "\n",
      "The classification loss after processing this batch is:  0.2734545171260834\n",
      "The representation loss after processing this batch is:  0.003980774432420731\n",
      "\n",
      "The classification loss after processing this batch is:  0.2076951414346695\n",
      "The representation loss after processing this batch is:  0.003640495240688324\n",
      "\n",
      "The classification loss after processing this batch is:  0.2306005209684372\n",
      "The representation loss after processing this batch is:  0.0036709606647491455\n",
      "\n",
      "The classification loss after processing this batch is:  0.2563476860523224\n",
      "The representation loss after processing this batch is:  0.004163190722465515\n",
      "\n",
      "The classification loss after processing this batch is:  0.171050027012825\n",
      "The representation loss after processing this batch is:  0.004124023020267487\n",
      "\n",
      "The classification loss after processing this batch is:  0.23843000829219818\n",
      "The representation loss after processing this batch is:  0.0034436583518981934\n",
      "\n",
      "The classification loss after processing this batch is:  0.33236828446388245\n",
      "The representation loss after processing this batch is:  0.003193378448486328\n",
      "\n",
      "The classification loss after processing this batch is:  0.22002744674682617\n",
      "The representation loss after processing this batch is:  0.0035529211163520813\n",
      "\n",
      "The classification loss after processing this batch is:  0.3394066393375397\n",
      "The representation loss after processing this batch is:  0.003242064267396927\n",
      "\n",
      "The classification loss after processing this batch is:  0.29643768072128296\n",
      "The representation loss after processing this batch is:  0.0031966567039489746\n",
      "\n",
      "The classification loss after processing this batch is:  0.16778403520584106\n",
      "The representation loss after processing this batch is:  0.003683537244796753\n",
      "\n",
      "The classification loss after processing this batch is:  0.2226298451423645\n",
      "The representation loss after processing this batch is:  0.0032831355929374695\n",
      "\n",
      "The classification loss after processing this batch is:  0.28088295459747314\n",
      "The representation loss after processing this batch is:  0.0037842392921447754\n",
      "\n",
      "The classification loss after processing this batch is:  0.22314049303531647\n",
      "The representation loss after processing this batch is:  0.003782413899898529\n",
      "\n",
      "The classification loss after processing this batch is:  0.4762963056564331\n",
      "The representation loss after processing this batch is:  0.0034446269273757935\n",
      "\n",
      "The classification loss after processing this batch is:  0.32634931802749634\n",
      "The representation loss after processing this batch is:  0.003989763557910919\n",
      "\n",
      "The classification loss after processing this batch is:  0.3426213264465332\n",
      "The representation loss after processing this batch is:  0.003752961754798889\n",
      "\n",
      "The classification loss after processing this batch is:  0.24259574711322784\n",
      "The representation loss after processing this batch is:  0.003264274448156357\n",
      "\n",
      "The classification loss after processing this batch is:  0.2932218909263611\n",
      "The representation loss after processing this batch is:  0.0035415776073932648\n",
      "\n",
      "The classification loss after processing this batch is:  0.25726547837257385\n",
      "The representation loss after processing this batch is:  0.0032253414392471313\n",
      "\n",
      "The classification loss after processing this batch is:  0.29954835772514343\n",
      "The representation loss after processing this batch is:  0.003255024552345276\n",
      "\n",
      "The classification loss after processing this batch is:  0.29940101504325867\n",
      "The representation loss after processing this batch is:  0.003907196223735809\n",
      "\n",
      "The classification loss after processing this batch is:  0.3215743601322174\n",
      "The representation loss after processing this batch is:  0.004284858703613281\n",
      "\n",
      "The classification loss after processing this batch is:  0.3013629913330078\n",
      "The representation loss after processing this batch is:  0.00385361909866333\n",
      "\n",
      "The classification loss after processing this batch is:  0.28512561321258545\n",
      "The representation loss after processing this batch is:  0.003404289484024048\n",
      "\n",
      "The classification loss after processing this batch is:  0.36797961592674255\n",
      "The representation loss after processing this batch is:  0.003824964165687561\n",
      "\n",
      "The classification loss after processing this batch is:  0.26854240894317627\n",
      "The representation loss after processing this batch is:  0.0034591779112815857\n",
      "\n",
      "The classification loss after processing this batch is:  0.27129918336868286\n",
      "The representation loss after processing this batch is:  0.003530852496623993\n",
      "\n",
      "The classification loss after processing this batch is:  0.23321104049682617\n",
      "The representation loss after processing this batch is:  0.003611914813518524\n",
      "\n",
      "The classification loss after processing this batch is:  0.244119793176651\n",
      "The representation loss after processing this batch is:  0.004394404590129852\n",
      "\n",
      "The classification loss after processing this batch is:  0.20243927836418152\n",
      "The representation loss after processing this batch is:  0.00420026108622551\n",
      "\n",
      "The classification loss after processing this batch is:  0.30249422788619995\n",
      "The representation loss after processing this batch is:  0.003183860331773758\n",
      "\n",
      "The classification loss after processing this batch is:  0.4414016604423523\n",
      "The representation loss after processing this batch is:  0.00376201793551445\n",
      "\n",
      "The classification loss after processing this batch is:  0.21204549074172974\n",
      "The representation loss after processing this batch is:  0.0040016695857048035\n",
      "\n",
      "The classification loss after processing this batch is:  0.38090211153030396\n",
      "The representation loss after processing this batch is:  0.0038456879556179047\n",
      "\n",
      "The classification loss after processing this batch is:  0.3969426453113556\n",
      "The representation loss after processing this batch is:  0.0034954436123371124\n",
      "\n",
      "The classification loss after processing this batch is:  0.33302396535873413\n",
      "The representation loss after processing this batch is:  0.004277832806110382\n",
      "\n",
      "The classification loss after processing this batch is:  0.2303299903869629\n",
      "The representation loss after processing this batch is:  0.003570888191461563\n",
      "\n",
      "The classification loss after processing this batch is:  0.3830593228340149\n",
      "The representation loss after processing this batch is:  0.00322515144944191\n",
      "\n",
      "The classification loss after processing this batch is:  0.36635974049568176\n",
      "The representation loss after processing this batch is:  0.003720007836818695\n",
      "\n",
      "The classification loss after processing this batch is:  0.25666481256484985\n",
      "The representation loss after processing this batch is:  0.003828544169664383\n",
      "\n",
      "The classification loss after processing this batch is:  0.15710881352424622\n",
      "The representation loss after processing this batch is:  0.0038312599062919617\n",
      "\n",
      "The classification loss after processing this batch is:  0.2606468200683594\n",
      "The representation loss after processing this batch is:  0.0039466992020606995\n",
      "\n",
      "The classification loss after processing this batch is:  0.24758516252040863\n",
      "The representation loss after processing this batch is:  0.004098132252693176\n",
      "\n",
      "The classification loss after processing this batch is:  0.3029155135154724\n",
      "The representation loss after processing this batch is:  0.0033837147057056427\n",
      "\n",
      "The classification loss after processing this batch is:  0.38361114263534546\n",
      "The representation loss after processing this batch is:  0.003907490521669388\n",
      "\n",
      "The classification loss after processing this batch is:  0.30641621351242065\n",
      "The representation loss after processing this batch is:  0.0032505132257938385\n",
      "\n",
      "The classification loss after processing this batch is:  0.2704191207885742\n",
      "The representation loss after processing this batch is:  0.0046999454498291016\n",
      "\n",
      "The classification loss after processing this batch is:  0.2951109707355499\n",
      "The representation loss after processing this batch is:  0.004182975739240646\n",
      "\n",
      "The classification loss after processing this batch is:  0.2707602381706238\n",
      "The representation loss after processing this batch is:  0.004466094076633453\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.25570210814476013\n",
      "The representation loss after processing this batch is:  0.0037588104605674744\n",
      "\n",
      "The classification loss after processing this batch is:  0.46344324946403503\n",
      "The representation loss after processing this batch is:  0.00388249009847641\n",
      "\n",
      "The classification loss after processing this batch is:  0.3463391661643982\n",
      "The representation loss after processing this batch is:  0.004124559462070465\n",
      "\n",
      "The classification loss after processing this batch is:  0.2435952126979828\n",
      "The representation loss after processing this batch is:  0.003539830446243286\n",
      "\n",
      "The classification loss after processing this batch is:  0.2127041220664978\n",
      "The representation loss after processing this batch is:  0.003495398908853531\n",
      "\n",
      "The classification loss after processing this batch is:  0.21381695568561554\n",
      "The representation loss after processing this batch is:  0.0030876025557518005\n",
      "\n",
      "The classification loss after processing this batch is:  0.19561335444450378\n",
      "The representation loss after processing this batch is:  0.003917194902896881\n",
      "\n",
      "The classification loss after processing this batch is:  0.22947420179843903\n",
      "The representation loss after processing this batch is:  0.0032933056354522705\n",
      "\n",
      "The classification loss after processing this batch is:  0.39898183941841125\n",
      "The representation loss after processing this batch is:  0.0031759999692440033\n",
      "\n",
      "The classification loss after processing this batch is:  0.4096260070800781\n",
      "The representation loss after processing this batch is:  0.004047371447086334\n",
      "\n",
      "The classification loss after processing this batch is:  0.29506346583366394\n",
      "The representation loss after processing this batch is:  0.0031720437109470367\n",
      "\n",
      "The classification loss after processing this batch is:  0.24652573466300964\n",
      "The representation loss after processing this batch is:  0.003538094460964203\n",
      "\n",
      "The classification loss after processing this batch is:  0.22984860837459564\n",
      "The representation loss after processing this batch is:  0.003786575049161911\n",
      "\n",
      "The classification loss after processing this batch is:  0.2579236924648285\n",
      "The representation loss after processing this batch is:  0.003415234386920929\n",
      "\n",
      "The classification loss after processing this batch is:  0.3841957449913025\n",
      "The representation loss after processing this batch is:  0.0038391277194023132\n",
      "\n",
      "The classification loss after processing this batch is:  0.28979071974754333\n",
      "The representation loss after processing this batch is:  0.0032080449163913727\n",
      "\n",
      "The classification loss after processing this batch is:  0.3668670058250427\n",
      "The representation loss after processing this batch is:  0.0036320462822914124\n",
      "\n",
      "The classification loss after processing this batch is:  0.28178709745407104\n",
      "The representation loss after processing this batch is:  0.0034176409244537354\n",
      "\n",
      "The classification loss after processing this batch is:  0.13730669021606445\n",
      "The representation loss after processing this batch is:  0.00390644371509552\n",
      "\n",
      "The classification loss after processing this batch is:  0.3137393295764923\n",
      "The representation loss after processing this batch is:  0.0037702620029449463\n",
      "\n",
      "The classification loss after processing this batch is:  0.2867221534252167\n",
      "The representation loss after processing this batch is:  0.0033318698406219482\n",
      "\n",
      "The classification loss after processing this batch is:  0.345507949590683\n",
      "The representation loss after processing this batch is:  0.003675416111946106\n",
      "\n",
      "The classification loss after processing this batch is:  0.31098663806915283\n",
      "The representation loss after processing this batch is:  0.0031179897487163544\n",
      "\n",
      "The classification loss after processing this batch is:  0.3524710536003113\n",
      "The representation loss after processing this batch is:  0.003161683678627014\n",
      "\n",
      "The classification loss after processing this batch is:  0.32383087277412415\n",
      "The representation loss after processing this batch is:  0.0035557299852371216\n",
      "\n",
      "The classification loss after processing this batch is:  0.3574993908405304\n",
      "The representation loss after processing this batch is:  0.003472398966550827\n",
      "\n",
      "The classification loss after processing this batch is:  0.4013535678386688\n",
      "The representation loss after processing this batch is:  0.0034970641136169434\n",
      "\n",
      "The classification loss after processing this batch is:  0.43865278363227844\n",
      "The representation loss after processing this batch is:  0.0032111182808876038\n",
      "\n",
      "The classification loss after processing this batch is:  0.3248157501220703\n",
      "The representation loss after processing this batch is:  0.0031851157546043396\n",
      "\n",
      "The classification loss after processing this batch is:  0.1828376203775406\n",
      "The representation loss after processing this batch is:  0.00431746244430542\n",
      "\n",
      "The classification loss after processing this batch is:  0.12567321956157684\n",
      "The representation loss after processing this batch is:  0.0035519972443580627\n",
      "\n",
      "The classification loss after processing this batch is:  0.25480130314826965\n",
      "The representation loss after processing this batch is:  0.0036946386098861694\n",
      "\n",
      "The classification loss after processing this batch is:  0.1640966534614563\n",
      "The representation loss after processing this batch is:  0.0059060826897621155\n",
      "\n",
      "The classification loss after processing this batch is:  0.31504160165786743\n",
      "The representation loss after processing this batch is:  0.0036707520484924316\n",
      "\n",
      "The classification loss after processing this batch is:  0.20123952627182007\n",
      "The representation loss after processing this batch is:  0.003924921154975891\n",
      "\n",
      "The classification loss after processing this batch is:  0.30710458755493164\n",
      "The representation loss after processing this batch is:  0.0035247281193733215\n",
      "\n",
      "The classification loss after processing this batch is:  0.13286428153514862\n",
      "The representation loss after processing this batch is:  0.00401567667722702\n",
      "\n",
      "The classification loss after processing this batch is:  0.3085401654243469\n",
      "The representation loss after processing this batch is:  0.0036750920116901398\n",
      "\n",
      "The classification loss after processing this batch is:  0.2403610497713089\n",
      "The representation loss after processing this batch is:  0.003745250403881073\n",
      "\n",
      "The classification loss after processing this batch is:  0.2871578335762024\n",
      "The representation loss after processing this batch is:  0.0036654993891716003\n",
      "\n",
      "The classification loss after processing this batch is:  0.2828393280506134\n",
      "The representation loss after processing this batch is:  0.0033900216221809387\n",
      "\n",
      "The classification loss after processing this batch is:  0.18640832602977753\n",
      "The representation loss after processing this batch is:  0.002901580184698105\n",
      "\n",
      "The classification loss after processing this batch is:  0.23867228627204895\n",
      "The representation loss after processing this batch is:  0.0035049617290496826\n",
      "\n",
      "The classification loss after processing this batch is:  0.28306975960731506\n",
      "The representation loss after processing this batch is:  0.003526538610458374\n",
      "\n",
      "The classification loss after processing this batch is:  0.2644668221473694\n",
      "The representation loss after processing this batch is:  0.0037559643387794495\n",
      "\n",
      "The classification loss after processing this batch is:  0.1983059048652649\n",
      "The representation loss after processing this batch is:  0.0036852359771728516\n",
      "\n",
      "The classification loss after processing this batch is:  0.19313694536685944\n",
      "The representation loss after processing this batch is:  0.0038127601146698\n",
      "\n",
      "The classification loss after processing this batch is:  0.11934743076562881\n",
      "The representation loss after processing this batch is:  0.0038590803742408752\n",
      "\n",
      "The classification loss after processing this batch is:  0.1886782944202423\n",
      "The representation loss after processing this batch is:  0.004320718348026276\n",
      "\n",
      "The classification loss after processing this batch is:  0.1552320420742035\n",
      "The representation loss after processing this batch is:  0.004103861749172211\n",
      "\n",
      "The classification loss after processing this batch is:  0.30945679545402527\n",
      "The representation loss after processing this batch is:  0.0038310252130031586\n",
      "\n",
      "The classification loss after processing this batch is:  0.16925519704818726\n",
      "The representation loss after processing this batch is:  0.0037847310304641724\n",
      "\n",
      "The classification loss after processing this batch is:  0.18270301818847656\n",
      "The representation loss after processing this batch is:  0.003246992826461792\n",
      "\n",
      "The classification loss after processing this batch is:  0.25069329142570496\n",
      "The representation loss after processing this batch is:  0.003963641822338104\n",
      "\n",
      "The classification loss after processing this batch is:  0.2641421854496002\n",
      "The representation loss after processing this batch is:  0.0032008886337280273\n",
      "\n",
      "The classification loss after processing this batch is:  0.27787476778030396\n",
      "The representation loss after processing this batch is:  0.0031305402517318726\n",
      "\n",
      "The classification loss after processing this batch is:  0.1757693588733673\n",
      "The representation loss after processing this batch is:  0.003755614161491394\n",
      "\n",
      "The classification loss after processing this batch is:  0.1493896096944809\n",
      "The representation loss after processing this batch is:  0.003433428704738617\n",
      "\n",
      "The classification loss after processing this batch is:  0.15272799134254456\n",
      "The representation loss after processing this batch is:  0.0037139728665351868\n",
      "\n",
      "The classification loss after processing this batch is:  0.23552373051643372\n",
      "The representation loss after processing this batch is:  0.003932096064090729\n",
      "\n",
      "The classification loss after processing this batch is:  0.2658296823501587\n",
      "The representation loss after processing this batch is:  0.0037895366549491882\n",
      "\n",
      "The classification loss after processing this batch is:  0.2007070928812027\n",
      "The representation loss after processing this batch is:  0.0036085769534111023\n",
      "\n",
      "The classification loss after processing this batch is:  0.33624598383903503\n",
      "The representation loss after processing this batch is:  0.0035556964576244354\n",
      "\n",
      "The classification loss after processing this batch is:  0.1983329951763153\n",
      "The representation loss after processing this batch is:  0.003543764352798462\n",
      "\n",
      "The classification loss after processing this batch is:  0.2699560225009918\n",
      "The representation loss after processing this batch is:  0.0034158341586589813\n",
      "\n",
      "The classification loss after processing this batch is:  0.332304447889328\n",
      "The representation loss after processing this batch is:  0.003559272736310959\n",
      "\n",
      "The classification loss after processing this batch is:  0.23080727458000183\n",
      "The representation loss after processing this batch is:  0.0034504085779190063\n",
      "\n",
      "The classification loss after processing this batch is:  0.35825058817863464\n",
      "The representation loss after processing this batch is:  0.003699246793985367\n",
      "\n",
      "The classification loss after processing this batch is:  0.25572633743286133\n",
      "The representation loss after processing this batch is:  0.0030530989170074463\n",
      "\n",
      "The classification loss after processing this batch is:  0.25624144077301025\n",
      "The representation loss after processing this batch is:  0.003622889518737793\n",
      "\n",
      "The classification loss after processing this batch is:  0.24658343195915222\n",
      "The representation loss after processing this batch is:  0.0034782811999320984\n",
      "\n",
      "The classification loss after processing this batch is:  0.2364092767238617\n",
      "The representation loss after processing this batch is:  0.0038288310170173645\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.23216110467910767\n",
      "The representation loss after processing this batch is:  0.002942349761724472\n",
      "\n",
      "The classification loss after processing this batch is:  0.2641088664531708\n",
      "The representation loss after processing this batch is:  0.0033039897680282593\n",
      "\n",
      "The classification loss after processing this batch is:  0.31238606572151184\n",
      "The representation loss after processing this batch is:  0.0034352801740169525\n",
      "\n",
      "The classification loss after processing this batch is:  0.2285662442445755\n",
      "The representation loss after processing this batch is:  0.003710635006427765\n",
      "\n",
      "The classification loss after processing this batch is:  0.16981008648872375\n",
      "The representation loss after processing this batch is:  0.0030763596296310425\n",
      "\n",
      "The classification loss after processing this batch is:  0.25503408908843994\n",
      "The representation loss after processing this batch is:  0.003054201602935791\n",
      "\n",
      "The classification loss after processing this batch is:  0.2872913181781769\n",
      "The representation loss after processing this batch is:  0.0029592812061309814\n",
      "\n",
      "The classification loss after processing this batch is:  0.17202065885066986\n",
      "The representation loss after processing this batch is:  0.0033600330352783203\n",
      "\n",
      "The classification loss after processing this batch is:  0.24630075693130493\n",
      "The representation loss after processing this batch is:  0.0035453327000141144\n",
      "\n",
      "The classification loss after processing this batch is:  0.25828883051872253\n",
      "The representation loss after processing this batch is:  0.0030972734093666077\n",
      "\n",
      "The classification loss after processing this batch is:  0.1754179447889328\n",
      "The representation loss after processing this batch is:  0.00383102148771286\n",
      "\n",
      "The classification loss after processing this batch is:  0.18203993141651154\n",
      "The representation loss after processing this batch is:  0.004107125103473663\n",
      "\n",
      "The classification loss after processing this batch is:  0.21364951133728027\n",
      "The representation loss after processing this batch is:  0.0038140490651130676\n",
      "\n",
      "The classification loss after processing this batch is:  0.20252589881420135\n",
      "The representation loss after processing this batch is:  0.0036270692944526672\n",
      "\n",
      "The classification loss after processing this batch is:  0.22785186767578125\n",
      "The representation loss after processing this batch is:  0.003935527056455612\n",
      "\n",
      "The classification loss after processing this batch is:  0.23326745629310608\n",
      "The representation loss after processing this batch is:  0.0038474872708320618\n",
      "\n",
      "The classification loss after processing this batch is:  0.1972372978925705\n",
      "The representation loss after processing this batch is:  0.003668230026960373\n",
      "\n",
      "The classification loss after processing this batch is:  0.2660568058490753\n",
      "The representation loss after processing this batch is:  0.0030087679624557495\n",
      "\n",
      "The classification loss after processing this batch is:  0.30605900287628174\n",
      "The representation loss after processing this batch is:  0.00340261310338974\n",
      "\n",
      "The classification loss after processing this batch is:  0.1267925649881363\n",
      "The representation loss after processing this batch is:  0.0041845813393592834\n",
      "\n",
      "The classification loss after processing this batch is:  0.17975997924804688\n",
      "The representation loss after processing this batch is:  0.003511127084493637\n",
      "\n",
      "The classification loss after processing this batch is:  0.22342577576637268\n",
      "The representation loss after processing this batch is:  0.0033058971166610718\n",
      "\n",
      "The classification loss after processing this batch is:  0.24727846682071686\n",
      "The representation loss after processing this batch is:  0.0036930814385414124\n",
      "\n",
      "The classification loss after processing this batch is:  0.23715639114379883\n",
      "The representation loss after processing this batch is:  0.0034796670079231262\n",
      "\n",
      "The classification loss after processing this batch is:  0.2755368649959564\n",
      "The representation loss after processing this batch is:  0.003578227013349533\n",
      "\n",
      "The classification loss after processing this batch is:  0.2166261374950409\n",
      "The representation loss after processing this batch is:  0.00430944561958313\n",
      "\n",
      "The classification loss after processing this batch is:  0.20334887504577637\n",
      "The representation loss after processing this batch is:  0.0037851519882678986\n",
      "\n",
      "The classification loss after processing this batch is:  0.3184215724468231\n",
      "The representation loss after processing this batch is:  0.0036076977849006653\n",
      "\n",
      "The classification loss after processing this batch is:  0.3126372694969177\n",
      "The representation loss after processing this batch is:  0.0032357685267925262\n",
      "\n",
      "The classification loss after processing this batch is:  0.25314709544181824\n",
      "The representation loss after processing this batch is:  0.0033262036740779877\n",
      "\n",
      "The classification loss after processing this batch is:  0.16169290244579315\n",
      "The representation loss after processing this batch is:  0.004162922501564026\n",
      "\n",
      "The classification loss after processing this batch is:  0.14046941697597504\n",
      "The representation loss after processing this batch is:  0.0038327574729919434\n",
      "\n",
      "The classification loss after processing this batch is:  0.3309677839279175\n",
      "The representation loss after processing this batch is:  0.0035441555082798004\n",
      "\n",
      "The classification loss after processing this batch is:  0.32294851541519165\n",
      "The representation loss after processing this batch is:  0.003039710223674774\n",
      "\n",
      "The classification loss after processing this batch is:  0.3364974558353424\n",
      "The representation loss after processing this batch is:  0.003774389624595642\n",
      "\n",
      "The classification loss after processing this batch is:  0.2777361571788788\n",
      "The representation loss after processing this batch is:  0.0031939372420310974\n",
      "\n",
      "The classification loss after processing this batch is:  0.3263154923915863\n",
      "The representation loss after processing this batch is:  0.003714095801115036\n",
      "\n",
      "The classification loss after processing this batch is:  0.3350953459739685\n",
      "The representation loss after processing this batch is:  0.003298018127679825\n",
      "\n",
      "The classification loss after processing this batch is:  0.3582846224308014\n",
      "The representation loss after processing this batch is:  0.0032273270189762115\n",
      "\n",
      "The classification loss after processing this batch is:  0.3393149673938751\n",
      "The representation loss after processing this batch is:  0.0035250484943389893\n",
      "\n",
      "The classification loss after processing this batch is:  0.3165048360824585\n",
      "The representation loss after processing this batch is:  0.0037785395979881287\n",
      "\n",
      "The classification loss after processing this batch is:  0.22286510467529297\n",
      "The representation loss after processing this batch is:  0.003997497260570526\n",
      "\n",
      "The classification loss after processing this batch is:  0.14519253373146057\n",
      "The representation loss after processing this batch is:  0.003935538232326508\n",
      "\n",
      "The classification loss after processing this batch is:  0.21684637665748596\n",
      "The representation loss after processing this batch is:  0.004062488675117493\n",
      "\n",
      "The classification loss after processing this batch is:  0.22469301521778107\n",
      "The representation loss after processing this batch is:  0.0032226070761680603\n",
      "\n",
      "The classification loss after processing this batch is:  0.18142223358154297\n",
      "The representation loss after processing this batch is:  0.003271348774433136\n",
      "\n",
      "The classification loss after processing this batch is:  0.2297455221414566\n",
      "The representation loss after processing this batch is:  0.0035456083714962006\n",
      "\n",
      "The classification loss after processing this batch is:  0.2521292269229889\n",
      "The representation loss after processing this batch is:  0.003559812903404236\n",
      "\n",
      "The classification loss after processing this batch is:  0.19929876923561096\n",
      "The representation loss after processing this batch is:  0.0032094940543174744\n",
      "\n",
      "The classification loss after processing this batch is:  0.22896505892276764\n",
      "The representation loss after processing this batch is:  0.003448519855737686\n",
      "\n",
      "The classification loss after processing this batch is:  0.21325823664665222\n",
      "The representation loss after processing this batch is:  0.0031713582575321198\n",
      "\n",
      "The classification loss after processing this batch is:  0.22416894137859344\n",
      "The representation loss after processing this batch is:  0.0035147368907928467\n",
      "\n",
      "The classification loss after processing this batch is:  0.22339282929897308\n",
      "The representation loss after processing this batch is:  0.0034296177327632904\n",
      "\n",
      "The classification loss after processing this batch is:  0.2721394896507263\n",
      "The representation loss after processing this batch is:  0.0035743936896324158\n",
      "\n",
      "The classification loss after processing this batch is:  0.24344266951084137\n",
      "The representation loss after processing this batch is:  0.005071915686130524\n",
      "\n",
      "The classification loss after processing this batch is:  0.15881720185279846\n",
      "The representation loss after processing this batch is:  0.003413178026676178\n",
      "\n",
      "The classification loss after processing this batch is:  0.17933307588100433\n",
      "The representation loss after processing this batch is:  0.0038697198033332825\n",
      "\n",
      "The classification loss after processing this batch is:  0.24590447545051575\n",
      "The representation loss after processing this batch is:  0.0034702643752098083\n",
      "\n",
      "The classification loss after processing this batch is:  0.36906641721725464\n",
      "The representation loss after processing this batch is:  0.0034264177083969116\n",
      "\n",
      "The classification loss after processing this batch is:  0.24640604853630066\n",
      "The representation loss after processing this batch is:  0.003172837197780609\n",
      "\n",
      "The classification loss after processing this batch is:  0.1320972889661789\n",
      "The representation loss after processing this batch is:  0.00316045805811882\n",
      "\n",
      "The classification loss after processing this batch is:  0.2376948744058609\n",
      "The representation loss after processing this batch is:  0.003009110689163208\n",
      "\n",
      "The classification loss after processing this batch is:  0.09868904203176498\n",
      "The representation loss after processing this batch is:  0.0038212984800338745\n",
      "\n",
      "The classification loss after processing this batch is:  0.24041986465454102\n",
      "The representation loss after processing this batch is:  0.0034936070442199707\n",
      "\n",
      "The classification loss after processing this batch is:  0.19617077708244324\n",
      "The representation loss after processing this batch is:  0.0036808624863624573\n",
      "\n",
      "The classification loss after processing this batch is:  0.1324843466281891\n",
      "The representation loss after processing this batch is:  0.003200329840183258\n",
      "\n",
      "The classification loss after processing this batch is:  0.1619093269109726\n",
      "The representation loss after processing this batch is:  0.003525868058204651\n",
      "\n",
      "The classification loss after processing this batch is:  0.17509345710277557\n",
      "The representation loss after processing this batch is:  0.0035424605011940002\n",
      "\n",
      "The classification loss after processing this batch is:  0.16214904189109802\n",
      "The representation loss after processing this batch is:  0.003147900104522705\n",
      "\n",
      "The classification loss after processing this batch is:  0.36542659997940063\n",
      "The representation loss after processing this batch is:  0.0033727027475833893\n",
      "\n",
      "The classification loss after processing this batch is:  0.41535621881484985\n",
      "The representation loss after processing this batch is:  0.003541741520166397\n",
      "\n",
      "The classification loss after processing this batch is:  0.28614944219589233\n",
      "The representation loss after processing this batch is:  0.003372516483068466\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.3302837908267975\n",
      "The representation loss after processing this batch is:  0.003916997462511063\n",
      "\n",
      "The classification loss after processing this batch is:  0.27862077951431274\n",
      "The representation loss after processing this batch is:  0.0034773387014865875\n",
      "\n",
      "The classification loss after processing this batch is:  0.2163202315568924\n",
      "The representation loss after processing this batch is:  0.003589421510696411\n",
      "\n",
      "The classification loss after processing this batch is:  0.33041611313819885\n",
      "The representation loss after processing this batch is:  0.003510408103466034\n",
      "\n",
      "The classification loss after processing this batch is:  0.22351369261741638\n",
      "The representation loss after processing this batch is:  0.0036437399685382843\n",
      "\n",
      "The classification loss after processing this batch is:  0.2531587779521942\n",
      "The representation loss after processing this batch is:  0.003041975200176239\n",
      "\n",
      "The classification loss after processing this batch is:  0.2727818191051483\n",
      "The representation loss after processing this batch is:  0.003568485379219055\n",
      "\n",
      "The classification loss after processing this batch is:  0.2583470344543457\n",
      "The representation loss after processing this batch is:  0.003020305186510086\n",
      "\n",
      "The classification loss after processing this batch is:  0.26187819242477417\n",
      "The representation loss after processing this batch is:  0.0034349672496318817\n",
      "\n",
      "The classification loss after processing this batch is:  0.2601282000541687\n",
      "The representation loss after processing this batch is:  0.0033836886286735535\n",
      "\n",
      "The classification loss after processing this batch is:  0.2746669054031372\n",
      "The representation loss after processing this batch is:  0.0036770477890968323\n",
      "\n",
      "The classification loss after processing this batch is:  0.20566272735595703\n",
      "The representation loss after processing this batch is:  0.0035050883889198303\n",
      "\n",
      "The classification loss after processing this batch is:  0.18691648542881012\n",
      "The representation loss after processing this batch is:  0.003686167299747467\n",
      "\n",
      "The classification loss after processing this batch is:  0.22522644698619843\n",
      "The representation loss after processing this batch is:  0.003070373088121414\n",
      "\n",
      "The classification loss after processing this batch is:  0.28191840648651123\n",
      "The representation loss after processing this batch is:  0.0036413222551345825\n",
      "\n",
      "The classification loss after processing this batch is:  0.12102887779474258\n",
      "The representation loss after processing this batch is:  0.003135688602924347\n",
      "\n",
      "The classification loss after processing this batch is:  0.1922919899225235\n",
      "The representation loss after processing this batch is:  0.003184136003255844\n",
      "\n",
      "The classification loss after processing this batch is:  0.3255530893802643\n",
      "The representation loss after processing this batch is:  0.0033121779561042786\n",
      "\n",
      "The classification loss after processing this batch is:  0.2618055045604706\n",
      "The representation loss after processing this batch is:  0.003083735704421997\n",
      "\n",
      "The classification loss after processing this batch is:  0.21787399053573608\n",
      "The representation loss after processing this batch is:  0.0034690499305725098\n",
      "\n",
      "The classification loss after processing this batch is:  0.37866970896720886\n",
      "The representation loss after processing this batch is:  0.003285590559244156\n",
      "\n",
      "The classification loss after processing this batch is:  0.15970243513584137\n",
      "The representation loss after processing this batch is:  0.004127047955989838\n",
      "\n",
      "The classification loss after processing this batch is:  0.14507578313350677\n",
      "The representation loss after processing this batch is:  0.00310666486620903\n",
      "\n",
      "The classification loss after processing this batch is:  0.18216028809547424\n",
      "The representation loss after processing this batch is:  0.0034430399537086487\n",
      "\n",
      "The classification loss after processing this batch is:  0.25368741154670715\n",
      "The representation loss after processing this batch is:  0.004002474248409271\n",
      "\n",
      "The classification loss after processing this batch is:  0.25562453269958496\n",
      "The representation loss after processing this batch is:  0.0037651658058166504\n",
      "\n",
      "The classification loss after processing this batch is:  0.1980806291103363\n",
      "The representation loss after processing this batch is:  0.0039925649762153625\n",
      "\n",
      "The classification loss after processing this batch is:  0.23871712386608124\n",
      "The representation loss after processing this batch is:  0.003236837685108185\n",
      "\n",
      "The classification loss after processing this batch is:  0.20904047787189484\n",
      "The representation loss after processing this batch is:  0.0034782923758029938\n",
      "\n",
      "The classification loss after processing this batch is:  0.23697850108146667\n",
      "The representation loss after processing this batch is:  0.0036137886345386505\n",
      "\n",
      "The classification loss after processing this batch is:  0.24369308352470398\n",
      "The representation loss after processing this batch is:  0.00357871875166893\n",
      "\n",
      "The classification loss after processing this batch is:  0.33665651082992554\n",
      "The representation loss after processing this batch is:  0.003250792622566223\n",
      "\n",
      "The classification loss after processing this batch is:  0.31222811341285706\n",
      "The representation loss after processing this batch is:  0.0036891289055347443\n",
      "\n",
      "The classification loss after processing this batch is:  0.37387049198150635\n",
      "The representation loss after processing this batch is:  0.0031475648283958435\n",
      "\n",
      "The classification loss after processing this batch is:  0.3162899613380432\n",
      "The representation loss after processing this batch is:  0.003189999610185623\n",
      "\n",
      "The classification loss after processing this batch is:  0.3005329668521881\n",
      "The representation loss after processing this batch is:  0.003429871052503586\n",
      "\n",
      "The classification loss after processing this batch is:  0.3298914134502411\n",
      "The representation loss after processing this batch is:  0.0035438276827335358\n",
      "\n",
      "The classification loss after processing this batch is:  0.11651893705129623\n",
      "The representation loss after processing this batch is:  0.003990098834037781\n",
      "\n",
      "The classification loss after processing this batch is:  0.21253159642219543\n",
      "The representation loss after processing this batch is:  0.004577916115522385\n",
      "\n",
      "The classification loss after processing this batch is:  0.1812743842601776\n",
      "The representation loss after processing this batch is:  0.004347212612628937\n",
      "\n",
      "The classification loss after processing this batch is:  0.1930115669965744\n",
      "The representation loss after processing this batch is:  0.004368770867586136\n",
      "\n",
      "The classification loss after processing this batch is:  0.2473902702331543\n",
      "The representation loss after processing this batch is:  0.0026994459331035614\n",
      "\n",
      "The classification loss after processing this batch is:  0.23085927963256836\n",
      "The representation loss after processing this batch is:  0.0032651126384735107\n",
      "\n",
      "The classification loss after processing this batch is:  0.22951485216617584\n",
      "The representation loss after processing this batch is:  0.0034671910107135773\n",
      "\n",
      "The classification loss after processing this batch is:  0.30215519666671753\n",
      "The representation loss after processing this batch is:  0.0032130032777786255\n",
      "\n",
      "The classification loss after processing this batch is:  0.2539861798286438\n",
      "The representation loss after processing this batch is:  0.0033818036317825317\n",
      "\n",
      "The classification loss after processing this batch is:  0.32111361622810364\n",
      "The representation loss after processing this batch is:  0.0038091614842414856\n",
      "\n",
      "The classification loss after processing this batch is:  0.24341657757759094\n",
      "The representation loss after processing this batch is:  0.0039800480008125305\n",
      "\n",
      "The classification loss after processing this batch is:  0.25787225365638733\n",
      "The representation loss after processing this batch is:  0.003046654164791107\n",
      "\n",
      "The classification loss after processing this batch is:  0.22589166462421417\n",
      "The representation loss after processing this batch is:  0.003855682909488678\n",
      "\n",
      "The classification loss after processing this batch is:  0.2888253629207611\n",
      "The representation loss after processing this batch is:  0.004120390862226486\n",
      "\n",
      "The classification loss after processing this batch is:  0.40612801909446716\n",
      "The representation loss after processing this batch is:  0.004123300313949585\n",
      "\n",
      "The classification loss after processing this batch is:  0.13555166125297546\n",
      "The representation loss after processing this batch is:  0.0029945969581604004\n",
      "\n",
      "The classification loss after processing this batch is:  0.16108296811580658\n",
      "The representation loss after processing this batch is:  0.0035959668457508087\n",
      "\n",
      "The classification loss after processing this batch is:  0.3333113491535187\n",
      "The representation loss after processing this batch is:  0.003811921924352646\n",
      "\n",
      "The classification loss after processing this batch is:  0.15369455516338348\n",
      "The representation loss after processing this batch is:  0.0036957263946533203\n",
      "\n",
      "The classification loss after processing this batch is:  0.2565830647945404\n",
      "The representation loss after processing this batch is:  0.0032857656478881836\n",
      "\n",
      "The classification loss after processing this batch is:  0.2562064528465271\n",
      "The representation loss after processing this batch is:  0.0037915557622909546\n",
      "\n",
      "The classification loss after processing this batch is:  0.24533751606941223\n",
      "The representation loss after processing this batch is:  0.003415655344724655\n",
      "\n",
      "The classification loss after processing this batch is:  0.364467054605484\n",
      "The representation loss after processing this batch is:  0.004240311682224274\n",
      "\n",
      "The classification loss after processing this batch is:  0.3044638931751251\n",
      "The representation loss after processing this batch is:  0.003708329051733017\n",
      "\n",
      "The classification loss after processing this batch is:  0.33055737614631653\n",
      "The representation loss after processing this batch is:  0.0041808560490608215\n",
      "\n",
      "The classification loss after processing this batch is:  0.19218245148658752\n",
      "The representation loss after processing this batch is:  0.0030172616243362427\n",
      "\n",
      "The classification loss after processing this batch is:  0.321833997964859\n",
      "The representation loss after processing this batch is:  0.002878677099943161\n",
      "\n",
      "The classification loss after processing this batch is:  0.1441073715686798\n",
      "The representation loss after processing this batch is:  0.0033799931406974792\n",
      "\n",
      "The classification loss after processing this batch is:  0.12061019986867905\n",
      "The representation loss after processing this batch is:  0.003112807869911194\n",
      "\n",
      "The classification loss after processing this batch is:  0.19527561962604523\n",
      "The representation loss after processing this batch is:  0.0031011179089546204\n",
      "\n",
      "The classification loss after processing this batch is:  0.13416427373886108\n",
      "The representation loss after processing this batch is:  0.0032866448163986206\n",
      "\n",
      "The classification loss after processing this batch is:  0.22375689446926117\n",
      "The representation loss after processing this batch is:  0.0032265186309814453\n",
      "\n",
      "The classification loss after processing this batch is:  0.1325794756412506\n",
      "The representation loss after processing this batch is:  0.003000423312187195\n",
      "\n",
      "The classification loss after processing this batch is:  0.21001116931438446\n",
      "The representation loss after processing this batch is:  0.0030413269996643066\n",
      "\n",
      "The classification loss after processing this batch is:  0.2148006409406662\n",
      "The representation loss after processing this batch is:  0.003064122051000595\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.31288382411003113\n",
      "The representation loss after processing this batch is:  0.003704659640789032\n",
      "\n",
      "The classification loss after processing this batch is:  0.29497385025024414\n",
      "The representation loss after processing this batch is:  0.0029894039034843445\n",
      "\n",
      "The classification loss after processing this batch is:  0.17114776372909546\n",
      "The representation loss after processing this batch is:  0.004007279872894287\n",
      "\n",
      "The classification loss after processing this batch is:  0.29059484601020813\n",
      "The representation loss after processing this batch is:  0.00333201140165329\n",
      "\n",
      "The classification loss after processing this batch is:  0.208891361951828\n",
      "The representation loss after processing this batch is:  0.0033504776656627655\n",
      "\n",
      "The classification loss after processing this batch is:  0.2892637252807617\n",
      "The representation loss after processing this batch is:  0.0034789331257343292\n",
      "\n",
      "The classification loss after processing this batch is:  0.41761261224746704\n",
      "The representation loss after processing this batch is:  0.003405176103115082\n",
      "\n",
      "The classification loss after processing this batch is:  0.25017136335372925\n",
      "The representation loss after processing this batch is:  0.0031495317816734314\n",
      "\n",
      "The classification loss after processing this batch is:  0.31152471899986267\n",
      "The representation loss after processing this batch is:  0.003049265593290329\n",
      "\n",
      "The classification loss after processing this batch is:  0.2573891580104828\n",
      "The representation loss after processing this batch is:  0.0030771344900131226\n",
      "\n",
      "The classification loss after processing this batch is:  0.28367307782173157\n",
      "The representation loss after processing this batch is:  0.003159724175930023\n",
      "\n",
      "The classification loss after processing this batch is:  0.20429010689258575\n",
      "The representation loss after processing this batch is:  0.003522731363773346\n",
      "\n",
      "The classification loss after processing this batch is:  0.16400478780269623\n",
      "The representation loss after processing this batch is:  0.003084130585193634\n",
      "\n",
      "The classification loss after processing this batch is:  0.17701773345470428\n",
      "The representation loss after processing this batch is:  0.003263227641582489\n",
      "\n",
      "The classification loss after processing this batch is:  0.16753734648227692\n",
      "The representation loss after processing this batch is:  0.0033522695302963257\n",
      "\n",
      "The classification loss after processing this batch is:  0.12874116003513336\n",
      "The representation loss after processing this batch is:  0.003567330539226532\n",
      "\n",
      "The classification loss after processing this batch is:  0.24893873929977417\n",
      "The representation loss after processing this batch is:  0.0033539682626724243\n",
      "\n",
      "The classification loss after processing this batch is:  0.16092948615550995\n",
      "The representation loss after processing this batch is:  0.0039297789335250854\n",
      "\n",
      "The classification loss after processing this batch is:  0.33334535360336304\n",
      "The representation loss after processing this batch is:  0.0039879269897937775\n",
      "\n",
      "The classification loss after processing this batch is:  0.1961144059896469\n",
      "The representation loss after processing this batch is:  0.003893911838531494\n",
      "\n",
      "The classification loss after processing this batch is:  0.25780120491981506\n",
      "The representation loss after processing this batch is:  0.0036951079964637756\n",
      "\n",
      "The classification loss after processing this batch is:  0.3764273226261139\n",
      "The representation loss after processing this batch is:  0.0031768903136253357\n",
      "\n",
      "The classification loss after processing this batch is:  0.2687660753726959\n",
      "The representation loss after processing this batch is:  0.0029383860528469086\n",
      "\n",
      "The classification loss after processing this batch is:  0.15115733444690704\n",
      "The representation loss after processing this batch is:  0.0033478066325187683\n",
      "\n",
      "The classification loss after processing this batch is:  0.15151606500148773\n",
      "The representation loss after processing this batch is:  0.003782518208026886\n",
      "\n",
      "The classification loss after processing this batch is:  0.16132578253746033\n",
      "The representation loss after processing this batch is:  0.0035034939646720886\n",
      "\n",
      "The classification loss after processing this batch is:  0.17220449447631836\n",
      "The representation loss after processing this batch is:  0.003406532108783722\n",
      "\n",
      "The classification loss after processing this batch is:  0.17387227714061737\n",
      "The representation loss after processing this batch is:  0.0026498734951019287\n",
      "\n",
      "The classification loss after processing this batch is:  0.38084638118743896\n",
      "The representation loss after processing this batch is:  0.003199312835931778\n",
      "\n",
      "The classification loss after processing this batch is:  0.37480857968330383\n",
      "The representation loss after processing this batch is:  0.0032301507890224457\n",
      "\n",
      "The classification loss after processing this batch is:  0.18818680942058563\n",
      "The representation loss after processing this batch is:  0.003700152039527893\n",
      "\n",
      "The classification loss after processing this batch is:  0.3449367582798004\n",
      "The representation loss after processing this batch is:  0.0036532580852508545\n",
      "\n",
      "The classification loss after processing this batch is:  0.14224866032600403\n",
      "The representation loss after processing this batch is:  0.003349706530570984\n",
      "\n",
      "The classification loss after processing this batch is:  0.23627185821533203\n",
      "The representation loss after processing this batch is:  0.0035319700837135315\n",
      "\n",
      "The classification loss after processing this batch is:  0.3077731430530548\n",
      "The representation loss after processing this batch is:  0.0033172816038131714\n",
      "\n",
      "The classification loss after processing this batch is:  0.2238612025976181\n",
      "The representation loss after processing this batch is:  0.004172034561634064\n",
      "\n",
      "The classification loss after processing this batch is:  0.2387949526309967\n",
      "The representation loss after processing this batch is:  0.005042716860771179\n",
      "\n",
      "The classification loss after processing this batch is:  0.17418935894966125\n",
      "The representation loss after processing this batch is:  0.004151776432991028\n",
      "\n",
      "The classification loss after processing this batch is:  0.2565212845802307\n",
      "The representation loss after processing this batch is:  0.004362471401691437\n",
      "\n",
      "The classification loss after processing this batch is:  0.2791404724121094\n",
      "The representation loss after processing this batch is:  0.004402138292789459\n",
      "\n",
      "The classification loss after processing this batch is:  0.22138771414756775\n",
      "The representation loss after processing this batch is:  0.003932014107704163\n",
      "\n",
      "The classification loss after processing this batch is:  0.21889010071754456\n",
      "The representation loss after processing this batch is:  0.00330912321805954\n",
      "\n",
      "The classification loss after processing this batch is:  0.32138949632644653\n",
      "The representation loss after processing this batch is:  0.002912960946559906\n",
      "\n",
      "The classification loss after processing this batch is:  0.2702215909957886\n",
      "The representation loss after processing this batch is:  0.002978302538394928\n",
      "\n",
      "The classification loss after processing this batch is:  0.2686377167701721\n",
      "The representation loss after processing this batch is:  0.0030307434499263763\n",
      "\n",
      "The classification loss after processing this batch is:  0.1515701413154602\n",
      "The representation loss after processing this batch is:  0.00380803644657135\n",
      "\n",
      "The classification loss after processing this batch is:  0.11096714437007904\n",
      "The representation loss after processing this batch is:  0.0036021992564201355\n",
      "\n",
      "The classification loss after processing this batch is:  0.25575727224349976\n",
      "The representation loss after processing this batch is:  0.0035408958792686462\n",
      "\n",
      "The classification loss after processing this batch is:  0.1760578453540802\n",
      "The representation loss after processing this batch is:  0.003707706928253174\n",
      "\n",
      "The classification loss after processing this batch is:  0.3607248067855835\n",
      "The representation loss after processing this batch is:  0.003257550299167633\n",
      "\n",
      "The classification loss after processing this batch is:  0.12045936286449432\n",
      "The representation loss after processing this batch is:  0.003918930888175964\n",
      "\n",
      "The classification loss after processing this batch is:  0.21079064905643463\n",
      "The representation loss after processing this batch is:  0.002974696457386017\n",
      "\n",
      "The classification loss after processing this batch is:  0.2795427739620209\n",
      "The representation loss after processing this batch is:  0.003792453557252884\n",
      "\n",
      "The classification loss after processing this batch is:  0.2079031616449356\n",
      "The representation loss after processing this batch is:  0.003450140357017517\n",
      "\n",
      "The classification loss after processing this batch is:  0.2932850420475006\n",
      "The representation loss after processing this batch is:  0.00321120023727417\n",
      "\n",
      "The classification loss after processing this batch is:  0.14754916727542877\n",
      "The representation loss after processing this batch is:  0.0037713125348091125\n",
      "\n",
      "The classification loss after processing this batch is:  0.17666710913181305\n",
      "The representation loss after processing this batch is:  0.0031701214611530304\n",
      "\n",
      "The classification loss after processing this batch is:  0.15074443817138672\n",
      "The representation loss after processing this batch is:  0.0030899979174137115\n",
      "\n",
      "The classification loss after processing this batch is:  0.273232638835907\n",
      "The representation loss after processing this batch is:  0.004413403570652008\n",
      "\n",
      "The classification loss after processing this batch is:  0.2789534330368042\n",
      "The representation loss after processing this batch is:  0.0036475397646427155\n",
      "\n",
      "The classification loss after processing this batch is:  0.3043002784252167\n",
      "The representation loss after processing this batch is:  0.0031150728464126587\n",
      "\n",
      "The classification loss after processing this batch is:  0.32940104603767395\n",
      "The representation loss after processing this batch is:  0.0032278522849082947\n",
      "\n",
      "The classification loss after processing this batch is:  0.4144071042537689\n",
      "The representation loss after processing this batch is:  0.0030967891216278076\n",
      "\n",
      "The classification loss after processing this batch is:  0.2281535118818283\n",
      "The representation loss after processing this batch is:  0.0037233158946037292\n",
      "\n",
      "The classification loss after processing this batch is:  0.3777172863483429\n",
      "The representation loss after processing this batch is:  0.0033990293741226196\n",
      "\n",
      "The classification loss after processing this batch is:  0.22265629470348358\n",
      "The representation loss after processing this batch is:  0.00335693359375\n",
      "\n",
      "The classification loss after processing this batch is:  0.17734555900096893\n",
      "The representation loss after processing this batch is:  0.003181472420692444\n",
      "\n",
      "The classification loss after processing this batch is:  0.1568494439125061\n",
      "The representation loss after processing this batch is:  0.0030807480216026306\n",
      "\n",
      "The classification loss after processing this batch is:  0.1517772674560547\n",
      "The representation loss after processing this batch is:  0.003784582018852234\n",
      "\n",
      "The classification loss after processing this batch is:  0.31725677847862244\n",
      "The representation loss after processing this batch is:  0.0036791712045669556\n",
      "\n",
      "The classification loss after processing this batch is:  0.20239369571208954\n",
      "The representation loss after processing this batch is:  0.0036112889647483826\n",
      "\n",
      "The classification loss after processing this batch is:  0.24055616557598114\n",
      "The representation loss after processing this batch is:  0.0038422085344791412\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.20648640394210815\n",
      "The representation loss after processing this batch is:  0.004080519080162048\n",
      "\n",
      "The classification loss after processing this batch is:  0.19971159100532532\n",
      "The representation loss after processing this batch is:  0.003260381519794464\n",
      "\n",
      "The classification loss after processing this batch is:  0.17109426856040955\n",
      "The representation loss after processing this batch is:  0.00344260036945343\n",
      "\n",
      "The classification loss after processing this batch is:  0.2542474865913391\n",
      "The representation loss after processing this batch is:  0.00290071964263916\n",
      "\n",
      "The classification loss after processing this batch is:  0.24620892107486725\n",
      "The representation loss after processing this batch is:  0.003176286816596985\n",
      "\n",
      "The classification loss after processing this batch is:  0.31324055790901184\n",
      "The representation loss after processing this batch is:  0.0036938712000846863\n",
      "\n",
      "The classification loss after processing this batch is:  0.1906568557024002\n",
      "The representation loss after processing this batch is:  0.00314977765083313\n",
      "\n",
      "The classification loss after processing this batch is:  0.39849770069122314\n",
      "The representation loss after processing this batch is:  0.0025239139795303345\n",
      "\n",
      "The classification loss after processing this batch is:  0.22677236795425415\n",
      "The representation loss after processing this batch is:  0.0027747787535190582\n",
      "\n",
      "The classification loss after processing this batch is:  0.2288060188293457\n",
      "The representation loss after processing this batch is:  0.0030507855117321014\n",
      "\n",
      "The classification loss after processing this batch is:  0.19993038475513458\n",
      "The representation loss after processing this batch is:  0.0033922456204891205\n",
      "\n",
      "The classification loss after processing this batch is:  0.17091968655586243\n",
      "The representation loss after processing this batch is:  0.0031684376299381256\n",
      "\n",
      "The classification loss after processing this batch is:  0.18640466034412384\n",
      "The representation loss after processing this batch is:  0.0032767802476882935\n",
      "\n",
      "The classification loss after processing this batch is:  0.16673824191093445\n",
      "The representation loss after processing this batch is:  0.0036257654428482056\n",
      "\n",
      "The classification loss after processing this batch is:  0.275637149810791\n",
      "The representation loss after processing this batch is:  0.0035529807209968567\n",
      "\n",
      "The classification loss after processing this batch is:  0.34556278586387634\n",
      "The representation loss after processing this batch is:  0.003935769200325012\n",
      "\n",
      "The classification loss after processing this batch is:  0.2938966751098633\n",
      "The representation loss after processing this batch is:  0.0037180520594120026\n",
      "\n",
      "The classification loss after processing this batch is:  0.2647527754306793\n",
      "The representation loss after processing this batch is:  0.0034869275987148285\n",
      "\n",
      "The classification loss after processing this batch is:  0.21528272330760956\n",
      "The representation loss after processing this batch is:  0.0041551776230335236\n",
      "\n",
      "The classification loss after processing this batch is:  0.35178497433662415\n",
      "The representation loss after processing this batch is:  0.0030448026955127716\n",
      "\n",
      "The classification loss after processing this batch is:  0.22338555753231049\n",
      "The representation loss after processing this batch is:  0.0032081082463264465\n",
      "\n",
      "The classification loss after processing this batch is:  0.10410647839307785\n",
      "The representation loss after processing this batch is:  0.00335654616355896\n",
      "\n",
      "The classification loss after processing this batch is:  0.20146021246910095\n",
      "The representation loss after processing this batch is:  0.003140673041343689\n",
      "\n",
      "The classification loss after processing this batch is:  0.4120413362979889\n",
      "The representation loss after processing this batch is:  0.003797125071287155\n",
      "\n",
      "The classification loss after processing this batch is:  0.45530185103416443\n",
      "The representation loss after processing this batch is:  0.003093719482421875\n",
      "\n",
      "The classification loss after processing this batch is:  0.41041386127471924\n",
      "The representation loss after processing this batch is:  0.0030555129051208496\n",
      "\n",
      "The classification loss after processing this batch is:  0.28116464614868164\n",
      "The representation loss after processing this batch is:  0.0033062919974327087\n",
      "\n",
      "The classification loss after processing this batch is:  0.19967800378799438\n",
      "The representation loss after processing this batch is:  0.003243491053581238\n",
      "\n",
      "The classification loss after processing this batch is:  0.2044386863708496\n",
      "The representation loss after processing this batch is:  0.0032587647438049316\n",
      "\n",
      "The classification loss after processing this batch is:  0.1941276490688324\n",
      "The representation loss after processing this batch is:  0.003784462809562683\n",
      "\n",
      "The classification loss after processing this batch is:  0.2812381386756897\n",
      "The representation loss after processing this batch is:  0.003832995891571045\n",
      "\n",
      "The classification loss after processing this batch is:  0.2094803750514984\n",
      "The representation loss after processing this batch is:  0.0038745030760765076\n",
      "\n",
      "The classification loss after processing this batch is:  0.2555324137210846\n",
      "The representation loss after processing this batch is:  0.0038589313626289368\n",
      "\n",
      "The classification loss after processing this batch is:  0.21878579258918762\n",
      "The representation loss after processing this batch is:  0.0036353468894958496\n",
      "\n",
      "The classification loss after processing this batch is:  0.16499856114387512\n",
      "The representation loss after processing this batch is:  0.0033050179481506348\n",
      "\n",
      "The classification loss after processing this batch is:  0.2359657734632492\n",
      "The representation loss after processing this batch is:  0.004177197813987732\n",
      "\n",
      "The classification loss after processing this batch is:  0.227386936545372\n",
      "The representation loss after processing this batch is:  0.0032250136137008667\n",
      "\n",
      "The classification loss after processing this batch is:  0.22333653271198273\n",
      "The representation loss after processing this batch is:  0.0031672008335590363\n",
      "\n",
      "The classification loss after processing this batch is:  0.3941245973110199\n",
      "The representation loss after processing this batch is:  0.004357226192951202\n",
      "\n",
      "The classification loss after processing this batch is:  0.39274126291275024\n",
      "The representation loss after processing this batch is:  0.003888048231601715\n",
      "\n",
      "The classification loss after processing this batch is:  0.27673786878585815\n",
      "The representation loss after processing this batch is:  0.004335038363933563\n",
      "\n",
      "The classification loss after processing this batch is:  0.2246580719947815\n",
      "The representation loss after processing this batch is:  0.003772743046283722\n",
      "\n",
      "The classification loss after processing this batch is:  0.2060292363166809\n",
      "The representation loss after processing this batch is:  0.003897435963153839\n",
      "\n",
      "The classification loss after processing this batch is:  0.14223533868789673\n",
      "The representation loss after processing this batch is:  0.00356871634721756\n",
      "\n",
      "The classification loss after processing this batch is:  0.33534500002861023\n",
      "The representation loss after processing this batch is:  0.003491036593914032\n",
      "\n",
      "The classification loss after processing this batch is:  0.2568203806877136\n",
      "The representation loss after processing this batch is:  0.003612406551837921\n",
      "\n",
      "The classification loss after processing this batch is:  0.22838211059570312\n",
      "The representation loss after processing this batch is:  0.003712601959705353\n",
      "\n",
      "The classification loss after processing this batch is:  0.3206234276294708\n",
      "The representation loss after processing this batch is:  0.0032164230942726135\n",
      "\n",
      "The classification loss after processing this batch is:  0.14645643532276154\n",
      "The representation loss after processing this batch is:  0.003186829388141632\n",
      "\n",
      "The classification loss after processing this batch is:  0.1842864602804184\n",
      "The representation loss after processing this batch is:  0.0036382079124450684\n",
      "\n",
      "The classification loss after processing this batch is:  0.1526510864496231\n",
      "The representation loss after processing this batch is:  0.0029745101928710938\n",
      "\n",
      "The classification loss after processing this batch is:  0.3242037892341614\n",
      "The representation loss after processing this batch is:  0.0032206811010837555\n",
      "\n",
      "The classification loss after processing this batch is:  0.33715012669563293\n",
      "The representation loss after processing this batch is:  0.00305938720703125\n",
      "\n",
      "The classification loss after processing this batch is:  0.2270459234714508\n",
      "The representation loss after processing this batch is:  0.003070719540119171\n",
      "\n",
      "The classification loss after processing this batch is:  0.2353675216436386\n",
      "The representation loss after processing this batch is:  0.003229595720767975\n",
      "\n",
      "The classification loss after processing this batch is:  0.13080215454101562\n",
      "The representation loss after processing this batch is:  0.002990312874317169\n",
      "\n",
      "The classification loss after processing this batch is:  0.16151203215122223\n",
      "The representation loss after processing this batch is:  0.003262639045715332\n",
      "\n",
      "The classification loss after processing this batch is:  0.12785647809505463\n",
      "The representation loss after processing this batch is:  0.0036147087812423706\n",
      "\n",
      "The classification loss after processing this batch is:  0.1395471692085266\n",
      "The representation loss after processing this batch is:  0.0034364983439445496\n",
      "\n",
      "The classification loss after processing this batch is:  0.1973826140165329\n",
      "The representation loss after processing this batch is:  0.0028486885130405426\n",
      "\n",
      "The classification loss after processing this batch is:  0.21018671989440918\n",
      "The representation loss after processing this batch is:  0.0033440738916397095\n",
      "\n",
      "The classification loss after processing this batch is:  0.2764136493206024\n",
      "The representation loss after processing this batch is:  0.003722652792930603\n",
      "\n",
      "The classification loss after processing this batch is:  0.09837041050195694\n",
      "The representation loss after processing this batch is:  0.002788349986076355\n",
      "\n",
      "The classification loss after processing this batch is:  0.158273383975029\n",
      "The representation loss after processing this batch is:  0.003295261412858963\n",
      "\n",
      "The classification loss after processing this batch is:  0.1713644117116928\n",
      "The representation loss after processing this batch is:  0.004011400043964386\n",
      "\n",
      "The classification loss after processing this batch is:  0.2882528603076935\n",
      "The representation loss after processing this batch is:  0.0033921338617801666\n",
      "\n",
      "The classification loss after processing this batch is:  0.13987763226032257\n",
      "The representation loss after processing this batch is:  0.0036266371607780457\n",
      "\n",
      "The classification loss after processing this batch is:  0.40498703718185425\n",
      "The representation loss after processing this batch is:  0.003516577184200287\n",
      "\n",
      "The classification loss after processing this batch is:  0.3646576702594757\n",
      "The representation loss after processing this batch is:  0.0035000257194042206\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.33595889806747437\n",
      "The representation loss after processing this batch is:  0.00368407741189003\n",
      "\n",
      "The classification loss after processing this batch is:  0.22045892477035522\n",
      "The representation loss after processing this batch is:  0.003408830612897873\n",
      "\n",
      "The classification loss after processing this batch is:  0.14352242648601532\n",
      "The representation loss after processing this batch is:  0.0037645921111106873\n",
      "\n",
      "The classification loss after processing this batch is:  0.21470597386360168\n",
      "The representation loss after processing this batch is:  0.003385476768016815\n",
      "\n",
      "The classification loss after processing this batch is:  0.21442630887031555\n",
      "The representation loss after processing this batch is:  0.003458090126514435\n",
      "\n",
      "The classification loss after processing this batch is:  0.14991943538188934\n",
      "The representation loss after processing this batch is:  0.003166012465953827\n",
      "\n",
      "The classification loss after processing this batch is:  0.10539517551660538\n",
      "The representation loss after processing this batch is:  0.0033634528517723083\n",
      "\n",
      "The classification loss after processing this batch is:  0.2510516047477722\n",
      "The representation loss after processing this batch is:  0.00313664972782135\n",
      "\n",
      "The classification loss after processing this batch is:  0.29523104429244995\n",
      "The representation loss after processing this batch is:  0.0030034855008125305\n",
      "\n",
      "The classification loss after processing this batch is:  0.23328904807567596\n",
      "The representation loss after processing this batch is:  0.0035683102905750275\n",
      "\n",
      "The classification loss after processing this batch is:  0.3224639594554901\n",
      "The representation loss after processing this batch is:  0.003120526671409607\n",
      "\n",
      "The classification loss after processing this batch is:  0.3656984269618988\n",
      "The representation loss after processing this batch is:  0.00344056636095047\n",
      "\n",
      "The classification loss after processing this batch is:  0.4660235345363617\n",
      "The representation loss after processing this batch is:  0.003179095685482025\n",
      "\n",
      "The classification loss after processing this batch is:  0.3128625154495239\n",
      "The representation loss after processing this batch is:  0.0031153708696365356\n",
      "\n",
      "The classification loss after processing this batch is:  0.215979665517807\n",
      "The representation loss after processing this batch is:  0.0032706111669540405\n",
      "\n",
      "The classification loss after processing this batch is:  0.2874228358268738\n",
      "The representation loss after processing this batch is:  0.0033381879329681396\n",
      "\n",
      "The classification loss after processing this batch is:  0.21726740896701813\n",
      "The representation loss after processing this batch is:  0.0034033730626106262\n",
      "\n",
      "The classification loss after processing this batch is:  0.1952284425497055\n",
      "The representation loss after processing this batch is:  0.0034321770071983337\n",
      "\n",
      "The classification loss after processing this batch is:  0.15617775917053223\n",
      "The representation loss after processing this batch is:  0.002970859408378601\n",
      "\n",
      "The classification loss after processing this batch is:  0.16452273726463318\n",
      "The representation loss after processing this batch is:  0.00306045264005661\n",
      "\n",
      "The classification loss after processing this batch is:  0.11372449994087219\n",
      "The representation loss after processing this batch is:  0.003808923065662384\n",
      "\n",
      "The classification loss after processing this batch is:  0.22352108359336853\n",
      "The representation loss after processing this batch is:  0.003365900367498398\n",
      "\n",
      "The classification loss after processing this batch is:  0.2828570604324341\n",
      "The representation loss after processing this batch is:  0.002946130931377411\n",
      "\n",
      "The classification loss after processing this batch is:  0.16818378865718842\n",
      "The representation loss after processing this batch is:  0.003487221896648407\n",
      "\n",
      "The classification loss after processing this batch is:  0.1750972419977188\n",
      "The representation loss after processing this batch is:  0.003203216940164566\n",
      "\n",
      "The classification loss after processing this batch is:  0.2459356039762497\n",
      "The representation loss after processing this batch is:  0.0034605860710144043\n",
      "\n",
      "The classification loss after processing this batch is:  0.11224876344203949\n",
      "The representation loss after processing this batch is:  0.0032296031713485718\n",
      "\n",
      "The classification loss after processing this batch is:  0.30434316396713257\n",
      "The representation loss after processing this batch is:  0.003535039722919464\n",
      "\n",
      "The classification loss after processing this batch is:  0.187626451253891\n",
      "The representation loss after processing this batch is:  0.002964518964290619\n",
      "\n",
      "The classification loss after processing this batch is:  0.33724892139434814\n",
      "The representation loss after processing this batch is:  0.0029126591980457306\n",
      "\n",
      "The classification loss after processing this batch is:  0.3008614480495453\n",
      "The representation loss after processing this batch is:  0.003315545618534088\n",
      "\n",
      "The classification loss after processing this batch is:  0.30008599162101746\n",
      "The representation loss after processing this batch is:  0.0028759539127349854\n",
      "\n",
      "The classification loss after processing this batch is:  0.09333005547523499\n",
      "The representation loss after processing this batch is:  0.002889588475227356\n",
      "\n",
      "The classification loss after processing this batch is:  0.11029182374477386\n",
      "The representation loss after processing this batch is:  0.003317795693874359\n",
      "\n",
      "The classification loss after processing this batch is:  0.2131045013666153\n",
      "The representation loss after processing this batch is:  0.003570716828107834\n",
      "\n",
      "The classification loss after processing this batch is:  0.11963649839162827\n",
      "The representation loss after processing this batch is:  0.0037592127919197083\n",
      "\n",
      "The classification loss after processing this batch is:  0.25193649530410767\n",
      "The representation loss after processing this batch is:  0.0036047250032424927\n",
      "\n",
      "The classification loss after processing this batch is:  0.1750200092792511\n",
      "The representation loss after processing this batch is:  0.003966875374317169\n",
      "\n",
      "The classification loss after processing this batch is:  0.2180955857038498\n",
      "The representation loss after processing this batch is:  0.003484688699245453\n",
      "\n",
      "The classification loss after processing this batch is:  0.2619534134864807\n",
      "The representation loss after processing this batch is:  0.0033396854996681213\n",
      "\n",
      "The classification loss after processing this batch is:  0.16133186221122742\n",
      "The representation loss after processing this batch is:  0.003601767122745514\n",
      "\n",
      "The classification loss after processing this batch is:  0.18214306235313416\n",
      "The representation loss after processing this batch is:  0.003953211009502411\n",
      "\n",
      "The classification loss after processing this batch is:  0.26333898305892944\n",
      "The representation loss after processing this batch is:  0.0031819045543670654\n",
      "\n",
      "The classification loss after processing this batch is:  0.22911103069782257\n",
      "The representation loss after processing this batch is:  0.003400951623916626\n",
      "\n",
      "The classification loss after processing this batch is:  0.3252854645252228\n",
      "The representation loss after processing this batch is:  0.0038395337760448456\n",
      "\n",
      "The classification loss after processing this batch is:  0.36473074555397034\n",
      "The representation loss after processing this batch is:  0.003720194101333618\n",
      "\n",
      "The classification loss after processing this batch is:  0.3188271224498749\n",
      "The representation loss after processing this batch is:  0.0029802843928337097\n",
      "\n",
      "The classification loss after processing this batch is:  0.16484929621219635\n",
      "The representation loss after processing this batch is:  0.003432631492614746\n",
      "\n",
      "The classification loss after processing this batch is:  0.1416759043931961\n",
      "The representation loss after processing this batch is:  0.0031778812408447266\n",
      "\n",
      "The classification loss after processing this batch is:  0.15871044993400574\n",
      "The representation loss after processing this batch is:  0.0032413750886917114\n",
      "\n",
      "The classification loss after processing this batch is:  0.14019054174423218\n",
      "The representation loss after processing this batch is:  0.0035715028643608093\n",
      "\n",
      "The classification loss after processing this batch is:  0.2495398223400116\n",
      "The representation loss after processing this batch is:  0.002878434956073761\n",
      "\n",
      "The classification loss after processing this batch is:  0.1948169767856598\n",
      "The representation loss after processing this batch is:  0.0032702311873435974\n",
      "\n",
      "The classification loss after processing this batch is:  0.2237905114889145\n",
      "The representation loss after processing this batch is:  0.003644131124019623\n",
      "\n",
      "The classification loss after processing this batch is:  0.14417387545108795\n",
      "The representation loss after processing this batch is:  0.003218814730644226\n",
      "\n",
      "The classification loss after processing this batch is:  0.2320810705423355\n",
      "The representation loss after processing this batch is:  0.003041885793209076\n",
      "\n",
      "The classification loss after processing this batch is:  0.1614486128091812\n",
      "The representation loss after processing this batch is:  0.003445260226726532\n",
      "\n",
      "The classification loss after processing this batch is:  0.24420174956321716\n",
      "The representation loss after processing this batch is:  0.003120221197605133\n",
      "\n",
      "The classification loss after processing this batch is:  0.22853800654411316\n",
      "The representation loss after processing this batch is:  0.0033517107367515564\n",
      "\n",
      "The classification loss after processing this batch is:  0.19293180108070374\n",
      "The representation loss after processing this batch is:  0.0032189711928367615\n",
      "\n",
      "The classification loss after processing this batch is:  0.21030369400978088\n",
      "The representation loss after processing this batch is:  0.003193490207195282\n",
      "\n",
      "The classification loss after processing this batch is:  0.26826012134552\n",
      "The representation loss after processing this batch is:  0.0036628320813179016\n",
      "\n",
      "The classification loss after processing this batch is:  0.16025105118751526\n",
      "The representation loss after processing this batch is:  0.0032047033309936523\n",
      "\n",
      "The classification loss after processing this batch is:  0.12040650844573975\n",
      "The representation loss after processing this batch is:  0.0032829269766807556\n",
      "\n",
      "The classification loss after processing this batch is:  0.1740482896566391\n",
      "The representation loss after processing this batch is:  0.003426395356655121\n",
      "\n",
      "The classification loss after processing this batch is:  0.16687332093715668\n",
      "The representation loss after processing this batch is:  0.0035212598741054535\n",
      "\n",
      "The classification loss after processing this batch is:  0.2970123291015625\n",
      "The representation loss after processing this batch is:  0.002811979502439499\n",
      "\n",
      "The classification loss after processing this batch is:  0.24617187678813934\n",
      "The representation loss after processing this batch is:  0.0037964917719364166\n",
      "\n",
      "The classification loss after processing this batch is:  0.2330380082130432\n",
      "The representation loss after processing this batch is:  0.003864757716655731\n",
      "\n",
      "The classification loss after processing this batch is:  0.15074793994426727\n",
      "The representation loss after processing this batch is:  0.0036833584308624268\n",
      "\n",
      "The classification loss after processing this batch is:  0.15464134514331818\n",
      "The representation loss after processing this batch is:  0.0031467899680137634\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.3629591763019562\n",
      "The representation loss after processing this batch is:  0.003609016537666321\n",
      "\n",
      "The classification loss after processing this batch is:  0.11229292303323746\n",
      "The representation loss after processing this batch is:  0.0036823898553848267\n",
      "\n",
      "The classification loss after processing this batch is:  0.18611058592796326\n",
      "The representation loss after processing this batch is:  0.003607124090194702\n",
      "\n",
      "The classification loss after processing this batch is:  0.24496930837631226\n",
      "The representation loss after processing this batch is:  0.0029228627681732178\n",
      "\n",
      "The classification loss after processing this batch is:  0.38125619292259216\n",
      "The representation loss after processing this batch is:  0.0035621151328086853\n",
      "\n",
      "The classification loss after processing this batch is:  0.1657858043909073\n",
      "The representation loss after processing this batch is:  0.003182917833328247\n",
      "\n",
      "The classification loss after processing this batch is:  0.24080206453800201\n",
      "The representation loss after processing this batch is:  0.0027868151664733887\n",
      "\n",
      "The classification loss after processing this batch is:  0.13068066537380219\n",
      "The representation loss after processing this batch is:  0.003475964069366455\n",
      "\n",
      "The classification loss after processing this batch is:  0.11013361811637878\n",
      "The representation loss after processing this batch is:  0.003258727490901947\n",
      "\n",
      "The classification loss after processing this batch is:  0.22197720408439636\n",
      "The representation loss after processing this batch is:  0.00406067818403244\n",
      "\n",
      "The classification loss after processing this batch is:  0.18773531913757324\n",
      "The representation loss after processing this batch is:  0.004212580621242523\n",
      "\n",
      "The classification loss after processing this batch is:  0.12336157262325287\n",
      "The representation loss after processing this batch is:  0.003802977502346039\n",
      "\n",
      "The classification loss after processing this batch is:  0.16427253186702728\n",
      "The representation loss after processing this batch is:  0.0030885785818099976\n",
      "\n",
      "The classification loss after processing this batch is:  0.2781859040260315\n",
      "The representation loss after processing this batch is:  0.002967067062854767\n",
      "\n",
      "The classification loss after processing this batch is:  0.23497602343559265\n",
      "The representation loss after processing this batch is:  0.003080226480960846\n",
      "\n",
      "The classification loss after processing this batch is:  0.1648665815591812\n",
      "The representation loss after processing this batch is:  0.0028299279510974884\n",
      "\n",
      "The classification loss after processing this batch is:  0.21014609932899475\n",
      "The representation loss after processing this batch is:  0.0031327754259109497\n",
      "\n",
      "The classification loss after processing this batch is:  0.3051932454109192\n",
      "The representation loss after processing this batch is:  0.0028666220605373383\n",
      "\n",
      "The classification loss after processing this batch is:  0.3149627149105072\n",
      "The representation loss after processing this batch is:  0.0033979415893554688\n",
      "\n",
      "The classification loss after processing this batch is:  0.2618541419506073\n",
      "The representation loss after processing this batch is:  0.002898178994655609\n",
      "\n",
      "The classification loss after processing this batch is:  0.2744959592819214\n",
      "The representation loss after processing this batch is:  0.003551580011844635\n",
      "\n",
      "The classification loss after processing this batch is:  0.33109718561172485\n",
      "The representation loss after processing this batch is:  0.003391724079847336\n",
      "\n",
      "The classification loss after processing this batch is:  0.16808439791202545\n",
      "The representation loss after processing this batch is:  0.003678753972053528\n",
      "\n",
      "The classification loss after processing this batch is:  0.16126200556755066\n",
      "The representation loss after processing this batch is:  0.003553435206413269\n",
      "\n",
      "The classification loss after processing this batch is:  0.147482231259346\n",
      "The representation loss after processing this batch is:  0.003215119242668152\n",
      "\n",
      "The classification loss after processing this batch is:  0.17245705425739288\n",
      "The representation loss after processing this batch is:  0.0028489232063293457\n",
      "\n",
      "The classification loss after processing this batch is:  0.256968230009079\n",
      "The representation loss after processing this batch is:  0.0032145455479621887\n",
      "\n",
      "The classification loss after processing this batch is:  0.1760433465242386\n",
      "The representation loss after processing this batch is:  0.0037834346294403076\n",
      "\n",
      "The classification loss after processing this batch is:  0.10079170763492584\n",
      "The representation loss after processing this batch is:  0.0035069212317466736\n",
      "\n",
      "The classification loss after processing this batch is:  0.09133335202932358\n",
      "The representation loss after processing this batch is:  0.003697618842124939\n",
      "\n",
      "The classification loss after processing this batch is:  0.12787993252277374\n",
      "The representation loss after processing this batch is:  0.003627382218837738\n",
      "\n",
      "The classification loss after processing this batch is:  0.1634625643491745\n",
      "The representation loss after processing this batch is:  0.0037240907549858093\n",
      "\n",
      "The classification loss after processing this batch is:  0.17633789777755737\n",
      "The representation loss after processing this batch is:  0.003487035632133484\n",
      "\n",
      "The classification loss after processing this batch is:  0.1281360238790512\n",
      "The representation loss after processing this batch is:  0.0031220167875289917\n",
      "\n",
      "The classification loss after processing this batch is:  0.09533121436834335\n",
      "The representation loss after processing this batch is:  0.0035375282168388367\n",
      "\n",
      "The classification loss after processing this batch is:  0.12717901170253754\n",
      "The representation loss after processing this batch is:  0.004261709749698639\n",
      "\n",
      "The classification loss after processing this batch is:  0.13028612732887268\n",
      "The representation loss after processing this batch is:  0.004649944603443146\n",
      "\n",
      "The classification loss after processing this batch is:  0.0733148604631424\n",
      "The representation loss after processing this batch is:  0.004742242395877838\n",
      "\n",
      "The classification loss after processing this batch is:  0.1157413050532341\n",
      "The representation loss after processing this batch is:  0.0036150291562080383\n",
      "\n",
      "The classification loss after processing this batch is:  0.2540622353553772\n",
      "The representation loss after processing this batch is:  0.003614276647567749\n",
      "\n",
      "The classification loss after processing this batch is:  0.10527363419532776\n",
      "The representation loss after processing this batch is:  0.004111245274543762\n",
      "\n",
      "The classification loss after processing this batch is:  0.05452638119459152\n",
      "The representation loss after processing this batch is:  0.004020608961582184\n",
      "\n",
      "The classification loss after processing this batch is:  0.09568870812654495\n",
      "The representation loss after processing this batch is:  0.004110097885131836\n",
      "\n",
      "The classification loss after processing this batch is:  0.10967572778463364\n",
      "The representation loss after processing this batch is:  0.0034824535250663757\n",
      "\n",
      "The classification loss after processing this batch is:  0.08275521546602249\n",
      "The representation loss after processing this batch is:  0.003527902066707611\n",
      "\n",
      "The classification loss after processing this batch is:  0.10381493717432022\n",
      "The representation loss after processing this batch is:  0.0037171542644500732\n",
      "\n",
      "The classification loss after processing this batch is:  0.10105385631322861\n",
      "The representation loss after processing this batch is:  0.0040509626269340515\n",
      "\n",
      "The classification loss after processing this batch is:  0.40767723321914673\n",
      "The representation loss after processing this batch is:  0.00437212735414505\n",
      "\n",
      "The classification loss after processing this batch is:  0.38533833622932434\n",
      "The representation loss after processing this batch is:  0.004398763179779053\n",
      "\n",
      "The classification loss after processing this batch is:  0.29776227474212646\n",
      "The representation loss after processing this batch is:  0.004251167178153992\n",
      "\n",
      "The classification loss after processing this batch is:  0.11062891036272049\n",
      "The representation loss after processing this batch is:  0.0032592862844467163\n",
      "\n",
      "The classification loss after processing this batch is:  0.08618641644716263\n",
      "The representation loss after processing this batch is:  0.003731928765773773\n",
      "\n",
      "The classification loss after processing this batch is:  0.10517870634794235\n",
      "The representation loss after processing this batch is:  0.00286981463432312\n",
      "\n",
      "The classification loss after processing this batch is:  0.16558058559894562\n",
      "The representation loss after processing this batch is:  0.0028298497200012207\n",
      "\n",
      "The classification loss after processing this batch is:  0.4319775402545929\n",
      "The representation loss after processing this batch is:  0.003517262637615204\n",
      "\n",
      "The classification loss after processing this batch is:  0.14304789900779724\n",
      "The representation loss after processing this batch is:  0.0030765533447265625\n",
      "\n",
      "The classification loss after processing this batch is:  0.09413138031959534\n",
      "The representation loss after processing this batch is:  0.003972798585891724\n",
      "\n",
      "The classification loss after processing this batch is:  0.1610221564769745\n",
      "The representation loss after processing this batch is:  0.003548726439476013\n",
      "\n",
      "The classification loss after processing this batch is:  0.12139622867107391\n",
      "The representation loss after processing this batch is:  0.003905095160007477\n",
      "\n",
      "The classification loss after processing this batch is:  0.19137762486934662\n",
      "The representation loss after processing this batch is:  0.0032095909118652344\n",
      "\n",
      "The classification loss after processing this batch is:  0.12555894255638123\n",
      "The representation loss after processing this batch is:  0.0029543116688728333\n",
      "\n",
      "The classification loss after processing this batch is:  0.17823629081249237\n",
      "The representation loss after processing this batch is:  0.002916894853115082\n",
      "\n",
      "The classification loss after processing this batch is:  0.1697218269109726\n",
      "The representation loss after processing this batch is:  0.0032792799174785614\n",
      "\n",
      "The classification loss after processing this batch is:  0.22258275747299194\n",
      "The representation loss after processing this batch is:  0.003416728228330612\n",
      "\n",
      "The classification loss after processing this batch is:  0.12361249327659607\n",
      "The representation loss after processing this batch is:  0.0038017407059669495\n",
      "\n",
      "The classification loss after processing this batch is:  0.18560591340065002\n",
      "The representation loss after processing this batch is:  0.003999896347522736\n",
      "\n",
      "The classification loss after processing this batch is:  0.1474405974149704\n",
      "The representation loss after processing this batch is:  0.0028247684240341187\n",
      "\n",
      "The classification loss after processing this batch is:  0.23175309598445892\n",
      "The representation loss after processing this batch is:  0.0031170956790447235\n",
      "\n",
      "The classification loss after processing this batch is:  0.19703082740306854\n",
      "The representation loss after processing this batch is:  0.0030536502599716187\n",
      "\n",
      "The classification loss after processing this batch is:  0.26165771484375\n",
      "The representation loss after processing this batch is:  0.003023281693458557\n",
      "\n",
      "The classification loss after processing this batch is:  0.22401860356330872\n",
      "The representation loss after processing this batch is:  0.003345716744661331\n",
      "\n",
      "The classification loss after processing this batch is:  0.27941834926605225\n",
      "The representation loss after processing this batch is:  0.003971848636865616\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.12837159633636475\n",
      "The representation loss after processing this batch is:  0.003196343779563904\n",
      "\n",
      "The classification loss after processing this batch is:  0.4197961091995239\n",
      "The representation loss after processing this batch is:  0.0030889511108398438\n",
      "\n",
      "The classification loss after processing this batch is:  0.21985338628292084\n",
      "The representation loss after processing this batch is:  0.0027945153415203094\n",
      "\n",
      "The classification loss after processing this batch is:  0.20728597044944763\n",
      "The representation loss after processing this batch is:  0.0030588433146476746\n",
      "\n",
      "The classification loss after processing this batch is:  0.3099066913127899\n",
      "The representation loss after processing this batch is:  0.003745395690202713\n",
      "\n",
      "The classification loss after processing this batch is:  0.2784474492073059\n",
      "The representation loss after processing this batch is:  0.003527231514453888\n",
      "\n",
      "The classification loss after processing this batch is:  0.12071340531110764\n",
      "The representation loss after processing this batch is:  0.003269735723733902\n",
      "\n",
      "The classification loss after processing this batch is:  0.3138411343097687\n",
      "The representation loss after processing this batch is:  0.003984339535236359\n",
      "\n",
      "The classification loss after processing this batch is:  0.24017249047756195\n",
      "The representation loss after processing this batch is:  0.003261413425207138\n",
      "\n",
      "The classification loss after processing this batch is:  0.3663976490497589\n",
      "The representation loss after processing this batch is:  0.0028925947844982147\n",
      "\n",
      "The classification loss after processing this batch is:  0.16443322598934174\n",
      "The representation loss after processing this batch is:  0.002847343683242798\n",
      "\n",
      "The classification loss after processing this batch is:  0.1343035101890564\n",
      "The representation loss after processing this batch is:  0.0032467246055603027\n",
      "\n",
      "The classification loss after processing this batch is:  0.15961244702339172\n",
      "The representation loss after processing this batch is:  0.0031066201627254486\n",
      "\n",
      "The classification loss after processing this batch is:  0.1930251568555832\n",
      "The representation loss after processing this batch is:  0.002624139189720154\n",
      "\n",
      "The classification loss after processing this batch is:  0.18613497912883759\n",
      "The representation loss after processing this batch is:  0.0032273828983306885\n",
      "\n",
      "The classification loss after processing this batch is:  0.09426260739564896\n",
      "The representation loss after processing this batch is:  0.0031442642211914062\n",
      "\n",
      "The classification loss after processing this batch is:  0.10051799565553665\n",
      "The representation loss after processing this batch is:  0.0032515227794647217\n",
      "\n",
      "The classification loss after processing this batch is:  0.16200405359268188\n",
      "The representation loss after processing this batch is:  0.003179021179676056\n",
      "\n",
      "The classification loss after processing this batch is:  0.1492813676595688\n",
      "The representation loss after processing this batch is:  0.0037471726536750793\n",
      "\n",
      "The classification loss after processing this batch is:  0.22824496030807495\n",
      "The representation loss after processing this batch is:  0.0033022649586200714\n",
      "\n",
      "The classification loss after processing this batch is:  0.1843942105770111\n",
      "The representation loss after processing this batch is:  0.003962483257055283\n",
      "\n",
      "The classification loss after processing this batch is:  0.15406547486782074\n",
      "The representation loss after processing this batch is:  0.0032438859343528748\n",
      "\n",
      "The classification loss after processing this batch is:  0.09901327639818192\n",
      "The representation loss after processing this batch is:  0.0031281784176826477\n",
      "\n",
      "The classification loss after processing this batch is:  0.1368343085050583\n",
      "The representation loss after processing this batch is:  0.0037198252975940704\n",
      "\n",
      "The classification loss after processing this batch is:  0.1723528504371643\n",
      "The representation loss after processing this batch is:  0.0031422600150108337\n",
      "\n",
      "The classification loss after processing this batch is:  0.1140737310051918\n",
      "The representation loss after processing this batch is:  0.0035708919167518616\n",
      "\n",
      "The classification loss after processing this batch is:  0.167305126786232\n",
      "The representation loss after processing this batch is:  0.0032468438148498535\n",
      "\n",
      "The classification loss after processing this batch is:  0.31613388657569885\n",
      "The representation loss after processing this batch is:  0.003456801176071167\n",
      "\n",
      "The classification loss after processing this batch is:  0.18433347344398499\n",
      "The representation loss after processing this batch is:  0.0030949413776397705\n",
      "\n",
      "The classification loss after processing this batch is:  0.181248277425766\n",
      "The representation loss after processing this batch is:  0.003107856959104538\n",
      "\n",
      "The classification loss after processing this batch is:  0.1881079375743866\n",
      "The representation loss after processing this batch is:  0.00322713702917099\n",
      "\n",
      "The classification loss after processing this batch is:  0.1501520723104477\n",
      "The representation loss after processing this batch is:  0.0029920339584350586\n",
      "\n",
      "The classification loss after processing this batch is:  0.16196094453334808\n",
      "The representation loss after processing this batch is:  0.002903454005718231\n",
      "\n",
      "The classification loss after processing this batch is:  0.2685543894767761\n",
      "The representation loss after processing this batch is:  0.003689747303724289\n",
      "\n",
      "The classification loss after processing this batch is:  0.11635789275169373\n",
      "The representation loss after processing this batch is:  0.003341861069202423\n",
      "\n",
      "The classification loss after processing this batch is:  0.18856173753738403\n",
      "The representation loss after processing this batch is:  0.003101624548435211\n",
      "\n",
      "The classification loss after processing this batch is:  0.15276043117046356\n",
      "The representation loss after processing this batch is:  0.0037526898086071014\n",
      "\n",
      "The classification loss after processing this batch is:  0.19743837416172028\n",
      "The representation loss after processing this batch is:  0.0028275474905967712\n",
      "\n",
      "The classification loss after processing this batch is:  0.20780858397483826\n",
      "The representation loss after processing this batch is:  0.002998076379299164\n",
      "\n",
      "The classification loss after processing this batch is:  0.15226830542087555\n",
      "The representation loss after processing this batch is:  0.003238879144191742\n",
      "\n",
      "The classification loss after processing this batch is:  0.17397768795490265\n",
      "The representation loss after processing this batch is:  0.003427848219871521\n",
      "\n",
      "The classification loss after processing this batch is:  0.20652195811271667\n",
      "The representation loss after processing this batch is:  0.0033851265907287598\n",
      "\n",
      "The classification loss after processing this batch is:  0.2161065638065338\n",
      "The representation loss after processing this batch is:  0.0031615793704986572\n",
      "\n",
      "The classification loss after processing this batch is:  0.2204853743314743\n",
      "The representation loss after processing this batch is:  0.00284586101770401\n",
      "\n",
      "The classification loss after processing this batch is:  0.17109279334545135\n",
      "The representation loss after processing this batch is:  0.003406904637813568\n",
      "\n",
      "The classification loss after processing this batch is:  0.2010493278503418\n",
      "The representation loss after processing this batch is:  0.0030743181705474854\n",
      "\n",
      "The classification loss after processing this batch is:  0.13414154946804047\n",
      "The representation loss after processing this batch is:  0.0030495375394821167\n",
      "\n",
      "The classification loss after processing this batch is:  0.12109526991844177\n",
      "The representation loss after processing this batch is:  0.002739734947681427\n",
      "\n",
      "The classification loss after processing this batch is:  0.24676688015460968\n",
      "The representation loss after processing this batch is:  0.003007803112268448\n",
      "\n",
      "The classification loss after processing this batch is:  0.24209937453269958\n",
      "The representation loss after processing this batch is:  0.003115430474281311\n",
      "\n",
      "The classification loss after processing this batch is:  0.15485936403274536\n",
      "The representation loss after processing this batch is:  0.003089945763349533\n",
      "\n",
      "The classification loss after processing this batch is:  0.1484432816505432\n",
      "The representation loss after processing this batch is:  0.0028943270444869995\n",
      "\n",
      "The classification loss after processing this batch is:  0.166913703083992\n",
      "The representation loss after processing this batch is:  0.0027902163565158844\n",
      "\n",
      "The classification loss after processing this batch is:  0.2086520493030548\n",
      "The representation loss after processing this batch is:  0.0032328441739082336\n",
      "\n",
      "The classification loss after processing this batch is:  0.2297854721546173\n",
      "The representation loss after processing this batch is:  0.0028409622609615326\n",
      "\n",
      "The classification loss after processing this batch is:  0.12696942687034607\n",
      "The representation loss after processing this batch is:  0.0030997246503829956\n",
      "\n",
      "The classification loss after processing this batch is:  0.3181721270084381\n",
      "The representation loss after processing this batch is:  0.0031985603272914886\n",
      "\n",
      "The classification loss after processing this batch is:  0.21997451782226562\n",
      "The representation loss after processing this batch is:  0.003316648304462433\n",
      "\n",
      "The classification loss after processing this batch is:  0.2109786868095398\n",
      "The representation loss after processing this batch is:  0.003025658428668976\n",
      "\n",
      "The classification loss after processing this batch is:  0.16834597289562225\n",
      "The representation loss after processing this batch is:  0.002488180994987488\n",
      "\n",
      "The classification loss after processing this batch is:  0.1363225281238556\n",
      "The representation loss after processing this batch is:  0.0032564178109169006\n",
      "\n",
      "The classification loss after processing this batch is:  0.18352803587913513\n",
      "The representation loss after processing this batch is:  0.0027945786714553833\n",
      "\n",
      "The classification loss after processing this batch is:  0.23027125000953674\n",
      "The representation loss after processing this batch is:  0.0029871314764022827\n",
      "\n",
      "The classification loss after processing this batch is:  0.15341073274612427\n",
      "The representation loss after processing this batch is:  0.002830006182193756\n",
      "\n",
      "The classification loss after processing this batch is:  0.36388543248176575\n",
      "The representation loss after processing this batch is:  0.0029852353036403656\n",
      "\n",
      "The classification loss after processing this batch is:  0.17908762395381927\n",
      "The representation loss after processing this batch is:  0.00280558317899704\n",
      "\n",
      "The classification loss after processing this batch is:  0.14677883684635162\n",
      "The representation loss after processing this batch is:  0.0039087384939193726\n",
      "\n",
      "The classification loss after processing this batch is:  0.23015639185905457\n",
      "The representation loss after processing this batch is:  0.0032208114862442017\n",
      "\n",
      "The classification loss after processing this batch is:  0.14837726950645447\n",
      "The representation loss after processing this batch is:  0.0035141929984092712\n",
      "\n",
      "The classification loss after processing this batch is:  0.35236796736717224\n",
      "The representation loss after processing this batch is:  0.0033896788954734802\n",
      "\n",
      "The classification loss after processing this batch is:  0.19599412381649017\n",
      "The representation loss after processing this batch is:  0.0029469728469848633\n",
      "\n",
      "The classification loss after processing this batch is:  0.23649589717388153\n",
      "The representation loss after processing this batch is:  0.0030338913202285767\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.412854939699173\n",
      "The representation loss after processing this batch is:  0.0032151155173778534\n",
      "\n",
      "The classification loss after processing this batch is:  0.2542418837547302\n",
      "The representation loss after processing this batch is:  0.002889402210712433\n",
      "\n",
      "The classification loss after processing this batch is:  0.14784838259220123\n",
      "The representation loss after processing this batch is:  0.003144197165966034\n",
      "\n",
      "The classification loss after processing this batch is:  0.2711048126220703\n",
      "The representation loss after processing this batch is:  0.0029400475323200226\n",
      "\n",
      "The classification loss after processing this batch is:  0.24638350307941437\n",
      "The representation loss after processing this batch is:  0.0029676631093025208\n",
      "\n",
      "The classification loss after processing this batch is:  0.19721965491771698\n",
      "The representation loss after processing this batch is:  0.0032083578407764435\n",
      "\n",
      "The classification loss after processing this batch is:  0.1406988799571991\n",
      "The representation loss after processing this batch is:  0.002912379801273346\n",
      "\n",
      "The classification loss after processing this batch is:  0.17851607501506805\n",
      "The representation loss after processing this batch is:  0.002663560211658478\n",
      "\n",
      "The classification loss after processing this batch is:  0.2318209558725357\n",
      "The representation loss after processing this batch is:  0.0030269399285316467\n",
      "\n",
      "The classification loss after processing this batch is:  0.20475418865680695\n",
      "The representation loss after processing this batch is:  0.0036905407905578613\n",
      "\n",
      "The classification loss after processing this batch is:  0.2707490921020508\n",
      "The representation loss after processing this batch is:  0.0030645616352558136\n",
      "\n",
      "The classification loss after processing this batch is:  0.2970059812068939\n",
      "The representation loss after processing this batch is:  0.003301464021205902\n",
      "\n",
      "The classification loss after processing this batch is:  0.28620827198028564\n",
      "The representation loss after processing this batch is:  0.0035607069730758667\n",
      "\n",
      "The classification loss after processing this batch is:  0.16034866869449615\n",
      "The representation loss after processing this batch is:  0.003925256431102753\n",
      "\n",
      "The classification loss after processing this batch is:  0.16195672750473022\n",
      "The representation loss after processing this batch is:  0.002842634916305542\n",
      "\n",
      "The classification loss after processing this batch is:  0.11491300910711288\n",
      "The representation loss after processing this batch is:  0.0030225999653339386\n",
      "\n",
      "The classification loss after processing this batch is:  0.20170678198337555\n",
      "The representation loss after processing this batch is:  0.0032080933451652527\n",
      "\n",
      "The classification loss after processing this batch is:  0.15494689345359802\n",
      "The representation loss after processing this batch is:  0.0031501278281211853\n",
      "\n",
      "The classification loss after processing this batch is:  0.3106738328933716\n",
      "The representation loss after processing this batch is:  0.003258123993873596\n",
      "\n",
      "The classification loss after processing this batch is:  0.353040486574173\n",
      "The representation loss after processing this batch is:  0.0032472386956214905\n",
      "\n",
      "The classification loss after processing this batch is:  0.18090900778770447\n",
      "The representation loss after processing this batch is:  0.0034193098545074463\n",
      "\n",
      "The classification loss after processing this batch is:  0.18248382210731506\n",
      "The representation loss after processing this batch is:  0.0033865198493003845\n",
      "\n",
      "The classification loss after processing this batch is:  0.2147742658853531\n",
      "The representation loss after processing this batch is:  0.0030155032873153687\n",
      "\n",
      "The classification loss after processing this batch is:  0.12571685016155243\n",
      "The representation loss after processing this batch is:  0.003581628203392029\n",
      "\n",
      "The classification loss after processing this batch is:  0.12244033068418503\n",
      "The representation loss after processing this batch is:  0.003137044608592987\n",
      "\n",
      "The classification loss after processing this batch is:  0.21046772599220276\n",
      "The representation loss after processing this batch is:  0.002803392708301544\n",
      "\n",
      "The classification loss after processing this batch is:  0.19246281683444977\n",
      "The representation loss after processing this batch is:  0.004332996904850006\n",
      "\n",
      "The classification loss after processing this batch is:  0.156135693192482\n",
      "The representation loss after processing this batch is:  0.0032670199871063232\n",
      "\n",
      "The classification loss after processing this batch is:  0.3276544511318207\n",
      "The representation loss after processing this batch is:  0.004249263554811478\n",
      "\n",
      "The classification loss after processing this batch is:  0.3015829622745514\n",
      "The representation loss after processing this batch is:  0.002999037504196167\n",
      "\n",
      "The classification loss after processing this batch is:  0.23910363018512726\n",
      "The representation loss after processing this batch is:  0.0034377053380012512\n",
      "\n",
      "The classification loss after processing this batch is:  0.3058337867259979\n",
      "The representation loss after processing this batch is:  0.0032938718795776367\n",
      "\n",
      "The classification loss after processing this batch is:  0.23364610970020294\n",
      "The representation loss after processing this batch is:  0.002938099205493927\n",
      "\n",
      "The classification loss after processing this batch is:  0.14345966279506683\n",
      "The representation loss after processing this batch is:  0.003366723656654358\n",
      "\n",
      "The classification loss after processing this batch is:  0.23886333405971527\n",
      "The representation loss after processing this batch is:  0.003081347793340683\n",
      "\n",
      "The classification loss after processing this batch is:  0.43415671586990356\n",
      "The representation loss after processing this batch is:  0.0036281123757362366\n",
      "\n",
      "The classification loss after processing this batch is:  0.2536568343639374\n",
      "The representation loss after processing this batch is:  0.0037711523473262787\n",
      "\n",
      "The classification loss after processing this batch is:  0.1480035036802292\n",
      "The representation loss after processing this batch is:  0.00405893474817276\n",
      "\n",
      "The classification loss after processing this batch is:  0.17650966346263885\n",
      "The representation loss after processing this batch is:  0.00392691045999527\n",
      "\n",
      "The classification loss after processing this batch is:  0.13056261837482452\n",
      "The representation loss after processing this batch is:  0.0037705153226852417\n",
      "\n",
      "The classification loss after processing this batch is:  0.1867312490940094\n",
      "The representation loss after processing this batch is:  0.003522053360939026\n",
      "\n",
      "The classification loss after processing this batch is:  0.11546134203672409\n",
      "The representation loss after processing this batch is:  0.003593064844608307\n",
      "\n",
      "The classification loss after processing this batch is:  0.24953950941562653\n",
      "The representation loss after processing this batch is:  0.0028030946850776672\n",
      "\n",
      "The classification loss after processing this batch is:  0.1813676804304123\n",
      "The representation loss after processing this batch is:  0.003005973994731903\n",
      "\n",
      "The classification loss after processing this batch is:  0.33573853969573975\n",
      "The representation loss after processing this batch is:  0.0031905919313430786\n",
      "\n",
      "The classification loss after processing this batch is:  0.17738959193229675\n",
      "The representation loss after processing this batch is:  0.0032123811542987823\n",
      "\n",
      "The classification loss after processing this batch is:  0.19704556465148926\n",
      "The representation loss after processing this batch is:  0.0029558055102825165\n",
      "\n",
      "The classification loss after processing this batch is:  0.22600875794887543\n",
      "The representation loss after processing this batch is:  0.0029998570680618286\n",
      "\n",
      "The classification loss after processing this batch is:  0.22603563964366913\n",
      "The representation loss after processing this batch is:  0.003191925585269928\n",
      "\n",
      "The classification loss after processing this batch is:  0.13815489411354065\n",
      "The representation loss after processing this batch is:  0.0030294805765151978\n",
      "\n",
      "The classification loss after processing this batch is:  0.2510586380958557\n",
      "The representation loss after processing this batch is:  0.0032660439610481262\n",
      "\n",
      "The classification loss after processing this batch is:  0.25638386607170105\n",
      "The representation loss after processing this batch is:  0.0029899924993515015\n",
      "\n",
      "The classification loss after processing this batch is:  0.23700577020645142\n",
      "The representation loss after processing this batch is:  0.002884428948163986\n",
      "\n",
      "The classification loss after processing this batch is:  0.22689040005207062\n",
      "The representation loss after processing this batch is:  0.002894386649131775\n",
      "\n",
      "The classification loss after processing this batch is:  0.20459146797657013\n",
      "The representation loss after processing this batch is:  0.003368183970451355\n",
      "\n",
      "The classification loss after processing this batch is:  0.3028058409690857\n",
      "The representation loss after processing this batch is:  0.0033043548464775085\n",
      "\n",
      "The classification loss after processing this batch is:  0.255813866853714\n",
      "The representation loss after processing this batch is:  0.003251500427722931\n",
      "\n",
      "The classification loss after processing this batch is:  0.1586942970752716\n",
      "The representation loss after processing this batch is:  0.0035287216305732727\n",
      "\n",
      "The classification loss after processing this batch is:  0.19845539331436157\n",
      "The representation loss after processing this batch is:  0.0036680176854133606\n",
      "\n",
      "The classification loss after processing this batch is:  0.3632938265800476\n",
      "The representation loss after processing this batch is:  0.002949334681034088\n",
      "\n",
      "The classification loss after processing this batch is:  0.29720067977905273\n",
      "The representation loss after processing this batch is:  0.0029496029019355774\n",
      "\n",
      "The classification loss after processing this batch is:  0.3330186605453491\n",
      "The representation loss after processing this batch is:  0.0036633871495723724\n",
      "\n",
      "The classification loss after processing this batch is:  0.3751267194747925\n",
      "The representation loss after processing this batch is:  0.002770937979221344\n",
      "\n",
      "The classification loss after processing this batch is:  0.27173563838005066\n",
      "The representation loss after processing this batch is:  0.0031160935759544373\n",
      "\n",
      "The classification loss after processing this batch is:  0.15947653353214264\n",
      "The representation loss after processing this batch is:  0.0030005723237991333\n",
      "\n",
      "The classification loss after processing this batch is:  0.13652263581752777\n",
      "The representation loss after processing this batch is:  0.003076396882534027\n",
      "\n",
      "The classification loss after processing this batch is:  0.12923409044742584\n",
      "The representation loss after processing this batch is:  0.003842674195766449\n",
      "\n",
      "The classification loss after processing this batch is:  0.1974286437034607\n",
      "The representation loss after processing this batch is:  0.004162795841693878\n",
      "\n",
      "The classification loss after processing this batch is:  0.10102648288011551\n",
      "The representation loss after processing this batch is:  0.0033129900693893433\n",
      "\n",
      "The classification loss after processing this batch is:  0.22950083017349243\n",
      "The representation loss after processing this batch is:  0.004340894520282745\n",
      "\n",
      "The classification loss after processing this batch is:  0.20585152506828308\n",
      "The representation loss after processing this batch is:  0.0033773668110370636\n",
      "\n",
      "The classification loss after processing this batch is:  0.19333121180534363\n",
      "The representation loss after processing this batch is:  0.0030281543731689453\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.29745230078697205\n",
      "The representation loss after processing this batch is:  0.002908967435359955\n",
      "\n",
      "The classification loss after processing this batch is:  0.17347083985805511\n",
      "The representation loss after processing this batch is:  0.0037878043949604034\n",
      "\n",
      "The classification loss after processing this batch is:  0.2561739981174469\n",
      "The representation loss after processing this batch is:  0.004125960171222687\n",
      "\n",
      "The classification loss after processing this batch is:  0.31019294261932373\n",
      "The representation loss after processing this batch is:  0.004112660884857178\n",
      "\n",
      "The classification loss after processing this batch is:  0.18979482352733612\n",
      "The representation loss after processing this batch is:  0.0034365952014923096\n",
      "\n",
      "The classification loss after processing this batch is:  0.21067164838314056\n",
      "The representation loss after processing this batch is:  0.002792052924633026\n",
      "\n",
      "The classification loss after processing this batch is:  0.16429118812084198\n",
      "The representation loss after processing this batch is:  0.0033138394355773926\n",
      "\n",
      "The classification loss after processing this batch is:  0.10489535331726074\n",
      "The representation loss after processing this batch is:  0.003385573625564575\n",
      "\n",
      "The classification loss after processing this batch is:  0.11535148322582245\n",
      "The representation loss after processing this batch is:  0.0031003952026367188\n",
      "\n",
      "The classification loss after processing this batch is:  0.15788139402866364\n",
      "The representation loss after processing this batch is:  0.0030523426830768585\n",
      "\n",
      "The classification loss after processing this batch is:  0.20607200264930725\n",
      "The representation loss after processing this batch is:  0.002679266035556793\n",
      "\n",
      "The classification loss after processing this batch is:  0.1689288467168808\n",
      "The representation loss after processing this batch is:  0.0032112151384353638\n",
      "\n",
      "The classification loss after processing this batch is:  0.23369359970092773\n",
      "The representation loss after processing this batch is:  0.00314456969499588\n",
      "\n",
      "The classification loss after processing this batch is:  0.45497387647628784\n",
      "The representation loss after processing this batch is:  0.0031976625323295593\n",
      "\n",
      "The classification loss after processing this batch is:  0.32512742280960083\n",
      "The representation loss after processing this batch is:  0.0034031718969345093\n",
      "\n",
      "The classification loss after processing this batch is:  0.15825599431991577\n",
      "The representation loss after processing this batch is:  0.0030868276953697205\n",
      "\n",
      "The classification loss after processing this batch is:  0.15670731663703918\n",
      "The representation loss after processing this batch is:  0.0030029453337192535\n",
      "\n",
      "The classification loss after processing this batch is:  0.20916277170181274\n",
      "The representation loss after processing this batch is:  0.0029382258653640747\n",
      "\n",
      "The classification loss after processing this batch is:  0.16415531933307648\n",
      "The representation loss after processing this batch is:  0.002970479428768158\n",
      "\n",
      "The classification loss after processing this batch is:  0.10317819565534592\n",
      "The representation loss after processing this batch is:  0.003131166100502014\n",
      "\n",
      "The classification loss after processing this batch is:  0.13699375092983246\n",
      "The representation loss after processing this batch is:  0.003464743494987488\n",
      "\n",
      "The classification loss after processing this batch is:  0.17241233587265015\n",
      "The representation loss after processing this batch is:  0.002734057605266571\n",
      "\n",
      "The classification loss after processing this batch is:  0.25641775131225586\n",
      "The representation loss after processing this batch is:  0.0032278038561344147\n",
      "\n",
      "The classification loss after processing this batch is:  0.12307104468345642\n",
      "The representation loss after processing this batch is:  0.0033096149563789368\n",
      "\n",
      "The classification loss after processing this batch is:  0.12463176995515823\n",
      "The representation loss after processing this batch is:  0.0031887441873550415\n",
      "\n",
      "The classification loss after processing this batch is:  0.12572911381721497\n",
      "The representation loss after processing this batch is:  0.002869587391614914\n",
      "\n",
      "The classification loss after processing this batch is:  0.33738481998443604\n",
      "The representation loss after processing this batch is:  0.0029391907155513763\n",
      "\n",
      "The classification loss after processing this batch is:  0.16637779772281647\n",
      "The representation loss after processing this batch is:  0.0031994283199310303\n",
      "\n",
      "The classification loss after processing this batch is:  0.11324526369571686\n",
      "The representation loss after processing this batch is:  0.003427751362323761\n",
      "\n",
      "The classification loss after processing this batch is:  0.25841787457466125\n",
      "The representation loss after processing this batch is:  0.003298617899417877\n",
      "\n",
      "The classification loss after processing this batch is:  0.15453097224235535\n",
      "The representation loss after processing this batch is:  0.002879194915294647\n",
      "\n",
      "The classification loss after processing this batch is:  0.12071151286363602\n",
      "The representation loss after processing this batch is:  0.0029782429337501526\n",
      "\n",
      "The classification loss after processing this batch is:  0.2115769386291504\n",
      "The representation loss after processing this batch is:  0.0031838268041610718\n",
      "\n",
      "The classification loss after processing this batch is:  0.11571482568979263\n",
      "The representation loss after processing this batch is:  0.0028533414006233215\n",
      "\n",
      "The classification loss after processing this batch is:  0.14341050386428833\n",
      "The representation loss after processing this batch is:  0.0033035390079021454\n",
      "\n",
      "The classification loss after processing this batch is:  0.2274247109889984\n",
      "The representation loss after processing this batch is:  0.0028045065701007843\n",
      "\n",
      "The classification loss after processing this batch is:  0.27013522386550903\n",
      "The representation loss after processing this batch is:  0.0030603446066379547\n",
      "\n",
      "The classification loss after processing this batch is:  0.20402184128761292\n",
      "The representation loss after processing this batch is:  0.003238774836063385\n",
      "\n",
      "The classification loss after processing this batch is:  0.26810646057128906\n",
      "The representation loss after processing this batch is:  0.0031438544392585754\n",
      "\n",
      "The classification loss after processing this batch is:  0.16740217804908752\n",
      "The representation loss after processing this batch is:  0.003170117735862732\n",
      "\n",
      "The classification loss after processing this batch is:  0.22296571731567383\n",
      "The representation loss after processing this batch is:  0.0031312406063079834\n",
      "\n",
      "The classification loss after processing this batch is:  0.15474513173103333\n",
      "The representation loss after processing this batch is:  0.0032568350434303284\n",
      "\n",
      "The classification loss after processing this batch is:  0.2222961038351059\n",
      "The representation loss after processing this batch is:  0.0035619623959064484\n",
      "\n",
      "The classification loss after processing this batch is:  0.13620837032794952\n",
      "The representation loss after processing this batch is:  0.0030830763280391693\n",
      "\n",
      "The classification loss after processing this batch is:  0.24314428865909576\n",
      "The representation loss after processing this batch is:  0.0034616924822330475\n",
      "\n",
      "The classification loss after processing this batch is:  0.14876756072044373\n",
      "The representation loss after processing this batch is:  0.0034066587686538696\n",
      "\n",
      "The classification loss after processing this batch is:  0.2391481250524521\n",
      "The representation loss after processing this batch is:  0.0027670860290527344\n",
      "\n",
      "The classification loss after processing this batch is:  0.19369402527809143\n",
      "The representation loss after processing this batch is:  0.0025322549045085907\n",
      "\n",
      "The classification loss after processing this batch is:  0.20423723757266998\n",
      "The representation loss after processing this batch is:  0.0032252632081508636\n",
      "\n",
      "The classification loss after processing this batch is:  0.2281276285648346\n",
      "The representation loss after processing this batch is:  0.0031623169779777527\n",
      "\n",
      "The classification loss after processing this batch is:  0.23153363168239594\n",
      "The representation loss after processing this batch is:  0.0029994696378707886\n",
      "\n",
      "The classification loss after processing this batch is:  0.2683042883872986\n",
      "The representation loss after processing this batch is:  0.0028180554509162903\n",
      "\n",
      "The classification loss after processing this batch is:  0.32455068826675415\n",
      "The representation loss after processing this batch is:  0.0028427429497241974\n",
      "\n",
      "The classification loss after processing this batch is:  0.37337929010391235\n",
      "The representation loss after processing this batch is:  0.002512384206056595\n",
      "\n",
      "The classification loss after processing this batch is:  0.31121957302093506\n",
      "The representation loss after processing this batch is:  0.0026545636355876923\n",
      "\n",
      "The classification loss after processing this batch is:  0.15534597635269165\n",
      "The representation loss after processing this batch is:  0.0031178705394268036\n",
      "\n",
      "The classification loss after processing this batch is:  0.2399870902299881\n",
      "The representation loss after processing this batch is:  0.0034344978630542755\n",
      "\n",
      "The classification loss after processing this batch is:  0.14192934334278107\n",
      "The representation loss after processing this batch is:  0.00355539470911026\n",
      "\n",
      "The classification loss after processing this batch is:  0.21711626648902893\n",
      "The representation loss after processing this batch is:  0.0032053031027317047\n",
      "\n",
      "The classification loss after processing this batch is:  0.3018881678581238\n",
      "The representation loss after processing this batch is:  0.003211379051208496\n",
      "\n",
      "The classification loss after processing this batch is:  0.41604843735694885\n",
      "The representation loss after processing this batch is:  0.003114864230155945\n",
      "\n",
      "The classification loss after processing this batch is:  0.4589129686355591\n",
      "The representation loss after processing this batch is:  0.0026835575699806213\n",
      "\n",
      "The classification loss after processing this batch is:  0.2647060453891754\n",
      "The representation loss after processing this batch is:  0.003163151443004608\n",
      "\n",
      "The classification loss after processing this batch is:  0.14190538227558136\n",
      "The representation loss after processing this batch is:  0.0032675229012966156\n",
      "\n",
      "The classification loss after processing this batch is:  0.1508580893278122\n",
      "The representation loss after processing this batch is:  0.0030419155955314636\n",
      "\n",
      "The classification loss after processing this batch is:  0.2558876574039459\n",
      "The representation loss after processing this batch is:  0.002841547131538391\n",
      "\n",
      "The classification loss after processing this batch is:  0.1478758454322815\n",
      "The representation loss after processing this batch is:  0.003207564353942871\n",
      "\n",
      "The classification loss after processing this batch is:  0.14646799862384796\n",
      "The representation loss after processing this batch is:  0.0032196156680583954\n",
      "\n",
      "The classification loss after processing this batch is:  0.16661781072616577\n",
      "The representation loss after processing this batch is:  0.0033345967531204224\n",
      "\n",
      "The classification loss after processing this batch is:  0.06344468146562576\n",
      "The representation loss after processing this batch is:  0.0033549144864082336\n",
      "\n",
      "The classification loss after processing this batch is:  0.17389178276062012\n",
      "The representation loss after processing this batch is:  0.0037540942430496216\n",
      "\n",
      "The classification loss after processing this batch is:  0.20105807483196259\n",
      "The representation loss after processing this batch is:  0.003385297954082489\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.24754036962985992\n",
      "The representation loss after processing this batch is:  0.003119315952062607\n",
      "\n",
      "The classification loss after processing this batch is:  0.19615046679973602\n",
      "The representation loss after processing this batch is:  0.0033827759325504303\n",
      "\n",
      "The classification loss after processing this batch is:  0.18694782257080078\n",
      "The representation loss after processing this batch is:  0.0030596479773521423\n",
      "\n",
      "The classification loss after processing this batch is:  0.253030002117157\n",
      "The representation loss after processing this batch is:  0.0034688562154769897\n",
      "\n",
      "The classification loss after processing this batch is:  0.1539698988199234\n",
      "The representation loss after processing this batch is:  0.003295205533504486\n",
      "\n",
      "The classification loss after processing this batch is:  0.17868439853191376\n",
      "The representation loss after processing this batch is:  0.003670237958431244\n",
      "\n",
      "The classification loss after processing this batch is:  0.21644115447998047\n",
      "The representation loss after processing this batch is:  0.0033000558614730835\n",
      "\n",
      "The classification loss after processing this batch is:  0.23531241714954376\n",
      "The representation loss after processing this batch is:  0.002787157893180847\n",
      "\n",
      "The classification loss after processing this batch is:  0.18790200352668762\n",
      "The representation loss after processing this batch is:  0.0030987337231636047\n",
      "\n",
      "The classification loss after processing this batch is:  0.30039092898368835\n",
      "The representation loss after processing this batch is:  0.002971220761537552\n",
      "\n",
      "The classification loss after processing this batch is:  0.3914657533168793\n",
      "The representation loss after processing this batch is:  0.0032302066683769226\n",
      "\n",
      "The classification loss after processing this batch is:  0.15208877623081207\n",
      "The representation loss after processing this batch is:  0.0030502118170261383\n",
      "\n",
      "The classification loss after processing this batch is:  0.17581459879875183\n",
      "The representation loss after processing this batch is:  0.0033853501081466675\n",
      "\n",
      "The classification loss after processing this batch is:  0.2014870047569275\n",
      "The representation loss after processing this batch is:  0.003620721399784088\n",
      "\n",
      "The classification loss after processing this batch is:  0.25254586338996887\n",
      "The representation loss after processing this batch is:  0.0033017173409461975\n",
      "\n",
      "The classification loss after processing this batch is:  0.34138455986976624\n",
      "The representation loss after processing this batch is:  0.0035210996866226196\n",
      "\n",
      "The classification loss after processing this batch is:  0.2836262285709381\n",
      "The representation loss after processing this batch is:  0.003947116434574127\n",
      "\n",
      "The classification loss after processing this batch is:  0.3611232340335846\n",
      "The representation loss after processing this batch is:  0.003876425325870514\n",
      "\n",
      "The classification loss after processing this batch is:  0.25535935163497925\n",
      "The representation loss after processing this batch is:  0.0038497447967529297\n",
      "\n",
      "The classification loss after processing this batch is:  0.2188379317522049\n",
      "The representation loss after processing this batch is:  0.0033921971917152405\n",
      "\n",
      "The classification loss after processing this batch is:  0.21134522557258606\n",
      "The representation loss after processing this batch is:  0.0040583983063697815\n",
      "\n",
      "The classification loss after processing this batch is:  0.14846692979335785\n",
      "The representation loss after processing this batch is:  0.0032798871397972107\n",
      "\n",
      "The classification loss after processing this batch is:  0.24383950233459473\n",
      "The representation loss after processing this batch is:  0.003563009202480316\n",
      "\n",
      "The classification loss after processing this batch is:  0.18767030537128448\n",
      "The representation loss after processing this batch is:  0.003004681318998337\n",
      "\n",
      "The classification loss after processing this batch is:  0.1203361228108406\n",
      "The representation loss after processing this batch is:  0.002992302179336548\n",
      "\n",
      "The classification loss after processing this batch is:  0.15698952972888947\n",
      "The representation loss after processing this batch is:  0.0031292960047721863\n",
      "\n",
      "The classification loss after processing this batch is:  0.1781211793422699\n",
      "The representation loss after processing this batch is:  0.00351928174495697\n",
      "\n",
      "The classification loss after processing this batch is:  0.2226736694574356\n",
      "The representation loss after processing this batch is:  0.0029060393571853638\n",
      "\n",
      "The classification loss after processing this batch is:  0.15093931555747986\n",
      "The representation loss after processing this batch is:  0.0030865445733070374\n",
      "\n",
      "The classification loss after processing this batch is:  0.17630046606063843\n",
      "The representation loss after processing this batch is:  0.0028215497732162476\n",
      "\n",
      "The classification loss after processing this batch is:  0.12318785488605499\n",
      "The representation loss after processing this batch is:  0.002929903566837311\n",
      "\n",
      "The classification loss after processing this batch is:  0.1786045879125595\n",
      "The representation loss after processing this batch is:  0.0025564953684806824\n",
      "\n",
      "The classification loss after processing this batch is:  0.17237381637096405\n",
      "The representation loss after processing this batch is:  0.0027828142046928406\n",
      "\n",
      "The classification loss after processing this batch is:  0.5744788646697998\n",
      "The representation loss after processing this batch is:  0.003322616219520569\n",
      "\n",
      "The classification loss after processing this batch is:  0.20084036886692047\n",
      "The representation loss after processing this batch is:  0.003079663962125778\n",
      "\n",
      "The classification loss after processing this batch is:  0.305692195892334\n",
      "The representation loss after processing this batch is:  0.002924613654613495\n",
      "\n",
      "The classification loss after processing this batch is:  0.31007224321365356\n",
      "The representation loss after processing this batch is:  0.0031231343746185303\n",
      "\n",
      "The classification loss after processing this batch is:  0.18715229630470276\n",
      "The representation loss after processing this batch is:  0.003013238310813904\n",
      "\n",
      "The classification loss after processing this batch is:  0.3842807710170746\n",
      "The representation loss after processing this batch is:  0.0034634433686733246\n",
      "\n",
      "The classification loss after processing this batch is:  0.22430719435214996\n",
      "The representation loss after processing this batch is:  0.0032392404973506927\n",
      "\n",
      "The classification loss after processing this batch is:  0.31603020429611206\n",
      "The representation loss after processing this batch is:  0.002789534628391266\n",
      "\n",
      "The classification loss after processing this batch is:  0.12716124951839447\n",
      "The representation loss after processing this batch is:  0.002836570143699646\n",
      "\n",
      "The classification loss after processing this batch is:  0.17212773859500885\n",
      "The representation loss after processing this batch is:  0.0029501989483833313\n",
      "\n",
      "The classification loss after processing this batch is:  0.09167103469371796\n",
      "The representation loss after processing this batch is:  0.0035027116537094116\n",
      "\n",
      "The classification loss after processing this batch is:  0.1027652695775032\n",
      "The representation loss after processing this batch is:  0.0033029019832611084\n",
      "\n",
      "The classification loss after processing this batch is:  0.16099976003170013\n",
      "The representation loss after processing this batch is:  0.003125689923763275\n",
      "\n",
      "The classification loss after processing this batch is:  0.11770889163017273\n",
      "The representation loss after processing this batch is:  0.0026762112975120544\n",
      "\n",
      "The classification loss after processing this batch is:  0.1829300820827484\n",
      "The representation loss after processing this batch is:  0.0032614991068840027\n",
      "\n",
      "The classification loss after processing this batch is:  0.17184080183506012\n",
      "The representation loss after processing this batch is:  0.003588669002056122\n",
      "\n",
      "The classification loss after processing this batch is:  0.14477893710136414\n",
      "The representation loss after processing this batch is:  0.0029234886169433594\n",
      "\n",
      "The classification loss after processing this batch is:  0.2407507449388504\n",
      "The representation loss after processing this batch is:  0.002602260559797287\n",
      "\n",
      "The classification loss after processing this batch is:  0.20365473628044128\n",
      "The representation loss after processing this batch is:  0.003331892192363739\n",
      "\n",
      "The classification loss after processing this batch is:  0.16664600372314453\n",
      "The representation loss after processing this batch is:  0.003091316670179367\n",
      "\n",
      "The classification loss after processing this batch is:  0.20101581513881683\n",
      "The representation loss after processing this batch is:  0.0034807026386260986\n",
      "\n",
      "The classification loss after processing this batch is:  0.25880756974220276\n",
      "The representation loss after processing this batch is:  0.0033500343561172485\n",
      "\n",
      "The classification loss after processing this batch is:  0.18146257102489471\n",
      "The representation loss after processing this batch is:  0.002810440957546234\n",
      "\n",
      "The classification loss after processing this batch is:  0.15450157225131989\n",
      "The representation loss after processing this batch is:  0.0028544440865516663\n",
      "\n",
      "The classification loss after processing this batch is:  0.2823258340358734\n",
      "The representation loss after processing this batch is:  0.0032038167119026184\n",
      "\n",
      "The classification loss after processing this batch is:  0.23819656670093536\n",
      "The representation loss after processing this batch is:  0.0031118765473365784\n",
      "\n",
      "The classification loss after processing this batch is:  0.2204982191324234\n",
      "The representation loss after processing this batch is:  0.0029460862278938293\n",
      "\n",
      "The classification loss after processing this batch is:  0.14631237089633942\n",
      "The representation loss after processing this batch is:  0.002998456358909607\n",
      "\n",
      "The classification loss after processing this batch is:  0.20678791403770447\n",
      "The representation loss after processing this batch is:  0.003492392599582672\n",
      "\n",
      "The classification loss after processing this batch is:  0.2277626395225525\n",
      "The representation loss after processing this batch is:  0.0031102560460567474\n",
      "\n",
      "The classification loss after processing this batch is:  0.20379601418972015\n",
      "The representation loss after processing this batch is:  0.003673221915960312\n",
      "\n",
      "The classification loss after processing this batch is:  0.15229906141757965\n",
      "The representation loss after processing this batch is:  0.003890823572874069\n",
      "\n",
      "The classification loss after processing this batch is:  0.1586158126592636\n",
      "The representation loss after processing this batch is:  0.004691131412982941\n",
      "\n",
      "The classification loss after processing this batch is:  0.2369850128889084\n",
      "The representation loss after processing this batch is:  0.0035047754645347595\n",
      "\n",
      "The classification loss after processing this batch is:  0.2733538746833801\n",
      "The representation loss after processing this batch is:  0.0033534206449985504\n",
      "\n",
      "The classification loss after processing this batch is:  0.20531469583511353\n",
      "The representation loss after processing this batch is:  0.00452287495136261\n",
      "\n",
      "The classification loss after processing this batch is:  0.1985732913017273\n",
      "The representation loss after processing this batch is:  0.0035488493740558624\n",
      "\n",
      "The classification loss after processing this batch is:  0.11993011832237244\n",
      "The representation loss after processing this batch is:  0.002632133662700653\n",
      "\n",
      "The classification loss after processing this batch is:  0.26982179284095764\n",
      "The representation loss after processing this batch is:  0.0029795318841934204\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1280640810728073\n",
      "The representation loss after processing this batch is:  0.0032312944531440735\n",
      "\n",
      "The classification loss after processing this batch is:  0.15632864832878113\n",
      "The representation loss after processing this batch is:  0.003214441239833832\n",
      "\n",
      "The classification loss after processing this batch is:  0.151136115193367\n",
      "The representation loss after processing this batch is:  0.0035568922758102417\n",
      "\n",
      "The classification loss after processing this batch is:  0.1550133228302002\n",
      "The representation loss after processing this batch is:  0.003246508538722992\n",
      "\n",
      "The classification loss after processing this batch is:  0.1771365851163864\n",
      "The representation loss after processing this batch is:  0.0033205263316631317\n",
      "\n",
      "The classification loss after processing this batch is:  0.24445849657058716\n",
      "The representation loss after processing this batch is:  0.0036407113075256348\n",
      "\n",
      "The classification loss after processing this batch is:  0.198062926530838\n",
      "The representation loss after processing this batch is:  0.003517448902130127\n",
      "\n",
      "The classification loss after processing this batch is:  0.2185644805431366\n",
      "The representation loss after processing this batch is:  0.003296155482530594\n",
      "\n",
      "The classification loss after processing this batch is:  0.2134747952222824\n",
      "The representation loss after processing this batch is:  0.0037977993488311768\n",
      "\n",
      "The classification loss after processing this batch is:  0.14384476840496063\n",
      "The representation loss after processing this batch is:  0.003235429525375366\n",
      "\n",
      "The classification loss after processing this batch is:  0.15128377079963684\n",
      "The representation loss after processing this batch is:  0.002768799662590027\n",
      "\n",
      "The classification loss after processing this batch is:  0.16010375320911407\n",
      "The representation loss after processing this batch is:  0.003696683794260025\n",
      "\n",
      "The classification loss after processing this batch is:  0.19056877493858337\n",
      "The representation loss after processing this batch is:  0.0030498355627059937\n",
      "\n",
      "The classification loss after processing this batch is:  0.10807038843631744\n",
      "The representation loss after processing this batch is:  0.0027628690004348755\n",
      "\n",
      "The classification loss after processing this batch is:  0.1077311560511589\n",
      "The representation loss after processing this batch is:  0.00273769348859787\n",
      "\n",
      "The classification loss after processing this batch is:  0.14772342145442963\n",
      "The representation loss after processing this batch is:  0.0035627558827400208\n",
      "\n",
      "The classification loss after processing this batch is:  0.1496437042951584\n",
      "The representation loss after processing this batch is:  0.0029485896229743958\n",
      "\n",
      "The classification loss after processing this batch is:  0.25367021560668945\n",
      "The representation loss after processing this batch is:  0.0031816810369491577\n",
      "\n",
      "The classification loss after processing this batch is:  0.2168455421924591\n",
      "The representation loss after processing this batch is:  0.0029875002801418304\n",
      "\n",
      "The classification loss after processing this batch is:  0.23257866501808167\n",
      "The representation loss after processing this batch is:  0.003178723156452179\n",
      "\n",
      "The classification loss after processing this batch is:  0.12254776805639267\n",
      "The representation loss after processing this batch is:  0.003269881010055542\n",
      "\n",
      "The classification loss after processing this batch is:  0.26198455691337585\n",
      "The representation loss after processing this batch is:  0.0029896944761276245\n",
      "\n",
      "The classification loss after processing this batch is:  0.20255349576473236\n",
      "The representation loss after processing this batch is:  0.0029993876814842224\n",
      "\n",
      "The classification loss after processing this batch is:  0.17136768996715546\n",
      "The representation loss after processing this batch is:  0.0029173940420150757\n",
      "\n",
      "The classification loss after processing this batch is:  0.20297333598136902\n",
      "The representation loss after processing this batch is:  0.003243684768676758\n",
      "\n",
      "The classification loss after processing this batch is:  0.23584601283073425\n",
      "The representation loss after processing this batch is:  0.003511779010295868\n",
      "\n",
      "The classification loss after processing this batch is:  0.11079365760087967\n",
      "The representation loss after processing this batch is:  0.003021053969860077\n",
      "\n",
      "The classification loss after processing this batch is:  0.11929073929786682\n",
      "The representation loss after processing this batch is:  0.00313723087310791\n",
      "\n",
      "The classification loss after processing this batch is:  0.12584976851940155\n",
      "The representation loss after processing this batch is:  0.002830512821674347\n",
      "\n",
      "The classification loss after processing this batch is:  0.23601455986499786\n",
      "The representation loss after processing this batch is:  0.003291212022304535\n",
      "\n",
      "The classification loss after processing this batch is:  0.1919373869895935\n",
      "The representation loss after processing this batch is:  0.002963438630104065\n",
      "\n",
      "The classification loss after processing this batch is:  0.18794812262058258\n",
      "The representation loss after processing this batch is:  0.003923133015632629\n",
      "\n",
      "The classification loss after processing this batch is:  0.2616127133369446\n",
      "The representation loss after processing this batch is:  0.0034046992659568787\n",
      "\n",
      "The classification loss after processing this batch is:  0.24051381647586823\n",
      "The representation loss after processing this batch is:  0.003493398427963257\n",
      "\n",
      "The classification loss after processing this batch is:  0.2250310629606247\n",
      "The representation loss after processing this batch is:  0.0028494447469711304\n",
      "\n",
      "The classification loss after processing this batch is:  0.3694100081920624\n",
      "The representation loss after processing this batch is:  0.003226783126592636\n",
      "\n",
      "The classification loss after processing this batch is:  0.24689896404743195\n",
      "The representation loss after processing this batch is:  0.0027818791568279266\n",
      "\n",
      "The classification loss after processing this batch is:  0.20634585618972778\n",
      "The representation loss after processing this batch is:  0.0027737878262996674\n",
      "\n",
      "The classification loss after processing this batch is:  0.1337117850780487\n",
      "The representation loss after processing this batch is:  0.00281461700797081\n",
      "\n",
      "The classification loss after processing this batch is:  0.11178430169820786\n",
      "The representation loss after processing this batch is:  0.00288960337638855\n",
      "\n",
      "The classification loss after processing this batch is:  0.12381304055452347\n",
      "The representation loss after processing this batch is:  0.002992108464241028\n",
      "\n",
      "The classification loss after processing this batch is:  0.1546556055545807\n",
      "The representation loss after processing this batch is:  0.003703981637954712\n",
      "\n",
      "The classification loss after processing this batch is:  0.18782171607017517\n",
      "The representation loss after processing this batch is:  0.002908259630203247\n",
      "\n",
      "The classification loss after processing this batch is:  0.15937167406082153\n",
      "The representation loss after processing this batch is:  0.0029917284846305847\n",
      "\n",
      "The classification loss after processing this batch is:  0.25823235511779785\n",
      "The representation loss after processing this batch is:  0.003125883638858795\n",
      "\n",
      "The classification loss after processing this batch is:  0.21584807336330414\n",
      "The representation loss after processing this batch is:  0.003258906304836273\n",
      "\n",
      "The classification loss after processing this batch is:  0.2663634717464447\n",
      "The representation loss after processing this batch is:  0.0027401186525821686\n",
      "\n",
      "The classification loss after processing this batch is:  0.1838742196559906\n",
      "The representation loss after processing this batch is:  0.0030233822762966156\n",
      "\n",
      "The classification loss after processing this batch is:  0.3205588459968567\n",
      "The representation loss after processing this batch is:  0.0027456730604171753\n",
      "\n",
      "The classification loss after processing this batch is:  0.19784358143806458\n",
      "The representation loss after processing this batch is:  0.0031965523958206177\n",
      "\n",
      "The classification loss after processing this batch is:  0.13462109863758087\n",
      "The representation loss after processing this batch is:  0.00279805064201355\n",
      "\n",
      "The classification loss after processing this batch is:  0.1934272199869156\n",
      "The representation loss after processing this batch is:  0.0028558894991874695\n",
      "\n",
      "The classification loss after processing this batch is:  0.10559374839067459\n",
      "The representation loss after processing this batch is:  0.0028404034674167633\n",
      "\n",
      "The classification loss after processing this batch is:  0.11330807954072952\n",
      "The representation loss after processing this batch is:  0.003121480345726013\n",
      "\n",
      "The classification loss after processing this batch is:  0.1908486783504486\n",
      "The representation loss after processing this batch is:  0.0031994208693504333\n",
      "\n",
      "The classification loss after processing this batch is:  0.2265947014093399\n",
      "The representation loss after processing this batch is:  0.0028476715087890625\n",
      "\n",
      "The classification loss after processing this batch is:  0.22092898190021515\n",
      "The representation loss after processing this batch is:  0.0031715556979179382\n",
      "\n",
      "The classification loss after processing this batch is:  0.13856907188892365\n",
      "The representation loss after processing this batch is:  0.003213934600353241\n",
      "\n",
      "The classification loss after processing this batch is:  0.166513592004776\n",
      "The representation loss after processing this batch is:  0.003658965229988098\n",
      "\n",
      "The classification loss after processing this batch is:  0.1221117451786995\n",
      "The representation loss after processing this batch is:  0.003084629774093628\n",
      "\n",
      "The classification loss after processing this batch is:  0.29101377725601196\n",
      "The representation loss after processing this batch is:  0.0029820799827575684\n",
      "\n",
      "The classification loss after processing this batch is:  0.12353837490081787\n",
      "The representation loss after processing this batch is:  0.0027833059430122375\n",
      "\n",
      "The classification loss after processing this batch is:  0.09692348539829254\n",
      "The representation loss after processing this batch is:  0.003168240189552307\n",
      "\n",
      "The classification loss after processing this batch is:  0.18103335797786713\n",
      "The representation loss after processing this batch is:  0.0040088072419166565\n",
      "\n",
      "The classification loss after processing this batch is:  0.1807478368282318\n",
      "The representation loss after processing this batch is:  0.003208853304386139\n",
      "\n",
      "The classification loss after processing this batch is:  0.1486416757106781\n",
      "The representation loss after processing this batch is:  0.0037144124507904053\n",
      "\n",
      "The classification loss after processing this batch is:  0.13058623671531677\n",
      "The representation loss after processing this batch is:  0.002499926835298538\n",
      "\n",
      "The classification loss after processing this batch is:  0.1956651657819748\n",
      "The representation loss after processing this batch is:  0.0035790279507637024\n",
      "\n",
      "The classification loss after processing this batch is:  0.27170148491859436\n",
      "The representation loss after processing this batch is:  0.00366780161857605\n",
      "\n",
      "The classification loss after processing this batch is:  0.2859725058078766\n",
      "The representation loss after processing this batch is:  0.00309772789478302\n",
      "\n",
      "The classification loss after processing this batch is:  0.2518211305141449\n",
      "The representation loss after processing this batch is:  0.0035912320017814636\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1177956759929657\n",
      "The representation loss after processing this batch is:  0.0032601431012153625\n",
      "\n",
      "The classification loss after processing this batch is:  0.14473682641983032\n",
      "The representation loss after processing this batch is:  0.0027296654880046844\n",
      "\n",
      "The classification loss after processing this batch is:  0.28530070185661316\n",
      "The representation loss after processing this batch is:  0.003232695162296295\n",
      "\n",
      "The classification loss after processing this batch is:  0.3242259919643402\n",
      "The representation loss after processing this batch is:  0.003140389919281006\n",
      "\n",
      "The classification loss after processing this batch is:  0.286848247051239\n",
      "The representation loss after processing this batch is:  0.0032406002283096313\n",
      "\n",
      "The classification loss after processing this batch is:  0.3604196012020111\n",
      "The representation loss after processing this batch is:  0.0032330378890037537\n",
      "\n",
      "The classification loss after processing this batch is:  0.1716785728931427\n",
      "The representation loss after processing this batch is:  0.0030890442430973053\n",
      "\n",
      "The classification loss after processing this batch is:  0.25207969546318054\n",
      "The representation loss after processing this batch is:  0.0029023736715316772\n",
      "\n",
      "The classification loss after processing this batch is:  0.17448307573795319\n",
      "The representation loss after processing this batch is:  0.0028328001499176025\n",
      "\n",
      "The classification loss after processing this batch is:  0.17190971970558167\n",
      "The representation loss after processing this batch is:  0.0032033771276474\n",
      "\n",
      "The classification loss after processing this batch is:  0.1387598216533661\n",
      "The representation loss after processing this batch is:  0.0029639676213264465\n",
      "\n",
      "The classification loss after processing this batch is:  0.16538673639297485\n",
      "The representation loss after processing this batch is:  0.002822592854499817\n",
      "\n",
      "The classification loss after processing this batch is:  0.2409813553094864\n",
      "The representation loss after processing this batch is:  0.0029630251228809357\n",
      "\n",
      "The classification loss after processing this batch is:  0.17723624408245087\n",
      "The representation loss after processing this batch is:  0.003324907273054123\n",
      "\n",
      "The classification loss after processing this batch is:  0.20319096744060516\n",
      "The representation loss after processing this batch is:  0.003399074077606201\n",
      "\n",
      "The classification loss after processing this batch is:  0.1087094396352768\n",
      "The representation loss after processing this batch is:  0.00348605215549469\n",
      "\n",
      "The classification loss after processing this batch is:  0.15395770967006683\n",
      "The representation loss after processing this batch is:  0.0033540725708007812\n",
      "\n",
      "The classification loss after processing this batch is:  0.16663728654384613\n",
      "The representation loss after processing this batch is:  0.003207944333553314\n",
      "\n",
      "The classification loss after processing this batch is:  0.21690601110458374\n",
      "The representation loss after processing this batch is:  0.0032682716846466064\n",
      "\n",
      "The classification loss after processing this batch is:  0.10333595424890518\n",
      "The representation loss after processing this batch is:  0.0035654082894325256\n",
      "\n",
      "The classification loss after processing this batch is:  0.1293557733297348\n",
      "The representation loss after processing this batch is:  0.0029121115803718567\n",
      "\n",
      "The classification loss after processing this batch is:  0.2156098634004593\n",
      "The representation loss after processing this batch is:  0.0034088343381881714\n",
      "\n",
      "The classification loss after processing this batch is:  0.2465648651123047\n",
      "The representation loss after processing this batch is:  0.002936549484729767\n",
      "\n",
      "The classification loss after processing this batch is:  0.20773814618587494\n",
      "The representation loss after processing this batch is:  0.002882726490497589\n",
      "\n",
      "The classification loss after processing this batch is:  0.1478598266839981\n",
      "The representation loss after processing this batch is:  0.0027957558631896973\n",
      "\n",
      "The classification loss after processing this batch is:  0.10677751898765564\n",
      "The representation loss after processing this batch is:  0.0030624009668827057\n",
      "\n",
      "The classification loss after processing this batch is:  0.1331336945295334\n",
      "The representation loss after processing this batch is:  0.0028568170964717865\n",
      "\n",
      "The classification loss after processing this batch is:  0.1684902459383011\n",
      "The representation loss after processing this batch is:  0.003384821116924286\n",
      "\n",
      "The classification loss after processing this batch is:  0.2195107638835907\n",
      "The representation loss after processing this batch is:  0.0028678104281425476\n",
      "\n",
      "The classification loss after processing this batch is:  0.20897822082042694\n",
      "The representation loss after processing this batch is:  0.004024386405944824\n",
      "\n",
      "The classification loss after processing this batch is:  0.13464419543743134\n",
      "The representation loss after processing this batch is:  0.0029210075736045837\n",
      "\n",
      "The classification loss after processing this batch is:  0.23089101910591125\n",
      "The representation loss after processing this batch is:  0.003018055111169815\n",
      "\n",
      "The classification loss after processing this batch is:  0.291904091835022\n",
      "The representation loss after processing this batch is:  0.0030763670802116394\n",
      "\n",
      "The classification loss after processing this batch is:  0.09191497415304184\n",
      "The representation loss after processing this batch is:  0.003008916974067688\n",
      "\n",
      "The classification loss after processing this batch is:  0.1661377251148224\n",
      "The representation loss after processing this batch is:  0.0029496848583221436\n",
      "\n",
      "The classification loss after processing this batch is:  0.26842376589775085\n",
      "The representation loss after processing this batch is:  0.0028076544404029846\n",
      "\n",
      "The classification loss after processing this batch is:  0.2796516716480255\n",
      "The representation loss after processing this batch is:  0.003099098801612854\n",
      "\n",
      "The classification loss after processing this batch is:  0.1689717173576355\n",
      "The representation loss after processing this batch is:  0.0030090361833572388\n",
      "\n",
      "The classification loss after processing this batch is:  0.3061489760875702\n",
      "The representation loss after processing this batch is:  0.002807512879371643\n",
      "\n",
      "The classification loss after processing this batch is:  0.22931961715221405\n",
      "The representation loss after processing this batch is:  0.0031553953886032104\n",
      "\n",
      "The classification loss after processing this batch is:  0.2742525637149811\n",
      "The representation loss after processing this batch is:  0.0034486837685108185\n",
      "\n",
      "The classification loss after processing this batch is:  0.18977370858192444\n",
      "The representation loss after processing this batch is:  0.0034654736518859863\n",
      "\n",
      "The classification loss after processing this batch is:  0.26338550448417664\n",
      "The representation loss after processing this batch is:  0.0030594468116760254\n",
      "\n",
      "The classification loss after processing this batch is:  0.14752721786499023\n",
      "The representation loss after processing this batch is:  0.004614129662513733\n",
      "\n",
      "The classification loss after processing this batch is:  0.15586309134960175\n",
      "The representation loss after processing this batch is:  0.0028577670454978943\n",
      "\n",
      "The classification loss after processing this batch is:  0.1537550538778305\n",
      "The representation loss after processing this batch is:  0.0028464943170547485\n",
      "\n",
      "The classification loss after processing this batch is:  0.14882810413837433\n",
      "The representation loss after processing this batch is:  0.002647344022989273\n",
      "\n",
      "The classification loss after processing this batch is:  0.20354719460010529\n",
      "The representation loss after processing this batch is:  0.0030825138092041016\n",
      "\n",
      "The classification loss after processing this batch is:  0.17672625184059143\n",
      "The representation loss after processing this batch is:  0.003177069127559662\n",
      "\n",
      "The classification loss after processing this batch is:  0.2358662337064743\n",
      "The representation loss after processing this batch is:  0.002960778772830963\n",
      "\n",
      "The classification loss after processing this batch is:  0.10235759615898132\n",
      "The representation loss after processing this batch is:  0.003245905041694641\n",
      "\n",
      "The classification loss after processing this batch is:  0.13234595954418182\n",
      "The representation loss after processing this batch is:  0.0033761560916900635\n",
      "\n",
      "The classification loss after processing this batch is:  0.20863255858421326\n",
      "The representation loss after processing this batch is:  0.0034353509545326233\n",
      "\n",
      "The classification loss after processing this batch is:  0.09589163213968277\n",
      "The representation loss after processing this batch is:  0.0031812041997909546\n",
      "\n",
      "The classification loss after processing this batch is:  0.15296824276447296\n",
      "The representation loss after processing this batch is:  0.0029575079679489136\n",
      "\n",
      "The classification loss after processing this batch is:  0.10652109980583191\n",
      "The representation loss after processing this batch is:  0.0030931979417800903\n",
      "\n",
      "The classification loss after processing this batch is:  0.11263581365346909\n",
      "The representation loss after processing this batch is:  0.0028776973485946655\n",
      "\n",
      "The classification loss after processing this batch is:  0.19837668538093567\n",
      "The representation loss after processing this batch is:  0.0035459622740745544\n",
      "\n",
      "The classification loss after processing this batch is:  0.20967790484428406\n",
      "The representation loss after processing this batch is:  0.004076182842254639\n",
      "\n",
      "The classification loss after processing this batch is:  0.1991504579782486\n",
      "The representation loss after processing this batch is:  0.003975264728069305\n",
      "\n",
      "The classification loss after processing this batch is:  0.16252878308296204\n",
      "The representation loss after processing this batch is:  0.003128413110971451\n",
      "\n",
      "The classification loss after processing this batch is:  0.18608084321022034\n",
      "The representation loss after processing this batch is:  0.0031202025711536407\n",
      "\n",
      "The classification loss after processing this batch is:  0.15281197428703308\n",
      "The representation loss after processing this batch is:  0.002936452627182007\n",
      "\n",
      "The classification loss after processing this batch is:  0.11881884932518005\n",
      "The representation loss after processing this batch is:  0.0031392350792884827\n",
      "\n",
      "The classification loss after processing this batch is:  0.11980243027210236\n",
      "The representation loss after processing this batch is:  0.0030300691723823547\n",
      "\n",
      "The classification loss after processing this batch is:  0.10844569653272629\n",
      "The representation loss after processing this batch is:  0.003417268395423889\n",
      "\n",
      "The classification loss after processing this batch is:  0.1692986786365509\n",
      "The representation loss after processing this batch is:  0.003545135259628296\n",
      "\n",
      "The classification loss after processing this batch is:  0.25825148820877075\n",
      "The representation loss after processing this batch is:  0.0031741149723529816\n",
      "\n",
      "The classification loss after processing this batch is:  0.21324409544467926\n",
      "The representation loss after processing this batch is:  0.0027974769473075867\n",
      "\n",
      "The classification loss after processing this batch is:  0.15858550369739532\n",
      "The representation loss after processing this batch is:  0.004107348620891571\n",
      "\n",
      "The classification loss after processing this batch is:  0.14705124497413635\n",
      "The representation loss after processing this batch is:  0.003557443618774414\n",
      "\n",
      "The classification loss after processing this batch is:  0.19629642367362976\n",
      "The representation loss after processing this batch is:  0.003180108964443207\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.15526120364665985\n",
      "The representation loss after processing this batch is:  0.00326620414853096\n",
      "\n",
      "The classification loss after processing this batch is:  0.4322362244129181\n",
      "The representation loss after processing this batch is:  0.0035103484988212585\n",
      "\n",
      "The classification loss after processing this batch is:  0.1694101244211197\n",
      "The representation loss after processing this batch is:  0.0031077563762664795\n",
      "\n",
      "The classification loss after processing this batch is:  0.31019002199172974\n",
      "The representation loss after processing this batch is:  0.004098899662494659\n",
      "\n",
      "The classification loss after processing this batch is:  0.17166917026042938\n",
      "The representation loss after processing this batch is:  0.002912849187850952\n",
      "\n",
      "The classification loss after processing this batch is:  0.18015989661216736\n",
      "The representation loss after processing this batch is:  0.003016427159309387\n",
      "\n",
      "The classification loss after processing this batch is:  0.18806149065494537\n",
      "The representation loss after processing this batch is:  0.0027422457933425903\n",
      "\n",
      "The classification loss after processing this batch is:  0.2035740464925766\n",
      "The representation loss after processing this batch is:  0.0034824833273887634\n",
      "\n",
      "The classification loss after processing this batch is:  0.2986219525337219\n",
      "The representation loss after processing this batch is:  0.0030219629406929016\n",
      "\n",
      "The classification loss after processing this batch is:  0.2556091248989105\n",
      "The representation loss after processing this batch is:  0.003690853714942932\n",
      "\n",
      "The classification loss after processing this batch is:  0.2207653820514679\n",
      "The representation loss after processing this batch is:  0.0037519484758377075\n",
      "\n",
      "The classification loss after processing this batch is:  0.19741378724575043\n",
      "The representation loss after processing this batch is:  0.0031839460134506226\n",
      "\n",
      "The classification loss after processing this batch is:  0.08757491409778595\n",
      "The representation loss after processing this batch is:  0.0035438165068626404\n",
      "\n",
      "The classification loss after processing this batch is:  0.187594473361969\n",
      "The representation loss after processing this batch is:  0.0028790049254894257\n",
      "\n",
      "The classification loss after processing this batch is:  0.15983568131923676\n",
      "The representation loss after processing this batch is:  0.003033298999071121\n",
      "\n",
      "The classification loss after processing this batch is:  0.11712057143449783\n",
      "The representation loss after processing this batch is:  0.003285512328147888\n",
      "\n",
      "The classification loss after processing this batch is:  0.18198423087596893\n",
      "The representation loss after processing this batch is:  0.0029135942459106445\n",
      "\n",
      "The classification loss after processing this batch is:  0.29042142629623413\n",
      "The representation loss after processing this batch is:  0.0031865835189819336\n",
      "\n",
      "The classification loss after processing this batch is:  0.18622557818889618\n",
      "The representation loss after processing this batch is:  0.002591043710708618\n",
      "\n",
      "The classification loss after processing this batch is:  0.17935466766357422\n",
      "The representation loss after processing this batch is:  0.0033054761588573456\n",
      "\n",
      "The classification loss after processing this batch is:  0.14038725197315216\n",
      "The representation loss after processing this batch is:  0.0029633939266204834\n",
      "\n",
      "The classification loss after processing this batch is:  0.17004677653312683\n",
      "The representation loss after processing this batch is:  0.003206498920917511\n",
      "\n",
      "The classification loss after processing this batch is:  0.1777530014514923\n",
      "The representation loss after processing this batch is:  0.0034393519163131714\n",
      "\n",
      "The classification loss after processing this batch is:  0.10761692374944687\n",
      "The representation loss after processing this batch is:  0.003752969205379486\n",
      "\n",
      "The classification loss after processing this batch is:  0.16934934258460999\n",
      "The representation loss after processing this batch is:  0.002844490110874176\n",
      "\n",
      "The classification loss after processing this batch is:  0.23680639266967773\n",
      "The representation loss after processing this batch is:  0.0027638114988803864\n",
      "\n",
      "The classification loss after processing this batch is:  0.13859353959560394\n",
      "The representation loss after processing this batch is:  0.0030697286128997803\n",
      "\n",
      "The classification loss after processing this batch is:  0.2525656819343567\n",
      "The representation loss after processing this batch is:  0.0027502812445163727\n",
      "\n",
      "The classification loss after processing this batch is:  0.20328441262245178\n",
      "The representation loss after processing this batch is:  0.0027162358164787292\n",
      "\n",
      "The classification loss after processing this batch is:  0.09996933490037918\n",
      "The representation loss after processing this batch is:  0.0029242560267448425\n",
      "\n",
      "The classification loss after processing this batch is:  0.1397889107465744\n",
      "The representation loss after processing this batch is:  0.0028195977210998535\n",
      "\n",
      "The classification loss after processing this batch is:  0.20705458521842957\n",
      "The representation loss after processing this batch is:  0.0031442195177078247\n",
      "\n",
      "The classification loss after processing this batch is:  0.12583839893341064\n",
      "The representation loss after processing this batch is:  0.003128349781036377\n",
      "\n",
      "The classification loss after processing this batch is:  0.3820233643054962\n",
      "The representation loss after processing this batch is:  0.0029118508100509644\n",
      "\n",
      "The classification loss after processing this batch is:  0.22491973638534546\n",
      "The representation loss after processing this batch is:  0.003186628222465515\n",
      "\n",
      "The classification loss after processing this batch is:  0.26760852336883545\n",
      "The representation loss after processing this batch is:  0.002920575439929962\n",
      "\n",
      "The classification loss after processing this batch is:  0.15622758865356445\n",
      "The representation loss after processing this batch is:  0.0026206225156784058\n",
      "\n",
      "The classification loss after processing this batch is:  0.21580474078655243\n",
      "The representation loss after processing this batch is:  0.003092817962169647\n",
      "\n",
      "The classification loss after processing this batch is:  0.1635887622833252\n",
      "The representation loss after processing this batch is:  0.0026610009372234344\n",
      "\n",
      "The classification loss after processing this batch is:  0.18795344233512878\n",
      "The representation loss after processing this batch is:  0.0028254427015781403\n",
      "\n",
      "The classification loss after processing this batch is:  0.23017536103725433\n",
      "The representation loss after processing this batch is:  0.0034087151288986206\n",
      "\n",
      "The classification loss after processing this batch is:  0.20566628873348236\n",
      "The representation loss after processing this batch is:  0.003699112683534622\n",
      "\n",
      "The classification loss after processing this batch is:  0.21489496529102325\n",
      "The representation loss after processing this batch is:  0.0030975230038166046\n",
      "\n",
      "The classification loss after processing this batch is:  0.20126880705356598\n",
      "The representation loss after processing this batch is:  0.0030126944184303284\n",
      "\n",
      "The classification loss after processing this batch is:  0.2725573182106018\n",
      "The representation loss after processing this batch is:  0.0033346861600875854\n",
      "\n",
      "The classification loss after processing this batch is:  0.19517087936401367\n",
      "The representation loss after processing this batch is:  0.0030907392501831055\n",
      "\n",
      "The classification loss after processing this batch is:  0.22331473231315613\n",
      "The representation loss after processing this batch is:  0.003363765776157379\n",
      "\n",
      "The classification loss after processing this batch is:  0.1452426314353943\n",
      "The representation loss after processing this batch is:  0.0030380934476852417\n",
      "\n",
      "The classification loss after processing this batch is:  0.1863432675600052\n",
      "The representation loss after processing this batch is:  0.00359904021024704\n",
      "\n",
      "The classification loss after processing this batch is:  0.11710552871227264\n",
      "The representation loss after processing this batch is:  0.0034241043031215668\n",
      "\n",
      "The classification loss after processing this batch is:  0.2284344583749771\n",
      "The representation loss after processing this batch is:  0.002804674208164215\n",
      "\n",
      "The classification loss after processing this batch is:  0.3197404742240906\n",
      "The representation loss after processing this batch is:  0.0029567331075668335\n",
      "\n",
      "The classification loss after processing this batch is:  0.13414809107780457\n",
      "The representation loss after processing this batch is:  0.0033230558037757874\n",
      "\n",
      "The classification loss after processing this batch is:  0.2637929320335388\n",
      "The representation loss after processing this batch is:  0.003065824508666992\n",
      "\n",
      "The classification loss after processing this batch is:  0.28500086069107056\n",
      "The representation loss after processing this batch is:  0.0029054880142211914\n",
      "\n",
      "The classification loss after processing this batch is:  0.23753005266189575\n",
      "The representation loss after processing this batch is:  0.0035558566451072693\n",
      "\n",
      "The classification loss after processing this batch is:  0.1344505250453949\n",
      "The representation loss after processing this batch is:  0.0029581747949123383\n",
      "\n",
      "The classification loss after processing this batch is:  0.26536208391189575\n",
      "The representation loss after processing this batch is:  0.0028553269803524017\n",
      "\n",
      "The classification loss after processing this batch is:  0.2641389071941376\n",
      "The representation loss after processing this batch is:  0.00325080007314682\n",
      "\n",
      "The classification loss after processing this batch is:  0.16499042510986328\n",
      "The representation loss after processing this batch is:  0.0033372677862644196\n",
      "\n",
      "The classification loss after processing this batch is:  0.09574832022190094\n",
      "The representation loss after processing this batch is:  0.0035355910658836365\n",
      "\n",
      "The classification loss after processing this batch is:  0.1685275137424469\n",
      "The representation loss after processing this batch is:  0.0032667815685272217\n",
      "\n",
      "The classification loss after processing this batch is:  0.15431635081768036\n",
      "The representation loss after processing this batch is:  0.003375239670276642\n",
      "\n",
      "The classification loss after processing this batch is:  0.19789333641529083\n",
      "The representation loss after processing this batch is:  0.002933874726295471\n",
      "\n",
      "The classification loss after processing this batch is:  0.2932991087436676\n",
      "The representation loss after processing this batch is:  0.003376789391040802\n",
      "\n",
      "The classification loss after processing this batch is:  0.22716490924358368\n",
      "The representation loss after processing this batch is:  0.0028266049921512604\n",
      "\n",
      "The classification loss after processing this batch is:  0.18356813490390778\n",
      "The representation loss after processing this batch is:  0.0037031136453151703\n",
      "\n",
      "The classification loss after processing this batch is:  0.19333577156066895\n",
      "The representation loss after processing this batch is:  0.003540143370628357\n",
      "\n",
      "The classification loss after processing this batch is:  0.1876864731311798\n",
      "The representation loss after processing this batch is:  0.003649406135082245\n",
      "\n",
      "The classification loss after processing this batch is:  0.17046041786670685\n",
      "The representation loss after processing this batch is:  0.00315287709236145\n",
      "\n",
      "The classification loss after processing this batch is:  0.3297407031059265\n",
      "The representation loss after processing this batch is:  0.0034710168838500977\n",
      "\n",
      "The classification loss after processing this batch is:  0.25927427411079407\n",
      "The representation loss after processing this batch is:  0.003965303301811218\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1678374856710434\n",
      "The representation loss after processing this batch is:  0.0029510706663131714\n",
      "\n",
      "The classification loss after processing this batch is:  0.1272321194410324\n",
      "The representation loss after processing this batch is:  0.00317995622754097\n",
      "\n",
      "The classification loss after processing this batch is:  0.1386800855398178\n",
      "The representation loss after processing this batch is:  0.0027472898364067078\n",
      "\n",
      "The classification loss after processing this batch is:  0.12433936446905136\n",
      "The representation loss after processing this batch is:  0.0036515891551971436\n",
      "\n",
      "The classification loss after processing this batch is:  0.1522982269525528\n",
      "The representation loss after processing this batch is:  0.0027912408113479614\n",
      "\n",
      "The classification loss after processing this batch is:  0.28891268372535706\n",
      "The representation loss after processing this batch is:  0.002846173942089081\n",
      "\n",
      "The classification loss after processing this batch is:  0.3380883038043976\n",
      "The representation loss after processing this batch is:  0.0036963075399398804\n",
      "\n",
      "The classification loss after processing this batch is:  0.2108047753572464\n",
      "The representation loss after processing this batch is:  0.0027910619974136353\n",
      "\n",
      "The classification loss after processing this batch is:  0.1770583540201187\n",
      "The representation loss after processing this batch is:  0.003024239093065262\n",
      "\n",
      "The classification loss after processing this batch is:  0.15320688486099243\n",
      "The representation loss after processing this batch is:  0.003380902111530304\n",
      "\n",
      "The classification loss after processing this batch is:  0.166555255651474\n",
      "The representation loss after processing this batch is:  0.0029639489948749542\n",
      "\n",
      "The classification loss after processing this batch is:  0.2687777876853943\n",
      "The representation loss after processing this batch is:  0.003270938992500305\n",
      "\n",
      "The classification loss after processing this batch is:  0.19435685873031616\n",
      "The representation loss after processing this batch is:  0.002724267542362213\n",
      "\n",
      "The classification loss after processing this batch is:  0.3199005424976349\n",
      "The representation loss after processing this batch is:  0.0032119452953338623\n",
      "\n",
      "The classification loss after processing this batch is:  0.2051858752965927\n",
      "The representation loss after processing this batch is:  0.0030615031719207764\n",
      "\n",
      "The classification loss after processing this batch is:  0.08464820683002472\n",
      "The representation loss after processing this batch is:  0.003563404083251953\n",
      "\n",
      "The classification loss after processing this batch is:  0.2217148095369339\n",
      "The representation loss after processing this batch is:  0.003298133611679077\n",
      "\n",
      "The classification loss after processing this batch is:  0.20313701033592224\n",
      "The representation loss after processing this batch is:  0.0028777755796909332\n",
      "\n",
      "The classification loss after processing this batch is:  0.2581670880317688\n",
      "The representation loss after processing this batch is:  0.003203265368938446\n",
      "\n",
      "The classification loss after processing this batch is:  0.2121480256319046\n",
      "The representation loss after processing this batch is:  0.002777520567178726\n",
      "\n",
      "The classification loss after processing this batch is:  0.24552392959594727\n",
      "The representation loss after processing this batch is:  0.002733781933784485\n",
      "\n",
      "The classification loss after processing this batch is:  0.20906880497932434\n",
      "The representation loss after processing this batch is:  0.0029653534293174744\n",
      "\n",
      "The classification loss after processing this batch is:  0.26617828011512756\n",
      "The representation loss after processing this batch is:  0.0029701553285121918\n",
      "\n",
      "The classification loss after processing this batch is:  0.28689202666282654\n",
      "The representation loss after processing this batch is:  0.0030814334750175476\n",
      "\n",
      "The classification loss after processing this batch is:  0.35906708240509033\n",
      "The representation loss after processing this batch is:  0.002752237021923065\n",
      "\n",
      "The classification loss after processing this batch is:  0.23433953523635864\n",
      "The representation loss after processing this batch is:  0.0030013173818588257\n",
      "\n",
      "The classification loss after processing this batch is:  0.11329277604818344\n",
      "The representation loss after processing this batch is:  0.0035557523369789124\n",
      "\n",
      "The classification loss after processing this batch is:  0.07007535547018051\n",
      "The representation loss after processing this batch is:  0.0032398179173469543\n",
      "\n",
      "The classification loss after processing this batch is:  0.17311333119869232\n",
      "The representation loss after processing this batch is:  0.0033252835273742676\n",
      "\n",
      "The classification loss after processing this batch is:  0.10577763617038727\n",
      "The representation loss after processing this batch is:  0.005070626735687256\n",
      "\n",
      "The classification loss after processing this batch is:  0.20389382541179657\n",
      "The representation loss after processing this batch is:  0.003139995038509369\n",
      "\n",
      "The classification loss after processing this batch is:  0.14512284100055695\n",
      "The representation loss after processing this batch is:  0.0035451874136924744\n",
      "\n",
      "The classification loss after processing this batch is:  0.21336516737937927\n",
      "The representation loss after processing this batch is:  0.0031072646379470825\n",
      "\n",
      "The classification loss after processing this batch is:  0.08050576597452164\n",
      "The representation loss after processing this batch is:  0.003457985818386078\n",
      "\n",
      "The classification loss after processing this batch is:  0.2185671180486679\n",
      "The representation loss after processing this batch is:  0.003073573112487793\n",
      "\n",
      "The classification loss after processing this batch is:  0.18557381629943848\n",
      "The representation loss after processing this batch is:  0.003325037658214569\n",
      "\n",
      "The classification loss after processing this batch is:  0.2162557989358902\n",
      "The representation loss after processing this batch is:  0.0031638145446777344\n",
      "\n",
      "The classification loss after processing this batch is:  0.17708219587802887\n",
      "The representation loss after processing this batch is:  0.00298280268907547\n",
      "\n",
      "The classification loss after processing this batch is:  0.12632553279399872\n",
      "The representation loss after processing this batch is:  0.0025867149233818054\n",
      "\n",
      "The classification loss after processing this batch is:  0.16939817368984222\n",
      "The representation loss after processing this batch is:  0.0031169988214969635\n",
      "\n",
      "The classification loss after processing this batch is:  0.2217860221862793\n",
      "The representation loss after processing this batch is:  0.003045611083507538\n",
      "\n",
      "The classification loss after processing this batch is:  0.18924850225448608\n",
      "The representation loss after processing this batch is:  0.0030821412801742554\n",
      "\n",
      "The classification loss after processing this batch is:  0.15217801928520203\n",
      "The representation loss after processing this batch is:  0.003420703113079071\n",
      "\n",
      "The classification loss after processing this batch is:  0.14324887096881866\n",
      "The representation loss after processing this batch is:  0.0033207908272743225\n",
      "\n",
      "The classification loss after processing this batch is:  0.07020477950572968\n",
      "The representation loss after processing this batch is:  0.0032101497054100037\n",
      "\n",
      "The classification loss after processing this batch is:  0.12240231782197952\n",
      "The representation loss after processing this batch is:  0.0035811737179756165\n",
      "\n",
      "The classification loss after processing this batch is:  0.08870352059602737\n",
      "The representation loss after processing this batch is:  0.0034258291125297546\n",
      "\n",
      "The classification loss after processing this batch is:  0.21022091805934906\n",
      "The representation loss after processing this batch is:  0.0032357797026634216\n",
      "\n",
      "The classification loss after processing this batch is:  0.12699361145496368\n",
      "The representation loss after processing this batch is:  0.003199346363544464\n",
      "\n",
      "The classification loss after processing this batch is:  0.12031754106283188\n",
      "The representation loss after processing this batch is:  0.0027644485235214233\n",
      "\n",
      "The classification loss after processing this batch is:  0.18002432584762573\n",
      "The representation loss after processing this batch is:  0.00360049307346344\n",
      "\n",
      "The classification loss after processing this batch is:  0.18343588709831238\n",
      "The representation loss after processing this batch is:  0.002830192446708679\n",
      "\n",
      "The classification loss after processing this batch is:  0.17300154268741608\n",
      "The representation loss after processing this batch is:  0.00270833820104599\n",
      "\n",
      "The classification loss after processing this batch is:  0.10840453952550888\n",
      "The representation loss after processing this batch is:  0.003093622624874115\n",
      "\n",
      "The classification loss after processing this batch is:  0.0880330353975296\n",
      "The representation loss after processing this batch is:  0.003075234591960907\n",
      "\n",
      "The classification loss after processing this batch is:  0.0917329341173172\n",
      "The representation loss after processing this batch is:  0.0030429065227508545\n",
      "\n",
      "The classification loss after processing this batch is:  0.1735791265964508\n",
      "The representation loss after processing this batch is:  0.003319486975669861\n",
      "\n",
      "The classification loss after processing this batch is:  0.20682747662067413\n",
      "The representation loss after processing this batch is:  0.0032066628336906433\n",
      "\n",
      "The classification loss after processing this batch is:  0.1260400116443634\n",
      "The representation loss after processing this batch is:  0.003123648464679718\n",
      "\n",
      "The classification loss after processing this batch is:  0.24078139662742615\n",
      "The representation loss after processing this batch is:  0.0030077658593654633\n",
      "\n",
      "The classification loss after processing this batch is:  0.12614555656909943\n",
      "The representation loss after processing this batch is:  0.00312110036611557\n",
      "\n",
      "The classification loss after processing this batch is:  0.1856788992881775\n",
      "The representation loss after processing this batch is:  0.002844683825969696\n",
      "\n",
      "The classification loss after processing this batch is:  0.24649731814861298\n",
      "The representation loss after processing this batch is:  0.003171205520629883\n",
      "\n",
      "The classification loss after processing this batch is:  0.15195365250110626\n",
      "The representation loss after processing this batch is:  0.0030044838786125183\n",
      "\n",
      "The classification loss after processing this batch is:  0.2558031678199768\n",
      "The representation loss after processing this batch is:  0.0028319917619228363\n",
      "\n",
      "The classification loss after processing this batch is:  0.18147026002407074\n",
      "The representation loss after processing this batch is:  0.002638794481754303\n",
      "\n",
      "The classification loss after processing this batch is:  0.1929006576538086\n",
      "The representation loss after processing this batch is:  0.0030548349022865295\n",
      "\n",
      "The classification loss after processing this batch is:  0.19229669868946075\n",
      "The representation loss after processing this batch is:  0.002780422568321228\n",
      "\n",
      "The classification loss after processing this batch is:  0.1460593193769455\n",
      "The representation loss after processing this batch is:  0.003371037542819977\n",
      "\n",
      "The classification loss after processing this batch is:  0.17540937662124634\n",
      "The representation loss after processing this batch is:  0.002632811665534973\n",
      "\n",
      "The classification loss after processing this batch is:  0.16524915397167206\n",
      "The representation loss after processing this batch is:  0.003094024956226349\n",
      "\n",
      "The classification loss after processing this batch is:  0.23416295647621155\n",
      "The representation loss after processing this batch is:  0.0030638501048088074\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.16798926889896393\n",
      "The representation loss after processing this batch is:  0.003094486892223358\n",
      "\n",
      "The classification loss after processing this batch is:  0.12019108235836029\n",
      "The representation loss after processing this batch is:  0.0028949305415153503\n",
      "\n",
      "The classification loss after processing this batch is:  0.1854337602853775\n",
      "The representation loss after processing this batch is:  0.002807512879371643\n",
      "\n",
      "The classification loss after processing this batch is:  0.24074022471904755\n",
      "The representation loss after processing this batch is:  0.002537459135055542\n",
      "\n",
      "The classification loss after processing this batch is:  0.11602849513292313\n",
      "The representation loss after processing this batch is:  0.002911895513534546\n",
      "\n",
      "The classification loss after processing this batch is:  0.1759222149848938\n",
      "The representation loss after processing this batch is:  0.0031053461134433746\n",
      "\n",
      "The classification loss after processing this batch is:  0.1796128898859024\n",
      "The representation loss after processing this batch is:  0.002671360969543457\n",
      "\n",
      "The classification loss after processing this batch is:  0.1293530911207199\n",
      "The representation loss after processing this batch is:  0.0033360347151756287\n",
      "\n",
      "The classification loss after processing this batch is:  0.11106094717979431\n",
      "The representation loss after processing this batch is:  0.003476381301879883\n",
      "\n",
      "The classification loss after processing this batch is:  0.14773009717464447\n",
      "The representation loss after processing this batch is:  0.003460913896560669\n",
      "\n",
      "The classification loss after processing this batch is:  0.14384178817272186\n",
      "The representation loss after processing this batch is:  0.003095325082540512\n",
      "\n",
      "The classification loss after processing this batch is:  0.16611900925636292\n",
      "The representation loss after processing this batch is:  0.0033194534480571747\n",
      "\n",
      "The classification loss after processing this batch is:  0.18561990559101105\n",
      "The representation loss after processing this batch is:  0.0032744072377681732\n",
      "\n",
      "The classification loss after processing this batch is:  0.15273040533065796\n",
      "The representation loss after processing this batch is:  0.00327509269118309\n",
      "\n",
      "The classification loss after processing this batch is:  0.19801504909992218\n",
      "The representation loss after processing this batch is:  0.0024954192340373993\n",
      "\n",
      "The classification loss after processing this batch is:  0.23101934790611267\n",
      "The representation loss after processing this batch is:  0.0031721144914627075\n",
      "\n",
      "The classification loss after processing this batch is:  0.08061947673559189\n",
      "The representation loss after processing this batch is:  0.0035268589854240417\n",
      "\n",
      "The classification loss after processing this batch is:  0.11096739768981934\n",
      "The representation loss after processing this batch is:  0.003023289144039154\n",
      "\n",
      "The classification loss after processing this batch is:  0.1548253744840622\n",
      "The representation loss after processing this batch is:  0.003002569079399109\n",
      "\n",
      "The classification loss after processing this batch is:  0.16747309267520905\n",
      "The representation loss after processing this batch is:  0.00307493656873703\n",
      "\n",
      "The classification loss after processing this batch is:  0.16269920766353607\n",
      "The representation loss after processing this batch is:  0.003018409013748169\n",
      "\n",
      "The classification loss after processing this batch is:  0.18952777981758118\n",
      "The representation loss after processing this batch is:  0.0030302703380584717\n",
      "\n",
      "The classification loss after processing this batch is:  0.17160841822624207\n",
      "The representation loss after processing this batch is:  0.0035291239619255066\n",
      "\n",
      "The classification loss after processing this batch is:  0.16221068799495697\n",
      "The representation loss after processing this batch is:  0.0032297521829605103\n",
      "\n",
      "The classification loss after processing this batch is:  0.2474685162305832\n",
      "The representation loss after processing this batch is:  0.0030211955308914185\n",
      "\n",
      "The classification loss after processing this batch is:  0.2319691926240921\n",
      "The representation loss after processing this batch is:  0.002801336348056793\n",
      "\n",
      "The classification loss after processing this batch is:  0.19293612241744995\n",
      "The representation loss after processing this batch is:  0.0027079693973064423\n",
      "\n",
      "The classification loss after processing this batch is:  0.1155269518494606\n",
      "The representation loss after processing this batch is:  0.0035390183329582214\n",
      "\n",
      "The classification loss after processing this batch is:  0.08783233165740967\n",
      "The representation loss after processing this batch is:  0.0033793598413467407\n",
      "\n",
      "The classification loss after processing this batch is:  0.242253839969635\n",
      "The representation loss after processing this batch is:  0.002772558480501175\n",
      "\n",
      "The classification loss after processing this batch is:  0.2573527693748474\n",
      "The representation loss after processing this batch is:  0.002562936395406723\n",
      "\n",
      "The classification loss after processing this batch is:  0.2546852231025696\n",
      "The representation loss after processing this batch is:  0.0031392723321914673\n",
      "\n",
      "The classification loss after processing this batch is:  0.21306414902210236\n",
      "The representation loss after processing this batch is:  0.0028529539704322815\n",
      "\n",
      "The classification loss after processing this batch is:  0.2530919909477234\n",
      "The representation loss after processing this batch is:  0.002958551049232483\n",
      "\n",
      "The classification loss after processing this batch is:  0.2750243544578552\n",
      "The representation loss after processing this batch is:  0.0029481351375579834\n",
      "\n",
      "The classification loss after processing this batch is:  0.2818169593811035\n",
      "The representation loss after processing this batch is:  0.002702508121728897\n",
      "\n",
      "The classification loss after processing this batch is:  0.26739925146102905\n",
      "The representation loss after processing this batch is:  0.0029994919896125793\n",
      "\n",
      "The classification loss after processing this batch is:  0.24238885939121246\n",
      "The representation loss after processing this batch is:  0.0031538456678390503\n",
      "\n",
      "The classification loss after processing this batch is:  0.1541105955839157\n",
      "The representation loss after processing this batch is:  0.003648631274700165\n",
      "\n",
      "The classification loss after processing this batch is:  0.10300257056951523\n",
      "The representation loss after processing this batch is:  0.0035178661346435547\n",
      "\n",
      "The classification loss after processing this batch is:  0.16410326957702637\n",
      "The representation loss after processing this batch is:  0.0032767951488494873\n",
      "\n",
      "The classification loss after processing this batch is:  0.1456105262041092\n",
      "The representation loss after processing this batch is:  0.0028627924621105194\n",
      "\n",
      "The classification loss after processing this batch is:  0.12256976217031479\n",
      "The representation loss after processing this batch is:  0.002738628536462784\n",
      "\n",
      "The classification loss after processing this batch is:  0.13358335196971893\n",
      "The representation loss after processing this batch is:  0.0027924999594688416\n",
      "\n",
      "The classification loss after processing this batch is:  0.18968293070793152\n",
      "The representation loss after processing this batch is:  0.002886265516281128\n",
      "\n",
      "The classification loss after processing this batch is:  0.12965230643749237\n",
      "The representation loss after processing this batch is:  0.002912066876888275\n",
      "\n",
      "The classification loss after processing this batch is:  0.15682074427604675\n",
      "The representation loss after processing this batch is:  0.0033460669219493866\n",
      "\n",
      "The classification loss after processing this batch is:  0.15099740028381348\n",
      "The representation loss after processing this batch is:  0.0028037354350090027\n",
      "\n",
      "The classification loss after processing this batch is:  0.14295461773872375\n",
      "The representation loss after processing this batch is:  0.0028134621679782867\n",
      "\n",
      "The classification loss after processing this batch is:  0.13418862223625183\n",
      "The representation loss after processing this batch is:  0.003136947751045227\n",
      "\n",
      "The classification loss after processing this batch is:  0.17439530789852142\n",
      "The representation loss after processing this batch is:  0.002970196306705475\n",
      "\n",
      "The classification loss after processing this batch is:  0.19927692413330078\n",
      "The representation loss after processing this batch is:  0.00393947958946228\n",
      "\n",
      "The classification loss after processing this batch is:  0.09923401474952698\n",
      "The representation loss after processing this batch is:  0.0029993653297424316\n",
      "\n",
      "The classification loss after processing this batch is:  0.11501273512840271\n",
      "The representation loss after processing this batch is:  0.003361836075782776\n",
      "\n",
      "The classification loss after processing this batch is:  0.19706059992313385\n",
      "The representation loss after processing this batch is:  0.0028869137167930603\n",
      "\n",
      "The classification loss after processing this batch is:  0.28238824009895325\n",
      "The representation loss after processing this batch is:  0.0029226578772068024\n",
      "\n",
      "The classification loss after processing this batch is:  0.1742633432149887\n",
      "The representation loss after processing this batch is:  0.0028060227632522583\n",
      "\n",
      "The classification loss after processing this batch is:  0.08825362473726273\n",
      "The representation loss after processing this batch is:  0.002745702862739563\n",
      "\n",
      "The classification loss after processing this batch is:  0.1659490317106247\n",
      "The representation loss after processing this batch is:  0.002599775791168213\n",
      "\n",
      "The classification loss after processing this batch is:  0.05374462530016899\n",
      "The representation loss after processing this batch is:  0.0033602938055992126\n",
      "\n",
      "The classification loss after processing this batch is:  0.1556583046913147\n",
      "The representation loss after processing this batch is:  0.0030216574668884277\n",
      "\n",
      "The classification loss after processing this batch is:  0.14431160688400269\n",
      "The representation loss after processing this batch is:  0.0031538456678390503\n",
      "\n",
      "The classification loss after processing this batch is:  0.09174450486898422\n",
      "The representation loss after processing this batch is:  0.002690359950065613\n",
      "\n",
      "The classification loss after processing this batch is:  0.1092856302857399\n",
      "The representation loss after processing this batch is:  0.003268428146839142\n",
      "\n",
      "The classification loss after processing this batch is:  0.11947361379861832\n",
      "The representation loss after processing this batch is:  0.0029595643281936646\n",
      "\n",
      "The classification loss after processing this batch is:  0.11287524551153183\n",
      "The representation loss after processing this batch is:  0.0026340559124946594\n",
      "\n",
      "The classification loss after processing this batch is:  0.28244102001190186\n",
      "The representation loss after processing this batch is:  0.0029194019734859467\n",
      "\n",
      "The classification loss after processing this batch is:  0.3220681846141815\n",
      "The representation loss after processing this batch is:  0.003012053668498993\n",
      "\n",
      "The classification loss after processing this batch is:  0.23792333900928497\n",
      "The representation loss after processing this batch is:  0.002866417169570923\n",
      "\n",
      "The classification loss after processing this batch is:  0.2684231102466583\n",
      "The representation loss after processing this batch is:  0.003239881247282028\n",
      "\n",
      "The classification loss after processing this batch is:  0.20443686842918396\n",
      "The representation loss after processing this batch is:  0.0029386505484580994\n",
      "\n",
      "The classification loss after processing this batch is:  0.14840476214885712\n",
      "The representation loss after processing this batch is:  0.0029509365558624268\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2639046907424927\n",
      "The representation loss after processing this batch is:  0.002862103283405304\n",
      "\n",
      "The classification loss after processing this batch is:  0.17626091837882996\n",
      "The representation loss after processing this batch is:  0.003149077296257019\n",
      "\n",
      "The classification loss after processing this batch is:  0.1996169239282608\n",
      "The representation loss after processing this batch is:  0.0027157291769981384\n",
      "\n",
      "The classification loss after processing this batch is:  0.20514602959156036\n",
      "The representation loss after processing this batch is:  0.0031134262681007385\n",
      "\n",
      "The classification loss after processing this batch is:  0.18890336155891418\n",
      "The representation loss after processing this batch is:  0.002601839601993561\n",
      "\n",
      "The classification loss after processing this batch is:  0.1663466989994049\n",
      "The representation loss after processing this batch is:  0.0029982104897499084\n",
      "\n",
      "The classification loss after processing this batch is:  0.17751996219158173\n",
      "The representation loss after processing this batch is:  0.0029121041297912598\n",
      "\n",
      "The classification loss after processing this batch is:  0.19395239651203156\n",
      "The representation loss after processing this batch is:  0.003108762204647064\n",
      "\n",
      "The classification loss after processing this batch is:  0.1308748424053192\n",
      "The representation loss after processing this batch is:  0.0031516700983047485\n",
      "\n",
      "The classification loss after processing this batch is:  0.11538516730070114\n",
      "The representation loss after processing this batch is:  0.0030073821544647217\n",
      "\n",
      "The classification loss after processing this batch is:  0.16736863553524017\n",
      "The representation loss after processing this batch is:  0.0026888884603977203\n",
      "\n",
      "The classification loss after processing this batch is:  0.22142067551612854\n",
      "The representation loss after processing this batch is:  0.0030193030834198\n",
      "\n",
      "The classification loss after processing this batch is:  0.0808785930275917\n",
      "The representation loss after processing this batch is:  0.002779148519039154\n",
      "\n",
      "The classification loss after processing this batch is:  0.12054355442523956\n",
      "The representation loss after processing this batch is:  0.0026200488209724426\n",
      "\n",
      "The classification loss after processing this batch is:  0.25226178765296936\n",
      "The representation loss after processing this batch is:  0.002709176391363144\n",
      "\n",
      "The classification loss after processing this batch is:  0.2244245409965515\n",
      "The representation loss after processing this batch is:  0.0027128979563713074\n",
      "\n",
      "The classification loss after processing this batch is:  0.14689065515995026\n",
      "The representation loss after processing this batch is:  0.0028353407979011536\n",
      "\n",
      "The classification loss after processing this batch is:  0.2762816250324249\n",
      "The representation loss after processing this batch is:  0.0028270483016967773\n",
      "\n",
      "The classification loss after processing this batch is:  0.10213469713926315\n",
      "The representation loss after processing this batch is:  0.0035677775740623474\n",
      "\n",
      "The classification loss after processing this batch is:  0.08412967622280121\n",
      "The representation loss after processing this batch is:  0.0026654712855815887\n",
      "\n",
      "The classification loss after processing this batch is:  0.10469330847263336\n",
      "The representation loss after processing this batch is:  0.002879135310649872\n",
      "\n",
      "The classification loss after processing this batch is:  0.2085985243320465\n",
      "The representation loss after processing this batch is:  0.003744564950466156\n",
      "\n",
      "The classification loss after processing this batch is:  0.19548824429512024\n",
      "The representation loss after processing this batch is:  0.003352351486682892\n",
      "\n",
      "The classification loss after processing this batch is:  0.12564896047115326\n",
      "The representation loss after processing this batch is:  0.003650769591331482\n",
      "\n",
      "The classification loss after processing this batch is:  0.17001256346702576\n",
      "The representation loss after processing this batch is:  0.002833586186170578\n",
      "\n",
      "The classification loss after processing this batch is:  0.1351030021905899\n",
      "The representation loss after processing this batch is:  0.0029148533940315247\n",
      "\n",
      "The classification loss after processing this batch is:  0.18406619131565094\n",
      "The representation loss after processing this batch is:  0.0030951648950576782\n",
      "\n",
      "The classification loss after processing this batch is:  0.17595995962619781\n",
      "The representation loss after processing this batch is:  0.0030046626925468445\n",
      "\n",
      "The classification loss after processing this batch is:  0.23970066010951996\n",
      "The representation loss after processing this batch is:  0.0027098022401332855\n",
      "\n",
      "The classification loss after processing this batch is:  0.22874495387077332\n",
      "The representation loss after processing this batch is:  0.003102816641330719\n",
      "\n",
      "The classification loss after processing this batch is:  0.3076729476451874\n",
      "The representation loss after processing this batch is:  0.0026227831840515137\n",
      "\n",
      "The classification loss after processing this batch is:  0.22565174102783203\n",
      "The representation loss after processing this batch is:  0.0026442110538482666\n",
      "\n",
      "The classification loss after processing this batch is:  0.23068930208683014\n",
      "The representation loss after processing this batch is:  0.002787090837955475\n",
      "\n",
      "The classification loss after processing this batch is:  0.24070078134536743\n",
      "The representation loss after processing this batch is:  0.0029093101620674133\n",
      "\n",
      "The classification loss after processing this batch is:  0.07965319603681564\n",
      "The representation loss after processing this batch is:  0.0032455548644065857\n",
      "\n",
      "The classification loss after processing this batch is:  0.14663352072238922\n",
      "The representation loss after processing this batch is:  0.0037298426032066345\n",
      "\n",
      "The classification loss after processing this batch is:  0.11370303481817245\n",
      "The representation loss after processing this batch is:  0.0034441575407981873\n",
      "\n",
      "The classification loss after processing this batch is:  0.14774702489376068\n",
      "The representation loss after processing this batch is:  0.0033964775502681732\n",
      "\n",
      "The classification loss after processing this batch is:  0.1645049750804901\n",
      "The representation loss after processing this batch is:  0.002400420606136322\n",
      "\n",
      "The classification loss after processing this batch is:  0.14964723587036133\n",
      "The representation loss after processing this batch is:  0.0028352253139019012\n",
      "\n",
      "The classification loss after processing this batch is:  0.17109523713588715\n",
      "The representation loss after processing this batch is:  0.003009110689163208\n",
      "\n",
      "The classification loss after processing this batch is:  0.21924589574337006\n",
      "The representation loss after processing this batch is:  0.002945542335510254\n",
      "\n",
      "The classification loss after processing this batch is:  0.19372282922267914\n",
      "The representation loss after processing this batch is:  0.0027679502964019775\n",
      "\n",
      "The classification loss after processing this batch is:  0.2495008260011673\n",
      "The representation loss after processing this batch is:  0.003261283040046692\n",
      "\n",
      "The classification loss after processing this batch is:  0.16542433202266693\n",
      "The representation loss after processing this batch is:  0.003208175301551819\n",
      "\n",
      "The classification loss after processing this batch is:  0.16991011798381805\n",
      "The representation loss after processing this batch is:  0.002599261701107025\n",
      "\n",
      "The classification loss after processing this batch is:  0.14740625023841858\n",
      "The representation loss after processing this batch is:  0.00328991562128067\n",
      "\n",
      "The classification loss after processing this batch is:  0.21627181768417358\n",
      "The representation loss after processing this batch is:  0.0037076659500598907\n",
      "\n",
      "The classification loss after processing this batch is:  0.3223038613796234\n",
      "The representation loss after processing this batch is:  0.0034524649381637573\n",
      "\n",
      "The classification loss after processing this batch is:  0.08908320218324661\n",
      "The representation loss after processing this batch is:  0.00273682177066803\n",
      "\n",
      "The classification loss after processing this batch is:  0.10153572261333466\n",
      "The representation loss after processing this batch is:  0.003096196800470352\n",
      "\n",
      "The classification loss after processing this batch is:  0.260240763425827\n",
      "The representation loss after processing this batch is:  0.003459971398115158\n",
      "\n",
      "The classification loss after processing this batch is:  0.08751817047595978\n",
      "The representation loss after processing this batch is:  0.0032890141010284424\n",
      "\n",
      "The classification loss after processing this batch is:  0.1423240602016449\n",
      "The representation loss after processing this batch is:  0.0028717592358589172\n",
      "\n",
      "The classification loss after processing this batch is:  0.18858757615089417\n",
      "The representation loss after processing this batch is:  0.003024153411388397\n",
      "\n",
      "The classification loss after processing this batch is:  0.1662125438451767\n",
      "The representation loss after processing this batch is:  0.0030959807336330414\n",
      "\n",
      "The classification loss after processing this batch is:  0.2549222707748413\n",
      "The representation loss after processing this batch is:  0.003586098551750183\n",
      "\n",
      "The classification loss after processing this batch is:  0.20783491432666779\n",
      "The representation loss after processing this batch is:  0.0034662336111068726\n",
      "\n",
      "The classification loss after processing this batch is:  0.2202916145324707\n",
      "The representation loss after processing this batch is:  0.003695085644721985\n",
      "\n",
      "The classification loss after processing this batch is:  0.13442012667655945\n",
      "The representation loss after processing this batch is:  0.002597171813249588\n",
      "\n",
      "The classification loss after processing this batch is:  0.23395182192325592\n",
      "The representation loss after processing this batch is:  0.0025995559990406036\n",
      "\n",
      "The classification loss after processing this batch is:  0.09354481846094131\n",
      "The representation loss after processing this batch is:  0.002813078463077545\n",
      "\n",
      "The classification loss after processing this batch is:  0.0766356885433197\n",
      "The representation loss after processing this batch is:  0.0027521178126335144\n",
      "\n",
      "The classification loss after processing this batch is:  0.13823992013931274\n",
      "The representation loss after processing this batch is:  0.002940591424703598\n",
      "\n",
      "The classification loss after processing this batch is:  0.09784296154975891\n",
      "The representation loss after processing this batch is:  0.0028798282146453857\n",
      "\n",
      "The classification loss after processing this batch is:  0.14201736450195312\n",
      "The representation loss after processing this batch is:  0.0028792768716812134\n",
      "\n",
      "The classification loss after processing this batch is:  0.09526467323303223\n",
      "The representation loss after processing this batch is:  0.002611745148897171\n",
      "\n",
      "The classification loss after processing this batch is:  0.13420461118221283\n",
      "The representation loss after processing this batch is:  0.0026386529207229614\n",
      "\n",
      "The classification loss after processing this batch is:  0.16426397860050201\n",
      "The representation loss after processing this batch is:  0.002699829638004303\n",
      "\n",
      "The classification loss after processing this batch is:  0.2299770712852478\n",
      "The representation loss after processing this batch is:  0.0029695257544517517\n",
      "\n",
      "The classification loss after processing this batch is:  0.2361196130514145\n",
      "The representation loss after processing this batch is:  0.0027184411883354187\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.11914057284593582\n",
      "The representation loss after processing this batch is:  0.0033585280179977417\n",
      "\n",
      "The classification loss after processing this batch is:  0.2357778400182724\n",
      "The representation loss after processing this batch is:  0.002889096736907959\n",
      "\n",
      "The classification loss after processing this batch is:  0.13244707882404327\n",
      "The representation loss after processing this batch is:  0.002842310816049576\n",
      "\n",
      "The classification loss after processing this batch is:  0.21566009521484375\n",
      "The representation loss after processing this batch is:  0.00291626900434494\n",
      "\n",
      "The classification loss after processing this batch is:  0.32318392395973206\n",
      "The representation loss after processing this batch is:  0.0031280890107154846\n",
      "\n",
      "The classification loss after processing this batch is:  0.16848841309547424\n",
      "The representation loss after processing this batch is:  0.002887248992919922\n",
      "\n",
      "The classification loss after processing this batch is:  0.2358967363834381\n",
      "The representation loss after processing this batch is:  0.0027817338705062866\n",
      "\n",
      "The classification loss after processing this batch is:  0.19316135346889496\n",
      "The representation loss after processing this batch is:  0.00294668972492218\n",
      "\n",
      "The classification loss after processing this batch is:  0.2174435555934906\n",
      "The representation loss after processing this batch is:  0.002799723297357559\n",
      "\n",
      "The classification loss after processing this batch is:  0.14349547028541565\n",
      "The representation loss after processing this batch is:  0.002909645438194275\n",
      "\n",
      "The classification loss after processing this batch is:  0.12725092470645905\n",
      "The representation loss after processing this batch is:  0.002866305410861969\n",
      "\n",
      "The classification loss after processing this batch is:  0.1341809332370758\n",
      "The representation loss after processing this batch is:  0.0027863234281539917\n",
      "\n",
      "The classification loss after processing this batch is:  0.11440805345773697\n",
      "The representation loss after processing this batch is:  0.002976946532726288\n",
      "\n",
      "The classification loss after processing this batch is:  0.08594466000795364\n",
      "The representation loss after processing this batch is:  0.002796560525894165\n",
      "\n",
      "The classification loss after processing this batch is:  0.1806599348783493\n",
      "The representation loss after processing this batch is:  0.0030536428093910217\n",
      "\n",
      "The classification loss after processing this batch is:  0.10081280767917633\n",
      "The representation loss after processing this batch is:  0.0031899437308311462\n",
      "\n",
      "The classification loss after processing this batch is:  0.2633001208305359\n",
      "The representation loss after processing this batch is:  0.003458809107542038\n",
      "\n",
      "The classification loss after processing this batch is:  0.13719390332698822\n",
      "The representation loss after processing this batch is:  0.0032495781779289246\n",
      "\n",
      "The classification loss after processing this batch is:  0.22242571413516998\n",
      "The representation loss after processing this batch is:  0.0031886547803878784\n",
      "\n",
      "The classification loss after processing this batch is:  0.2971574068069458\n",
      "The representation loss after processing this batch is:  0.0027483105659484863\n",
      "\n",
      "The classification loss after processing this batch is:  0.19457349181175232\n",
      "The representation loss after processing this batch is:  0.002558846026659012\n",
      "\n",
      "The classification loss after processing this batch is:  0.09557007253170013\n",
      "The representation loss after processing this batch is:  0.00287516787648201\n",
      "\n",
      "The classification loss after processing this batch is:  0.10561183094978333\n",
      "The representation loss after processing this batch is:  0.0033070817589759827\n",
      "\n",
      "The classification loss after processing this batch is:  0.10116081684827805\n",
      "The representation loss after processing this batch is:  0.0031908750534057617\n",
      "\n",
      "The classification loss after processing this batch is:  0.1317378431558609\n",
      "The representation loss after processing this batch is:  0.003069773316383362\n",
      "\n",
      "The classification loss after processing this batch is:  0.1278311312198639\n",
      "The representation loss after processing this batch is:  0.002357546240091324\n",
      "\n",
      "The classification loss after processing this batch is:  0.32827484607696533\n",
      "The representation loss after processing this batch is:  0.002795632928609848\n",
      "\n",
      "The classification loss after processing this batch is:  0.2716096341609955\n",
      "The representation loss after processing this batch is:  0.0029296651482582092\n",
      "\n",
      "The classification loss after processing this batch is:  0.14937500655651093\n",
      "The representation loss after processing this batch is:  0.003238201141357422\n",
      "\n",
      "The classification loss after processing this batch is:  0.28188201785087585\n",
      "The representation loss after processing this batch is:  0.0031419098377227783\n",
      "\n",
      "The classification loss after processing this batch is:  0.09747196733951569\n",
      "The representation loss after processing this batch is:  0.0030745267868041992\n",
      "\n",
      "The classification loss after processing this batch is:  0.15102465450763702\n",
      "The representation loss after processing this batch is:  0.003117438405752182\n",
      "\n",
      "The classification loss after processing this batch is:  0.22499042749404907\n",
      "The representation loss after processing this batch is:  0.002793140709400177\n",
      "\n",
      "The classification loss after processing this batch is:  0.15838852524757385\n",
      "The representation loss after processing this batch is:  0.003489762544631958\n",
      "\n",
      "The classification loss after processing this batch is:  0.17997317016124725\n",
      "The representation loss after processing this batch is:  0.004010319709777832\n",
      "\n",
      "The classification loss after processing this batch is:  0.13001962006092072\n",
      "The representation loss after processing this batch is:  0.003218546509742737\n",
      "\n",
      "The classification loss after processing this batch is:  0.18087880313396454\n",
      "The representation loss after processing this batch is:  0.003882378339767456\n",
      "\n",
      "The classification loss after processing this batch is:  0.22938603162765503\n",
      "The representation loss after processing this batch is:  0.003734789788722992\n",
      "\n",
      "The classification loss after processing this batch is:  0.14361511170864105\n",
      "The representation loss after processing this batch is:  0.0034134462475776672\n",
      "\n",
      "The classification loss after processing this batch is:  0.1791660040616989\n",
      "The representation loss after processing this batch is:  0.003021515905857086\n",
      "\n",
      "The classification loss after processing this batch is:  0.24998626112937927\n",
      "The representation loss after processing this batch is:  0.002634868025779724\n",
      "\n",
      "The classification loss after processing this batch is:  0.19293434917926788\n",
      "The representation loss after processing this batch is:  0.002533402293920517\n",
      "\n",
      "The classification loss after processing this batch is:  0.18690437078475952\n",
      "The representation loss after processing this batch is:  0.0026669837534427643\n",
      "\n",
      "The classification loss after processing this batch is:  0.10578946769237518\n",
      "The representation loss after processing this batch is:  0.0033581405878067017\n",
      "\n",
      "The classification loss after processing this batch is:  0.059630054980516434\n",
      "The representation loss after processing this batch is:  0.0030640438199043274\n",
      "\n",
      "The classification loss after processing this batch is:  0.1954410821199417\n",
      "The representation loss after processing this batch is:  0.003026328980922699\n",
      "\n",
      "The classification loss after processing this batch is:  0.10903476923704147\n",
      "The representation loss after processing this batch is:  0.0032388418912887573\n",
      "\n",
      "The classification loss after processing this batch is:  0.3013657331466675\n",
      "The representation loss after processing this batch is:  0.0028182119131088257\n",
      "\n",
      "The classification loss after processing this batch is:  0.07910896092653275\n",
      "The representation loss after processing this batch is:  0.0034203678369522095\n",
      "\n",
      "The classification loss after processing this batch is:  0.1519186943769455\n",
      "The representation loss after processing this batch is:  0.0025455355644226074\n",
      "\n",
      "The classification loss after processing this batch is:  0.21360453963279724\n",
      "The representation loss after processing this batch is:  0.003045734018087387\n",
      "\n",
      "The classification loss after processing this batch is:  0.1586020588874817\n",
      "The representation loss after processing this batch is:  0.002970948815345764\n",
      "\n",
      "The classification loss after processing this batch is:  0.1865694224834442\n",
      "The representation loss after processing this batch is:  0.002869516611099243\n",
      "\n",
      "The classification loss after processing this batch is:  0.09480351954698563\n",
      "The representation loss after processing this batch is:  0.0030461475253105164\n",
      "\n",
      "The classification loss after processing this batch is:  0.10836362093687057\n",
      "The representation loss after processing this batch is:  0.0028754472732543945\n",
      "\n",
      "The classification loss after processing this batch is:  0.10098877549171448\n",
      "The representation loss after processing this batch is:  0.0026478171348571777\n",
      "\n",
      "The classification loss after processing this batch is:  0.20753206312656403\n",
      "The representation loss after processing this batch is:  0.003904305398464203\n",
      "\n",
      "The classification loss after processing this batch is:  0.2178427129983902\n",
      "The representation loss after processing this batch is:  0.003267209976911545\n",
      "\n",
      "The classification loss after processing this batch is:  0.22079871594905853\n",
      "The representation loss after processing this batch is:  0.0026656053960323334\n",
      "\n",
      "The classification loss after processing this batch is:  0.2559635639190674\n",
      "The representation loss after processing this batch is:  0.0026084333658218384\n",
      "\n",
      "The classification loss after processing this batch is:  0.3569825291633606\n",
      "The representation loss after processing this batch is:  0.0026595741510391235\n",
      "\n",
      "The classification loss after processing this batch is:  0.15731780230998993\n",
      "The representation loss after processing this batch is:  0.0031379982829093933\n",
      "\n",
      "The classification loss after processing this batch is:  0.29972079396247864\n",
      "The representation loss after processing this batch is:  0.002921469509601593\n",
      "\n",
      "The classification loss after processing this batch is:  0.16780176758766174\n",
      "The representation loss after processing this batch is:  0.002998657524585724\n",
      "\n",
      "The classification loss after processing this batch is:  0.13331054151058197\n",
      "The representation loss after processing this batch is:  0.0027339160442352295\n",
      "\n",
      "The classification loss after processing this batch is:  0.10186503082513809\n",
      "The representation loss after processing this batch is:  0.002582855522632599\n",
      "\n",
      "The classification loss after processing this batch is:  0.10130178183317184\n",
      "The representation loss after processing this batch is:  0.0030000656843185425\n",
      "\n",
      "The classification loss after processing this batch is:  0.25271737575531006\n",
      "The representation loss after processing this batch is:  0.0029839351773262024\n",
      "\n",
      "The classification loss after processing this batch is:  0.15467241406440735\n",
      "The representation loss after processing this batch is:  0.002985522150993347\n",
      "\n",
      "The classification loss after processing this batch is:  0.18081879615783691\n",
      "The representation loss after processing this batch is:  0.0033460818231105804\n",
      "\n",
      "The classification loss after processing this batch is:  0.1539618819952011\n",
      "The representation loss after processing this batch is:  0.003686860203742981\n",
      "\n",
      "The classification loss after processing this batch is:  0.1411203294992447\n",
      "The representation loss after processing this batch is:  0.0027612075209617615\n",
      "\n",
      "The classification loss after processing this batch is:  0.12030200660228729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.0029001235961914062\n",
      "\n",
      "The classification loss after processing this batch is:  0.20514236390590668\n",
      "The representation loss after processing this batch is:  0.0025283917784690857\n",
      "\n",
      "The classification loss after processing this batch is:  0.20362690091133118\n",
      "The representation loss after processing this batch is:  0.0027660951018333435\n",
      "\n",
      "The classification loss after processing this batch is:  0.2456287294626236\n",
      "The representation loss after processing this batch is:  0.003224208950996399\n",
      "\n",
      "The classification loss after processing this batch is:  0.14888018369674683\n",
      "The representation loss after processing this batch is:  0.0026924312114715576\n",
      "\n",
      "The classification loss after processing this batch is:  0.3465636074542999\n",
      "The representation loss after processing this batch is:  0.0022570043802261353\n",
      "\n",
      "The classification loss after processing this batch is:  0.1632220596075058\n",
      "The representation loss after processing this batch is:  0.0024477243423461914\n",
      "\n",
      "The classification loss after processing this batch is:  0.16393207013607025\n",
      "The representation loss after processing this batch is:  0.0026894286274909973\n",
      "\n",
      "The classification loss after processing this batch is:  0.15537743270397186\n",
      "The representation loss after processing this batch is:  0.00315287709236145\n",
      "\n",
      "The classification loss after processing this batch is:  0.12615010142326355\n",
      "The representation loss after processing this batch is:  0.002680707722902298\n",
      "\n",
      "The classification loss after processing this batch is:  0.16805489361286163\n",
      "The representation loss after processing this batch is:  0.002788342535495758\n",
      "\n",
      "The classification loss after processing this batch is:  0.12508776783943176\n",
      "The representation loss after processing this batch is:  0.0030827373266220093\n",
      "\n",
      "The classification loss after processing this batch is:  0.21699877083301544\n",
      "The representation loss after processing this batch is:  0.002841982990503311\n",
      "\n",
      "The classification loss after processing this batch is:  0.270428329706192\n",
      "The representation loss after processing this batch is:  0.0033064261078834534\n",
      "\n",
      "The classification loss after processing this batch is:  0.22796346247196198\n",
      "The representation loss after processing this batch is:  0.003307897597551346\n",
      "\n",
      "The classification loss after processing this batch is:  0.1805771142244339\n",
      "The representation loss after processing this batch is:  0.002979457378387451\n",
      "\n",
      "The classification loss after processing this batch is:  0.15229377150535583\n",
      "The representation loss after processing this batch is:  0.003627609461545944\n",
      "\n",
      "The classification loss after processing this batch is:  0.26493483781814575\n",
      "The representation loss after processing this batch is:  0.0027937814593315125\n",
      "\n",
      "The classification loss after processing this batch is:  0.17366459965705872\n",
      "The representation loss after processing this batch is:  0.002879105508327484\n",
      "\n",
      "The classification loss after processing this batch is:  0.0658390000462532\n",
      "The representation loss after processing this batch is:  0.0029045119881629944\n",
      "\n",
      "The classification loss after processing this batch is:  0.1452692598104477\n",
      "The representation loss after processing this batch is:  0.0028338581323623657\n",
      "\n",
      "The classification loss after processing this batch is:  0.3235304057598114\n",
      "The representation loss after processing this batch is:  0.0032424628734588623\n",
      "\n",
      "The classification loss after processing this batch is:  0.36531946063041687\n",
      "The representation loss after processing this batch is:  0.002946123480796814\n",
      "\n",
      "The classification loss after processing this batch is:  0.32764682173728943\n",
      "The representation loss after processing this batch is:  0.002654310315847397\n",
      "\n",
      "The classification loss after processing this batch is:  0.2277524173259735\n",
      "The representation loss after processing this batch is:  0.0026809051632881165\n",
      "\n",
      "The classification loss after processing this batch is:  0.1370573341846466\n",
      "The representation loss after processing this batch is:  0.002856053411960602\n",
      "\n",
      "The classification loss after processing this batch is:  0.15375825762748718\n",
      "The representation loss after processing this batch is:  0.00297541543841362\n",
      "\n",
      "The classification loss after processing this batch is:  0.13461968302726746\n",
      "The representation loss after processing this batch is:  0.0033236779272556305\n",
      "\n",
      "The classification loss after processing this batch is:  0.19880342483520508\n",
      "The representation loss after processing this batch is:  0.003281988203525543\n",
      "\n",
      "The classification loss after processing this batch is:  0.15391257405281067\n",
      "The representation loss after processing this batch is:  0.00345524400472641\n",
      "\n",
      "The classification loss after processing this batch is:  0.1806458979845047\n",
      "The representation loss after processing this batch is:  0.0033918172121047974\n",
      "\n",
      "The classification loss after processing this batch is:  0.15009437501430511\n",
      "The representation loss after processing this batch is:  0.002960480749607086\n",
      "\n",
      "The classification loss after processing this batch is:  0.11585692316293716\n",
      "The representation loss after processing this batch is:  0.002787068486213684\n",
      "\n",
      "The classification loss after processing this batch is:  0.20998293161392212\n",
      "The representation loss after processing this batch is:  0.0033972933888435364\n",
      "\n",
      "The classification loss after processing this batch is:  0.18921954929828644\n",
      "The representation loss after processing this batch is:  0.002691134810447693\n",
      "\n",
      "The classification loss after processing this batch is:  0.15881095826625824\n",
      "The representation loss after processing this batch is:  0.0029497630894184113\n",
      "\n",
      "The classification loss after processing this batch is:  0.3191501498222351\n",
      "The representation loss after processing this batch is:  0.00389200821518898\n",
      "\n",
      "The classification loss after processing this batch is:  0.3283918499946594\n",
      "The representation loss after processing this batch is:  0.003346998244524002\n",
      "\n",
      "The classification loss after processing this batch is:  0.2033674567937851\n",
      "The representation loss after processing this batch is:  0.003142938017845154\n",
      "\n",
      "The classification loss after processing this batch is:  0.16047480702400208\n",
      "The representation loss after processing this batch is:  0.0032341554760932922\n",
      "\n",
      "The classification loss after processing this batch is:  0.15901361405849457\n",
      "The representation loss after processing this batch is:  0.0031640082597732544\n",
      "\n",
      "The classification loss after processing this batch is:  0.10021490603685379\n",
      "The representation loss after processing this batch is:  0.0030245184898376465\n",
      "\n",
      "The classification loss after processing this batch is:  0.2721279263496399\n",
      "The representation loss after processing this batch is:  0.0030739083886146545\n",
      "\n",
      "The classification loss after processing this batch is:  0.20945340394973755\n",
      "The representation loss after processing this batch is:  0.003092728555202484\n",
      "\n",
      "The classification loss after processing this batch is:  0.17616496980190277\n",
      "The representation loss after processing this batch is:  0.003065064549446106\n",
      "\n",
      "The classification loss after processing this batch is:  0.2892291247844696\n",
      "The representation loss after processing this batch is:  0.0027717426419258118\n",
      "\n",
      "The classification loss after processing this batch is:  0.09678082913160324\n",
      "The representation loss after processing this batch is:  0.0028660260140895844\n",
      "\n",
      "The classification loss after processing this batch is:  0.12062141299247742\n",
      "The representation loss after processing this batch is:  0.003257639706134796\n",
      "\n",
      "The classification loss after processing this batch is:  0.10810636729001999\n",
      "The representation loss after processing this batch is:  0.002514667809009552\n",
      "\n",
      "The classification loss after processing this batch is:  0.2391229271888733\n",
      "The representation loss after processing this batch is:  0.002704169601202011\n",
      "\n",
      "The classification loss after processing this batch is:  0.26296040415763855\n",
      "The representation loss after processing this batch is:  0.002829641103744507\n",
      "\n",
      "The classification loss after processing this batch is:  0.1608600914478302\n",
      "The representation loss after processing this batch is:  0.0026668235659599304\n",
      "\n",
      "The classification loss after processing this batch is:  0.18090181052684784\n",
      "The representation loss after processing this batch is:  0.0027072355151176453\n",
      "\n",
      "The classification loss after processing this batch is:  0.08061052858829498\n",
      "The representation loss after processing this batch is:  0.002642817795276642\n",
      "\n",
      "The classification loss after processing this batch is:  0.122154101729393\n",
      "The representation loss after processing this batch is:  0.002809479832649231\n",
      "\n",
      "The classification loss after processing this batch is:  0.09075264632701874\n",
      "The representation loss after processing this batch is:  0.003040023148059845\n",
      "\n",
      "The classification loss after processing this batch is:  0.08877424150705338\n",
      "The representation loss after processing this batch is:  0.0030086636543273926\n",
      "\n",
      "The classification loss after processing this batch is:  0.14567990601062775\n",
      "The representation loss after processing this batch is:  0.002638578414916992\n",
      "\n",
      "The classification loss after processing this batch is:  0.18201757967472076\n",
      "The representation loss after processing this batch is:  0.0028471723198890686\n",
      "\n",
      "The classification loss after processing this batch is:  0.24037106335163116\n",
      "The representation loss after processing this batch is:  0.0028634443879127502\n",
      "\n",
      "The classification loss after processing this batch is:  0.05609101429581642\n",
      "The representation loss after processing this batch is:  0.002462521195411682\n",
      "\n",
      "The classification loss after processing this batch is:  0.09102634340524673\n",
      "The representation loss after processing this batch is:  0.0029587410390377045\n",
      "\n",
      "The classification loss after processing this batch is:  0.12338494509458542\n",
      "The representation loss after processing this batch is:  0.0032754242420196533\n",
      "\n",
      "The classification loss after processing this batch is:  0.22064755856990814\n",
      "The representation loss after processing this batch is:  0.002762299031019211\n",
      "\n",
      "The classification loss after processing this batch is:  0.10577695071697235\n",
      "The representation loss after processing this batch is:  0.0030794739723205566\n",
      "\n",
      "The classification loss after processing this batch is:  0.28972327709198\n",
      "The representation loss after processing this batch is:  0.002962835133075714\n",
      "\n",
      "The classification loss after processing this batch is:  0.29147544503211975\n",
      "The representation loss after processing this batch is:  0.003014393150806427\n",
      "\n",
      "The classification loss after processing this batch is:  0.2433747798204422\n",
      "The representation loss after processing this batch is:  0.0030793435871601105\n",
      "\n",
      "The classification loss after processing this batch is:  0.17367736995220184\n",
      "The representation loss after processing this batch is:  0.0030167512595653534\n",
      "\n",
      "The classification loss after processing this batch is:  0.09570945054292679\n",
      "The representation loss after processing this batch is:  0.0031060054898262024\n",
      "\n",
      "The classification loss after processing this batch is:  0.1829579621553421\n",
      "The representation loss after processing this batch is:  0.0027688369154930115\n",
      "\n",
      "The classification loss after processing this batch is:  0.1677367240190506\n",
      "The representation loss after processing this batch is:  0.002941116690635681\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10071178525686264\n",
      "The representation loss after processing this batch is:  0.0028281882405281067\n",
      "\n",
      "The classification loss after processing this batch is:  0.07158636301755905\n",
      "The representation loss after processing this batch is:  0.002840481698513031\n",
      "\n",
      "The classification loss after processing this batch is:  0.22111953794956207\n",
      "The representation loss after processing this batch is:  0.002832546830177307\n",
      "\n",
      "The classification loss after processing this batch is:  0.242617666721344\n",
      "The representation loss after processing this batch is:  0.0026419535279273987\n",
      "\n",
      "The classification loss after processing this batch is:  0.1530599594116211\n",
      "The representation loss after processing this batch is:  0.0031074099242687225\n",
      "\n",
      "The classification loss after processing this batch is:  0.2730456590652466\n",
      "The representation loss after processing this batch is:  0.00284595787525177\n",
      "\n",
      "The classification loss after processing this batch is:  0.28894680738449097\n",
      "The representation loss after processing this batch is:  0.0029234737157821655\n",
      "\n",
      "The classification loss after processing this batch is:  0.4147823750972748\n",
      "The representation loss after processing this batch is:  0.002552282065153122\n",
      "\n",
      "The classification loss after processing this batch is:  0.23264077305793762\n",
      "The representation loss after processing this batch is:  0.002831973135471344\n",
      "\n",
      "The classification loss after processing this batch is:  0.1523783653974533\n",
      "The representation loss after processing this batch is:  0.0030896812677383423\n",
      "\n",
      "The classification loss after processing this batch is:  0.22330617904663086\n",
      "The representation loss after processing this batch is:  0.0028569623827934265\n",
      "\n",
      "The classification loss after processing this batch is:  0.14826247096061707\n",
      "The representation loss after processing this batch is:  0.0030353963375091553\n",
      "\n",
      "The classification loss after processing this batch is:  0.11354248225688934\n",
      "The representation loss after processing this batch is:  0.003063555806875229\n",
      "\n",
      "The classification loss after processing this batch is:  0.11993838101625443\n",
      "The representation loss after processing this batch is:  0.002544727176427841\n",
      "\n",
      "The classification loss after processing this batch is:  0.11056353151798248\n",
      "The representation loss after processing this batch is:  0.0029812604188919067\n",
      "\n",
      "The classification loss after processing this batch is:  0.07019786536693573\n",
      "The representation loss after processing this batch is:  0.003282018005847931\n",
      "\n",
      "The classification loss after processing this batch is:  0.1596500724554062\n",
      "The representation loss after processing this batch is:  0.0028738118708133698\n",
      "\n",
      "The classification loss after processing this batch is:  0.2068067491054535\n",
      "The representation loss after processing this batch is:  0.002703361213207245\n",
      "\n",
      "The classification loss after processing this batch is:  0.11702574789524078\n",
      "The representation loss after processing this batch is:  0.0030113235116004944\n",
      "\n",
      "The classification loss after processing this batch is:  0.12159625440835953\n",
      "The representation loss after processing this batch is:  0.002606775611639023\n",
      "\n",
      "The classification loss after processing this batch is:  0.19176633656024933\n",
      "The representation loss after processing this batch is:  0.002931937575340271\n",
      "\n",
      "The classification loss after processing this batch is:  0.07695368677377701\n",
      "The representation loss after processing this batch is:  0.0028146281838417053\n",
      "\n",
      "The classification loss after processing this batch is:  0.23069898784160614\n",
      "The representation loss after processing this batch is:  0.002988159656524658\n",
      "\n",
      "The classification loss after processing this batch is:  0.14263662695884705\n",
      "The representation loss after processing this batch is:  0.0026308000087738037\n",
      "\n",
      "The classification loss after processing this batch is:  0.2866355776786804\n",
      "The representation loss after processing this batch is:  0.0026999488472938538\n",
      "\n",
      "The classification loss after processing this batch is:  0.22726628184318542\n",
      "The representation loss after processing this batch is:  0.0028586313128471375\n",
      "\n",
      "The classification loss after processing this batch is:  0.232089564204216\n",
      "The representation loss after processing this batch is:  0.002596307545900345\n",
      "\n",
      "The classification loss after processing this batch is:  0.06249489635229111\n",
      "The representation loss after processing this batch is:  0.002749107778072357\n",
      "\n",
      "The classification loss after processing this batch is:  0.07415031641721725\n",
      "The representation loss after processing this batch is:  0.00287078320980072\n",
      "\n",
      "The classification loss after processing this batch is:  0.17739686369895935\n",
      "The representation loss after processing this batch is:  0.0030779652297496796\n",
      "\n",
      "The classification loss after processing this batch is:  0.07448729872703552\n",
      "The representation loss after processing this batch is:  0.003173127770423889\n",
      "\n",
      "The classification loss after processing this batch is:  0.20242561399936676\n",
      "The representation loss after processing this batch is:  0.0029911696910858154\n",
      "\n",
      "The classification loss after processing this batch is:  0.11974479258060455\n",
      "The representation loss after processing this batch is:  0.0030523762106895447\n",
      "\n",
      "The classification loss after processing this batch is:  0.1392461359500885\n",
      "The representation loss after processing this batch is:  0.0030608326196670532\n",
      "\n",
      "The classification loss after processing this batch is:  0.19022274017333984\n",
      "The representation loss after processing this batch is:  0.002932727336883545\n",
      "\n",
      "The classification loss after processing this batch is:  0.1124902069568634\n",
      "The representation loss after processing this batch is:  0.0030745193362236023\n",
      "\n",
      "The classification loss after processing this batch is:  0.1381242424249649\n",
      "The representation loss after processing this batch is:  0.00342356413602829\n",
      "\n",
      "The classification loss after processing this batch is:  0.23179510235786438\n",
      "The representation loss after processing this batch is:  0.0028784945607185364\n",
      "\n",
      "The classification loss after processing this batch is:  0.1831255406141281\n",
      "The representation loss after processing this batch is:  0.003054678440093994\n",
      "\n",
      "The classification loss after processing this batch is:  0.2624469995498657\n",
      "The representation loss after processing this batch is:  0.0030008330941200256\n",
      "\n",
      "The classification loss after processing this batch is:  0.29531368613243103\n",
      "The representation loss after processing this batch is:  0.003242477774620056\n",
      "\n",
      "The classification loss after processing this batch is:  0.2033088058233261\n",
      "The representation loss after processing this batch is:  0.002568945288658142\n",
      "\n",
      "The classification loss after processing this batch is:  0.12150830775499344\n",
      "The representation loss after processing this batch is:  0.0027722008526325226\n",
      "\n",
      "The classification loss after processing this batch is:  0.09515972435474396\n",
      "The representation loss after processing this batch is:  0.0026444047689437866\n",
      "\n",
      "The classification loss after processing this batch is:  0.12240056693553925\n",
      "The representation loss after processing this batch is:  0.0028412416577339172\n",
      "\n",
      "The classification loss after processing this batch is:  0.0960036963224411\n",
      "The representation loss after processing this batch is:  0.003076896071434021\n",
      "\n",
      "The classification loss after processing this batch is:  0.18446485698223114\n",
      "The representation loss after processing this batch is:  0.002469513565301895\n",
      "\n",
      "The classification loss after processing this batch is:  0.1421547532081604\n",
      "The representation loss after processing this batch is:  0.0029635056853294373\n",
      "\n",
      "The classification loss after processing this batch is:  0.17230413854122162\n",
      "The representation loss after processing this batch is:  0.003009885549545288\n",
      "\n",
      "The classification loss after processing this batch is:  0.10115554183721542\n",
      "The representation loss after processing this batch is:  0.0026721209287643433\n",
      "\n",
      "The classification loss after processing this batch is:  0.20231905579566956\n",
      "The representation loss after processing this batch is:  0.0026640556752681732\n",
      "\n",
      "The classification loss after processing this batch is:  0.11392829567193985\n",
      "The representation loss after processing this batch is:  0.003046773374080658\n",
      "\n",
      "The classification loss after processing this batch is:  0.1975886970758438\n",
      "The representation loss after processing this batch is:  0.00267694890499115\n",
      "\n",
      "The classification loss after processing this batch is:  0.1803101897239685\n",
      "The representation loss after processing this batch is:  0.0028825178742408752\n",
      "\n",
      "The classification loss after processing this batch is:  0.1531480997800827\n",
      "The representation loss after processing this batch is:  0.0028725415468215942\n",
      "\n",
      "The classification loss after processing this batch is:  0.1397193968296051\n",
      "The representation loss after processing this batch is:  0.00295904278755188\n",
      "\n",
      "The classification loss after processing this batch is:  0.2153194546699524\n",
      "The representation loss after processing this batch is:  0.0031062737107276917\n",
      "\n",
      "The classification loss after processing this batch is:  0.11250036209821701\n",
      "The representation loss after processing this batch is:  0.0030037537217140198\n",
      "\n",
      "The classification loss after processing this batch is:  0.09230409562587738\n",
      "The representation loss after processing this batch is:  0.002947390079498291\n",
      "\n",
      "The classification loss after processing this batch is:  0.11882997304201126\n",
      "The representation loss after processing this batch is:  0.0030246861279010773\n",
      "\n",
      "The classification loss after processing this batch is:  0.11569170653820038\n",
      "The representation loss after processing this batch is:  0.0030334852635860443\n",
      "\n",
      "The classification loss after processing this batch is:  0.2240019589662552\n",
      "The representation loss after processing this batch is:  0.002455834299325943\n",
      "\n",
      "The classification loss after processing this batch is:  0.2031913697719574\n",
      "The representation loss after processing this batch is:  0.003191553056240082\n",
      "\n",
      "The classification loss after processing this batch is:  0.1715407818555832\n",
      "The representation loss after processing this batch is:  0.003193996846675873\n",
      "\n",
      "The classification loss after processing this batch is:  0.10986939817667007\n",
      "The representation loss after processing this batch is:  0.0030006468296051025\n",
      "\n",
      "The classification loss after processing this batch is:  0.10557512938976288\n",
      "The representation loss after processing this batch is:  0.0027956292033195496\n",
      "\n",
      "The classification loss after processing this batch is:  0.2730342745780945\n",
      "The representation loss after processing this batch is:  0.003173183649778366\n",
      "\n",
      "The classification loss after processing this batch is:  0.08107524365186691\n",
      "The representation loss after processing this batch is:  0.0030666887760162354\n",
      "\n",
      "The classification loss after processing this batch is:  0.14172939956188202\n",
      "The representation loss after processing this batch is:  0.0031996071338653564\n",
      "\n",
      "The classification loss after processing this batch is:  0.20004361867904663\n",
      "The representation loss after processing this batch is:  0.002578333020210266\n",
      "\n",
      "The classification loss after processing this batch is:  0.3366601765155792\n",
      "The representation loss after processing this batch is:  0.0030040517449378967\n",
      "\n",
      "The classification loss after processing this batch is:  0.11779181659221649\n",
      "The representation loss after processing this batch is:  0.0029827281832695007\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.16294756531715393\n",
      "The representation loss after processing this batch is:  0.0024992190301418304\n",
      "\n",
      "The classification loss after processing this batch is:  0.09015101939439774\n",
      "The representation loss after processing this batch is:  0.0029824823141098022\n",
      "\n",
      "The classification loss after processing this batch is:  0.06946033984422684\n",
      "The representation loss after processing this batch is:  0.002746090292930603\n",
      "\n",
      "The classification loss after processing this batch is:  0.16432644426822662\n",
      "The representation loss after processing this batch is:  0.003488674759864807\n",
      "\n",
      "The classification loss after processing this batch is:  0.13711626827716827\n",
      "The representation loss after processing this batch is:  0.003637559711933136\n",
      "\n",
      "The classification loss after processing this batch is:  0.08784699440002441\n",
      "The representation loss after processing this batch is:  0.0030104145407676697\n",
      "\n",
      "The classification loss after processing this batch is:  0.10895151644945145\n",
      "The representation loss after processing this batch is:  0.002717122435569763\n",
      "\n",
      "The classification loss after processing this batch is:  0.2101500779390335\n",
      "The representation loss after processing this batch is:  0.0024520084261894226\n",
      "\n",
      "The classification loss after processing this batch is:  0.18127281963825226\n",
      "The representation loss after processing this batch is:  0.0027367882430553436\n",
      "\n",
      "The classification loss after processing this batch is:  0.11228158324956894\n",
      "The representation loss after processing this batch is:  0.002381622791290283\n",
      "\n",
      "The classification loss after processing this batch is:  0.15513046085834503\n",
      "The representation loss after processing this batch is:  0.002707555890083313\n",
      "\n",
      "The classification loss after processing this batch is:  0.2658420503139496\n",
      "The representation loss after processing this batch is:  0.0024712756276130676\n",
      "\n",
      "The classification loss after processing this batch is:  0.2609637975692749\n",
      "The representation loss after processing this batch is:  0.0029685422778129578\n",
      "\n",
      "The classification loss after processing this batch is:  0.22364400327205658\n",
      "The representation loss after processing this batch is:  0.002453222870826721\n",
      "\n",
      "The classification loss after processing this batch is:  0.20927093923091888\n",
      "The representation loss after processing this batch is:  0.003199473023414612\n",
      "\n",
      "The classification loss after processing this batch is:  0.2559097409248352\n",
      "The representation loss after processing this batch is:  0.002792537212371826\n",
      "\n",
      "The classification loss after processing this batch is:  0.13008089363574982\n",
      "The representation loss after processing this batch is:  0.0034614428877830505\n",
      "\n",
      "The classification loss after processing this batch is:  0.12094052135944366\n",
      "The representation loss after processing this batch is:  0.0031416788697242737\n",
      "\n",
      "The classification loss after processing this batch is:  0.09390537440776825\n",
      "The representation loss after processing this batch is:  0.002882733941078186\n",
      "\n",
      "The classification loss after processing this batch is:  0.12415504455566406\n",
      "The representation loss after processing this batch is:  0.0024793222546577454\n",
      "\n",
      "The classification loss after processing this batch is:  0.2371601015329361\n",
      "The representation loss after processing this batch is:  0.0027711093425750732\n",
      "\n",
      "The classification loss after processing this batch is:  0.1331813782453537\n",
      "The representation loss after processing this batch is:  0.0033309534192085266\n",
      "\n",
      "The classification loss after processing this batch is:  0.08044557273387909\n",
      "The representation loss after processing this batch is:  0.0028794407844543457\n",
      "\n",
      "The classification loss after processing this batch is:  0.05765731632709503\n",
      "The representation loss after processing this batch is:  0.003323398530483246\n",
      "\n",
      "The classification loss after processing this batch is:  0.0815695971250534\n",
      "The representation loss after processing this batch is:  0.0032039210200309753\n",
      "\n",
      "The classification loss after processing this batch is:  0.11578813195228577\n",
      "The representation loss after processing this batch is:  0.0035404637455940247\n",
      "\n",
      "The classification loss after processing this batch is:  0.13160328567028046\n",
      "The representation loss after processing this batch is:  0.003081865608692169\n",
      "\n",
      "The classification loss after processing this batch is:  0.09478171914815903\n",
      "The representation loss after processing this batch is:  0.002803303301334381\n",
      "\n",
      "The classification loss after processing this batch is:  0.05260217562317848\n",
      "The representation loss after processing this batch is:  0.0033238306641578674\n",
      "\n",
      "The classification loss after processing this batch is:  0.07852905243635178\n",
      "The representation loss after processing this batch is:  0.0037523582577705383\n",
      "\n",
      "The classification loss after processing this batch is:  0.10680171847343445\n",
      "The representation loss after processing this batch is:  0.003973968327045441\n",
      "\n",
      "The classification loss after processing this batch is:  0.03922821208834648\n",
      "The representation loss after processing this batch is:  0.004152059555053711\n",
      "\n",
      "The classification loss after processing this batch is:  0.07943235337734222\n",
      "The representation loss after processing this batch is:  0.0032727718353271484\n",
      "\n",
      "The classification loss after processing this batch is:  0.20387154817581177\n",
      "The representation loss after processing this batch is:  0.0033134520053863525\n",
      "\n",
      "The classification loss after processing this batch is:  0.06276313215494156\n",
      "The representation loss after processing this batch is:  0.0036967918276786804\n",
      "\n",
      "The classification loss after processing this batch is:  0.028225572779774666\n",
      "The representation loss after processing this batch is:  0.0034580081701278687\n",
      "\n",
      "The classification loss after processing this batch is:  0.05044945329427719\n",
      "The representation loss after processing this batch is:  0.003223232924938202\n",
      "\n",
      "The classification loss after processing this batch is:  0.0752800777554512\n",
      "The representation loss after processing this batch is:  0.003175199031829834\n",
      "\n",
      "The classification loss after processing this batch is:  0.055404651910066605\n",
      "The representation loss after processing this batch is:  0.003322012722492218\n",
      "\n",
      "The classification loss after processing this batch is:  0.058571841567754745\n",
      "The representation loss after processing this batch is:  0.0035191327333450317\n",
      "\n",
      "The classification loss after processing this batch is:  0.05397585406899452\n",
      "The representation loss after processing this batch is:  0.003686666488647461\n",
      "\n",
      "The classification loss after processing this batch is:  0.29532527923583984\n",
      "The representation loss after processing this batch is:  0.003795921802520752\n",
      "\n",
      "The classification loss after processing this batch is:  0.31556758284568787\n",
      "The representation loss after processing this batch is:  0.004043743014335632\n",
      "\n",
      "The classification loss after processing this batch is:  0.2509562373161316\n",
      "The representation loss after processing this batch is:  0.004020243883132935\n",
      "\n",
      "The classification loss after processing this batch is:  0.08328957110643387\n",
      "The representation loss after processing this batch is:  0.0029460862278938293\n",
      "\n",
      "The classification loss after processing this batch is:  0.04579468443989754\n",
      "The representation loss after processing this batch is:  0.0034018009901046753\n",
      "\n",
      "The classification loss after processing this batch is:  0.05490906164050102\n",
      "The representation loss after processing this batch is:  0.00268351286649704\n",
      "\n",
      "The classification loss after processing this batch is:  0.1383925974369049\n",
      "The representation loss after processing this batch is:  0.002363823354244232\n",
      "\n",
      "The classification loss after processing this batch is:  0.38831081986427307\n",
      "The representation loss after processing this batch is:  0.003243573009967804\n",
      "\n",
      "The classification loss after processing this batch is:  0.10369633138179779\n",
      "The representation loss after processing this batch is:  0.002806730568408966\n",
      "\n",
      "The classification loss after processing this batch is:  0.07239922136068344\n",
      "The representation loss after processing this batch is:  0.003476075828075409\n",
      "\n",
      "The classification loss after processing this batch is:  0.11127913743257523\n",
      "The representation loss after processing this batch is:  0.0030750706791877747\n",
      "\n",
      "The classification loss after processing this batch is:  0.07528948783874512\n",
      "The representation loss after processing this batch is:  0.003908611834049225\n",
      "\n",
      "The classification loss after processing this batch is:  0.1374076008796692\n",
      "The representation loss after processing this batch is:  0.002763018012046814\n",
      "\n",
      "The classification loss after processing this batch is:  0.08045851439237595\n",
      "The representation loss after processing this batch is:  0.002734273672103882\n",
      "\n",
      "The classification loss after processing this batch is:  0.11675409227609634\n",
      "The representation loss after processing this batch is:  0.002617478370666504\n",
      "\n",
      "The classification loss after processing this batch is:  0.13056351244449615\n",
      "The representation loss after processing this batch is:  0.0027311518788337708\n",
      "\n",
      "The classification loss after processing this batch is:  0.16096769273281097\n",
      "The representation loss after processing this batch is:  0.002837926149368286\n",
      "\n",
      "The classification loss after processing this batch is:  0.09394396096467972\n",
      "The representation loss after processing this batch is:  0.0033345073461532593\n",
      "\n",
      "The classification loss after processing this batch is:  0.12633201479911804\n",
      "The representation loss after processing this batch is:  0.003348827362060547\n",
      "\n",
      "The classification loss after processing this batch is:  0.11572767794132233\n",
      "The representation loss after processing this batch is:  0.0026742666959762573\n",
      "\n",
      "The classification loss after processing this batch is:  0.1747012436389923\n",
      "The representation loss after processing this batch is:  0.002619568258523941\n",
      "\n",
      "The classification loss after processing this batch is:  0.13003964722156525\n",
      "The representation loss after processing this batch is:  0.0027507059276103973\n",
      "\n",
      "The classification loss after processing this batch is:  0.2027183175086975\n",
      "The representation loss after processing this batch is:  0.0026641637086868286\n",
      "\n",
      "The classification loss after processing this batch is:  0.18339072167873383\n",
      "The representation loss after processing this batch is:  0.0028497278690338135\n",
      "\n",
      "The classification loss after processing this batch is:  0.22431373596191406\n",
      "The representation loss after processing this batch is:  0.0035238899290561676\n",
      "\n",
      "The classification loss after processing this batch is:  0.09077392518520355\n",
      "The representation loss after processing this batch is:  0.0029005706310272217\n",
      "\n",
      "The classification loss after processing this batch is:  0.3479495346546173\n",
      "The representation loss after processing this batch is:  0.0027206428349018097\n",
      "\n",
      "The classification loss after processing this batch is:  0.16992351412773132\n",
      "The representation loss after processing this batch is:  0.002402018755674362\n",
      "\n",
      "The classification loss after processing this batch is:  0.1507757157087326\n",
      "The representation loss after processing this batch is:  0.0026931948959827423\n",
      "\n",
      "The classification loss after processing this batch is:  0.25668925046920776\n",
      "The representation loss after processing this batch is:  0.003095082938671112\n",
      "\n",
      "The classification loss after processing this batch is:  0.22553476691246033\n",
      "The representation loss after processing this batch is:  0.0031303688883781433\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08580590784549713\n",
      "The representation loss after processing this batch is:  0.0028788968920707703\n",
      "\n",
      "The classification loss after processing this batch is:  0.2560877203941345\n",
      "The representation loss after processing this batch is:  0.003467053174972534\n",
      "\n",
      "The classification loss after processing this batch is:  0.18200190365314484\n",
      "The representation loss after processing this batch is:  0.002975042909383774\n",
      "\n",
      "The classification loss after processing this batch is:  0.3205004930496216\n",
      "The representation loss after processing this batch is:  0.0026719197630882263\n",
      "\n",
      "The classification loss after processing this batch is:  0.11980835348367691\n",
      "The representation loss after processing this batch is:  0.0025552622973918915\n",
      "\n",
      "The classification loss after processing this batch is:  0.09408973902463913\n",
      "The representation loss after processing this batch is:  0.0028565898537635803\n",
      "\n",
      "The classification loss after processing this batch is:  0.11662093549966812\n",
      "The representation loss after processing this batch is:  0.0026760175824165344\n",
      "\n",
      "The classification loss after processing this batch is:  0.12944957613945007\n",
      "The representation loss after processing this batch is:  0.002218525856733322\n",
      "\n",
      "The classification loss after processing this batch is:  0.14583644270896912\n",
      "The representation loss after processing this batch is:  0.002909984439611435\n",
      "\n",
      "The classification loss after processing this batch is:  0.07158037275075912\n",
      "The representation loss after processing this batch is:  0.0028171762824058533\n",
      "\n",
      "The classification loss after processing this batch is:  0.06700123101472855\n",
      "The representation loss after processing this batch is:  0.0028165802359580994\n",
      "\n",
      "The classification loss after processing this batch is:  0.11519559472799301\n",
      "The representation loss after processing this batch is:  0.002762790769338608\n",
      "\n",
      "The classification loss after processing this batch is:  0.1101381778717041\n",
      "The representation loss after processing this batch is:  0.0032466240227222443\n",
      "\n",
      "The classification loss after processing this batch is:  0.1760769635438919\n",
      "The representation loss after processing this batch is:  0.0028555728495121002\n",
      "\n",
      "The classification loss after processing this batch is:  0.1259288340806961\n",
      "The representation loss after processing this batch is:  0.003445390611886978\n",
      "\n",
      "The classification loss after processing this batch is:  0.1203271821141243\n",
      "The representation loss after processing this batch is:  0.0026236288249492645\n",
      "\n",
      "The classification loss after processing this batch is:  0.0657205730676651\n",
      "The representation loss after processing this batch is:  0.002850867807865143\n",
      "\n",
      "The classification loss after processing this batch is:  0.09171245247125626\n",
      "The representation loss after processing this batch is:  0.003221660852432251\n",
      "\n",
      "The classification loss after processing this batch is:  0.12217331677675247\n",
      "The representation loss after processing this batch is:  0.00266912579536438\n",
      "\n",
      "The classification loss after processing this batch is:  0.09412228316068649\n",
      "The representation loss after processing this batch is:  0.0030800998210906982\n",
      "\n",
      "The classification loss after processing this batch is:  0.11733879894018173\n",
      "The representation loss after processing this batch is:  0.002826504409313202\n",
      "\n",
      "The classification loss after processing this batch is:  0.24944324791431427\n",
      "The representation loss after processing this batch is:  0.003275923430919647\n",
      "\n",
      "The classification loss after processing this batch is:  0.13144508004188538\n",
      "The representation loss after processing this batch is:  0.0027451664209365845\n",
      "\n",
      "The classification loss after processing this batch is:  0.1268206685781479\n",
      "The representation loss after processing this batch is:  0.0027367547154426575\n",
      "\n",
      "The classification loss after processing this batch is:  0.14984019100666046\n",
      "The representation loss after processing this batch is:  0.0027874186635017395\n",
      "\n",
      "The classification loss after processing this batch is:  0.10080181807279587\n",
      "The representation loss after processing this batch is:  0.002645399421453476\n",
      "\n",
      "The classification loss after processing this batch is:  0.11169135570526123\n",
      "The representation loss after processing this batch is:  0.0025610439479351044\n",
      "\n",
      "The classification loss after processing this batch is:  0.24045635759830475\n",
      "The representation loss after processing this batch is:  0.003155190497636795\n",
      "\n",
      "The classification loss after processing this batch is:  0.07473842799663544\n",
      "The representation loss after processing this batch is:  0.002936527132987976\n",
      "\n",
      "The classification loss after processing this batch is:  0.15179449319839478\n",
      "The representation loss after processing this batch is:  0.0025887563824653625\n",
      "\n",
      "The classification loss after processing this batch is:  0.11395802348852158\n",
      "The representation loss after processing this batch is:  0.003148544579744339\n",
      "\n",
      "The classification loss after processing this batch is:  0.13867023587226868\n",
      "The representation loss after processing this batch is:  0.0024412348866462708\n",
      "\n",
      "The classification loss after processing this batch is:  0.15632161498069763\n",
      "The representation loss after processing this batch is:  0.0025495141744613647\n",
      "\n",
      "The classification loss after processing this batch is:  0.10028944909572601\n",
      "The representation loss after processing this batch is:  0.0029071345925331116\n",
      "\n",
      "The classification loss after processing this batch is:  0.14310312271118164\n",
      "The representation loss after processing this batch is:  0.0030836015939712524\n",
      "\n",
      "The classification loss after processing this batch is:  0.16131280362606049\n",
      "The representation loss after processing this batch is:  0.0029309019446372986\n",
      "\n",
      "The classification loss after processing this batch is:  0.1645527482032776\n",
      "The representation loss after processing this batch is:  0.0028183013200759888\n",
      "\n",
      "The classification loss after processing this batch is:  0.16698764264583588\n",
      "The representation loss after processing this batch is:  0.0025222748517990112\n",
      "\n",
      "The classification loss after processing this batch is:  0.136764258146286\n",
      "The representation loss after processing this batch is:  0.003030940890312195\n",
      "\n",
      "The classification loss after processing this batch is:  0.15915827453136444\n",
      "The representation loss after processing this batch is:  0.002794802188873291\n",
      "\n",
      "The classification loss after processing this batch is:  0.10272547602653503\n",
      "The representation loss after processing this batch is:  0.002638190984725952\n",
      "\n",
      "The classification loss after processing this batch is:  0.09516461938619614\n",
      "The representation loss after processing this batch is:  0.0024059563875198364\n",
      "\n",
      "The classification loss after processing this batch is:  0.20745159685611725\n",
      "The representation loss after processing this batch is:  0.002710726112127304\n",
      "\n",
      "The classification loss after processing this batch is:  0.1926080286502838\n",
      "The representation loss after processing this batch is:  0.0027652010321617126\n",
      "\n",
      "The classification loss after processing this batch is:  0.10758688300848007\n",
      "The representation loss after processing this batch is:  0.002579815685749054\n",
      "\n",
      "The classification loss after processing this batch is:  0.10166428238153458\n",
      "The representation loss after processing this batch is:  0.00255594402551651\n",
      "\n",
      "The classification loss after processing this batch is:  0.11264603585004807\n",
      "The representation loss after processing this batch is:  0.0026194341480731964\n",
      "\n",
      "The classification loss after processing this batch is:  0.1437457650899887\n",
      "The representation loss after processing this batch is:  0.00263909250497818\n",
      "\n",
      "The classification loss after processing this batch is:  0.1829366832971573\n",
      "The representation loss after processing this batch is:  0.002604331821203232\n",
      "\n",
      "The classification loss after processing this batch is:  0.0873185470700264\n",
      "The representation loss after processing this batch is:  0.0026124194264411926\n",
      "\n",
      "The classification loss after processing this batch is:  0.2641697824001312\n",
      "The representation loss after processing this batch is:  0.002794947475194931\n",
      "\n",
      "The classification loss after processing this batch is:  0.1812923401594162\n",
      "The representation loss after processing this batch is:  0.0026552192866802216\n",
      "\n",
      "The classification loss after processing this batch is:  0.15199324488639832\n",
      "The representation loss after processing this batch is:  0.0026992522180080414\n",
      "\n",
      "The classification loss after processing this batch is:  0.1179574579000473\n",
      "The representation loss after processing this batch is:  0.002314295619726181\n",
      "\n",
      "The classification loss after processing this batch is:  0.10206864774227142\n",
      "The representation loss after processing this batch is:  0.0028029903769493103\n",
      "\n",
      "The classification loss after processing this batch is:  0.1285988986492157\n",
      "The representation loss after processing this batch is:  0.0024633631110191345\n",
      "\n",
      "The classification loss after processing this batch is:  0.20664635300636292\n",
      "The representation loss after processing this batch is:  0.00256405770778656\n",
      "\n",
      "The classification loss after processing this batch is:  0.11601810902357101\n",
      "The representation loss after processing this batch is:  0.0024782605469226837\n",
      "\n",
      "The classification loss after processing this batch is:  0.3135688602924347\n",
      "The representation loss after processing this batch is:  0.002491489052772522\n",
      "\n",
      "The classification loss after processing this batch is:  0.14222285151481628\n",
      "The representation loss after processing this batch is:  0.0024393871426582336\n",
      "\n",
      "The classification loss after processing this batch is:  0.09925013035535812\n",
      "The representation loss after processing this batch is:  0.003349699079990387\n",
      "\n",
      "The classification loss after processing this batch is:  0.1921849250793457\n",
      "The representation loss after processing this batch is:  0.002866603434085846\n",
      "\n",
      "The classification loss after processing this batch is:  0.09784002602100372\n",
      "The representation loss after processing this batch is:  0.003025621175765991\n",
      "\n",
      "The classification loss after processing this batch is:  0.3053951561450958\n",
      "The representation loss after processing this batch is:  0.00290747731924057\n",
      "\n",
      "The classification loss after processing this batch is:  0.14595122635364532\n",
      "The representation loss after processing this batch is:  0.002680271863937378\n",
      "\n",
      "The classification loss after processing this batch is:  0.18922945857048035\n",
      "The representation loss after processing this batch is:  0.0026219524443149567\n",
      "\n",
      "The classification loss after processing this batch is:  0.32662060856819153\n",
      "The representation loss after processing this batch is:  0.0027659647166728973\n",
      "\n",
      "The classification loss after processing this batch is:  0.19593864679336548\n",
      "The representation loss after processing this batch is:  0.0025014728307724\n",
      "\n",
      "The classification loss after processing this batch is:  0.09614743292331696\n",
      "The representation loss after processing this batch is:  0.00266227126121521\n",
      "\n",
      "The classification loss after processing this batch is:  0.20818538963794708\n",
      "The representation loss after processing this batch is:  0.0025061778724193573\n",
      "\n",
      "The classification loss after processing this batch is:  0.1873989701271057\n",
      "The representation loss after processing this batch is:  0.0026984214782714844\n",
      "\n",
      "The classification loss after processing this batch is:  0.1571761518716812\n",
      "The representation loss after processing this batch is:  0.0028456561267375946\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10387597978115082\n",
      "The representation loss after processing this batch is:  0.0025678128004074097\n",
      "\n",
      "The classification loss after processing this batch is:  0.12813805043697357\n",
      "The representation loss after processing this batch is:  0.00247153639793396\n",
      "\n",
      "The classification loss after processing this batch is:  0.18796738982200623\n",
      "The representation loss after processing this batch is:  0.0026293769478797913\n",
      "\n",
      "The classification loss after processing this batch is:  0.16672039031982422\n",
      "The representation loss after processing this batch is:  0.0031579509377479553\n",
      "\n",
      "The classification loss after processing this batch is:  0.2247466742992401\n",
      "The representation loss after processing this batch is:  0.002814117819070816\n",
      "\n",
      "The classification loss after processing this batch is:  0.2692706882953644\n",
      "The representation loss after processing this batch is:  0.002915196120738983\n",
      "\n",
      "The classification loss after processing this batch is:  0.22257791459560394\n",
      "The representation loss after processing this batch is:  0.003110744059085846\n",
      "\n",
      "The classification loss after processing this batch is:  0.11155173927545547\n",
      "The representation loss after processing this batch is:  0.0032194480299949646\n",
      "\n",
      "The classification loss after processing this batch is:  0.12387578934431076\n",
      "The representation loss after processing this batch is:  0.0025648102164268494\n",
      "\n",
      "The classification loss after processing this batch is:  0.07453559339046478\n",
      "The representation loss after processing this batch is:  0.002723235636949539\n",
      "\n",
      "The classification loss after processing this batch is:  0.16692018508911133\n",
      "The representation loss after processing this batch is:  0.003076404333114624\n",
      "\n",
      "The classification loss after processing this batch is:  0.1223631277680397\n",
      "The representation loss after processing this batch is:  0.002801664173603058\n",
      "\n",
      "The classification loss after processing this batch is:  0.2918449342250824\n",
      "The representation loss after processing this batch is:  0.0026494264602661133\n",
      "\n",
      "The classification loss after processing this batch is:  0.3033502697944641\n",
      "The representation loss after processing this batch is:  0.0027060583233833313\n",
      "\n",
      "The classification loss after processing this batch is:  0.14106138050556183\n",
      "The representation loss after processing this batch is:  0.0031374096870422363\n",
      "\n",
      "The classification loss after processing this batch is:  0.15418976545333862\n",
      "The representation loss after processing this batch is:  0.0029819458723068237\n",
      "\n",
      "The classification loss after processing this batch is:  0.18482939898967743\n",
      "The representation loss after processing this batch is:  0.0025746189057826996\n",
      "\n",
      "The classification loss after processing this batch is:  0.08625971525907516\n",
      "The representation loss after processing this batch is:  0.00299091637134552\n",
      "\n",
      "The classification loss after processing this batch is:  0.08813372999429703\n",
      "The representation loss after processing this batch is:  0.0028221160173416138\n",
      "\n",
      "The classification loss after processing this batch is:  0.16025860607624054\n",
      "The representation loss after processing this batch is:  0.0025055259466171265\n",
      "\n",
      "The classification loss after processing this batch is:  0.1331152468919754\n",
      "The representation loss after processing this batch is:  0.003674611449241638\n",
      "\n",
      "The classification loss after processing this batch is:  0.1157536506652832\n",
      "The representation loss after processing this batch is:  0.0028665363788604736\n",
      "\n",
      "The classification loss after processing this batch is:  0.2874939739704132\n",
      "The representation loss after processing this batch is:  0.0038921386003494263\n",
      "\n",
      "The classification loss after processing this batch is:  0.25615403056144714\n",
      "The representation loss after processing this batch is:  0.0026331469416618347\n",
      "\n",
      "The classification loss after processing this batch is:  0.1741795837879181\n",
      "The representation loss after processing this batch is:  0.00302799791097641\n",
      "\n",
      "The classification loss after processing this batch is:  0.24632081389427185\n",
      "The representation loss after processing this batch is:  0.0028498470783233643\n",
      "\n",
      "The classification loss after processing this batch is:  0.20371170341968536\n",
      "The representation loss after processing this batch is:  0.0026741474866867065\n",
      "\n",
      "The classification loss after processing this batch is:  0.09933895617723465\n",
      "The representation loss after processing this batch is:  0.0028872862458229065\n",
      "\n",
      "The classification loss after processing this batch is:  0.1777297705411911\n",
      "The representation loss after processing this batch is:  0.0027089975774288177\n",
      "\n",
      "The classification loss after processing this batch is:  0.4007264971733093\n",
      "The representation loss after processing this batch is:  0.0031964853405952454\n",
      "\n",
      "The classification loss after processing this batch is:  0.20056501030921936\n",
      "The representation loss after processing this batch is:  0.0031129419803619385\n",
      "\n",
      "The classification loss after processing this batch is:  0.10265270620584488\n",
      "The representation loss after processing this batch is:  0.0033195503056049347\n",
      "\n",
      "The classification loss after processing this batch is:  0.1156122013926506\n",
      "The representation loss after processing this batch is:  0.0032242536544799805\n",
      "\n",
      "The classification loss after processing this batch is:  0.0909610465168953\n",
      "The representation loss after processing this batch is:  0.003331683576107025\n",
      "\n",
      "The classification loss after processing this batch is:  0.13299116492271423\n",
      "The representation loss after processing this batch is:  0.0030894726514816284\n",
      "\n",
      "The classification loss after processing this batch is:  0.09293235093355179\n",
      "The representation loss after processing this batch is:  0.0030678287148475647\n",
      "\n",
      "The classification loss after processing this batch is:  0.1895691603422165\n",
      "The representation loss after processing this batch is:  0.002484530210494995\n",
      "\n",
      "The classification loss after processing this batch is:  0.13997234404087067\n",
      "The representation loss after processing this batch is:  0.0026411041617393494\n",
      "\n",
      "The classification loss after processing this batch is:  0.2585422098636627\n",
      "The representation loss after processing this batch is:  0.0026368871331214905\n",
      "\n",
      "The classification loss after processing this batch is:  0.13058415055274963\n",
      "The representation loss after processing this batch is:  0.002697039395570755\n",
      "\n",
      "The classification loss after processing this batch is:  0.14846239984035492\n",
      "The representation loss after processing this batch is:  0.002613440155982971\n",
      "\n",
      "The classification loss after processing this batch is:  0.18376708030700684\n",
      "The representation loss after processing this batch is:  0.0027445554733276367\n",
      "\n",
      "The classification loss after processing this batch is:  0.1661183089017868\n",
      "The representation loss after processing this batch is:  0.0028227269649505615\n",
      "\n",
      "The classification loss after processing this batch is:  0.09509924054145813\n",
      "The representation loss after processing this batch is:  0.00260818749666214\n",
      "\n",
      "The classification loss after processing this batch is:  0.20678633451461792\n",
      "The representation loss after processing this batch is:  0.002798035740852356\n",
      "\n",
      "The classification loss after processing this batch is:  0.2046865075826645\n",
      "The representation loss after processing this batch is:  0.002803504467010498\n",
      "\n",
      "The classification loss after processing this batch is:  0.19090747833251953\n",
      "The representation loss after processing this batch is:  0.002512820065021515\n",
      "\n",
      "The classification loss after processing this batch is:  0.171611025929451\n",
      "The representation loss after processing this batch is:  0.0028437450528144836\n",
      "\n",
      "The classification loss after processing this batch is:  0.18881569802761078\n",
      "The representation loss after processing this batch is:  0.0028982385993003845\n",
      "\n",
      "The classification loss after processing this batch is:  0.24352870881557465\n",
      "The representation loss after processing this batch is:  0.002997424453496933\n",
      "\n",
      "The classification loss after processing this batch is:  0.20017389953136444\n",
      "The representation loss after processing this batch is:  0.0030019357800483704\n",
      "\n",
      "The classification loss after processing this batch is:  0.1284203678369522\n",
      "The representation loss after processing this batch is:  0.003171779215335846\n",
      "\n",
      "The classification loss after processing this batch is:  0.14575229585170746\n",
      "The representation loss after processing this batch is:  0.003308221697807312\n",
      "\n",
      "The classification loss after processing this batch is:  0.28958430886268616\n",
      "The representation loss after processing this batch is:  0.002554371953010559\n",
      "\n",
      "The classification loss after processing this batch is:  0.2227177619934082\n",
      "The representation loss after processing this batch is:  0.0027301274240016937\n",
      "\n",
      "The classification loss after processing this batch is:  0.2884501516819\n",
      "The representation loss after processing this batch is:  0.0030914805829524994\n",
      "\n",
      "The classification loss after processing this batch is:  0.3216188848018646\n",
      "The representation loss after processing this batch is:  0.002540998160839081\n",
      "\n",
      "The classification loss after processing this batch is:  0.21737605333328247\n",
      "The representation loss after processing this batch is:  0.0027793869376182556\n",
      "\n",
      "The classification loss after processing this batch is:  0.12921972572803497\n",
      "The representation loss after processing this batch is:  0.0029607638716697693\n",
      "\n",
      "The classification loss after processing this batch is:  0.09650438278913498\n",
      "The representation loss after processing this batch is:  0.002705756574869156\n",
      "\n",
      "The classification loss after processing this batch is:  0.08643300831317902\n",
      "The representation loss after processing this batch is:  0.003286227583885193\n",
      "\n",
      "The classification loss after processing this batch is:  0.1504967361688614\n",
      "The representation loss after processing this batch is:  0.0033697038888931274\n",
      "\n",
      "The classification loss after processing this batch is:  0.08439920842647552\n",
      "The representation loss after processing this batch is:  0.0030213668942451477\n",
      "\n",
      "The classification loss after processing this batch is:  0.19036439061164856\n",
      "The representation loss after processing this batch is:  0.003834240138530731\n",
      "\n",
      "The classification loss after processing this batch is:  0.14912398159503937\n",
      "The representation loss after processing this batch is:  0.002736452966928482\n",
      "\n",
      "The classification loss after processing this batch is:  0.14016662538051605\n",
      "The representation loss after processing this batch is:  0.002727735787630081\n",
      "\n",
      "The classification loss after processing this batch is:  0.23714135587215424\n",
      "The representation loss after processing this batch is:  0.0026540718972682953\n",
      "\n",
      "The classification loss after processing this batch is:  0.12774568796157837\n",
      "The representation loss after processing this batch is:  0.0032900571823120117\n",
      "\n",
      "The classification loss after processing this batch is:  0.19348840415477753\n",
      "The representation loss after processing this batch is:  0.0037925317883491516\n",
      "\n",
      "The classification loss after processing this batch is:  0.26458948850631714\n",
      "The representation loss after processing this batch is:  0.003676801919937134\n",
      "\n",
      "The classification loss after processing this batch is:  0.16024473309516907\n",
      "The representation loss after processing this batch is:  0.0031284168362617493\n",
      "\n",
      "The classification loss after processing this batch is:  0.16388198733329773\n",
      "The representation loss after processing this batch is:  0.002570614218711853\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10011851787567139\n",
      "The representation loss after processing this batch is:  0.0026046037673950195\n",
      "\n",
      "The classification loss after processing this batch is:  0.06247192248702049\n",
      "The representation loss after processing this batch is:  0.0029904544353485107\n",
      "\n",
      "The classification loss after processing this batch is:  0.0860961303114891\n",
      "The representation loss after processing this batch is:  0.002948448061943054\n",
      "\n",
      "The classification loss after processing this batch is:  0.11621157079935074\n",
      "The representation loss after processing this batch is:  0.0027533285319805145\n",
      "\n",
      "The classification loss after processing this batch is:  0.1549314558506012\n",
      "The representation loss after processing this batch is:  0.002453848719596863\n",
      "\n",
      "The classification loss after processing this batch is:  0.13735456764698029\n",
      "The representation loss after processing this batch is:  0.0028859004378318787\n",
      "\n",
      "The classification loss after processing this batch is:  0.1790468841791153\n",
      "The representation loss after processing this batch is:  0.002781517803668976\n",
      "\n",
      "The classification loss after processing this batch is:  0.38665786385536194\n",
      "The representation loss after processing this batch is:  0.0029806867241859436\n",
      "\n",
      "The classification loss after processing this batch is:  0.2819477617740631\n",
      "The representation loss after processing this batch is:  0.002913370728492737\n",
      "\n",
      "The classification loss after processing this batch is:  0.12458417564630508\n",
      "The representation loss after processing this batch is:  0.002834536135196686\n",
      "\n",
      "The classification loss after processing this batch is:  0.10494526475667953\n",
      "The representation loss after processing this batch is:  0.0025893375277519226\n",
      "\n",
      "The classification loss after processing this batch is:  0.1470010131597519\n",
      "The representation loss after processing this batch is:  0.002701215445995331\n",
      "\n",
      "The classification loss after processing this batch is:  0.12095464766025543\n",
      "The representation loss after processing this batch is:  0.0028632953763008118\n",
      "\n",
      "The classification loss after processing this batch is:  0.06896485388278961\n",
      "The representation loss after processing this batch is:  0.0028120875358581543\n",
      "\n",
      "The classification loss after processing this batch is:  0.08636622130870819\n",
      "The representation loss after processing this batch is:  0.0029798895120620728\n",
      "\n",
      "The classification loss after processing this batch is:  0.12831756472587585\n",
      "The representation loss after processing this batch is:  0.00252436101436615\n",
      "\n",
      "The classification loss after processing this batch is:  0.18689985573291779\n",
      "The representation loss after processing this batch is:  0.0026964060962200165\n",
      "\n",
      "The classification loss after processing this batch is:  0.09844230115413666\n",
      "The representation loss after processing this batch is:  0.0030288323760032654\n",
      "\n",
      "The classification loss after processing this batch is:  0.09746956080198288\n",
      "The representation loss after processing this batch is:  0.0028435736894607544\n",
      "\n",
      "The classification loss after processing this batch is:  0.08734210580587387\n",
      "The representation loss after processing this batch is:  0.0025816522538661957\n",
      "\n",
      "The classification loss after processing this batch is:  0.29564332962036133\n",
      "The representation loss after processing this batch is:  0.0024933554232120514\n",
      "\n",
      "The classification loss after processing this batch is:  0.13406461477279663\n",
      "The representation loss after processing this batch is:  0.0029224753379821777\n",
      "\n",
      "The classification loss after processing this batch is:  0.08016570657491684\n",
      "The representation loss after processing this batch is:  0.002977754920721054\n",
      "\n",
      "The classification loss after processing this batch is:  0.20319072902202606\n",
      "The representation loss after processing this batch is:  0.00288226455450058\n",
      "\n",
      "The classification loss after processing this batch is:  0.1164681538939476\n",
      "The representation loss after processing this batch is:  0.002597518265247345\n",
      "\n",
      "The classification loss after processing this batch is:  0.08691539615392685\n",
      "The representation loss after processing this batch is:  0.0026408210396766663\n",
      "\n",
      "The classification loss after processing this batch is:  0.16234153509140015\n",
      "The representation loss after processing this batch is:  0.0026579760015010834\n",
      "\n",
      "The classification loss after processing this batch is:  0.08432971686124802\n",
      "The representation loss after processing this batch is:  0.0024149641394615173\n",
      "\n",
      "The classification loss after processing this batch is:  0.09744828194379807\n",
      "The representation loss after processing this batch is:  0.002911355346441269\n",
      "\n",
      "The classification loss after processing this batch is:  0.16774646937847137\n",
      "The representation loss after processing this batch is:  0.0024185627698898315\n",
      "\n",
      "The classification loss after processing this batch is:  0.2151452898979187\n",
      "The representation loss after processing this batch is:  0.0027145259082317352\n",
      "\n",
      "The classification loss after processing this batch is:  0.14978721737861633\n",
      "The representation loss after processing this batch is:  0.0028407499194145203\n",
      "\n",
      "The classification loss after processing this batch is:  0.20988470315933228\n",
      "The representation loss after processing this batch is:  0.0026434138417243958\n",
      "\n",
      "The classification loss after processing this batch is:  0.13188131153583527\n",
      "The representation loss after processing this batch is:  0.002666223794221878\n",
      "\n",
      "The classification loss after processing this batch is:  0.1875935047864914\n",
      "The representation loss after processing this batch is:  0.00263068825006485\n",
      "\n",
      "The classification loss after processing this batch is:  0.11748449504375458\n",
      "The representation loss after processing this batch is:  0.0029794424772262573\n",
      "\n",
      "The classification loss after processing this batch is:  0.17196954786777496\n",
      "The representation loss after processing this batch is:  0.002972908318042755\n",
      "\n",
      "The classification loss after processing this batch is:  0.09985648840665817\n",
      "The representation loss after processing this batch is:  0.0026914067566394806\n",
      "\n",
      "The classification loss after processing this batch is:  0.20415648818016052\n",
      "The representation loss after processing this batch is:  0.0028927363455295563\n",
      "\n",
      "The classification loss after processing this batch is:  0.12547741830348969\n",
      "The representation loss after processing this batch is:  0.0030436664819717407\n",
      "\n",
      "The classification loss after processing this batch is:  0.20826172828674316\n",
      "The representation loss after processing this batch is:  0.0025124289095401764\n",
      "\n",
      "The classification loss after processing this batch is:  0.15182724595069885\n",
      "The representation loss after processing this batch is:  0.0023167282342910767\n",
      "\n",
      "The classification loss after processing this batch is:  0.15417644381523132\n",
      "The representation loss after processing this batch is:  0.0027885623276233673\n",
      "\n",
      "The classification loss after processing this batch is:  0.19471748173236847\n",
      "The representation loss after processing this batch is:  0.0026466287672519684\n",
      "\n",
      "The classification loss after processing this batch is:  0.15039438009262085\n",
      "The representation loss after processing this batch is:  0.002626076340675354\n",
      "\n",
      "The classification loss after processing this batch is:  0.1958458125591278\n",
      "The representation loss after processing this batch is:  0.0026900656521320343\n",
      "\n",
      "The classification loss after processing this batch is:  0.24415798485279083\n",
      "The representation loss after processing this batch is:  0.0024651773273944855\n",
      "\n",
      "The classification loss after processing this batch is:  0.3013037145137787\n",
      "The representation loss after processing this batch is:  0.0023506172001361847\n",
      "\n",
      "The classification loss after processing this batch is:  0.251313179731369\n",
      "The representation loss after processing this batch is:  0.0024435073137283325\n",
      "\n",
      "The classification loss after processing this batch is:  0.10458455234766006\n",
      "The representation loss after processing this batch is:  0.002776890993118286\n",
      "\n",
      "The classification loss after processing this batch is:  0.19680903851985931\n",
      "The representation loss after processing this batch is:  0.0031244270503520966\n",
      "\n",
      "The classification loss after processing this batch is:  0.1170029491186142\n",
      "The representation loss after processing this batch is:  0.0030963271856307983\n",
      "\n",
      "The classification loss after processing this batch is:  0.16009673476219177\n",
      "The representation loss after processing this batch is:  0.0029725804924964905\n",
      "\n",
      "The classification loss after processing this batch is:  0.2326682209968567\n",
      "The representation loss after processing this batch is:  0.002955608069896698\n",
      "\n",
      "The classification loss after processing this batch is:  0.3166005313396454\n",
      "The representation loss after processing this batch is:  0.0028918907046318054\n",
      "\n",
      "The classification loss after processing this batch is:  0.39945441484451294\n",
      "The representation loss after processing this batch is:  0.0024731457233428955\n",
      "\n",
      "The classification loss after processing this batch is:  0.2133069932460785\n",
      "The representation loss after processing this batch is:  0.002926025539636612\n",
      "\n",
      "The classification loss after processing this batch is:  0.10763618350028992\n",
      "The representation loss after processing this batch is:  0.002823401242494583\n",
      "\n",
      "The classification loss after processing this batch is:  0.11410214751958847\n",
      "The representation loss after processing this batch is:  0.00276125967502594\n",
      "\n",
      "The classification loss after processing this batch is:  0.20406030118465424\n",
      "The representation loss after processing this batch is:  0.0026902295649051666\n",
      "\n",
      "The classification loss after processing this batch is:  0.11173155158758163\n",
      "The representation loss after processing this batch is:  0.0029491186141967773\n",
      "\n",
      "The classification loss after processing this batch is:  0.12271013855934143\n",
      "The representation loss after processing this batch is:  0.002785295248031616\n",
      "\n",
      "The classification loss after processing this batch is:  0.13435694575309753\n",
      "The representation loss after processing this batch is:  0.0028441473841667175\n",
      "\n",
      "The classification loss after processing this batch is:  0.044438108801841736\n",
      "The representation loss after processing this batch is:  0.002971366047859192\n",
      "\n",
      "The classification loss after processing this batch is:  0.12523619830608368\n",
      "The representation loss after processing this batch is:  0.0033600591123104095\n",
      "\n",
      "The classification loss after processing this batch is:  0.16002894937992096\n",
      "The representation loss after processing this batch is:  0.003034766763448715\n",
      "\n",
      "The classification loss after processing this batch is:  0.20559994876384735\n",
      "The representation loss after processing this batch is:  0.0025653280317783356\n",
      "\n",
      "The classification loss after processing this batch is:  0.16188225150108337\n",
      "The representation loss after processing this batch is:  0.002754524350166321\n",
      "\n",
      "The classification loss after processing this batch is:  0.13566653430461884\n",
      "The representation loss after processing this batch is:  0.0028970539569854736\n",
      "\n",
      "The classification loss after processing this batch is:  0.19556614756584167\n",
      "The representation loss after processing this batch is:  0.0031116679310798645\n",
      "\n",
      "The classification loss after processing this batch is:  0.11226410418748856\n",
      "The representation loss after processing this batch is:  0.0029159672558307648\n",
      "\n",
      "The classification loss after processing this batch is:  0.14908939599990845\n",
      "The representation loss after processing this batch is:  0.003244534134864807\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.16520293056964874\n",
      "The representation loss after processing this batch is:  0.0029378384351730347\n",
      "\n",
      "The classification loss after processing this batch is:  0.18386904895305634\n",
      "The representation loss after processing this batch is:  0.0026886537671089172\n",
      "\n",
      "The classification loss after processing this batch is:  0.16317196190357208\n",
      "The representation loss after processing this batch is:  0.0030012354254722595\n",
      "\n",
      "The classification loss after processing this batch is:  0.27552270889282227\n",
      "The representation loss after processing this batch is:  0.002686426043510437\n",
      "\n",
      "The classification loss after processing this batch is:  0.3198952376842499\n",
      "The representation loss after processing this batch is:  0.002793446183204651\n",
      "\n",
      "The classification loss after processing this batch is:  0.11102040857076645\n",
      "The representation loss after processing this batch is:  0.0027009136974811554\n",
      "\n",
      "The classification loss after processing this batch is:  0.14600586891174316\n",
      "The representation loss after processing this batch is:  0.0029072165489196777\n",
      "\n",
      "The classification loss after processing this batch is:  0.14886468648910522\n",
      "The representation loss after processing this batch is:  0.0031490325927734375\n",
      "\n",
      "The classification loss after processing this batch is:  0.20171229541301727\n",
      "The representation loss after processing this batch is:  0.0028020478785037994\n",
      "\n",
      "The classification loss after processing this batch is:  0.2704674303531647\n",
      "The representation loss after processing this batch is:  0.002982199192047119\n",
      "\n",
      "The classification loss after processing this batch is:  0.2406814843416214\n",
      "The representation loss after processing this batch is:  0.003367200493812561\n",
      "\n",
      "The classification loss after processing this batch is:  0.29657867550849915\n",
      "The representation loss after processing this batch is:  0.003327876329421997\n",
      "\n",
      "The classification loss after processing this batch is:  0.17883427441120148\n",
      "The representation loss after processing this batch is:  0.003417462110519409\n",
      "\n",
      "The classification loss after processing this batch is:  0.19201315939426422\n",
      "The representation loss after processing this batch is:  0.0031275786459445953\n",
      "\n",
      "The classification loss after processing this batch is:  0.17114965617656708\n",
      "The representation loss after processing this batch is:  0.0034694671630859375\n",
      "\n",
      "The classification loss after processing this batch is:  0.11605570465326309\n",
      "The representation loss after processing this batch is:  0.003007650375366211\n",
      "\n",
      "The classification loss after processing this batch is:  0.22736503183841705\n",
      "The representation loss after processing this batch is:  0.0031860098242759705\n",
      "\n",
      "The classification loss after processing this batch is:  0.15156875550746918\n",
      "The representation loss after processing this batch is:  0.002685926854610443\n",
      "\n",
      "The classification loss after processing this batch is:  0.08628695458173752\n",
      "The representation loss after processing this batch is:  0.0026685744524002075\n",
      "\n",
      "The classification loss after processing this batch is:  0.12363319098949432\n",
      "The representation loss after processing this batch is:  0.002730071544647217\n",
      "\n",
      "The classification loss after processing this batch is:  0.15109588205814362\n",
      "The representation loss after processing this batch is:  0.003101550042629242\n",
      "\n",
      "The classification loss after processing this batch is:  0.17209161818027496\n",
      "The representation loss after processing this batch is:  0.002742428332567215\n",
      "\n",
      "The classification loss after processing this batch is:  0.11525086313486099\n",
      "The representation loss after processing this batch is:  0.002800263464450836\n",
      "\n",
      "The classification loss after processing this batch is:  0.12382292747497559\n",
      "The representation loss after processing this batch is:  0.0026297420263290405\n",
      "\n",
      "The classification loss after processing this batch is:  0.0768887922167778\n",
      "The representation loss after processing this batch is:  0.002708442509174347\n",
      "\n",
      "The classification loss after processing this batch is:  0.1484161764383316\n",
      "The representation loss after processing this batch is:  0.002359408885240555\n",
      "\n",
      "The classification loss after processing this batch is:  0.1342647820711136\n",
      "The representation loss after processing this batch is:  0.002534274011850357\n",
      "\n",
      "The classification loss after processing this batch is:  0.4831479787826538\n",
      "The representation loss after processing this batch is:  0.0028392747044563293\n",
      "\n",
      "The classification loss after processing this batch is:  0.1548776477575302\n",
      "The representation loss after processing this batch is:  0.0028133168816566467\n",
      "\n",
      "The classification loss after processing this batch is:  0.2330433428287506\n",
      "The representation loss after processing this batch is:  0.002481311559677124\n",
      "\n",
      "The classification loss after processing this batch is:  0.2689843773841858\n",
      "The representation loss after processing this batch is:  0.0027863681316375732\n",
      "\n",
      "The classification loss after processing this batch is:  0.12721140682697296\n",
      "The representation loss after processing this batch is:  0.002559192478656769\n",
      "\n",
      "The classification loss after processing this batch is:  0.30797022581100464\n",
      "The representation loss after processing this batch is:  0.003076322376728058\n",
      "\n",
      "The classification loss after processing this batch is:  0.16787753999233246\n",
      "The representation loss after processing this batch is:  0.0028695985674858093\n",
      "\n",
      "The classification loss after processing this batch is:  0.26367223262786865\n",
      "The representation loss after processing this batch is:  0.00239722803235054\n",
      "\n",
      "The classification loss after processing this batch is:  0.08953800052404404\n",
      "The representation loss after processing this batch is:  0.002464212477207184\n",
      "\n",
      "The classification loss after processing this batch is:  0.13935081660747528\n",
      "The representation loss after processing this batch is:  0.002670988440513611\n",
      "\n",
      "The classification loss after processing this batch is:  0.060065858066082\n",
      "The representation loss after processing this batch is:  0.002967551350593567\n",
      "\n",
      "The classification loss after processing this batch is:  0.06295107305049896\n",
      "The representation loss after processing this batch is:  0.0027914494276046753\n",
      "\n",
      "The classification loss after processing this batch is:  0.11195492744445801\n",
      "The representation loss after processing this batch is:  0.002821899950504303\n",
      "\n",
      "The classification loss after processing this batch is:  0.08777137845754623\n",
      "The representation loss after processing this batch is:  0.002474568784236908\n",
      "\n",
      "The classification loss after processing this batch is:  0.16672055423259735\n",
      "The representation loss after processing this batch is:  0.002951495349407196\n",
      "\n",
      "The classification loss after processing this batch is:  0.1272539645433426\n",
      "The representation loss after processing this batch is:  0.0030578896403312683\n",
      "\n",
      "The classification loss after processing this batch is:  0.11262352764606476\n",
      "The representation loss after processing this batch is:  0.0026281625032424927\n",
      "\n",
      "The classification loss after processing this batch is:  0.18831494450569153\n",
      "The representation loss after processing this batch is:  0.00230606272816658\n",
      "\n",
      "The classification loss after processing this batch is:  0.13678701221942902\n",
      "The representation loss after processing this batch is:  0.002955421805381775\n",
      "\n",
      "The classification loss after processing this batch is:  0.1309177428483963\n",
      "The representation loss after processing this batch is:  0.0028218887746334076\n",
      "\n",
      "The classification loss after processing this batch is:  0.15727117657661438\n",
      "The representation loss after processing this batch is:  0.0028165876865386963\n",
      "\n",
      "The classification loss after processing this batch is:  0.2085128128528595\n",
      "The representation loss after processing this batch is:  0.0028706789016723633\n",
      "\n",
      "The classification loss after processing this batch is:  0.13501964509487152\n",
      "The representation loss after processing this batch is:  0.0025808289647102356\n",
      "\n",
      "The classification loss after processing this batch is:  0.11101443320512772\n",
      "The representation loss after processing this batch is:  0.0026216022670269012\n",
      "\n",
      "The classification loss after processing this batch is:  0.2333499640226364\n",
      "The representation loss after processing this batch is:  0.0029895231127738953\n",
      "\n",
      "The classification loss after processing this batch is:  0.18370601534843445\n",
      "The representation loss after processing this batch is:  0.0026497915387153625\n",
      "\n",
      "The classification loss after processing this batch is:  0.19200128316879272\n",
      "The representation loss after processing this batch is:  0.0027376413345336914\n",
      "\n",
      "The classification loss after processing this batch is:  0.09186002612113953\n",
      "The representation loss after processing this batch is:  0.0027131661772727966\n",
      "\n",
      "The classification loss after processing this batch is:  0.16470788419246674\n",
      "The representation loss after processing this batch is:  0.003170713782310486\n",
      "\n",
      "The classification loss after processing this batch is:  0.18277788162231445\n",
      "The representation loss after processing this batch is:  0.0028371475636959076\n",
      "\n",
      "The classification loss after processing this batch is:  0.14729465544223785\n",
      "The representation loss after processing this batch is:  0.003299955278635025\n",
      "\n",
      "The classification loss after processing this batch is:  0.12428216636180878\n",
      "The representation loss after processing this batch is:  0.003503117710351944\n",
      "\n",
      "The classification loss after processing this batch is:  0.11248701065778732\n",
      "The representation loss after processing this batch is:  0.0038188397884368896\n",
      "\n",
      "The classification loss after processing this batch is:  0.18936987221240997\n",
      "The representation loss after processing this batch is:  0.002905122935771942\n",
      "\n",
      "The classification loss after processing this batch is:  0.2230169028043747\n",
      "The representation loss after processing this batch is:  0.0029535889625549316\n",
      "\n",
      "The classification loss after processing this batch is:  0.15525248646736145\n",
      "The representation loss after processing this batch is:  0.004114232957363129\n",
      "\n",
      "The classification loss after processing this batch is:  0.1622539609670639\n",
      "The representation loss after processing this batch is:  0.0031055398285388947\n",
      "\n",
      "The classification loss after processing this batch is:  0.08386624604463577\n",
      "The representation loss after processing this batch is:  0.0023346655070781708\n",
      "\n",
      "The classification loss after processing this batch is:  0.22577665746212006\n",
      "The representation loss after processing this batch is:  0.0027486607432365417\n",
      "\n",
      "The classification loss after processing this batch is:  0.09944074600934982\n",
      "The representation loss after processing this batch is:  0.0027286186814308167\n",
      "\n",
      "The classification loss after processing this batch is:  0.12511178851127625\n",
      "The representation loss after processing this batch is:  0.002958916127681732\n",
      "\n",
      "The classification loss after processing this batch is:  0.12299417704343796\n",
      "The representation loss after processing this batch is:  0.0031058788299560547\n",
      "\n",
      "The classification loss after processing this batch is:  0.12539419531822205\n",
      "The representation loss after processing this batch is:  0.0028730034828186035\n",
      "\n",
      "The classification loss after processing this batch is:  0.13865973055362701\n",
      "The representation loss after processing this batch is:  0.00300632044672966\n",
      "\n",
      "The classification loss after processing this batch is:  0.19081629812717438\n",
      "The representation loss after processing this batch is:  0.003258928656578064\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.15818378329277039\n",
      "The representation loss after processing this batch is:  0.003219813108444214\n",
      "\n",
      "The classification loss after processing this batch is:  0.16386063396930695\n",
      "The representation loss after processing this batch is:  0.002820335328578949\n",
      "\n",
      "The classification loss after processing this batch is:  0.18010219931602478\n",
      "The representation loss after processing this batch is:  0.0033781975507736206\n",
      "\n",
      "The classification loss after processing this batch is:  0.10153593122959137\n",
      "The representation loss after processing this batch is:  0.0027260780334472656\n",
      "\n",
      "The classification loss after processing this batch is:  0.11160895228385925\n",
      "The representation loss after processing this batch is:  0.002654626965522766\n",
      "\n",
      "The classification loss after processing this batch is:  0.11025109887123108\n",
      "The representation loss after processing this batch is:  0.0032151788473129272\n",
      "\n",
      "The classification loss after processing this batch is:  0.14213193953037262\n",
      "The representation loss after processing this batch is:  0.002831496298313141\n",
      "\n",
      "The classification loss after processing this batch is:  0.08029458671808243\n",
      "The representation loss after processing this batch is:  0.002583123743534088\n",
      "\n",
      "The classification loss after processing this batch is:  0.08488909900188446\n",
      "The representation loss after processing this batch is:  0.0025002285838127136\n",
      "\n",
      "The classification loss after processing this batch is:  0.10114774107933044\n",
      "The representation loss after processing this batch is:  0.0031072497367858887\n",
      "\n",
      "The classification loss after processing this batch is:  0.09586762636899948\n",
      "The representation loss after processing this batch is:  0.002756066620349884\n",
      "\n",
      "The classification loss after processing this batch is:  0.2008509337902069\n",
      "The representation loss after processing this batch is:  0.0026779919862747192\n",
      "\n",
      "The classification loss after processing this batch is:  0.1437891572713852\n",
      "The representation loss after processing this batch is:  0.002587728202342987\n",
      "\n",
      "The classification loss after processing this batch is:  0.1787712275981903\n",
      "The representation loss after processing this batch is:  0.0028194859623908997\n",
      "\n",
      "The classification loss after processing this batch is:  0.08796118199825287\n",
      "The representation loss after processing this batch is:  0.0029805228114128113\n",
      "\n",
      "The classification loss after processing this batch is:  0.21701635420322418\n",
      "The representation loss after processing this batch is:  0.0026595816016197205\n",
      "\n",
      "The classification loss after processing this batch is:  0.17658217251300812\n",
      "The representation loss after processing this batch is:  0.0027456507086753845\n",
      "\n",
      "The classification loss after processing this batch is:  0.136702761054039\n",
      "The representation loss after processing this batch is:  0.002596937119960785\n",
      "\n",
      "The classification loss after processing this batch is:  0.1523571014404297\n",
      "The representation loss after processing this batch is:  0.002947695553302765\n",
      "\n",
      "The classification loss after processing this batch is:  0.17464733123779297\n",
      "The representation loss after processing this batch is:  0.003233194351196289\n",
      "\n",
      "The classification loss after processing this batch is:  0.08669878542423248\n",
      "The representation loss after processing this batch is:  0.002773858606815338\n",
      "\n",
      "The classification loss after processing this batch is:  0.07985494285821915\n",
      "The representation loss after processing this batch is:  0.002798929810523987\n",
      "\n",
      "The classification loss after processing this batch is:  0.099604532122612\n",
      "The representation loss after processing this batch is:  0.002566419541835785\n",
      "\n",
      "The classification loss after processing this batch is:  0.1969321072101593\n",
      "The representation loss after processing this batch is:  0.0028483495116233826\n",
      "\n",
      "The classification loss after processing this batch is:  0.16315512359142303\n",
      "The representation loss after processing this batch is:  0.0026676394045352936\n",
      "\n",
      "The classification loss after processing this batch is:  0.1642286330461502\n",
      "The representation loss after processing this batch is:  0.0032812654972076416\n",
      "\n",
      "The classification loss after processing this batch is:  0.20746900141239166\n",
      "The representation loss after processing this batch is:  0.0031615346670150757\n",
      "\n",
      "The classification loss after processing this batch is:  0.17977721989154816\n",
      "The representation loss after processing this batch is:  0.003000810742378235\n",
      "\n",
      "The classification loss after processing this batch is:  0.17894449830055237\n",
      "The representation loss after processing this batch is:  0.002604171633720398\n",
      "\n",
      "The classification loss after processing this batch is:  0.3076806962490082\n",
      "The representation loss after processing this batch is:  0.002741817384958267\n",
      "\n",
      "The classification loss after processing this batch is:  0.20821921527385712\n",
      "The representation loss after processing this batch is:  0.00251556932926178\n",
      "\n",
      "The classification loss after processing this batch is:  0.14738310873508453\n",
      "The representation loss after processing this batch is:  0.002492561936378479\n",
      "\n",
      "The classification loss after processing this batch is:  0.10105442255735397\n",
      "The representation loss after processing this batch is:  0.0026344656944274902\n",
      "\n",
      "The classification loss after processing this batch is:  0.08335304260253906\n",
      "The representation loss after processing this batch is:  0.002634897828102112\n",
      "\n",
      "The classification loss after processing this batch is:  0.09172329306602478\n",
      "The representation loss after processing this batch is:  0.0027147382497787476\n",
      "\n",
      "The classification loss after processing this batch is:  0.10842260718345642\n",
      "The representation loss after processing this batch is:  0.003248438239097595\n",
      "\n",
      "The classification loss after processing this batch is:  0.15486612915992737\n",
      "The representation loss after processing this batch is:  0.002517908811569214\n",
      "\n",
      "The classification loss after processing this batch is:  0.11934006214141846\n",
      "The representation loss after processing this batch is:  0.0026795491576194763\n",
      "\n",
      "The classification loss after processing this batch is:  0.20886093378067017\n",
      "The representation loss after processing this batch is:  0.002930261194705963\n",
      "\n",
      "The classification loss after processing this batch is:  0.18098506331443787\n",
      "The representation loss after processing this batch is:  0.002886436879634857\n",
      "\n",
      "The classification loss after processing this batch is:  0.21624402701854706\n",
      "The representation loss after processing this batch is:  0.002400510013103485\n",
      "\n",
      "The classification loss after processing this batch is:  0.14641860127449036\n",
      "The representation loss after processing this batch is:  0.002743765711784363\n",
      "\n",
      "The classification loss after processing this batch is:  0.24946682155132294\n",
      "The representation loss after processing this batch is:  0.00254739448428154\n",
      "\n",
      "The classification loss after processing this batch is:  0.17087985575199127\n",
      "The representation loss after processing this batch is:  0.002680610865354538\n",
      "\n",
      "The classification loss after processing this batch is:  0.11879615485668182\n",
      "The representation loss after processing this batch is:  0.00248129665851593\n",
      "\n",
      "The classification loss after processing this batch is:  0.16008932888507843\n",
      "The representation loss after processing this batch is:  0.0025190934538841248\n",
      "\n",
      "The classification loss after processing this batch is:  0.08805135637521744\n",
      "The representation loss after processing this batch is:  0.0025932639837265015\n",
      "\n",
      "The classification loss after processing this batch is:  0.08064617961645126\n",
      "The representation loss after processing this batch is:  0.002627220004796982\n",
      "\n",
      "The classification loss after processing this batch is:  0.16066262125968933\n",
      "The representation loss after processing this batch is:  0.00277777761220932\n",
      "\n",
      "The classification loss after processing this batch is:  0.1810131072998047\n",
      "The representation loss after processing this batch is:  0.002524830400943756\n",
      "\n",
      "The classification loss after processing this batch is:  0.17514480650424957\n",
      "The representation loss after processing this batch is:  0.002842426300048828\n",
      "\n",
      "The classification loss after processing this batch is:  0.09650611877441406\n",
      "The representation loss after processing this batch is:  0.002877078950405121\n",
      "\n",
      "The classification loss after processing this batch is:  0.12925948202610016\n",
      "The representation loss after processing this batch is:  0.0031818822026252747\n",
      "\n",
      "The classification loss after processing this batch is:  0.09791439026594162\n",
      "The representation loss after processing this batch is:  0.0028562843799591064\n",
      "\n",
      "The classification loss after processing this batch is:  0.2741512954235077\n",
      "The representation loss after processing this batch is:  0.002731889486312866\n",
      "\n",
      "The classification loss after processing this batch is:  0.08824785053730011\n",
      "The representation loss after processing this batch is:  0.0025564581155776978\n",
      "\n",
      "The classification loss after processing this batch is:  0.07283424586057663\n",
      "The representation loss after processing this batch is:  0.0029707998037338257\n",
      "\n",
      "The classification loss after processing this batch is:  0.16391481459140778\n",
      "The representation loss after processing this batch is:  0.003297150135040283\n",
      "\n",
      "The classification loss after processing this batch is:  0.14394588768482208\n",
      "The representation loss after processing this batch is:  0.003023199737071991\n",
      "\n",
      "The classification loss after processing this batch is:  0.11056380718946457\n",
      "The representation loss after processing this batch is:  0.0032175928354263306\n",
      "\n",
      "The classification loss after processing this batch is:  0.08801743388175964\n",
      "The representation loss after processing this batch is:  0.002532772719860077\n",
      "\n",
      "The classification loss after processing this batch is:  0.1451135128736496\n",
      "The representation loss after processing this batch is:  0.0034371912479400635\n",
      "\n",
      "The classification loss after processing this batch is:  0.20260143280029297\n",
      "The representation loss after processing this batch is:  0.0032576024532318115\n",
      "\n",
      "The classification loss after processing this batch is:  0.24158161878585815\n",
      "The representation loss after processing this batch is:  0.002690080553293228\n",
      "\n",
      "The classification loss after processing this batch is:  0.21161168813705444\n",
      "The representation loss after processing this batch is:  0.003240838646888733\n",
      "\n",
      "The classification loss after processing this batch is:  0.08774814009666443\n",
      "The representation loss after processing this batch is:  0.002972252666950226\n",
      "\n",
      "The classification loss after processing this batch is:  0.10720625519752502\n",
      "The representation loss after processing this batch is:  0.002360895276069641\n",
      "\n",
      "The classification loss after processing this batch is:  0.22133608162403107\n",
      "The representation loss after processing this batch is:  0.0030038878321647644\n",
      "\n",
      "The classification loss after processing this batch is:  0.2590425908565521\n",
      "The representation loss after processing this batch is:  0.002779453992843628\n",
      "\n",
      "The classification loss after processing this batch is:  0.23327280580997467\n",
      "The representation loss after processing this batch is:  0.0028927214443683624\n",
      "\n",
      "The classification loss after processing this batch is:  0.2984392046928406\n",
      "The representation loss after processing this batch is:  0.0026900246739387512\n",
      "\n",
      "The classification loss after processing this batch is:  0.14934034645557404\n",
      "The representation loss after processing this batch is:  0.002643164247274399\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.21212543547153473\n",
      "The representation loss after processing this batch is:  0.002565711736679077\n",
      "\n",
      "The classification loss after processing this batch is:  0.13237303495407104\n",
      "The representation loss after processing this batch is:  0.0023789331316947937\n",
      "\n",
      "The classification loss after processing this batch is:  0.12965735793113708\n",
      "The representation loss after processing this batch is:  0.002952978014945984\n",
      "\n",
      "The classification loss after processing this batch is:  0.10547458380460739\n",
      "The representation loss after processing this batch is:  0.0027666985988616943\n",
      "\n",
      "The classification loss after processing this batch is:  0.1404837965965271\n",
      "The representation loss after processing this batch is:  0.0026813149452209473\n",
      "\n",
      "The classification loss after processing this batch is:  0.19259004294872284\n",
      "The representation loss after processing this batch is:  0.0025436803698539734\n",
      "\n",
      "The classification loss after processing this batch is:  0.13031348586082458\n",
      "The representation loss after processing this batch is:  0.002871718257665634\n",
      "\n",
      "The classification loss after processing this batch is:  0.17580968141555786\n",
      "The representation loss after processing this batch is:  0.0031568333506584167\n",
      "\n",
      "The classification loss after processing this batch is:  0.07380010932683945\n",
      "The representation loss after processing this batch is:  0.003100447356700897\n",
      "\n",
      "The classification loss after processing this batch is:  0.1182299554347992\n",
      "The representation loss after processing this batch is:  0.0030441805720329285\n",
      "\n",
      "The classification loss after processing this batch is:  0.12929578125476837\n",
      "The representation loss after processing this batch is:  0.0026745200157165527\n",
      "\n",
      "The classification loss after processing this batch is:  0.208251953125\n",
      "The representation loss after processing this batch is:  0.002809591591358185\n",
      "\n",
      "The classification loss after processing this batch is:  0.06942201405763626\n",
      "The representation loss after processing this batch is:  0.0031250864267349243\n",
      "\n",
      "The classification loss after processing this batch is:  0.09804148226976395\n",
      "The representation loss after processing this batch is:  0.002562105655670166\n",
      "\n",
      "The classification loss after processing this batch is:  0.1833081990480423\n",
      "The representation loss after processing this batch is:  0.003089234232902527\n",
      "\n",
      "The classification loss after processing this batch is:  0.18559306859970093\n",
      "The representation loss after processing this batch is:  0.002820245921611786\n",
      "\n",
      "The classification loss after processing this batch is:  0.18217222392559052\n",
      "The representation loss after processing this batch is:  0.002618171274662018\n",
      "\n",
      "The classification loss after processing this batch is:  0.12966448068618774\n",
      "The representation loss after processing this batch is:  0.0025140196084976196\n",
      "\n",
      "The classification loss after processing this batch is:  0.08291477710008621\n",
      "The representation loss after processing this batch is:  0.0027443356812000275\n",
      "\n",
      "The classification loss after processing this batch is:  0.12565353512763977\n",
      "The representation loss after processing this batch is:  0.0024597682058811188\n",
      "\n",
      "The classification loss after processing this batch is:  0.1301249861717224\n",
      "The representation loss after processing this batch is:  0.0029130205512046814\n",
      "\n",
      "The classification loss after processing this batch is:  0.17516568303108215\n",
      "The representation loss after processing this batch is:  0.0026956722140312195\n",
      "\n",
      "The classification loss after processing this batch is:  0.1620032638311386\n",
      "The representation loss after processing this batch is:  0.0035886093974113464\n",
      "\n",
      "The classification loss after processing this batch is:  0.10143882781267166\n",
      "The representation loss after processing this batch is:  0.0025107339024543762\n",
      "\n",
      "The classification loss after processing this batch is:  0.18701261281967163\n",
      "The representation loss after processing this batch is:  0.00261123850941658\n",
      "\n",
      "The classification loss after processing this batch is:  0.24264153838157654\n",
      "The representation loss after processing this batch is:  0.0027791783213615417\n",
      "\n",
      "The classification loss after processing this batch is:  0.06532637774944305\n",
      "The representation loss after processing this batch is:  0.002810753881931305\n",
      "\n",
      "The classification loss after processing this batch is:  0.12958580255508423\n",
      "The representation loss after processing this batch is:  0.0027309060096740723\n",
      "\n",
      "The classification loss after processing this batch is:  0.2270793616771698\n",
      "The representation loss after processing this batch is:  0.002532072365283966\n",
      "\n",
      "The classification loss after processing this batch is:  0.23528680205345154\n",
      "The representation loss after processing this batch is:  0.002719491720199585\n",
      "\n",
      "The classification loss after processing this batch is:  0.15026897192001343\n",
      "The representation loss after processing this batch is:  0.0026205405592918396\n",
      "\n",
      "The classification loss after processing this batch is:  0.24920907616615295\n",
      "The representation loss after processing this batch is:  0.0025334209203720093\n",
      "\n",
      "The classification loss after processing this batch is:  0.19156333804130554\n",
      "The representation loss after processing this batch is:  0.0026835203170776367\n",
      "\n",
      "The classification loss after processing this batch is:  0.23792055249214172\n",
      "The representation loss after processing this batch is:  0.0030436143279075623\n",
      "\n",
      "The classification loss after processing this batch is:  0.15354789793491364\n",
      "The representation loss after processing this batch is:  0.0031531602144241333\n",
      "\n",
      "The classification loss after processing this batch is:  0.21387574076652527\n",
      "The representation loss after processing this batch is:  0.0026599057018756866\n",
      "\n",
      "The classification loss after processing this batch is:  0.11681248992681503\n",
      "The representation loss after processing this batch is:  0.0039388760924339294\n",
      "\n",
      "The classification loss after processing this batch is:  0.11854489892721176\n",
      "The representation loss after processing this batch is:  0.0027101337909698486\n",
      "\n",
      "The classification loss after processing this batch is:  0.12465868145227432\n",
      "The representation loss after processing this batch is:  0.0026007965207099915\n",
      "\n",
      "The classification loss after processing this batch is:  0.11535760015249252\n",
      "The representation loss after processing this batch is:  0.0024161897599697113\n",
      "\n",
      "The classification loss after processing this batch is:  0.16108347475528717\n",
      "The representation loss after processing this batch is:  0.0027989447116851807\n",
      "\n",
      "The classification loss after processing this batch is:  0.1402888298034668\n",
      "The representation loss after processing this batch is:  0.0026702210307121277\n",
      "\n",
      "The classification loss after processing this batch is:  0.1966773122549057\n",
      "The representation loss after processing this batch is:  0.0027524977922439575\n",
      "\n",
      "The classification loss after processing this batch is:  0.07052294164896011\n",
      "The representation loss after processing this batch is:  0.0028979629278182983\n",
      "\n",
      "The classification loss after processing this batch is:  0.09545547515153885\n",
      "The representation loss after processing this batch is:  0.0031500086188316345\n",
      "\n",
      "The classification loss after processing this batch is:  0.19073626399040222\n",
      "The representation loss after processing this batch is:  0.003022998571395874\n",
      "\n",
      "The classification loss after processing this batch is:  0.06171746179461479\n",
      "The representation loss after processing this batch is:  0.0027443841099739075\n",
      "\n",
      "The classification loss after processing this batch is:  0.11274390667676926\n",
      "The representation loss after processing this batch is:  0.0025799721479415894\n",
      "\n",
      "The classification loss after processing this batch is:  0.07168111950159073\n",
      "The representation loss after processing this batch is:  0.00284479558467865\n",
      "\n",
      "The classification loss after processing this batch is:  0.0976271778345108\n",
      "The representation loss after processing this batch is:  0.0025646239519119263\n",
      "\n",
      "The classification loss after processing this batch is:  0.16814075410366058\n",
      "The representation loss after processing this batch is:  0.0032336190342903137\n",
      "\n",
      "The classification loss after processing this batch is:  0.18452732264995575\n",
      "The representation loss after processing this batch is:  0.0036362558603286743\n",
      "\n",
      "The classification loss after processing this batch is:  0.17344507575035095\n",
      "The representation loss after processing this batch is:  0.0035575702786445618\n",
      "\n",
      "The classification loss after processing this batch is:  0.11838351935148239\n",
      "The representation loss after processing this batch is:  0.002834383398294449\n",
      "\n",
      "The classification loss after processing this batch is:  0.14696842432022095\n",
      "The representation loss after processing this batch is:  0.002624623477458954\n",
      "\n",
      "The classification loss after processing this batch is:  0.13259737193584442\n",
      "The representation loss after processing this batch is:  0.0027088001370429993\n",
      "\n",
      "The classification loss after processing this batch is:  0.07778304070234299\n",
      "The representation loss after processing this batch is:  0.002895861864089966\n",
      "\n",
      "The classification loss after processing this batch is:  0.0901772603392601\n",
      "The representation loss after processing this batch is:  0.002660207450389862\n",
      "\n",
      "The classification loss after processing this batch is:  0.07363057136535645\n",
      "The representation loss after processing this batch is:  0.0031106695532798767\n",
      "\n",
      "The classification loss after processing this batch is:  0.12592746317386627\n",
      "The representation loss after processing this batch is:  0.003120649605989456\n",
      "\n",
      "The classification loss after processing this batch is:  0.20756103098392487\n",
      "The representation loss after processing this batch is:  0.002903524786233902\n",
      "\n",
      "The classification loss after processing this batch is:  0.1784842163324356\n",
      "The representation loss after processing this batch is:  0.0024717971682548523\n",
      "\n",
      "The classification loss after processing this batch is:  0.14621038734912872\n",
      "The representation loss after processing this batch is:  0.003942675888538361\n",
      "\n",
      "The classification loss after processing this batch is:  0.10896097123622894\n",
      "The representation loss after processing this batch is:  0.003005571663379669\n",
      "\n",
      "The classification loss after processing this batch is:  0.15361131727695465\n",
      "The representation loss after processing this batch is:  0.002875532954931259\n",
      "\n",
      "The classification loss after processing this batch is:  0.11290205270051956\n",
      "The representation loss after processing this batch is:  0.002815764397382736\n",
      "\n",
      "The classification loss after processing this batch is:  0.4033241271972656\n",
      "The representation loss after processing this batch is:  0.0030163154006004333\n",
      "\n",
      "The classification loss after processing this batch is:  0.12404424697160721\n",
      "The representation loss after processing this batch is:  0.002885758876800537\n",
      "\n",
      "The classification loss after processing this batch is:  0.27177155017852783\n",
      "The representation loss after processing this batch is:  0.0036354511976242065\n",
      "\n",
      "The classification loss after processing this batch is:  0.13477569818496704\n",
      "The representation loss after processing this batch is:  0.0025799348950386047\n",
      "\n",
      "The classification loss after processing this batch is:  0.13848501443862915\n",
      "The representation loss after processing this batch is:  0.0027002692222595215\n",
      "\n",
      "The classification loss after processing this batch is:  0.17274951934814453\n",
      "The representation loss after processing this batch is:  0.0023892223834991455\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.16425567865371704\n",
      "The representation loss after processing this batch is:  0.0029761455953121185\n",
      "\n",
      "The classification loss after processing this batch is:  0.24412943422794342\n",
      "The representation loss after processing this batch is:  0.0028030872344970703\n",
      "\n",
      "The classification loss after processing this batch is:  0.19597110152244568\n",
      "The representation loss after processing this batch is:  0.00321882963180542\n",
      "\n",
      "The classification loss after processing this batch is:  0.1876547783613205\n",
      "The representation loss after processing this batch is:  0.003275640308856964\n",
      "\n",
      "The classification loss after processing this batch is:  0.16906806826591492\n",
      "The representation loss after processing this batch is:  0.0029988735914230347\n",
      "\n",
      "The classification loss after processing this batch is:  0.060389187186956406\n",
      "The representation loss after processing this batch is:  0.0029793530702590942\n",
      "\n",
      "The classification loss after processing this batch is:  0.16655360162258148\n",
      "The representation loss after processing this batch is:  0.0026322118937969208\n",
      "\n",
      "The classification loss after processing this batch is:  0.14263500273227692\n",
      "The representation loss after processing this batch is:  0.0026668012142181396\n",
      "\n",
      "The classification loss after processing this batch is:  0.08785261958837509\n",
      "The representation loss after processing this batch is:  0.002832084894180298\n",
      "\n",
      "The classification loss after processing this batch is:  0.15496371686458588\n",
      "The representation loss after processing this batch is:  0.0027544796466827393\n",
      "\n",
      "The classification loss after processing this batch is:  0.24630028009414673\n",
      "The representation loss after processing this batch is:  0.002806149423122406\n",
      "\n",
      "The classification loss after processing this batch is:  0.15181928873062134\n",
      "The representation loss after processing this batch is:  0.002379912883043289\n",
      "\n",
      "The classification loss after processing this batch is:  0.12973089516162872\n",
      "The representation loss after processing this batch is:  0.002972535789012909\n",
      "\n",
      "The classification loss after processing this batch is:  0.11393529921770096\n",
      "The representation loss after processing this batch is:  0.0026742741465568542\n",
      "\n",
      "The classification loss after processing this batch is:  0.12624509632587433\n",
      "The representation loss after processing this batch is:  0.0027743950486183167\n",
      "\n",
      "The classification loss after processing this batch is:  0.14708618819713593\n",
      "The representation loss after processing this batch is:  0.003003939986228943\n",
      "\n",
      "The classification loss after processing this batch is:  0.07640429586172104\n",
      "The representation loss after processing this batch is:  0.0031211450695991516\n",
      "\n",
      "The classification loss after processing this batch is:  0.14805223047733307\n",
      "The representation loss after processing this batch is:  0.0026272013783454895\n",
      "\n",
      "The classification loss after processing this batch is:  0.18723848462104797\n",
      "The representation loss after processing this batch is:  0.002434235066175461\n",
      "\n",
      "The classification loss after processing this batch is:  0.11273549497127533\n",
      "The representation loss after processing this batch is:  0.002775907516479492\n",
      "\n",
      "The classification loss after processing this batch is:  0.19424046576023102\n",
      "The representation loss after processing this batch is:  0.002466060221195221\n",
      "\n",
      "The classification loss after processing this batch is:  0.15268731117248535\n",
      "The representation loss after processing this batch is:  0.0023285262286663055\n",
      "\n",
      "The classification loss after processing this batch is:  0.08068910241127014\n",
      "The representation loss after processing this batch is:  0.0026369616389274597\n",
      "\n",
      "The classification loss after processing this batch is:  0.10202118009328842\n",
      "The representation loss after processing this batch is:  0.002647310495376587\n",
      "\n",
      "The classification loss after processing this batch is:  0.17887254059314728\n",
      "The representation loss after processing this batch is:  0.0027640312910079956\n",
      "\n",
      "The classification loss after processing this batch is:  0.08696258068084717\n",
      "The representation loss after processing this batch is:  0.0027969293296337128\n",
      "\n",
      "The classification loss after processing this batch is:  0.36632677912712097\n",
      "The representation loss after processing this batch is:  0.002551816403865814\n",
      "\n",
      "The classification loss after processing this batch is:  0.16985465586185455\n",
      "The representation loss after processing this batch is:  0.002789832651615143\n",
      "\n",
      "The classification loss after processing this batch is:  0.23001715540885925\n",
      "The representation loss after processing this batch is:  0.0027228444814682007\n",
      "\n",
      "The classification loss after processing this batch is:  0.11792109161615372\n",
      "The representation loss after processing this batch is:  0.002260640263557434\n",
      "\n",
      "The classification loss after processing this batch is:  0.17346280813217163\n",
      "The representation loss after processing this batch is:  0.002860836684703827\n",
      "\n",
      "The classification loss after processing this batch is:  0.11330167949199677\n",
      "The representation loss after processing this batch is:  0.002419035881757736\n",
      "\n",
      "The classification loss after processing this batch is:  0.13141420483589172\n",
      "The representation loss after processing this batch is:  0.0025261379778385162\n",
      "\n",
      "The classification loss after processing this batch is:  0.20745258033275604\n",
      "The representation loss after processing this batch is:  0.002984777092933655\n",
      "\n",
      "The classification loss after processing this batch is:  0.15142299234867096\n",
      "The representation loss after processing this batch is:  0.0033283382654190063\n",
      "\n",
      "The classification loss after processing this batch is:  0.19011303782463074\n",
      "The representation loss after processing this batch is:  0.002716023474931717\n",
      "\n",
      "The classification loss after processing this batch is:  0.15925559401512146\n",
      "The representation loss after processing this batch is:  0.0027585551142692566\n",
      "\n",
      "The classification loss after processing this batch is:  0.22119645774364471\n",
      "The representation loss after processing this batch is:  0.002984747290611267\n",
      "\n",
      "The classification loss after processing this batch is:  0.16913294792175293\n",
      "The representation loss after processing this batch is:  0.0027831047773361206\n",
      "\n",
      "The classification loss after processing this batch is:  0.1985069215297699\n",
      "The representation loss after processing this batch is:  0.0030528679490089417\n",
      "\n",
      "The classification loss after processing this batch is:  0.11057937890291214\n",
      "The representation loss after processing this batch is:  0.0028221309185028076\n",
      "\n",
      "The classification loss after processing this batch is:  0.1380210816860199\n",
      "The representation loss after processing this batch is:  0.0032181665301322937\n",
      "\n",
      "The classification loss after processing this batch is:  0.08017459511756897\n",
      "The representation loss after processing this batch is:  0.002939485013484955\n",
      "\n",
      "The classification loss after processing this batch is:  0.19239065051078796\n",
      "The representation loss after processing this batch is:  0.002574227750301361\n",
      "\n",
      "The classification loss after processing this batch is:  0.2541173994541168\n",
      "The representation loss after processing this batch is:  0.0027015432715415955\n",
      "\n",
      "The classification loss after processing this batch is:  0.10213859379291534\n",
      "The representation loss after processing this batch is:  0.0030135363340377808\n",
      "\n",
      "The classification loss after processing this batch is:  0.20548827946186066\n",
      "The representation loss after processing this batch is:  0.0028698109090328217\n",
      "\n",
      "The classification loss after processing this batch is:  0.2094264030456543\n",
      "The representation loss after processing this batch is:  0.002626970410346985\n",
      "\n",
      "The classification loss after processing this batch is:  0.19675537943840027\n",
      "The representation loss after processing this batch is:  0.00314369797706604\n",
      "\n",
      "The classification loss after processing this batch is:  0.09696213901042938\n",
      "The representation loss after processing this batch is:  0.002676505595445633\n",
      "\n",
      "The classification loss after processing this batch is:  0.1995275467634201\n",
      "The representation loss after processing this batch is:  0.002756122499704361\n",
      "\n",
      "The classification loss after processing this batch is:  0.210067018866539\n",
      "The representation loss after processing this batch is:  0.0029940754175186157\n",
      "\n",
      "The classification loss after processing this batch is:  0.12215642631053925\n",
      "The representation loss after processing this batch is:  0.0031804069876670837\n",
      "\n",
      "The classification loss after processing this batch is:  0.065231092274189\n",
      "The representation loss after processing this batch is:  0.003154739737510681\n",
      "\n",
      "The classification loss after processing this batch is:  0.14003436267375946\n",
      "The representation loss after processing this batch is:  0.0028867945075035095\n",
      "\n",
      "The classification loss after processing this batch is:  0.12021350860595703\n",
      "The representation loss after processing this batch is:  0.003069832921028137\n",
      "\n",
      "The classification loss after processing this batch is:  0.15475362539291382\n",
      "The representation loss after processing this batch is:  0.002568427473306656\n",
      "\n",
      "The classification loss after processing this batch is:  0.25020742416381836\n",
      "The representation loss after processing this batch is:  0.0030736029148101807\n",
      "\n",
      "The classification loss after processing this batch is:  0.1806597262620926\n",
      "The representation loss after processing this batch is:  0.0026282034814357758\n",
      "\n",
      "The classification loss after processing this batch is:  0.1487620770931244\n",
      "The representation loss after processing this batch is:  0.0030882544815540314\n",
      "\n",
      "The classification loss after processing this batch is:  0.15214022994041443\n",
      "The representation loss after processing this batch is:  0.0030299462378025055\n",
      "\n",
      "The classification loss after processing this batch is:  0.13588352501392365\n",
      "The representation loss after processing this batch is:  0.003102317452430725\n",
      "\n",
      "The classification loss after processing this batch is:  0.14137379825115204\n",
      "The representation loss after processing this batch is:  0.002851516008377075\n",
      "\n",
      "The classification loss after processing this batch is:  0.27136263251304626\n",
      "The representation loss after processing this batch is:  0.0028157830238342285\n",
      "\n",
      "The classification loss after processing this batch is:  0.21893498301506042\n",
      "The representation loss after processing this batch is:  0.0038888901472091675\n",
      "\n",
      "The classification loss after processing this batch is:  0.12816359102725983\n",
      "The representation loss after processing this batch is:  0.002754315733909607\n",
      "\n",
      "The classification loss after processing this batch is:  0.09363250434398651\n",
      "The representation loss after processing this batch is:  0.002928994596004486\n",
      "\n",
      "The classification loss after processing this batch is:  0.11664506793022156\n",
      "The representation loss after processing this batch is:  0.0026664286851882935\n",
      "\n",
      "The classification loss after processing this batch is:  0.09388076514005661\n",
      "The representation loss after processing this batch is:  0.0031545981764793396\n",
      "\n",
      "The classification loss after processing this batch is:  0.13998937606811523\n",
      "The representation loss after processing this batch is:  0.0026228763163089752\n",
      "\n",
      "The classification loss after processing this batch is:  0.24766717851161957\n",
      "The representation loss after processing this batch is:  0.002659376710653305\n",
      "\n",
      "The classification loss after processing this batch is:  0.30642169713974\n",
      "The representation loss after processing this batch is:  0.0032187998294830322\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1650822013616562\n",
      "The representation loss after processing this batch is:  0.0026749297976493835\n",
      "\n",
      "The classification loss after processing this batch is:  0.1460505872964859\n",
      "The representation loss after processing this batch is:  0.00266261026263237\n",
      "\n",
      "The classification loss after processing this batch is:  0.12337760627269745\n",
      "The representation loss after processing this batch is:  0.0029163621366024017\n",
      "\n",
      "The classification loss after processing this batch is:  0.13528801500797272\n",
      "The representation loss after processing this batch is:  0.0026632435619831085\n",
      "\n",
      "The classification loss after processing this batch is:  0.2468244880437851\n",
      "The representation loss after processing this batch is:  0.003035884350538254\n",
      "\n",
      "The classification loss after processing this batch is:  0.16266052424907684\n",
      "The representation loss after processing this batch is:  0.0024481453001499176\n",
      "\n",
      "The classification loss after processing this batch is:  0.31745651364326477\n",
      "The representation loss after processing this batch is:  0.0028514638543128967\n",
      "\n",
      "The classification loss after processing this batch is:  0.1760624349117279\n",
      "The representation loss after processing this batch is:  0.0028819218277931213\n",
      "\n",
      "The classification loss after processing this batch is:  0.0714162141084671\n",
      "The representation loss after processing this batch is:  0.0032276511192321777\n",
      "\n",
      "The classification loss after processing this batch is:  0.1886109858751297\n",
      "The representation loss after processing this batch is:  0.0029121525585651398\n",
      "\n",
      "The classification loss after processing this batch is:  0.16649526357650757\n",
      "The representation loss after processing this batch is:  0.0026389434933662415\n",
      "\n",
      "The classification loss after processing this batch is:  0.21191805601119995\n",
      "The representation loss after processing this batch is:  0.0029668956995010376\n",
      "\n",
      "The classification loss after processing this batch is:  0.18442527949810028\n",
      "The representation loss after processing this batch is:  0.0025360584259033203\n",
      "\n",
      "The classification loss after processing this batch is:  0.21735195815563202\n",
      "The representation loss after processing this batch is:  0.002542436122894287\n",
      "\n",
      "The classification loss after processing this batch is:  0.15834204852581024\n",
      "The representation loss after processing this batch is:  0.002759203314781189\n",
      "\n",
      "The classification loss after processing this batch is:  0.22166210412979126\n",
      "The representation loss after processing this batch is:  0.00272175669670105\n",
      "\n",
      "The classification loss after processing this batch is:  0.23368816077709198\n",
      "The representation loss after processing this batch is:  0.0028712227940559387\n",
      "\n",
      "The classification loss after processing this batch is:  0.30131280422210693\n",
      "The representation loss after processing this batch is:  0.0025497302412986755\n",
      "\n",
      "The classification loss after processing this batch is:  0.1949513852596283\n",
      "The representation loss after processing this batch is:  0.0028031840920448303\n",
      "\n",
      "The classification loss after processing this batch is:  0.07764562964439392\n",
      "The representation loss after processing this batch is:  0.0033037513494491577\n",
      "\n",
      "The classification loss after processing this batch is:  0.04463794082403183\n",
      "The representation loss after processing this batch is:  0.0029328539967536926\n",
      "\n",
      "The classification loss after processing this batch is:  0.12883351743221283\n",
      "The representation loss after processing this batch is:  0.003146633505821228\n",
      "\n",
      "The classification loss after processing this batch is:  0.0894581601023674\n",
      "The representation loss after processing this batch is:  0.004530645906925201\n",
      "\n",
      "The classification loss after processing this batch is:  0.16602954268455505\n",
      "The representation loss after processing this batch is:  0.0028454139828681946\n",
      "\n",
      "The classification loss after processing this batch is:  0.12181475758552551\n",
      "The representation loss after processing this batch is:  0.003325223922729492\n",
      "\n",
      "The classification loss after processing this batch is:  0.18341274559497833\n",
      "The representation loss after processing this batch is:  0.0028688237071037292\n",
      "\n",
      "The classification loss after processing this batch is:  0.06372536718845367\n",
      "The representation loss after processing this batch is:  0.003070421516895294\n",
      "\n",
      "The classification loss after processing this batch is:  0.1671064794063568\n",
      "The representation loss after processing this batch is:  0.0027431733906269073\n",
      "\n",
      "The classification loss after processing this batch is:  0.1525900512933731\n",
      "The representation loss after processing this batch is:  0.003071047365665436\n",
      "\n",
      "The classification loss after processing this batch is:  0.18100854754447937\n",
      "The representation loss after processing this batch is:  0.0027743354439735413\n",
      "\n",
      "The classification loss after processing this batch is:  0.123847097158432\n",
      "The representation loss after processing this batch is:  0.002838633954524994\n",
      "\n",
      "The classification loss after processing this batch is:  0.09873077273368835\n",
      "The representation loss after processing this batch is:  0.0022777654230594635\n",
      "\n",
      "The classification loss after processing this batch is:  0.14105577766895294\n",
      "The representation loss after processing this batch is:  0.002773486077785492\n",
      "\n",
      "The classification loss after processing this batch is:  0.17786923050880432\n",
      "The representation loss after processing this batch is:  0.002649061381816864\n",
      "\n",
      "The classification loss after processing this batch is:  0.14461882412433624\n",
      "The representation loss after processing this batch is:  0.0027963221073150635\n",
      "\n",
      "The classification loss after processing this batch is:  0.14388300478458405\n",
      "The representation loss after processing this batch is:  0.0031297728419303894\n",
      "\n",
      "The classification loss after processing this batch is:  0.12212918698787689\n",
      "The representation loss after processing this batch is:  0.0029264837503433228\n",
      "\n",
      "The classification loss after processing this batch is:  0.046664200723171234\n",
      "The representation loss after processing this batch is:  0.002889774739742279\n",
      "\n",
      "The classification loss after processing this batch is:  0.09621163457632065\n",
      "The representation loss after processing this batch is:  0.003192506730556488\n",
      "\n",
      "The classification loss after processing this batch is:  0.0648527517914772\n",
      "The representation loss after processing this batch is:  0.0029505938291549683\n",
      "\n",
      "The classification loss after processing this batch is:  0.1596357822418213\n",
      "The representation loss after processing this batch is:  0.002816900610923767\n",
      "\n",
      "The classification loss after processing this batch is:  0.09113841503858566\n",
      "The representation loss after processing this batch is:  0.0028840526938438416\n",
      "\n",
      "The classification loss after processing this batch is:  0.10041354596614838\n",
      "The representation loss after processing this batch is:  0.002704612910747528\n",
      "\n",
      "The classification loss after processing this batch is:  0.1515560895204544\n",
      "The representation loss after processing this batch is:  0.0030988454818725586\n",
      "\n",
      "The classification loss after processing this batch is:  0.14450842142105103\n",
      "The representation loss after processing this batch is:  0.0026258528232574463\n",
      "\n",
      "The classification loss after processing this batch is:  0.11485154926776886\n",
      "The representation loss after processing this batch is:  0.0024930983781814575\n",
      "\n",
      "The classification loss after processing this batch is:  0.07392922788858414\n",
      "The representation loss after processing this batch is:  0.0027082934975624084\n",
      "\n",
      "The classification loss after processing this batch is:  0.0666906014084816\n",
      "The representation loss after processing this batch is:  0.0027656853199005127\n",
      "\n",
      "The classification loss after processing this batch is:  0.06408794224262238\n",
      "The representation loss after processing this batch is:  0.0027282163500785828\n",
      "\n",
      "The classification loss after processing this batch is:  0.15509551763534546\n",
      "The representation loss after processing this batch is:  0.002943187952041626\n",
      "\n",
      "The classification loss after processing this batch is:  0.16892650723457336\n",
      "The representation loss after processing this batch is:  0.0029564201831817627\n",
      "\n",
      "The classification loss after processing this batch is:  0.09284830093383789\n",
      "The representation loss after processing this batch is:  0.002829432487487793\n",
      "\n",
      "The classification loss after processing this batch is:  0.1962566375732422\n",
      "The representation loss after processing this batch is:  0.0028507523238658905\n",
      "\n",
      "The classification loss after processing this batch is:  0.09378734230995178\n",
      "The representation loss after processing this batch is:  0.002782776951789856\n",
      "\n",
      "The classification loss after processing this batch is:  0.15702299773693085\n",
      "The representation loss after processing this batch is:  0.0026721395552158356\n",
      "\n",
      "The classification loss after processing this batch is:  0.21070438623428345\n",
      "The representation loss after processing this batch is:  0.002837676554918289\n",
      "\n",
      "The classification loss after processing this batch is:  0.12035902589559555\n",
      "The representation loss after processing this batch is:  0.002775333821773529\n",
      "\n",
      "The classification loss after processing this batch is:  0.21570901572704315\n",
      "The representation loss after processing this batch is:  0.0025952793657779694\n",
      "\n",
      "The classification loss after processing this batch is:  0.1498817503452301\n",
      "The representation loss after processing this batch is:  0.0023684129118919373\n",
      "\n",
      "The classification loss after processing this batch is:  0.16790328919887543\n",
      "The representation loss after processing this batch is:  0.002659544348716736\n",
      "\n",
      "The classification loss after processing this batch is:  0.15743303298950195\n",
      "The representation loss after processing this batch is:  0.0026714205741882324\n",
      "\n",
      "The classification loss after processing this batch is:  0.1092991828918457\n",
      "The representation loss after processing this batch is:  0.002968698740005493\n",
      "\n",
      "The classification loss after processing this batch is:  0.1485951691865921\n",
      "The representation loss after processing this batch is:  0.0024975761771202087\n",
      "\n",
      "The classification loss after processing this batch is:  0.12628886103630066\n",
      "The representation loss after processing this batch is:  0.0029628723859786987\n",
      "\n",
      "The classification loss after processing this batch is:  0.2086421698331833\n",
      "The representation loss after processing this batch is:  0.0028275437653064728\n",
      "\n",
      "The classification loss after processing this batch is:  0.1376703381538391\n",
      "The representation loss after processing this batch is:  0.0027999356389045715\n",
      "\n",
      "The classification loss after processing this batch is:  0.09267307072877884\n",
      "The representation loss after processing this batch is:  0.002743564546108246\n",
      "\n",
      "The classification loss after processing this batch is:  0.15615519881248474\n",
      "The representation loss after processing this batch is:  0.002556130290031433\n",
      "\n",
      "The classification loss after processing this batch is:  0.22318467497825623\n",
      "The representation loss after processing this batch is:  0.0024413131177425385\n",
      "\n",
      "The classification loss after processing this batch is:  0.09296848624944687\n",
      "The representation loss after processing this batch is:  0.0027001500129699707\n",
      "\n",
      "The classification loss after processing this batch is:  0.13893680274486542\n",
      "The representation loss after processing this batch is:  0.0027252696454524994\n",
      "\n",
      "The classification loss after processing this batch is:  0.1450745314359665\n",
      "The representation loss after processing this batch is:  0.002330280840396881\n",
      "\n",
      "The classification loss after processing this batch is:  0.10659199208021164\n",
      "The representation loss after processing this batch is:  0.0032381638884544373\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.07736856490373611\n",
      "The representation loss after processing this batch is:  0.003046199679374695\n",
      "\n",
      "The classification loss after processing this batch is:  0.1164945438504219\n",
      "The representation loss after processing this batch is:  0.003361999988555908\n",
      "\n",
      "The classification loss after processing this batch is:  0.11783938109874725\n",
      "The representation loss after processing this batch is:  0.0029289312660694122\n",
      "\n",
      "The classification loss after processing this batch is:  0.13377881050109863\n",
      "The representation loss after processing this batch is:  0.002897653728723526\n",
      "\n",
      "The classification loss after processing this batch is:  0.17180758714675903\n",
      "The representation loss after processing this batch is:  0.003001488745212555\n",
      "\n",
      "The classification loss after processing this batch is:  0.13614943623542786\n",
      "The representation loss after processing this batch is:  0.0029385611414909363\n",
      "\n",
      "The classification loss after processing this batch is:  0.18153387308120728\n",
      "The representation loss after processing this batch is:  0.0023432038724422455\n",
      "\n",
      "The classification loss after processing this batch is:  0.19361881911754608\n",
      "The representation loss after processing this batch is:  0.0031019262969493866\n",
      "\n",
      "The classification loss after processing this batch is:  0.062142934650182724\n",
      "The representation loss after processing this batch is:  0.003109775483608246\n",
      "\n",
      "The classification loss after processing this batch is:  0.08092871308326721\n",
      "The representation loss after processing this batch is:  0.002747219055891037\n",
      "\n",
      "The classification loss after processing this batch is:  0.12860837578773499\n",
      "The representation loss after processing this batch is:  0.0027094483375549316\n",
      "\n",
      "The classification loss after processing this batch is:  0.14415524899959564\n",
      "The representation loss after processing this batch is:  0.002844899892807007\n",
      "\n",
      "The classification loss after processing this batch is:  0.12468285858631134\n",
      "The representation loss after processing this batch is:  0.002774760127067566\n",
      "\n",
      "The classification loss after processing this batch is:  0.14489182829856873\n",
      "The representation loss after processing this batch is:  0.0027854517102241516\n",
      "\n",
      "The classification loss after processing this batch is:  0.142177551984787\n",
      "The representation loss after processing this batch is:  0.0032417476177215576\n",
      "\n",
      "The classification loss after processing this batch is:  0.14547698199748993\n",
      "The representation loss after processing this batch is:  0.002985723316669464\n",
      "\n",
      "The classification loss after processing this batch is:  0.20475082099437714\n",
      "The representation loss after processing this batch is:  0.002645649015903473\n",
      "\n",
      "The classification loss after processing this batch is:  0.1909763067960739\n",
      "The representation loss after processing this batch is:  0.0026305541396141052\n",
      "\n",
      "The classification loss after processing this batch is:  0.1619464010000229\n",
      "The representation loss after processing this batch is:  0.002454962581396103\n",
      "\n",
      "The classification loss after processing this batch is:  0.0866212472319603\n",
      "The representation loss after processing this batch is:  0.003284849226474762\n",
      "\n",
      "The classification loss after processing this batch is:  0.06657751649618149\n",
      "The representation loss after processing this batch is:  0.0030063465237617493\n",
      "\n",
      "The classification loss after processing this batch is:  0.19631236791610718\n",
      "The representation loss after processing this batch is:  0.0024130716919898987\n",
      "\n",
      "The classification loss after processing this batch is:  0.23000532388687134\n",
      "The representation loss after processing this batch is:  0.0024505257606506348\n",
      "\n",
      "The classification loss after processing this batch is:  0.20138536393642426\n",
      "The representation loss after processing this batch is:  0.002835504710674286\n",
      "\n",
      "The classification loss after processing this batch is:  0.18348897993564606\n",
      "The representation loss after processing this batch is:  0.0026383697986602783\n",
      "\n",
      "The classification loss after processing this batch is:  0.1976243406534195\n",
      "The representation loss after processing this batch is:  0.0028231479227542877\n",
      "\n",
      "The classification loss after processing this batch is:  0.2303079217672348\n",
      "The representation loss after processing this batch is:  0.002903468906879425\n",
      "\n",
      "The classification loss after processing this batch is:  0.2456316202878952\n",
      "The representation loss after processing this batch is:  0.0027074627578258514\n",
      "\n",
      "The classification loss after processing this batch is:  0.24164576828479767\n",
      "The representation loss after processing this batch is:  0.002871192991733551\n",
      "\n",
      "The classification loss after processing this batch is:  0.20780546963214874\n",
      "The representation loss after processing this batch is:  0.002869822084903717\n",
      "\n",
      "The classification loss after processing this batch is:  0.14892305433750153\n",
      "The representation loss after processing this batch is:  0.0033782050013542175\n",
      "\n",
      "The classification loss after processing this batch is:  0.08861281722784042\n",
      "The representation loss after processing this batch is:  0.003124319016933441\n",
      "\n",
      "The classification loss after processing this batch is:  0.1343580037355423\n",
      "The representation loss after processing this batch is:  0.0028230585157871246\n",
      "\n",
      "The classification loss after processing this batch is:  0.11911264806985855\n",
      "The representation loss after processing this batch is:  0.002575717866420746\n",
      "\n",
      "The classification loss after processing this batch is:  0.10243377089500427\n",
      "The representation loss after processing this batch is:  0.002510886639356613\n",
      "\n",
      "The classification loss after processing this batch is:  0.08768381178379059\n",
      "The representation loss after processing this batch is:  0.002566017210483551\n",
      "\n",
      "The classification loss after processing this batch is:  0.15861757099628448\n",
      "The representation loss after processing this batch is:  0.0026145577430725098\n",
      "\n",
      "The classification loss after processing this batch is:  0.0986490547657013\n",
      "The representation loss after processing this batch is:  0.00267617404460907\n",
      "\n",
      "The classification loss after processing this batch is:  0.11962784826755524\n",
      "The representation loss after processing this batch is:  0.0030843988060951233\n",
      "\n",
      "The classification loss after processing this batch is:  0.12398680299520493\n",
      "The representation loss after processing this batch is:  0.002508983016014099\n",
      "\n",
      "The classification loss after processing this batch is:  0.10859178751707077\n",
      "The representation loss after processing this batch is:  0.00257086381316185\n",
      "\n",
      "The classification loss after processing this batch is:  0.09526320546865463\n",
      "The representation loss after processing this batch is:  0.0028813257813453674\n",
      "\n",
      "The classification loss after processing this batch is:  0.1339523047208786\n",
      "The representation loss after processing this batch is:  0.002659682184457779\n",
      "\n",
      "The classification loss after processing this batch is:  0.17330233752727509\n",
      "The representation loss after processing this batch is:  0.0033864937722682953\n",
      "\n",
      "The classification loss after processing this batch is:  0.07104681432247162\n",
      "The representation loss after processing this batch is:  0.0028163492679595947\n",
      "\n",
      "The classification loss after processing this batch is:  0.08244545757770538\n",
      "The representation loss after processing this batch is:  0.0030076876282691956\n",
      "\n",
      "The classification loss after processing this batch is:  0.1687459796667099\n",
      "The representation loss after processing this batch is:  0.0026427656412124634\n",
      "\n",
      "The classification loss after processing this batch is:  0.23084530234336853\n",
      "The representation loss after processing this batch is:  0.0026876218616962433\n",
      "\n",
      "The classification loss after processing this batch is:  0.1469554305076599\n",
      "The representation loss after processing this batch is:  0.0026850923895835876\n",
      "\n",
      "The classification loss after processing this batch is:  0.07519928365945816\n",
      "The representation loss after processing this batch is:  0.0024652108550071716\n",
      "\n",
      "The classification loss after processing this batch is:  0.13360397517681122\n",
      "The representation loss after processing this batch is:  0.0024806633591651917\n",
      "\n",
      "The classification loss after processing this batch is:  0.037815939635038376\n",
      "The representation loss after processing this batch is:  0.0029753372073173523\n",
      "\n",
      "The classification loss after processing this batch is:  0.13732199370861053\n",
      "The representation loss after processing this batch is:  0.0027437955141067505\n",
      "\n",
      "The classification loss after processing this batch is:  0.11991479992866516\n",
      "The representation loss after processing this batch is:  0.0028564557433128357\n",
      "\n",
      "The classification loss after processing this batch is:  0.07369629293680191\n",
      "The representation loss after processing this batch is:  0.0024674460291862488\n",
      "\n",
      "The classification loss after processing this batch is:  0.08513598144054413\n",
      "The representation loss after processing this batch is:  0.0028186365962028503\n",
      "\n",
      "The classification loss after processing this batch is:  0.10812848061323166\n",
      "The representation loss after processing this batch is:  0.0026895031332969666\n",
      "\n",
      "The classification loss after processing this batch is:  0.09171398729085922\n",
      "The representation loss after processing this batch is:  0.0025490745902061462\n",
      "\n",
      "The classification loss after processing this batch is:  0.24079135060310364\n",
      "The representation loss after processing this batch is:  0.00267675518989563\n",
      "\n",
      "The classification loss after processing this batch is:  0.2879895865917206\n",
      "The representation loss after processing this batch is:  0.002709619700908661\n",
      "\n",
      "The classification loss after processing this batch is:  0.21233360469341278\n",
      "The representation loss after processing this batch is:  0.0026168115437030792\n",
      "\n",
      "The classification loss after processing this batch is:  0.22695499658584595\n",
      "The representation loss after processing this batch is:  0.002794358879327774\n",
      "\n",
      "The classification loss after processing this batch is:  0.1635328233242035\n",
      "The representation loss after processing this batch is:  0.0026691630482673645\n",
      "\n",
      "The classification loss after processing this batch is:  0.10287733376026154\n",
      "The representation loss after processing this batch is:  0.0026502981781959534\n",
      "\n",
      "The classification loss after processing this batch is:  0.23018021881580353\n",
      "The representation loss after processing this batch is:  0.0026064440608024597\n",
      "\n",
      "The classification loss after processing this batch is:  0.14551909267902374\n",
      "The representation loss after processing this batch is:  0.002901501953601837\n",
      "\n",
      "The classification loss after processing this batch is:  0.161764457821846\n",
      "The representation loss after processing this batch is:  0.002606719732284546\n",
      "\n",
      "The classification loss after processing this batch is:  0.16861280798912048\n",
      "The representation loss after processing this batch is:  0.0029503554105758667\n",
      "\n",
      "The classification loss after processing this batch is:  0.15766718983650208\n",
      "The representation loss after processing this batch is:  0.0026326067745685577\n",
      "\n",
      "The classification loss after processing this batch is:  0.12113051861524582\n",
      "The representation loss after processing this batch is:  0.002767398953437805\n",
      "\n",
      "The classification loss after processing this batch is:  0.14017820358276367\n",
      "The representation loss after processing this batch is:  0.002819228917360306\n",
      "\n",
      "The classification loss after processing this batch is:  0.1595948487520218\n",
      "The representation loss after processing this batch is:  0.002807319164276123\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08439609408378601\n",
      "The representation loss after processing this batch is:  0.002880997955799103\n",
      "\n",
      "The classification loss after processing this batch is:  0.07794753462076187\n",
      "The representation loss after processing this batch is:  0.002847563475370407\n",
      "\n",
      "The classification loss after processing this batch is:  0.13772700726985931\n",
      "The representation loss after processing this batch is:  0.0025320835411548615\n",
      "\n",
      "The classification loss after processing this batch is:  0.19592441618442535\n",
      "The representation loss after processing this batch is:  0.0026543810963630676\n",
      "\n",
      "The classification loss after processing this batch is:  0.06235591694712639\n",
      "The representation loss after processing this batch is:  0.0025704801082611084\n",
      "\n",
      "The classification loss after processing this batch is:  0.08989714086055756\n",
      "The representation loss after processing this batch is:  0.002552565187215805\n",
      "\n",
      "The classification loss after processing this batch is:  0.21212133765220642\n",
      "The representation loss after processing this batch is:  0.0024367421865463257\n",
      "\n",
      "The classification loss after processing this batch is:  0.20725923776626587\n",
      "The representation loss after processing this batch is:  0.0025768354535102844\n",
      "\n",
      "The classification loss after processing this batch is:  0.11320781707763672\n",
      "The representation loss after processing this batch is:  0.002524644136428833\n",
      "\n",
      "The classification loss after processing this batch is:  0.2304864525794983\n",
      "The representation loss after processing this batch is:  0.0025311000645160675\n",
      "\n",
      "The classification loss after processing this batch is:  0.08366359025239944\n",
      "The representation loss after processing this batch is:  0.0031503289937973022\n",
      "\n",
      "The classification loss after processing this batch is:  0.058577630668878555\n",
      "The representation loss after processing this batch is:  0.0025161951780319214\n",
      "\n",
      "The classification loss after processing this batch is:  0.07843780517578125\n",
      "The representation loss after processing this batch is:  0.0025511756539344788\n",
      "\n",
      "The classification loss after processing this batch is:  0.18115736544132233\n",
      "The representation loss after processing this batch is:  0.003331199288368225\n",
      "\n",
      "The classification loss after processing this batch is:  0.17447657883167267\n",
      "The representation loss after processing this batch is:  0.0030937492847442627\n",
      "\n",
      "The classification loss after processing this batch is:  0.0949995294213295\n",
      "The representation loss after processing this batch is:  0.003445848822593689\n",
      "\n",
      "The classification loss after processing this batch is:  0.1316528618335724\n",
      "The representation loss after processing this batch is:  0.002603735774755478\n",
      "\n",
      "The classification loss after processing this batch is:  0.1016254872083664\n",
      "The representation loss after processing this batch is:  0.0027762651443481445\n",
      "\n",
      "The classification loss after processing this batch is:  0.15917295217514038\n",
      "The representation loss after processing this batch is:  0.0027612335979938507\n",
      "\n",
      "The classification loss after processing this batch is:  0.13310874998569489\n",
      "The representation loss after processing this batch is:  0.0026378780603408813\n",
      "\n",
      "The classification loss after processing this batch is:  0.20176321268081665\n",
      "The representation loss after processing this batch is:  0.0024638399481773376\n",
      "\n",
      "The classification loss after processing this batch is:  0.1882944405078888\n",
      "The representation loss after processing this batch is:  0.002787873148918152\n",
      "\n",
      "The classification loss after processing this batch is:  0.2698710858821869\n",
      "The representation loss after processing this batch is:  0.0023428350687026978\n",
      "\n",
      "The classification loss after processing this batch is:  0.16747023165225983\n",
      "The representation loss after processing this batch is:  0.0024085193872451782\n",
      "\n",
      "The classification loss after processing this batch is:  0.19859689474105835\n",
      "The representation loss after processing this batch is:  0.0026057735085487366\n",
      "\n",
      "The classification loss after processing this batch is:  0.1826629340648651\n",
      "The representation loss after processing this batch is:  0.0026609227061271667\n",
      "\n",
      "The classification loss after processing this batch is:  0.06930963695049286\n",
      "The representation loss after processing this batch is:  0.00283755362033844\n",
      "\n",
      "The classification loss after processing this batch is:  0.11965147405862808\n",
      "The representation loss after processing this batch is:  0.0032616369426250458\n",
      "\n",
      "The classification loss after processing this batch is:  0.08503713458776474\n",
      "The representation loss after processing this batch is:  0.00312669575214386\n",
      "\n",
      "The classification loss after processing this batch is:  0.12649108469486237\n",
      "The representation loss after processing this batch is:  0.002765454351902008\n",
      "\n",
      "The classification loss after processing this batch is:  0.13327692449092865\n",
      "The representation loss after processing this batch is:  0.0022780001163482666\n",
      "\n",
      "The classification loss after processing this batch is:  0.11704931408166885\n",
      "The representation loss after processing this batch is:  0.0025631338357925415\n",
      "\n",
      "The classification loss after processing this batch is:  0.1432264894247055\n",
      "The representation loss after processing this batch is:  0.0027308613061904907\n",
      "\n",
      "The classification loss after processing this batch is:  0.1736653745174408\n",
      "The representation loss after processing this batch is:  0.0026731640100479126\n",
      "\n",
      "The classification loss after processing this batch is:  0.16140633821487427\n",
      "The representation loss after processing this batch is:  0.0024836882948875427\n",
      "\n",
      "The classification loss after processing this batch is:  0.2128351479768753\n",
      "The representation loss after processing this batch is:  0.002946816384792328\n",
      "\n",
      "The classification loss after processing this batch is:  0.12613031268119812\n",
      "The representation loss after processing this batch is:  0.002897687256336212\n",
      "\n",
      "The classification loss after processing this batch is:  0.13425347208976746\n",
      "The representation loss after processing this batch is:  0.0025211982429027557\n",
      "\n",
      "The classification loss after processing this batch is:  0.11410404741764069\n",
      "The representation loss after processing this batch is:  0.0029994547367095947\n",
      "\n",
      "The classification loss after processing this batch is:  0.19604626297950745\n",
      "The representation loss after processing this batch is:  0.003527209162712097\n",
      "\n",
      "The classification loss after processing this batch is:  0.29224109649658203\n",
      "The representation loss after processing this batch is:  0.0031205788254737854\n",
      "\n",
      "The classification loss after processing this batch is:  0.06312581151723862\n",
      "The representation loss after processing this batch is:  0.00249486044049263\n",
      "\n",
      "The classification loss after processing this batch is:  0.08276275545358658\n",
      "The representation loss after processing this batch is:  0.002843070775270462\n",
      "\n",
      "The classification loss after processing this batch is:  0.22264163196086884\n",
      "The representation loss after processing this batch is:  0.0032121092081069946\n",
      "\n",
      "The classification loss after processing this batch is:  0.06263205409049988\n",
      "The representation loss after processing this batch is:  0.0029567331075668335\n",
      "\n",
      "The classification loss after processing this batch is:  0.0943203717470169\n",
      "The representation loss after processing this batch is:  0.002730797976255417\n",
      "\n",
      "The classification loss after processing this batch is:  0.1575150489807129\n",
      "The representation loss after processing this batch is:  0.002733856439590454\n",
      "\n",
      "The classification loss after processing this batch is:  0.11997909098863602\n",
      "The representation loss after processing this batch is:  0.002973593771457672\n",
      "\n",
      "The classification loss after processing this batch is:  0.2107154279947281\n",
      "The representation loss after processing this batch is:  0.003267355263233185\n",
      "\n",
      "The classification loss after processing this batch is:  0.16545620560646057\n",
      "The representation loss after processing this batch is:  0.003325272351503372\n",
      "\n",
      "The classification loss after processing this batch is:  0.17011165618896484\n",
      "The representation loss after processing this batch is:  0.003198757767677307\n",
      "\n",
      "The classification loss after processing this batch is:  0.10852212458848953\n",
      "The representation loss after processing this batch is:  0.0023274794220924377\n",
      "\n",
      "The classification loss after processing this batch is:  0.19611549377441406\n",
      "The representation loss after processing this batch is:  0.0023658908903598785\n",
      "\n",
      "The classification loss after processing this batch is:  0.07221513241529465\n",
      "The representation loss after processing this batch is:  0.0026256293058395386\n",
      "\n",
      "The classification loss after processing this batch is:  0.05684462562203407\n",
      "The representation loss after processing this batch is:  0.0025508999824523926\n",
      "\n",
      "The classification loss after processing this batch is:  0.11364302784204483\n",
      "The representation loss after processing this batch is:  0.002671618014574051\n",
      "\n",
      "The classification loss after processing this batch is:  0.0814739540219307\n",
      "The representation loss after processing this batch is:  0.0027529820799827576\n",
      "\n",
      "The classification loss after processing this batch is:  0.11472510546445847\n",
      "The representation loss after processing this batch is:  0.0026039481163024902\n",
      "\n",
      "The classification loss after processing this batch is:  0.07579634338617325\n",
      "The representation loss after processing this batch is:  0.0023633018136024475\n",
      "\n",
      "The classification loss after processing this batch is:  0.10029413551092148\n",
      "The representation loss after processing this batch is:  0.0026557520031929016\n",
      "\n",
      "The classification loss after processing this batch is:  0.13944168388843536\n",
      "The representation loss after processing this batch is:  0.0024978332221508026\n",
      "\n",
      "The classification loss after processing this batch is:  0.18862947821617126\n",
      "The representation loss after processing this batch is:  0.0028376057744026184\n",
      "\n",
      "The classification loss after processing this batch is:  0.20489400625228882\n",
      "The representation loss after processing this batch is:  0.002540118992328644\n",
      "\n",
      "The classification loss after processing this batch is:  0.09312307089567184\n",
      "The representation loss after processing this batch is:  0.0030314400792121887\n",
      "\n",
      "The classification loss after processing this batch is:  0.21718420088291168\n",
      "The representation loss after processing this batch is:  0.002661708742380142\n",
      "\n",
      "The classification loss after processing this batch is:  0.09451809525489807\n",
      "The representation loss after processing this batch is:  0.002602614462375641\n",
      "\n",
      "The classification loss after processing this batch is:  0.17039449512958527\n",
      "The representation loss after processing this batch is:  0.0027252212166786194\n",
      "\n",
      "The classification loss after processing this batch is:  0.2761979103088379\n",
      "The representation loss after processing this batch is:  0.0030373409390449524\n",
      "\n",
      "The classification loss after processing this batch is:  0.13084790110588074\n",
      "The representation loss after processing this batch is:  0.0026405826210975647\n",
      "\n",
      "The classification loss after processing this batch is:  0.19196024537086487\n",
      "The representation loss after processing this batch is:  0.0026340559124946594\n",
      "\n",
      "The classification loss after processing this batch is:  0.15312600135803223\n",
      "The representation loss after processing this batch is:  0.0027031302452087402\n",
      "\n",
      "The classification loss after processing this batch is:  0.18373295664787292\n",
      "The representation loss after processing this batch is:  0.0026078224182128906\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.12037577480077744\n",
      "The representation loss after processing this batch is:  0.002599462866783142\n",
      "\n",
      "The classification loss after processing this batch is:  0.11156247556209564\n",
      "The representation loss after processing this batch is:  0.002786301076412201\n",
      "\n",
      "The classification loss after processing this batch is:  0.11395183205604553\n",
      "The representation loss after processing this batch is:  0.0026304051280021667\n",
      "\n",
      "The classification loss after processing this batch is:  0.08254579454660416\n",
      "The representation loss after processing this batch is:  0.0027648359537124634\n",
      "\n",
      "The classification loss after processing this batch is:  0.06431550532579422\n",
      "The representation loss after processing this batch is:  0.0025140270590782166\n",
      "\n",
      "The classification loss after processing this batch is:  0.148210808634758\n",
      "The representation loss after processing this batch is:  0.003004923462867737\n",
      "\n",
      "The classification loss after processing this batch is:  0.06762094050645828\n",
      "The representation loss after processing this batch is:  0.002839617431163788\n",
      "\n",
      "The classification loss after processing this batch is:  0.24138972163200378\n",
      "The representation loss after processing this batch is:  0.003111075609922409\n",
      "\n",
      "The classification loss after processing this batch is:  0.10874732583761215\n",
      "The representation loss after processing this batch is:  0.00284712016582489\n",
      "\n",
      "The classification loss after processing this batch is:  0.2134166657924652\n",
      "The representation loss after processing this batch is:  0.0027711912989616394\n",
      "\n",
      "The classification loss after processing this batch is:  0.264031320810318\n",
      "The representation loss after processing this batch is:  0.0024671368300914764\n",
      "\n",
      "The classification loss after processing this batch is:  0.15929876267910004\n",
      "The representation loss after processing this batch is:  0.002395123243331909\n",
      "\n",
      "The classification loss after processing this batch is:  0.06686045229434967\n",
      "The representation loss after processing this batch is:  0.0027269795536994934\n",
      "\n",
      "The classification loss after processing this batch is:  0.08185281604528427\n",
      "The representation loss after processing this batch is:  0.003050185739994049\n",
      "\n",
      "The classification loss after processing this batch is:  0.07615651935338974\n",
      "The representation loss after processing this batch is:  0.0030688270926475525\n",
      "\n",
      "The classification loss after processing this batch is:  0.10286174714565277\n",
      "The representation loss after processing this batch is:  0.0028574392199516296\n",
      "\n",
      "The classification loss after processing this batch is:  0.10756468772888184\n",
      "The representation loss after processing this batch is:  0.002283874899148941\n",
      "\n",
      "The classification loss after processing this batch is:  0.2861890196800232\n",
      "The representation loss after processing this batch is:  0.002630770206451416\n",
      "\n",
      "The classification loss after processing this batch is:  0.2174498289823532\n",
      "The representation loss after processing this batch is:  0.00254661962389946\n",
      "\n",
      "The classification loss after processing this batch is:  0.12544918060302734\n",
      "The representation loss after processing this batch is:  0.0031157881021499634\n",
      "\n",
      "The classification loss after processing this batch is:  0.25249937176704407\n",
      "The representation loss after processing this batch is:  0.0030307024717330933\n",
      "\n",
      "The classification loss after processing this batch is:  0.07751919329166412\n",
      "The representation loss after processing this batch is:  0.002826482057571411\n",
      "\n",
      "The classification loss after processing this batch is:  0.12035862356424332\n",
      "The representation loss after processing this batch is:  0.0027339793741703033\n",
      "\n",
      "The classification loss after processing this batch is:  0.18681234121322632\n",
      "The representation loss after processing this batch is:  0.002573445439338684\n",
      "\n",
      "The classification loss after processing this batch is:  0.12760253250598907\n",
      "The representation loss after processing this batch is:  0.003140542656183243\n",
      "\n",
      "The classification loss after processing this batch is:  0.15189848840236664\n",
      "The representation loss after processing this batch is:  0.0036274492740631104\n",
      "\n",
      "The classification loss after processing this batch is:  0.11582259088754654\n",
      "The representation loss after processing this batch is:  0.0029389895498752594\n",
      "\n",
      "The classification loss after processing this batch is:  0.15414482355117798\n",
      "The representation loss after processing this batch is:  0.003240451216697693\n",
      "\n",
      "The classification loss after processing this batch is:  0.20992761850357056\n",
      "The representation loss after processing this batch is:  0.0032896995544433594\n",
      "\n",
      "The classification loss after processing this batch is:  0.11038943380117416\n",
      "The representation loss after processing this batch is:  0.003173835575580597\n",
      "\n",
      "The classification loss after processing this batch is:  0.165846049785614\n",
      "The representation loss after processing this batch is:  0.002707339823246002\n",
      "\n",
      "The classification loss after processing this batch is:  0.22158215939998627\n",
      "The representation loss after processing this batch is:  0.002485118806362152\n",
      "\n",
      "The classification loss after processing this batch is:  0.15549932420253754\n",
      "The representation loss after processing this batch is:  0.002424478530883789\n",
      "\n",
      "The classification loss after processing this batch is:  0.1539718061685562\n",
      "The representation loss after processing this batch is:  0.002495117485523224\n",
      "\n",
      "The classification loss after processing this batch is:  0.08671042323112488\n",
      "The representation loss after processing this batch is:  0.0031533241271972656\n",
      "\n",
      "The classification loss after processing this batch is:  0.044596217572689056\n",
      "The representation loss after processing this batch is:  0.0029204636812210083\n",
      "\n",
      "The classification loss after processing this batch is:  0.1644132286310196\n",
      "The representation loss after processing this batch is:  0.0027874186635017395\n",
      "\n",
      "The classification loss after processing this batch is:  0.08335764706134796\n",
      "The representation loss after processing this batch is:  0.00289076566696167\n",
      "\n",
      "The classification loss after processing this batch is:  0.2725638747215271\n",
      "The representation loss after processing this batch is:  0.002615891396999359\n",
      "\n",
      "The classification loss after processing this batch is:  0.06259261071681976\n",
      "The representation loss after processing this batch is:  0.003041200339794159\n",
      "\n",
      "The classification loss after processing this batch is:  0.12484298646450043\n",
      "The representation loss after processing this batch is:  0.0023761093616485596\n",
      "\n",
      "The classification loss after processing this batch is:  0.18303340673446655\n",
      "The representation loss after processing this batch is:  0.0027196109294891357\n",
      "\n",
      "The classification loss after processing this batch is:  0.14111144840717316\n",
      "The representation loss after processing this batch is:  0.00261591374874115\n",
      "\n",
      "The classification loss after processing this batch is:  0.13828019797801971\n",
      "The representation loss after processing this batch is:  0.002846352756023407\n",
      "\n",
      "The classification loss after processing this batch is:  0.06900617480278015\n",
      "The representation loss after processing this batch is:  0.0027122721076011658\n",
      "\n",
      "The classification loss after processing this batch is:  0.0808265209197998\n",
      "The representation loss after processing this batch is:  0.002607349306344986\n",
      "\n",
      "The classification loss after processing this batch is:  0.07525690644979477\n",
      "The representation loss after processing this batch is:  0.0025343596935272217\n",
      "\n",
      "The classification loss after processing this batch is:  0.17200130224227905\n",
      "The representation loss after processing this batch is:  0.0035549551248550415\n",
      "\n",
      "The classification loss after processing this batch is:  0.19799837470054626\n",
      "The representation loss after processing this batch is:  0.003096155822277069\n",
      "\n",
      "The classification loss after processing this batch is:  0.18712745606899261\n",
      "The representation loss after processing this batch is:  0.002445448189973831\n",
      "\n",
      "The classification loss after processing this batch is:  0.20809103548526764\n",
      "The representation loss after processing this batch is:  0.0024205930531024933\n",
      "\n",
      "The classification loss after processing this batch is:  0.3055005371570587\n",
      "The representation loss after processing this batch is:  0.0025095343589782715\n",
      "\n",
      "The classification loss after processing this batch is:  0.12847456336021423\n",
      "The representation loss after processing this batch is:  0.0029469281435012817\n",
      "\n",
      "The classification loss after processing this batch is:  0.2577299177646637\n",
      "The representation loss after processing this batch is:  0.002727724611759186\n",
      "\n",
      "The classification loss after processing this batch is:  0.1395801603794098\n",
      "The representation loss after processing this batch is:  0.0027663931250572205\n",
      "\n",
      "The classification loss after processing this batch is:  0.1162758618593216\n",
      "The representation loss after processing this batch is:  0.002527795732021332\n",
      "\n",
      "The classification loss after processing this batch is:  0.07243349403142929\n",
      "The representation loss after processing this batch is:  0.00241021066904068\n",
      "\n",
      "The classification loss after processing this batch is:  0.08232972770929337\n",
      "The representation loss after processing this batch is:  0.0027321726083755493\n",
      "\n",
      "The classification loss after processing this batch is:  0.2388428896665573\n",
      "The representation loss after processing this batch is:  0.0027614831924438477\n",
      "\n",
      "The classification loss after processing this batch is:  0.13123396039009094\n",
      "The representation loss after processing this batch is:  0.002818778157234192\n",
      "\n",
      "The classification loss after processing this batch is:  0.14311037957668304\n",
      "The representation loss after processing this batch is:  0.0030337460339069366\n",
      "\n",
      "The classification loss after processing this batch is:  0.11933064460754395\n",
      "The representation loss after processing this batch is:  0.0031975358724594116\n",
      "\n",
      "The classification loss after processing this batch is:  0.10913734138011932\n",
      "The representation loss after processing this batch is:  0.0026841014623641968\n",
      "\n",
      "The classification loss after processing this batch is:  0.09558998793363571\n",
      "The representation loss after processing this batch is:  0.0026661306619644165\n",
      "\n",
      "The classification loss after processing this batch is:  0.18053069710731506\n",
      "The representation loss after processing this batch is:  0.002475529909133911\n",
      "\n",
      "The classification loss after processing this batch is:  0.19213487207889557\n",
      "The representation loss after processing this batch is:  0.002590171992778778\n",
      "\n",
      "The classification loss after processing this batch is:  0.22319836914539337\n",
      "The representation loss after processing this batch is:  0.0030855685472488403\n",
      "\n",
      "The classification loss after processing this batch is:  0.12486020475625992\n",
      "The representation loss after processing this batch is:  0.002438582479953766\n",
      "\n",
      "The classification loss after processing this batch is:  0.32767269015312195\n",
      "The representation loss after processing this batch is:  0.0022166743874549866\n",
      "\n",
      "The classification loss after processing this batch is:  0.12173546850681305\n",
      "The representation loss after processing this batch is:  0.002359982579946518\n",
      "\n",
      "The classification loss after processing this batch is:  0.13067284226417542\n",
      "The representation loss after processing this batch is:  0.0024955756962299347\n",
      "\n",
      "The classification loss after processing this batch is:  0.13038699328899384\n",
      "The representation loss after processing this batch is:  0.0030318163335323334\n",
      "\n",
      "The classification loss after processing this batch is:  0.09468194842338562\n",
      "The representation loss after processing this batch is:  0.002529531717300415\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1508595198392868\n",
      "The representation loss after processing this batch is:  0.0027527734637260437\n",
      "\n",
      "The classification loss after processing this batch is:  0.09906218945980072\n",
      "The representation loss after processing this batch is:  0.0027801617980003357\n",
      "\n",
      "The classification loss after processing this batch is:  0.1917051523923874\n",
      "The representation loss after processing this batch is:  0.002607487142086029\n",
      "\n",
      "The classification loss after processing this batch is:  0.24021528661251068\n",
      "The representation loss after processing this batch is:  0.0029899775981903076\n",
      "\n",
      "The classification loss after processing this batch is:  0.1999632567167282\n",
      "The representation loss after processing this batch is:  0.0028009451925754547\n",
      "\n",
      "The classification loss after processing this batch is:  0.1478297859430313\n",
      "The representation loss after processing this batch is:  0.0029653646051883698\n",
      "\n",
      "The classification loss after processing this batch is:  0.12417292594909668\n",
      "The representation loss after processing this batch is:  0.003241695463657379\n",
      "\n",
      "The classification loss after processing this batch is:  0.2123292088508606\n",
      "The representation loss after processing this batch is:  0.0024820230901241302\n",
      "\n",
      "The classification loss after processing this batch is:  0.14510419964790344\n",
      "The representation loss after processing this batch is:  0.002516530454158783\n",
      "\n",
      "The classification loss after processing this batch is:  0.04322189465165138\n",
      "The representation loss after processing this batch is:  0.002893581986427307\n",
      "\n",
      "The classification loss after processing this batch is:  0.12507282197475433\n",
      "The representation loss after processing this batch is:  0.002618134021759033\n",
      "\n",
      "The classification loss after processing this batch is:  0.26822996139526367\n",
      "The representation loss after processing this batch is:  0.003032296895980835\n",
      "\n",
      "The classification loss after processing this batch is:  0.31844252347946167\n",
      "The representation loss after processing this batch is:  0.002854175865650177\n",
      "\n",
      "The classification loss after processing this batch is:  0.28556695580482483\n",
      "The representation loss after processing this batch is:  0.002521451562643051\n",
      "\n",
      "The classification loss after processing this batch is:  0.19905391335487366\n",
      "The representation loss after processing this batch is:  0.0023058317601680756\n",
      "\n",
      "The classification loss after processing this batch is:  0.10900262743234634\n",
      "The representation loss after processing this batch is:  0.0026324838399887085\n",
      "\n",
      "The classification loss after processing this batch is:  0.12775912880897522\n",
      "The representation loss after processing this batch is:  0.002687878906726837\n",
      "\n",
      "The classification loss after processing this batch is:  0.11275938153266907\n",
      "The representation loss after processing this batch is:  0.003119826316833496\n",
      "\n",
      "The classification loss after processing this batch is:  0.17199872434139252\n",
      "The representation loss after processing this batch is:  0.003088831901550293\n",
      "\n",
      "The classification loss after processing this batch is:  0.13583402335643768\n",
      "The representation loss after processing this batch is:  0.003136090934276581\n",
      "\n",
      "The classification loss after processing this batch is:  0.15030650794506073\n",
      "The representation loss after processing this batch is:  0.003053903579711914\n",
      "\n",
      "The classification loss after processing this batch is:  0.12375058978796005\n",
      "The representation loss after processing this batch is:  0.0027878396213054657\n",
      "\n",
      "The classification loss after processing this batch is:  0.09331916272640228\n",
      "The representation loss after processing this batch is:  0.00266990065574646\n",
      "\n",
      "The classification loss after processing this batch is:  0.19669373333454132\n",
      "The representation loss after processing this batch is:  0.0028984099626541138\n",
      "\n",
      "The classification loss after processing this batch is:  0.1687900424003601\n",
      "The representation loss after processing this batch is:  0.0026709362864494324\n",
      "\n",
      "The classification loss after processing this batch is:  0.12472391128540039\n",
      "The representation loss after processing this batch is:  0.0027014948427677155\n",
      "\n",
      "The classification loss after processing this batch is:  0.2734604775905609\n",
      "The representation loss after processing this batch is:  0.003501061350107193\n",
      "\n",
      "The classification loss after processing this batch is:  0.2961481809616089\n",
      "The representation loss after processing this batch is:  0.002994135022163391\n",
      "\n",
      "The classification loss after processing this batch is:  0.17894035577774048\n",
      "The representation loss after processing this batch is:  0.002828054130077362\n",
      "\n",
      "The classification loss after processing this batch is:  0.1276845633983612\n",
      "The representation loss after processing this batch is:  0.0029518157243728638\n",
      "\n",
      "The classification loss after processing this batch is:  0.12893596291542053\n",
      "The representation loss after processing this batch is:  0.0028456225991249084\n",
      "\n",
      "The classification loss after processing this batch is:  0.07388066500425339\n",
      "The representation loss after processing this batch is:  0.002789631485939026\n",
      "\n",
      "The classification loss after processing this batch is:  0.21901346743106842\n",
      "The representation loss after processing this batch is:  0.002842143177986145\n",
      "\n",
      "The classification loss after processing this batch is:  0.17022983729839325\n",
      "The representation loss after processing this batch is:  0.002968624234199524\n",
      "\n",
      "The classification loss after processing this batch is:  0.14294733107089996\n",
      "The representation loss after processing this batch is:  0.002858467400074005\n",
      "\n",
      "The classification loss after processing this batch is:  0.2798251509666443\n",
      "The representation loss after processing this batch is:  0.0026811063289642334\n",
      "\n",
      "The classification loss after processing this batch is:  0.07313448935747147\n",
      "The representation loss after processing this batch is:  0.002720113843679428\n",
      "\n",
      "The classification loss after processing this batch is:  0.08875247091054916\n",
      "The representation loss after processing this batch is:  0.0031077638268470764\n",
      "\n",
      "The classification loss after processing this batch is:  0.08015993237495422\n",
      "The representation loss after processing this batch is:  0.0024433434009552\n",
      "\n",
      "The classification loss after processing this batch is:  0.20191128551959991\n",
      "The representation loss after processing this batch is:  0.002603963017463684\n",
      "\n",
      "The classification loss after processing this batch is:  0.22493155300617218\n",
      "The representation loss after processing this batch is:  0.00269424170255661\n",
      "\n",
      "The classification loss after processing this batch is:  0.13072258234024048\n",
      "The representation loss after processing this batch is:  0.0024720504879951477\n",
      "\n",
      "The classification loss after processing this batch is:  0.14457911252975464\n",
      "The representation loss after processing this batch is:  0.002620503306388855\n",
      "\n",
      "The classification loss after processing this batch is:  0.059202056378126144\n",
      "The representation loss after processing this batch is:  0.002546742558479309\n",
      "\n",
      "The classification loss after processing this batch is:  0.0968298688530922\n",
      "The representation loss after processing this batch is:  0.002579331398010254\n",
      "\n",
      "The classification loss after processing this batch is:  0.07980012893676758\n",
      "The representation loss after processing this batch is:  0.002718783915042877\n",
      "\n",
      "The classification loss after processing this batch is:  0.06344383955001831\n",
      "The representation loss after processing this batch is:  0.0027561336755752563\n",
      "\n",
      "The classification loss after processing this batch is:  0.11821259558200836\n",
      "The representation loss after processing this batch is:  0.002567555755376816\n",
      "\n",
      "The classification loss after processing this batch is:  0.18631382286548615\n",
      "The representation loss after processing this batch is:  0.0026747658848762512\n",
      "\n",
      "The classification loss after processing this batch is:  0.22478824853897095\n",
      "The representation loss after processing this batch is:  0.0027052685618400574\n",
      "\n",
      "The classification loss after processing this batch is:  0.03652432933449745\n",
      "The representation loss after processing this batch is:  0.002329859882593155\n",
      "\n",
      "The classification loss after processing this batch is:  0.06650831550359726\n",
      "The representation loss after processing this batch is:  0.0028407424688339233\n",
      "\n",
      "The classification loss after processing this batch is:  0.10018391907215118\n",
      "The representation loss after processing this batch is:  0.003032878041267395\n",
      "\n",
      "The classification loss after processing this batch is:  0.18269866704940796\n",
      "The representation loss after processing this batch is:  0.0025797300040721893\n",
      "\n",
      "The classification loss after processing this batch is:  0.08543802052736282\n",
      "The representation loss after processing this batch is:  0.0028619468212127686\n",
      "\n",
      "The classification loss after processing this batch is:  0.22065286338329315\n",
      "The representation loss after processing this batch is:  0.0028379857540130615\n",
      "\n",
      "The classification loss after processing this batch is:  0.24606043100357056\n",
      "The representation loss after processing this batch is:  0.0029315613210201263\n",
      "\n",
      "The classification loss after processing this batch is:  0.1918388158082962\n",
      "The representation loss after processing this batch is:  0.002840619534254074\n",
      "\n",
      "The classification loss after processing this batch is:  0.1459968537092209\n",
      "The representation loss after processing this batch is:  0.002925824373960495\n",
      "\n",
      "The classification loss after processing this batch is:  0.07677195221185684\n",
      "The representation loss after processing this batch is:  0.0027269944548606873\n",
      "\n",
      "The classification loss after processing this batch is:  0.16534163057804108\n",
      "The representation loss after processing this batch is:  0.0025404691696166992\n",
      "\n",
      "The classification loss after processing this batch is:  0.1513727754354477\n",
      "The representation loss after processing this batch is:  0.0027017593383789062\n",
      "\n",
      "The classification loss after processing this batch is:  0.08280609548091888\n",
      "The representation loss after processing this batch is:  0.002650141716003418\n",
      "\n",
      "The classification loss after processing this batch is:  0.06073037534952164\n",
      "The representation loss after processing this batch is:  0.0025689899921417236\n",
      "\n",
      "The classification loss after processing this batch is:  0.21670430898666382\n",
      "The representation loss after processing this batch is:  0.0026796050369739532\n",
      "\n",
      "The classification loss after processing this batch is:  0.22582294046878815\n",
      "The representation loss after processing this batch is:  0.002469535917043686\n",
      "\n",
      "The classification loss after processing this batch is:  0.11770937591791153\n",
      "The representation loss after processing this batch is:  0.0027570202946662903\n",
      "\n",
      "The classification loss after processing this batch is:  0.25329986214637756\n",
      "The representation loss after processing this batch is:  0.002583317458629608\n",
      "\n",
      "The classification loss after processing this batch is:  0.2540626525878906\n",
      "The representation loss after processing this batch is:  0.0026806890964508057\n",
      "\n",
      "The classification loss after processing this batch is:  0.3766627311706543\n",
      "The representation loss after processing this batch is:  0.0023997463285923004\n",
      "\n",
      "The classification loss after processing this batch is:  0.1820528507232666\n",
      "The representation loss after processing this batch is:  0.002771511673927307\n",
      "\n",
      "The classification loss after processing this batch is:  0.12303603440523148\n",
      "The representation loss after processing this batch is:  0.002902492880821228\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.19830824434757233\n",
      "The representation loss after processing this batch is:  0.0027770623564720154\n",
      "\n",
      "The classification loss after processing this batch is:  0.10815612226724625\n",
      "The representation loss after processing this batch is:  0.002839617431163788\n",
      "\n",
      "The classification loss after processing this batch is:  0.08362244814634323\n",
      "The representation loss after processing this batch is:  0.002949364483356476\n",
      "\n",
      "The classification loss after processing this batch is:  0.10737760365009308\n",
      "The representation loss after processing this batch is:  0.002333085983991623\n",
      "\n",
      "The classification loss after processing this batch is:  0.08507803827524185\n",
      "The representation loss after processing this batch is:  0.002885490655899048\n",
      "\n",
      "The classification loss after processing this batch is:  0.043427761644124985\n",
      "The representation loss after processing this batch is:  0.0031571760773658752\n",
      "\n",
      "The classification loss after processing this batch is:  0.1295996457338333\n",
      "The representation loss after processing this batch is:  0.00266912579536438\n",
      "\n",
      "The classification loss after processing this batch is:  0.1812237948179245\n",
      "The representation loss after processing this batch is:  0.002614721655845642\n",
      "\n",
      "The classification loss after processing this batch is:  0.09898652881383896\n",
      "The representation loss after processing this batch is:  0.002757526934146881\n",
      "\n",
      "The classification loss after processing this batch is:  0.10398539155721664\n",
      "The representation loss after processing this batch is:  0.0024702809751033783\n",
      "\n",
      "The classification loss after processing this batch is:  0.16568797826766968\n",
      "The representation loss after processing this batch is:  0.002746105194091797\n",
      "\n",
      "The classification loss after processing this batch is:  0.05383778363466263\n",
      "The representation loss after processing this batch is:  0.0026085227727890015\n",
      "\n",
      "The classification loss after processing this batch is:  0.18957535922527313\n",
      "The representation loss after processing this batch is:  0.002763204276561737\n",
      "\n",
      "The classification loss after processing this batch is:  0.1174330785870552\n",
      "The representation loss after processing this batch is:  0.0024741962552070618\n",
      "\n",
      "The classification loss after processing this batch is:  0.24744366109371185\n",
      "The representation loss after processing this batch is:  0.0026447437703609467\n",
      "\n",
      "The classification loss after processing this batch is:  0.1901950240135193\n",
      "The representation loss after processing this batch is:  0.002526484429836273\n",
      "\n",
      "The classification loss after processing this batch is:  0.18999280035495758\n",
      "The representation loss after processing this batch is:  0.0024425871670246124\n",
      "\n",
      "The classification loss after processing this batch is:  0.04894811287522316\n",
      "The representation loss after processing this batch is:  0.0025890469551086426\n",
      "\n",
      "The classification loss after processing this batch is:  0.056382857263088226\n",
      "The representation loss after processing this batch is:  0.002569757401943207\n",
      "\n",
      "The classification loss after processing this batch is:  0.1579715460538864\n",
      "The representation loss after processing this batch is:  0.002926863729953766\n",
      "\n",
      "The classification loss after processing this batch is:  0.06044428423047066\n",
      "The representation loss after processing this batch is:  0.002959892153739929\n",
      "\n",
      "The classification loss after processing this batch is:  0.16434471309185028\n",
      "The representation loss after processing this batch is:  0.0028180181980133057\n",
      "\n",
      "The classification loss after processing this batch is:  0.09450840950012207\n",
      "The representation loss after processing this batch is:  0.0029833614826202393\n",
      "\n",
      "The classification loss after processing this batch is:  0.10385952144861221\n",
      "The representation loss after processing this batch is:  0.002798318862915039\n",
      "\n",
      "The classification loss after processing this batch is:  0.14949053525924683\n",
      "The representation loss after processing this batch is:  0.002733007073402405\n",
      "\n",
      "The classification loss after processing this batch is:  0.08359592407941818\n",
      "The representation loss after processing this batch is:  0.0028841421008110046\n",
      "\n",
      "The classification loss after processing this batch is:  0.1070811077952385\n",
      "The representation loss after processing this batch is:  0.0033283084630966187\n",
      "\n",
      "The classification loss after processing this batch is:  0.2167731672525406\n",
      "The representation loss after processing this batch is:  0.002719990909099579\n",
      "\n",
      "The classification loss after processing this batch is:  0.16466973721981049\n",
      "The representation loss after processing this batch is:  0.0030023232102394104\n",
      "\n",
      "The classification loss after processing this batch is:  0.22436383366584778\n",
      "The representation loss after processing this batch is:  0.0028457194566726685\n",
      "\n",
      "The classification loss after processing this batch is:  0.2457830011844635\n",
      "The representation loss after processing this batch is:  0.0030266493558883667\n",
      "\n",
      "The classification loss after processing this batch is:  0.1550682634115219\n",
      "The representation loss after processing this batch is:  0.0024358034133911133\n",
      "\n",
      "The classification loss after processing this batch is:  0.10597635805606842\n",
      "The representation loss after processing this batch is:  0.0025479383766651154\n",
      "\n",
      "The classification loss after processing this batch is:  0.06729651987552643\n",
      "The representation loss after processing this batch is:  0.0024631917476654053\n",
      "\n",
      "The classification loss after processing this batch is:  0.09831251949071884\n",
      "The representation loss after processing this batch is:  0.0026949867606163025\n",
      "\n",
      "The classification loss after processing this batch is:  0.07775194942951202\n",
      "The representation loss after processing this batch is:  0.002807728946208954\n",
      "\n",
      "The classification loss after processing this batch is:  0.14952252805233002\n",
      "The representation loss after processing this batch is:  0.002342790365219116\n",
      "\n",
      "The classification loss after processing this batch is:  0.12002640217542648\n",
      "The representation loss after processing this batch is:  0.002902805805206299\n",
      "\n",
      "The classification loss after processing this batch is:  0.15172983705997467\n",
      "The representation loss after processing this batch is:  0.002750381827354431\n",
      "\n",
      "The classification loss after processing this batch is:  0.08357832580804825\n",
      "The representation loss after processing this batch is:  0.002497941255569458\n",
      "\n",
      "The classification loss after processing this batch is:  0.19884485006332397\n",
      "The representation loss after processing this batch is:  0.0024001821875572205\n",
      "\n",
      "The classification loss after processing this batch is:  0.097174271941185\n",
      "The representation loss after processing this batch is:  0.0027369707822799683\n",
      "\n",
      "The classification loss after processing this batch is:  0.173857182264328\n",
      "The representation loss after processing this batch is:  0.0024769455194473267\n",
      "\n",
      "The classification loss after processing this batch is:  0.16987353563308716\n",
      "The representation loss after processing this batch is:  0.0026702880859375\n",
      "\n",
      "The classification loss after processing this batch is:  0.13935710489749908\n",
      "The representation loss after processing this batch is:  0.0027282610535621643\n",
      "\n",
      "The classification loss after processing this batch is:  0.12052319943904877\n",
      "The representation loss after processing this batch is:  0.0027350857853889465\n",
      "\n",
      "The classification loss after processing this batch is:  0.19677022099494934\n",
      "The representation loss after processing this batch is:  0.0028739571571350098\n",
      "\n",
      "The classification loss after processing this batch is:  0.09996374696493149\n",
      "The representation loss after processing this batch is:  0.0026557743549346924\n",
      "\n",
      "The classification loss after processing this batch is:  0.08103401213884354\n",
      "The representation loss after processing this batch is:  0.002603203058242798\n",
      "\n",
      "The classification loss after processing this batch is:  0.10124220699071884\n",
      "The representation loss after processing this batch is:  0.0028566867113113403\n",
      "\n",
      "The classification loss after processing this batch is:  0.09168003499507904\n",
      "The representation loss after processing this batch is:  0.002601116895675659\n",
      "\n",
      "The classification loss after processing this batch is:  0.1862575113773346\n",
      "The representation loss after processing this batch is:  0.0024500563740730286\n",
      "\n",
      "The classification loss after processing this batch is:  0.1761682778596878\n",
      "The representation loss after processing this batch is:  0.002871297299861908\n",
      "\n",
      "The classification loss after processing this batch is:  0.13215990364551544\n",
      "The representation loss after processing this batch is:  0.0029310211539268494\n",
      "\n",
      "The classification loss after processing this batch is:  0.09230518341064453\n",
      "The representation loss after processing this batch is:  0.0027183890342712402\n",
      "\n",
      "The classification loss after processing this batch is:  0.09106341749429703\n",
      "The representation loss after processing this batch is:  0.00283205509185791\n",
      "\n",
      "The classification loss after processing this batch is:  0.2249256819486618\n",
      "The representation loss after processing this batch is:  0.0028576627373695374\n",
      "\n",
      "The classification loss after processing this batch is:  0.06395315378904343\n",
      "The representation loss after processing this batch is:  0.0027369335293769836\n",
      "\n",
      "The classification loss after processing this batch is:  0.11489422619342804\n",
      "The representation loss after processing this batch is:  0.0030448883771896362\n",
      "\n",
      "The classification loss after processing this batch is:  0.18008968234062195\n",
      "The representation loss after processing this batch is:  0.0024878457188606262\n",
      "\n",
      "The classification loss after processing this batch is:  0.30906370282173157\n",
      "The representation loss after processing this batch is:  0.0027915015816688538\n",
      "\n",
      "The classification loss after processing this batch is:  0.09888418018817902\n",
      "The representation loss after processing this batch is:  0.002723991870880127\n",
      "\n",
      "The classification loss after processing this batch is:  0.13640864193439484\n",
      "The representation loss after processing this batch is:  0.002437084913253784\n",
      "\n",
      "The classification loss after processing this batch is:  0.06850910186767578\n",
      "The representation loss after processing this batch is:  0.0027676373720169067\n",
      "\n",
      "The classification loss after processing this batch is:  0.054040685296058655\n",
      "The representation loss after processing this batch is:  0.0024648942053318024\n",
      "\n",
      "The classification loss after processing this batch is:  0.13456936180591583\n",
      "The representation loss after processing this batch is:  0.0032779276371002197\n",
      "\n",
      "The classification loss after processing this batch is:  0.11274610459804535\n",
      "The representation loss after processing this batch is:  0.003331385552883148\n",
      "\n",
      "The classification loss after processing this batch is:  0.07974594086408615\n",
      "The representation loss after processing this batch is:  0.002775028347969055\n",
      "\n",
      "The classification loss after processing this batch is:  0.08728184551000595\n",
      "The representation loss after processing this batch is:  0.0024649202823638916\n",
      "\n",
      "The classification loss after processing this batch is:  0.18701171875\n",
      "The representation loss after processing this batch is:  0.0023633725941181183\n",
      "\n",
      "The classification loss after processing this batch is:  0.1555352360010147\n",
      "The representation loss after processing this batch is:  0.0025399252772331238\n",
      "\n",
      "The classification loss after processing this batch is:  0.08706576377153397\n",
      "The representation loss after processing this batch is:  0.00224912166595459\n",
      "\n",
      "The classification loss after processing this batch is:  0.11060896515846252\n",
      "The representation loss after processing this batch is:  0.00253855437040329\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.24452632665634155\n",
      "The representation loss after processing this batch is:  0.0024282485246658325\n",
      "\n",
      "The classification loss after processing this batch is:  0.2381618767976761\n",
      "The representation loss after processing this batch is:  0.0028922930359840393\n",
      "\n",
      "The classification loss after processing this batch is:  0.19846111536026\n",
      "The representation loss after processing this batch is:  0.002310246229171753\n",
      "\n",
      "The classification loss after processing this batch is:  0.16541044414043427\n",
      "The representation loss after processing this batch is:  0.0030032694339752197\n",
      "\n",
      "The classification loss after processing this batch is:  0.21648000180721283\n",
      "The representation loss after processing this batch is:  0.0024552755057811737\n",
      "\n",
      "The classification loss after processing this batch is:  0.10823190212249756\n",
      "The representation loss after processing this batch is:  0.003279447555541992\n",
      "\n",
      "The classification loss after processing this batch is:  0.10488574951887131\n",
      "The representation loss after processing this batch is:  0.002986699342727661\n",
      "\n",
      "The classification loss after processing this batch is:  0.07012150436639786\n",
      "The representation loss after processing this batch is:  0.002740081399679184\n",
      "\n",
      "The classification loss after processing this batch is:  0.10078659653663635\n",
      "The representation loss after processing this batch is:  0.002354733645915985\n",
      "\n",
      "The classification loss after processing this batch is:  0.20041970908641815\n",
      "The representation loss after processing this batch is:  0.0025183968245983124\n",
      "\n",
      "The classification loss after processing this batch is:  0.10318596661090851\n",
      "The representation loss after processing this batch is:  0.0031538158655166626\n",
      "\n",
      "The classification loss after processing this batch is:  0.06513593345880508\n",
      "The representation loss after processing this batch is:  0.0026593655347824097\n",
      "\n",
      "The classification loss after processing this batch is:  0.04405178129673004\n",
      "The representation loss after processing this batch is:  0.0031815990805625916\n",
      "\n",
      "The classification loss after processing this batch is:  0.055197834968566895\n",
      "The representation loss after processing this batch is:  0.0030372440814971924\n",
      "\n",
      "The classification loss after processing this batch is:  0.07678424566984177\n",
      "The representation loss after processing this batch is:  0.003363966941833496\n",
      "\n",
      "The classification loss after processing this batch is:  0.10749553143978119\n",
      "The representation loss after processing this batch is:  0.0030621960759162903\n",
      "\n",
      "The classification loss after processing this batch is:  0.07424724847078323\n",
      "The representation loss after processing this batch is:  0.002675361931324005\n",
      "\n",
      "The classification loss after processing this batch is:  0.03662935271859169\n",
      "The representation loss after processing this batch is:  0.0031102746725082397\n",
      "\n",
      "The classification loss after processing this batch is:  0.058753326535224915\n",
      "The representation loss after processing this batch is:  0.0036320313811302185\n",
      "\n",
      "The classification loss after processing this batch is:  0.09308046847581863\n",
      "The representation loss after processing this batch is:  0.0036935657262802124\n",
      "\n",
      "The classification loss after processing this batch is:  0.02642921544611454\n",
      "The representation loss after processing this batch is:  0.003904491662979126\n",
      "\n",
      "The classification loss after processing this batch is:  0.06245557963848114\n",
      "The representation loss after processing this batch is:  0.0031125396490097046\n",
      "\n",
      "The classification loss after processing this batch is:  0.17612336575984955\n",
      "The representation loss after processing this batch is:  0.0031315088272094727\n",
      "\n",
      "The classification loss after processing this batch is:  0.04541696608066559\n",
      "The representation loss after processing this batch is:  0.0034898892045021057\n",
      "\n",
      "The classification loss after processing this batch is:  0.019847393035888672\n",
      "The representation loss after processing this batch is:  0.0032336413860321045\n",
      "\n",
      "The classification loss after processing this batch is:  0.032065991312265396\n",
      "The representation loss after processing this batch is:  0.0030216872692108154\n",
      "\n",
      "The classification loss after processing this batch is:  0.05659696087241173\n",
      "The representation loss after processing this batch is:  0.0032123029232025146\n",
      "\n",
      "The classification loss after processing this batch is:  0.04258180037140846\n",
      "The representation loss after processing this batch is:  0.003268703818321228\n",
      "\n",
      "The classification loss after processing this batch is:  0.039248935878276825\n",
      "The representation loss after processing this batch is:  0.003290504217147827\n",
      "\n",
      "The classification loss after processing this batch is:  0.03475109487771988\n",
      "The representation loss after processing this batch is:  0.0034539103507995605\n",
      "\n",
      "The classification loss after processing this batch is:  0.22637805342674255\n",
      "The representation loss after processing this batch is:  0.003821462392807007\n",
      "\n",
      "The classification loss after processing this batch is:  0.29121631383895874\n",
      "The representation loss after processing this batch is:  0.0036882534623146057\n",
      "\n",
      "The classification loss after processing this batch is:  0.21718765795230865\n",
      "The representation loss after processing this batch is:  0.003843732178211212\n",
      "\n",
      "The classification loss after processing this batch is:  0.06369840353727341\n",
      "The representation loss after processing this batch is:  0.002854950726032257\n",
      "\n",
      "The classification loss after processing this batch is:  0.02844892255961895\n",
      "The representation loss after processing this batch is:  0.003483287990093231\n",
      "\n",
      "The classification loss after processing this batch is:  0.03539678826928139\n",
      "The representation loss after processing this batch is:  0.002628706395626068\n",
      "\n",
      "The classification loss after processing this batch is:  0.13081707060337067\n",
      "The representation loss after processing this batch is:  0.002305261790752411\n",
      "\n",
      "The classification loss after processing this batch is:  0.3684817850589752\n",
      "The representation loss after processing this batch is:  0.003156013786792755\n",
      "\n",
      "The classification loss after processing this batch is:  0.08102631568908691\n",
      "The representation loss after processing this batch is:  0.0027502402663230896\n",
      "\n",
      "The classification loss after processing this batch is:  0.05708867684006691\n",
      "The representation loss after processing this batch is:  0.003440745174884796\n",
      "\n",
      "The classification loss after processing this batch is:  0.07566772401332855\n",
      "The representation loss after processing this batch is:  0.0031863898038864136\n",
      "\n",
      "The classification loss after processing this batch is:  0.053412098437547684\n",
      "The representation loss after processing this batch is:  0.003919191658496857\n",
      "\n",
      "The classification loss after processing this batch is:  0.11588915437459946\n",
      "The representation loss after processing this batch is:  0.002504725009202957\n",
      "\n",
      "The classification loss after processing this batch is:  0.06077321618795395\n",
      "The representation loss after processing this batch is:  0.002581275999546051\n",
      "\n",
      "The classification loss after processing this batch is:  0.09487739205360413\n",
      "The representation loss after processing this batch is:  0.002470117062330246\n",
      "\n",
      "The classification loss after processing this batch is:  0.11777445673942566\n",
      "The representation loss after processing this batch is:  0.0024605095386505127\n",
      "\n",
      "The classification loss after processing this batch is:  0.135372593998909\n",
      "The representation loss after processing this batch is:  0.002813763916492462\n",
      "\n",
      "The classification loss after processing this batch is:  0.07781975716352463\n",
      "The representation loss after processing this batch is:  0.003048121929168701\n",
      "\n",
      "The classification loss after processing this batch is:  0.10143984109163284\n",
      "The representation loss after processing this batch is:  0.003059394657611847\n",
      "\n",
      "The classification loss after processing this batch is:  0.110014408826828\n",
      "The representation loss after processing this batch is:  0.002454988658428192\n",
      "\n",
      "The classification loss after processing this batch is:  0.14363569021224976\n",
      "The representation loss after processing this batch is:  0.0024351850152015686\n",
      "\n",
      "The classification loss after processing this batch is:  0.10240764915943146\n",
      "The representation loss after processing this batch is:  0.002681359648704529\n",
      "\n",
      "The classification loss after processing this batch is:  0.17799073457717896\n",
      "The representation loss after processing this batch is:  0.002452123910188675\n",
      "\n",
      "The classification loss after processing this batch is:  0.16380077600479126\n",
      "The representation loss after processing this batch is:  0.0026603303849697113\n",
      "\n",
      "The classification loss after processing this batch is:  0.1851918250322342\n",
      "The representation loss after processing this batch is:  0.003290858119726181\n",
      "\n",
      "The classification loss after processing this batch is:  0.07669317722320557\n",
      "The representation loss after processing this batch is:  0.0026514828205108643\n",
      "\n",
      "The classification loss after processing this batch is:  0.3073592483997345\n",
      "The representation loss after processing this batch is:  0.0026052817702293396\n",
      "\n",
      "The classification loss after processing this batch is:  0.15805330872535706\n",
      "The representation loss after processing this batch is:  0.00229475274682045\n",
      "\n",
      "The classification loss after processing this batch is:  0.13031205534934998\n",
      "The representation loss after processing this batch is:  0.0024339891970157623\n",
      "\n",
      "The classification loss after processing this batch is:  0.24343213438987732\n",
      "The representation loss after processing this batch is:  0.0027315355837345123\n",
      "\n",
      "The classification loss after processing this batch is:  0.18512985110282898\n",
      "The representation loss after processing this batch is:  0.0028614550828933716\n",
      "\n",
      "The classification loss after processing this batch is:  0.0665469542145729\n",
      "The representation loss after processing this batch is:  0.002667441964149475\n",
      "\n",
      "The classification loss after processing this batch is:  0.23292867839336395\n",
      "The representation loss after processing this batch is:  0.0030412226915359497\n",
      "\n",
      "The classification loss after processing this batch is:  0.1470070481300354\n",
      "The representation loss after processing this batch is:  0.002762928605079651\n",
      "\n",
      "The classification loss after processing this batch is:  0.28410547971725464\n",
      "The representation loss after processing this batch is:  0.002501659095287323\n",
      "\n",
      "The classification loss after processing this batch is:  0.09813855588436127\n",
      "The representation loss after processing this batch is:  0.0024306215345859528\n",
      "\n",
      "The classification loss after processing this batch is:  0.07295286655426025\n",
      "The representation loss after processing this batch is:  0.002643890678882599\n",
      "\n",
      "The classification loss after processing this batch is:  0.09296781569719315\n",
      "The representation loss after processing this batch is:  0.002614084631204605\n",
      "\n",
      "The classification loss after processing this batch is:  0.09449192136526108\n",
      "The representation loss after processing this batch is:  0.0021751224994659424\n",
      "\n",
      "The classification loss after processing this batch is:  0.12074639648199081\n",
      "The representation loss after processing this batch is:  0.0026338398456573486\n",
      "\n",
      "The classification loss after processing this batch is:  0.05467161163687706\n",
      "The representation loss after processing this batch is:  0.0027143359184265137\n",
      "\n",
      "The classification loss after processing this batch is:  0.05096687749028206\n",
      "The representation loss after processing this batch is:  0.002857021987438202\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.09157559275627136\n",
      "The representation loss after processing this batch is:  0.002586372196674347\n",
      "\n",
      "The classification loss after processing this batch is:  0.08540328592061996\n",
      "The representation loss after processing this batch is:  0.0030014514923095703\n",
      "\n",
      "The classification loss after processing this batch is:  0.16115345060825348\n",
      "The representation loss after processing this batch is:  0.002640385180711746\n",
      "\n",
      "The classification loss after processing this batch is:  0.09266389161348343\n",
      "The representation loss after processing this batch is:  0.003112509846687317\n",
      "\n",
      "The classification loss after processing this batch is:  0.10423443466424942\n",
      "The representation loss after processing this batch is:  0.002435624599456787\n",
      "\n",
      "The classification loss after processing this batch is:  0.05167084187269211\n",
      "The representation loss after processing this batch is:  0.002709232270717621\n",
      "\n",
      "The classification loss after processing this batch is:  0.06837618350982666\n",
      "The representation loss after processing this batch is:  0.002957988530397415\n",
      "\n",
      "The classification loss after processing this batch is:  0.10098154842853546\n",
      "The representation loss after processing this batch is:  0.0024474933743476868\n",
      "\n",
      "The classification loss after processing this batch is:  0.08752067387104034\n",
      "The representation loss after processing this batch is:  0.0028936639428138733\n",
      "\n",
      "The classification loss after processing this batch is:  0.09118478000164032\n",
      "The representation loss after processing this batch is:  0.002635084092617035\n",
      "\n",
      "The classification loss after processing this batch is:  0.20723597705364227\n",
      "The representation loss after processing this batch is:  0.003026619553565979\n",
      "\n",
      "The classification loss after processing this batch is:  0.1072980985045433\n",
      "The representation loss after processing this batch is:  0.002572886645793915\n",
      "\n",
      "The classification loss after processing this batch is:  0.09651293605566025\n",
      "The representation loss after processing this batch is:  0.0025260671973228455\n",
      "\n",
      "The classification loss after processing this batch is:  0.13780435919761658\n",
      "The representation loss after processing this batch is:  0.0027702972292900085\n",
      "\n",
      "The classification loss after processing this batch is:  0.08259768038988113\n",
      "The representation loss after processing this batch is:  0.002515885978937149\n",
      "\n",
      "The classification loss after processing this batch is:  0.0932675451040268\n",
      "The representation loss after processing this batch is:  0.0024026185274124146\n",
      "\n",
      "The classification loss after processing this batch is:  0.22058574855327606\n",
      "The representation loss after processing this batch is:  0.0030653253197669983\n",
      "\n",
      "The classification loss after processing this batch is:  0.05854245275259018\n",
      "The representation loss after processing this batch is:  0.002615615725517273\n",
      "\n",
      "The classification loss after processing this batch is:  0.12477508932352066\n",
      "The representation loss after processing this batch is:  0.002410970628261566\n",
      "\n",
      "The classification loss after processing this batch is:  0.1067206859588623\n",
      "The representation loss after processing this batch is:  0.002779681235551834\n",
      "\n",
      "The classification loss after processing this batch is:  0.11023961007595062\n",
      "The representation loss after processing this batch is:  0.002340957522392273\n",
      "\n",
      "The classification loss after processing this batch is:  0.12625530362129211\n",
      "The representation loss after processing this batch is:  0.0024022944271564484\n",
      "\n",
      "The classification loss after processing this batch is:  0.07623299211263657\n",
      "The representation loss after processing this batch is:  0.002700474113225937\n",
      "\n",
      "The classification loss after processing this batch is:  0.13095858693122864\n",
      "The representation loss after processing this batch is:  0.0027567222714424133\n",
      "\n",
      "The classification loss after processing this batch is:  0.13372988998889923\n",
      "The representation loss after processing this batch is:  0.002816818654537201\n",
      "\n",
      "The classification loss after processing this batch is:  0.1323341578245163\n",
      "The representation loss after processing this batch is:  0.002799876034259796\n",
      "\n",
      "The classification loss after processing this batch is:  0.14202143251895905\n",
      "The representation loss after processing this batch is:  0.002460569143295288\n",
      "\n",
      "The classification loss after processing this batch is:  0.12772025167942047\n",
      "The representation loss after processing this batch is:  0.0028373822569847107\n",
      "\n",
      "The classification loss after processing this batch is:  0.13888050615787506\n",
      "The representation loss after processing this batch is:  0.002582766115665436\n",
      "\n",
      "The classification loss after processing this batch is:  0.08463624119758606\n",
      "The representation loss after processing this batch is:  0.0024364516139030457\n",
      "\n",
      "The classification loss after processing this batch is:  0.08219155669212341\n",
      "The representation loss after processing this batch is:  0.002331152558326721\n",
      "\n",
      "The classification loss after processing this batch is:  0.19032913446426392\n",
      "The representation loss after processing this batch is:  0.0025873929262161255\n",
      "\n",
      "The classification loss after processing this batch is:  0.17316150665283203\n",
      "The representation loss after processing this batch is:  0.0025923699140548706\n",
      "\n",
      "The classification loss after processing this batch is:  0.08995097130537033\n",
      "The representation loss after processing this batch is:  0.002473551779985428\n",
      "\n",
      "The classification loss after processing this batch is:  0.08185070008039474\n",
      "The representation loss after processing this batch is:  0.0024495869874954224\n",
      "\n",
      "The classification loss after processing this batch is:  0.08433911204338074\n",
      "The representation loss after processing this batch is:  0.002434421330690384\n",
      "\n",
      "The classification loss after processing this batch is:  0.1072673574090004\n",
      "The representation loss after processing this batch is:  0.002746596932411194\n",
      "\n",
      "The classification loss after processing this batch is:  0.15914548933506012\n",
      "The representation loss after processing this batch is:  0.0023594051599502563\n",
      "\n",
      "The classification loss after processing this batch is:  0.07010950893163681\n",
      "The representation loss after processing this batch is:  0.0024488717317581177\n",
      "\n",
      "The classification loss after processing this batch is:  0.23493175208568573\n",
      "The representation loss after processing this batch is:  0.002538330852985382\n",
      "\n",
      "The classification loss after processing this batch is:  0.16341571509838104\n",
      "The representation loss after processing this batch is:  0.0024984925985336304\n",
      "\n",
      "The classification loss after processing this batch is:  0.13844230771064758\n",
      "The representation loss after processing this batch is:  0.002505183219909668\n",
      "\n",
      "The classification loss after processing this batch is:  0.0920189693570137\n",
      "The representation loss after processing this batch is:  0.0022734925150871277\n",
      "\n",
      "The classification loss after processing this batch is:  0.0810151994228363\n",
      "The representation loss after processing this batch is:  0.0026270300149917603\n",
      "\n",
      "The classification loss after processing this batch is:  0.10318037122488022\n",
      "The representation loss after processing this batch is:  0.0023304708302021027\n",
      "\n",
      "The classification loss after processing this batch is:  0.18354421854019165\n",
      "The representation loss after processing this batch is:  0.0024480074644088745\n",
      "\n",
      "The classification loss after processing this batch is:  0.09682813286781311\n",
      "The representation loss after processing this batch is:  0.002377808094024658\n",
      "\n",
      "The classification loss after processing this batch is:  0.2965594530105591\n",
      "The representation loss after processing this batch is:  0.0023560598492622375\n",
      "\n",
      "The classification loss after processing this batch is:  0.12321066111326218\n",
      "The representation loss after processing this batch is:  0.0022563710808753967\n",
      "\n",
      "The classification loss after processing this batch is:  0.07699988037347794\n",
      "The representation loss after processing this batch is:  0.003146819770336151\n",
      "\n",
      "The classification loss after processing this batch is:  0.17647622525691986\n",
      "The representation loss after processing this batch is:  0.0027143433690071106\n",
      "\n",
      "The classification loss after processing this batch is:  0.07523741573095322\n",
      "The representation loss after processing this batch is:  0.002938702702522278\n",
      "\n",
      "The classification loss after processing this batch is:  0.2684617340564728\n",
      "The representation loss after processing this batch is:  0.0028971582651138306\n",
      "\n",
      "The classification loss after processing this batch is:  0.12297912687063217\n",
      "The representation loss after processing this batch is:  0.002493828535079956\n",
      "\n",
      "The classification loss after processing this batch is:  0.17018525302410126\n",
      "The representation loss after processing this batch is:  0.0024557262659072876\n",
      "\n",
      "The classification loss after processing this batch is:  0.2765308916568756\n",
      "The representation loss after processing this batch is:  0.002603743225336075\n",
      "\n",
      "The classification loss after processing this batch is:  0.1650526523590088\n",
      "The representation loss after processing this batch is:  0.0023444145917892456\n",
      "\n",
      "The classification loss after processing this batch is:  0.07770248502492905\n",
      "The representation loss after processing this batch is:  0.0025764480233192444\n",
      "\n",
      "The classification loss after processing this batch is:  0.17576618492603302\n",
      "The representation loss after processing this batch is:  0.002440754324197769\n",
      "\n",
      "The classification loss after processing this batch is:  0.15137717127799988\n",
      "The representation loss after processing this batch is:  0.0025994032621383667\n",
      "\n",
      "The classification loss after processing this batch is:  0.13987042009830475\n",
      "The representation loss after processing this batch is:  0.002649053931236267\n",
      "\n",
      "The classification loss after processing this batch is:  0.08581279963254929\n",
      "The representation loss after processing this batch is:  0.002420566976070404\n",
      "\n",
      "The classification loss after processing this batch is:  0.10022018849849701\n",
      "The representation loss after processing this batch is:  0.002481512725353241\n",
      "\n",
      "The classification loss after processing this batch is:  0.17022551596164703\n",
      "The representation loss after processing this batch is:  0.0024635568261146545\n",
      "\n",
      "The classification loss after processing this batch is:  0.15411125123500824\n",
      "The representation loss after processing this batch is:  0.002987779676914215\n",
      "\n",
      "The classification loss after processing this batch is:  0.18799318373203278\n",
      "The representation loss after processing this batch is:  0.002632439136505127\n",
      "\n",
      "The classification loss after processing this batch is:  0.24818958342075348\n",
      "The representation loss after processing this batch is:  0.0027147382497787476\n",
      "\n",
      "The classification loss after processing this batch is:  0.1783275008201599\n",
      "The representation loss after processing this batch is:  0.002836473286151886\n",
      "\n",
      "The classification loss after processing this batch is:  0.0881478413939476\n",
      "The representation loss after processing this batch is:  0.0029687583446502686\n",
      "\n",
      "The classification loss after processing this batch is:  0.09943854063749313\n",
      "The representation loss after processing this batch is:  0.0025138668715953827\n",
      "\n",
      "The classification loss after processing this batch is:  0.060324300080537796\n",
      "The representation loss after processing this batch is:  0.0025942623615264893\n",
      "\n",
      "The classification loss after processing this batch is:  0.1436198502779007\n",
      "The representation loss after processing this batch is:  0.0028336793184280396\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10854797810316086\n",
      "The representation loss after processing this batch is:  0.002654634416103363\n",
      "\n",
      "The classification loss after processing this batch is:  0.2662625014781952\n",
      "The representation loss after processing this batch is:  0.0026535093784332275\n",
      "\n",
      "The classification loss after processing this batch is:  0.2714892029762268\n",
      "The representation loss after processing this batch is:  0.002573050558567047\n",
      "\n",
      "The classification loss after processing this batch is:  0.11124084889888763\n",
      "The representation loss after processing this batch is:  0.002838931977748871\n",
      "\n",
      "The classification loss after processing this batch is:  0.12940089404582977\n",
      "The representation loss after processing this batch is:  0.0028567835688591003\n",
      "\n",
      "The classification loss after processing this batch is:  0.15984627604484558\n",
      "The representation loss after processing this batch is:  0.0024377554655075073\n",
      "\n",
      "The classification loss after processing this batch is:  0.06894396245479584\n",
      "The representation loss after processing this batch is:  0.002818174660205841\n",
      "\n",
      "The classification loss after processing this batch is:  0.06744620949029922\n",
      "The representation loss after processing this batch is:  0.0027851462364196777\n",
      "\n",
      "The classification loss after processing this batch is:  0.1384345442056656\n",
      "The representation loss after processing this batch is:  0.002394162118434906\n",
      "\n",
      "The classification loss after processing this batch is:  0.10097753256559372\n",
      "The representation loss after processing this batch is:  0.003382951021194458\n",
      "\n",
      "The classification loss after processing this batch is:  0.10276664048433304\n",
      "The representation loss after processing this batch is:  0.0028484612703323364\n",
      "\n",
      "The classification loss after processing this batch is:  0.2625694274902344\n",
      "The representation loss after processing this batch is:  0.003663722425699234\n",
      "\n",
      "The classification loss after processing this batch is:  0.23435598611831665\n",
      "The representation loss after processing this batch is:  0.002405114471912384\n",
      "\n",
      "The classification loss after processing this batch is:  0.13288834691047668\n",
      "The representation loss after processing this batch is:  0.0029008910059928894\n",
      "\n",
      "The classification loss after processing this batch is:  0.21363051235675812\n",
      "The representation loss after processing this batch is:  0.002599157392978668\n",
      "\n",
      "The classification loss after processing this batch is:  0.19125179946422577\n",
      "The representation loss after processing this batch is:  0.0025213658809661865\n",
      "\n",
      "The classification loss after processing this batch is:  0.07978006452322006\n",
      "The representation loss after processing this batch is:  0.0027046315371990204\n",
      "\n",
      "The classification loss after processing this batch is:  0.14560934901237488\n",
      "The representation loss after processing this batch is:  0.002442043274641037\n",
      "\n",
      "The classification loss after processing this batch is:  0.37686389684677124\n",
      "The representation loss after processing this batch is:  0.0030412450432777405\n",
      "\n",
      "The classification loss after processing this batch is:  0.1676476001739502\n",
      "The representation loss after processing this batch is:  0.0028039850294589996\n",
      "\n",
      "The classification loss after processing this batch is:  0.07900776714086533\n",
      "The representation loss after processing this batch is:  0.00299149751663208\n",
      "\n",
      "The classification loss after processing this batch is:  0.08372869342565536\n",
      "The representation loss after processing this batch is:  0.0030526146292686462\n",
      "\n",
      "The classification loss after processing this batch is:  0.06713191419839859\n",
      "The representation loss after processing this batch is:  0.00311453640460968\n",
      "\n",
      "The classification loss after processing this batch is:  0.10827238112688065\n",
      "The representation loss after processing this batch is:  0.0027564018964767456\n",
      "\n",
      "The classification loss after processing this batch is:  0.07832305878400803\n",
      "The representation loss after processing this batch is:  0.0029237493872642517\n",
      "\n",
      "The classification loss after processing this batch is:  0.15336060523986816\n",
      "The representation loss after processing this batch is:  0.0024255365133285522\n",
      "\n",
      "The classification loss after processing this batch is:  0.11487722396850586\n",
      "The representation loss after processing this batch is:  0.002587631344795227\n",
      "\n",
      "The classification loss after processing this batch is:  0.2137213498353958\n",
      "The representation loss after processing this batch is:  0.002511456608772278\n",
      "\n",
      "The classification loss after processing this batch is:  0.10222702473402023\n",
      "The representation loss after processing this batch is:  0.002430323511362076\n",
      "\n",
      "The classification loss after processing this batch is:  0.11776216328144073\n",
      "The representation loss after processing this batch is:  0.002497360110282898\n",
      "\n",
      "The classification loss after processing this batch is:  0.15899063646793365\n",
      "The representation loss after processing this batch is:  0.002505183219909668\n",
      "\n",
      "The classification loss after processing this batch is:  0.14337457716464996\n",
      "The representation loss after processing this batch is:  0.002653505653142929\n",
      "\n",
      "The classification loss after processing this batch is:  0.07727847993373871\n",
      "The representation loss after processing this batch is:  0.002355054020881653\n",
      "\n",
      "The classification loss after processing this batch is:  0.17487117648124695\n",
      "The representation loss after processing this batch is:  0.002538636326789856\n",
      "\n",
      "The classification loss after processing this batch is:  0.1846093386411667\n",
      "The representation loss after processing this batch is:  0.0025504156947135925\n",
      "\n",
      "The classification loss after processing this batch is:  0.16160570085048676\n",
      "The representation loss after processing this batch is:  0.0023060105741024017\n",
      "\n",
      "The classification loss after processing this batch is:  0.1428111046552658\n",
      "The representation loss after processing this batch is:  0.0027911290526390076\n",
      "\n",
      "The classification loss after processing this batch is:  0.18402688205242157\n",
      "The representation loss after processing this batch is:  0.002673804759979248\n",
      "\n",
      "The classification loss after processing this batch is:  0.2232964187860489\n",
      "The representation loss after processing this batch is:  0.0027679093182086945\n",
      "\n",
      "The classification loss after processing this batch is:  0.17233365774154663\n",
      "The representation loss after processing this batch is:  0.0028931573033332825\n",
      "\n",
      "The classification loss after processing this batch is:  0.10583610087633133\n",
      "The representation loss after processing this batch is:  0.0029147565364837646\n",
      "\n",
      "The classification loss after processing this batch is:  0.11082679778337479\n",
      "The representation loss after processing this batch is:  0.00303708016872406\n",
      "\n",
      "The classification loss after processing this batch is:  0.24779722094535828\n",
      "The representation loss after processing this batch is:  0.0024910978972911835\n",
      "\n",
      "The classification loss after processing this batch is:  0.19253619015216827\n",
      "The representation loss after processing this batch is:  0.0024764761328697205\n",
      "\n",
      "The classification loss after processing this batch is:  0.26545435190200806\n",
      "The representation loss after processing this batch is:  0.0028698258101940155\n",
      "\n",
      "The classification loss after processing this batch is:  0.28860992193222046\n",
      "The representation loss after processing this batch is:  0.0023194551467895508\n",
      "\n",
      "The classification loss after processing this batch is:  0.18996506929397583\n",
      "The representation loss after processing this batch is:  0.0025096572935581207\n",
      "\n",
      "The classification loss after processing this batch is:  0.10214266926050186\n",
      "The representation loss after processing this batch is:  0.0026765987277030945\n",
      "\n",
      "The classification loss after processing this batch is:  0.08973280340433121\n",
      "The representation loss after processing this batch is:  0.002541564404964447\n",
      "\n",
      "The classification loss after processing this batch is:  0.0643773227930069\n",
      "The representation loss after processing this batch is:  0.002989530563354492\n",
      "\n",
      "The classification loss after processing this batch is:  0.13249097764492035\n",
      "The representation loss after processing this batch is:  0.0031414180994033813\n",
      "\n",
      "The classification loss after processing this batch is:  0.06919345259666443\n",
      "The representation loss after processing this batch is:  0.0027113929390907288\n",
      "\n",
      "The classification loss after processing this batch is:  0.18230700492858887\n",
      "The representation loss after processing this batch is:  0.0036674514412879944\n",
      "\n",
      "The classification loss after processing this batch is:  0.1283639818429947\n",
      "The representation loss after processing this batch is:  0.002620302140712738\n",
      "\n",
      "The classification loss after processing this batch is:  0.11461029201745987\n",
      "The representation loss after processing this batch is:  0.0026158951222896576\n",
      "\n",
      "The classification loss after processing this batch is:  0.20571552217006683\n",
      "The representation loss after processing this batch is:  0.002499207854270935\n",
      "\n",
      "The classification loss after processing this batch is:  0.10328236222267151\n",
      "The representation loss after processing this batch is:  0.0028765052556991577\n",
      "\n",
      "The classification loss after processing this batch is:  0.1459900289773941\n",
      "The representation loss after processing this batch is:  0.003596007823944092\n",
      "\n",
      "The classification loss after processing this batch is:  0.25041723251342773\n",
      "The representation loss after processing this batch is:  0.003467559814453125\n",
      "\n",
      "The classification loss after processing this batch is:  0.1371859610080719\n",
      "The representation loss after processing this batch is:  0.002812124788761139\n",
      "\n",
      "The classification loss after processing this batch is:  0.14222291111946106\n",
      "The representation loss after processing this batch is:  0.0024758577346801758\n",
      "\n",
      "The classification loss after processing this batch is:  0.0742165818810463\n",
      "The representation loss after processing this batch is:  0.0024060383439064026\n",
      "\n",
      "The classification loss after processing this batch is:  0.04150727018713951\n",
      "The representation loss after processing this batch is:  0.002931170165538788\n",
      "\n",
      "The classification loss after processing this batch is:  0.07288816571235657\n",
      "The representation loss after processing this batch is:  0.002999447286128998\n",
      "\n",
      "The classification loss after processing this batch is:  0.08148963749408722\n",
      "The representation loss after processing this batch is:  0.0027705617249011993\n",
      "\n",
      "The classification loss after processing this batch is:  0.1229998916387558\n",
      "The representation loss after processing this batch is:  0.0023470669984817505\n",
      "\n",
      "The classification loss after processing this batch is:  0.10909492522478104\n",
      "The representation loss after processing this batch is:  0.002849891781806946\n",
      "\n",
      "The classification loss after processing this batch is:  0.14852409064769745\n",
      "The representation loss after processing this batch is:  0.002795994281768799\n",
      "\n",
      "The classification loss after processing this batch is:  0.3346972167491913\n",
      "The representation loss after processing this batch is:  0.002875998616218567\n",
      "\n",
      "The classification loss after processing this batch is:  0.2514742314815521\n",
      "The representation loss after processing this batch is:  0.00269944965839386\n",
      "\n",
      "The classification loss after processing this batch is:  0.10735511779785156\n",
      "The representation loss after processing this batch is:  0.002611979842185974\n",
      "\n",
      "The classification loss after processing this batch is:  0.07953792065382004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.002740524709224701\n",
      "\n",
      "The classification loss after processing this batch is:  0.11614135652780533\n",
      "The representation loss after processing this batch is:  0.002628698945045471\n",
      "\n",
      "The classification loss after processing this batch is:  0.10131663829088211\n",
      "The representation loss after processing this batch is:  0.0025588199496269226\n",
      "\n",
      "The classification loss after processing this batch is:  0.049655117094516754\n",
      "The representation loss after processing this batch is:  0.002609550952911377\n",
      "\n",
      "The classification loss after processing this batch is:  0.06332697719335556\n",
      "The representation loss after processing this batch is:  0.002800416201353073\n",
      "\n",
      "The classification loss after processing this batch is:  0.10715209692716599\n",
      "The representation loss after processing this batch is:  0.0023788996040821075\n",
      "\n",
      "The classification loss after processing this batch is:  0.1557280570268631\n",
      "The representation loss after processing this batch is:  0.0026008151471614838\n",
      "\n",
      "The classification loss after processing this batch is:  0.08834102749824524\n",
      "The representation loss after processing this batch is:  0.002856522798538208\n",
      "\n",
      "The classification loss after processing this batch is:  0.07914233207702637\n",
      "The representation loss after processing this batch is:  0.002641148865222931\n",
      "\n",
      "The classification loss after processing this batch is:  0.07140152901411057\n",
      "The representation loss after processing this batch is:  0.002405688166618347\n",
      "\n",
      "The classification loss after processing this batch is:  0.2690748870372772\n",
      "The representation loss after processing this batch is:  0.002401195466518402\n",
      "\n",
      "The classification loss after processing this batch is:  0.1197318509221077\n",
      "The representation loss after processing this batch is:  0.0028065666556358337\n",
      "\n",
      "The classification loss after processing this batch is:  0.062152571976184845\n",
      "The representation loss after processing this batch is:  0.002764452248811722\n",
      "\n",
      "The classification loss after processing this batch is:  0.1578686386346817\n",
      "The representation loss after processing this batch is:  0.002652980387210846\n",
      "\n",
      "The classification loss after processing this batch is:  0.107512928545475\n",
      "The representation loss after processing this batch is:  0.0025204792618751526\n",
      "\n",
      "The classification loss after processing this batch is:  0.06648486107587814\n",
      "The representation loss after processing this batch is:  0.0024241991341114044\n",
      "\n",
      "The classification loss after processing this batch is:  0.13892967998981476\n",
      "The representation loss after processing this batch is:  0.0025655999779701233\n",
      "\n",
      "The classification loss after processing this batch is:  0.06460447609424591\n",
      "The representation loss after processing this batch is:  0.002284109592437744\n",
      "\n",
      "The classification loss after processing this batch is:  0.07011640816926956\n",
      "The representation loss after processing this batch is:  0.002784356474876404\n",
      "\n",
      "The classification loss after processing this batch is:  0.12964755296707153\n",
      "The representation loss after processing this batch is:  0.002239268273115158\n",
      "\n",
      "The classification loss after processing this batch is:  0.17907415330410004\n",
      "The representation loss after processing this batch is:  0.0026308149099349976\n",
      "\n",
      "The classification loss after processing this batch is:  0.13064268231391907\n",
      "The representation loss after processing this batch is:  0.0026414841413497925\n",
      "\n",
      "The classification loss after processing this batch is:  0.17691639065742493\n",
      "The representation loss after processing this batch is:  0.002535555511713028\n",
      "\n",
      "The classification loss after processing this batch is:  0.11906849592924118\n",
      "The representation loss after processing this batch is:  0.0025067031383514404\n",
      "\n",
      "The classification loss after processing this batch is:  0.1722629815340042\n",
      "The representation loss after processing this batch is:  0.0026141777634620667\n",
      "\n",
      "The classification loss after processing this batch is:  0.09161046147346497\n",
      "The representation loss after processing this batch is:  0.0027763396501541138\n",
      "\n",
      "The classification loss after processing this batch is:  0.1397145688533783\n",
      "The representation loss after processing this batch is:  0.0026077181100845337\n",
      "\n",
      "The classification loss after processing this batch is:  0.07684088498353958\n",
      "The representation loss after processing this batch is:  0.00254223495721817\n",
      "\n",
      "The classification loss after processing this batch is:  0.1782427430152893\n",
      "The representation loss after processing this batch is:  0.0025904327630996704\n",
      "\n",
      "The classification loss after processing this batch is:  0.10521717369556427\n",
      "The representation loss after processing this batch is:  0.0028722211718559265\n",
      "\n",
      "The classification loss after processing this batch is:  0.1868380904197693\n",
      "The representation loss after processing this batch is:  0.002434905618429184\n",
      "\n",
      "The classification loss after processing this batch is:  0.12357227504253387\n",
      "The representation loss after processing this batch is:  0.002341862767934799\n",
      "\n",
      "The classification loss after processing this batch is:  0.12469985336065292\n",
      "The representation loss after processing this batch is:  0.0026668012142181396\n",
      "\n",
      "The classification loss after processing this batch is:  0.1620190292596817\n",
      "The representation loss after processing this batch is:  0.00246322900056839\n",
      "\n",
      "The classification loss after processing this batch is:  0.11138138175010681\n",
      "The representation loss after processing this batch is:  0.0024983324110507965\n",
      "\n",
      "The classification loss after processing this batch is:  0.161212757229805\n",
      "The representation loss after processing this batch is:  0.0027072392404079437\n",
      "\n",
      "The classification loss after processing this batch is:  0.220797598361969\n",
      "The representation loss after processing this batch is:  0.002348635345697403\n",
      "\n",
      "The classification loss after processing this batch is:  0.2638274133205414\n",
      "The representation loss after processing this batch is:  0.0022711940109729767\n",
      "\n",
      "The classification loss after processing this batch is:  0.21466872096061707\n",
      "The representation loss after processing this batch is:  0.0024910196661949158\n",
      "\n",
      "The classification loss after processing this batch is:  0.085850290954113\n",
      "The representation loss after processing this batch is:  0.002719193696975708\n",
      "\n",
      "The classification loss after processing this batch is:  0.16408760845661163\n",
      "The representation loss after processing this batch is:  0.0028853416442871094\n",
      "\n",
      "The classification loss after processing this batch is:  0.10737176984548569\n",
      "The representation loss after processing this batch is:  0.0028253644704818726\n",
      "\n",
      "The classification loss after processing this batch is:  0.12198303639888763\n",
      "The representation loss after processing this batch is:  0.0028794333338737488\n",
      "\n",
      "The classification loss after processing this batch is:  0.18618112802505493\n",
      "The representation loss after processing this batch is:  0.002966754138469696\n",
      "\n",
      "The classification loss after processing this batch is:  0.2678294777870178\n",
      "The representation loss after processing this batch is:  0.0027787014842033386\n",
      "\n",
      "The classification loss after processing this batch is:  0.3494267165660858\n",
      "The representation loss after processing this batch is:  0.0023632608354091644\n",
      "\n",
      "The classification loss after processing this batch is:  0.17371836304664612\n",
      "The representation loss after processing this batch is:  0.0027422383427619934\n",
      "\n",
      "The classification loss after processing this batch is:  0.08896417915821075\n",
      "The representation loss after processing this batch is:  0.0028054825961589813\n",
      "\n",
      "The classification loss after processing this batch is:  0.10189750790596008\n",
      "The representation loss after processing this batch is:  0.0026946961879730225\n",
      "\n",
      "The classification loss after processing this batch is:  0.19144859910011292\n",
      "The representation loss after processing this batch is:  0.0026173852384090424\n",
      "\n",
      "The classification loss after processing this batch is:  0.10030906647443771\n",
      "The representation loss after processing this batch is:  0.002907104790210724\n",
      "\n",
      "The classification loss after processing this batch is:  0.11294230073690414\n",
      "The representation loss after processing this batch is:  0.002549603581428528\n",
      "\n",
      "The classification loss after processing this batch is:  0.11758187413215637\n",
      "The representation loss after processing this batch is:  0.0026345103979110718\n",
      "\n",
      "The classification loss after processing this batch is:  0.038636934012174606\n",
      "The representation loss after processing this batch is:  0.0028158575296401978\n",
      "\n",
      "The classification loss after processing this batch is:  0.10353599488735199\n",
      "The representation loss after processing this batch is:  0.0029514916241168976\n",
      "\n",
      "The classification loss after processing this batch is:  0.15247535705566406\n",
      "The representation loss after processing this batch is:  0.002746887505054474\n",
      "\n",
      "The classification loss after processing this batch is:  0.1919076144695282\n",
      "The representation loss after processing this batch is:  0.002301715314388275\n",
      "\n",
      "The classification loss after processing this batch is:  0.13941176235675812\n",
      "The representation loss after processing this batch is:  0.0026365667581558228\n",
      "\n",
      "The classification loss after processing this batch is:  0.11353961378335953\n",
      "The representation loss after processing this batch is:  0.0026032105088233948\n",
      "\n",
      "The classification loss after processing this batch is:  0.1704498678445816\n",
      "The representation loss after processing this batch is:  0.0029220134019851685\n",
      "\n",
      "The classification loss after processing this batch is:  0.09163784980773926\n",
      "The representation loss after processing this batch is:  0.0028237514197826385\n",
      "\n",
      "The classification loss after processing this batch is:  0.12337175756692886\n",
      "The representation loss after processing this batch is:  0.002988003194332123\n",
      "\n",
      "The classification loss after processing this batch is:  0.14097149670124054\n",
      "The representation loss after processing this batch is:  0.002812713384628296\n",
      "\n",
      "The classification loss after processing this batch is:  0.15595486760139465\n",
      "The representation loss after processing this batch is:  0.0025823041796684265\n",
      "\n",
      "The classification loss after processing this batch is:  0.15029138326644897\n",
      "The representation loss after processing this batch is:  0.002620898187160492\n",
      "\n",
      "The classification loss after processing this batch is:  0.25439929962158203\n",
      "The representation loss after processing this batch is:  0.002491503953933716\n",
      "\n",
      "The classification loss after processing this batch is:  0.2976096570491791\n",
      "The representation loss after processing this batch is:  0.0025659725069999695\n",
      "\n",
      "The classification loss after processing this batch is:  0.08996812999248505\n",
      "The representation loss after processing this batch is:  0.002489738166332245\n",
      "\n",
      "The classification loss after processing this batch is:  0.12544986605644226\n",
      "The representation loss after processing this batch is:  0.0027998611330986023\n",
      "\n",
      "The classification loss after processing this batch is:  0.128783717751503\n",
      "The representation loss after processing this batch is:  0.00277496874332428\n",
      "\n",
      "The classification loss after processing this batch is:  0.16873012483119965\n",
      "The representation loss after processing this batch is:  0.002625260502099991\n",
      "\n",
      "The classification loss after processing this batch is:  0.24211004376411438\n",
      "The representation loss after processing this batch is:  0.00287424772977829\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.21715082228183746\n",
      "The representation loss after processing this batch is:  0.00299198180437088\n",
      "\n",
      "The classification loss after processing this batch is:  0.266963928937912\n",
      "The representation loss after processing this batch is:  0.0031706392765045166\n",
      "\n",
      "The classification loss after processing this batch is:  0.13729919493198395\n",
      "The representation loss after processing this batch is:  0.0031227320432662964\n",
      "\n",
      "The classification loss after processing this batch is:  0.1701558232307434\n",
      "The representation loss after processing this batch is:  0.002925671637058258\n",
      "\n",
      "The classification loss after processing this batch is:  0.15381470322608948\n",
      "The representation loss after processing this batch is:  0.003230758011341095\n",
      "\n",
      "The classification loss after processing this batch is:  0.08987811952829361\n",
      "The representation loss after processing this batch is:  0.0027736425399780273\n",
      "\n",
      "The classification loss after processing this batch is:  0.2180650383234024\n",
      "The representation loss after processing this batch is:  0.002840731292963028\n",
      "\n",
      "The classification loss after processing this batch is:  0.13500718772411346\n",
      "The representation loss after processing this batch is:  0.0025496818125247955\n",
      "\n",
      "The classification loss after processing this batch is:  0.06672782450914383\n",
      "The representation loss after processing this batch is:  0.0025686509907245636\n",
      "\n",
      "The classification loss after processing this batch is:  0.10727204382419586\n",
      "The representation loss after processing this batch is:  0.002444334328174591\n",
      "\n",
      "The classification loss after processing this batch is:  0.12918739020824432\n",
      "The representation loss after processing this batch is:  0.0029133930802345276\n",
      "\n",
      "The classification loss after processing this batch is:  0.16028520464897156\n",
      "The representation loss after processing this batch is:  0.002485256642103195\n",
      "\n",
      "The classification loss after processing this batch is:  0.09904594719409943\n",
      "The representation loss after processing this batch is:  0.0025932863354682922\n",
      "\n",
      "The classification loss after processing this batch is:  0.10397045314311981\n",
      "The representation loss after processing this batch is:  0.002423606812953949\n",
      "\n",
      "The classification loss after processing this batch is:  0.0580347403883934\n",
      "The representation loss after processing this batch is:  0.002558797597885132\n",
      "\n",
      "The classification loss after processing this batch is:  0.13721337914466858\n",
      "The representation loss after processing this batch is:  0.002225089818239212\n",
      "\n",
      "The classification loss after processing this batch is:  0.11422409117221832\n",
      "The representation loss after processing this batch is:  0.0023068413138389587\n",
      "\n",
      "The classification loss after processing this batch is:  0.45271220803260803\n",
      "The representation loss after processing this batch is:  0.002672433853149414\n",
      "\n",
      "The classification loss after processing this batch is:  0.13056765496730804\n",
      "The representation loss after processing this batch is:  0.0027250684797763824\n",
      "\n",
      "The classification loss after processing this batch is:  0.20707865059375763\n",
      "The representation loss after processing this batch is:  0.0024219080805778503\n",
      "\n",
      "The classification loss after processing this batch is:  0.25045573711395264\n",
      "The representation loss after processing this batch is:  0.0026944130659103394\n",
      "\n",
      "The classification loss after processing this batch is:  0.11064749211072922\n",
      "The representation loss after processing this batch is:  0.002347208559513092\n",
      "\n",
      "The classification loss after processing this batch is:  0.26972752809524536\n",
      "The representation loss after processing this batch is:  0.002911791205406189\n",
      "\n",
      "The classification loss after processing this batch is:  0.13966010510921478\n",
      "The representation loss after processing this batch is:  0.00280965119600296\n",
      "\n",
      "The classification loss after processing this batch is:  0.24782361090183258\n",
      "The representation loss after processing this batch is:  0.0023172013461589813\n",
      "\n",
      "The classification loss after processing this batch is:  0.07168502360582352\n",
      "The representation loss after processing this batch is:  0.0023257359862327576\n",
      "\n",
      "The classification loss after processing this batch is:  0.12173774838447571\n",
      "The representation loss after processing this batch is:  0.0026815757155418396\n",
      "\n",
      "The classification loss after processing this batch is:  0.04720747098326683\n",
      "The representation loss after processing this batch is:  0.0028105899691581726\n",
      "\n",
      "The classification loss after processing this batch is:  0.048705317080020905\n",
      "The representation loss after processing this batch is:  0.0026569589972496033\n",
      "\n",
      "The classification loss after processing this batch is:  0.08625315874814987\n",
      "The representation loss after processing this batch is:  0.0025588497519493103\n",
      "\n",
      "The classification loss after processing this batch is:  0.07394979894161224\n",
      "The representation loss after processing this batch is:  0.002450495958328247\n",
      "\n",
      "The classification loss after processing this batch is:  0.15392757952213287\n",
      "The representation loss after processing this batch is:  0.0027244389057159424\n",
      "\n",
      "The classification loss after processing this batch is:  0.10465431958436966\n",
      "The representation loss after processing this batch is:  0.003044731914997101\n",
      "\n",
      "The classification loss after processing this batch is:  0.08766581118106842\n",
      "The representation loss after processing this batch is:  0.002518661320209503\n",
      "\n",
      "The classification loss after processing this batch is:  0.16800574958324432\n",
      "The representation loss after processing this batch is:  0.0022104009985923767\n",
      "\n",
      "The classification loss after processing this batch is:  0.10448653995990753\n",
      "The representation loss after processing this batch is:  0.0029224082827568054\n",
      "\n",
      "The classification loss after processing this batch is:  0.11771687120199203\n",
      "The representation loss after processing this batch is:  0.0026690103113651276\n",
      "\n",
      "The classification loss after processing this batch is:  0.13891394436359406\n",
      "The representation loss after processing this batch is:  0.002737760543823242\n",
      "\n",
      "The classification loss after processing this batch is:  0.18857629597187042\n",
      "The representation loss after processing this batch is:  0.0026874467730522156\n",
      "\n",
      "The classification loss after processing this batch is:  0.11572809517383575\n",
      "The representation loss after processing this batch is:  0.002393081784248352\n",
      "\n",
      "The classification loss after processing this batch is:  0.0952029675245285\n",
      "The representation loss after processing this batch is:  0.002384219318628311\n",
      "\n",
      "The classification loss after processing this batch is:  0.2089610993862152\n",
      "The representation loss after processing this batch is:  0.002781696617603302\n",
      "\n",
      "The classification loss after processing this batch is:  0.16670794785022736\n",
      "The representation loss after processing this batch is:  0.0024918466806411743\n",
      "\n",
      "The classification loss after processing this batch is:  0.167836531996727\n",
      "The representation loss after processing this batch is:  0.002530038356781006\n",
      "\n",
      "The classification loss after processing this batch is:  0.06787681579589844\n",
      "The representation loss after processing this batch is:  0.0025520697236061096\n",
      "\n",
      "The classification loss after processing this batch is:  0.14526589214801788\n",
      "The representation loss after processing this batch is:  0.0029439777135849\n",
      "\n",
      "The classification loss after processing this batch is:  0.15541931986808777\n",
      "The representation loss after processing this batch is:  0.002731647342443466\n",
      "\n",
      "The classification loss after processing this batch is:  0.12953399121761322\n",
      "The representation loss after processing this batch is:  0.0029653534293174744\n",
      "\n",
      "The classification loss after processing this batch is:  0.11317682266235352\n",
      "The representation loss after processing this batch is:  0.0033314786851406097\n",
      "\n",
      "The classification loss after processing this batch is:  0.09606529027223587\n",
      "The representation loss after processing this batch is:  0.0033566169440746307\n",
      "\n",
      "The classification loss after processing this batch is:  0.16251009702682495\n",
      "The representation loss after processing this batch is:  0.002902604639530182\n",
      "\n",
      "The classification loss after processing this batch is:  0.19570378959178925\n",
      "The representation loss after processing this batch is:  0.002731017768383026\n",
      "\n",
      "The classification loss after processing this batch is:  0.14104457199573517\n",
      "The representation loss after processing this batch is:  0.003522440791130066\n",
      "\n",
      "The classification loss after processing this batch is:  0.13678154349327087\n",
      "The representation loss after processing this batch is:  0.002842996269464493\n",
      "\n",
      "The classification loss after processing this batch is:  0.06236426904797554\n",
      "The representation loss after processing this batch is:  0.0022084638476371765\n",
      "\n",
      "The classification loss after processing this batch is:  0.2052038162946701\n",
      "The representation loss after processing this batch is:  0.0025573447346687317\n",
      "\n",
      "The classification loss after processing this batch is:  0.09085846692323685\n",
      "The representation loss after processing this batch is:  0.002498030662536621\n",
      "\n",
      "The classification loss after processing this batch is:  0.11330904811620712\n",
      "The representation loss after processing this batch is:  0.002762153744697571\n",
      "\n",
      "The classification loss after processing this batch is:  0.11279471218585968\n",
      "The representation loss after processing this batch is:  0.0028998106718063354\n",
      "\n",
      "The classification loss after processing this batch is:  0.10457868129014969\n",
      "The representation loss after processing this batch is:  0.00256907194852829\n",
      "\n",
      "The classification loss after processing this batch is:  0.12015213817358017\n",
      "The representation loss after processing this batch is:  0.0027657561004161835\n",
      "\n",
      "The classification loss after processing this batch is:  0.16196230053901672\n",
      "The representation loss after processing this batch is:  0.0031631439924240112\n",
      "\n",
      "The classification loss after processing this batch is:  0.1446496993303299\n",
      "The representation loss after processing this batch is:  0.0031492114067077637\n",
      "\n",
      "The classification loss after processing this batch is:  0.1465965062379837\n",
      "The representation loss after processing this batch is:  0.0025759339332580566\n",
      "\n",
      "The classification loss after processing this batch is:  0.16144201159477234\n",
      "The representation loss after processing this batch is:  0.003246437758207321\n",
      "\n",
      "The classification loss after processing this batch is:  0.0836201161146164\n",
      "The representation loss after processing this batch is:  0.002475939691066742\n",
      "\n",
      "The classification loss after processing this batch is:  0.09514256566762924\n",
      "The representation loss after processing this batch is:  0.002534925937652588\n",
      "\n",
      "The classification loss after processing this batch is:  0.08777043968439102\n",
      "The representation loss after processing this batch is:  0.00300704687833786\n",
      "\n",
      "The classification loss after processing this batch is:  0.11030197888612747\n",
      "The representation loss after processing this batch is:  0.002670619636774063\n",
      "\n",
      "The classification loss after processing this batch is:  0.06519804894924164\n",
      "The representation loss after processing this batch is:  0.00257134810090065\n",
      "\n",
      "The classification loss after processing this batch is:  0.06650083512067795\n",
      "The representation loss after processing this batch is:  0.00238761305809021\n",
      "\n",
      "The classification loss after processing this batch is:  0.07823599874973297\n",
      "The representation loss after processing this batch is:  0.0028578490018844604\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.07087216526269913\n",
      "The representation loss after processing this batch is:  0.002730816602706909\n",
      "\n",
      "The classification loss after processing this batch is:  0.16384004056453705\n",
      "The representation loss after processing this batch is:  0.0025636032223701477\n",
      "\n",
      "The classification loss after processing this batch is:  0.10659802705049515\n",
      "The representation loss after processing this batch is:  0.002324730157852173\n",
      "\n",
      "The classification loss after processing this batch is:  0.1431688815355301\n",
      "The representation loss after processing this batch is:  0.0026483237743377686\n",
      "\n",
      "The classification loss after processing this batch is:  0.07039868831634521\n",
      "The representation loss after processing this batch is:  0.002920083701610565\n",
      "\n",
      "The classification loss after processing this batch is:  0.18147630989551544\n",
      "The representation loss after processing this batch is:  0.0025619827210903168\n",
      "\n",
      "The classification loss after processing this batch is:  0.15638169646263123\n",
      "The representation loss after processing this batch is:  0.0026376619935035706\n",
      "\n",
      "The classification loss after processing this batch is:  0.12602540850639343\n",
      "The representation loss after processing this batch is:  0.0025606676936149597\n",
      "\n",
      "The classification loss after processing this batch is:  0.11981818079948425\n",
      "The representation loss after processing this batch is:  0.0027309581637382507\n",
      "\n",
      "The classification loss after processing this batch is:  0.14081671833992004\n",
      "The representation loss after processing this batch is:  0.003015846014022827\n",
      "\n",
      "The classification loss after processing this batch is:  0.06898590177297592\n",
      "The representation loss after processing this batch is:  0.002596713602542877\n",
      "\n",
      "The classification loss after processing this batch is:  0.07196454703807831\n",
      "The representation loss after processing this batch is:  0.0026684701442718506\n",
      "\n",
      "The classification loss after processing this batch is:  0.08320271968841553\n",
      "The representation loss after processing this batch is:  0.002455778419971466\n",
      "\n",
      "The classification loss after processing this batch is:  0.17455895245075226\n",
      "The representation loss after processing this batch is:  0.0027030110359191895\n",
      "\n",
      "The classification loss after processing this batch is:  0.1430789977312088\n",
      "The representation loss after processing this batch is:  0.00247969850897789\n",
      "\n",
      "The classification loss after processing this batch is:  0.13751105964183807\n",
      "The representation loss after processing this batch is:  0.003106728196144104\n",
      "\n",
      "The classification loss after processing this batch is:  0.17351089417934418\n",
      "The representation loss after processing this batch is:  0.0027397647500038147\n",
      "\n",
      "The classification loss after processing this batch is:  0.1466277688741684\n",
      "The representation loss after processing this batch is:  0.002814747393131256\n",
      "\n",
      "The classification loss after processing this batch is:  0.15584738552570343\n",
      "The representation loss after processing this batch is:  0.002471916377544403\n",
      "\n",
      "The classification loss after processing this batch is:  0.28334203362464905\n",
      "The representation loss after processing this batch is:  0.002431076020002365\n",
      "\n",
      "The classification loss after processing this batch is:  0.19281117618083954\n",
      "The representation loss after processing this batch is:  0.00235169380903244\n",
      "\n",
      "The classification loss after processing this batch is:  0.11886873096227646\n",
      "The representation loss after processing this batch is:  0.002299092710018158\n",
      "\n",
      "The classification loss after processing this batch is:  0.08263678103685379\n",
      "The representation loss after processing this batch is:  0.002597235143184662\n",
      "\n",
      "The classification loss after processing this batch is:  0.070108562707901\n",
      "The representation loss after processing this batch is:  0.0024191290140151978\n",
      "\n",
      "The classification loss after processing this batch is:  0.07505708187818527\n",
      "The representation loss after processing this batch is:  0.002556547522544861\n",
      "\n",
      "The classification loss after processing this batch is:  0.08535721898078918\n",
      "The representation loss after processing this batch is:  0.0030426830053329468\n",
      "\n",
      "The classification loss after processing this batch is:  0.13836650550365448\n",
      "The representation loss after processing this batch is:  0.0024384334683418274\n",
      "\n",
      "The classification loss after processing this batch is:  0.10358979552984238\n",
      "The representation loss after processing this batch is:  0.0026457756757736206\n",
      "\n",
      "The classification loss after processing this batch is:  0.20072314143180847\n",
      "The representation loss after processing this batch is:  0.0026793591678142548\n",
      "\n",
      "The classification loss after processing this batch is:  0.154546320438385\n",
      "The representation loss after processing this batch is:  0.0026459023356437683\n",
      "\n",
      "The classification loss after processing this batch is:  0.1897723227739334\n",
      "The representation loss after processing this batch is:  0.0022597424685955048\n",
      "\n",
      "The classification loss after processing this batch is:  0.1294030398130417\n",
      "The representation loss after processing this batch is:  0.002449292689561844\n",
      "\n",
      "The classification loss after processing this batch is:  0.21753151714801788\n",
      "The representation loss after processing this batch is:  0.0024118199944496155\n",
      "\n",
      "The classification loss after processing this batch is:  0.14109160006046295\n",
      "The representation loss after processing this batch is:  0.002435252070426941\n",
      "\n",
      "The classification loss after processing this batch is:  0.10345565527677536\n",
      "The representation loss after processing this batch is:  0.0024332553148269653\n",
      "\n",
      "The classification loss after processing this batch is:  0.1452610194683075\n",
      "The representation loss after processing this batch is:  0.0023628026247024536\n",
      "\n",
      "The classification loss after processing this batch is:  0.07304862886667252\n",
      "The representation loss after processing this batch is:  0.002417493611574173\n",
      "\n",
      "The classification loss after processing this batch is:  0.06294756382703781\n",
      "The representation loss after processing this batch is:  0.0024766214191913605\n",
      "\n",
      "The classification loss after processing this batch is:  0.14978241920471191\n",
      "The representation loss after processing this batch is:  0.0027389004826545715\n",
      "\n",
      "The classification loss after processing this batch is:  0.17869551479816437\n",
      "The representation loss after processing this batch is:  0.002473108470439911\n",
      "\n",
      "The classification loss after processing this batch is:  0.15267686545848846\n",
      "The representation loss after processing this batch is:  0.0026755332946777344\n",
      "\n",
      "The classification loss after processing this batch is:  0.0824972614645958\n",
      "The representation loss after processing this batch is:  0.0027167871594429016\n",
      "\n",
      "The classification loss after processing this batch is:  0.11549592018127441\n",
      "The representation loss after processing this batch is:  0.0028791651129722595\n",
      "\n",
      "The classification loss after processing this batch is:  0.08978653699159622\n",
      "The representation loss after processing this batch is:  0.002667270600795746\n",
      "\n",
      "The classification loss after processing this batch is:  0.2599574029445648\n",
      "The representation loss after processing this batch is:  0.002554573118686676\n",
      "\n",
      "The classification loss after processing this batch is:  0.07742806524038315\n",
      "The representation loss after processing this batch is:  0.002480253577232361\n",
      "\n",
      "The classification loss after processing this batch is:  0.05863969400525093\n",
      "The representation loss after processing this batch is:  0.0026433318853378296\n",
      "\n",
      "The classification loss after processing this batch is:  0.15086786448955536\n",
      "The representation loss after processing this batch is:  0.002972446382045746\n",
      "\n",
      "The classification loss after processing this batch is:  0.1241680309176445\n",
      "The representation loss after processing this batch is:  0.0028423145413398743\n",
      "\n",
      "The classification loss after processing this batch is:  0.09146597236394882\n",
      "The representation loss after processing this batch is:  0.0028434842824935913\n",
      "\n",
      "The classification loss after processing this batch is:  0.07068099081516266\n",
      "The representation loss after processing this batch is:  0.00240321084856987\n",
      "\n",
      "The classification loss after processing this batch is:  0.12465385347604752\n",
      "The representation loss after processing this batch is:  0.0032344013452529907\n",
      "\n",
      "The classification loss after processing this batch is:  0.17168234288692474\n",
      "The representation loss after processing this batch is:  0.003143228590488434\n",
      "\n",
      "The classification loss after processing this batch is:  0.22035427391529083\n",
      "The representation loss after processing this batch is:  0.0025367364287376404\n",
      "\n",
      "The classification loss after processing this batch is:  0.1856027990579605\n",
      "The representation loss after processing this batch is:  0.002899840474128723\n",
      "\n",
      "The classification loss after processing this batch is:  0.07582154870033264\n",
      "The representation loss after processing this batch is:  0.0028488188982009888\n",
      "\n",
      "The classification loss after processing this batch is:  0.08314060419797897\n",
      "The representation loss after processing this batch is:  0.0022543929517269135\n",
      "\n",
      "The classification loss after processing this batch is:  0.1766357719898224\n",
      "The representation loss after processing this batch is:  0.002813369035720825\n",
      "\n",
      "The classification loss after processing this batch is:  0.22316566109657288\n",
      "The representation loss after processing this batch is:  0.002707831561565399\n",
      "\n",
      "The classification loss after processing this batch is:  0.1983102411031723\n",
      "The representation loss after processing this batch is:  0.002703290432691574\n",
      "\n",
      "The classification loss after processing this batch is:  0.25975802540779114\n",
      "The representation loss after processing this batch is:  0.0023979507386684418\n",
      "\n",
      "The classification loss after processing this batch is:  0.12562522292137146\n",
      "The representation loss after processing this batch is:  0.0024319738149642944\n",
      "\n",
      "The classification loss after processing this batch is:  0.19558340311050415\n",
      "The representation loss after processing this batch is:  0.0023751631379127502\n",
      "\n",
      "The classification loss after processing this batch is:  0.10750232636928558\n",
      "The representation loss after processing this batch is:  0.0021878257393836975\n",
      "\n",
      "The classification loss after processing this batch is:  0.10633662343025208\n",
      "The representation loss after processing this batch is:  0.0027377083897590637\n",
      "\n",
      "The classification loss after processing this batch is:  0.07446294277906418\n",
      "The representation loss after processing this batch is:  0.0026677511632442474\n",
      "\n",
      "The classification loss after processing this batch is:  0.1241171732544899\n",
      "The representation loss after processing this batch is:  0.0025984644889831543\n",
      "\n",
      "The classification loss after processing this batch is:  0.16122029721736908\n",
      "The representation loss after processing this batch is:  0.0024331845343112946\n",
      "\n",
      "The classification loss after processing this batch is:  0.10310684144496918\n",
      "The representation loss after processing this batch is:  0.0025502294301986694\n",
      "\n",
      "The classification loss after processing this batch is:  0.16199247539043427\n",
      "The representation loss after processing this batch is:  0.003034919500350952\n",
      "\n",
      "The classification loss after processing this batch is:  0.059545788913965225\n",
      "The representation loss after processing this batch is:  0.0030150115489959717\n",
      "\n",
      "The classification loss after processing this batch is:  0.10152196139097214\n",
      "The representation loss after processing this batch is:  0.0029177889227867126\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.11112675815820694\n",
      "The representation loss after processing this batch is:  0.002520732581615448\n",
      "\n",
      "The classification loss after processing this batch is:  0.20239537954330444\n",
      "The representation loss after processing this batch is:  0.002799421548843384\n",
      "\n",
      "The classification loss after processing this batch is:  0.058138009160757065\n",
      "The representation loss after processing this batch is:  0.0032053142786026\n",
      "\n",
      "The classification loss after processing this batch is:  0.08935552090406418\n",
      "The representation loss after processing this batch is:  0.002525482326745987\n",
      "\n",
      "The classification loss after processing this batch is:  0.17013797163963318\n",
      "The representation loss after processing this batch is:  0.002781391143798828\n",
      "\n",
      "The classification loss after processing this batch is:  0.14408062398433685\n",
      "The representation loss after processing this batch is:  0.0027105845510959625\n",
      "\n",
      "The classification loss after processing this batch is:  0.16787974536418915\n",
      "The representation loss after processing this batch is:  0.0024775341153144836\n",
      "\n",
      "The classification loss after processing this batch is:  0.11061074584722519\n",
      "The representation loss after processing this batch is:  0.0024338550865650177\n",
      "\n",
      "The classification loss after processing this batch is:  0.07506105303764343\n",
      "The representation loss after processing this batch is:  0.0026211775839328766\n",
      "\n",
      "The classification loss after processing this batch is:  0.1198926791548729\n",
      "The representation loss after processing this batch is:  0.0023504942655563354\n",
      "\n",
      "The classification loss after processing this batch is:  0.10492142289876938\n",
      "The representation loss after processing this batch is:  0.0027311593294143677\n",
      "\n",
      "The classification loss after processing this batch is:  0.14269645512104034\n",
      "The representation loss after processing this batch is:  0.0026207715272903442\n",
      "\n",
      "The classification loss after processing this batch is:  0.13531111180782318\n",
      "The representation loss after processing this batch is:  0.003145664930343628\n",
      "\n",
      "The classification loss after processing this batch is:  0.07719399780035019\n",
      "The representation loss after processing this batch is:  0.0025093629956245422\n",
      "\n",
      "The classification loss after processing this batch is:  0.15726338326931\n",
      "The representation loss after processing this batch is:  0.0024374499917030334\n",
      "\n",
      "The classification loss after processing this batch is:  0.20310229063034058\n",
      "The representation loss after processing this batch is:  0.002748638391494751\n",
      "\n",
      "The classification loss after processing this batch is:  0.053434766829013824\n",
      "The representation loss after processing this batch is:  0.0026951953768730164\n",
      "\n",
      "The classification loss after processing this batch is:  0.1161862388253212\n",
      "The representation loss after processing this batch is:  0.0024030692875385284\n",
      "\n",
      "The classification loss after processing this batch is:  0.19986341893672943\n",
      "The representation loss after processing this batch is:  0.0024008043110370636\n",
      "\n",
      "The classification loss after processing this batch is:  0.2031790167093277\n",
      "The representation loss after processing this batch is:  0.002622745931148529\n",
      "\n",
      "The classification loss after processing this batch is:  0.1385652869939804\n",
      "The representation loss after processing this batch is:  0.0024360865354537964\n",
      "\n",
      "The classification loss after processing this batch is:  0.21767927706241608\n",
      "The representation loss after processing this batch is:  0.002437002956867218\n",
      "\n",
      "The classification loss after processing this batch is:  0.16885608434677124\n",
      "The representation loss after processing this batch is:  0.00243503600358963\n",
      "\n",
      "The classification loss after processing this batch is:  0.2111920416355133\n",
      "The representation loss after processing this batch is:  0.0028963759541511536\n",
      "\n",
      "The classification loss after processing this batch is:  0.1198090985417366\n",
      "The representation loss after processing this batch is:  0.002978108823299408\n",
      "\n",
      "The classification loss after processing this batch is:  0.19683298468589783\n",
      "The representation loss after processing this batch is:  0.0025474093854427338\n",
      "\n",
      "The classification loss after processing this batch is:  0.11293544620275497\n",
      "The representation loss after processing this batch is:  0.003772236406803131\n",
      "\n",
      "The classification loss after processing this batch is:  0.08829076588153839\n",
      "The representation loss after processing this batch is:  0.0025581642985343933\n",
      "\n",
      "The classification loss after processing this batch is:  0.1054835096001625\n",
      "The representation loss after processing this batch is:  0.0024411454796791077\n",
      "\n",
      "The classification loss after processing this batch is:  0.09614180028438568\n",
      "The representation loss after processing this batch is:  0.002351924777030945\n",
      "\n",
      "The classification loss after processing this batch is:  0.14287719130516052\n",
      "The representation loss after processing this batch is:  0.0027167946100234985\n",
      "\n",
      "The classification loss after processing this batch is:  0.12202543765306473\n",
      "The representation loss after processing this batch is:  0.002537742257118225\n",
      "\n",
      "The classification loss after processing this batch is:  0.17427019774913788\n",
      "The representation loss after processing this batch is:  0.0026177018880844116\n",
      "\n",
      "The classification loss after processing this batch is:  0.05429781973361969\n",
      "The representation loss after processing this batch is:  0.0026768669486045837\n",
      "\n",
      "The classification loss after processing this batch is:  0.07575039565563202\n",
      "The representation loss after processing this batch is:  0.002978883683681488\n",
      "\n",
      "The classification loss after processing this batch is:  0.17381009459495544\n",
      "The representation loss after processing this batch is:  0.002862676978111267\n",
      "\n",
      "The classification loss after processing this batch is:  0.04453779011964798\n",
      "The representation loss after processing this batch is:  0.0026011765003204346\n",
      "\n",
      "The classification loss after processing this batch is:  0.09552671015262604\n",
      "The representation loss after processing this batch is:  0.002476029098033905\n",
      "\n",
      "The classification loss after processing this batch is:  0.057067468762397766\n",
      "The representation loss after processing this batch is:  0.0026247650384902954\n",
      "\n",
      "The classification loss after processing this batch is:  0.09005720168352127\n",
      "The representation loss after processing this batch is:  0.0024577677249908447\n",
      "\n",
      "The classification loss after processing this batch is:  0.16016076505184174\n",
      "The representation loss after processing this batch is:  0.003094092011451721\n",
      "\n",
      "The classification loss after processing this batch is:  0.16975612938404083\n",
      "The representation loss after processing this batch is:  0.0035749152302742004\n",
      "\n",
      "The classification loss after processing this batch is:  0.16657975316047668\n",
      "The representation loss after processing this batch is:  0.0032856017351150513\n",
      "\n",
      "The classification loss after processing this batch is:  0.09639916568994522\n",
      "The representation loss after processing this batch is:  0.0026364699006080627\n",
      "\n",
      "The classification loss after processing this batch is:  0.12853677570819855\n",
      "The representation loss after processing this batch is:  0.002405967563390732\n",
      "\n",
      "The classification loss after processing this batch is:  0.11681856960058212\n",
      "The representation loss after processing this batch is:  0.002634100615978241\n",
      "\n",
      "The classification loss after processing this batch is:  0.06429794430732727\n",
      "The representation loss after processing this batch is:  0.0028938353061676025\n",
      "\n",
      "The classification loss after processing this batch is:  0.07098080217838287\n",
      "The representation loss after processing this batch is:  0.002635229378938675\n",
      "\n",
      "The classification loss after processing this batch is:  0.05682138726115227\n",
      "The representation loss after processing this batch is:  0.003032110631465912\n",
      "\n",
      "The classification loss after processing this batch is:  0.10174092650413513\n",
      "The representation loss after processing this batch is:  0.002878636121749878\n",
      "\n",
      "The classification loss after processing this batch is:  0.19078698754310608\n",
      "The representation loss after processing this batch is:  0.0028128288686275482\n",
      "\n",
      "The classification loss after processing this batch is:  0.16447687149047852\n",
      "The representation loss after processing this batch is:  0.002421334385871887\n",
      "\n",
      "The classification loss after processing this batch is:  0.13248254358768463\n",
      "The representation loss after processing this batch is:  0.003526359796524048\n",
      "\n",
      "The classification loss after processing this batch is:  0.09784077107906342\n",
      "The representation loss after processing this batch is:  0.002849362790584564\n",
      "\n",
      "The classification loss after processing this batch is:  0.13250404596328735\n",
      "The representation loss after processing this batch is:  0.0026331543922424316\n",
      "\n",
      "The classification loss after processing this batch is:  0.1018143817782402\n",
      "The representation loss after processing this batch is:  0.002555340528488159\n",
      "\n",
      "The classification loss after processing this batch is:  0.3705975115299225\n",
      "The representation loss after processing this batch is:  0.0028403252363204956\n",
      "\n",
      "The classification loss after processing this batch is:  0.10944341123104095\n",
      "The representation loss after processing this batch is:  0.002803519368171692\n",
      "\n",
      "The classification loss after processing this batch is:  0.25490081310272217\n",
      "The representation loss after processing this batch is:  0.0034386590123176575\n",
      "\n",
      "The classification loss after processing this batch is:  0.10993244498968124\n",
      "The representation loss after processing this batch is:  0.002427726984024048\n",
      "\n",
      "The classification loss after processing this batch is:  0.11547814309597015\n",
      "The representation loss after processing this batch is:  0.0025104880332946777\n",
      "\n",
      "The classification loss after processing this batch is:  0.16494327783584595\n",
      "The representation loss after processing this batch is:  0.002374202013015747\n",
      "\n",
      "The classification loss after processing this batch is:  0.12879352271556854\n",
      "The representation loss after processing this batch is:  0.002686653286218643\n",
      "\n",
      "The classification loss after processing this batch is:  0.21874716877937317\n",
      "The representation loss after processing this batch is:  0.00261804461479187\n",
      "\n",
      "The classification loss after processing this batch is:  0.16036424040794373\n",
      "The representation loss after processing this batch is:  0.0029737427830696106\n",
      "\n",
      "The classification loss after processing this batch is:  0.1692502349615097\n",
      "The representation loss after processing this batch is:  0.0031708255410194397\n",
      "\n",
      "The classification loss after processing this batch is:  0.15526190400123596\n",
      "The representation loss after processing this batch is:  0.002923518419265747\n",
      "\n",
      "The classification loss after processing this batch is:  0.04686667025089264\n",
      "The representation loss after processing this batch is:  0.0026732906699180603\n",
      "\n",
      "The classification loss after processing this batch is:  0.14809957146644592\n",
      "The representation loss after processing this batch is:  0.0024869851768016815\n",
      "\n",
      "The classification loss after processing this batch is:  0.1297815442085266\n",
      "The representation loss after processing this batch is:  0.0024778470396995544\n",
      "\n",
      "The classification loss after processing this batch is:  0.0680079460144043\n",
      "The representation loss after processing this batch is:  0.0027245506644248962\n",
      "\n",
      "The classification loss after processing this batch is:  0.149190291762352\n",
      "The representation loss after processing this batch is:  0.0025599002838134766\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.22387509047985077\n",
      "The representation loss after processing this batch is:  0.0026813820004463196\n",
      "\n",
      "The classification loss after processing this batch is:  0.12203562259674072\n",
      "The representation loss after processing this batch is:  0.0022532716393470764\n",
      "\n",
      "The classification loss after processing this batch is:  0.1043098121881485\n",
      "The representation loss after processing this batch is:  0.00280563160777092\n",
      "\n",
      "The classification loss after processing this batch is:  0.10295386612415314\n",
      "The representation loss after processing this batch is:  0.002485603094100952\n",
      "\n",
      "The classification loss after processing this batch is:  0.09760645031929016\n",
      "The representation loss after processing this batch is:  0.0026530921459198\n",
      "\n",
      "The classification loss after processing this batch is:  0.11958550661802292\n",
      "The representation loss after processing this batch is:  0.0027961507439613342\n",
      "\n",
      "The classification loss after processing this batch is:  0.06077255308628082\n",
      "The representation loss after processing this batch is:  0.0028545185923576355\n",
      "\n",
      "The classification loss after processing this batch is:  0.13385558128356934\n",
      "The representation loss after processing this batch is:  0.002396427094936371\n",
      "\n",
      "The classification loss after processing this batch is:  0.16227903962135315\n",
      "The representation loss after processing this batch is:  0.002279657870531082\n",
      "\n",
      "The classification loss after processing this batch is:  0.08944875746965408\n",
      "The representation loss after processing this batch is:  0.0026847273111343384\n",
      "\n",
      "The classification loss after processing this batch is:  0.16617923974990845\n",
      "The representation loss after processing this batch is:  0.0023810938000679016\n",
      "\n",
      "The classification loss after processing this batch is:  0.12842196226119995\n",
      "The representation loss after processing this batch is:  0.0022765398025512695\n",
      "\n",
      "The classification loss after processing this batch is:  0.06851177662611008\n",
      "The representation loss after processing this batch is:  0.002521209418773651\n",
      "\n",
      "The classification loss after processing this batch is:  0.0848919227719307\n",
      "The representation loss after processing this batch is:  0.0026304498314857483\n",
      "\n",
      "The classification loss after processing this batch is:  0.15366262197494507\n",
      "The representation loss after processing this batch is:  0.0026209279894828796\n",
      "\n",
      "The classification loss after processing this batch is:  0.07267842441797256\n",
      "The representation loss after processing this batch is:  0.0026893913745880127\n",
      "\n",
      "The classification loss after processing this batch is:  0.34431201219558716\n",
      "The representation loss after processing this batch is:  0.0023757442831993103\n",
      "\n",
      "The classification loss after processing this batch is:  0.1357434242963791\n",
      "The representation loss after processing this batch is:  0.002705991268157959\n",
      "\n",
      "The classification loss after processing this batch is:  0.20101600885391235\n",
      "The representation loss after processing this batch is:  0.0025058165192604065\n",
      "\n",
      "The classification loss after processing this batch is:  0.10397259145975113\n",
      "The representation loss after processing this batch is:  0.002196170389652252\n",
      "\n",
      "The classification loss after processing this batch is:  0.15064077079296112\n",
      "The representation loss after processing this batch is:  0.0025957897305488586\n",
      "\n",
      "The classification loss after processing this batch is:  0.09193948656320572\n",
      "The representation loss after processing this batch is:  0.0022915638983249664\n",
      "\n",
      "The classification loss after processing this batch is:  0.1060304343700409\n",
      "The representation loss after processing this batch is:  0.0024157799780368805\n",
      "\n",
      "The classification loss after processing this batch is:  0.1944972425699234\n",
      "The representation loss after processing this batch is:  0.0027941353619098663\n",
      "\n",
      "The classification loss after processing this batch is:  0.12488590180873871\n",
      "The representation loss after processing this batch is:  0.0031537115573883057\n",
      "\n",
      "The classification loss after processing this batch is:  0.16953697800636292\n",
      "The representation loss after processing this batch is:  0.0024857819080352783\n",
      "\n",
      "The classification loss after processing this batch is:  0.13340841233730316\n",
      "The representation loss after processing this batch is:  0.0026037469506263733\n",
      "\n",
      "The classification loss after processing this batch is:  0.19139009714126587\n",
      "The representation loss after processing this batch is:  0.0028742551803588867\n",
      "\n",
      "The classification loss after processing this batch is:  0.16055484116077423\n",
      "The representation loss after processing this batch is:  0.002703435719013214\n",
      "\n",
      "The classification loss after processing this batch is:  0.1878611445426941\n",
      "The representation loss after processing this batch is:  0.002733476459980011\n",
      "\n",
      "The classification loss after processing this batch is:  0.09441061317920685\n",
      "The representation loss after processing this batch is:  0.0026538223028182983\n",
      "\n",
      "The classification loss after processing this batch is:  0.1220640316605568\n",
      "The representation loss after processing this batch is:  0.0031110718846321106\n",
      "\n",
      "The classification loss after processing this batch is:  0.06709401309490204\n",
      "The representation loss after processing this batch is:  0.002663031220436096\n",
      "\n",
      "The classification loss after processing this batch is:  0.18042288720607758\n",
      "The representation loss after processing this batch is:  0.002408064901828766\n",
      "\n",
      "The classification loss after processing this batch is:  0.21916908025741577\n",
      "The representation loss after processing this batch is:  0.002534128725528717\n",
      "\n",
      "The classification loss after processing this batch is:  0.08968048542737961\n",
      "The representation loss after processing this batch is:  0.0029698312282562256\n",
      "\n",
      "The classification loss after processing this batch is:  0.17693328857421875\n",
      "The representation loss after processing this batch is:  0.002804696559906006\n",
      "\n",
      "The classification loss after processing this batch is:  0.17605526745319366\n",
      "The representation loss after processing this batch is:  0.002542465925216675\n",
      "\n",
      "The classification loss after processing this batch is:  0.18506543338298798\n",
      "The representation loss after processing this batch is:  0.0028883591294288635\n",
      "\n",
      "The classification loss after processing this batch is:  0.07549338042736053\n",
      "The representation loss after processing this batch is:  0.002514787018299103\n",
      "\n",
      "The classification loss after processing this batch is:  0.16460920870304108\n",
      "The representation loss after processing this batch is:  0.0026475340127944946\n",
      "\n",
      "The classification loss after processing this batch is:  0.17655305564403534\n",
      "The representation loss after processing this batch is:  0.002705216407775879\n",
      "\n",
      "The classification loss after processing this batch is:  0.10056997835636139\n",
      "The representation loss after processing this batch is:  0.002956174314022064\n",
      "\n",
      "The classification loss after processing this batch is:  0.05355597659945488\n",
      "The representation loss after processing this batch is:  0.002912558615207672\n",
      "\n",
      "The classification loss after processing this batch is:  0.12373842298984528\n",
      "The representation loss after processing this batch is:  0.0026322901248931885\n",
      "\n",
      "The classification loss after processing this batch is:  0.10405994951725006\n",
      "The representation loss after processing this batch is:  0.0028319135308265686\n",
      "\n",
      "The classification loss after processing this batch is:  0.12666159868240356\n",
      "The representation loss after processing this batch is:  0.002559281885623932\n",
      "\n",
      "The classification loss after processing this batch is:  0.22571848332881927\n",
      "The representation loss after processing this batch is:  0.0028489790856838226\n",
      "\n",
      "The classification loss after processing this batch is:  0.16148516535758972\n",
      "The representation loss after processing this batch is:  0.002428170293569565\n",
      "\n",
      "The classification loss after processing this batch is:  0.12588101625442505\n",
      "The representation loss after processing this batch is:  0.002868376672267914\n",
      "\n",
      "The classification loss after processing this batch is:  0.14985446631908417\n",
      "The representation loss after processing this batch is:  0.002751283347606659\n",
      "\n",
      "The classification loss after processing this batch is:  0.11386223137378693\n",
      "The representation loss after processing this batch is:  0.002974368631839752\n",
      "\n",
      "The classification loss after processing this batch is:  0.12204282730817795\n",
      "The representation loss after processing this batch is:  0.0026487112045288086\n",
      "\n",
      "The classification loss after processing this batch is:  0.2214183211326599\n",
      "The representation loss after processing this batch is:  0.002673730254173279\n",
      "\n",
      "The classification loss after processing this batch is:  0.18513084948062897\n",
      "The representation loss after processing this batch is:  0.003656946122646332\n",
      "\n",
      "The classification loss after processing this batch is:  0.12076785415410995\n",
      "The representation loss after processing this batch is:  0.0026831552386283875\n",
      "\n",
      "The classification loss after processing this batch is:  0.08259250223636627\n",
      "The representation loss after processing this batch is:  0.0028267428278923035\n",
      "\n",
      "The classification loss after processing this batch is:  0.10972582548856735\n",
      "The representation loss after processing this batch is:  0.002573978155851364\n",
      "\n",
      "The classification loss after processing this batch is:  0.07751835137605667\n",
      "The representation loss after processing this batch is:  0.002984769642353058\n",
      "\n",
      "The classification loss after processing this batch is:  0.1266781985759735\n",
      "The representation loss after processing this batch is:  0.002548154443502426\n",
      "\n",
      "The classification loss after processing this batch is:  0.23694047331809998\n",
      "The representation loss after processing this batch is:  0.002554193139076233\n",
      "\n",
      "The classification loss after processing this batch is:  0.2869722247123718\n",
      "The representation loss after processing this batch is:  0.003004692494869232\n",
      "\n",
      "The classification loss after processing this batch is:  0.13532835245132446\n",
      "The representation loss after processing this batch is:  0.002510271966457367\n",
      "\n",
      "The classification loss after processing this batch is:  0.1281701624393463\n",
      "The representation loss after processing this batch is:  0.0025185085833072662\n",
      "\n",
      "The classification loss after processing this batch is:  0.10264758765697479\n",
      "The representation loss after processing this batch is:  0.00264914333820343\n",
      "\n",
      "The classification loss after processing this batch is:  0.12167815119028091\n",
      "The representation loss after processing this batch is:  0.0025533773005008698\n",
      "\n",
      "The classification loss after processing this batch is:  0.21889573335647583\n",
      "The representation loss after processing this batch is:  0.002936162054538727\n",
      "\n",
      "The classification loss after processing this batch is:  0.15112771093845367\n",
      "The representation loss after processing this batch is:  0.0023756027221679688\n",
      "\n",
      "The classification loss after processing this batch is:  0.31072381138801575\n",
      "The representation loss after processing this batch is:  0.0025826841592788696\n",
      "\n",
      "The classification loss after processing this batch is:  0.16421769559383392\n",
      "The representation loss after processing this batch is:  0.002755209803581238\n",
      "\n",
      "The classification loss after processing this batch is:  0.0664796382188797\n",
      "The representation loss after processing this batch is:  0.003063000738620758\n",
      "\n",
      "The classification loss after processing this batch is:  0.15577548742294312\n",
      "The representation loss after processing this batch is:  0.0025929398834705353\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14429457485675812\n",
      "The representation loss after processing this batch is:  0.002524442970752716\n",
      "\n",
      "The classification loss after processing this batch is:  0.18635018169879913\n",
      "The representation loss after processing this batch is:  0.002783045172691345\n",
      "\n",
      "The classification loss after processing this batch is:  0.14846055209636688\n",
      "The representation loss after processing this batch is:  0.0024517178535461426\n",
      "\n",
      "The classification loss after processing this batch is:  0.19312109053134918\n",
      "The representation loss after processing this batch is:  0.0023770034313201904\n",
      "\n",
      "The classification loss after processing this batch is:  0.1333431750535965\n",
      "The representation loss after processing this batch is:  0.00255575031042099\n",
      "\n",
      "The classification loss after processing this batch is:  0.18322314321994781\n",
      "The representation loss after processing this batch is:  0.002585098147392273\n",
      "\n",
      "The classification loss after processing this batch is:  0.20709390938282013\n",
      "The representation loss after processing this batch is:  0.0027739927172660828\n",
      "\n",
      "The classification loss after processing this batch is:  0.26097115874290466\n",
      "The representation loss after processing this batch is:  0.0024669021368026733\n",
      "\n",
      "The classification loss after processing this batch is:  0.16575975716114044\n",
      "The representation loss after processing this batch is:  0.002579234540462494\n",
      "\n",
      "The classification loss after processing this batch is:  0.059658609330654144\n",
      "The representation loss after processing this batch is:  0.0031717047095298767\n",
      "\n",
      "The classification loss after processing this batch is:  0.034723516553640366\n",
      "The representation loss after processing this batch is:  0.0026910975575447083\n",
      "\n",
      "The classification loss after processing this batch is:  0.1116701066493988\n",
      "The representation loss after processing this batch is:  0.003062129020690918\n",
      "\n",
      "The classification loss after processing this batch is:  0.08261594921350479\n",
      "The representation loss after processing this batch is:  0.0043051764369010925\n",
      "\n",
      "The classification loss after processing this batch is:  0.15386134386062622\n",
      "The representation loss after processing this batch is:  0.00273953378200531\n",
      "\n",
      "The classification loss after processing this batch is:  0.11370305716991425\n",
      "The representation loss after processing this batch is:  0.003214620053768158\n",
      "\n",
      "The classification loss after processing this batch is:  0.16280598938465118\n",
      "The representation loss after processing this batch is:  0.0026271268725395203\n",
      "\n",
      "The classification loss after processing this batch is:  0.059077657759189606\n",
      "The representation loss after processing this batch is:  0.0028333142399787903\n",
      "\n",
      "The classification loss after processing this batch is:  0.1458001732826233\n",
      "The representation loss after processing this batch is:  0.002622883766889572\n",
      "\n",
      "The classification loss after processing this batch is:  0.12307000160217285\n",
      "The representation loss after processing this batch is:  0.002817772328853607\n",
      "\n",
      "The classification loss after processing this batch is:  0.1617007553577423\n",
      "The representation loss after processing this batch is:  0.0026549920439720154\n",
      "\n",
      "The classification loss after processing this batch is:  0.10126058012247086\n",
      "The representation loss after processing this batch is:  0.0026082322001457214\n",
      "\n",
      "The classification loss after processing this batch is:  0.08600731194019318\n",
      "The representation loss after processing this batch is:  0.0021072998642921448\n",
      "\n",
      "The classification loss after processing this batch is:  0.12577584385871887\n",
      "The representation loss after processing this batch is:  0.0025065168738365173\n",
      "\n",
      "The classification loss after processing this batch is:  0.158375546336174\n",
      "The representation loss after processing this batch is:  0.0026328489184379578\n",
      "\n",
      "The classification loss after processing this batch is:  0.12253858149051666\n",
      "The representation loss after processing this batch is:  0.002538815140724182\n",
      "\n",
      "The classification loss after processing this batch is:  0.14214877784252167\n",
      "The representation loss after processing this batch is:  0.002894103527069092\n",
      "\n",
      "The classification loss after processing this batch is:  0.10489676147699356\n",
      "The representation loss after processing this batch is:  0.0026914402842521667\n",
      "\n",
      "The classification loss after processing this batch is:  0.03705411031842232\n",
      "The representation loss after processing this batch is:  0.0026611462235450745\n",
      "\n",
      "The classification loss after processing this batch is:  0.07894197106361389\n",
      "The representation loss after processing this batch is:  0.0030637606978416443\n",
      "\n",
      "The classification loss after processing this batch is:  0.05301427096128464\n",
      "The representation loss after processing this batch is:  0.0027275606989860535\n",
      "\n",
      "The classification loss after processing this batch is:  0.1302633136510849\n",
      "The representation loss after processing this batch is:  0.0027276799082756042\n",
      "\n",
      "The classification loss after processing this batch is:  0.07146313041448593\n",
      "The representation loss after processing this batch is:  0.002720378339290619\n",
      "\n",
      "The classification loss after processing this batch is:  0.07875414937734604\n",
      "The representation loss after processing this batch is:  0.002568475902080536\n",
      "\n",
      "The classification loss after processing this batch is:  0.1297597736120224\n",
      "The representation loss after processing this batch is:  0.0028911083936691284\n",
      "\n",
      "The classification loss after processing this batch is:  0.12218396365642548\n",
      "The representation loss after processing this batch is:  0.0025741904973983765\n",
      "\n",
      "The classification loss after processing this batch is:  0.08130655437707901\n",
      "The representation loss after processing this batch is:  0.0024064183235168457\n",
      "\n",
      "The classification loss after processing this batch is:  0.05631566792726517\n",
      "The representation loss after processing this batch is:  0.0026059597730636597\n",
      "\n",
      "The classification loss after processing this batch is:  0.05774141848087311\n",
      "The representation loss after processing this batch is:  0.002613469958305359\n",
      "\n",
      "The classification loss after processing this batch is:  0.04837697371840477\n",
      "The representation loss after processing this batch is:  0.0026852041482925415\n",
      "\n",
      "The classification loss after processing this batch is:  0.13930535316467285\n",
      "The representation loss after processing this batch is:  0.002596423029899597\n",
      "\n",
      "The classification loss after processing this batch is:  0.14197273552417755\n",
      "The representation loss after processing this batch is:  0.0028434544801712036\n",
      "\n",
      "The classification loss after processing this batch is:  0.07516571134328842\n",
      "The representation loss after processing this batch is:  0.002602972090244293\n",
      "\n",
      "The classification loss after processing this batch is:  0.1662788987159729\n",
      "The representation loss after processing this batch is:  0.0027391277253627777\n",
      "\n",
      "The classification loss after processing this batch is:  0.07354912906885147\n",
      "The representation loss after processing this batch is:  0.0026180073618888855\n",
      "\n",
      "The classification loss after processing this batch is:  0.13882651925086975\n",
      "The representation loss after processing this batch is:  0.002483207732439041\n",
      "\n",
      "The classification loss after processing this batch is:  0.1938098967075348\n",
      "The representation loss after processing this batch is:  0.0027630142867565155\n",
      "\n",
      "The classification loss after processing this batch is:  0.10429108142852783\n",
      "The representation loss after processing this batch is:  0.0026800036430358887\n",
      "\n",
      "The classification loss after processing this batch is:  0.18675324320793152\n",
      "The representation loss after processing this batch is:  0.002365581691265106\n",
      "\n",
      "The classification loss after processing this batch is:  0.13145242631435394\n",
      "The representation loss after processing this batch is:  0.002272278070449829\n",
      "\n",
      "The classification loss after processing this batch is:  0.15484802424907684\n",
      "The representation loss after processing this batch is:  0.0025110095739364624\n",
      "\n",
      "The classification loss after processing this batch is:  0.13755346834659576\n",
      "The representation loss after processing this batch is:  0.0024769455194473267\n",
      "\n",
      "The classification loss after processing this batch is:  0.08602520823478699\n",
      "The representation loss after processing this batch is:  0.0028029829263687134\n",
      "\n",
      "The classification loss after processing this batch is:  0.12814070284366608\n",
      "The representation loss after processing this batch is:  0.0022838711738586426\n",
      "\n",
      "The classification loss after processing this batch is:  0.10889855772256851\n",
      "The representation loss after processing this batch is:  0.002818956971168518\n",
      "\n",
      "The classification loss after processing this batch is:  0.18735866248607635\n",
      "The representation loss after processing this batch is:  0.002765186131000519\n",
      "\n",
      "The classification loss after processing this batch is:  0.12504206597805023\n",
      "The representation loss after processing this batch is:  0.002681538462638855\n",
      "\n",
      "The classification loss after processing this batch is:  0.07630575448274612\n",
      "The representation loss after processing this batch is:  0.002579711377620697\n",
      "\n",
      "The classification loss after processing this batch is:  0.13325653970241547\n",
      "The representation loss after processing this batch is:  0.0025229379534721375\n",
      "\n",
      "The classification loss after processing this batch is:  0.20584771037101746\n",
      "The representation loss after processing this batch is:  0.0023843683302402496\n",
      "\n",
      "The classification loss after processing this batch is:  0.08301830291748047\n",
      "The representation loss after processing this batch is:  0.002610333263874054\n",
      "\n",
      "The classification loss after processing this batch is:  0.12748493254184723\n",
      "The representation loss after processing this batch is:  0.0024887695908546448\n",
      "\n",
      "The classification loss after processing this batch is:  0.12370476871728897\n",
      "The representation loss after processing this batch is:  0.002266436815261841\n",
      "\n",
      "The classification loss after processing this batch is:  0.0877058282494545\n",
      "The representation loss after processing this batch is:  0.0029699280858039856\n",
      "\n",
      "The classification loss after processing this batch is:  0.05724218860268593\n",
      "The representation loss after processing this batch is:  0.0030035823583602905\n",
      "\n",
      "The classification loss after processing this batch is:  0.10721127688884735\n",
      "The representation loss after processing this batch is:  0.0031617656350135803\n",
      "\n",
      "The classification loss after processing this batch is:  0.10704924911260605\n",
      "The representation loss after processing this batch is:  0.0027407631278038025\n",
      "\n",
      "The classification loss after processing this batch is:  0.11563432216644287\n",
      "The representation loss after processing this batch is:  0.0026379115879535675\n",
      "\n",
      "The classification loss after processing this batch is:  0.16347680985927582\n",
      "The representation loss after processing this batch is:  0.002849176526069641\n",
      "\n",
      "The classification loss after processing this batch is:  0.13170306384563446\n",
      "The representation loss after processing this batch is:  0.002807728946208954\n",
      "\n",
      "The classification loss after processing this batch is:  0.1604911834001541\n",
      "The representation loss after processing this batch is:  0.0022814273834228516\n",
      "\n",
      "The classification loss after processing this batch is:  0.1685095578432083\n",
      "The representation loss after processing this batch is:  0.0029826760292053223\n",
      "\n",
      "The classification loss after processing this batch is:  0.054618652909994125\n",
      "The representation loss after processing this batch is:  0.002833262085914612\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.06346867233514786\n",
      "The representation loss after processing this batch is:  0.0026325471699237823\n",
      "\n",
      "The classification loss after processing this batch is:  0.10782972723245621\n",
      "The representation loss after processing this batch is:  0.002555079758167267\n",
      "\n",
      "The classification loss after processing this batch is:  0.12328552454710007\n",
      "The representation loss after processing this batch is:  0.0027778595685958862\n",
      "\n",
      "The classification loss after processing this batch is:  0.10521713644266129\n",
      "The representation loss after processing this batch is:  0.002547331154346466\n",
      "\n",
      "The classification loss after processing this batch is:  0.12286494672298431\n",
      "The representation loss after processing this batch is:  0.0026439428329467773\n",
      "\n",
      "The classification loss after processing this batch is:  0.1255297064781189\n",
      "The representation loss after processing this batch is:  0.0031970813870429993\n",
      "\n",
      "The classification loss after processing this batch is:  0.13241496682167053\n",
      "The representation loss after processing this batch is:  0.0029430463910102844\n",
      "\n",
      "The classification loss after processing this batch is:  0.1800537407398224\n",
      "The representation loss after processing this batch is:  0.002581849694252014\n",
      "\n",
      "The classification loss after processing this batch is:  0.16938333213329315\n",
      "The representation loss after processing this batch is:  0.002577558159828186\n",
      "\n",
      "The classification loss after processing this batch is:  0.14771434664726257\n",
      "The representation loss after processing this batch is:  0.0024270527064800262\n",
      "\n",
      "The classification loss after processing this batch is:  0.07108981162309647\n",
      "The representation loss after processing this batch is:  0.0030747130513191223\n",
      "\n",
      "The classification loss after processing this batch is:  0.049181487411260605\n",
      "The representation loss after processing this batch is:  0.002991005778312683\n",
      "\n",
      "The classification loss after processing this batch is:  0.16458609700202942\n",
      "The representation loss after processing this batch is:  0.002352919429540634\n",
      "\n",
      "The classification loss after processing this batch is:  0.21005675196647644\n",
      "The representation loss after processing this batch is:  0.002453148365020752\n",
      "\n",
      "The classification loss after processing this batch is:  0.17445608973503113\n",
      "The representation loss after processing this batch is:  0.0026832669973373413\n",
      "\n",
      "The classification loss after processing this batch is:  0.15940794348716736\n",
      "The representation loss after processing this batch is:  0.0025688931345939636\n",
      "\n",
      "The classification loss after processing this batch is:  0.16589903831481934\n",
      "The representation loss after processing this batch is:  0.0027390047907829285\n",
      "\n",
      "The classification loss after processing this batch is:  0.19946403801441193\n",
      "The representation loss after processing this batch is:  0.002638868987560272\n",
      "\n",
      "The classification loss after processing this batch is:  0.2166152447462082\n",
      "The representation loss after processing this batch is:  0.0026265867054462433\n",
      "\n",
      "The classification loss after processing this batch is:  0.21841123700141907\n",
      "The representation loss after processing this batch is:  0.0028015747666358948\n",
      "\n",
      "The classification loss after processing this batch is:  0.17698243260383606\n",
      "The representation loss after processing this batch is:  0.0027775131165981293\n",
      "\n",
      "The classification loss after processing this batch is:  0.1263546645641327\n",
      "The representation loss after processing this batch is:  0.0032715126872062683\n",
      "\n",
      "The classification loss after processing this batch is:  0.08051174134016037\n",
      "The representation loss after processing this batch is:  0.002984575927257538\n",
      "\n",
      "The classification loss after processing this batch is:  0.12054720520973206\n",
      "The representation loss after processing this batch is:  0.0026635117828845978\n",
      "\n",
      "The classification loss after processing this batch is:  0.10046451538801193\n",
      "The representation loss after processing this batch is:  0.0024144649505615234\n",
      "\n",
      "The classification loss after processing this batch is:  0.08559338003396988\n",
      "The representation loss after processing this batch is:  0.002422630786895752\n",
      "\n",
      "The classification loss after processing this batch is:  0.0657576322555542\n",
      "The representation loss after processing this batch is:  0.002469640225172043\n",
      "\n",
      "The classification loss after processing this batch is:  0.14645470678806305\n",
      "The representation loss after processing this batch is:  0.002514675259590149\n",
      "\n",
      "The classification loss after processing this batch is:  0.07816579192876816\n",
      "The representation loss after processing this batch is:  0.0025887638330459595\n",
      "\n",
      "The classification loss after processing this batch is:  0.09939605742692947\n",
      "The representation loss after processing this batch is:  0.0029497407376766205\n",
      "\n",
      "The classification loss after processing this batch is:  0.10574999451637268\n",
      "The representation loss after processing this batch is:  0.0022504031658172607\n",
      "\n",
      "The classification loss after processing this batch is:  0.09073369950056076\n",
      "The representation loss after processing this batch is:  0.0023927539587020874\n",
      "\n",
      "The classification loss after processing this batch is:  0.08270061761140823\n",
      "The representation loss after processing this batch is:  0.0027747489511966705\n",
      "\n",
      "The classification loss after processing this batch is:  0.10826428979635239\n",
      "The representation loss after processing this batch is:  0.0024595148861408234\n",
      "\n",
      "The classification loss after processing this batch is:  0.1519479900598526\n",
      "The representation loss after processing this batch is:  0.0030210092663764954\n",
      "\n",
      "The classification loss after processing this batch is:  0.051808517426252365\n",
      "The representation loss after processing this batch is:  0.0028293579816818237\n",
      "\n",
      "The classification loss after processing this batch is:  0.059172455221414566\n",
      "The representation loss after processing this batch is:  0.0028712376952171326\n",
      "\n",
      "The classification loss after processing this batch is:  0.150162011384964\n",
      "The representation loss after processing this batch is:  0.0025781914591789246\n",
      "\n",
      "The classification loss after processing this batch is:  0.20255401730537415\n",
      "The representation loss after processing this batch is:  0.002512369304895401\n",
      "\n",
      "The classification loss after processing this batch is:  0.12321925163269043\n",
      "The representation loss after processing this batch is:  0.0026060864329338074\n",
      "\n",
      "The classification loss after processing this batch is:  0.06074175983667374\n",
      "The representation loss after processing this batch is:  0.002360958606004715\n",
      "\n",
      "The classification loss after processing this batch is:  0.11178500950336456\n",
      "The representation loss after processing this batch is:  0.002465464174747467\n",
      "\n",
      "The classification loss after processing this batch is:  0.029625173658132553\n",
      "The representation loss after processing this batch is:  0.0027701333165168762\n",
      "\n",
      "The classification loss after processing this batch is:  0.1213226392865181\n",
      "The representation loss after processing this batch is:  0.002654433250427246\n",
      "\n",
      "The classification loss after processing this batch is:  0.10581748187541962\n",
      "The representation loss after processing this batch is:  0.002728857100009918\n",
      "\n",
      "The classification loss after processing this batch is:  0.06627640873193741\n",
      "The representation loss after processing this batch is:  0.002342037856578827\n",
      "\n",
      "The classification loss after processing this batch is:  0.07227461040019989\n",
      "The representation loss after processing this batch is:  0.0026551857590675354\n",
      "\n",
      "The classification loss after processing this batch is:  0.10274113714694977\n",
      "The representation loss after processing this batch is:  0.002565421164035797\n",
      "\n",
      "The classification loss after processing this batch is:  0.08099861443042755\n",
      "The representation loss after processing this batch is:  0.0025148913264274597\n",
      "\n",
      "The classification loss after processing this batch is:  0.21163609623908997\n",
      "The representation loss after processing this batch is:  0.0025340616703033447\n",
      "\n",
      "The classification loss after processing this batch is:  0.2658863365650177\n",
      "The representation loss after processing this batch is:  0.002644535154104233\n",
      "\n",
      "The classification loss after processing this batch is:  0.19641225039958954\n",
      "The representation loss after processing this batch is:  0.002573266625404358\n",
      "\n",
      "The classification loss after processing this batch is:  0.21012061834335327\n",
      "The representation loss after processing this batch is:  0.0026388242840766907\n",
      "\n",
      "The classification loss after processing this batch is:  0.12460818141698837\n",
      "The representation loss after processing this batch is:  0.0025224462151527405\n",
      "\n",
      "The classification loss after processing this batch is:  0.083421491086483\n",
      "The representation loss after processing this batch is:  0.0025090500712394714\n",
      "\n",
      "The classification loss after processing this batch is:  0.19429820775985718\n",
      "The representation loss after processing this batch is:  0.002422153949737549\n",
      "\n",
      "The classification loss after processing this batch is:  0.13545343279838562\n",
      "The representation loss after processing this batch is:  0.002593372017145157\n",
      "\n",
      "The classification loss after processing this batch is:  0.14316202700138092\n",
      "The representation loss after processing this batch is:  0.0025020912289619446\n",
      "\n",
      "The classification loss after processing this batch is:  0.15302476286888123\n",
      "The representation loss after processing this batch is:  0.0028012096881866455\n",
      "\n",
      "The classification loss after processing this batch is:  0.1429235339164734\n",
      "The representation loss after processing this batch is:  0.0026201680302619934\n",
      "\n",
      "The classification loss after processing this batch is:  0.09705599397420883\n",
      "The representation loss after processing this batch is:  0.0026501379907131195\n",
      "\n",
      "The classification loss after processing this batch is:  0.1178157851099968\n",
      "The representation loss after processing this batch is:  0.002628117799758911\n",
      "\n",
      "The classification loss after processing this batch is:  0.1478053629398346\n",
      "The representation loss after processing this batch is:  0.00259573757648468\n",
      "\n",
      "The classification loss after processing this batch is:  0.06475905328989029\n",
      "The representation loss after processing this batch is:  0.002748355269432068\n",
      "\n",
      "The classification loss after processing this batch is:  0.06204867362976074\n",
      "The representation loss after processing this batch is:  0.0026932433247566223\n",
      "\n",
      "The classification loss after processing this batch is:  0.12007765471935272\n",
      "The representation loss after processing this batch is:  0.0024796947836875916\n",
      "\n",
      "The classification loss after processing this batch is:  0.17304351925849915\n",
      "The representation loss after processing this batch is:  0.00247027724981308\n",
      "\n",
      "The classification loss after processing this batch is:  0.05724659934639931\n",
      "The representation loss after processing this batch is:  0.0024213939905166626\n",
      "\n",
      "The classification loss after processing this batch is:  0.07301635295152664\n",
      "The representation loss after processing this batch is:  0.002465583384037018\n",
      "\n",
      "The classification loss after processing this batch is:  0.18215928971767426\n",
      "The representation loss after processing this batch is:  0.0022991150617599487\n",
      "\n",
      "The classification loss after processing this batch is:  0.19478660821914673\n",
      "The representation loss after processing this batch is:  0.0024227574467658997\n",
      "\n",
      "The classification loss after processing this batch is:  0.0925716906785965\n",
      "The representation loss after processing this batch is:  0.002401381731033325\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.20118919014930725\n",
      "The representation loss after processing this batch is:  0.0024108774960041046\n",
      "\n",
      "The classification loss after processing this batch is:  0.07130619883537292\n",
      "The representation loss after processing this batch is:  0.00295354425907135\n",
      "\n",
      "The classification loss after processing this batch is:  0.042210932821035385\n",
      "The representation loss after processing this batch is:  0.002445630729198456\n",
      "\n",
      "The classification loss after processing this batch is:  0.06204860284924507\n",
      "The representation loss after processing this batch is:  0.002422928810119629\n",
      "\n",
      "The classification loss after processing this batch is:  0.16381222009658813\n",
      "The representation loss after processing this batch is:  0.0031344667077064514\n",
      "\n",
      "The classification loss after processing this batch is:  0.16330856084823608\n",
      "The representation loss after processing this batch is:  0.0028349310159683228\n",
      "\n",
      "The classification loss after processing this batch is:  0.0832664892077446\n",
      "The representation loss after processing this batch is:  0.0033513903617858887\n",
      "\n",
      "The classification loss after processing this batch is:  0.1060781478881836\n",
      "The representation loss after processing this batch is:  0.0024286024272441864\n",
      "\n",
      "The classification loss after processing this batch is:  0.08079979568719864\n",
      "The representation loss after processing this batch is:  0.0026424378156661987\n",
      "\n",
      "The classification loss after processing this batch is:  0.1464233547449112\n",
      "The representation loss after processing this batch is:  0.0026320628821849823\n",
      "\n",
      "The classification loss after processing this batch is:  0.1137000173330307\n",
      "The representation loss after processing this batch is:  0.0024154819548130035\n",
      "\n",
      "The classification loss after processing this batch is:  0.18110808730125427\n",
      "The representation loss after processing this batch is:  0.0023896805942058563\n",
      "\n",
      "The classification loss after processing this batch is:  0.16996632516384125\n",
      "The representation loss after processing this batch is:  0.0026902779936790466\n",
      "\n",
      "The classification loss after processing this batch is:  0.25169095396995544\n",
      "The representation loss after processing this batch is:  0.0021901875734329224\n",
      "\n",
      "The classification loss after processing this batch is:  0.13867142796516418\n",
      "The representation loss after processing this batch is:  0.0023928694427013397\n",
      "\n",
      "The classification loss after processing this batch is:  0.17773501574993134\n",
      "The representation loss after processing this batch is:  0.0024805888533592224\n",
      "\n",
      "The classification loss after processing this batch is:  0.16318511962890625\n",
      "The representation loss after processing this batch is:  0.002561599016189575\n",
      "\n",
      "The classification loss after processing this batch is:  0.0701976791024208\n",
      "The representation loss after processing this batch is:  0.002728395164012909\n",
      "\n",
      "The classification loss after processing this batch is:  0.10717449337244034\n",
      "The representation loss after processing this batch is:  0.0030226558446884155\n",
      "\n",
      "The classification loss after processing this batch is:  0.06818569451570511\n",
      "The representation loss after processing this batch is:  0.002840951085090637\n",
      "\n",
      "The classification loss after processing this batch is:  0.11457297205924988\n",
      "The representation loss after processing this batch is:  0.0024933479726314545\n",
      "\n",
      "The classification loss after processing this batch is:  0.11744809150695801\n",
      "The representation loss after processing this batch is:  0.0021988190710544586\n",
      "\n",
      "The classification loss after processing this batch is:  0.10550748556852341\n",
      "The representation loss after processing this batch is:  0.002366919070482254\n",
      "\n",
      "The classification loss after processing this batch is:  0.11647803336381912\n",
      "The representation loss after processing this batch is:  0.0025357380509376526\n",
      "\n",
      "The classification loss after processing this batch is:  0.15801368653774261\n",
      "The representation loss after processing this batch is:  0.0024748966097831726\n",
      "\n",
      "The classification loss after processing this batch is:  0.1365961879491806\n",
      "The representation loss after processing this batch is:  0.0023922696709632874\n",
      "\n",
      "The classification loss after processing this batch is:  0.19276651740074158\n",
      "The representation loss after processing this batch is:  0.002666175365447998\n",
      "\n",
      "The classification loss after processing this batch is:  0.10339723527431488\n",
      "The representation loss after processing this batch is:  0.002825804054737091\n",
      "\n",
      "The classification loss after processing this batch is:  0.11276663094758987\n",
      "The representation loss after processing this batch is:  0.002331819385290146\n",
      "\n",
      "The classification loss after processing this batch is:  0.0997907742857933\n",
      "The representation loss after processing this batch is:  0.002879604697227478\n",
      "\n",
      "The classification loss after processing this batch is:  0.18306589126586914\n",
      "The representation loss after processing this batch is:  0.0032965727150440216\n",
      "\n",
      "The classification loss after processing this batch is:  0.28173795342445374\n",
      "The representation loss after processing this batch is:  0.0029579848051071167\n",
      "\n",
      "The classification loss after processing this batch is:  0.05200028419494629\n",
      "The representation loss after processing this batch is:  0.002419549971818924\n",
      "\n",
      "The classification loss after processing this batch is:  0.07481049001216888\n",
      "The representation loss after processing this batch is:  0.002662181854248047\n",
      "\n",
      "The classification loss after processing this batch is:  0.21277466416358948\n",
      "The representation loss after processing this batch is:  0.003105252981185913\n",
      "\n",
      "The classification loss after processing this batch is:  0.05004953220486641\n",
      "The representation loss after processing this batch is:  0.0028212592005729675\n",
      "\n",
      "The classification loss after processing this batch is:  0.079635851085186\n",
      "The representation loss after processing this batch is:  0.0025473646819591522\n",
      "\n",
      "The classification loss after processing this batch is:  0.14460232853889465\n",
      "The representation loss after processing this batch is:  0.0026871412992477417\n",
      "\n",
      "The classification loss after processing this batch is:  0.09333393722772598\n",
      "The representation loss after processing this batch is:  0.002864070236682892\n",
      "\n",
      "The classification loss after processing this batch is:  0.1786615401506424\n",
      "The representation loss after processing this batch is:  0.0031309351325035095\n",
      "\n",
      "The classification loss after processing this batch is:  0.13615059852600098\n",
      "The representation loss after processing this batch is:  0.0031188130378723145\n",
      "\n",
      "The classification loss after processing this batch is:  0.1419449746608734\n",
      "The representation loss after processing this batch is:  0.002941407263278961\n",
      "\n",
      "The classification loss after processing this batch is:  0.09122894704341888\n",
      "The representation loss after processing this batch is:  0.0022179707884788513\n",
      "\n",
      "The classification loss after processing this batch is:  0.1711529940366745\n",
      "The representation loss after processing this batch is:  0.0022850409150123596\n",
      "\n",
      "The classification loss after processing this batch is:  0.05058376118540764\n",
      "The representation loss after processing this batch is:  0.0024931132793426514\n",
      "\n",
      "The classification loss after processing this batch is:  0.045175857841968536\n",
      "The representation loss after processing this batch is:  0.0024861395359039307\n",
      "\n",
      "The classification loss after processing this batch is:  0.10961399972438812\n",
      "The representation loss after processing this batch is:  0.002584502100944519\n",
      "\n",
      "The classification loss after processing this batch is:  0.07392227649688721\n",
      "The representation loss after processing this batch is:  0.002652302384376526\n",
      "\n",
      "The classification loss after processing this batch is:  0.1021612137556076\n",
      "The representation loss after processing this batch is:  0.0023428313434123993\n",
      "\n",
      "The classification loss after processing this batch is:  0.06752027571201324\n",
      "The representation loss after processing this batch is:  0.0023549534380435944\n",
      "\n",
      "The classification loss after processing this batch is:  0.08559868484735489\n",
      "The representation loss after processing this batch is:  0.002616051584482193\n",
      "\n",
      "The classification loss after processing this batch is:  0.12907792627811432\n",
      "The representation loss after processing this batch is:  0.0024454332888126373\n",
      "\n",
      "The classification loss after processing this batch is:  0.17137466371059418\n",
      "The representation loss after processing this batch is:  0.0027597621083259583\n",
      "\n",
      "The classification loss after processing this batch is:  0.18092960119247437\n",
      "The representation loss after processing this batch is:  0.0024760663509368896\n",
      "\n",
      "The classification loss after processing this batch is:  0.07939716428518295\n",
      "The representation loss after processing this batch is:  0.0027682334184646606\n",
      "\n",
      "The classification loss after processing this batch is:  0.19405101239681244\n",
      "The representation loss after processing this batch is:  0.002545643597841263\n",
      "\n",
      "The classification loss after processing this batch is:  0.08063005656003952\n",
      "The representation loss after processing this batch is:  0.0023701973259449005\n",
      "\n",
      "The classification loss after processing this batch is:  0.150245800614357\n",
      "The representation loss after processing this batch is:  0.0025466158986091614\n",
      "\n",
      "The classification loss after processing this batch is:  0.25046685338020325\n",
      "The representation loss after processing this batch is:  0.0029218122363090515\n",
      "\n",
      "The classification loss after processing this batch is:  0.1076466515660286\n",
      "The representation loss after processing this batch is:  0.002461664378643036\n",
      "\n",
      "The classification loss after processing this batch is:  0.16531316936016083\n",
      "The representation loss after processing this batch is:  0.0025311484932899475\n",
      "\n",
      "The classification loss after processing this batch is:  0.12381540238857269\n",
      "The representation loss after processing this batch is:  0.0025341957807540894\n",
      "\n",
      "The classification loss after processing this batch is:  0.17054350674152374\n",
      "The representation loss after processing this batch is:  0.0024499446153640747\n",
      "\n",
      "The classification loss after processing this batch is:  0.10441317409276962\n",
      "The representation loss after processing this batch is:  0.0024729743599891663\n",
      "\n",
      "The classification loss after processing this batch is:  0.0963967815041542\n",
      "The representation loss after processing this batch is:  0.002624422311782837\n",
      "\n",
      "The classification loss after processing this batch is:  0.10308262705802917\n",
      "The representation loss after processing this batch is:  0.002634584903717041\n",
      "\n",
      "The classification loss after processing this batch is:  0.05930608510971069\n",
      "The representation loss after processing this batch is:  0.002631925046443939\n",
      "\n",
      "The classification loss after processing this batch is:  0.05007027089595795\n",
      "The representation loss after processing this batch is:  0.002347327768802643\n",
      "\n",
      "The classification loss after processing this batch is:  0.13080230355262756\n",
      "The representation loss after processing this batch is:  0.0030298978090286255\n",
      "\n",
      "The classification loss after processing this batch is:  0.05273028090596199\n",
      "The representation loss after processing this batch is:  0.0027544572949409485\n",
      "\n",
      "The classification loss after processing this batch is:  0.21401074528694153\n",
      "The representation loss after processing this batch is:  0.003011908382177353\n",
      "\n",
      "The classification loss after processing this batch is:  0.09817968308925629\n",
      "The representation loss after processing this batch is:  0.0025877952575683594\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.20120741426944733\n",
      "The representation loss after processing this batch is:  0.002563178539276123\n",
      "\n",
      "The classification loss after processing this batch is:  0.24103416502475739\n",
      "The representation loss after processing this batch is:  0.0023734718561172485\n",
      "\n",
      "The classification loss after processing this batch is:  0.1435641646385193\n",
      "The representation loss after processing this batch is:  0.002376370131969452\n",
      "\n",
      "The classification loss after processing this batch is:  0.05404987558722496\n",
      "The representation loss after processing this batch is:  0.0027496516704559326\n",
      "\n",
      "The classification loss after processing this batch is:  0.07044745236635208\n",
      "The representation loss after processing this batch is:  0.002971276640892029\n",
      "\n",
      "The classification loss after processing this batch is:  0.06302950531244278\n",
      "The representation loss after processing this batch is:  0.003031298518180847\n",
      "\n",
      "The classification loss after processing this batch is:  0.08977223187685013\n",
      "The representation loss after processing this batch is:  0.0028415918350219727\n",
      "\n",
      "The classification loss after processing this batch is:  0.09991150349378586\n",
      "The representation loss after processing this batch is:  0.0022114627063274384\n",
      "\n",
      "The classification loss after processing this batch is:  0.2739427387714386\n",
      "The representation loss after processing this batch is:  0.002513311803340912\n",
      "\n",
      "The classification loss after processing this batch is:  0.19952984154224396\n",
      "The representation loss after processing this batch is:  0.0023417212069034576\n",
      "\n",
      "The classification loss after processing this batch is:  0.11306976526975632\n",
      "The representation loss after processing this batch is:  0.00300724059343338\n",
      "\n",
      "The classification loss after processing this batch is:  0.23665674030780792\n",
      "The representation loss after processing this batch is:  0.0030057281255722046\n",
      "\n",
      "The classification loss after processing this batch is:  0.06560351699590683\n",
      "The representation loss after processing this batch is:  0.0026120319962501526\n",
      "\n",
      "The classification loss after processing this batch is:  0.10588320344686508\n",
      "The representation loss after processing this batch is:  0.002528242766857147\n",
      "\n",
      "The classification loss after processing this batch is:  0.16724705696105957\n",
      "The representation loss after processing this batch is:  0.0025342553853988647\n",
      "\n",
      "The classification loss after processing this batch is:  0.10567004233598709\n",
      "The representation loss after processing this batch is:  0.002988900989294052\n",
      "\n",
      "The classification loss after processing this batch is:  0.13059145212173462\n",
      "The representation loss after processing this batch is:  0.003408655524253845\n",
      "\n",
      "The classification loss after processing this batch is:  0.09789041429758072\n",
      "The representation loss after processing this batch is:  0.0027708522975444794\n",
      "\n",
      "The classification loss after processing this batch is:  0.1335112601518631\n",
      "The representation loss after processing this batch is:  0.0029950812458992004\n",
      "\n",
      "The classification loss after processing this batch is:  0.19821389019489288\n",
      "The representation loss after processing this batch is:  0.003005020320415497\n",
      "\n",
      "The classification loss after processing this batch is:  0.09298144280910492\n",
      "The representation loss after processing this batch is:  0.00302857905626297\n",
      "\n",
      "The classification loss after processing this batch is:  0.15498162806034088\n",
      "The representation loss after processing this batch is:  0.0025019049644470215\n",
      "\n",
      "The classification loss after processing this batch is:  0.19956819713115692\n",
      "The representation loss after processing this batch is:  0.0023691654205322266\n",
      "\n",
      "The classification loss after processing this batch is:  0.12724655866622925\n",
      "The representation loss after processing this batch is:  0.0024594292044639587\n",
      "\n",
      "The classification loss after processing this batch is:  0.13536910712718964\n",
      "The representation loss after processing this batch is:  0.002327635884284973\n",
      "\n",
      "The classification loss after processing this batch is:  0.0807323232293129\n",
      "The representation loss after processing this batch is:  0.0029510483145713806\n",
      "\n",
      "The classification loss after processing this batch is:  0.03777395188808441\n",
      "The representation loss after processing this batch is:  0.0027171000838279724\n",
      "\n",
      "The classification loss after processing this batch is:  0.1354551762342453\n",
      "The representation loss after processing this batch is:  0.002725765109062195\n",
      "\n",
      "The classification loss after processing this batch is:  0.07150575518608093\n",
      "The representation loss after processing this batch is:  0.002728186547756195\n",
      "\n",
      "The classification loss after processing this batch is:  0.257707417011261\n",
      "The representation loss after processing this batch is:  0.002468191087245941\n",
      "\n",
      "The classification loss after processing this batch is:  0.050905343145132065\n",
      "The representation loss after processing this batch is:  0.0028703734278678894\n",
      "\n",
      "The classification loss after processing this batch is:  0.11392578482627869\n",
      "The representation loss after processing this batch is:  0.002357758581638336\n",
      "\n",
      "The classification loss after processing this batch is:  0.16164208948612213\n",
      "The representation loss after processing this batch is:  0.0025748535990715027\n",
      "\n",
      "The classification loss after processing this batch is:  0.12310341745615005\n",
      "The representation loss after processing this batch is:  0.002408228814601898\n",
      "\n",
      "The classification loss after processing this batch is:  0.11912045627832413\n",
      "The representation loss after processing this batch is:  0.002777867019176483\n",
      "\n",
      "The classification loss after processing this batch is:  0.058668628334999084\n",
      "The representation loss after processing this batch is:  0.0026153400540351868\n",
      "\n",
      "The classification loss after processing this batch is:  0.06745836138725281\n",
      "The representation loss after processing this batch is:  0.002453599125146866\n",
      "\n",
      "The classification loss after processing this batch is:  0.06049831584095955\n",
      "The representation loss after processing this batch is:  0.002492506057024002\n",
      "\n",
      "The classification loss after processing this batch is:  0.1438715010881424\n",
      "The representation loss after processing this batch is:  0.0035325288772583008\n",
      "\n",
      "The classification loss after processing this batch is:  0.18047048151493073\n",
      "The representation loss after processing this batch is:  0.0029348433017730713\n",
      "\n",
      "The classification loss after processing this batch is:  0.16020555794239044\n",
      "The representation loss after processing this batch is:  0.0022776834666728973\n",
      "\n",
      "The classification loss after processing this batch is:  0.18265588581562042\n",
      "The representation loss after processing this batch is:  0.002388816326856613\n",
      "\n",
      "The classification loss after processing this batch is:  0.285052090883255\n",
      "The representation loss after processing this batch is:  0.002436921000480652\n",
      "\n",
      "The classification loss after processing this batch is:  0.11117450147867203\n",
      "The representation loss after processing this batch is:  0.002927906811237335\n",
      "\n",
      "The classification loss after processing this batch is:  0.21753773093223572\n",
      "The representation loss after processing this batch is:  0.002708934247493744\n",
      "\n",
      "The classification loss after processing this batch is:  0.11791348457336426\n",
      "The representation loss after processing this batch is:  0.002578742802143097\n",
      "\n",
      "The classification loss after processing this batch is:  0.1010272204875946\n",
      "The representation loss after processing this batch is:  0.0025318562984466553\n",
      "\n",
      "The classification loss after processing this batch is:  0.05588797852396965\n",
      "The representation loss after processing this batch is:  0.0023991987109184265\n",
      "\n",
      "The classification loss after processing this batch is:  0.07125107944011688\n",
      "The representation loss after processing this batch is:  0.0025508105754852295\n",
      "\n",
      "The classification loss after processing this batch is:  0.22557874023914337\n",
      "The representation loss after processing this batch is:  0.00266072154045105\n",
      "\n",
      "The classification loss after processing this batch is:  0.11616059392690659\n",
      "The representation loss after processing this batch is:  0.0027110204100608826\n",
      "\n",
      "The classification loss after processing this batch is:  0.12357289344072342\n",
      "The representation loss after processing this batch is:  0.002878241240978241\n",
      "\n",
      "The classification loss after processing this batch is:  0.10182787477970123\n",
      "The representation loss after processing this batch is:  0.0029493868350982666\n",
      "\n",
      "The classification loss after processing this batch is:  0.09604629874229431\n",
      "The representation loss after processing this batch is:  0.0026816576719284058\n",
      "\n",
      "The classification loss after processing this batch is:  0.07730875164270401\n",
      "The representation loss after processing this batch is:  0.0025218650698661804\n",
      "\n",
      "The classification loss after processing this batch is:  0.1640337109565735\n",
      "The representation loss after processing this batch is:  0.0024115294218063354\n",
      "\n",
      "The classification loss after processing this batch is:  0.18804004788398743\n",
      "The representation loss after processing this batch is:  0.0024562478065490723\n",
      "\n",
      "The classification loss after processing this batch is:  0.1918662041425705\n",
      "The representation loss after processing this batch is:  0.0028776079416275024\n",
      "\n",
      "The classification loss after processing this batch is:  0.11456310003995895\n",
      "The representation loss after processing this batch is:  0.0024421326816082\n",
      "\n",
      "The classification loss after processing this batch is:  0.297728031873703\n",
      "The representation loss after processing this batch is:  0.0021808668971061707\n",
      "\n",
      "The classification loss after processing this batch is:  0.09950044006109238\n",
      "The representation loss after processing this batch is:  0.0023148544132709503\n",
      "\n",
      "The classification loss after processing this batch is:  0.11608059704303741\n",
      "The representation loss after processing this batch is:  0.002365078777074814\n",
      "\n",
      "The classification loss after processing this batch is:  0.1188647598028183\n",
      "The representation loss after processing this batch is:  0.002865772694349289\n",
      "\n",
      "The classification loss after processing this batch is:  0.08198118209838867\n",
      "The representation loss after processing this batch is:  0.0024165958166122437\n",
      "\n",
      "The classification loss after processing this batch is:  0.14490093290805817\n",
      "The representation loss after processing this batch is:  0.0026220083236694336\n",
      "\n",
      "The classification loss after processing this batch is:  0.08646973222494125\n",
      "The representation loss after processing this batch is:  0.0027013644576072693\n",
      "\n",
      "The classification loss after processing this batch is:  0.16772893071174622\n",
      "The representation loss after processing this batch is:  0.002572912722826004\n",
      "\n",
      "The classification loss after processing this batch is:  0.20803683996200562\n",
      "The representation loss after processing this batch is:  0.002862371504306793\n",
      "\n",
      "The classification loss after processing this batch is:  0.18692488968372345\n",
      "The representation loss after processing this batch is:  0.0027151182293891907\n",
      "\n",
      "The classification loss after processing this batch is:  0.1255037784576416\n",
      "The representation loss after processing this batch is:  0.0028815045952796936\n",
      "\n",
      "The classification loss after processing this batch is:  0.10446393489837646\n",
      "The representation loss after processing this batch is:  0.0030406415462493896\n",
      "\n",
      "The classification loss after processing this batch is:  0.18170200288295746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.002373073250055313\n",
      "\n",
      "The classification loss after processing this batch is:  0.13241489231586456\n",
      "The representation loss after processing this batch is:  0.0024102479219436646\n",
      "\n",
      "The classification loss after processing this batch is:  0.035179223865270615\n",
      "The representation loss after processing this batch is:  0.002661503851413727\n",
      "\n",
      "The classification loss after processing this batch is:  0.11715690046548843\n",
      "The representation loss after processing this batch is:  0.002546742558479309\n",
      "\n",
      "The classification loss after processing this batch is:  0.23710645735263824\n",
      "The representation loss after processing this batch is:  0.002841208130121231\n",
      "\n",
      "The classification loss after processing this batch is:  0.29084283113479614\n",
      "The representation loss after processing this batch is:  0.0028121918439865112\n",
      "\n",
      "The classification loss after processing this batch is:  0.2519196569919586\n",
      "The representation loss after processing this batch is:  0.0025604739785194397\n",
      "\n",
      "The classification loss after processing this batch is:  0.17988434433937073\n",
      "The representation loss after processing this batch is:  0.002263076603412628\n",
      "\n",
      "The classification loss after processing this batch is:  0.08875229954719543\n",
      "The representation loss after processing this batch is:  0.0025065019726753235\n",
      "\n",
      "The classification loss after processing this batch is:  0.11228721588850021\n",
      "The representation loss after processing this batch is:  0.0024842247366905212\n",
      "\n",
      "The classification loss after processing this batch is:  0.10391203314065933\n",
      "The representation loss after processing this batch is:  0.0028750337660312653\n",
      "\n",
      "The classification loss after processing this batch is:  0.16040778160095215\n",
      "The representation loss after processing this batch is:  0.0030353739857673645\n",
      "\n",
      "The classification loss after processing this batch is:  0.12184896320104599\n",
      "The representation loss after processing this batch is:  0.0029501691460609436\n",
      "\n",
      "The classification loss after processing this batch is:  0.13290999829769135\n",
      "The representation loss after processing this batch is:  0.00299757719039917\n",
      "\n",
      "The classification loss after processing this batch is:  0.10557261854410172\n",
      "The representation loss after processing this batch is:  0.0026903264224529266\n",
      "\n",
      "The classification loss after processing this batch is:  0.07569702714681625\n",
      "The representation loss after processing this batch is:  0.002591162919998169\n",
      "\n",
      "The classification loss after processing this batch is:  0.18506580591201782\n",
      "The representation loss after processing this batch is:  0.002797544002532959\n",
      "\n",
      "The classification loss after processing this batch is:  0.15302394330501556\n",
      "The representation loss after processing this batch is:  0.002554468810558319\n",
      "\n",
      "The classification loss after processing this batch is:  0.11254028230905533\n",
      "The representation loss after processing this batch is:  0.002561524510383606\n",
      "\n",
      "The classification loss after processing this batch is:  0.2431422919034958\n",
      "The representation loss after processing this batch is:  0.0033937953412532806\n",
      "\n",
      "The classification loss after processing this batch is:  0.28848522901535034\n",
      "The representation loss after processing this batch is:  0.0029074400663375854\n",
      "\n",
      "The classification loss after processing this batch is:  0.16711406409740448\n",
      "The representation loss after processing this batch is:  0.0027117356657981873\n",
      "\n",
      "The classification loss after processing this batch is:  0.1061490848660469\n",
      "The representation loss after processing this batch is:  0.0027905628085136414\n",
      "\n",
      "The classification loss after processing this batch is:  0.11638948321342468\n",
      "The representation loss after processing this batch is:  0.0027710944414138794\n",
      "\n",
      "The classification loss after processing this batch is:  0.06044752895832062\n",
      "The representation loss after processing this batch is:  0.002740725874900818\n",
      "\n",
      "The classification loss after processing this batch is:  0.18227840960025787\n",
      "The representation loss after processing this batch is:  0.002768896520137787\n",
      "\n",
      "The classification loss after processing this batch is:  0.14740458130836487\n",
      "The representation loss after processing this batch is:  0.0028899312019348145\n",
      "\n",
      "The classification loss after processing this batch is:  0.11857655644416809\n",
      "The representation loss after processing this batch is:  0.002800300717353821\n",
      "\n",
      "The classification loss after processing this batch is:  0.2606762945652008\n",
      "The representation loss after processing this batch is:  0.002542853355407715\n",
      "\n",
      "The classification loss after processing this batch is:  0.06160443648695946\n",
      "The representation loss after processing this batch is:  0.0026303157210350037\n",
      "\n",
      "The classification loss after processing this batch is:  0.06920481473207474\n",
      "The representation loss after processing this batch is:  0.0029832273721694946\n",
      "\n",
      "The classification loss after processing this batch is:  0.06684953719377518\n",
      "The representation loss after processing this batch is:  0.002428479492664337\n",
      "\n",
      "The classification loss after processing this batch is:  0.17353957891464233\n",
      "The representation loss after processing this batch is:  0.002460833638906479\n",
      "\n",
      "The classification loss after processing this batch is:  0.20964211225509644\n",
      "The representation loss after processing this batch is:  0.0025875717401504517\n",
      "\n",
      "The classification loss after processing this batch is:  0.1188560500741005\n",
      "The representation loss after processing this batch is:  0.002356685698032379\n",
      "\n",
      "The classification loss after processing this batch is:  0.12310750782489777\n",
      "The representation loss after processing this batch is:  0.002561040222644806\n",
      "\n",
      "The classification loss after processing this batch is:  0.0461081899702549\n",
      "The representation loss after processing this batch is:  0.002415381371974945\n",
      "\n",
      "The classification loss after processing this batch is:  0.0867382287979126\n",
      "The representation loss after processing this batch is:  0.0024114996194839478\n",
      "\n",
      "The classification loss after processing this batch is:  0.07661761343479156\n",
      "The representation loss after processing this batch is:  0.0026801452040672302\n",
      "\n",
      "The classification loss after processing this batch is:  0.049158643931150436\n",
      "The representation loss after processing this batch is:  0.002630963921546936\n",
      "\n",
      "The classification loss after processing this batch is:  0.10373936593532562\n",
      "The representation loss after processing this batch is:  0.0025122053921222687\n",
      "\n",
      "The classification loss after processing this batch is:  0.17864568531513214\n",
      "The representation loss after processing this batch is:  0.0024910196661949158\n",
      "\n",
      "The classification loss after processing this batch is:  0.2094215303659439\n",
      "The representation loss after processing this batch is:  0.002616085112094879\n",
      "\n",
      "The classification loss after processing this batch is:  0.0277567021548748\n",
      "The representation loss after processing this batch is:  0.002278856933116913\n",
      "\n",
      "The classification loss after processing this batch is:  0.053812671452760696\n",
      "The representation loss after processing this batch is:  0.0027842558920383453\n",
      "\n",
      "The classification loss after processing this batch is:  0.08689992874860764\n",
      "The representation loss after processing this batch is:  0.0028717368841171265\n",
      "\n",
      "The classification loss after processing this batch is:  0.16169413924217224\n",
      "The representation loss after processing this batch is:  0.002565242350101471\n",
      "\n",
      "The classification loss after processing this batch is:  0.07585781067609787\n",
      "The representation loss after processing this batch is:  0.002818979322910309\n",
      "\n",
      "The classification loss after processing this batch is:  0.19450335204601288\n",
      "The representation loss after processing this batch is:  0.0027390718460083008\n",
      "\n",
      "The classification loss after processing this batch is:  0.21796336770057678\n",
      "The representation loss after processing this batch is:  0.0028205811977386475\n",
      "\n",
      "The classification loss after processing this batch is:  0.16201607882976532\n",
      "The representation loss after processing this batch is:  0.002763904631137848\n",
      "\n",
      "The classification loss after processing this batch is:  0.13079144060611725\n",
      "The representation loss after processing this batch is:  0.002851013094186783\n",
      "\n",
      "The classification loss after processing this batch is:  0.06721962243318558\n",
      "The representation loss after processing this batch is:  0.002672426402568817\n",
      "\n",
      "The classification loss after processing this batch is:  0.15483330190181732\n",
      "The representation loss after processing this batch is:  0.002299688756465912\n",
      "\n",
      "The classification loss after processing this batch is:  0.1436765342950821\n",
      "The representation loss after processing this batch is:  0.0025708600878715515\n",
      "\n",
      "The classification loss after processing this batch is:  0.07139896601438522\n",
      "The representation loss after processing this batch is:  0.002548396587371826\n",
      "\n",
      "The classification loss after processing this batch is:  0.05302088335156441\n",
      "The representation loss after processing this batch is:  0.0024090856313705444\n",
      "\n",
      "The classification loss after processing this batch is:  0.22270488739013672\n",
      "The representation loss after processing this batch is:  0.002556242048740387\n",
      "\n",
      "The classification loss after processing this batch is:  0.2120513617992401\n",
      "The representation loss after processing this batch is:  0.0023506172001361847\n",
      "\n",
      "The classification loss after processing this batch is:  0.097735695540905\n",
      "The representation loss after processing this batch is:  0.0025885961949825287\n",
      "\n",
      "The classification loss after processing this batch is:  0.246488556265831\n",
      "The representation loss after processing this batch is:  0.0025059133768081665\n",
      "\n",
      "The classification loss after processing this batch is:  0.23434296250343323\n",
      "The representation loss after processing this batch is:  0.0025673657655715942\n",
      "\n",
      "The classification loss after processing this batch is:  0.35528987646102905\n",
      "The representation loss after processing this batch is:  0.0024010352790355682\n",
      "\n",
      "The classification loss after processing this batch is:  0.15269915759563446\n",
      "The representation loss after processing this batch is:  0.0026491209864616394\n",
      "\n",
      "The classification loss after processing this batch is:  0.10542916506528854\n",
      "The representation loss after processing this batch is:  0.002774640917778015\n",
      "\n",
      "The classification loss after processing this batch is:  0.17257322371006012\n",
      "The representation loss after processing this batch is:  0.002699434757232666\n",
      "\n",
      "The classification loss after processing this batch is:  0.08726716786623001\n",
      "The representation loss after processing this batch is:  0.0026595070958137512\n",
      "\n",
      "The classification loss after processing this batch is:  0.07117180526256561\n",
      "The representation loss after processing this batch is:  0.002792075276374817\n",
      "\n",
      "The classification loss after processing this batch is:  0.10037582367658615\n",
      "The representation loss after processing this batch is:  0.0023164786398410797\n",
      "\n",
      "The classification loss after processing this batch is:  0.07019908726215363\n",
      "The representation loss after processing this batch is:  0.002730913460254669\n",
      "\n",
      "The classification loss after processing this batch is:  0.03148176893591881\n",
      "The representation loss after processing this batch is:  0.002988651394844055\n",
      "\n",
      "The classification loss after processing this batch is:  0.11638312041759491\n",
      "The representation loss after processing this batch is:  0.002534709870815277\n",
      "\n",
      "The classification loss after processing this batch is:  0.15178588032722473\n",
      "The representation loss after processing this batch is:  0.0025012940168380737\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08273757994174957\n",
      "The representation loss after processing this batch is:  0.0026462674140930176\n",
      "\n",
      "The classification loss after processing this batch is:  0.09447219222784042\n",
      "The representation loss after processing this batch is:  0.002434220165014267\n",
      "\n",
      "The classification loss after processing this batch is:  0.15255050361156464\n",
      "The representation loss after processing this batch is:  0.0025911852717399597\n",
      "\n",
      "The classification loss after processing this batch is:  0.044232748448848724\n",
      "The representation loss after processing this batch is:  0.0025136545300483704\n",
      "\n",
      "The classification loss after processing this batch is:  0.16915683448314667\n",
      "The representation loss after processing this batch is:  0.002710960805416107\n",
      "\n",
      "The classification loss after processing this batch is:  0.09898258745670319\n",
      "The representation loss after processing this batch is:  0.002357892692089081\n",
      "\n",
      "The classification loss after processing this batch is:  0.22406108677387238\n",
      "The representation loss after processing this batch is:  0.002560872584581375\n",
      "\n",
      "The classification loss after processing this batch is:  0.16506598889827728\n",
      "The representation loss after processing this batch is:  0.0024117976427078247\n",
      "\n",
      "The classification loss after processing this batch is:  0.16926482319831848\n",
      "The representation loss after processing this batch is:  0.002329029142856598\n",
      "\n",
      "The classification loss after processing this batch is:  0.04038489609956741\n",
      "The representation loss after processing this batch is:  0.0024179071187973022\n",
      "\n",
      "The classification loss after processing this batch is:  0.046096883714199066\n",
      "The representation loss after processing this batch is:  0.002436034381389618\n",
      "\n",
      "The classification loss after processing this batch is:  0.15080119669437408\n",
      "The representation loss after processing this batch is:  0.0027236081659793854\n",
      "\n",
      "The classification loss after processing this batch is:  0.05102534592151642\n",
      "The representation loss after processing this batch is:  0.00280192494392395\n",
      "\n",
      "The classification loss after processing this batch is:  0.14623771607875824\n",
      "The representation loss after processing this batch is:  0.0026966407895088196\n",
      "\n",
      "The classification loss after processing this batch is:  0.08383770287036896\n",
      "The representation loss after processing this batch is:  0.002872385084629059\n",
      "\n",
      "The classification loss after processing this batch is:  0.08413416892290115\n",
      "The representation loss after processing this batch is:  0.0026542171835899353\n",
      "\n",
      "The classification loss after processing this batch is:  0.12998193502426147\n",
      "The representation loss after processing this batch is:  0.0026087686419487\n",
      "\n",
      "The classification loss after processing this batch is:  0.07264894992113113\n",
      "The representation loss after processing this batch is:  0.002689950168132782\n",
      "\n",
      "The classification loss after processing this batch is:  0.0860222578048706\n",
      "The representation loss after processing this batch is:  0.0031228363513946533\n",
      "\n",
      "The classification loss after processing this batch is:  0.1953117698431015\n",
      "The representation loss after processing this batch is:  0.002542823553085327\n",
      "\n",
      "The classification loss after processing this batch is:  0.15447364747524261\n",
      "The representation loss after processing this batch is:  0.0027987807989120483\n",
      "\n",
      "The classification loss after processing this batch is:  0.2001028209924698\n",
      "The representation loss after processing this batch is:  0.002759084105491638\n",
      "\n",
      "The classification loss after processing this batch is:  0.21428531408309937\n",
      "The representation loss after processing this batch is:  0.0028982460498809814\n",
      "\n",
      "The classification loss after processing this batch is:  0.12492409348487854\n",
      "The representation loss after processing this batch is:  0.002338215708732605\n",
      "\n",
      "The classification loss after processing this batch is:  0.10415363311767578\n",
      "The representation loss after processing this batch is:  0.0024368315935134888\n",
      "\n",
      "The classification loss after processing this batch is:  0.06044381484389305\n",
      "The representation loss after processing this batch is:  0.002395160496234894\n",
      "\n",
      "The classification loss after processing this batch is:  0.08237194269895554\n",
      "The representation loss after processing this batch is:  0.002566978335380554\n",
      "\n",
      "The classification loss after processing this batch is:  0.06138220056891441\n",
      "The representation loss after processing this batch is:  0.0026656463742256165\n",
      "\n",
      "The classification loss after processing this batch is:  0.1261623650789261\n",
      "The representation loss after processing this batch is:  0.002300642430782318\n",
      "\n",
      "The classification loss after processing this batch is:  0.10036741942167282\n",
      "The representation loss after processing this batch is:  0.002728663384914398\n",
      "\n",
      "The classification loss after processing this batch is:  0.13550211489200592\n",
      "The representation loss after processing this batch is:  0.0025978609919548035\n",
      "\n",
      "The classification loss after processing this batch is:  0.07205688208341599\n",
      "The representation loss after processing this batch is:  0.002423129975795746\n",
      "\n",
      "The classification loss after processing this batch is:  0.1738545149564743\n",
      "The representation loss after processing this batch is:  0.00225241482257843\n",
      "\n",
      "The classification loss after processing this batch is:  0.08175161480903625\n",
      "The representation loss after processing this batch is:  0.0026114359498023987\n",
      "\n",
      "The classification loss after processing this batch is:  0.15741673111915588\n",
      "The representation loss after processing this batch is:  0.002392612397670746\n",
      "\n",
      "The classification loss after processing this batch is:  0.15115971863269806\n",
      "The representation loss after processing this batch is:  0.002573549747467041\n",
      "\n",
      "The classification loss after processing this batch is:  0.12368492782115936\n",
      "The representation loss after processing this batch is:  0.002610132098197937\n",
      "\n",
      "The classification loss after processing this batch is:  0.1022123396396637\n",
      "The representation loss after processing this batch is:  0.0026656687259674072\n",
      "\n",
      "The classification loss after processing this batch is:  0.18688374757766724\n",
      "The representation loss after processing this batch is:  0.002668023109436035\n",
      "\n",
      "The classification loss after processing this batch is:  0.094923235476017\n",
      "The representation loss after processing this batch is:  0.002492867410182953\n",
      "\n",
      "The classification loss after processing this batch is:  0.07305295020341873\n",
      "The representation loss after processing this batch is:  0.0023583397269248962\n",
      "\n",
      "The classification loss after processing this batch is:  0.08840683102607727\n",
      "The representation loss after processing this batch is:  0.0026673898100852966\n",
      "\n",
      "The classification loss after processing this batch is:  0.08195843547582626\n",
      "The representation loss after processing this batch is:  0.002482101321220398\n",
      "\n",
      "The classification loss after processing this batch is:  0.17345495522022247\n",
      "The representation loss after processing this batch is:  0.002408169209957123\n",
      "\n",
      "The classification loss after processing this batch is:  0.16877619922161102\n",
      "The representation loss after processing this batch is:  0.0027954503893852234\n",
      "\n",
      "The classification loss after processing this batch is:  0.1140584647655487\n",
      "The representation loss after processing this batch is:  0.0029463768005371094\n",
      "\n",
      "The classification loss after processing this batch is:  0.08108345419168472\n",
      "The representation loss after processing this batch is:  0.002650536596775055\n",
      "\n",
      "The classification loss after processing this batch is:  0.0854911059141159\n",
      "The representation loss after processing this batch is:  0.002808205783367157\n",
      "\n",
      "The classification loss after processing this batch is:  0.2035050094127655\n",
      "The representation loss after processing this batch is:  0.002730853855609894\n",
      "\n",
      "The classification loss after processing this batch is:  0.059202730655670166\n",
      "The representation loss after processing this batch is:  0.002593010663986206\n",
      "\n",
      "The classification loss after processing this batch is:  0.0959903821349144\n",
      "The representation loss after processing this batch is:  0.0029014497995376587\n",
      "\n",
      "The classification loss after processing this batch is:  0.17731580138206482\n",
      "The representation loss after processing this batch is:  0.0023575611412525177\n",
      "\n",
      "The classification loss after processing this batch is:  0.3069494366645813\n",
      "The representation loss after processing this batch is:  0.0025555267930030823\n",
      "\n",
      "The classification loss after processing this batch is:  0.08848898857831955\n",
      "The representation loss after processing this batch is:  0.002507217228412628\n",
      "\n",
      "The classification loss after processing this batch is:  0.1219261884689331\n",
      "The representation loss after processing this batch is:  0.0024359412491321564\n",
      "\n",
      "The classification loss after processing this batch is:  0.053497347980737686\n",
      "The representation loss after processing this batch is:  0.0026084259152412415\n",
      "\n",
      "The classification loss after processing this batch is:  0.04538746550679207\n",
      "The representation loss after processing this batch is:  0.002328813076019287\n",
      "\n",
      "The classification loss after processing this batch is:  0.11494816094636917\n",
      "The representation loss after processing this batch is:  0.0031630322337150574\n",
      "\n",
      "The classification loss after processing this batch is:  0.08978726714849472\n",
      "The representation loss after processing this batch is:  0.0032431408762931824\n",
      "\n",
      "The classification loss after processing this batch is:  0.06920219957828522\n",
      "The representation loss after processing this batch is:  0.0026274360716342926\n",
      "\n",
      "The classification loss after processing this batch is:  0.07191702723503113\n",
      "The representation loss after processing this batch is:  0.0023200511932373047\n",
      "\n",
      "The classification loss after processing this batch is:  0.17241305112838745\n",
      "The representation loss after processing this batch is:  0.0023769401013851166\n",
      "\n",
      "The classification loss after processing this batch is:  0.14064177870750427\n",
      "The representation loss after processing this batch is:  0.002432502806186676\n",
      "\n",
      "The classification loss after processing this batch is:  0.07585528492927551\n",
      "The representation loss after processing this batch is:  0.0021638385951519012\n",
      "\n",
      "The classification loss after processing this batch is:  0.0844469740986824\n",
      "The representation loss after processing this batch is:  0.0024678707122802734\n",
      "\n",
      "The classification loss after processing this batch is:  0.23428933322429657\n",
      "The representation loss after processing this batch is:  0.0023742131888866425\n",
      "\n",
      "The classification loss after processing this batch is:  0.22155360877513885\n",
      "The representation loss after processing this batch is:  0.0027310773730278015\n",
      "\n",
      "The classification loss after processing this batch is:  0.17713823914527893\n",
      "The representation loss after processing this batch is:  0.0022425763309001923\n",
      "\n",
      "The classification loss after processing this batch is:  0.14629755914211273\n",
      "The representation loss after processing this batch is:  0.002866983413696289\n",
      "\n",
      "The classification loss after processing this batch is:  0.19291459023952484\n",
      "The representation loss after processing this batch is:  0.002314440906047821\n",
      "\n",
      "The classification loss after processing this batch is:  0.09038452804088593\n",
      "The representation loss after processing this batch is:  0.003139585256576538\n",
      "\n",
      "The classification loss after processing this batch is:  0.09552440047264099\n",
      "The representation loss after processing this batch is:  0.0028366446495056152\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.055411335080862045\n",
      "The representation loss after processing this batch is:  0.0026764050126075745\n",
      "\n",
      "The classification loss after processing this batch is:  0.08532442897558212\n",
      "The representation loss after processing this batch is:  0.0022949501872062683\n",
      "\n",
      "The classification loss after processing this batch is:  0.18073712289333344\n",
      "The representation loss after processing this batch is:  0.0024335309863090515\n",
      "\n",
      "The classification loss after processing this batch is:  0.08828959614038467\n",
      "The representation loss after processing this batch is:  0.0029570162296295166\n",
      "\n",
      "The classification loss after processing this batch is:  0.05899260193109512\n",
      "The representation loss after processing this batch is:  0.002520039677619934\n",
      "\n",
      "The classification loss after processing this batch is:  0.034118108451366425\n",
      "The representation loss after processing this batch is:  0.003152221441268921\n",
      "\n",
      "The classification loss after processing this batch is:  0.04370633885264397\n",
      "The representation loss after processing this batch is:  0.002949543297290802\n",
      "\n",
      "The classification loss after processing this batch is:  0.061560917645692825\n",
      "The representation loss after processing this batch is:  0.003178149461746216\n",
      "\n",
      "The classification loss after processing this batch is:  0.08944333344697952\n",
      "The representation loss after processing this batch is:  0.003037385642528534\n",
      "\n",
      "The classification loss after processing this batch is:  0.06098393723368645\n",
      "The representation loss after processing this batch is:  0.0025842562317848206\n",
      "\n",
      "The classification loss after processing this batch is:  0.02892310544848442\n",
      "The representation loss after processing this batch is:  0.0030562207102775574\n",
      "\n",
      "The classification loss after processing this batch is:  0.04668497294187546\n",
      "The representation loss after processing this batch is:  0.003559499979019165\n",
      "\n",
      "The classification loss after processing this batch is:  0.08464669436216354\n",
      "The representation loss after processing this batch is:  0.003532111644744873\n",
      "\n",
      "The classification loss after processing this batch is:  0.019291169941425323\n",
      "The representation loss after processing this batch is:  0.0036667436361312866\n",
      "\n",
      "The classification loss after processing this batch is:  0.049838192760944366\n",
      "The representation loss after processing this batch is:  0.0030060335993766785\n",
      "\n",
      "The classification loss after processing this batch is:  0.16360187530517578\n",
      "The representation loss after processing this batch is:  0.0029134899377822876\n",
      "\n",
      "The classification loss after processing this batch is:  0.03368797153234482\n",
      "The representation loss after processing this batch is:  0.0033844783902168274\n",
      "\n",
      "The classification loss after processing this batch is:  0.015130702406167984\n",
      "The representation loss after processing this batch is:  0.003117963671684265\n",
      "\n",
      "The classification loss after processing this batch is:  0.023959267884492874\n",
      "The representation loss after processing this batch is:  0.0028004273772239685\n",
      "\n",
      "The classification loss after processing this batch is:  0.04177910089492798\n",
      "The representation loss after processing this batch is:  0.003137342631816864\n",
      "\n",
      "The classification loss after processing this batch is:  0.03211689367890358\n",
      "The representation loss after processing this batch is:  0.0032832175493240356\n",
      "\n",
      "The classification loss after processing this batch is:  0.030564896762371063\n",
      "The representation loss after processing this batch is:  0.0032130777835845947\n",
      "\n",
      "The classification loss after processing this batch is:  0.0259697362780571\n",
      "The representation loss after processing this batch is:  0.003341890871524811\n",
      "\n",
      "The classification loss after processing this batch is:  0.1889924854040146\n",
      "The representation loss after processing this batch is:  0.0037691593170166016\n",
      "\n",
      "The classification loss after processing this batch is:  0.27778998017311096\n",
      "The representation loss after processing this batch is:  0.003463737666606903\n",
      "\n",
      "The classification loss after processing this batch is:  0.19635938107967377\n",
      "The representation loss after processing this batch is:  0.0036673620343208313\n",
      "\n",
      "The classification loss after processing this batch is:  0.05515368655323982\n",
      "The representation loss after processing this batch is:  0.0027155056595802307\n",
      "\n",
      "The classification loss after processing this batch is:  0.022226722911000252\n",
      "The representation loss after processing this batch is:  0.0033627599477767944\n",
      "\n",
      "The classification loss after processing this batch is:  0.026097675785422325\n",
      "The representation loss after processing this batch is:  0.0024649500846862793\n",
      "\n",
      "The classification loss after processing this batch is:  0.12963585555553436\n",
      "The representation loss after processing this batch is:  0.002280227839946747\n",
      "\n",
      "The classification loss after processing this batch is:  0.35292765498161316\n",
      "The representation loss after processing this batch is:  0.003042764961719513\n",
      "\n",
      "The classification loss after processing this batch is:  0.07035520672798157\n",
      "The representation loss after processing this batch is:  0.0026624202728271484\n",
      "\n",
      "The classification loss after processing this batch is:  0.04777251183986664\n",
      "The representation loss after processing this batch is:  0.0033289268612861633\n",
      "\n",
      "The classification loss after processing this batch is:  0.05798095464706421\n",
      "The representation loss after processing this batch is:  0.003281734883785248\n",
      "\n",
      "The classification loss after processing this batch is:  0.047155365347862244\n",
      "The representation loss after processing this batch is:  0.0037564486265182495\n",
      "\n",
      "The classification loss after processing this batch is:  0.10201454907655716\n",
      "The representation loss after processing this batch is:  0.0024394243955612183\n",
      "\n",
      "The classification loss after processing this batch is:  0.04948834329843521\n",
      "The representation loss after processing this batch is:  0.002422034740447998\n",
      "\n",
      "The classification loss after processing this batch is:  0.08157555013895035\n",
      "The representation loss after processing this batch is:  0.0024886950850486755\n",
      "\n",
      "The classification loss after processing this batch is:  0.1109980046749115\n",
      "The representation loss after processing this batch is:  0.0023878365755081177\n",
      "\n",
      "The classification loss after processing this batch is:  0.11429620534181595\n",
      "The representation loss after processing this batch is:  0.0027656257152557373\n",
      "\n",
      "The classification loss after processing this batch is:  0.06881751865148544\n",
      "The representation loss after processing this batch is:  0.0029740110039711\n",
      "\n",
      "The classification loss after processing this batch is:  0.08645370602607727\n",
      "The representation loss after processing this batch is:  0.002859644591808319\n",
      "\n",
      "The classification loss after processing this batch is:  0.10286787897348404\n",
      "The representation loss after processing this batch is:  0.0023678503930568695\n",
      "\n",
      "The classification loss after processing this batch is:  0.12426157295703888\n",
      "The representation loss after processing this batch is:  0.002341434359550476\n",
      "\n",
      "The classification loss after processing this batch is:  0.08589651435613632\n",
      "The representation loss after processing this batch is:  0.002541378140449524\n",
      "\n",
      "The classification loss after processing this batch is:  0.15982241928577423\n",
      "The representation loss after processing this batch is:  0.0023221299052238464\n",
      "\n",
      "The classification loss after processing this batch is:  0.14599238336086273\n",
      "The representation loss after processing this batch is:  0.002496078610420227\n",
      "\n",
      "The classification loss after processing this batch is:  0.15613970160484314\n",
      "The representation loss after processing this batch is:  0.0032296888530254364\n",
      "\n",
      "The classification loss after processing this batch is:  0.0658976286649704\n",
      "The representation loss after processing this batch is:  0.0024989545345306396\n",
      "\n",
      "The classification loss after processing this batch is:  0.27519720792770386\n",
      "The representation loss after processing this batch is:  0.002438552677631378\n",
      "\n",
      "The classification loss after processing this batch is:  0.14206968247890472\n",
      "The representation loss after processing this batch is:  0.0022829845547676086\n",
      "\n",
      "The classification loss after processing this batch is:  0.11656186729669571\n",
      "The representation loss after processing this batch is:  0.002324223518371582\n",
      "\n",
      "The classification loss after processing this batch is:  0.22348074615001678\n",
      "The representation loss after processing this batch is:  0.002643667161464691\n",
      "\n",
      "The classification loss after processing this batch is:  0.15297432243824005\n",
      "The representation loss after processing this batch is:  0.002735741436481476\n",
      "\n",
      "The classification loss after processing this batch is:  0.05187426134943962\n",
      "The representation loss after processing this batch is:  0.002598874270915985\n",
      "\n",
      "The classification loss after processing this batch is:  0.21057148277759552\n",
      "The representation loss after processing this batch is:  0.0028496012091636658\n",
      "\n",
      "The classification loss after processing this batch is:  0.13051599264144897\n",
      "The representation loss after processing this batch is:  0.0026967450976371765\n",
      "\n",
      "The classification loss after processing this batch is:  0.27176398038864136\n",
      "The representation loss after processing this batch is:  0.0023397505283355713\n",
      "\n",
      "The classification loss after processing this batch is:  0.08632803708314896\n",
      "The representation loss after processing this batch is:  0.0024045147001743317\n",
      "\n",
      "The classification loss after processing this batch is:  0.06177028268575668\n",
      "The representation loss after processing this batch is:  0.002566009759902954\n",
      "\n",
      "The classification loss after processing this batch is:  0.08387842774391174\n",
      "The representation loss after processing this batch is:  0.002465568482875824\n",
      "\n",
      "The classification loss after processing this batch is:  0.07805678993463516\n",
      "The representation loss after processing this batch is:  0.0021097473800182343\n",
      "\n",
      "The classification loss after processing this batch is:  0.09951508045196533\n",
      "The representation loss after processing this batch is:  0.0024653859436511993\n",
      "\n",
      "The classification loss after processing this batch is:  0.05126481130719185\n",
      "The representation loss after processing this batch is:  0.0026111379265785217\n",
      "\n",
      "The classification loss after processing this batch is:  0.04260701313614845\n",
      "The representation loss after processing this batch is:  0.0026755258440971375\n",
      "\n",
      "The classification loss after processing this batch is:  0.07587703317403793\n",
      "The representation loss after processing this batch is:  0.0025076307356357574\n",
      "\n",
      "The classification loss after processing this batch is:  0.0702645555138588\n",
      "The representation loss after processing this batch is:  0.0028799064457416534\n",
      "\n",
      "The classification loss after processing this batch is:  0.15401588380336761\n",
      "The representation loss after processing this batch is:  0.0024447962641716003\n",
      "\n",
      "The classification loss after processing this batch is:  0.07491113990545273\n",
      "The representation loss after processing this batch is:  0.0029098205268383026\n",
      "\n",
      "The classification loss after processing this batch is:  0.09486059099435806\n",
      "The representation loss after processing this batch is:  0.0023516081273555756\n",
      "\n",
      "The classification loss after processing this batch is:  0.043110866099596024\n",
      "The representation loss after processing this batch is:  0.0025418177247047424\n",
      "\n",
      "The classification loss after processing this batch is:  0.061892036348581314\n",
      "The representation loss after processing this batch is:  0.002839222550392151\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08704280108213425\n",
      "The representation loss after processing this batch is:  0.0023685209453105927\n",
      "\n",
      "The classification loss after processing this batch is:  0.08072587847709656\n",
      "The representation loss after processing this batch is:  0.002748429775238037\n",
      "\n",
      "The classification loss after processing this batch is:  0.07773125171661377\n",
      "The representation loss after processing this batch is:  0.0025848671793937683\n",
      "\n",
      "The classification loss after processing this batch is:  0.18419910967350006\n",
      "The representation loss after processing this batch is:  0.002857029438018799\n",
      "\n",
      "The classification loss after processing this batch is:  0.0947633609175682\n",
      "The representation loss after processing this batch is:  0.002497442066669464\n",
      "\n",
      "The classification loss after processing this batch is:  0.08042499423027039\n",
      "The representation loss after processing this batch is:  0.0024290643632411957\n",
      "\n",
      "The classification loss after processing this batch is:  0.1345175802707672\n",
      "The representation loss after processing this batch is:  0.0026991739869117737\n",
      "\n",
      "The classification loss after processing this batch is:  0.06184802204370499\n",
      "The representation loss after processing this batch is:  0.0023516565561294556\n",
      "\n",
      "The classification loss after processing this batch is:  0.08132163435220718\n",
      "The representation loss after processing this batch is:  0.0022386498749256134\n",
      "\n",
      "The classification loss after processing this batch is:  0.20371344685554504\n",
      "The representation loss after processing this batch is:  0.002851370722055435\n",
      "\n",
      "The classification loss after processing this batch is:  0.04767383262515068\n",
      "The representation loss after processing this batch is:  0.002527676522731781\n",
      "\n",
      "The classification loss after processing this batch is:  0.1181839257478714\n",
      "The representation loss after processing this batch is:  0.0023765861988067627\n",
      "\n",
      "The classification loss after processing this batch is:  0.09032479673624039\n",
      "The representation loss after processing this batch is:  0.002547856420278549\n",
      "\n",
      "The classification loss after processing this batch is:  0.09141317754983902\n",
      "The representation loss after processing this batch is:  0.002324100583791733\n",
      "\n",
      "The classification loss after processing this batch is:  0.1029796302318573\n",
      "The representation loss after processing this batch is:  0.002330198884010315\n",
      "\n",
      "The classification loss after processing this batch is:  0.06316099315881729\n",
      "The representation loss after processing this batch is:  0.0026007816195487976\n",
      "\n",
      "The classification loss after processing this batch is:  0.1316864788532257\n",
      "The representation loss after processing this batch is:  0.0027710869908332825\n",
      "\n",
      "The classification loss after processing this batch is:  0.11553860455751419\n",
      "The representation loss after processing this batch is:  0.0027268901467323303\n",
      "\n",
      "The classification loss after processing this batch is:  0.12139252573251724\n",
      "The representation loss after processing this batch is:  0.002669490873813629\n",
      "\n",
      "The classification loss after processing this batch is:  0.12872609496116638\n",
      "The representation loss after processing this batch is:  0.0023890063166618347\n",
      "\n",
      "The classification loss after processing this batch is:  0.12154772132635117\n",
      "The representation loss after processing this batch is:  0.002689070999622345\n",
      "\n",
      "The classification loss after processing this batch is:  0.11516625434160233\n",
      "The representation loss after processing this batch is:  0.0024706050753593445\n",
      "\n",
      "The classification loss after processing this batch is:  0.07923881709575653\n",
      "The representation loss after processing this batch is:  0.0023607686161994934\n",
      "\n",
      "The classification loss after processing this batch is:  0.07381918281316757\n",
      "The representation loss after processing this batch is:  0.0023037493228912354\n",
      "\n",
      "The classification loss after processing this batch is:  0.1795872002840042\n",
      "The representation loss after processing this batch is:  0.0025660060346126556\n",
      "\n",
      "The classification loss after processing this batch is:  0.15565909445285797\n",
      "The representation loss after processing this batch is:  0.002499222755432129\n",
      "\n",
      "The classification loss after processing this batch is:  0.07872964441776276\n",
      "The representation loss after processing this batch is:  0.0024250373244285583\n",
      "\n",
      "The classification loss after processing this batch is:  0.06828607618808746\n",
      "The representation loss after processing this batch is:  0.002454802393913269\n",
      "\n",
      "The classification loss after processing this batch is:  0.07306831330060959\n",
      "The representation loss after processing this batch is:  0.002376493066549301\n",
      "\n",
      "The classification loss after processing this batch is:  0.0825941190123558\n",
      "The representation loss after processing this batch is:  0.0027791112661361694\n",
      "\n",
      "The classification loss after processing this batch is:  0.1425977349281311\n",
      "The representation loss after processing this batch is:  0.0022369734942913055\n",
      "\n",
      "The classification loss after processing this batch is:  0.06373954564332962\n",
      "The representation loss after processing this batch is:  0.0023766979575157166\n",
      "\n",
      "The classification loss after processing this batch is:  0.20950549840927124\n",
      "The representation loss after processing this batch is:  0.0023602694272994995\n",
      "\n",
      "The classification loss after processing this batch is:  0.14204075932502747\n",
      "The representation loss after processing this batch is:  0.0024097561836242676\n",
      "\n",
      "The classification loss after processing this batch is:  0.1269175112247467\n",
      "The representation loss after processing this batch is:  0.0024116933345794678\n",
      "\n",
      "The classification loss after processing this batch is:  0.07515761256217957\n",
      "The representation loss after processing this batch is:  0.0022269003093242645\n",
      "\n",
      "The classification loss after processing this batch is:  0.06591461598873138\n",
      "The representation loss after processing this batch is:  0.0025534480810165405\n",
      "\n",
      "The classification loss after processing this batch is:  0.0948137417435646\n",
      "The representation loss after processing this batch is:  0.0022692345082759857\n",
      "\n",
      "The classification loss after processing this batch is:  0.17182572185993195\n",
      "The representation loss after processing this batch is:  0.0023171529173851013\n",
      "\n",
      "The classification loss after processing this batch is:  0.090814009308815\n",
      "The representation loss after processing this batch is:  0.002354070544242859\n",
      "\n",
      "The classification loss after processing this batch is:  0.28073450922966003\n",
      "The representation loss after processing this batch is:  0.002330973744392395\n",
      "\n",
      "The classification loss after processing this batch is:  0.10770385712385178\n",
      "The representation loss after processing this batch is:  0.002178814262151718\n",
      "\n",
      "The classification loss after processing this batch is:  0.06563138216733932\n",
      "The representation loss after processing this batch is:  0.003032602369785309\n",
      "\n",
      "The classification loss after processing this batch is:  0.16298727691173553\n",
      "The representation loss after processing this batch is:  0.002699457108974457\n",
      "\n",
      "The classification loss after processing this batch is:  0.06248270720243454\n",
      "The representation loss after processing this batch is:  0.002826996147632599\n",
      "\n",
      "The classification loss after processing this batch is:  0.2510010600090027\n",
      "The representation loss after processing this batch is:  0.0027976781129837036\n",
      "\n",
      "The classification loss after processing this batch is:  0.11591565608978271\n",
      "The representation loss after processing this batch is:  0.0023031458258628845\n",
      "\n",
      "The classification loss after processing this batch is:  0.1686009019613266\n",
      "The representation loss after processing this batch is:  0.0024376623332500458\n",
      "\n",
      "The classification loss after processing this batch is:  0.2452584207057953\n",
      "The representation loss after processing this batch is:  0.0025399401783943176\n",
      "\n",
      "The classification loss after processing this batch is:  0.14387144148349762\n",
      "The representation loss after processing this batch is:  0.002306602895259857\n",
      "\n",
      "The classification loss after processing this batch is:  0.06293570250272751\n",
      "The representation loss after processing this batch is:  0.0025375336408615112\n",
      "\n",
      "The classification loss after processing this batch is:  0.157307967543602\n",
      "The representation loss after processing this batch is:  0.0023931115865707397\n",
      "\n",
      "The classification loss after processing this batch is:  0.12812554836273193\n",
      "The representation loss after processing this batch is:  0.0025815218687057495\n",
      "\n",
      "The classification loss after processing this batch is:  0.12410495430231094\n",
      "The representation loss after processing this batch is:  0.0024804994463920593\n",
      "\n",
      "The classification loss after processing this batch is:  0.07460670918226242\n",
      "The representation loss after processing this batch is:  0.0023034140467643738\n",
      "\n",
      "The classification loss after processing this batch is:  0.08719158172607422\n",
      "The representation loss after processing this batch is:  0.00237264484167099\n",
      "\n",
      "The classification loss after processing this batch is:  0.1569404900074005\n",
      "The representation loss after processing this batch is:  0.0024071484804153442\n",
      "\n",
      "The classification loss after processing this batch is:  0.1459972858428955\n",
      "The representation loss after processing this batch is:  0.0029404684901237488\n",
      "\n",
      "The classification loss after processing this batch is:  0.16986078023910522\n",
      "The representation loss after processing this batch is:  0.0024684593081474304\n",
      "\n",
      "The classification loss after processing this batch is:  0.23016105592250824\n",
      "The representation loss after processing this batch is:  0.0025955289602279663\n",
      "\n",
      "The classification loss after processing this batch is:  0.15746857225894928\n",
      "The representation loss after processing this batch is:  0.002820022404193878\n",
      "\n",
      "The classification loss after processing this batch is:  0.07745934277772903\n",
      "The representation loss after processing this batch is:  0.0028183311223983765\n",
      "\n",
      "The classification loss after processing this batch is:  0.08172845840454102\n",
      "The representation loss after processing this batch is:  0.0024420619010925293\n",
      "\n",
      "The classification loss after processing this batch is:  0.046688511967659\n",
      "The representation loss after processing this batch is:  0.0025487393140792847\n",
      "\n",
      "The classification loss after processing this batch is:  0.1293822079896927\n",
      "The representation loss after processing this batch is:  0.0026927143335342407\n",
      "\n",
      "The classification loss after processing this batch is:  0.09763047099113464\n",
      "The representation loss after processing this batch is:  0.0025856494903564453\n",
      "\n",
      "The classification loss after processing this batch is:  0.25525444746017456\n",
      "The representation loss after processing this batch is:  0.002690359950065613\n",
      "\n",
      "The classification loss after processing this batch is:  0.258709579706192\n",
      "The representation loss after processing this batch is:  0.0025033652782440186\n",
      "\n",
      "The classification loss after processing this batch is:  0.09174574911594391\n",
      "The representation loss after processing this batch is:  0.002716757357120514\n",
      "\n",
      "The classification loss after processing this batch is:  0.11837859451770782\n",
      "The representation loss after processing this batch is:  0.002778284251689911\n",
      "\n",
      "The classification loss after processing this batch is:  0.14740462601184845\n",
      "The representation loss after processing this batch is:  0.002320054918527603\n",
      "\n",
      "The classification loss after processing this batch is:  0.05585068091750145\n",
      "The representation loss after processing this batch is:  0.002664923667907715\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.05846729129552841\n",
      "The representation loss after processing this batch is:  0.0027368739247322083\n",
      "\n",
      "The classification loss after processing this batch is:  0.11958661675453186\n",
      "The representation loss after processing this batch is:  0.0023561418056488037\n",
      "\n",
      "The classification loss after processing this batch is:  0.0782320648431778\n",
      "The representation loss after processing this batch is:  0.003212064504623413\n",
      "\n",
      "The classification loss after processing this batch is:  0.09195657819509506\n",
      "The representation loss after processing this batch is:  0.002862546592950821\n",
      "\n",
      "The classification loss after processing this batch is:  0.2336483597755432\n",
      "The representation loss after processing this batch is:  0.0035632625222206116\n",
      "\n",
      "The classification loss after processing this batch is:  0.22671197354793549\n",
      "The representation loss after processing this batch is:  0.002254076302051544\n",
      "\n",
      "The classification loss after processing this batch is:  0.11410399526357651\n",
      "The representation loss after processing this batch is:  0.0028024092316627502\n",
      "\n",
      "The classification loss after processing this batch is:  0.18974903225898743\n",
      "The representation loss after processing this batch is:  0.002597130835056305\n",
      "\n",
      "The classification loss after processing this batch is:  0.18600283563137054\n",
      "The representation loss after processing this batch is:  0.0024533234536647797\n",
      "\n",
      "The classification loss after processing this batch is:  0.07119438052177429\n",
      "The representation loss after processing this batch is:  0.0025634728372097015\n",
      "\n",
      "The classification loss after processing this batch is:  0.1316480040550232\n",
      "The representation loss after processing this batch is:  0.0023608431220054626\n",
      "\n",
      "The classification loss after processing this batch is:  0.36845335364341736\n",
      "The representation loss after processing this batch is:  0.0029672831296920776\n",
      "\n",
      "The classification loss after processing this batch is:  0.1511341780424118\n",
      "The representation loss after processing this batch is:  0.0027543343603610992\n",
      "\n",
      "The classification loss after processing this batch is:  0.061519913375377655\n",
      "The representation loss after processing this batch is:  0.0028593093156814575\n",
      "\n",
      "The classification loss after processing this batch is:  0.06976820528507233\n",
      "The representation loss after processing this batch is:  0.002956915646791458\n",
      "\n",
      "The classification loss after processing this batch is:  0.05620387941598892\n",
      "The representation loss after processing this batch is:  0.0029831677675247192\n",
      "\n",
      "The classification loss after processing this batch is:  0.09400923550128937\n",
      "The representation loss after processing this batch is:  0.0027066990733146667\n",
      "\n",
      "The classification loss after processing this batch is:  0.0686359852552414\n",
      "The representation loss after processing this batch is:  0.0028273463249206543\n",
      "\n",
      "The classification loss after processing this batch is:  0.13438883423805237\n",
      "The representation loss after processing this batch is:  0.0023786239326000214\n",
      "\n",
      "The classification loss after processing this batch is:  0.10112845152616501\n",
      "The representation loss after processing this batch is:  0.0024348944425582886\n",
      "\n",
      "The classification loss after processing this batch is:  0.18871520459651947\n",
      "The representation loss after processing this batch is:  0.00242006778717041\n",
      "\n",
      "The classification loss after processing this batch is:  0.08577706664800644\n",
      "The representation loss after processing this batch is:  0.0022679604589939117\n",
      "\n",
      "The classification loss after processing this batch is:  0.10599331557750702\n",
      "The representation loss after processing this batch is:  0.0024222470819950104\n",
      "\n",
      "The classification loss after processing this batch is:  0.14098504185676575\n",
      "The representation loss after processing this batch is:  0.002429857850074768\n",
      "\n",
      "The classification loss after processing this batch is:  0.12875735759735107\n",
      "The representation loss after processing this batch is:  0.00254666805267334\n",
      "\n",
      "The classification loss after processing this batch is:  0.06623857468366623\n",
      "The representation loss after processing this batch is:  0.0023458972573280334\n",
      "\n",
      "The classification loss after processing this batch is:  0.16202156245708466\n",
      "The representation loss after processing this batch is:  0.002426549792289734\n",
      "\n",
      "The classification loss after processing this batch is:  0.17137864232063293\n",
      "The representation loss after processing this batch is:  0.002494916319847107\n",
      "\n",
      "The classification loss after processing this batch is:  0.13914655148983002\n",
      "The representation loss after processing this batch is:  0.0022669732570648193\n",
      "\n",
      "The classification loss after processing this batch is:  0.12603338062763214\n",
      "The representation loss after processing this batch is:  0.0027113258838653564\n",
      "\n",
      "The classification loss after processing this batch is:  0.1758812516927719\n",
      "The representation loss after processing this batch is:  0.0026325955986976624\n",
      "\n",
      "The classification loss after processing this batch is:  0.2035321593284607\n",
      "The representation loss after processing this batch is:  0.002794615924358368\n",
      "\n",
      "The classification loss after processing this batch is:  0.14910182356834412\n",
      "The representation loss after processing this batch is:  0.0028308629989624023\n",
      "\n",
      "The classification loss after processing this batch is:  0.09188508242368698\n",
      "The representation loss after processing this batch is:  0.002876855432987213\n",
      "\n",
      "The classification loss after processing this batch is:  0.09012962877750397\n",
      "The representation loss after processing this batch is:  0.0029280632734298706\n",
      "\n",
      "The classification loss after processing this batch is:  0.2243504524230957\n",
      "The representation loss after processing this batch is:  0.0024453848600387573\n",
      "\n",
      "The classification loss after processing this batch is:  0.1722693145275116\n",
      "The representation loss after processing this batch is:  0.002377469092607498\n",
      "\n",
      "The classification loss after processing this batch is:  0.26151785254478455\n",
      "The representation loss after processing this batch is:  0.0027177929878234863\n",
      "\n",
      "The classification loss after processing this batch is:  0.2735593914985657\n",
      "The representation loss after processing this batch is:  0.002289406955242157\n",
      "\n",
      "The classification loss after processing this batch is:  0.17123033106327057\n",
      "The representation loss after processing this batch is:  0.002411533147096634\n",
      "\n",
      "The classification loss after processing this batch is:  0.09077318012714386\n",
      "The representation loss after processing this batch is:  0.002503439784049988\n",
      "\n",
      "The classification loss after processing this batch is:  0.07551970332860947\n",
      "The representation loss after processing this batch is:  0.002459317445755005\n",
      "\n",
      "The classification loss after processing this batch is:  0.05291100591421127\n",
      "The representation loss after processing this batch is:  0.0028642266988754272\n",
      "\n",
      "The classification loss after processing this batch is:  0.11645285040140152\n",
      "The representation loss after processing this batch is:  0.0030379444360733032\n",
      "\n",
      "The classification loss after processing this batch is:  0.06013169139623642\n",
      "The representation loss after processing this batch is:  0.002600274980068207\n",
      "\n",
      "The classification loss after processing this batch is:  0.18387793004512787\n",
      "The representation loss after processing this batch is:  0.0034995824098587036\n",
      "\n",
      "The classification loss after processing this batch is:  0.11515501141548157\n",
      "The representation loss after processing this batch is:  0.002587161958217621\n",
      "\n",
      "The classification loss after processing this batch is:  0.09864380955696106\n",
      "The representation loss after processing this batch is:  0.002626575529575348\n",
      "\n",
      "The classification loss after processing this batch is:  0.18961948156356812\n",
      "The representation loss after processing this batch is:  0.002450093626976013\n",
      "\n",
      "The classification loss after processing this batch is:  0.08683522790670395\n",
      "The representation loss after processing this batch is:  0.002751678228378296\n",
      "\n",
      "The classification loss after processing this batch is:  0.11300592124462128\n",
      "The representation loss after processing this batch is:  0.0034100040793418884\n",
      "\n",
      "The classification loss after processing this batch is:  0.2433585226535797\n",
      "The representation loss after processing this batch is:  0.0033060386776924133\n",
      "\n",
      "The classification loss after processing this batch is:  0.1251026690006256\n",
      "The representation loss after processing this batch is:  0.0027847066521644592\n",
      "\n",
      "The classification loss after processing this batch is:  0.1354273408651352\n",
      "The representation loss after processing this batch is:  0.002424784004688263\n",
      "\n",
      "The classification loss after processing this batch is:  0.0665365681052208\n",
      "The representation loss after processing this batch is:  0.0023543089628219604\n",
      "\n",
      "The classification loss after processing this batch is:  0.03606312721967697\n",
      "The representation loss after processing this batch is:  0.0028371959924697876\n",
      "\n",
      "The classification loss after processing this batch is:  0.06510712206363678\n",
      "The representation loss after processing this batch is:  0.0028808414936065674\n",
      "\n",
      "The classification loss after processing this batch is:  0.06682156026363373\n",
      "The representation loss after processing this batch is:  0.0026467517018318176\n",
      "\n",
      "The classification loss after processing this batch is:  0.10666020214557648\n",
      "The representation loss after processing this batch is:  0.00225009024143219\n",
      "\n",
      "The classification loss after processing this batch is:  0.09351885318756104\n",
      "The representation loss after processing this batch is:  0.0028024762868881226\n",
      "\n",
      "The classification loss after processing this batch is:  0.12429531663656235\n",
      "The representation loss after processing this batch is:  0.002695053815841675\n",
      "\n",
      "The classification loss after processing this batch is:  0.31905752420425415\n",
      "The representation loss after processing this batch is:  0.002824351191520691\n",
      "\n",
      "The classification loss after processing this batch is:  0.23590022325515747\n",
      "The representation loss after processing this batch is:  0.0026439279317855835\n",
      "\n",
      "The classification loss after processing this batch is:  0.09789880365133286\n",
      "The representation loss after processing this batch is:  0.0024766921997070312\n",
      "\n",
      "The classification loss after processing this batch is:  0.06751041114330292\n",
      "The representation loss after processing this batch is:  0.0027975067496299744\n",
      "\n",
      "The classification loss after processing this batch is:  0.09976771473884583\n",
      "The representation loss after processing this batch is:  0.0025131553411483765\n",
      "\n",
      "The classification loss after processing this batch is:  0.08586455881595612\n",
      "The representation loss after processing this batch is:  0.002512916922569275\n",
      "\n",
      "The classification loss after processing this batch is:  0.04019538313150406\n",
      "The representation loss after processing this batch is:  0.0024786442518234253\n",
      "\n",
      "The classification loss after processing this batch is:  0.05405011028051376\n",
      "The representation loss after processing this batch is:  0.0026977472007274628\n",
      "\n",
      "The classification loss after processing this batch is:  0.09684129804372787\n",
      "The representation loss after processing this batch is:  0.0022299066185951233\n",
      "\n",
      "The classification loss after processing this batch is:  0.13498455286026\n",
      "The representation loss after processing this batch is:  0.002438783645629883\n",
      "\n",
      "The classification loss after processing this batch is:  0.08396319299936295\n",
      "The representation loss after processing this batch is:  0.002739228308200836\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.06911031901836395\n",
      "The representation loss after processing this batch is:  0.002505481243133545\n",
      "\n",
      "The classification loss after processing this batch is:  0.06193969026207924\n",
      "The representation loss after processing this batch is:  0.0023165233433246613\n",
      "\n",
      "The classification loss after processing this batch is:  0.26043620705604553\n",
      "The representation loss after processing this batch is:  0.0023292601108551025\n",
      "\n",
      "The classification loss after processing this batch is:  0.10448034852743149\n",
      "The representation loss after processing this batch is:  0.0027061328291893005\n",
      "\n",
      "The classification loss after processing this batch is:  0.054626815021038055\n",
      "The representation loss after processing this batch is:  0.002629324793815613\n",
      "\n",
      "The classification loss after processing this batch is:  0.12686681747436523\n",
      "The representation loss after processing this batch is:  0.00264856219291687\n",
      "\n",
      "The classification loss after processing this batch is:  0.09754879027605057\n",
      "The representation loss after processing this batch is:  0.0024132542312145233\n",
      "\n",
      "The classification loss after processing this batch is:  0.056804999709129333\n",
      "The representation loss after processing this batch is:  0.0023172013461589813\n",
      "\n",
      "The classification loss after processing this batch is:  0.1327144205570221\n",
      "The representation loss after processing this batch is:  0.0025051943957805634\n",
      "\n",
      "The classification loss after processing this batch is:  0.05871925875544548\n",
      "The representation loss after processing this batch is:  0.0022786930203437805\n",
      "\n",
      "The classification loss after processing this batch is:  0.06372754275798798\n",
      "The representation loss after processing this batch is:  0.002697579562664032\n",
      "\n",
      "The classification loss after processing this batch is:  0.11489197611808777\n",
      "The representation loss after processing this batch is:  0.0021284036338329315\n",
      "\n",
      "The classification loss after processing this batch is:  0.16459223628044128\n",
      "The representation loss after processing this batch is:  0.0025848597288131714\n",
      "\n",
      "The classification loss after processing this batch is:  0.12404327839612961\n",
      "The representation loss after processing this batch is:  0.002559646964073181\n",
      "\n",
      "The classification loss after processing this batch is:  0.15179313719272614\n",
      "The representation loss after processing this batch is:  0.0023842044174671173\n",
      "\n",
      "The classification loss after processing this batch is:  0.1112464964389801\n",
      "The representation loss after processing this batch is:  0.0024534687399864197\n",
      "\n",
      "The classification loss after processing this batch is:  0.17073504626750946\n",
      "The representation loss after processing this batch is:  0.002540886402130127\n",
      "\n",
      "The classification loss after processing this batch is:  0.081535205245018\n",
      "The representation loss after processing this batch is:  0.002594761550426483\n",
      "\n",
      "The classification loss after processing this batch is:  0.12902969121932983\n",
      "The representation loss after processing this batch is:  0.002467069774866104\n",
      "\n",
      "The classification loss after processing this batch is:  0.06780710071325302\n",
      "The representation loss after processing this batch is:  0.0024361684918403625\n",
      "\n",
      "The classification loss after processing this batch is:  0.17912136018276215\n",
      "The representation loss after processing this batch is:  0.0024358443915843964\n",
      "\n",
      "The classification loss after processing this batch is:  0.10128424316644669\n",
      "The representation loss after processing this batch is:  0.002727694809436798\n",
      "\n",
      "The classification loss after processing this batch is:  0.1670874059200287\n",
      "The representation loss after processing this batch is:  0.002416156232357025\n",
      "\n",
      "The classification loss after processing this batch is:  0.10917150229215622\n",
      "The representation loss after processing this batch is:  0.0023179836571216583\n",
      "\n",
      "The classification loss after processing this batch is:  0.10798556357622147\n",
      "The representation loss after processing this batch is:  0.002605028450489044\n",
      "\n",
      "The classification loss after processing this batch is:  0.1488427072763443\n",
      "The representation loss after processing this batch is:  0.0023551806807518005\n",
      "\n",
      "The classification loss after processing this batch is:  0.09447606652975082\n",
      "The representation loss after processing this batch is:  0.0023830756545066833\n",
      "\n",
      "The classification loss after processing this batch is:  0.1421860158443451\n",
      "The representation loss after processing this batch is:  0.002539031207561493\n",
      "\n",
      "The classification loss after processing this batch is:  0.20228801667690277\n",
      "The representation loss after processing this batch is:  0.0022719502449035645\n",
      "\n",
      "The classification loss after processing this batch is:  0.24079670011997223\n",
      "The representation loss after processing this batch is:  0.0021682865917682648\n",
      "\n",
      "The classification loss after processing this batch is:  0.18763190507888794\n",
      "The representation loss after processing this batch is:  0.0024015307426452637\n",
      "\n",
      "The classification loss after processing this batch is:  0.07723485678434372\n",
      "The representation loss after processing this batch is:  0.002686265856027603\n",
      "\n",
      "The classification loss after processing this batch is:  0.15745550394058228\n",
      "The representation loss after processing this batch is:  0.002735558897256851\n",
      "\n",
      "The classification loss after processing this batch is:  0.09659399837255478\n",
      "The representation loss after processing this batch is:  0.0026634931564331055\n",
      "\n",
      "The classification loss after processing this batch is:  0.10299162566661835\n",
      "The representation loss after processing this batch is:  0.0026905611157417297\n",
      "\n",
      "The classification loss after processing this batch is:  0.16514310240745544\n",
      "The representation loss after processing this batch is:  0.002856932580471039\n",
      "\n",
      "The classification loss after processing this batch is:  0.23649349808692932\n",
      "The representation loss after processing this batch is:  0.0025794506072998047\n",
      "\n",
      "The classification loss after processing this batch is:  0.3193753659725189\n",
      "The representation loss after processing this batch is:  0.002314835786819458\n",
      "\n",
      "The classification loss after processing this batch is:  0.15395487844944\n",
      "The representation loss after processing this batch is:  0.002690289169549942\n",
      "\n",
      "The classification loss after processing this batch is:  0.07901910692453384\n",
      "The representation loss after processing this batch is:  0.0027057304978370667\n",
      "\n",
      "The classification loss after processing this batch is:  0.0976383313536644\n",
      "The representation loss after processing this batch is:  0.0026488006114959717\n",
      "\n",
      "The classification loss after processing this batch is:  0.18054494261741638\n",
      "The representation loss after processing this batch is:  0.0025026649236679077\n",
      "\n",
      "The classification loss after processing this batch is:  0.09580205380916595\n",
      "The representation loss after processing this batch is:  0.0027218908071517944\n",
      "\n",
      "The classification loss after processing this batch is:  0.11054589599370956\n",
      "The representation loss after processing this batch is:  0.002476431429386139\n",
      "\n",
      "The classification loss after processing this batch is:  0.11385371536016464\n",
      "The representation loss after processing this batch is:  0.0025058239698410034\n",
      "\n",
      "The classification loss after processing this batch is:  0.03244299069046974\n",
      "The representation loss after processing this batch is:  0.002747669816017151\n",
      "\n",
      "The classification loss after processing this batch is:  0.091156505048275\n",
      "The representation loss after processing this batch is:  0.0027546025812625885\n",
      "\n",
      "The classification loss after processing this batch is:  0.13569621741771698\n",
      "The representation loss after processing this batch is:  0.0027300454676151276\n",
      "\n",
      "The classification loss after processing this batch is:  0.17641253769397736\n",
      "The representation loss after processing this batch is:  0.0023285038769245148\n",
      "\n",
      "The classification loss after processing this batch is:  0.12398169934749603\n",
      "The representation loss after processing this batch is:  0.002500813454389572\n",
      "\n",
      "The classification loss after processing this batch is:  0.10064421594142914\n",
      "The representation loss after processing this batch is:  0.002635657787322998\n",
      "\n",
      "The classification loss after processing this batch is:  0.15437659621238708\n",
      "The representation loss after processing this batch is:  0.0028936639428138733\n",
      "\n",
      "The classification loss after processing this batch is:  0.08225078880786896\n",
      "The representation loss after processing this batch is:  0.002763189375400543\n",
      "\n",
      "The classification loss after processing this batch is:  0.10598649084568024\n",
      "The representation loss after processing this batch is:  0.0028320252895355225\n",
      "\n",
      "The classification loss after processing this batch is:  0.13283412158489227\n",
      "The representation loss after processing this batch is:  0.0027607977390289307\n",
      "\n",
      "The classification loss after processing this batch is:  0.13329647481441498\n",
      "The representation loss after processing this batch is:  0.002493046224117279\n",
      "\n",
      "The classification loss after processing this batch is:  0.143941268324852\n",
      "The representation loss after processing this batch is:  0.0024225041270256042\n",
      "\n",
      "The classification loss after processing this batch is:  0.23174266517162323\n",
      "The representation loss after processing this batch is:  0.0024037212133407593\n",
      "\n",
      "The classification loss after processing this batch is:  0.28119343519210815\n",
      "The representation loss after processing this batch is:  0.002497270703315735\n",
      "\n",
      "The classification loss after processing this batch is:  0.0769377276301384\n",
      "The representation loss after processing this batch is:  0.002350296825170517\n",
      "\n",
      "The classification loss after processing this batch is:  0.11504700034856796\n",
      "The representation loss after processing this batch is:  0.002764955163002014\n",
      "\n",
      "The classification loss after processing this batch is:  0.117521271109581\n",
      "The representation loss after processing this batch is:  0.0026913508772850037\n",
      "\n",
      "The classification loss after processing this batch is:  0.15348678827285767\n",
      "The representation loss after processing this batch is:  0.0024419687688350677\n",
      "\n",
      "The classification loss after processing this batch is:  0.22152017056941986\n",
      "The representation loss after processing this batch is:  0.002765066921710968\n",
      "\n",
      "The classification loss after processing this batch is:  0.19882401823997498\n",
      "The representation loss after processing this batch is:  0.0028527528047561646\n",
      "\n",
      "The classification loss after processing this batch is:  0.24521379172801971\n",
      "The representation loss after processing this batch is:  0.0030159950256347656\n",
      "\n",
      "The classification loss after processing this batch is:  0.11721602082252502\n",
      "The representation loss after processing this batch is:  0.002990543842315674\n",
      "\n",
      "The classification loss after processing this batch is:  0.1624939739704132\n",
      "The representation loss after processing this batch is:  0.0027289986610412598\n",
      "\n",
      "The classification loss after processing this batch is:  0.15681788325309753\n",
      "The representation loss after processing this batch is:  0.0031985044479370117\n",
      "\n",
      "The classification loss after processing this batch is:  0.0726720467209816\n",
      "The representation loss after processing this batch is:  0.0025973618030548096\n",
      "\n",
      "The classification loss after processing this batch is:  0.21630945801734924\n",
      "The representation loss after processing this batch is:  0.0027013011276721954\n",
      "\n",
      "The classification loss after processing this batch is:  0.11914075165987015\n",
      "The representation loss after processing this batch is:  0.0024204105138778687\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.054620131850242615\n",
      "The representation loss after processing this batch is:  0.002423606812953949\n",
      "\n",
      "The classification loss after processing this batch is:  0.09817290306091309\n",
      "The representation loss after processing this batch is:  0.0023324787616729736\n",
      "\n",
      "The classification loss after processing this batch is:  0.12090830504894257\n",
      "The representation loss after processing this batch is:  0.0028421208262443542\n",
      "\n",
      "The classification loss after processing this batch is:  0.1517450511455536\n",
      "The representation loss after processing this batch is:  0.002336248755455017\n",
      "\n",
      "The classification loss after processing this batch is:  0.09202774614095688\n",
      "The representation loss after processing this batch is:  0.002465255558490753\n",
      "\n",
      "The classification loss after processing this batch is:  0.09333683550357819\n",
      "The representation loss after processing this batch is:  0.0023622438311576843\n",
      "\n",
      "The classification loss after processing this batch is:  0.04869145527482033\n",
      "The representation loss after processing this batch is:  0.002427849918603897\n",
      "\n",
      "The classification loss after processing this batch is:  0.1322525292634964\n",
      "The representation loss after processing this batch is:  0.0021534934639930725\n",
      "\n",
      "The classification loss after processing this batch is:  0.10293344408273697\n",
      "The representation loss after processing this batch is:  0.0022806189954280853\n",
      "\n",
      "The classification loss after processing this batch is:  0.4299914538860321\n",
      "The representation loss after processing this batch is:  0.002617552876472473\n",
      "\n",
      "The classification loss after processing this batch is:  0.11355405300855637\n",
      "The representation loss after processing this batch is:  0.002651110291481018\n",
      "\n",
      "The classification loss after processing this batch is:  0.19495122134685516\n",
      "The representation loss after processing this batch is:  0.002296280115842819\n",
      "\n",
      "The classification loss after processing this batch is:  0.23963648080825806\n",
      "The representation loss after processing this batch is:  0.0026232153177261353\n",
      "\n",
      "The classification loss after processing this batch is:  0.09540227055549622\n",
      "The representation loss after processing this batch is:  0.0022730082273483276\n",
      "\n",
      "The classification loss after processing this batch is:  0.24856530129909515\n",
      "The representation loss after processing this batch is:  0.002752535045146942\n",
      "\n",
      "The classification loss after processing this batch is:  0.12817327678203583\n",
      "The representation loss after processing this batch is:  0.0027094371616840363\n",
      "\n",
      "The classification loss after processing this batch is:  0.23950979113578796\n",
      "The representation loss after processing this batch is:  0.002253372222185135\n",
      "\n",
      "The classification loss after processing this batch is:  0.06053376570343971\n",
      "The representation loss after processing this batch is:  0.002244219183921814\n",
      "\n",
      "The classification loss after processing this batch is:  0.10839040577411652\n",
      "The representation loss after processing this batch is:  0.0026433542370796204\n",
      "\n",
      "The classification loss after processing this batch is:  0.03917914628982544\n",
      "The representation loss after processing this batch is:  0.0026687979698181152\n",
      "\n",
      "The classification loss after processing this batch is:  0.03921222686767578\n",
      "The representation loss after processing this batch is:  0.0025597810745239258\n",
      "\n",
      "The classification loss after processing this batch is:  0.07182616740465164\n",
      "The representation loss after processing this batch is:  0.002414405345916748\n",
      "\n",
      "The classification loss after processing this batch is:  0.06589311361312866\n",
      "The representation loss after processing this batch is:  0.0023947209119796753\n",
      "\n",
      "The classification loss after processing this batch is:  0.14764656126499176\n",
      "The representation loss after processing this batch is:  0.0026431232690811157\n",
      "\n",
      "The classification loss after processing this batch is:  0.09405695647001266\n",
      "The representation loss after processing this batch is:  0.002923034131526947\n",
      "\n",
      "The classification loss after processing this batch is:  0.07823613286018372\n",
      "The representation loss after processing this batch is:  0.002421252429485321\n",
      "\n",
      "The classification loss after processing this batch is:  0.14757795631885529\n",
      "The representation loss after processing this batch is:  0.002208877354860306\n",
      "\n",
      "The classification loss after processing this batch is:  0.08433330059051514\n",
      "The representation loss after processing this batch is:  0.0027544721961021423\n",
      "\n",
      "The classification loss after processing this batch is:  0.10986197739839554\n",
      "The representation loss after processing this batch is:  0.0026105307042598724\n",
      "\n",
      "The classification loss after processing this batch is:  0.1285630315542221\n",
      "The representation loss after processing this batch is:  0.002601899206638336\n",
      "\n",
      "The classification loss after processing this batch is:  0.18011239171028137\n",
      "The representation loss after processing this batch is:  0.0026557818055152893\n",
      "\n",
      "The classification loss after processing this batch is:  0.10904047638177872\n",
      "The representation loss after processing this batch is:  0.002369854599237442\n",
      "\n",
      "The classification loss after processing this batch is:  0.08614761382341385\n",
      "The representation loss after processing this batch is:  0.0023609958589076996\n",
      "\n",
      "The classification loss after processing this batch is:  0.19803157448768616\n",
      "The representation loss after processing this batch is:  0.0026604607701301575\n",
      "\n",
      "The classification loss after processing this batch is:  0.1613437682390213\n",
      "The representation loss after processing this batch is:  0.0024373680353164673\n",
      "\n",
      "The classification loss after processing this batch is:  0.14917440712451935\n",
      "The representation loss after processing this batch is:  0.0024373605847358704\n",
      "\n",
      "The classification loss after processing this batch is:  0.057392895221710205\n",
      "The representation loss after processing this batch is:  0.002452261745929718\n",
      "\n",
      "The classification loss after processing this batch is:  0.13671420514583588\n",
      "The representation loss after processing this batch is:  0.002860419452190399\n",
      "\n",
      "The classification loss after processing this batch is:  0.1418498009443283\n",
      "The representation loss after processing this batch is:  0.0027078278362751007\n",
      "\n",
      "The classification loss after processing this batch is:  0.12237154692411423\n",
      "The representation loss after processing this batch is:  0.0027983561158180237\n",
      "\n",
      "The classification loss after processing this batch is:  0.11250109225511551\n",
      "The representation loss after processing this batch is:  0.0032698772847652435\n",
      "\n",
      "The classification loss after processing this batch is:  0.08802906423807144\n",
      "The representation loss after processing this batch is:  0.003075152635574341\n",
      "\n",
      "The classification loss after processing this batch is:  0.1478528082370758\n",
      "The representation loss after processing this batch is:  0.0027996227145195007\n",
      "\n",
      "The classification loss after processing this batch is:  0.19181004166603088\n",
      "The representation loss after processing this batch is:  0.002680126577615738\n",
      "\n",
      "The classification loss after processing this batch is:  0.12271323800086975\n",
      "The representation loss after processing this batch is:  0.003305085003376007\n",
      "\n",
      "The classification loss after processing this batch is:  0.11882766336202621\n",
      "The representation loss after processing this batch is:  0.0027067624032497406\n",
      "\n",
      "The classification loss after processing this batch is:  0.04696724936366081\n",
      "The representation loss after processing this batch is:  0.002209864556789398\n",
      "\n",
      "The classification loss after processing this batch is:  0.20136982202529907\n",
      "The representation loss after processing this batch is:  0.0023361332714557648\n",
      "\n",
      "The classification loss after processing this batch is:  0.07780607044696808\n",
      "The representation loss after processing this batch is:  0.0024336054921150208\n",
      "\n",
      "The classification loss after processing this batch is:  0.10698344558477402\n",
      "The representation loss after processing this batch is:  0.002629600465297699\n",
      "\n",
      "The classification loss after processing this batch is:  0.10747361183166504\n",
      "The representation loss after processing this batch is:  0.002842910587787628\n",
      "\n",
      "The classification loss after processing this batch is:  0.09436305612325668\n",
      "The representation loss after processing this batch is:  0.0024799033999443054\n",
      "\n",
      "The classification loss after processing this batch is:  0.10029479116201401\n",
      "The representation loss after processing this batch is:  0.002677015960216522\n",
      "\n",
      "The classification loss after processing this batch is:  0.1459270417690277\n",
      "The representation loss after processing this batch is:  0.0030973851680755615\n",
      "\n",
      "The classification loss after processing this batch is:  0.13582322001457214\n",
      "The representation loss after processing this batch is:  0.0030265003442764282\n",
      "\n",
      "The classification loss after processing this batch is:  0.12892088294029236\n",
      "The representation loss after processing this batch is:  0.002456486225128174\n",
      "\n",
      "The classification loss after processing this batch is:  0.14765475690364838\n",
      "The representation loss after processing this batch is:  0.0030556507408618927\n",
      "\n",
      "The classification loss after processing this batch is:  0.07589288055896759\n",
      "The representation loss after processing this batch is:  0.0023780539631843567\n",
      "\n",
      "The classification loss after processing this batch is:  0.08756255358457565\n",
      "The representation loss after processing this batch is:  0.002476431429386139\n",
      "\n",
      "The classification loss after processing this batch is:  0.07320306450128555\n",
      "The representation loss after processing this batch is:  0.002926260232925415\n",
      "\n",
      "The classification loss after processing this batch is:  0.09844135493040085\n",
      "The representation loss after processing this batch is:  0.0025483816862106323\n",
      "\n",
      "The classification loss after processing this batch is:  0.0566897951066494\n",
      "The representation loss after processing this batch is:  0.002496827393770218\n",
      "\n",
      "The classification loss after processing this batch is:  0.058172304183244705\n",
      "The representation loss after processing this batch is:  0.002302415668964386\n",
      "\n",
      "The classification loss after processing this batch is:  0.06593465805053711\n",
      "The representation loss after processing this batch is:  0.0027442872524261475\n",
      "\n",
      "The classification loss after processing this batch is:  0.05943064019083977\n",
      "The representation loss after processing this batch is:  0.0027007609605789185\n",
      "\n",
      "The classification loss after processing this batch is:  0.14207588136196136\n",
      "The representation loss after processing this batch is:  0.0025069862604141235\n",
      "\n",
      "The classification loss after processing this batch is:  0.09073654562234879\n",
      "The representation loss after processing this batch is:  0.002192191779613495\n",
      "\n",
      "The classification loss after processing this batch is:  0.12169727683067322\n",
      "The representation loss after processing this batch is:  0.0025568902492523193\n",
      "\n",
      "The classification loss after processing this batch is:  0.06346169114112854\n",
      "The representation loss after processing this batch is:  0.0027928799390792847\n",
      "\n",
      "The classification loss after processing this batch is:  0.1688118875026703\n",
      "The representation loss after processing this batch is:  0.0024537742137908936\n",
      "\n",
      "The classification loss after processing this batch is:  0.14478416740894318\n",
      "The representation loss after processing this batch is:  0.002499021589756012\n",
      "\n",
      "The classification loss after processing this batch is:  0.12222933769226074\n",
      "The representation loss after processing this batch is:  0.0025067776441574097\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.0988859087228775\n",
      "The representation loss after processing this batch is:  0.0026052817702293396\n",
      "\n",
      "The classification loss after processing this batch is:  0.12249650806188583\n",
      "The representation loss after processing this batch is:  0.002827361226081848\n",
      "\n",
      "The classification loss after processing this batch is:  0.0610235370695591\n",
      "The representation loss after processing this batch is:  0.0025087296962738037\n",
      "\n",
      "The classification loss after processing this batch is:  0.060418713837862015\n",
      "The representation loss after processing this batch is:  0.002551831305027008\n",
      "\n",
      "The classification loss after processing this batch is:  0.07284913212060928\n",
      "The representation loss after processing this batch is:  0.0024091005325317383\n",
      "\n",
      "The classification loss after processing this batch is:  0.16177740693092346\n",
      "The representation loss after processing this batch is:  0.002594500780105591\n",
      "\n",
      "The classification loss after processing this batch is:  0.13707396388053894\n",
      "The representation loss after processing this batch is:  0.0023976191878318787\n",
      "\n",
      "The classification loss after processing this batch is:  0.12255174666643143\n",
      "The representation loss after processing this batch is:  0.002991802990436554\n",
      "\n",
      "The classification loss after processing this batch is:  0.1654769331216812\n",
      "The representation loss after processing this batch is:  0.002584952861070633\n",
      "\n",
      "The classification loss after processing this batch is:  0.13070882856845856\n",
      "The representation loss after processing this batch is:  0.002703748643398285\n",
      "\n",
      "The classification loss after processing this batch is:  0.14702050387859344\n",
      "The representation loss after processing this batch is:  0.002449914813041687\n",
      "\n",
      "The classification loss after processing this batch is:  0.26479339599609375\n",
      "The representation loss after processing this batch is:  0.0024033263325691223\n",
      "\n",
      "The classification loss after processing this batch is:  0.17872123420238495\n",
      "The representation loss after processing this batch is:  0.002399180084466934\n",
      "\n",
      "The classification loss after processing this batch is:  0.10415229201316833\n",
      "The representation loss after processing this batch is:  0.002257823944091797\n",
      "\n",
      "The classification loss after processing this batch is:  0.0666041448712349\n",
      "The representation loss after processing this batch is:  0.0025138892233371735\n",
      "\n",
      "The classification loss after processing this batch is:  0.062385257333517075\n",
      "The representation loss after processing this batch is:  0.002302885055541992\n",
      "\n",
      "The classification loss after processing this batch is:  0.06125509366393089\n",
      "The representation loss after processing this batch is:  0.002521604299545288\n",
      "\n",
      "The classification loss after processing this batch is:  0.06788068264722824\n",
      "The representation loss after processing this batch is:  0.002909615635871887\n",
      "\n",
      "The classification loss after processing this batch is:  0.12837016582489014\n",
      "The representation loss after processing this batch is:  0.002453908324241638\n",
      "\n",
      "The classification loss after processing this batch is:  0.08661200106143951\n",
      "The representation loss after processing this batch is:  0.0026714354753494263\n",
      "\n",
      "The classification loss after processing this batch is:  0.18000581860542297\n",
      "The representation loss after processing this batch is:  0.0025730207562446594\n",
      "\n",
      "The classification loss after processing this batch is:  0.13883934915065765\n",
      "The representation loss after processing this batch is:  0.0025885477662086487\n",
      "\n",
      "The classification loss after processing this batch is:  0.17510715126991272\n",
      "The representation loss after processing this batch is:  0.0021782852709293365\n",
      "\n",
      "The classification loss after processing this batch is:  0.11613962054252625\n",
      "The representation loss after processing this batch is:  0.00234922394156456\n",
      "\n",
      "The classification loss after processing this batch is:  0.18535616993904114\n",
      "The representation loss after processing this batch is:  0.002345077693462372\n",
      "\n",
      "The classification loss after processing this batch is:  0.11841903626918793\n",
      "The representation loss after processing this batch is:  0.0022794120013713837\n",
      "\n",
      "The classification loss after processing this batch is:  0.09613839536905289\n",
      "The representation loss after processing this batch is:  0.0024533942341804504\n",
      "\n",
      "The classification loss after processing this batch is:  0.14068740606307983\n",
      "The representation loss after processing this batch is:  0.002302825450897217\n",
      "\n",
      "The classification loss after processing this batch is:  0.060452885925769806\n",
      "The representation loss after processing this batch is:  0.0023567862808704376\n",
      "\n",
      "The classification loss after processing this batch is:  0.05232004076242447\n",
      "The representation loss after processing this batch is:  0.00238887220621109\n",
      "\n",
      "The classification loss after processing this batch is:  0.1410367339849472\n",
      "The representation loss after processing this batch is:  0.0026614144444465637\n",
      "\n",
      "The classification loss after processing this batch is:  0.17364777624607086\n",
      "The representation loss after processing this batch is:  0.0024458542466163635\n",
      "\n",
      "The classification loss after processing this batch is:  0.1296236515045166\n",
      "The representation loss after processing this batch is:  0.0026545003056526184\n",
      "\n",
      "The classification loss after processing this batch is:  0.07083969563245773\n",
      "The representation loss after processing this batch is:  0.0026616379618644714\n",
      "\n",
      "The classification loss after processing this batch is:  0.10687322169542313\n",
      "The representation loss after processing this batch is:  0.002772323787212372\n",
      "\n",
      "The classification loss after processing this batch is:  0.08254115283489227\n",
      "The representation loss after processing this batch is:  0.0025841891765594482\n",
      "\n",
      "The classification loss after processing this batch is:  0.2507205605506897\n",
      "The representation loss after processing this batch is:  0.002497375011444092\n",
      "\n",
      "The classification loss after processing this batch is:  0.06928889453411102\n",
      "The representation loss after processing this batch is:  0.0024154186248779297\n",
      "\n",
      "The classification loss after processing this batch is:  0.048737410455942154\n",
      "The representation loss after processing this batch is:  0.0025353655219078064\n",
      "\n",
      "The classification loss after processing this batch is:  0.14117662608623505\n",
      "The representation loss after processing this batch is:  0.00290767103433609\n",
      "\n",
      "The classification loss after processing this batch is:  0.1087801456451416\n",
      "The representation loss after processing this batch is:  0.00275488942861557\n",
      "\n",
      "The classification loss after processing this batch is:  0.07697800546884537\n",
      "The representation loss after processing this batch is:  0.002683505415916443\n",
      "\n",
      "The classification loss after processing this batch is:  0.05885109677910805\n",
      "The representation loss after processing this batch is:  0.0023047029972076416\n",
      "\n",
      "The classification loss after processing this batch is:  0.10964014381170273\n",
      "The representation loss after processing this batch is:  0.003119252622127533\n",
      "\n",
      "The classification loss after processing this batch is:  0.16072294116020203\n",
      "The representation loss after processing this batch is:  0.0029086917638778687\n",
      "\n",
      "The classification loss after processing this batch is:  0.21098223328590393\n",
      "The representation loss after processing this batch is:  0.0023820847272872925\n",
      "\n",
      "The classification loss after processing this batch is:  0.1688990443944931\n",
      "The representation loss after processing this batch is:  0.002767018973827362\n",
      "\n",
      "The classification loss after processing this batch is:  0.0636497288942337\n",
      "The representation loss after processing this batch is:  0.0026718825101852417\n",
      "\n",
      "The classification loss after processing this batch is:  0.07115577161312103\n",
      "The representation loss after processing this batch is:  0.0022074654698371887\n",
      "\n",
      "The classification loss after processing this batch is:  0.1535770148038864\n",
      "The representation loss after processing this batch is:  0.0027354806661605835\n",
      "\n",
      "The classification loss after processing this batch is:  0.1942613571882248\n",
      "The representation loss after processing this batch is:  0.0026622265577316284\n",
      "\n",
      "The classification loss after processing this batch is:  0.1842508763074875\n",
      "The representation loss after processing this batch is:  0.0026839599013328552\n",
      "\n",
      "The classification loss after processing this batch is:  0.22858208417892456\n",
      "The representation loss after processing this batch is:  0.002306535840034485\n",
      "\n",
      "The classification loss after processing this batch is:  0.11050304770469666\n",
      "The representation loss after processing this batch is:  0.002294085919857025\n",
      "\n",
      "The classification loss after processing this batch is:  0.18253912031650543\n",
      "The representation loss after processing this batch is:  0.002291221171617508\n",
      "\n",
      "The classification loss after processing this batch is:  0.0958787351846695\n",
      "The representation loss after processing this batch is:  0.002162747085094452\n",
      "\n",
      "The classification loss after processing this batch is:  0.09449359774589539\n",
      "The representation loss after processing this batch is:  0.0025781244039535522\n",
      "\n",
      "The classification loss after processing this batch is:  0.05867082253098488\n",
      "The representation loss after processing this batch is:  0.0025192275643348694\n",
      "\n",
      "The classification loss after processing this batch is:  0.11749593168497086\n",
      "The representation loss after processing this batch is:  0.002544872462749481\n",
      "\n",
      "The classification loss after processing this batch is:  0.1409769356250763\n",
      "The representation loss after processing this batch is:  0.002332843840122223\n",
      "\n",
      "The classification loss after processing this batch is:  0.09291616827249527\n",
      "The representation loss after processing this batch is:  0.0024737119674682617\n",
      "\n",
      "The classification loss after processing this batch is:  0.15592294931411743\n",
      "The representation loss after processing this batch is:  0.0027943551540374756\n",
      "\n",
      "The classification loss after processing this batch is:  0.0499759279191494\n",
      "The representation loss after processing this batch is:  0.0028564482927322388\n",
      "\n",
      "The classification loss after processing this batch is:  0.0973520502448082\n",
      "The representation loss after processing this batch is:  0.0027788355946540833\n",
      "\n",
      "The classification loss after processing this batch is:  0.09893288463354111\n",
      "The representation loss after processing this batch is:  0.0024262666702270508\n",
      "\n",
      "The classification loss after processing this batch is:  0.1882140189409256\n",
      "The representation loss after processing this batch is:  0.0026747584342956543\n",
      "\n",
      "The classification loss after processing this batch is:  0.05429600551724434\n",
      "The representation loss after processing this batch is:  0.003190755844116211\n",
      "\n",
      "The classification loss after processing this batch is:  0.08324162662029266\n",
      "The representation loss after processing this batch is:  0.0024338029325008392\n",
      "\n",
      "The classification loss after processing this batch is:  0.16492795944213867\n",
      "The representation loss after processing this batch is:  0.002683967351913452\n",
      "\n",
      "The classification loss after processing this batch is:  0.11681929975748062\n",
      "The representation loss after processing this batch is:  0.0025720298290252686\n",
      "\n",
      "The classification loss after processing this batch is:  0.15422552824020386\n",
      "The representation loss after processing this batch is:  0.002347618341445923\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10272030532360077\n",
      "The representation loss after processing this batch is:  0.002333570271730423\n",
      "\n",
      "The classification loss after processing this batch is:  0.06593824923038483\n",
      "The representation loss after processing this batch is:  0.002598445862531662\n",
      "\n",
      "The classification loss after processing this batch is:  0.11891207844018936\n",
      "The representation loss after processing this batch is:  0.002201620489358902\n",
      "\n",
      "The classification loss after processing this batch is:  0.09770932793617249\n",
      "The representation loss after processing this batch is:  0.002657003700733185\n",
      "\n",
      "The classification loss after processing this batch is:  0.1250290423631668\n",
      "The representation loss after processing this batch is:  0.0025931671261787415\n",
      "\n",
      "The classification loss after processing this batch is:  0.12287867069244385\n",
      "The representation loss after processing this batch is:  0.0031226500868797302\n",
      "\n",
      "The classification loss after processing this batch is:  0.06437700241804123\n",
      "The representation loss after processing this batch is:  0.0024763718247413635\n",
      "\n",
      "The classification loss after processing this batch is:  0.14192481338977814\n",
      "The representation loss after processing this batch is:  0.002407848834991455\n",
      "\n",
      "The classification loss after processing this batch is:  0.17328877747058868\n",
      "The representation loss after processing this batch is:  0.0027787014842033386\n",
      "\n",
      "The classification loss after processing this batch is:  0.04148607328534126\n",
      "The representation loss after processing this batch is:  0.002671182155609131\n",
      "\n",
      "The classification loss after processing this batch is:  0.10021664947271347\n",
      "The representation loss after processing this batch is:  0.002247769385576248\n",
      "\n",
      "The classification loss after processing this batch is:  0.16775424778461456\n",
      "The representation loss after processing this batch is:  0.0023397281765937805\n",
      "\n",
      "The classification loss after processing this batch is:  0.168277308344841\n",
      "The representation loss after processing this batch is:  0.002563081681728363\n",
      "\n",
      "The classification loss after processing this batch is:  0.11887092888355255\n",
      "The representation loss after processing this batch is:  0.0023754313588142395\n",
      "\n",
      "The classification loss after processing this batch is:  0.18946942687034607\n",
      "The representation loss after processing this batch is:  0.0024260953068733215\n",
      "\n",
      "The classification loss after processing this batch is:  0.14058177173137665\n",
      "The representation loss after processing this batch is:  0.0024661198258399963\n",
      "\n",
      "The classification loss after processing this batch is:  0.18405860662460327\n",
      "The representation loss after processing this batch is:  0.0027620047330856323\n",
      "\n",
      "The classification loss after processing this batch is:  0.10182612389326096\n",
      "The representation loss after processing this batch is:  0.0028514564037323\n",
      "\n",
      "The classification loss after processing this batch is:  0.17826180160045624\n",
      "The representation loss after processing this batch is:  0.0024961084127426147\n",
      "\n",
      "The classification loss after processing this batch is:  0.10920142382383347\n",
      "The representation loss after processing this batch is:  0.0036669746041297913\n",
      "\n",
      "The classification loss after processing this batch is:  0.07619103789329529\n",
      "The representation loss after processing this batch is:  0.0025210678577423096\n",
      "\n",
      "The classification loss after processing this batch is:  0.0944153368473053\n",
      "The representation loss after processing this batch is:  0.0024812743067741394\n",
      "\n",
      "The classification loss after processing this batch is:  0.08898373693227768\n",
      "The representation loss after processing this batch is:  0.0023160576820373535\n",
      "\n",
      "The classification loss after processing this batch is:  0.12485574185848236\n",
      "The representation loss after processing this batch is:  0.002618148922920227\n",
      "\n",
      "The classification loss after processing this batch is:  0.10733612626791\n",
      "The representation loss after processing this batch is:  0.0024340301752090454\n",
      "\n",
      "The classification loss after processing this batch is:  0.1678764522075653\n",
      "The representation loss after processing this batch is:  0.00263933464884758\n",
      "\n",
      "The classification loss after processing this batch is:  0.0444633774459362\n",
      "The representation loss after processing this batch is:  0.002598583698272705\n",
      "\n",
      "The classification loss after processing this batch is:  0.06593063473701477\n",
      "The representation loss after processing this batch is:  0.002840794622898102\n",
      "\n",
      "The classification loss after processing this batch is:  0.16113261878490448\n",
      "The representation loss after processing this batch is:  0.0027337148785591125\n",
      "\n",
      "The classification loss after processing this batch is:  0.036656346172094345\n",
      "The representation loss after processing this batch is:  0.0025123730301856995\n",
      "\n",
      "The classification loss after processing this batch is:  0.08247285336256027\n",
      "The representation loss after processing this batch is:  0.0024479255080223083\n",
      "\n",
      "The classification loss after processing this batch is:  0.04867090284824371\n",
      "The representation loss after processing this batch is:  0.0026051700115203857\n",
      "\n",
      "The classification loss after processing this batch is:  0.08798808604478836\n",
      "The representation loss after processing this batch is:  0.0023389533162117004\n",
      "\n",
      "The classification loss after processing this batch is:  0.1498020738363266\n",
      "The representation loss after processing this batch is:  0.0028367266058921814\n",
      "\n",
      "The classification loss after processing this batch is:  0.15794801712036133\n",
      "The representation loss after processing this batch is:  0.003620833158493042\n",
      "\n",
      "The classification loss after processing this batch is:  0.15553945302963257\n",
      "The representation loss after processing this batch is:  0.0031602904200553894\n",
      "\n",
      "The classification loss after processing this batch is:  0.07889590412378311\n",
      "The representation loss after processing this batch is:  0.0026899464428424835\n",
      "\n",
      "The classification loss after processing this batch is:  0.12428166717290878\n",
      "The representation loss after processing this batch is:  0.002355523407459259\n",
      "\n",
      "The classification loss after processing this batch is:  0.11697201430797577\n",
      "The representation loss after processing this batch is:  0.002657659351825714\n",
      "\n",
      "The classification loss after processing this batch is:  0.05772202089428902\n",
      "The representation loss after processing this batch is:  0.0027856044471263885\n",
      "\n",
      "The classification loss after processing this batch is:  0.06140066310763359\n",
      "The representation loss after processing this batch is:  0.0024800747632980347\n",
      "\n",
      "The classification loss after processing this batch is:  0.046037428081035614\n",
      "The representation loss after processing this batch is:  0.002885669469833374\n",
      "\n",
      "The classification loss after processing this batch is:  0.09027938544750214\n",
      "The representation loss after processing this batch is:  0.002851482480764389\n",
      "\n",
      "The classification loss after processing this batch is:  0.18424561619758606\n",
      "The representation loss after processing this batch is:  0.0026372261345386505\n",
      "\n",
      "The classification loss after processing this batch is:  0.14830341935157776\n",
      "The representation loss after processing this batch is:  0.002362780272960663\n",
      "\n",
      "The classification loss after processing this batch is:  0.12375481426715851\n",
      "The representation loss after processing this batch is:  0.003296278417110443\n",
      "\n",
      "The classification loss after processing this batch is:  0.09705674648284912\n",
      "The representation loss after processing this batch is:  0.0028458908200263977\n",
      "\n",
      "The classification loss after processing this batch is:  0.12002570182085037\n",
      "The representation loss after processing this batch is:  0.0025830119848251343\n",
      "\n",
      "The classification loss after processing this batch is:  0.09491821378469467\n",
      "The representation loss after processing this batch is:  0.0024512112140655518\n",
      "\n",
      "The classification loss after processing this batch is:  0.3640652894973755\n",
      "The representation loss after processing this batch is:  0.002684295177459717\n",
      "\n",
      "The classification loss after processing this batch is:  0.09458969533443451\n",
      "The representation loss after processing this batch is:  0.002761371433734894\n",
      "\n",
      "The classification loss after processing this batch is:  0.23632913827896118\n",
      "The representation loss after processing this batch is:  0.0032869428396224976\n",
      "\n",
      "The classification loss after processing this batch is:  0.10430579632520676\n",
      "The representation loss after processing this batch is:  0.0023904144763946533\n",
      "\n",
      "The classification loss after processing this batch is:  0.10579988360404968\n",
      "The representation loss after processing this batch is:  0.0024633407592773438\n",
      "\n",
      "The classification loss after processing this batch is:  0.16028989851474762\n",
      "The representation loss after processing this batch is:  0.0023090392351150513\n",
      "\n",
      "The classification loss after processing this batch is:  0.11291330307722092\n",
      "The representation loss after processing this batch is:  0.0026211850345134735\n",
      "\n",
      "The classification loss after processing this batch is:  0.19550912082195282\n",
      "The representation loss after processing this batch is:  0.002601243555545807\n",
      "\n",
      "The classification loss after processing this batch is:  0.13595587015151978\n",
      "The representation loss after processing this batch is:  0.0029430091381073\n",
      "\n",
      "The classification loss after processing this batch is:  0.14902187883853912\n",
      "The representation loss after processing this batch is:  0.0031240805983543396\n",
      "\n",
      "The classification loss after processing this batch is:  0.14911018311977386\n",
      "The representation loss after processing this batch is:  0.002864249050617218\n",
      "\n",
      "The classification loss after processing this batch is:  0.04143674671649933\n",
      "The representation loss after processing this batch is:  0.0026276186108589172\n",
      "\n",
      "The classification loss after processing this batch is:  0.13648512959480286\n",
      "The representation loss after processing this batch is:  0.0023962557315826416\n",
      "\n",
      "The classification loss after processing this batch is:  0.12383740395307541\n",
      "The representation loss after processing this batch is:  0.002425946295261383\n",
      "\n",
      "The classification loss after processing this batch is:  0.05730636045336723\n",
      "The representation loss after processing this batch is:  0.002689145505428314\n",
      "\n",
      "The classification loss after processing this batch is:  0.14137855172157288\n",
      "The representation loss after processing this batch is:  0.0024214982986450195\n",
      "\n",
      "The classification loss after processing this batch is:  0.2201531082391739\n",
      "The representation loss after processing this batch is:  0.002644747495651245\n",
      "\n",
      "The classification loss after processing this batch is:  0.10424923151731491\n",
      "The representation loss after processing this batch is:  0.0021765977144241333\n",
      "\n",
      "The classification loss after processing this batch is:  0.0913945659995079\n",
      "The representation loss after processing this batch is:  0.0027109533548355103\n",
      "\n",
      "The classification loss after processing this batch is:  0.0970861092209816\n",
      "The representation loss after processing this batch is:  0.00240248441696167\n",
      "\n",
      "The classification loss after processing this batch is:  0.08559250086545944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.0025750398635864258\n",
      "\n",
      "The classification loss after processing this batch is:  0.1052081435918808\n",
      "The representation loss after processing this batch is:  0.002782389521598816\n",
      "\n",
      "The classification loss after processing this batch is:  0.05184514448046684\n",
      "The representation loss after processing this batch is:  0.0027601048350334167\n",
      "\n",
      "The classification loss after processing this batch is:  0.12888029217720032\n",
      "The representation loss after processing this batch is:  0.002345442771911621\n",
      "\n",
      "The classification loss after processing this batch is:  0.14396348595619202\n",
      "The representation loss after processing this batch is:  0.0022227726876735687\n",
      "\n",
      "The classification loss after processing this batch is:  0.07706915587186813\n",
      "The representation loss after processing this batch is:  0.0027123093605041504\n",
      "\n",
      "The classification loss after processing this batch is:  0.15017063915729523\n",
      "The representation loss after processing this batch is:  0.0023007094860076904\n",
      "\n",
      "The classification loss after processing this batch is:  0.11953258514404297\n",
      "The representation loss after processing this batch is:  0.0022560060024261475\n",
      "\n",
      "The classification loss after processing this batch is:  0.0629226416349411\n",
      "The representation loss after processing this batch is:  0.0024943947792053223\n",
      "\n",
      "The classification loss after processing this batch is:  0.07676634937524796\n",
      "The representation loss after processing this batch is:  0.0025790855288505554\n",
      "\n",
      "The classification loss after processing this batch is:  0.1353282332420349\n",
      "The representation loss after processing this batch is:  0.002518266439437866\n",
      "\n",
      "The classification loss after processing this batch is:  0.061508871614933014\n",
      "The representation loss after processing this batch is:  0.0025999844074249268\n",
      "\n",
      "The classification loss after processing this batch is:  0.33517295122146606\n",
      "The representation loss after processing this batch is:  0.0023173317313194275\n",
      "\n",
      "The classification loss after processing this batch is:  0.11782887578010559\n",
      "The representation loss after processing this batch is:  0.002702951431274414\n",
      "\n",
      "The classification loss after processing this batch is:  0.18699003756046295\n",
      "The representation loss after processing this batch is:  0.0023128241300582886\n",
      "\n",
      "The classification loss after processing this batch is:  0.0823391005396843\n",
      "The representation loss after processing this batch is:  0.0021523423492908478\n",
      "\n",
      "The classification loss after processing this batch is:  0.12698039412498474\n",
      "The representation loss after processing this batch is:  0.002513878047466278\n",
      "\n",
      "The classification loss after processing this batch is:  0.07831626385450363\n",
      "The representation loss after processing this batch is:  0.0022390931844711304\n",
      "\n",
      "The classification loss after processing this batch is:  0.09602584689855576\n",
      "The representation loss after processing this batch is:  0.00234324112534523\n",
      "\n",
      "The classification loss after processing this batch is:  0.18557356297969818\n",
      "The representation loss after processing this batch is:  0.0025919564068317413\n",
      "\n",
      "The classification loss after processing this batch is:  0.11499226093292236\n",
      "The representation loss after processing this batch is:  0.0030952244997024536\n",
      "\n",
      "The classification loss after processing this batch is:  0.15787382423877716\n",
      "The representation loss after processing this batch is:  0.0024624839425086975\n",
      "\n",
      "The classification loss after processing this batch is:  0.11456427723169327\n",
      "The representation loss after processing this batch is:  0.0025654137134552\n",
      "\n",
      "The classification loss after processing this batch is:  0.1764327734708786\n",
      "The representation loss after processing this batch is:  0.002762429416179657\n",
      "\n",
      "The classification loss after processing this batch is:  0.1489529013633728\n",
      "The representation loss after processing this batch is:  0.0026344656944274902\n",
      "\n",
      "The classification loss after processing this batch is:  0.17787297070026398\n",
      "The representation loss after processing this batch is:  0.0025305896997451782\n",
      "\n",
      "The classification loss after processing this batch is:  0.0873766839504242\n",
      "The representation loss after processing this batch is:  0.0025685206055641174\n",
      "\n",
      "The classification loss after processing this batch is:  0.10672826319932938\n",
      "The representation loss after processing this batch is:  0.003057345747947693\n",
      "\n",
      "The classification loss after processing this batch is:  0.05914884805679321\n",
      "The representation loss after processing this batch is:  0.0025401972234249115\n",
      "\n",
      "The classification loss after processing this batch is:  0.17103828489780426\n",
      "The representation loss after processing this batch is:  0.0023003146052360535\n",
      "\n",
      "The classification loss after processing this batch is:  0.20835348963737488\n",
      "The representation loss after processing this batch is:  0.0025207512080669403\n",
      "\n",
      "The classification loss after processing this batch is:  0.08490829169750214\n",
      "The representation loss after processing this batch is:  0.002930574119091034\n",
      "\n",
      "The classification loss after processing this batch is:  0.16024862229824066\n",
      "The representation loss after processing this batch is:  0.0027841851115226746\n",
      "\n",
      "The classification loss after processing this batch is:  0.16311584413051605\n",
      "The representation loss after processing this batch is:  0.002458028495311737\n",
      "\n",
      "The classification loss after processing this batch is:  0.17828276753425598\n",
      "The representation loss after processing this batch is:  0.002736620604991913\n",
      "\n",
      "The classification loss after processing this batch is:  0.0610201358795166\n",
      "The representation loss after processing this batch is:  0.0023643039166927338\n",
      "\n",
      "The classification loss after processing this batch is:  0.14776067435741425\n",
      "The representation loss after processing this batch is:  0.0025963857769966125\n",
      "\n",
      "The classification loss after processing this batch is:  0.16287875175476074\n",
      "The representation loss after processing this batch is:  0.0025690048933029175\n",
      "\n",
      "The classification loss after processing this batch is:  0.09225118905305862\n",
      "The representation loss after processing this batch is:  0.0027719996869564056\n",
      "\n",
      "The classification loss after processing this batch is:  0.04618329927325249\n",
      "The representation loss after processing this batch is:  0.002908945083618164\n",
      "\n",
      "The classification loss after processing this batch is:  0.11177994310855865\n",
      "The representation loss after processing this batch is:  0.002521499991416931\n",
      "\n",
      "The classification loss after processing this batch is:  0.09635476768016815\n",
      "The representation loss after processing this batch is:  0.00275372713804245\n",
      "\n",
      "The classification loss after processing this batch is:  0.10809390991926193\n",
      "The representation loss after processing this batch is:  0.002496868371963501\n",
      "\n",
      "The classification loss after processing this batch is:  0.20846731960773468\n",
      "The representation loss after processing this batch is:  0.002746894955635071\n",
      "\n",
      "The classification loss after processing this batch is:  0.14772024750709534\n",
      "The representation loss after processing this batch is:  0.002373240888118744\n",
      "\n",
      "The classification loss after processing this batch is:  0.11034233123064041\n",
      "The representation loss after processing this batch is:  0.002838447690010071\n",
      "\n",
      "The classification loss after processing this batch is:  0.14723806083202362\n",
      "The representation loss after processing this batch is:  0.002685699611902237\n",
      "\n",
      "The classification loss after processing this batch is:  0.10204382240772247\n",
      "The representation loss after processing this batch is:  0.002927727997303009\n",
      "\n",
      "The classification loss after processing this batch is:  0.10748327523469925\n",
      "The representation loss after processing this batch is:  0.0025637000799179077\n",
      "\n",
      "The classification loss after processing this batch is:  0.18706434965133667\n",
      "The representation loss after processing this batch is:  0.002612084150314331\n",
      "\n",
      "The classification loss after processing this batch is:  0.1754579097032547\n",
      "The representation loss after processing this batch is:  0.0035027116537094116\n",
      "\n",
      "The classification loss after processing this batch is:  0.11604487895965576\n",
      "The representation loss after processing this batch is:  0.0026385709643363953\n",
      "\n",
      "The classification loss after processing this batch is:  0.06936916708946228\n",
      "The representation loss after processing this batch is:  0.002817060798406601\n",
      "\n",
      "The classification loss after processing this batch is:  0.09856664389371872\n",
      "The representation loss after processing this batch is:  0.0025559067726135254\n",
      "\n",
      "The classification loss after processing this batch is:  0.06945773214101791\n",
      "The representation loss after processing this batch is:  0.002913057804107666\n",
      "\n",
      "The classification loss after processing this batch is:  0.11654306203126907\n",
      "The representation loss after processing this batch is:  0.0025068148970603943\n",
      "\n",
      "The classification loss after processing this batch is:  0.22264979779720306\n",
      "The representation loss after processing this batch is:  0.0024423450231552124\n",
      "\n",
      "The classification loss after processing this batch is:  0.2642534673213959\n",
      "The representation loss after processing this batch is:  0.0029194727540016174\n",
      "\n",
      "The classification loss after processing this batch is:  0.126397967338562\n",
      "The representation loss after processing this batch is:  0.0024224258959293365\n",
      "\n",
      "The classification loss after processing this batch is:  0.11771979182958603\n",
      "The representation loss after processing this batch is:  0.002393517643213272\n",
      "\n",
      "The classification loss after processing this batch is:  0.0932944267988205\n",
      "The representation loss after processing this batch is:  0.002576984465122223\n",
      "\n",
      "The classification loss after processing this batch is:  0.11831498891115189\n",
      "The representation loss after processing this batch is:  0.0025100335478782654\n",
      "\n",
      "The classification loss after processing this batch is:  0.20875829458236694\n",
      "The representation loss after processing this batch is:  0.002878289669752121\n",
      "\n",
      "The classification loss after processing this batch is:  0.1393629014492035\n",
      "The representation loss after processing this batch is:  0.0023306161165237427\n",
      "\n",
      "The classification loss after processing this batch is:  0.3077952563762665\n",
      "The representation loss after processing this batch is:  0.0025759413838386536\n",
      "\n",
      "The classification loss after processing this batch is:  0.1586495041847229\n",
      "The representation loss after processing this batch is:  0.0026639848947525024\n",
      "\n",
      "The classification loss after processing this batch is:  0.05732150003314018\n",
      "The representation loss after processing this batch is:  0.0030342265963554382\n",
      "\n",
      "The classification loss after processing this batch is:  0.137638121843338\n",
      "The representation loss after processing this batch is:  0.00250055268406868\n",
      "\n",
      "The classification loss after processing this batch is:  0.13185250759124756\n",
      "The representation loss after processing this batch is:  0.002405766397714615\n",
      "\n",
      "The classification loss after processing this batch is:  0.1738363355398178\n",
      "The representation loss after processing this batch is:  0.0026527345180511475\n",
      "\n",
      "The classification loss after processing this batch is:  0.12431623786687851\n",
      "The representation loss after processing this batch is:  0.0023450255393981934\n",
      "\n",
      "The classification loss after processing this batch is:  0.1737222820520401\n",
      "The representation loss after processing this batch is:  0.0023060664534568787\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.12078886479139328\n",
      "The representation loss after processing this batch is:  0.0024785473942756653\n",
      "\n",
      "The classification loss after processing this batch is:  0.15732938051223755\n",
      "The representation loss after processing this batch is:  0.0024968013167381287\n",
      "\n",
      "The classification loss after processing this batch is:  0.1925160139799118\n",
      "The representation loss after processing this batch is:  0.0026963576674461365\n",
      "\n",
      "The classification loss after processing this batch is:  0.23480266332626343\n",
      "The representation loss after processing this batch is:  0.0024445131421089172\n",
      "\n",
      "The classification loss after processing this batch is:  0.14409373700618744\n",
      "The representation loss after processing this batch is:  0.002501383423805237\n",
      "\n",
      "The classification loss after processing this batch is:  0.05060390755534172\n",
      "The representation loss after processing this batch is:  0.0030877143144607544\n",
      "\n",
      "The classification loss after processing this batch is:  0.025890879333019257\n",
      "The representation loss after processing this batch is:  0.0026540160179138184\n",
      "\n",
      "The classification loss after processing this batch is:  0.1033269539475441\n",
      "The representation loss after processing this batch is:  0.0029728561639785767\n",
      "\n",
      "The classification loss after processing this batch is:  0.0828196257352829\n",
      "The representation loss after processing this batch is:  0.004183284938335419\n",
      "\n",
      "The classification loss after processing this batch is:  0.15129759907722473\n",
      "The representation loss after processing this batch is:  0.002690427005290985\n",
      "\n",
      "The classification loss after processing this batch is:  0.11153481155633926\n",
      "The representation loss after processing this batch is:  0.003004804253578186\n",
      "\n",
      "The classification loss after processing this batch is:  0.14531752467155457\n",
      "The representation loss after processing this batch is:  0.002465665340423584\n",
      "\n",
      "The classification loss after processing this batch is:  0.05473615229129791\n",
      "The representation loss after processing this batch is:  0.0027844607830047607\n",
      "\n",
      "The classification loss after processing this batch is:  0.12827879190444946\n",
      "The representation loss after processing this batch is:  0.00257100909948349\n",
      "\n",
      "The classification loss after processing this batch is:  0.11373122036457062\n",
      "The representation loss after processing this batch is:  0.002734251320362091\n",
      "\n",
      "The classification loss after processing this batch is:  0.15450052917003632\n",
      "The representation loss after processing this batch is:  0.0027253180742263794\n",
      "\n",
      "The classification loss after processing this batch is:  0.08508496731519699\n",
      "The representation loss after processing this batch is:  0.0025278180837631226\n",
      "\n",
      "The classification loss after processing this batch is:  0.07375062257051468\n",
      "The representation loss after processing this batch is:  0.002053234726190567\n",
      "\n",
      "The classification loss after processing this batch is:  0.12388814240694046\n",
      "The representation loss after processing this batch is:  0.0024251416325569153\n",
      "\n",
      "The classification loss after processing this batch is:  0.1445259153842926\n",
      "The representation loss after processing this batch is:  0.0025415271520614624\n",
      "\n",
      "The classification loss after processing this batch is:  0.10982795059680939\n",
      "The representation loss after processing this batch is:  0.0023762881755828857\n",
      "\n",
      "The classification loss after processing this batch is:  0.14133800566196442\n",
      "The representation loss after processing this batch is:  0.002765752375125885\n",
      "\n",
      "The classification loss after processing this batch is:  0.09998355060815811\n",
      "The representation loss after processing this batch is:  0.0025928691029548645\n",
      "\n",
      "The classification loss after processing this batch is:  0.0325169637799263\n",
      "The representation loss after processing this batch is:  0.0024552345275878906\n",
      "\n",
      "The classification loss after processing this batch is:  0.06574108451604843\n",
      "The representation loss after processing this batch is:  0.0029370486736297607\n",
      "\n",
      "The classification loss after processing this batch is:  0.045049961656332016\n",
      "The representation loss after processing this batch is:  0.0026391446590423584\n",
      "\n",
      "The classification loss after processing this batch is:  0.11535942554473877\n",
      "The representation loss after processing this batch is:  0.0026872828602790833\n",
      "\n",
      "The classification loss after processing this batch is:  0.06589492410421371\n",
      "The representation loss after processing this batch is:  0.0025587528944015503\n",
      "\n",
      "The classification loss after processing this batch is:  0.06592921167612076\n",
      "The representation loss after processing this batch is:  0.002496756613254547\n",
      "\n",
      "The classification loss after processing this batch is:  0.11165384948253632\n",
      "The representation loss after processing this batch is:  0.0028732195496559143\n",
      "\n",
      "The classification loss after processing this batch is:  0.11162310093641281\n",
      "The representation loss after processing this batch is:  0.002490423619747162\n",
      "\n",
      "The classification loss after processing this batch is:  0.06675059348344803\n",
      "The representation loss after processing this batch is:  0.0023514926433563232\n",
      "\n",
      "The classification loss after processing this batch is:  0.048044245690107346\n",
      "The representation loss after processing this batch is:  0.0025184378027915955\n",
      "\n",
      "The classification loss after processing this batch is:  0.05159996449947357\n",
      "The representation loss after processing this batch is:  0.002588331699371338\n",
      "\n",
      "The classification loss after processing this batch is:  0.04069681838154793\n",
      "The representation loss after processing this batch is:  0.0026633813977241516\n",
      "\n",
      "The classification loss after processing this batch is:  0.13406017422676086\n",
      "The representation loss after processing this batch is:  0.0025330930948257446\n",
      "\n",
      "The classification loss after processing this batch is:  0.1253896802663803\n",
      "The representation loss after processing this batch is:  0.0027741268277168274\n",
      "\n",
      "The classification loss after processing this batch is:  0.06105518713593483\n",
      "The representation loss after processing this batch is:  0.0024838969111442566\n",
      "\n",
      "The classification loss after processing this batch is:  0.14791031181812286\n",
      "The representation loss after processing this batch is:  0.002587702125310898\n",
      "\n",
      "The classification loss after processing this batch is:  0.06389998644590378\n",
      "The representation loss after processing this batch is:  0.0024896934628486633\n",
      "\n",
      "The classification loss after processing this batch is:  0.13323253393173218\n",
      "The representation loss after processing this batch is:  0.002441123127937317\n",
      "\n",
      "The classification loss after processing this batch is:  0.17689929902553558\n",
      "The representation loss after processing this batch is:  0.002751033753156662\n",
      "\n",
      "The classification loss after processing this batch is:  0.0916958749294281\n",
      "The representation loss after processing this batch is:  0.002612106502056122\n",
      "\n",
      "The classification loss after processing this batch is:  0.1714901626110077\n",
      "The representation loss after processing this batch is:  0.002365667372941971\n",
      "\n",
      "The classification loss after processing this batch is:  0.11723313480615616\n",
      "The representation loss after processing this batch is:  0.0022226572036743164\n",
      "\n",
      "The classification loss after processing this batch is:  0.1574089229106903\n",
      "The representation loss after processing this batch is:  0.0024373680353164673\n",
      "\n",
      "The classification loss after processing this batch is:  0.12276769429445267\n",
      "The representation loss after processing this batch is:  0.002351529896259308\n",
      "\n",
      "The classification loss after processing this batch is:  0.07653580605983734\n",
      "The representation loss after processing this batch is:  0.0027173683047294617\n",
      "\n",
      "The classification loss after processing this batch is:  0.1135806143283844\n",
      "The representation loss after processing this batch is:  0.0022118017077445984\n",
      "\n",
      "The classification loss after processing this batch is:  0.10134883224964142\n",
      "The representation loss after processing this batch is:  0.002750307321548462\n",
      "\n",
      "The classification loss after processing this batch is:  0.16466684639453888\n",
      "The representation loss after processing this batch is:  0.002701926976442337\n",
      "\n",
      "The classification loss after processing this batch is:  0.11421331763267517\n",
      "The representation loss after processing this batch is:  0.0025705695152282715\n",
      "\n",
      "The classification loss after processing this batch is:  0.06611751019954681\n",
      "The representation loss after processing this batch is:  0.0025147274136543274\n",
      "\n",
      "The classification loss after processing this batch is:  0.11721386015415192\n",
      "The representation loss after processing this batch is:  0.00245676189661026\n",
      "\n",
      "The classification loss after processing this batch is:  0.19241517782211304\n",
      "The representation loss after processing this batch is:  0.0023875944316387177\n",
      "\n",
      "The classification loss after processing this batch is:  0.07512089610099792\n",
      "The representation loss after processing this batch is:  0.0025673583149909973\n",
      "\n",
      "The classification loss after processing this batch is:  0.1179397851228714\n",
      "The representation loss after processing this batch is:  0.002416543662548065\n",
      "\n",
      "The classification loss after processing this batch is:  0.10800154507160187\n",
      "The representation loss after processing this batch is:  0.002239815890789032\n",
      "\n",
      "The classification loss after processing this batch is:  0.079032301902771\n",
      "The representation loss after processing this batch is:  0.0028706416487693787\n",
      "\n",
      "The classification loss after processing this batch is:  0.0483253113925457\n",
      "The representation loss after processing this batch is:  0.0029361695051193237\n",
      "\n",
      "The classification loss after processing this batch is:  0.09675029665231705\n",
      "The representation loss after processing this batch is:  0.0029934197664260864\n",
      "\n",
      "The classification loss after processing this batch is:  0.10524330288171768\n",
      "The representation loss after processing this batch is:  0.0026907064020633698\n",
      "\n",
      "The classification loss after processing this batch is:  0.10136163234710693\n",
      "The representation loss after processing this batch is:  0.0025084130465984344\n",
      "\n",
      "The classification loss after processing this batch is:  0.14754047989845276\n",
      "The representation loss after processing this batch is:  0.0028329938650131226\n",
      "\n",
      "The classification loss after processing this batch is:  0.12978677451610565\n",
      "The representation loss after processing this batch is:  0.002759527415037155\n",
      "\n",
      "The classification loss after processing this batch is:  0.1472107321023941\n",
      "The representation loss after processing this batch is:  0.0022418759763240814\n",
      "\n",
      "The classification loss after processing this batch is:  0.15613968670368195\n",
      "The representation loss after processing this batch is:  0.0029125064611434937\n",
      "\n",
      "The classification loss after processing this batch is:  0.0505240373313427\n",
      "The representation loss after processing this batch is:  0.002728991210460663\n",
      "\n",
      "The classification loss after processing this batch is:  0.0532829686999321\n",
      "The representation loss after processing this batch is:  0.002536587417125702\n",
      "\n",
      "The classification loss after processing this batch is:  0.09544432163238525\n",
      "The representation loss after processing this batch is:  0.002504199743270874\n",
      "\n",
      "The classification loss after processing this batch is:  0.10908862948417664\n",
      "The representation loss after processing this batch is:  0.0026639997959136963\n",
      "\n",
      "The classification loss after processing this batch is:  0.09212788939476013\n",
      "The representation loss after processing this batch is:  0.0024742111563682556\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1117284968495369\n",
      "The representation loss after processing this batch is:  0.0025846511125564575\n",
      "\n",
      "The classification loss after processing this batch is:  0.1128433421254158\n",
      "The representation loss after processing this batch is:  0.0030082762241363525\n",
      "\n",
      "The classification loss after processing this batch is:  0.12633059918880463\n",
      "The representation loss after processing this batch is:  0.002833828330039978\n",
      "\n",
      "The classification loss after processing this batch is:  0.16560839116573334\n",
      "The representation loss after processing this batch is:  0.0024963319301605225\n",
      "\n",
      "The classification loss after processing this batch is:  0.15252819657325745\n",
      "The representation loss after processing this batch is:  0.0025062263011932373\n",
      "\n",
      "The classification loss after processing this batch is:  0.14923371374607086\n",
      "The representation loss after processing this batch is:  0.0023428238928318024\n",
      "\n",
      "The classification loss after processing this batch is:  0.06613239645957947\n",
      "The representation loss after processing this batch is:  0.002960704267024994\n",
      "\n",
      "The classification loss after processing this batch is:  0.04372930899262428\n",
      "The representation loss after processing this batch is:  0.0028303489089012146\n",
      "\n",
      "The classification loss after processing this batch is:  0.1478642076253891\n",
      "The representation loss after processing this batch is:  0.0022954754531383514\n",
      "\n",
      "The classification loss after processing this batch is:  0.19803060591220856\n",
      "The representation loss after processing this batch is:  0.0023332610726356506\n",
      "\n",
      "The classification loss after processing this batch is:  0.1573595404624939\n",
      "The representation loss after processing this batch is:  0.0025938600301742554\n",
      "\n",
      "The classification loss after processing this batch is:  0.1436184048652649\n",
      "The representation loss after processing this batch is:  0.0025151148438453674\n",
      "\n",
      "The classification loss after processing this batch is:  0.14343777298927307\n",
      "The representation loss after processing this batch is:  0.002570066601037979\n",
      "\n",
      "The classification loss after processing this batch is:  0.19125565886497498\n",
      "The representation loss after processing this batch is:  0.002513304352760315\n",
      "\n",
      "The classification loss after processing this batch is:  0.20713075995445251\n",
      "The representation loss after processing this batch is:  0.0025113560259342194\n",
      "\n",
      "The classification loss after processing this batch is:  0.20331726968288422\n",
      "The representation loss after processing this batch is:  0.002708040177822113\n",
      "\n",
      "The classification loss after processing this batch is:  0.15805545449256897\n",
      "The representation loss after processing this batch is:  0.002657722681760788\n",
      "\n",
      "The classification loss after processing this batch is:  0.11511602252721786\n",
      "The representation loss after processing this batch is:  0.003239627927541733\n",
      "\n",
      "The classification loss after processing this batch is:  0.07276257127523422\n",
      "The representation loss after processing this batch is:  0.0029500648379325867\n",
      "\n",
      "The classification loss after processing this batch is:  0.10732843726873398\n",
      "The representation loss after processing this batch is:  0.0026084408164024353\n",
      "\n",
      "The classification loss after processing this batch is:  0.09215404838323593\n",
      "The representation loss after processing this batch is:  0.0022870004177093506\n",
      "\n",
      "The classification loss after processing this batch is:  0.07038231194019318\n",
      "The representation loss after processing this batch is:  0.0023882240056991577\n",
      "\n",
      "The classification loss after processing this batch is:  0.05200110748410225\n",
      "The representation loss after processing this batch is:  0.002399977296590805\n",
      "\n",
      "The classification loss after processing this batch is:  0.13790363073349\n",
      "The representation loss after processing this batch is:  0.002474382519721985\n",
      "\n",
      "The classification loss after processing this batch is:  0.06466296315193176\n",
      "The representation loss after processing this batch is:  0.002593211829662323\n",
      "\n",
      "The classification loss after processing this batch is:  0.09141770750284195\n",
      "The representation loss after processing this batch is:  0.002845529466867447\n",
      "\n",
      "The classification loss after processing this batch is:  0.09620647132396698\n",
      "The representation loss after processing this batch is:  0.0021828562021255493\n",
      "\n",
      "The classification loss after processing this batch is:  0.07828836143016815\n",
      "The representation loss after processing this batch is:  0.002370554953813553\n",
      "\n",
      "The classification loss after processing this batch is:  0.07264979928731918\n",
      "The representation loss after processing this batch is:  0.0026789791882038116\n",
      "\n",
      "The classification loss after processing this batch is:  0.09175791591405869\n",
      "The representation loss after processing this batch is:  0.002452131360769272\n",
      "\n",
      "The classification loss after processing this batch is:  0.1365210860967636\n",
      "The representation loss after processing this batch is:  0.0028663724660873413\n",
      "\n",
      "The classification loss after processing this batch is:  0.040892548859119415\n",
      "The representation loss after processing this batch is:  0.002797722816467285\n",
      "\n",
      "The classification loss after processing this batch is:  0.04474533721804619\n",
      "The representation loss after processing this batch is:  0.0027545690536499023\n",
      "\n",
      "The classification loss after processing this batch is:  0.1345445066690445\n",
      "The representation loss after processing this batch is:  0.0025061964988708496\n",
      "\n",
      "The classification loss after processing this batch is:  0.17634843289852142\n",
      "The representation loss after processing this batch is:  0.002505306154489517\n",
      "\n",
      "The classification loss after processing this batch is:  0.10759146511554718\n",
      "The representation loss after processing this batch is:  0.0025530457496643066\n",
      "\n",
      "The classification loss after processing this batch is:  0.050604891031980515\n",
      "The representation loss after processing this batch is:  0.00228273868560791\n",
      "\n",
      "The classification loss after processing this batch is:  0.10240007191896439\n",
      "The representation loss after processing this batch is:  0.002407938241958618\n",
      "\n",
      "The classification loss after processing this batch is:  0.02515196055173874\n",
      "The representation loss after processing this batch is:  0.0026974454522132874\n",
      "\n",
      "The classification loss after processing this batch is:  0.11253781616687775\n",
      "The representation loss after processing this batch is:  0.0025440454483032227\n",
      "\n",
      "The classification loss after processing this batch is:  0.09789849817752838\n",
      "The representation loss after processing this batch is:  0.0027122944593429565\n",
      "\n",
      "The classification loss after processing this batch is:  0.06096506863832474\n",
      "The representation loss after processing this batch is:  0.002319924533367157\n",
      "\n",
      "The classification loss after processing this batch is:  0.0667264461517334\n",
      "The representation loss after processing this batch is:  0.0026226043701171875\n",
      "\n",
      "The classification loss after processing this batch is:  0.09304618835449219\n",
      "The representation loss after processing this batch is:  0.0025199875235557556\n",
      "\n",
      "The classification loss after processing this batch is:  0.06874330341815948\n",
      "The representation loss after processing this batch is:  0.002441875636577606\n",
      "\n",
      "The classification loss after processing this batch is:  0.19005423784255981\n",
      "The representation loss after processing this batch is:  0.0025513172149658203\n",
      "\n",
      "The classification loss after processing this batch is:  0.2586418390274048\n",
      "The representation loss after processing this batch is:  0.0025274865329265594\n",
      "\n",
      "The classification loss after processing this batch is:  0.17657817900180817\n",
      "The representation loss after processing this batch is:  0.0024814754724502563\n",
      "\n",
      "The classification loss after processing this batch is:  0.1923617720603943\n",
      "The representation loss after processing this batch is:  0.002530869096517563\n",
      "\n",
      "The classification loss after processing this batch is:  0.11426880955696106\n",
      "The representation loss after processing this batch is:  0.002507418394088745\n",
      "\n",
      "The classification loss after processing this batch is:  0.07355805486440659\n",
      "The representation loss after processing this batch is:  0.0024361833930015564\n",
      "\n",
      "The classification loss after processing this batch is:  0.17266665399074554\n",
      "The representation loss after processing this batch is:  0.00237341970205307\n",
      "\n",
      "The classification loss after processing this batch is:  0.12785640358924866\n",
      "The representation loss after processing this batch is:  0.0025551728904247284\n",
      "\n",
      "The classification loss after processing this batch is:  0.1238538920879364\n",
      "The representation loss after processing this batch is:  0.00256289541721344\n",
      "\n",
      "The classification loss after processing this batch is:  0.1418338268995285\n",
      "The representation loss after processing this batch is:  0.002759866416454315\n",
      "\n",
      "The classification loss after processing this batch is:  0.1358339786529541\n",
      "The representation loss after processing this batch is:  0.0025359690189361572\n",
      "\n",
      "The classification loss after processing this batch is:  0.07793440669775009\n",
      "The representation loss after processing this batch is:  0.0025125928223133087\n",
      "\n",
      "The classification loss after processing this batch is:  0.098199263215065\n",
      "The representation loss after processing this batch is:  0.002612285315990448\n",
      "\n",
      "The classification loss after processing this batch is:  0.13118544220924377\n",
      "The representation loss after processing this batch is:  0.0024925842881202698\n",
      "\n",
      "The classification loss after processing this batch is:  0.05166390910744667\n",
      "The representation loss after processing this batch is:  0.002657182514667511\n",
      "\n",
      "The classification loss after processing this batch is:  0.051394350826740265\n",
      "The representation loss after processing this batch is:  0.0026366636157035828\n",
      "\n",
      "The classification loss after processing this batch is:  0.10425470769405365\n",
      "The representation loss after processing this batch is:  0.0024145953357219696\n",
      "\n",
      "The classification loss after processing this batch is:  0.15913139283657074\n",
      "The representation loss after processing this batch is:  0.002417132258415222\n",
      "\n",
      "The classification loss after processing this batch is:  0.05274490267038345\n",
      "The representation loss after processing this batch is:  0.002369612455368042\n",
      "\n",
      "The classification loss after processing this batch is:  0.06496039032936096\n",
      "The representation loss after processing this batch is:  0.0024072490632534027\n",
      "\n",
      "The classification loss after processing this batch is:  0.15922872722148895\n",
      "The representation loss after processing this batch is:  0.002330571413040161\n",
      "\n",
      "The classification loss after processing this batch is:  0.1893574744462967\n",
      "The representation loss after processing this batch is:  0.002360016107559204\n",
      "\n",
      "The classification loss after processing this batch is:  0.0810767337679863\n",
      "The representation loss after processing this batch is:  0.0022743865847587585\n",
      "\n",
      "The classification loss after processing this batch is:  0.1817978024482727\n",
      "The representation loss after processing this batch is:  0.0022873654961586\n",
      "\n",
      "The classification loss after processing this batch is:  0.0636732429265976\n",
      "The representation loss after processing this batch is:  0.002848304808139801\n",
      "\n",
      "The classification loss after processing this batch is:  0.03565230593085289\n",
      "The representation loss after processing this batch is:  0.0024064406752586365\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.04974151775240898\n",
      "The representation loss after processing this batch is:  0.0023793652653694153\n",
      "\n",
      "The classification loss after processing this batch is:  0.1449935883283615\n",
      "The representation loss after processing this batch is:  0.003039538860321045\n",
      "\n",
      "The classification loss after processing this batch is:  0.15367881953716278\n",
      "The representation loss after processing this batch is:  0.0026565417647361755\n",
      "\n",
      "The classification loss after processing this batch is:  0.0760003849864006\n",
      "The representation loss after processing this batch is:  0.003189265727996826\n",
      "\n",
      "The classification loss after processing this batch is:  0.09438380599021912\n",
      "The representation loss after processing this batch is:  0.002302907407283783\n",
      "\n",
      "The classification loss after processing this batch is:  0.06618455797433853\n",
      "The representation loss after processing this batch is:  0.0026220008730888367\n",
      "\n",
      "The classification loss after processing this batch is:  0.13441674411296844\n",
      "The representation loss after processing this batch is:  0.0025845952332019806\n",
      "\n",
      "The classification loss after processing this batch is:  0.0952494665980339\n",
      "The representation loss after processing this batch is:  0.002346612513065338\n",
      "\n",
      "The classification loss after processing this batch is:  0.1583893597126007\n",
      "The representation loss after processing this batch is:  0.0024353638291358948\n",
      "\n",
      "The classification loss after processing this batch is:  0.15557034313678741\n",
      "The representation loss after processing this batch is:  0.002652369439601898\n",
      "\n",
      "The classification loss after processing this batch is:  0.23970529437065125\n",
      "The representation loss after processing this batch is:  0.0021841078996658325\n",
      "\n",
      "The classification loss after processing this batch is:  0.12128520011901855\n",
      "The representation loss after processing this batch is:  0.0022919103503227234\n",
      "\n",
      "The classification loss after processing this batch is:  0.17075970768928528\n",
      "The representation loss after processing this batch is:  0.002450421452522278\n",
      "\n",
      "The classification loss after processing this batch is:  0.1546001434326172\n",
      "The representation loss after processing this batch is:  0.0024922937154769897\n",
      "\n",
      "The classification loss after processing this batch is:  0.06825248152017593\n",
      "The representation loss after processing this batch is:  0.0025736279785633087\n",
      "\n",
      "The classification loss after processing this batch is:  0.10275297611951828\n",
      "The representation loss after processing this batch is:  0.002928629517555237\n",
      "\n",
      "The classification loss after processing this batch is:  0.05949697270989418\n",
      "The representation loss after processing this batch is:  0.002643302083015442\n",
      "\n",
      "The classification loss after processing this batch is:  0.10709431022405624\n",
      "The representation loss after processing this batch is:  0.0023374222218990326\n",
      "\n",
      "The classification loss after processing this batch is:  0.10420543700456619\n",
      "The representation loss after processing this batch is:  0.002138867974281311\n",
      "\n",
      "The classification loss after processing this batch is:  0.09222455322742462\n",
      "The representation loss after processing this batch is:  0.002318248152732849\n",
      "\n",
      "The classification loss after processing this batch is:  0.10188224166631699\n",
      "The representation loss after processing this batch is:  0.00245734304189682\n",
      "\n",
      "The classification loss after processing this batch is:  0.13995619118213654\n",
      "The representation loss after processing this batch is:  0.002370387315750122\n",
      "\n",
      "The classification loss after processing this batch is:  0.11398060619831085\n",
      "The representation loss after processing this batch is:  0.002364411950111389\n",
      "\n",
      "The classification loss after processing this batch is:  0.17605431377887726\n",
      "The representation loss after processing this batch is:  0.0025787651538848877\n",
      "\n",
      "The classification loss after processing this batch is:  0.08861545473337173\n",
      "The representation loss after processing this batch is:  0.0026741474866867065\n",
      "\n",
      "The classification loss after processing this batch is:  0.09313011914491653\n",
      "The representation loss after processing this batch is:  0.00221141055226326\n",
      "\n",
      "The classification loss after processing this batch is:  0.08515836298465729\n",
      "The representation loss after processing this batch is:  0.0028195008635520935\n",
      "\n",
      "The classification loss after processing this batch is:  0.17729666829109192\n",
      "The representation loss after processing this batch is:  0.0031872354447841644\n",
      "\n",
      "The classification loss after processing this batch is:  0.26017463207244873\n",
      "The representation loss after processing this batch is:  0.002788528800010681\n",
      "\n",
      "The classification loss after processing this batch is:  0.0412631593644619\n",
      "The representation loss after processing this batch is:  0.0023353174328804016\n",
      "\n",
      "The classification loss after processing this batch is:  0.06666140258312225\n",
      "The representation loss after processing this batch is:  0.002518441528081894\n",
      "\n",
      "The classification loss after processing this batch is:  0.19833190739154816\n",
      "The representation loss after processing this batch is:  0.0030288435518741608\n",
      "\n",
      "The classification loss after processing this batch is:  0.045686040073633194\n",
      "The representation loss after processing this batch is:  0.002803705632686615\n",
      "\n",
      "The classification loss after processing this batch is:  0.0638897567987442\n",
      "The representation loss after processing this batch is:  0.00243242084980011\n",
      "\n",
      "The classification loss after processing this batch is:  0.12898249924182892\n",
      "The representation loss after processing this batch is:  0.002656906843185425\n",
      "\n",
      "The classification loss after processing this batch is:  0.07634266465902328\n",
      "The representation loss after processing this batch is:  0.0027808472514152527\n",
      "\n",
      "The classification loss after processing this batch is:  0.14985887706279755\n",
      "The representation loss after processing this batch is:  0.0030480772256851196\n",
      "\n",
      "The classification loss after processing this batch is:  0.11262577027082443\n",
      "The representation loss after processing this batch is:  0.0029809176921844482\n",
      "\n",
      "The classification loss after processing this batch is:  0.12403691560029984\n",
      "The representation loss after processing this batch is:  0.002884507179260254\n",
      "\n",
      "The classification loss after processing this batch is:  0.08764370530843735\n",
      "The representation loss after processing this batch is:  0.0021556131541728973\n",
      "\n",
      "The classification loss after processing this batch is:  0.14660267531871796\n",
      "The representation loss after processing this batch is:  0.00227278470993042\n",
      "\n",
      "The classification loss after processing this batch is:  0.0391206331551075\n",
      "The representation loss after processing this batch is:  0.002404734492301941\n",
      "\n",
      "The classification loss after processing this batch is:  0.04018807411193848\n",
      "The representation loss after processing this batch is:  0.0024887770414352417\n",
      "\n",
      "The classification loss after processing this batch is:  0.10425829142332077\n",
      "The representation loss after processing this batch is:  0.002567622810602188\n",
      "\n",
      "The classification loss after processing this batch is:  0.0690205916762352\n",
      "The representation loss after processing this batch is:  0.002579130232334137\n",
      "\n",
      "The classification loss after processing this batch is:  0.09565511345863342\n",
      "The representation loss after processing this batch is:  0.0022508837282657623\n",
      "\n",
      "The classification loss after processing this batch is:  0.060413770377635956\n",
      "The representation loss after processing this batch is:  0.002333894371986389\n",
      "\n",
      "The classification loss after processing this batch is:  0.07463305443525314\n",
      "The representation loss after processing this batch is:  0.0025639235973358154\n",
      "\n",
      "The classification loss after processing this batch is:  0.1162668764591217\n",
      "The representation loss after processing this batch is:  0.002376280725002289\n",
      "\n",
      "The classification loss after processing this batch is:  0.15947557985782623\n",
      "The representation loss after processing this batch is:  0.0027958229184150696\n",
      "\n",
      "The classification loss after processing this batch is:  0.17120331525802612\n",
      "The representation loss after processing this batch is:  0.002419758588075638\n",
      "\n",
      "The classification loss after processing this batch is:  0.07019218802452087\n",
      "The representation loss after processing this batch is:  0.0027130097150802612\n",
      "\n",
      "The classification loss after processing this batch is:  0.18030564486980438\n",
      "The representation loss after processing this batch is:  0.002449706196784973\n",
      "\n",
      "The classification loss after processing this batch is:  0.06869137287139893\n",
      "The representation loss after processing this batch is:  0.002273932099342346\n",
      "\n",
      "The classification loss after processing this batch is:  0.13565734028816223\n",
      "The representation loss after processing this batch is:  0.0024763867259025574\n",
      "\n",
      "The classification loss after processing this batch is:  0.23196066915988922\n",
      "The representation loss after processing this batch is:  0.002853803336620331\n",
      "\n",
      "The classification loss after processing this batch is:  0.1005876436829567\n",
      "The representation loss after processing this batch is:  0.0023961924016475677\n",
      "\n",
      "The classification loss after processing this batch is:  0.15227238833904266\n",
      "The representation loss after processing this batch is:  0.0024407096207141876\n",
      "\n",
      "The classification loss after processing this batch is:  0.10902898013591766\n",
      "The representation loss after processing this batch is:  0.002426154911518097\n",
      "\n",
      "The classification loss after processing this batch is:  0.16632598638534546\n",
      "The representation loss after processing this batch is:  0.002397492527961731\n",
      "\n",
      "The classification loss after processing this batch is:  0.10014127939939499\n",
      "The representation loss after processing this batch is:  0.0024370476603507996\n",
      "\n",
      "The classification loss after processing this batch is:  0.08714165538549423\n",
      "The representation loss after processing this batch is:  0.002523079514503479\n",
      "\n",
      "The classification loss after processing this batch is:  0.09843257814645767\n",
      "The representation loss after processing this batch is:  0.0025929883122444153\n",
      "\n",
      "The classification loss after processing this batch is:  0.04961274191737175\n",
      "The representation loss after processing this batch is:  0.002572186291217804\n",
      "\n",
      "The classification loss after processing this batch is:  0.04215027391910553\n",
      "The representation loss after processing this batch is:  0.0022815167903900146\n",
      "\n",
      "The classification loss after processing this batch is:  0.11555342376232147\n",
      "The representation loss after processing this batch is:  0.0029311925172805786\n",
      "\n",
      "The classification loss after processing this batch is:  0.045862097293138504\n",
      "The representation loss after processing this batch is:  0.0027831941843032837\n",
      "\n",
      "The classification loss after processing this batch is:  0.19229553639888763\n",
      "The representation loss after processing this batch is:  0.002890590578317642\n",
      "\n",
      "The classification loss after processing this batch is:  0.0855877622961998\n",
      "The representation loss after processing this batch is:  0.0024605169892311096\n",
      "\n",
      "The classification loss after processing this batch is:  0.19394871592521667\n",
      "The representation loss after processing this batch is:  0.002405315637588501\n",
      "\n",
      "The classification loss after processing this batch is:  0.2364915907382965\n",
      "The representation loss after processing this batch is:  0.0022873058915138245\n",
      "\n",
      "The classification loss after processing this batch is:  0.1402360498905182\n",
      "The representation loss after processing this batch is:  0.002288173884153366\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.04730930179357529\n",
      "The representation loss after processing this batch is:  0.0027003400027751923\n",
      "\n",
      "The classification loss after processing this batch is:  0.06381835043430328\n",
      "The representation loss after processing this batch is:  0.0028172507882118225\n",
      "\n",
      "The classification loss after processing this batch is:  0.0514884851872921\n",
      "The representation loss after processing this batch is:  0.002935469150543213\n",
      "\n",
      "The classification loss after processing this batch is:  0.07984548062086105\n",
      "The representation loss after processing this batch is:  0.002767018973827362\n",
      "\n",
      "The classification loss after processing this batch is:  0.09553644061088562\n",
      "The representation loss after processing this batch is:  0.0021473579108715057\n",
      "\n",
      "The classification loss after processing this batch is:  0.24881142377853394\n",
      "The representation loss after processing this batch is:  0.0024845264852046967\n",
      "\n",
      "The classification loss after processing this batch is:  0.17815981805324554\n",
      "The representation loss after processing this batch is:  0.002280488610267639\n",
      "\n",
      "The classification loss after processing this batch is:  0.10541584342718124\n",
      "The representation loss after processing this batch is:  0.002859346568584442\n",
      "\n",
      "The classification loss after processing this batch is:  0.22234699130058289\n",
      "The representation loss after processing this batch is:  0.0029613375663757324\n",
      "\n",
      "The classification loss after processing this batch is:  0.056049566715955734\n",
      "The representation loss after processing this batch is:  0.0025549381971359253\n",
      "\n",
      "The classification loss after processing this batch is:  0.08904968947172165\n",
      "The representation loss after processing this batch is:  0.0025264322757720947\n",
      "\n",
      "The classification loss after processing this batch is:  0.15199561417102814\n",
      "The representation loss after processing this batch is:  0.002497568726539612\n",
      "\n",
      "The classification loss after processing this batch is:  0.09464218467473984\n",
      "The representation loss after processing this batch is:  0.0029224753379821777\n",
      "\n",
      "The classification loss after processing this batch is:  0.12082085013389587\n",
      "The representation loss after processing this batch is:  0.003283776342868805\n",
      "\n",
      "The classification loss after processing this batch is:  0.08980471640825272\n",
      "The representation loss after processing this batch is:  0.0027761906385421753\n",
      "\n",
      "The classification loss after processing this batch is:  0.11432281136512756\n",
      "The representation loss after processing this batch is:  0.0029928088188171387\n",
      "\n",
      "The classification loss after processing this batch is:  0.18073812127113342\n",
      "The representation loss after processing this batch is:  0.002915777266025543\n",
      "\n",
      "The classification loss after processing this batch is:  0.07740677148103714\n",
      "The representation loss after processing this batch is:  0.003030329942703247\n",
      "\n",
      "The classification loss after processing this batch is:  0.15591032803058624\n",
      "The representation loss after processing this batch is:  0.0024422258138656616\n",
      "\n",
      "The classification loss after processing this batch is:  0.1912796050310135\n",
      "The representation loss after processing this batch is:  0.0022749602794647217\n",
      "\n",
      "The classification loss after processing this batch is:  0.11455145478248596\n",
      "The representation loss after processing this batch is:  0.0024293437600135803\n",
      "\n",
      "The classification loss after processing this batch is:  0.12791530787944794\n",
      "The representation loss after processing this batch is:  0.0022479742765426636\n",
      "\n",
      "The classification loss after processing this batch is:  0.07160065323114395\n",
      "The representation loss after processing this batch is:  0.00292031466960907\n",
      "\n",
      "The classification loss after processing this batch is:  0.033281516283750534\n",
      "The representation loss after processing this batch is:  0.002589024603366852\n",
      "\n",
      "The classification loss after processing this batch is:  0.11892073601484299\n",
      "The representation loss after processing this batch is:  0.0027359500527381897\n",
      "\n",
      "The classification loss after processing this batch is:  0.06070934981107712\n",
      "The representation loss after processing this batch is:  0.0026431307196617126\n",
      "\n",
      "The classification loss after processing this batch is:  0.23774601519107819\n",
      "The representation loss after processing this batch is:  0.0023375600576400757\n",
      "\n",
      "The classification loss after processing this batch is:  0.045033276081085205\n",
      "The representation loss after processing this batch is:  0.002799607813358307\n",
      "\n",
      "The classification loss after processing this batch is:  0.10406792163848877\n",
      "The representation loss after processing this batch is:  0.0023410916328430176\n",
      "\n",
      "The classification loss after processing this batch is:  0.15286122262477875\n",
      "The representation loss after processing this batch is:  0.00250374898314476\n",
      "\n",
      "The classification loss after processing this batch is:  0.11725351959466934\n",
      "The representation loss after processing this batch is:  0.002348192036151886\n",
      "\n",
      "The classification loss after processing this batch is:  0.11241094768047333\n",
      "The representation loss after processing this batch is:  0.0026050955057144165\n",
      "\n",
      "The classification loss after processing this batch is:  0.054431233555078506\n",
      "The representation loss after processing this batch is:  0.0025541335344314575\n",
      "\n",
      "The classification loss after processing this batch is:  0.05820911377668381\n",
      "The representation loss after processing this batch is:  0.002361208200454712\n",
      "\n",
      "The classification loss after processing this batch is:  0.04907229170203209\n",
      "The representation loss after processing this batch is:  0.0024039335548877716\n",
      "\n",
      "The classification loss after processing this batch is:  0.1446727216243744\n",
      "The representation loss after processing this batch is:  0.0034468993544578552\n",
      "\n",
      "The classification loss after processing this batch is:  0.15894803404808044\n",
      "The representation loss after processing this batch is:  0.0027210600674152374\n",
      "\n",
      "The classification loss after processing this batch is:  0.1473950892686844\n",
      "The representation loss after processing this batch is:  0.0022045597434043884\n",
      "\n",
      "The classification loss after processing this batch is:  0.16692863404750824\n",
      "The representation loss after processing this batch is:  0.0023179687559604645\n",
      "\n",
      "The classification loss after processing this batch is:  0.27866214513778687\n",
      "The representation loss after processing this batch is:  0.0023481175303459167\n",
      "\n",
      "The classification loss after processing this batch is:  0.1007395014166832\n",
      "The representation loss after processing this batch is:  0.0028546154499053955\n",
      "\n",
      "The classification loss after processing this batch is:  0.19694161415100098\n",
      "The representation loss after processing this batch is:  0.0026241913437843323\n",
      "\n",
      "The classification loss after processing this batch is:  0.10499528795480728\n",
      "The representation loss after processing this batch is:  0.0025027692317962646\n",
      "\n",
      "The classification loss after processing this batch is:  0.08575168997049332\n",
      "The representation loss after processing this batch is:  0.0024685710668563843\n",
      "\n",
      "The classification loss after processing this batch is:  0.04941560700535774\n",
      "The representation loss after processing this batch is:  0.002308949828147888\n",
      "\n",
      "The classification loss after processing this batch is:  0.06240595877170563\n",
      "The representation loss after processing this batch is:  0.0025252923369407654\n",
      "\n",
      "The classification loss after processing this batch is:  0.21281595528125763\n",
      "The representation loss after processing this batch is:  0.0026104897260665894\n",
      "\n",
      "The classification loss after processing this batch is:  0.10242307931184769\n",
      "The representation loss after processing this batch is:  0.002628028392791748\n",
      "\n",
      "The classification loss after processing this batch is:  0.1122368574142456\n",
      "The representation loss after processing this batch is:  0.0028381571173667908\n",
      "\n",
      "The classification loss after processing this batch is:  0.09760868549346924\n",
      "The representation loss after processing this batch is:  0.0028592050075531006\n",
      "\n",
      "The classification loss after processing this batch is:  0.08728282153606415\n",
      "The representation loss after processing this batch is:  0.0026535242795944214\n",
      "\n",
      "The classification loss after processing this batch is:  0.06650910526514053\n",
      "The representation loss after processing this batch is:  0.002502724528312683\n",
      "\n",
      "The classification loss after processing this batch is:  0.15489187836647034\n",
      "The representation loss after processing this batch is:  0.0023633837699890137\n",
      "\n",
      "The classification loss after processing this batch is:  0.18648061156272888\n",
      "The representation loss after processing this batch is:  0.0023903101682662964\n",
      "\n",
      "The classification loss after processing this batch is:  0.17545749247074127\n",
      "The representation loss after processing this batch is:  0.002775922417640686\n",
      "\n",
      "The classification loss after processing this batch is:  0.10314517468214035\n",
      "The representation loss after processing this batch is:  0.002390451729297638\n",
      "\n",
      "The classification loss after processing this batch is:  0.2899438738822937\n",
      "The representation loss after processing this batch is:  0.00213579460978508\n",
      "\n",
      "The classification loss after processing this batch is:  0.0851927176117897\n",
      "The representation loss after processing this batch is:  0.002240978181362152\n",
      "\n",
      "The classification loss after processing this batch is:  0.1076119914650917\n",
      "The representation loss after processing this batch is:  0.002277769148349762\n",
      "\n",
      "The classification loss after processing this batch is:  0.1115150973200798\n",
      "The representation loss after processing this batch is:  0.002879023551940918\n",
      "\n",
      "The classification loss after processing this batch is:  0.07918551564216614\n",
      "The representation loss after processing this batch is:  0.0023621097207069397\n",
      "\n",
      "The classification loss after processing this batch is:  0.13728436827659607\n",
      "The representation loss after processing this batch is:  0.0025138407945632935\n",
      "\n",
      "The classification loss after processing this batch is:  0.07517901808023453\n",
      "The representation loss after processing this batch is:  0.0026766955852508545\n",
      "\n",
      "The classification loss after processing this batch is:  0.14720863103866577\n",
      "The representation loss after processing this batch is:  0.0025229305028915405\n",
      "\n",
      "The classification loss after processing this batch is:  0.18839584290981293\n",
      "The representation loss after processing this batch is:  0.0027559250593185425\n",
      "\n",
      "The classification loss after processing this batch is:  0.18120159208774567\n",
      "The representation loss after processing this batch is:  0.0026492252945899963\n",
      "\n",
      "The classification loss after processing this batch is:  0.11413734406232834\n",
      "The representation loss after processing this batch is:  0.0027876123785972595\n",
      "\n",
      "The classification loss after processing this batch is:  0.08615415543317795\n",
      "The representation loss after processing this batch is:  0.002872418612241745\n",
      "\n",
      "The classification loss after processing this batch is:  0.16082018613815308\n",
      "The representation loss after processing this batch is:  0.002381041646003723\n",
      "\n",
      "The classification loss after processing this batch is:  0.12450429052114487\n",
      "The representation loss after processing this batch is:  0.002419516444206238\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.02775021456182003\n",
      "The representation loss after processing this batch is:  0.0025392770767211914\n",
      "\n",
      "The classification loss after processing this batch is:  0.115827776491642\n",
      "The representation loss after processing this batch is:  0.0024299100041389465\n",
      "\n",
      "The classification loss after processing this batch is:  0.22025057673454285\n",
      "The representation loss after processing this batch is:  0.002726387232542038\n",
      "\n",
      "The classification loss after processing this batch is:  0.2644781768321991\n",
      "The representation loss after processing this batch is:  0.00275372713804245\n",
      "\n",
      "The classification loss after processing this batch is:  0.22608546912670135\n",
      "The representation loss after processing this batch is:  0.0024195238947868347\n",
      "\n",
      "The classification loss after processing this batch is:  0.1743190735578537\n",
      "The representation loss after processing this batch is:  0.002226606011390686\n",
      "\n",
      "The classification loss after processing this batch is:  0.07517566531896591\n",
      "The representation loss after processing this batch is:  0.0023559294641017914\n",
      "\n",
      "The classification loss after processing this batch is:  0.10514190047979355\n",
      "The representation loss after processing this batch is:  0.0023250579833984375\n",
      "\n",
      "The classification loss after processing this batch is:  0.10015352070331573\n",
      "The representation loss after processing this batch is:  0.0027744509279727936\n",
      "\n",
      "The classification loss after processing this batch is:  0.16130660474300385\n",
      "The representation loss after processing this batch is:  0.0028721094131469727\n",
      "\n",
      "The classification loss after processing this batch is:  0.11896197497844696\n",
      "The representation loss after processing this batch is:  0.002858877182006836\n",
      "\n",
      "The classification loss after processing this batch is:  0.1284848302602768\n",
      "The representation loss after processing this batch is:  0.0029243305325508118\n",
      "\n",
      "The classification loss after processing this batch is:  0.09339871257543564\n",
      "The representation loss after processing this batch is:  0.0025893598794937134\n",
      "\n",
      "The classification loss after processing this batch is:  0.06638980656862259\n",
      "The representation loss after processing this batch is:  0.0025301873683929443\n",
      "\n",
      "The classification loss after processing this batch is:  0.17872551083564758\n",
      "The representation loss after processing this batch is:  0.002759292721748352\n",
      "\n",
      "The classification loss after processing this batch is:  0.1417420655488968\n",
      "The representation loss after processing this batch is:  0.002409696578979492\n",
      "\n",
      "The classification loss after processing this batch is:  0.10502492636442184\n",
      "The representation loss after processing this batch is:  0.0025116056203842163\n",
      "\n",
      "The classification loss after processing this batch is:  0.22865301370620728\n",
      "The representation loss after processing this batch is:  0.003277856856584549\n",
      "\n",
      "The classification loss after processing this batch is:  0.2701406478881836\n",
      "The representation loss after processing this batch is:  0.002831108868122101\n",
      "\n",
      "The classification loss after processing this batch is:  0.1575731486082077\n",
      "The representation loss after processing this batch is:  0.002643376588821411\n",
      "\n",
      "The classification loss after processing this batch is:  0.08966260403394699\n",
      "The representation loss after processing this batch is:  0.002690345048904419\n",
      "\n",
      "The classification loss after processing this batch is:  0.11333628743886948\n",
      "The representation loss after processing this batch is:  0.002686142921447754\n",
      "\n",
      "The classification loss after processing this batch is:  0.05909140408039093\n",
      "The representation loss after processing this batch is:  0.0026994794607162476\n",
      "\n",
      "The classification loss after processing this batch is:  0.16658684611320496\n",
      "The representation loss after processing this batch is:  0.002747640013694763\n",
      "\n",
      "The classification loss after processing this batch is:  0.12985488772392273\n",
      "The representation loss after processing this batch is:  0.002838134765625\n",
      "\n",
      "The classification loss after processing this batch is:  0.10593870282173157\n",
      "The representation loss after processing this batch is:  0.002850376069545746\n",
      "\n",
      "The classification loss after processing this batch is:  0.24848909676074982\n",
      "The representation loss after processing this batch is:  0.002448640763759613\n",
      "\n",
      "The classification loss after processing this batch is:  0.05124581232666969\n",
      "The representation loss after processing this batch is:  0.0025369152426719666\n",
      "\n",
      "The classification loss after processing this batch is:  0.0610521174967289\n",
      "The representation loss after processing this batch is:  0.002864465117454529\n",
      "\n",
      "The classification loss after processing this batch is:  0.05585959926247597\n",
      "The representation loss after processing this batch is:  0.00233624130487442\n",
      "\n",
      "The classification loss after processing this batch is:  0.1545102745294571\n",
      "The representation loss after processing this batch is:  0.0024077855050563812\n",
      "\n",
      "The classification loss after processing this batch is:  0.19774731993675232\n",
      "The representation loss after processing this batch is:  0.0024852603673934937\n",
      "\n",
      "The classification loss after processing this batch is:  0.10909851640462875\n",
      "The representation loss after processing this batch is:  0.002284608781337738\n",
      "\n",
      "The classification loss after processing this batch is:  0.11005733162164688\n",
      "The representation loss after processing this batch is:  0.0025777891278266907\n",
      "\n",
      "The classification loss after processing this batch is:  0.04070204868912697\n",
      "The representation loss after processing this batch is:  0.0022748857736587524\n",
      "\n",
      "The classification loss after processing this batch is:  0.08484207838773727\n",
      "The representation loss after processing this batch is:  0.002355508506298065\n",
      "\n",
      "The classification loss after processing this batch is:  0.07197193056344986\n",
      "The representation loss after processing this batch is:  0.0026267245411872864\n",
      "\n",
      "The classification loss after processing this batch is:  0.04340599477291107\n",
      "The representation loss after processing this batch is:  0.0025780946016311646\n",
      "\n",
      "The classification loss after processing this batch is:  0.09597911685705185\n",
      "The representation loss after processing this batch is:  0.0024388469755649567\n",
      "\n",
      "The classification loss after processing this batch is:  0.1772259771823883\n",
      "The representation loss after processing this batch is:  0.0023775845766067505\n",
      "\n",
      "The classification loss after processing this batch is:  0.20742954313755035\n",
      "The representation loss after processing this batch is:  0.002503439784049988\n",
      "\n",
      "The classification loss after processing this batch is:  0.026230331510305405\n",
      "The representation loss after processing this batch is:  0.0022576376795768738\n",
      "\n",
      "The classification loss after processing this batch is:  0.044863637536764145\n",
      "The representation loss after processing this batch is:  0.0026279762387275696\n",
      "\n",
      "The classification loss after processing this batch is:  0.08095411956310272\n",
      "The representation loss after processing this batch is:  0.0027619600296020508\n",
      "\n",
      "The classification loss after processing this batch is:  0.1536213904619217\n",
      "The representation loss after processing this batch is:  0.002484619617462158\n",
      "\n",
      "The classification loss after processing this batch is:  0.06545041501522064\n",
      "The representation loss after processing this batch is:  0.0027718693017959595\n",
      "\n",
      "The classification loss after processing this batch is:  0.176993265748024\n",
      "The representation loss after processing this batch is:  0.0026803016662597656\n",
      "\n",
      "The classification loss after processing this batch is:  0.19956807792186737\n",
      "The representation loss after processing this batch is:  0.002770107239484787\n",
      "\n",
      "The classification loss after processing this batch is:  0.14268919825553894\n",
      "The representation loss after processing this batch is:  0.002743188291788101\n",
      "\n",
      "The classification loss after processing this batch is:  0.11757632344961166\n",
      "The representation loss after processing this batch is:  0.0027760975062847137\n",
      "\n",
      "The classification loss after processing this batch is:  0.05861811339855194\n",
      "The representation loss after processing this batch is:  0.0026425570249557495\n",
      "\n",
      "The classification loss after processing this batch is:  0.14364413917064667\n",
      "The representation loss after processing this batch is:  0.0022604092955589294\n",
      "\n",
      "The classification loss after processing this batch is:  0.13876059651374817\n",
      "The representation loss after processing this batch is:  0.0024540722370147705\n",
      "\n",
      "The classification loss after processing this batch is:  0.06529255211353302\n",
      "The representation loss after processing this batch is:  0.0025180503726005554\n",
      "\n",
      "The classification loss after processing this batch is:  0.045769426971673965\n",
      "The representation loss after processing this batch is:  0.0023603886365890503\n",
      "\n",
      "The classification loss after processing this batch is:  0.21556857228279114\n",
      "The representation loss after processing this batch is:  0.0024937987327575684\n",
      "\n",
      "The classification loss after processing this batch is:  0.20238898694515228\n",
      "The representation loss after processing this batch is:  0.0022843927145004272\n",
      "\n",
      "The classification loss after processing this batch is:  0.08470810949802399\n",
      "The representation loss after processing this batch is:  0.0024210400879383087\n",
      "\n",
      "The classification loss after processing this batch is:  0.2443883717060089\n",
      "The representation loss after processing this batch is:  0.0024408921599388123\n",
      "\n",
      "The classification loss after processing this batch is:  0.22860603034496307\n",
      "The representation loss after processing this batch is:  0.002550646662712097\n",
      "\n",
      "The classification loss after processing this batch is:  0.32048147916793823\n",
      "The representation loss after processing this batch is:  0.0023909062147140503\n",
      "\n",
      "The classification loss after processing this batch is:  0.12955763936042786\n",
      "The representation loss after processing this batch is:  0.002645067870616913\n",
      "\n",
      "The classification loss after processing this batch is:  0.09103969484567642\n",
      "The representation loss after processing this batch is:  0.0026862993836402893\n",
      "\n",
      "The classification loss after processing this batch is:  0.1566731035709381\n",
      "The representation loss after processing this batch is:  0.002665087580680847\n",
      "\n",
      "The classification loss after processing this batch is:  0.0751403346657753\n",
      "The representation loss after processing this batch is:  0.0025718659162521362\n",
      "\n",
      "The classification loss after processing this batch is:  0.0624021515250206\n",
      "The representation loss after processing this batch is:  0.0028028488159179688\n",
      "\n",
      "The classification loss after processing this batch is:  0.09433428198099136\n",
      "The representation loss after processing this batch is:  0.002264447510242462\n",
      "\n",
      "The classification loss after processing this batch is:  0.063239686191082\n",
      "The representation loss after processing this batch is:  0.0026036351919174194\n",
      "\n",
      "The classification loss after processing this batch is:  0.02439052239060402\n",
      "The representation loss after processing this batch is:  0.00288187712430954\n",
      "\n",
      "The classification loss after processing this batch is:  0.10665836930274963\n",
      "The representation loss after processing this batch is:  0.002513926476240158\n",
      "\n",
      "The classification loss after processing this batch is:  0.13671328127384186\n",
      "The representation loss after processing this batch is:  0.0023910775780677795\n",
      "\n",
      "The classification loss after processing this batch is:  0.07600563019514084\n",
      "The representation loss after processing this batch is:  0.0026030614972114563\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08694979548454285\n",
      "The representation loss after processing this batch is:  0.002402558922767639\n",
      "\n",
      "The classification loss after processing this batch is:  0.13912071287631989\n",
      "The representation loss after processing this batch is:  0.002513095736503601\n",
      "\n",
      "The classification loss after processing this batch is:  0.03661177679896355\n",
      "The representation loss after processing this batch is:  0.00245000422000885\n",
      "\n",
      "The classification loss after processing this batch is:  0.15686260163784027\n",
      "The representation loss after processing this batch is:  0.0026399269700050354\n",
      "\n",
      "The classification loss after processing this batch is:  0.08833198994398117\n",
      "The representation loss after processing this batch is:  0.002297930419445038\n",
      "\n",
      "The classification loss after processing this batch is:  0.2106734663248062\n",
      "The representation loss after processing this batch is:  0.0024959594011306763\n",
      "\n",
      "The classification loss after processing this batch is:  0.14648471772670746\n",
      "The representation loss after processing this batch is:  0.002383902668952942\n",
      "\n",
      "The classification loss after processing this batch is:  0.15215907990932465\n",
      "The representation loss after processing this batch is:  0.0022383742034435272\n",
      "\n",
      "The classification loss after processing this batch is:  0.034342121332883835\n",
      "The representation loss after processing this batch is:  0.0023458823561668396\n",
      "\n",
      "The classification loss after processing this batch is:  0.03871150687336922\n",
      "The representation loss after processing this batch is:  0.0024217143654823303\n",
      "\n",
      "The classification loss after processing this batch is:  0.14482857286930084\n",
      "The representation loss after processing this batch is:  0.0026198364794254303\n",
      "\n",
      "The classification loss after processing this batch is:  0.04609154537320137\n",
      "The representation loss after processing this batch is:  0.0026648640632629395\n",
      "\n",
      "The classification loss after processing this batch is:  0.12116198986768723\n",
      "The representation loss after processing this batch is:  0.0025852546095848083\n",
      "\n",
      "The classification loss after processing this batch is:  0.0769873782992363\n",
      "The representation loss after processing this batch is:  0.0027740299701690674\n",
      "\n",
      "The classification loss after processing this batch is:  0.07308170944452286\n",
      "The representation loss after processing this batch is:  0.0025950968265533447\n",
      "\n",
      "The classification loss after processing this batch is:  0.1125117689371109\n",
      "The representation loss after processing this batch is:  0.0025060325860977173\n",
      "\n",
      "The classification loss after processing this batch is:  0.06417059898376465\n",
      "The representation loss after processing this batch is:  0.002559751272201538\n",
      "\n",
      "The classification loss after processing this batch is:  0.07366892695426941\n",
      "The representation loss after processing this batch is:  0.003004513680934906\n",
      "\n",
      "The classification loss after processing this batch is:  0.1857852041721344\n",
      "The representation loss after processing this batch is:  0.0024532154202461243\n",
      "\n",
      "The classification loss after processing this batch is:  0.14792031049728394\n",
      "The representation loss after processing this batch is:  0.0027614906430244446\n",
      "\n",
      "The classification loss after processing this batch is:  0.18182392418384552\n",
      "The representation loss after processing this batch is:  0.002663061022758484\n",
      "\n",
      "The classification loss after processing this batch is:  0.19809108972549438\n",
      "The representation loss after processing this batch is:  0.002743631601333618\n",
      "\n",
      "The classification loss after processing this batch is:  0.11070641875267029\n",
      "The representation loss after processing this batch is:  0.0022568851709365845\n",
      "\n",
      "The classification loss after processing this batch is:  0.10287749767303467\n",
      "The representation loss after processing this batch is:  0.002322368323802948\n",
      "\n",
      "The classification loss after processing this batch is:  0.05871373414993286\n",
      "The representation loss after processing this batch is:  0.0023902207612991333\n",
      "\n",
      "The classification loss after processing this batch is:  0.06716019660234451\n",
      "The representation loss after processing this batch is:  0.0025085359811782837\n",
      "\n",
      "The classification loss after processing this batch is:  0.05434291809797287\n",
      "The representation loss after processing this batch is:  0.0025867819786071777\n",
      "\n",
      "The classification loss after processing this batch is:  0.10631751269102097\n",
      "The representation loss after processing this batch is:  0.002189911901950836\n",
      "\n",
      "The classification loss after processing this batch is:  0.0876246988773346\n",
      "The representation loss after processing this batch is:  0.002695702016353607\n",
      "\n",
      "The classification loss after processing this batch is:  0.12495186179876328\n",
      "The representation loss after processing this batch is:  0.002521306276321411\n",
      "\n",
      "The classification loss after processing this batch is:  0.06389608234167099\n",
      "The representation loss after processing this batch is:  0.002292647957801819\n",
      "\n",
      "The classification loss after processing this batch is:  0.1608988642692566\n",
      "The representation loss after processing this batch is:  0.002224758267402649\n",
      "\n",
      "The classification loss after processing this batch is:  0.07317913323640823\n",
      "The representation loss after processing this batch is:  0.0026279613375663757\n",
      "\n",
      "The classification loss after processing this batch is:  0.14997945725917816\n",
      "The representation loss after processing this batch is:  0.0023617297410964966\n",
      "\n",
      "The classification loss after processing this batch is:  0.138212651014328\n",
      "The representation loss after processing this batch is:  0.0025388002395629883\n",
      "\n",
      "The classification loss after processing this batch is:  0.11156266182661057\n",
      "The representation loss after processing this batch is:  0.0025900080800056458\n",
      "\n",
      "The classification loss after processing this batch is:  0.08954373002052307\n",
      "The representation loss after processing this batch is:  0.002568453550338745\n",
      "\n",
      "The classification loss after processing this batch is:  0.1731511652469635\n",
      "The representation loss after processing this batch is:  0.0025992020964622498\n",
      "\n",
      "The classification loss after processing this batch is:  0.08932898193597794\n",
      "The representation loss after processing this batch is:  0.0025032833218574524\n",
      "\n",
      "The classification loss after processing this batch is:  0.06878098845481873\n",
      "The representation loss after processing this batch is:  0.0023327916860580444\n",
      "\n",
      "The classification loss after processing this batch is:  0.07994593679904938\n",
      "The representation loss after processing this batch is:  0.0025317370891571045\n",
      "\n",
      "The classification loss after processing this batch is:  0.07607367634773254\n",
      "The representation loss after processing this batch is:  0.002409011125564575\n",
      "\n",
      "The classification loss after processing this batch is:  0.16564242541790009\n",
      "The representation loss after processing this batch is:  0.002351749688386917\n",
      "\n",
      "The classification loss after processing this batch is:  0.15926314890384674\n",
      "The representation loss after processing this batch is:  0.002664521336555481\n",
      "\n",
      "The classification loss after processing this batch is:  0.10189938545227051\n",
      "The representation loss after processing this batch is:  0.0029250606894493103\n",
      "\n",
      "The classification loss after processing this batch is:  0.07505607604980469\n",
      "The representation loss after processing this batch is:  0.0025944262742996216\n",
      "\n",
      "The classification loss after processing this batch is:  0.08198341727256775\n",
      "The representation loss after processing this batch is:  0.002791203558444977\n",
      "\n",
      "The classification loss after processing this batch is:  0.18756185472011566\n",
      "The representation loss after processing this batch is:  0.00265556201338768\n",
      "\n",
      "The classification loss after processing this batch is:  0.0546673908829689\n",
      "The representation loss after processing this batch is:  0.002476900815963745\n",
      "\n",
      "The classification loss after processing this batch is:  0.07988531142473221\n",
      "The representation loss after processing this batch is:  0.00289008766412735\n",
      "\n",
      "The classification loss after processing this batch is:  0.16656242311000824\n",
      "The representation loss after processing this batch is:  0.0022883154451847076\n",
      "\n",
      "The classification loss after processing this batch is:  0.29604142904281616\n",
      "The representation loss after processing this batch is:  0.0025194212794303894\n",
      "\n",
      "The classification loss after processing this batch is:  0.08283504098653793\n",
      "The representation loss after processing this batch is:  0.0024288445711135864\n",
      "\n",
      "The classification loss after processing this batch is:  0.11536871641874313\n",
      "The representation loss after processing this batch is:  0.0024279020726680756\n",
      "\n",
      "The classification loss after processing this batch is:  0.048494502902030945\n",
      "The representation loss after processing this batch is:  0.002527683973312378\n",
      "\n",
      "The classification loss after processing this batch is:  0.04000066965818405\n",
      "The representation loss after processing this batch is:  0.0022351518273353577\n",
      "\n",
      "The classification loss after processing this batch is:  0.10572150349617004\n",
      "The representation loss after processing this batch is:  0.0032075047492980957\n",
      "\n",
      "The classification loss after processing this batch is:  0.07985752075910568\n",
      "The representation loss after processing this batch is:  0.003273479640483856\n",
      "\n",
      "The classification loss after processing this batch is:  0.06113715469837189\n",
      "The representation loss after processing this batch is:  0.002534434199333191\n",
      "\n",
      "The classification loss after processing this batch is:  0.06195646896958351\n",
      "The representation loss after processing this batch is:  0.002316594123840332\n",
      "\n",
      "The classification loss after processing this batch is:  0.164801687002182\n",
      "The representation loss after processing this batch is:  0.002377878874540329\n",
      "\n",
      "The classification loss after processing this batch is:  0.12742964923381805\n",
      "The representation loss after processing this batch is:  0.002378024160861969\n",
      "\n",
      "The classification loss after processing this batch is:  0.0691538006067276\n",
      "The representation loss after processing this batch is:  0.0021406039595603943\n",
      "\n",
      "The classification loss after processing this batch is:  0.0724775567650795\n",
      "The representation loss after processing this batch is:  0.002446502447128296\n",
      "\n",
      "The classification loss after processing this batch is:  0.2183821052312851\n",
      "The representation loss after processing this batch is:  0.002366282045841217\n",
      "\n",
      "The classification loss after processing this batch is:  0.20416948199272156\n",
      "The representation loss after processing this batch is:  0.0026387497782707214\n",
      "\n",
      "The classification loss after processing this batch is:  0.16031616926193237\n",
      "The representation loss after processing this batch is:  0.002229783684015274\n",
      "\n",
      "The classification loss after processing this batch is:  0.1322205513715744\n",
      "The representation loss after processing this batch is:  0.002796858549118042\n",
      "\n",
      "The classification loss after processing this batch is:  0.16861169040203094\n",
      "The representation loss after processing this batch is:  0.002300489693880081\n",
      "\n",
      "The classification loss after processing this batch is:  0.08411422371864319\n",
      "The representation loss after processing this batch is:  0.0031056180596351624\n",
      "\n",
      "The classification loss after processing this batch is:  0.08569662272930145\n",
      "The representation loss after processing this batch is:  0.002796478569507599\n",
      "\n",
      "The classification loss after processing this batch is:  0.046961020678281784\n",
      "The representation loss after processing this batch is:  0.002653546631336212\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.0791168063879013\n",
      "The representation loss after processing this batch is:  0.0022829920053482056\n",
      "\n",
      "The classification loss after processing this batch is:  0.17385229468345642\n",
      "The representation loss after processing this batch is:  0.0024395324289798737\n",
      "\n",
      "The classification loss after processing this batch is:  0.07959451526403427\n",
      "The representation loss after processing this batch is:  0.0029642805457115173\n",
      "\n",
      "The classification loss after processing this batch is:  0.052223410457372665\n",
      "The representation loss after processing this batch is:  0.002477586269378662\n",
      "\n",
      "The classification loss after processing this batch is:  0.027625195682048798\n",
      "The representation loss after processing this batch is:  0.0031038224697113037\n",
      "\n",
      "The classification loss after processing this batch is:  0.03464977443218231\n",
      "The representation loss after processing this batch is:  0.0029081404209136963\n",
      "\n",
      "The classification loss after processing this batch is:  0.05486196279525757\n",
      "The representation loss after processing this batch is:  0.003123857080936432\n",
      "\n",
      "The classification loss after processing this batch is:  0.07259912043809891\n",
      "The representation loss after processing this batch is:  0.003078863024711609\n",
      "\n",
      "The classification loss after processing this batch is:  0.04627060890197754\n",
      "The representation loss after processing this batch is:  0.0025546252727508545\n",
      "\n",
      "The classification loss after processing this batch is:  0.022553181275725365\n",
      "The representation loss after processing this batch is:  0.002939864993095398\n",
      "\n",
      "The classification loss after processing this batch is:  0.03643155097961426\n",
      "The representation loss after processing this batch is:  0.003627106547355652\n",
      "\n",
      "The classification loss after processing this batch is:  0.08030672371387482\n",
      "The representation loss after processing this batch is:  0.0035332590341567993\n",
      "\n",
      "The classification loss after processing this batch is:  0.01408076286315918\n",
      "The representation loss after processing this batch is:  0.0035546720027923584\n",
      "\n",
      "The classification loss after processing this batch is:  0.03853241726756096\n",
      "The representation loss after processing this batch is:  0.0029840394854545593\n",
      "\n",
      "The classification loss after processing this batch is:  0.16247676312923431\n",
      "The representation loss after processing this batch is:  0.0028165504336357117\n",
      "\n",
      "The classification loss after processing this batch is:  0.027635494247078896\n",
      "The representation loss after processing this batch is:  0.0033516958355903625\n",
      "\n",
      "The classification loss after processing this batch is:  0.011727865785360336\n",
      "The representation loss after processing this batch is:  0.003092043101787567\n",
      "\n",
      "The classification loss after processing this batch is:  0.019617490470409393\n",
      "The representation loss after processing this batch is:  0.002742558717727661\n",
      "\n",
      "The classification loss after processing this batch is:  0.03149882331490517\n",
      "The representation loss after processing this batch is:  0.0031263604760169983\n",
      "\n",
      "The classification loss after processing this batch is:  0.025388173758983612\n",
      "The representation loss after processing this batch is:  0.0032978802919387817\n",
      "\n",
      "The classification loss after processing this batch is:  0.024412918835878372\n",
      "The representation loss after processing this batch is:  0.003119558095932007\n",
      "\n",
      "The classification loss after processing this batch is:  0.019889457151293755\n",
      "The representation loss after processing this batch is:  0.0032608062028884888\n",
      "\n",
      "The classification loss after processing this batch is:  0.16602304577827454\n",
      "The representation loss after processing this batch is:  0.003710046410560608\n",
      "\n",
      "The classification loss after processing this batch is:  0.27585700154304504\n",
      "The representation loss after processing this batch is:  0.0033972859382629395\n",
      "\n",
      "The classification loss after processing this batch is:  0.18229420483112335\n",
      "The representation loss after processing this batch is:  0.0036483556032180786\n",
      "\n",
      "The classification loss after processing this batch is:  0.047829799354076385\n",
      "The representation loss after processing this batch is:  0.002699807286262512\n",
      "\n",
      "The classification loss after processing this batch is:  0.017814453691244125\n",
      "The representation loss after processing this batch is:  0.003243282437324524\n",
      "\n",
      "The classification loss after processing this batch is:  0.02082187682390213\n",
      "The representation loss after processing this batch is:  0.00239747017621994\n",
      "\n",
      "The classification loss after processing this batch is:  0.1361110955476761\n",
      "The representation loss after processing this batch is:  0.0022516921162605286\n",
      "\n",
      "The classification loss after processing this batch is:  0.34506893157958984\n",
      "The representation loss after processing this batch is:  0.0029258951544761658\n",
      "\n",
      "The classification loss after processing this batch is:  0.05986390262842178\n",
      "The representation loss after processing this batch is:  0.0026212483644485474\n",
      "\n",
      "The classification loss after processing this batch is:  0.040101151913404465\n",
      "The representation loss after processing this batch is:  0.0032658427953720093\n",
      "\n",
      "The classification loss after processing this batch is:  0.0466429740190506\n",
      "The representation loss after processing this batch is:  0.0031739771366119385\n",
      "\n",
      "The classification loss after processing this batch is:  0.04324300214648247\n",
      "The representation loss after processing this batch is:  0.0036192983388900757\n",
      "\n",
      "The classification loss after processing this batch is:  0.09598572552204132\n",
      "The representation loss after processing this batch is:  0.0024337321519851685\n",
      "\n",
      "The classification loss after processing this batch is:  0.0437655933201313\n",
      "The representation loss after processing this batch is:  0.002366110682487488\n",
      "\n",
      "The classification loss after processing this batch is:  0.0713161900639534\n",
      "The representation loss after processing this batch is:  0.0024711862206459045\n",
      "\n",
      "The classification loss after processing this batch is:  0.10198773443698883\n",
      "The representation loss after processing this batch is:  0.0022871680557727814\n",
      "\n",
      "The classification loss after processing this batch is:  0.10790783911943436\n",
      "The representation loss after processing this batch is:  0.002719573676586151\n",
      "\n",
      "The classification loss after processing this batch is:  0.0673423781991005\n",
      "The representation loss after processing this batch is:  0.0028383657336235046\n",
      "\n",
      "The classification loss after processing this batch is:  0.07702042162418365\n",
      "The representation loss after processing this batch is:  0.0027099326252937317\n",
      "\n",
      "The classification loss after processing this batch is:  0.10295186191797256\n",
      "The representation loss after processing this batch is:  0.002319682389497757\n",
      "\n",
      "The classification loss after processing this batch is:  0.10806665569543839\n",
      "The representation loss after processing this batch is:  0.0023106783628463745\n",
      "\n",
      "The classification loss after processing this batch is:  0.0748295709490776\n",
      "The representation loss after processing this batch is:  0.002473078668117523\n",
      "\n",
      "The classification loss after processing this batch is:  0.13986539840698242\n",
      "The representation loss after processing this batch is:  0.0022630728781223297\n",
      "\n",
      "The classification loss after processing this batch is:  0.14050433039665222\n",
      "The representation loss after processing this batch is:  0.0024348199367523193\n",
      "\n",
      "The classification loss after processing this batch is:  0.13890758156776428\n",
      "The representation loss after processing this batch is:  0.0031131505966186523\n",
      "\n",
      "The classification loss after processing this batch is:  0.06130928173661232\n",
      "The representation loss after processing this batch is:  0.002409733831882477\n",
      "\n",
      "The classification loss after processing this batch is:  0.2481808364391327\n",
      "The representation loss after processing this batch is:  0.0023304522037506104\n",
      "\n",
      "The classification loss after processing this batch is:  0.13672000169754028\n",
      "The representation loss after processing this batch is:  0.0022265948355197906\n",
      "\n",
      "The classification loss after processing this batch is:  0.10729993134737015\n",
      "The representation loss after processing this batch is:  0.0022578760981559753\n",
      "\n",
      "The classification loss after processing this batch is:  0.21217094361782074\n",
      "The representation loss after processing this batch is:  0.0025627799332141876\n",
      "\n",
      "The classification loss after processing this batch is:  0.13212576508522034\n",
      "The representation loss after processing this batch is:  0.002666763961315155\n",
      "\n",
      "The classification loss after processing this batch is:  0.044855691492557526\n",
      "The representation loss after processing this batch is:  0.0025373250246047974\n",
      "\n",
      "The classification loss after processing this batch is:  0.19776372611522675\n",
      "The representation loss after processing this batch is:  0.002776503562927246\n",
      "\n",
      "The classification loss after processing this batch is:  0.1185922622680664\n",
      "The representation loss after processing this batch is:  0.0026343315839767456\n",
      "\n",
      "The classification loss after processing this batch is:  0.2536981701850891\n",
      "The representation loss after processing this batch is:  0.0022940561175346375\n",
      "\n",
      "The classification loss after processing this batch is:  0.07533871382474899\n",
      "The representation loss after processing this batch is:  0.002297632396221161\n",
      "\n",
      "The classification loss after processing this batch is:  0.05504657328128815\n",
      "The representation loss after processing this batch is:  0.002451278269290924\n",
      "\n",
      "The classification loss after processing this batch is:  0.07980469614267349\n",
      "The representation loss after processing this batch is:  0.0023747794330120087\n",
      "\n",
      "The classification loss after processing this batch is:  0.06915919482707977\n",
      "The representation loss after processing this batch is:  0.0021105147898197174\n",
      "\n",
      "The classification loss after processing this batch is:  0.08720624446868896\n",
      "The representation loss after processing this batch is:  0.002395372837781906\n",
      "\n",
      "The classification loss after processing this batch is:  0.04336995631456375\n",
      "The representation loss after processing this batch is:  0.002602607011795044\n",
      "\n",
      "The classification loss after processing this batch is:  0.037352047860622406\n",
      "The representation loss after processing this batch is:  0.002610631287097931\n",
      "\n",
      "The classification loss after processing this batch is:  0.06548594683408737\n",
      "The representation loss after processing this batch is:  0.002575129270553589\n",
      "\n",
      "The classification loss after processing this batch is:  0.05985311046242714\n",
      "The representation loss after processing this batch is:  0.00283200666308403\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14408622682094574\n",
      "The representation loss after processing this batch is:  0.002408605068922043\n",
      "\n",
      "The classification loss after processing this batch is:  0.06370007246732712\n",
      "The representation loss after processing this batch is:  0.002819657325744629\n",
      "\n",
      "The classification loss after processing this batch is:  0.08950839191675186\n",
      "The representation loss after processing this batch is:  0.0022597089409828186\n",
      "\n",
      "The classification loss after processing this batch is:  0.036354418843984604\n",
      "The representation loss after processing this batch is:  0.0024959146976470947\n",
      "\n",
      "The classification loss after processing this batch is:  0.05185015872120857\n",
      "The representation loss after processing this batch is:  0.0027707554399967194\n",
      "\n",
      "The classification loss after processing this batch is:  0.08015785366296768\n",
      "The representation loss after processing this batch is:  0.0023418068885803223\n",
      "\n",
      "The classification loss after processing this batch is:  0.07520309835672379\n",
      "The representation loss after processing this batch is:  0.002736121416091919\n",
      "\n",
      "The classification loss after processing this batch is:  0.06277267634868622\n",
      "The representation loss after processing this batch is:  0.0025269612669944763\n",
      "\n",
      "The classification loss after processing this batch is:  0.16234304010868073\n",
      "The representation loss after processing this batch is:  0.002688951790332794\n",
      "\n",
      "The classification loss after processing this batch is:  0.08460990339517593\n",
      "The representation loss after processing this batch is:  0.0024617835879325867\n",
      "\n",
      "The classification loss after processing this batch is:  0.06931421160697937\n",
      "The representation loss after processing this batch is:  0.002400338649749756\n",
      "\n",
      "The classification loss after processing this batch is:  0.13043218851089478\n",
      "The representation loss after processing this batch is:  0.002637900412082672\n",
      "\n",
      "The classification loss after processing this batch is:  0.053381867706775665\n",
      "The representation loss after processing this batch is:  0.002317652106285095\n",
      "\n",
      "The classification loss after processing this batch is:  0.0733947902917862\n",
      "The representation loss after processing this batch is:  0.0022517815232276917\n",
      "\n",
      "The classification loss after processing this batch is:  0.18652933835983276\n",
      "The representation loss after processing this batch is:  0.0027941055595874786\n",
      "\n",
      "The classification loss after processing this batch is:  0.0412551686167717\n",
      "The representation loss after processing this batch is:  0.002436242997646332\n",
      "\n",
      "The classification loss after processing this batch is:  0.11586116999387741\n",
      "The representation loss after processing this batch is:  0.0023752525448799133\n",
      "\n",
      "The classification loss after processing this batch is:  0.08425519615411758\n",
      "The representation loss after processing this batch is:  0.002474457025527954\n",
      "\n",
      "The classification loss after processing this batch is:  0.08316721767187119\n",
      "The representation loss after processing this batch is:  0.002294640988111496\n",
      "\n",
      "The classification loss after processing this batch is:  0.08782695978879929\n",
      "The representation loss after processing this batch is:  0.002330247312784195\n",
      "\n",
      "The classification loss after processing this batch is:  0.05252940580248833\n",
      "The representation loss after processing this batch is:  0.0025529228150844574\n",
      "\n",
      "The classification loss after processing this batch is:  0.1383860558271408\n",
      "The representation loss after processing this batch is:  0.002766825258731842\n",
      "\n",
      "The classification loss after processing this batch is:  0.1074734777212143\n",
      "The representation loss after processing this batch is:  0.002715006470680237\n",
      "\n",
      "The classification loss after processing this batch is:  0.11628709733486176\n",
      "The representation loss after processing this batch is:  0.002598978579044342\n",
      "\n",
      "The classification loss after processing this batch is:  0.11895844340324402\n",
      "The representation loss after processing this batch is:  0.0022852346301078796\n",
      "\n",
      "The classification loss after processing this batch is:  0.11791010946035385\n",
      "The representation loss after processing this batch is:  0.0025443509221076965\n",
      "\n",
      "The classification loss after processing this batch is:  0.10813195258378983\n",
      "The representation loss after processing this batch is:  0.002377353608608246\n",
      "\n",
      "The classification loss after processing this batch is:  0.0775994136929512\n",
      "The representation loss after processing this batch is:  0.002330407500267029\n",
      "\n",
      "The classification loss after processing this batch is:  0.07065105438232422\n",
      "The representation loss after processing this batch is:  0.0022623538970947266\n",
      "\n",
      "The classification loss after processing this batch is:  0.169621080160141\n",
      "The representation loss after processing this batch is:  0.0024905428290367126\n",
      "\n",
      "The classification loss after processing this batch is:  0.13919654488563538\n",
      "The representation loss after processing this batch is:  0.0024602413177490234\n",
      "\n",
      "The classification loss after processing this batch is:  0.07000713795423508\n",
      "The representation loss after processing this batch is:  0.002365715801715851\n",
      "\n",
      "The classification loss after processing this batch is:  0.06650577485561371\n",
      "The representation loss after processing this batch is:  0.0023589059710502625\n",
      "\n",
      "The classification loss after processing this batch is:  0.06290452927350998\n",
      "The representation loss after processing this batch is:  0.0023294053971767426\n",
      "\n",
      "The classification loss after processing this batch is:  0.07008259743452072\n",
      "The representation loss after processing this batch is:  0.0027304664254188538\n",
      "\n",
      "The classification loss after processing this batch is:  0.13507603108882904\n",
      "The representation loss after processing this batch is:  0.0021886229515075684\n",
      "\n",
      "The classification loss after processing this batch is:  0.06161046028137207\n",
      "The representation loss after processing this batch is:  0.0023073703050613403\n",
      "\n",
      "The classification loss after processing this batch is:  0.18743892014026642\n",
      "The representation loss after processing this batch is:  0.0023014694452285767\n",
      "\n",
      "The classification loss after processing this batch is:  0.13052614033222198\n",
      "The representation loss after processing this batch is:  0.0023200437426567078\n",
      "\n",
      "The classification loss after processing this batch is:  0.1163984164595604\n",
      "The representation loss after processing this batch is:  0.002351626753807068\n",
      "\n",
      "The classification loss after processing this batch is:  0.06691303849220276\n",
      "The representation loss after processing this batch is:  0.002115938812494278\n",
      "\n",
      "The classification loss after processing this batch is:  0.058014173060655594\n",
      "The representation loss after processing this batch is:  0.002499699592590332\n",
      "\n",
      "The classification loss after processing this batch is:  0.08755277842283249\n",
      "The representation loss after processing this batch is:  0.002217419445514679\n",
      "\n",
      "The classification loss after processing this batch is:  0.15899087488651276\n",
      "The representation loss after processing this batch is:  0.002208516001701355\n",
      "\n",
      "The classification loss after processing this batch is:  0.0814518854022026\n",
      "The representation loss after processing this batch is:  0.0022963285446166992\n",
      "\n",
      "The classification loss after processing this batch is:  0.2669893205165863\n",
      "The representation loss after processing this batch is:  0.0023091062903404236\n",
      "\n",
      "The classification loss after processing this batch is:  0.09854706376791\n",
      "The representation loss after processing this batch is:  0.0021528825163841248\n",
      "\n",
      "The classification loss after processing this batch is:  0.05693621560931206\n",
      "The representation loss after processing this batch is:  0.0029890015721321106\n",
      "\n",
      "The classification loss after processing this batch is:  0.15509256720542908\n",
      "The representation loss after processing this batch is:  0.0026578083634376526\n",
      "\n",
      "The classification loss after processing this batch is:  0.0573032908141613\n",
      "The representation loss after processing this batch is:  0.002791665494441986\n",
      "\n",
      "The classification loss after processing this batch is:  0.24245324730873108\n",
      "The representation loss after processing this batch is:  0.002693943679332733\n",
      "\n",
      "The classification loss after processing this batch is:  0.11132202297449112\n",
      "The representation loss after processing this batch is:  0.002246484160423279\n",
      "\n",
      "The classification loss after processing this batch is:  0.1740969568490982\n",
      "The representation loss after processing this batch is:  0.002397749572992325\n",
      "\n",
      "The classification loss after processing this batch is:  0.22004948556423187\n",
      "The representation loss after processing this batch is:  0.0024951137602329254\n",
      "\n",
      "The classification loss after processing this batch is:  0.13096033036708832\n",
      "The representation loss after processing this batch is:  0.00224091112613678\n",
      "\n",
      "The classification loss after processing this batch is:  0.05501379072666168\n",
      "The representation loss after processing this batch is:  0.002482384443283081\n",
      "\n",
      "The classification loss after processing this batch is:  0.13807502388954163\n",
      "The representation loss after processing this batch is:  0.002343788743019104\n",
      "\n",
      "The classification loss after processing this batch is:  0.11014287173748016\n",
      "The representation loss after processing this batch is:  0.002549387514591217\n",
      "\n",
      "The classification loss after processing this batch is:  0.11369851976633072\n",
      "The representation loss after processing this batch is:  0.002397194504737854\n",
      "\n",
      "The classification loss after processing this batch is:  0.06710740923881531\n",
      "The representation loss after processing this batch is:  0.0022457465529441833\n",
      "\n",
      "The classification loss after processing this batch is:  0.08720921725034714\n",
      "The representation loss after processing this batch is:  0.002348475158214569\n",
      "\n",
      "The classification loss after processing this batch is:  0.15590159595012665\n",
      "The representation loss after processing this batch is:  0.002392895519733429\n",
      "\n",
      "The classification loss after processing this batch is:  0.13851317763328552\n",
      "The representation loss after processing this batch is:  0.002783864736557007\n",
      "\n",
      "The classification loss after processing this batch is:  0.1610364019870758\n",
      "The representation loss after processing this batch is:  0.002349007874727249\n",
      "\n",
      "The classification loss after processing this batch is:  0.2216917723417282\n",
      "The representation loss after processing this batch is:  0.0025755465030670166\n",
      "\n",
      "The classification loss after processing this batch is:  0.13880003988742828\n",
      "The representation loss after processing this batch is:  0.002701081335544586\n",
      "\n",
      "The classification loss after processing this batch is:  0.06540997326374054\n",
      "The representation loss after processing this batch is:  0.002676732838153839\n",
      "\n",
      "The classification loss after processing this batch is:  0.06756556779146194\n",
      "The representation loss after processing this batch is:  0.0023875832557678223\n",
      "\n",
      "The classification loss after processing this batch is:  0.038931865245103836\n",
      "The representation loss after processing this batch is:  0.0024779215455055237\n",
      "\n",
      "The classification loss after processing this batch is:  0.12090083211660385\n",
      "The representation loss after processing this batch is:  0.002601146697998047\n",
      "\n",
      "The classification loss after processing this batch is:  0.09419631958007812\n",
      "The representation loss after processing this batch is:  0.0024939924478530884\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2454151213169098\n",
      "The representation loss after processing this batch is:  0.00261620432138443\n",
      "\n",
      "The classification loss after processing this batch is:  0.245985209941864\n",
      "The representation loss after processing this batch is:  0.002436131238937378\n",
      "\n",
      "The classification loss after processing this batch is:  0.08190441876649857\n",
      "The representation loss after processing this batch is:  0.0026681050658226013\n",
      "\n",
      "The classification loss after processing this batch is:  0.10407961159944534\n",
      "The representation loss after processing this batch is:  0.0026866719126701355\n",
      "\n",
      "The classification loss after processing this batch is:  0.13601723313331604\n",
      "The representation loss after processing this batch is:  0.0022482238709926605\n",
      "\n",
      "The classification loss after processing this batch is:  0.04941628873348236\n",
      "The representation loss after processing this batch is:  0.0025667771697044373\n",
      "\n",
      "The classification loss after processing this batch is:  0.052641674876213074\n",
      "The representation loss after processing this batch is:  0.0026424601674079895\n",
      "\n",
      "The classification loss after processing this batch is:  0.11151143163442612\n",
      "The representation loss after processing this batch is:  0.002263367176055908\n",
      "\n",
      "The classification loss after processing this batch is:  0.06959784775972366\n",
      "The representation loss after processing this batch is:  0.0030626878142356873\n",
      "\n",
      "The classification loss after processing this batch is:  0.08927810192108154\n",
      "The representation loss after processing this batch is:  0.0028029195964336395\n",
      "\n",
      "The classification loss after processing this batch is:  0.21939483284950256\n",
      "The representation loss after processing this batch is:  0.0033634528517723083\n",
      "\n",
      "The classification loss after processing this batch is:  0.22329814732074738\n",
      "The representation loss after processing this batch is:  0.0021856464445590973\n",
      "\n",
      "The classification loss after processing this batch is:  0.09687327593564987\n",
      "The representation loss after processing this batch is:  0.002778187394142151\n",
      "\n",
      "The classification loss after processing this batch is:  0.17677472531795502\n",
      "The representation loss after processing this batch is:  0.002571791410446167\n",
      "\n",
      "The classification loss after processing this batch is:  0.17818595468997955\n",
      "The representation loss after processing this batch is:  0.0023481175303459167\n",
      "\n",
      "The classification loss after processing this batch is:  0.06348032504320145\n",
      "The representation loss after processing this batch is:  0.0024592839181423187\n",
      "\n",
      "The classification loss after processing this batch is:  0.12088241428136826\n",
      "The representation loss after processing this batch is:  0.002294350415468216\n",
      "\n",
      "The classification loss after processing this batch is:  0.37032127380371094\n",
      "The representation loss after processing this batch is:  0.0029605552554130554\n",
      "\n",
      "The classification loss after processing this batch is:  0.14278827607631683\n",
      "The representation loss after processing this batch is:  0.002726607024669647\n",
      "\n",
      "The classification loss after processing this batch is:  0.05185028165578842\n",
      "The representation loss after processing this batch is:  0.0028587952256202698\n",
      "\n",
      "The classification loss after processing this batch is:  0.058649469166994095\n",
      "The representation loss after processing this batch is:  0.0028437189757823944\n",
      "\n",
      "The classification loss after processing this batch is:  0.05316297337412834\n",
      "The representation loss after processing this batch is:  0.0029046908020973206\n",
      "\n",
      "The classification loss after processing this batch is:  0.08626411110162735\n",
      "The representation loss after processing this batch is:  0.002679981291294098\n",
      "\n",
      "The classification loss after processing this batch is:  0.062404196709394455\n",
      "The representation loss after processing this batch is:  0.00278685986995697\n",
      "\n",
      "The classification loss after processing this batch is:  0.11980607360601425\n",
      "The representation loss after processing this batch is:  0.0023295320570468903\n",
      "\n",
      "The classification loss after processing this batch is:  0.09272079914808273\n",
      "The representation loss after processing this batch is:  0.00240112841129303\n",
      "\n",
      "The classification loss after processing this batch is:  0.1729111522436142\n",
      "The representation loss after processing this batch is:  0.002282552421092987\n",
      "\n",
      "The classification loss after processing this batch is:  0.07883954793214798\n",
      "The representation loss after processing this batch is:  0.0021808966994285583\n",
      "\n",
      "The classification loss after processing this batch is:  0.09515024721622467\n",
      "The representation loss after processing this batch is:  0.0024099834263324738\n",
      "\n",
      "The classification loss after processing this batch is:  0.1302555352449417\n",
      "The representation loss after processing this batch is:  0.002384774386882782\n",
      "\n",
      "The classification loss after processing this batch is:  0.11967775970697403\n",
      "The representation loss after processing this batch is:  0.00249369814991951\n",
      "\n",
      "The classification loss after processing this batch is:  0.06310494989156723\n",
      "The representation loss after processing this batch is:  0.002272374927997589\n",
      "\n",
      "The classification loss after processing this batch is:  0.15633393824100494\n",
      "The representation loss after processing this batch is:  0.002337843179702759\n",
      "\n",
      "The classification loss after processing this batch is:  0.16719016432762146\n",
      "The representation loss after processing this batch is:  0.0024291500449180603\n",
      "\n",
      "The classification loss after processing this batch is:  0.1251545399427414\n",
      "The representation loss after processing this batch is:  0.002250608056783676\n",
      "\n",
      "The classification loss after processing this batch is:  0.11379249393939972\n",
      "The representation loss after processing this batch is:  0.0026650577783584595\n",
      "\n",
      "The classification loss after processing this batch is:  0.17322960495948792\n",
      "The representation loss after processing this batch is:  0.0025760680437088013\n",
      "\n",
      "The classification loss after processing this batch is:  0.1912097930908203\n",
      "The representation loss after processing this batch is:  0.0027517974376678467\n",
      "\n",
      "The classification loss after processing this batch is:  0.1418001651763916\n",
      "The representation loss after processing this batch is:  0.00269993394613266\n",
      "\n",
      "The classification loss after processing this batch is:  0.08500850945711136\n",
      "The representation loss after processing this batch is:  0.0028278902173042297\n",
      "\n",
      "The classification loss after processing this batch is:  0.07799924165010452\n",
      "The representation loss after processing this batch is:  0.0028485730290412903\n",
      "\n",
      "The classification loss after processing this batch is:  0.2164575308561325\n",
      "The representation loss after processing this batch is:  0.0023651793599128723\n",
      "\n",
      "The classification loss after processing this batch is:  0.16390326619148254\n",
      "The representation loss after processing this batch is:  0.0022960230708122253\n",
      "\n",
      "The classification loss after processing this batch is:  0.2552605867385864\n",
      "The representation loss after processing this batch is:  0.0025813132524490356\n",
      "\n",
      "The classification loss after processing this batch is:  0.2671465277671814\n",
      "The representation loss after processing this batch is:  0.0022590532898902893\n",
      "\n",
      "The classification loss after processing this batch is:  0.15816931426525116\n",
      "The representation loss after processing this batch is:  0.0023035928606987\n",
      "\n",
      "The classification loss after processing this batch is:  0.08351429551839828\n",
      "The representation loss after processing this batch is:  0.002340741455554962\n",
      "\n",
      "The classification loss after processing this batch is:  0.06807518005371094\n",
      "The representation loss after processing this batch is:  0.0023156926035881042\n",
      "\n",
      "The classification loss after processing this batch is:  0.049568552523851395\n",
      "The representation loss after processing this batch is:  0.0027848705649375916\n",
      "\n",
      "The classification loss after processing this batch is:  0.10389862954616547\n",
      "The representation loss after processing this batch is:  0.003011442720890045\n",
      "\n",
      "The classification loss after processing this batch is:  0.05562249571084976\n",
      "The representation loss after processing this batch is:  0.00256434828042984\n",
      "\n",
      "The classification loss after processing this batch is:  0.18309135735034943\n",
      "The representation loss after processing this batch is:  0.003496326506137848\n",
      "\n",
      "The classification loss after processing this batch is:  0.10241774469614029\n",
      "The representation loss after processing this batch is:  0.0025484226644039154\n",
      "\n",
      "The classification loss after processing this batch is:  0.08282411098480225\n",
      "The representation loss after processing this batch is:  0.002622690051794052\n",
      "\n",
      "The classification loss after processing this batch is:  0.17608366906642914\n",
      "The representation loss after processing this batch is:  0.0023708492517471313\n",
      "\n",
      "The classification loss after processing this batch is:  0.07851117104291916\n",
      "The representation loss after processing this batch is:  0.002693530172109604\n",
      "\n",
      "The classification loss after processing this batch is:  0.09232281893491745\n",
      "The representation loss after processing this batch is:  0.0032791420817375183\n",
      "\n",
      "The classification loss after processing this batch is:  0.24046500027179718\n",
      "The representation loss after processing this batch is:  0.0032968297600746155\n",
      "\n",
      "The classification loss after processing this batch is:  0.11704880744218826\n",
      "The representation loss after processing this batch is:  0.002751551568508148\n",
      "\n",
      "The classification loss after processing this batch is:  0.12531785666942596\n",
      "The representation loss after processing this batch is:  0.002395179122686386\n",
      "\n",
      "The classification loss after processing this batch is:  0.05702528730034828\n",
      "The representation loss after processing this batch is:  0.002284891903400421\n",
      "\n",
      "The classification loss after processing this batch is:  0.029576105996966362\n",
      "The representation loss after processing this batch is:  0.002760268747806549\n",
      "\n",
      "The classification loss after processing this batch is:  0.05668133497238159\n",
      "The representation loss after processing this batch is:  0.0028317421674728394\n",
      "\n",
      "The classification loss after processing this batch is:  0.05654045194387436\n",
      "The representation loss after processing this batch is:  0.00253111869096756\n",
      "\n",
      "The classification loss after processing this batch is:  0.09677683562040329\n",
      "The representation loss after processing this batch is:  0.0022329911589622498\n",
      "\n",
      "The classification loss after processing this batch is:  0.08671855926513672\n",
      "The representation loss after processing this batch is:  0.002719081938266754\n",
      "\n",
      "The classification loss after processing this batch is:  0.11007622629404068\n",
      "The representation loss after processing this batch is:  0.0026288628578186035\n",
      "\n",
      "The classification loss after processing this batch is:  0.2958693504333496\n",
      "The representation loss after processing this batch is:  0.0027957484126091003\n",
      "\n",
      "The classification loss after processing this batch is:  0.21428315341472626\n",
      "The representation loss after processing this batch is:  0.0025935620069503784\n",
      "\n",
      "The classification loss after processing this batch is:  0.0886402353644371\n",
      "The representation loss after processing this batch is:  0.0024118050932884216\n",
      "\n",
      "The classification loss after processing this batch is:  0.05982606112957001\n",
      "The representation loss after processing this batch is:  0.002762623131275177\n",
      "\n",
      "The classification loss after processing this batch is:  0.08724011480808258\n",
      "The representation loss after processing this batch is:  0.0025739967823028564\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08007009327411652\n",
      "The representation loss after processing this batch is:  0.0025202110409736633\n",
      "\n",
      "The classification loss after processing this batch is:  0.031987763941287994\n",
      "The representation loss after processing this batch is:  0.0024177655577659607\n",
      "\n",
      "The classification loss after processing this batch is:  0.04477660357952118\n",
      "The representation loss after processing this batch is:  0.0026157647371292114\n",
      "\n",
      "The classification loss after processing this batch is:  0.0846661627292633\n",
      "The representation loss after processing this batch is:  0.0021411925554275513\n",
      "\n",
      "The classification loss after processing this batch is:  0.11486224085092545\n",
      "The representation loss after processing this batch is:  0.002327665686607361\n",
      "\n",
      "The classification loss after processing this batch is:  0.07860999554395676\n",
      "The representation loss after processing this batch is:  0.002678096294403076\n",
      "\n",
      "The classification loss after processing this batch is:  0.06227074936032295\n",
      "The representation loss after processing this batch is:  0.0025063008069992065\n",
      "\n",
      "The classification loss after processing this batch is:  0.05438404157757759\n",
      "The representation loss after processing this batch is:  0.0023352839052677155\n",
      "\n",
      "The classification loss after processing this batch is:  0.25186440348625183\n",
      "The representation loss after processing this batch is:  0.0022924914956092834\n",
      "\n",
      "The classification loss after processing this batch is:  0.09800489246845245\n",
      "The representation loss after processing this batch is:  0.0026474595069885254\n",
      "\n",
      "The classification loss after processing this batch is:  0.04940132424235344\n",
      "The representation loss after processing this batch is:  0.002579718828201294\n",
      "\n",
      "The classification loss after processing this batch is:  0.10814713686704636\n",
      "The representation loss after processing this batch is:  0.002584800124168396\n",
      "\n",
      "The classification loss after processing this batch is:  0.0907081812620163\n",
      "The representation loss after processing this batch is:  0.002316270023584366\n",
      "\n",
      "The classification loss after processing this batch is:  0.05054107680916786\n",
      "The representation loss after processing this batch is:  0.0022528991103172302\n",
      "\n",
      "The classification loss after processing this batch is:  0.12213287502527237\n",
      "The representation loss after processing this batch is:  0.002442099153995514\n",
      "\n",
      "The classification loss after processing this batch is:  0.05388319492340088\n",
      "The representation loss after processing this batch is:  0.0023383647203445435\n",
      "\n",
      "The classification loss after processing this batch is:  0.05908204987645149\n",
      "The representation loss after processing this batch is:  0.002623617649078369\n",
      "\n",
      "The classification loss after processing this batch is:  0.10085465013980865\n",
      "The representation loss after processing this batch is:  0.0020500943064689636\n",
      "\n",
      "The classification loss after processing this batch is:  0.15501099824905396\n",
      "The representation loss after processing this batch is:  0.0025410130620002747\n",
      "\n",
      "The classification loss after processing this batch is:  0.11704353988170624\n",
      "The representation loss after processing this batch is:  0.0025234073400497437\n",
      "\n",
      "The classification loss after processing this batch is:  0.1362379491329193\n",
      "The representation loss after processing this batch is:  0.002343393862247467\n",
      "\n",
      "The classification loss after processing this batch is:  0.10322396457195282\n",
      "The representation loss after processing this batch is:  0.0023979805409908295\n",
      "\n",
      "The classification loss after processing this batch is:  0.16570799052715302\n",
      "The representation loss after processing this batch is:  0.002413615584373474\n",
      "\n",
      "The classification loss after processing this batch is:  0.07241539657115936\n",
      "The representation loss after processing this batch is:  0.002512611448764801\n",
      "\n",
      "The classification loss after processing this batch is:  0.1199880912899971\n",
      "The representation loss after processing this batch is:  0.0023983418941497803\n",
      "\n",
      "The classification loss after processing this batch is:  0.0642257109284401\n",
      "The representation loss after processing this batch is:  0.0023457184433937073\n",
      "\n",
      "The classification loss after processing this batch is:  0.17582887411117554\n",
      "The representation loss after processing this batch is:  0.002362556755542755\n",
      "\n",
      "The classification loss after processing this batch is:  0.09754662215709686\n",
      "The representation loss after processing this batch is:  0.002648457884788513\n",
      "\n",
      "The classification loss after processing this batch is:  0.1529579907655716\n",
      "The representation loss after processing this batch is:  0.0023677200078964233\n",
      "\n",
      "The classification loss after processing this batch is:  0.09912088513374329\n",
      "The representation loss after processing this batch is:  0.002291671931743622\n",
      "\n",
      "The classification loss after processing this batch is:  0.09998058527708054\n",
      "The representation loss after processing this batch is:  0.0025434717535972595\n",
      "\n",
      "The classification loss after processing this batch is:  0.1409943699836731\n",
      "The representation loss after processing this batch is:  0.002310454845428467\n",
      "\n",
      "The classification loss after processing this batch is:  0.08628901839256287\n",
      "The representation loss after processing this batch is:  0.002294819802045822\n",
      "\n",
      "The classification loss after processing this batch is:  0.13081610202789307\n",
      "The representation loss after processing this batch is:  0.002503778785467148\n",
      "\n",
      "The classification loss after processing this batch is:  0.19166059792041779\n",
      "The representation loss after processing this batch is:  0.002291478216648102\n",
      "\n",
      "The classification loss after processing this batch is:  0.22173966467380524\n",
      "The representation loss after processing this batch is:  0.0021308623254299164\n",
      "\n",
      "The classification loss after processing this batch is:  0.1658620536327362\n",
      "The representation loss after processing this batch is:  0.00234927237033844\n",
      "\n",
      "The classification loss after processing this batch is:  0.0707104355096817\n",
      "The representation loss after processing this batch is:  0.0025733746588230133\n",
      "\n",
      "The classification loss after processing this batch is:  0.15151265263557434\n",
      "The representation loss after processing this batch is:  0.0025959908962249756\n",
      "\n",
      "The classification loss after processing this batch is:  0.09479903429746628\n",
      "The representation loss after processing this batch is:  0.0025986656546592712\n",
      "\n",
      "The classification loss after processing this batch is:  0.09067762643098831\n",
      "The representation loss after processing this batch is:  0.002615053206682205\n",
      "\n",
      "The classification loss after processing this batch is:  0.1515669971704483\n",
      "The representation loss after processing this batch is:  0.002777673304080963\n",
      "\n",
      "The classification loss after processing this batch is:  0.21291528642177582\n",
      "The representation loss after processing this batch is:  0.0024337396025657654\n",
      "\n",
      "The classification loss after processing this batch is:  0.2972489297389984\n",
      "The representation loss after processing this batch is:  0.002302803099155426\n",
      "\n",
      "The classification loss after processing this batch is:  0.13770753145217896\n",
      "The representation loss after processing this batch is:  0.0026270821690559387\n",
      "\n",
      "The classification loss after processing this batch is:  0.06968677043914795\n",
      "The representation loss after processing this batch is:  0.002569686621427536\n",
      "\n",
      "The classification loss after processing this batch is:  0.09742974489927292\n",
      "The representation loss after processing this batch is:  0.0026455894112586975\n",
      "\n",
      "The classification loss after processing this batch is:  0.1759548783302307\n",
      "The representation loss after processing this batch is:  0.002443809062242508\n",
      "\n",
      "The classification loss after processing this batch is:  0.09018278121948242\n",
      "The representation loss after processing this batch is:  0.002625301480293274\n",
      "\n",
      "The classification loss after processing this batch is:  0.10988274961709976\n",
      "The representation loss after processing this batch is:  0.0023910030722618103\n",
      "\n",
      "The classification loss after processing this batch is:  0.10612224787473679\n",
      "The representation loss after processing this batch is:  0.0024109184741973877\n",
      "\n",
      "The classification loss after processing this batch is:  0.02833227626979351\n",
      "The representation loss after processing this batch is:  0.0026341229677200317\n",
      "\n",
      "The classification loss after processing this batch is:  0.07720445841550827\n",
      "The representation loss after processing this batch is:  0.0026660561561584473\n",
      "\n",
      "The classification loss after processing this batch is:  0.12669657170772552\n",
      "The representation loss after processing this batch is:  0.002694014459848404\n",
      "\n",
      "The classification loss after processing this batch is:  0.15377792716026306\n",
      "The representation loss after processing this batch is:  0.0023438669741153717\n",
      "\n",
      "The classification loss after processing this batch is:  0.11585715413093567\n",
      "The representation loss after processing this batch is:  0.0023688264191150665\n",
      "\n",
      "The classification loss after processing this batch is:  0.09289118647575378\n",
      "The representation loss after processing this batch is:  0.0025639086961746216\n",
      "\n",
      "The classification loss after processing this batch is:  0.149663046002388\n",
      "The representation loss after processing this batch is:  0.002753637731075287\n",
      "\n",
      "The classification loss after processing this batch is:  0.07375795394182205\n",
      "The representation loss after processing this batch is:  0.0027040354907512665\n",
      "\n",
      "The classification loss after processing this batch is:  0.1007862463593483\n",
      "The representation loss after processing this batch is:  0.0027741342782974243\n",
      "\n",
      "The classification loss after processing this batch is:  0.1210547685623169\n",
      "The representation loss after processing this batch is:  0.0027266964316368103\n",
      "\n",
      "The classification loss after processing this batch is:  0.11935711652040482\n",
      "The representation loss after processing this batch is:  0.002453736960887909\n",
      "\n",
      "The classification loss after processing this batch is:  0.14226669073104858\n",
      "The representation loss after processing this batch is:  0.00234406441450119\n",
      "\n",
      "The classification loss after processing this batch is:  0.21875610947608948\n",
      "The representation loss after processing this batch is:  0.002301197499036789\n",
      "\n",
      "The classification loss after processing this batch is:  0.2595479190349579\n",
      "The representation loss after processing this batch is:  0.0024560317397117615\n",
      "\n",
      "The classification loss after processing this batch is:  0.06601489335298538\n",
      "The representation loss after processing this batch is:  0.002257969230413437\n",
      "\n",
      "The classification loss after processing this batch is:  0.10705684125423431\n",
      "The representation loss after processing this batch is:  0.002748411148786545\n",
      "\n",
      "The classification loss after processing this batch is:  0.11288514733314514\n",
      "The representation loss after processing this batch is:  0.002553340047597885\n",
      "\n",
      "The classification loss after processing this batch is:  0.13955242931842804\n",
      "The representation loss after processing this batch is:  0.002329733222723007\n",
      "\n",
      "The classification loss after processing this batch is:  0.20573383569717407\n",
      "The representation loss after processing this batch is:  0.002684682607650757\n",
      "\n",
      "The classification loss after processing this batch is:  0.1828153431415558\n",
      "The representation loss after processing this batch is:  0.002834886312484741\n",
      "\n",
      "The classification loss after processing this batch is:  0.21780692040920258\n",
      "The representation loss after processing this batch is:  0.0029285699129104614\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10404892265796661\n",
      "The representation loss after processing this batch is:  0.002844296395778656\n",
      "\n",
      "The classification loss after processing this batch is:  0.15316656231880188\n",
      "The representation loss after processing this batch is:  0.0027074813842773438\n",
      "\n",
      "The classification loss after processing this batch is:  0.1479613333940506\n",
      "The representation loss after processing this batch is:  0.003115728497505188\n",
      "\n",
      "The classification loss after processing this batch is:  0.05704730376601219\n",
      "The representation loss after processing this batch is:  0.0025526583194732666\n",
      "\n",
      "The classification loss after processing this batch is:  0.19934847950935364\n",
      "The representation loss after processing this batch is:  0.002606339752674103\n",
      "\n",
      "The classification loss after processing this batch is:  0.10535342246294022\n",
      "The representation loss after processing this batch is:  0.0023306608200073242\n",
      "\n",
      "The classification loss after processing this batch is:  0.04743681848049164\n",
      "The representation loss after processing this batch is:  0.0022812001407146454\n",
      "\n",
      "The classification loss after processing this batch is:  0.10281411558389664\n",
      "The representation loss after processing this batch is:  0.002304263412952423\n",
      "\n",
      "The classification loss after processing this batch is:  0.11694204807281494\n",
      "The representation loss after processing this batch is:  0.0027555376291275024\n",
      "\n",
      "The classification loss after processing this batch is:  0.1486944705247879\n",
      "The representation loss after processing this batch is:  0.0022369548678398132\n",
      "\n",
      "The classification loss after processing this batch is:  0.08063306659460068\n",
      "The representation loss after processing this batch is:  0.0023837611079216003\n",
      "\n",
      "The classification loss after processing this batch is:  0.0811125859618187\n",
      "The representation loss after processing this batch is:  0.0022940486669540405\n",
      "\n",
      "The classification loss after processing this batch is:  0.039735231548547745\n",
      "The representation loss after processing this batch is:  0.0024014078080654144\n",
      "\n",
      "The classification loss after processing this batch is:  0.13875463604927063\n",
      "The representation loss after processing this batch is:  0.0020964443683624268\n",
      "\n",
      "The classification loss after processing this batch is:  0.09396646171808243\n",
      "The representation loss after processing this batch is:  0.0022383034229278564\n",
      "\n",
      "The classification loss after processing this batch is:  0.41748735308647156\n",
      "The representation loss after processing this batch is:  0.0025969892740249634\n",
      "\n",
      "The classification loss after processing this batch is:  0.10104501247406006\n",
      "The representation loss after processing this batch is:  0.0026066675782203674\n",
      "\n",
      "The classification loss after processing this batch is:  0.1752670407295227\n",
      "The representation loss after processing this batch is:  0.002230346202850342\n",
      "\n",
      "The classification loss after processing this batch is:  0.22169837355613708\n",
      "The representation loss after processing this batch is:  0.0025654546916484833\n",
      "\n",
      "The classification loss after processing this batch is:  0.0809604749083519\n",
      "The representation loss after processing this batch is:  0.002225123345851898\n",
      "\n",
      "The classification loss after processing this batch is:  0.2347838133573532\n",
      "The representation loss after processing this batch is:  0.0026447251439094543\n",
      "\n",
      "The classification loss after processing this batch is:  0.11900261044502258\n",
      "The representation loss after processing this batch is:  0.0026363246142864227\n",
      "\n",
      "The classification loss after processing this batch is:  0.2377602607011795\n",
      "The representation loss after processing this batch is:  0.0022389590740203857\n",
      "\n",
      "The classification loss after processing this batch is:  0.053646501153707504\n",
      "The representation loss after processing this batch is:  0.0021865591406822205\n",
      "\n",
      "The classification loss after processing this batch is:  0.10072647780179977\n",
      "The representation loss after processing this batch is:  0.002631165087223053\n",
      "\n",
      "The classification loss after processing this batch is:  0.03265528380870819\n",
      "The representation loss after processing this batch is:  0.002549983561038971\n",
      "\n",
      "The classification loss after processing this batch is:  0.03325460106134415\n",
      "The representation loss after processing this batch is:  0.0025793910026550293\n",
      "\n",
      "The classification loss after processing this batch is:  0.06421205401420593\n",
      "The representation loss after processing this batch is:  0.0023638084530830383\n",
      "\n",
      "The classification loss after processing this batch is:  0.06121860817074776\n",
      "The representation loss after processing this batch is:  0.0023302584886550903\n",
      "\n",
      "The classification loss after processing this batch is:  0.1430101990699768\n",
      "The representation loss after processing this batch is:  0.002630360424518585\n",
      "\n",
      "The classification loss after processing this batch is:  0.08691022545099258\n",
      "The representation loss after processing this batch is:  0.0028388500213623047\n",
      "\n",
      "The classification loss after processing this batch is:  0.07117035239934921\n",
      "The representation loss after processing this batch is:  0.002333439886569977\n",
      "\n",
      "The classification loss after processing this batch is:  0.13450799882411957\n",
      "The representation loss after processing this batch is:  0.0021588727831840515\n",
      "\n",
      "The classification loss after processing this batch is:  0.07025420665740967\n",
      "The representation loss after processing this batch is:  0.0027293339371681213\n",
      "\n",
      "The classification loss after processing this batch is:  0.10388191044330597\n",
      "The representation loss after processing this batch is:  0.0025699101388454437\n",
      "\n",
      "The classification loss after processing this batch is:  0.12030307948589325\n",
      "The representation loss after processing this batch is:  0.002530500292778015\n",
      "\n",
      "The classification loss after processing this batch is:  0.17093543708324432\n",
      "The representation loss after processing this batch is:  0.0026281923055648804\n",
      "\n",
      "The classification loss after processing this batch is:  0.10616263002157211\n",
      "The representation loss after processing this batch is:  0.002317562699317932\n",
      "\n",
      "The classification loss after processing this batch is:  0.0797000601887703\n",
      "The representation loss after processing this batch is:  0.0023759156465530396\n",
      "\n",
      "The classification loss after processing this batch is:  0.18743477761745453\n",
      "The representation loss after processing this batch is:  0.002583906054496765\n",
      "\n",
      "The classification loss after processing this batch is:  0.15804506838321686\n",
      "The representation loss after processing this batch is:  0.0024003013968467712\n",
      "\n",
      "The classification loss after processing this batch is:  0.135173037648201\n",
      "The representation loss after processing this batch is:  0.002405308187007904\n",
      "\n",
      "The classification loss after processing this batch is:  0.05183875188231468\n",
      "The representation loss after processing this batch is:  0.00237254798412323\n",
      "\n",
      "The classification loss after processing this batch is:  0.1253775954246521\n",
      "The representation loss after processing this batch is:  0.002732120454311371\n",
      "\n",
      "The classification loss after processing this batch is:  0.12681719660758972\n",
      "The representation loss after processing this batch is:  0.002676505595445633\n",
      "\n",
      "The classification loss after processing this batch is:  0.11578094959259033\n",
      "The representation loss after processing this batch is:  0.0027552247047424316\n",
      "\n",
      "The classification loss after processing this batch is:  0.11175049096345901\n",
      "The representation loss after processing this batch is:  0.003229517489671707\n",
      "\n",
      "The classification loss after processing this batch is:  0.08001580834388733\n",
      "The representation loss after processing this batch is:  0.002946186810731888\n",
      "\n",
      "The classification loss after processing this batch is:  0.13918468356132507\n",
      "The representation loss after processing this batch is:  0.002704113721847534\n",
      "\n",
      "The classification loss after processing this batch is:  0.1888406127691269\n",
      "The representation loss after processing this batch is:  0.0026117265224456787\n",
      "\n",
      "The classification loss after processing this batch is:  0.11364042013883591\n",
      "The representation loss after processing this batch is:  0.0032114312052726746\n",
      "\n",
      "The classification loss after processing this batch is:  0.10853833705186844\n",
      "The representation loss after processing this batch is:  0.002610083669424057\n",
      "\n",
      "The classification loss after processing this batch is:  0.03980270400643349\n",
      "The representation loss after processing this batch is:  0.0021752342581748962\n",
      "\n",
      "The classification loss after processing this batch is:  0.18031665682792664\n",
      "The representation loss after processing this batch is:  0.0022924020886421204\n",
      "\n",
      "The classification loss after processing this batch is:  0.0721404030919075\n",
      "The representation loss after processing this batch is:  0.0024452917277812958\n",
      "\n",
      "The classification loss after processing this batch is:  0.10651635378599167\n",
      "The representation loss after processing this batch is:  0.002526119351387024\n",
      "\n",
      "The classification loss after processing this batch is:  0.10488803684711456\n",
      "The representation loss after processing this batch is:  0.00282982736825943\n",
      "\n",
      "The classification loss after processing this batch is:  0.08836695551872253\n",
      "The representation loss after processing this batch is:  0.002425186336040497\n",
      "\n",
      "The classification loss after processing this batch is:  0.09637451171875\n",
      "The representation loss after processing this batch is:  0.0026126913726329803\n",
      "\n",
      "The classification loss after processing this batch is:  0.1336461454629898\n",
      "The representation loss after processing this batch is:  0.0030493736267089844\n",
      "\n",
      "The classification loss after processing this batch is:  0.13391883671283722\n",
      "The representation loss after processing this batch is:  0.002964101731777191\n",
      "\n",
      "The classification loss after processing this batch is:  0.11778304725885391\n",
      "The representation loss after processing this batch is:  0.002360742539167404\n",
      "\n",
      "The classification loss after processing this batch is:  0.1392558217048645\n",
      "The representation loss after processing this batch is:  0.0029550455510616302\n",
      "\n",
      "The classification loss after processing this batch is:  0.07266219705343246\n",
      "The representation loss after processing this batch is:  0.002325713634490967\n",
      "\n",
      "The classification loss after processing this batch is:  0.08302097022533417\n",
      "The representation loss after processing this batch is:  0.002463817596435547\n",
      "\n",
      "The classification loss after processing this batch is:  0.06478270888328552\n",
      "The representation loss after processing this batch is:  0.0028933361172676086\n",
      "\n",
      "The classification loss after processing this batch is:  0.08463875204324722\n",
      "The representation loss after processing this batch is:  0.0025228001177310944\n",
      "\n",
      "The classification loss after processing this batch is:  0.05260646343231201\n",
      "The representation loss after processing this batch is:  0.0024790167808532715\n",
      "\n",
      "The classification loss after processing this batch is:  0.054194457828998566\n",
      "The representation loss after processing this batch is:  0.0022696256637573242\n",
      "\n",
      "The classification loss after processing this batch is:  0.05763057991862297\n",
      "The representation loss after processing this batch is:  0.002685539424419403\n",
      "\n",
      "The classification loss after processing this batch is:  0.04914305359125137\n",
      "The representation loss after processing this batch is:  0.0026523545384407043\n",
      "\n",
      "The classification loss after processing this batch is:  0.13003186881542206\n",
      "The representation loss after processing this batch is:  0.002408444881439209\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.07651601731777191\n",
      "The representation loss after processing this batch is:  0.002159133553504944\n",
      "\n",
      "The classification loss after processing this batch is:  0.10748981684446335\n",
      "The representation loss after processing this batch is:  0.002475738525390625\n",
      "\n",
      "The classification loss after processing this batch is:  0.05700443312525749\n",
      "The representation loss after processing this batch is:  0.0026955828070640564\n",
      "\n",
      "The classification loss after processing this batch is:  0.15634067356586456\n",
      "The representation loss after processing this batch is:  0.0024369657039642334\n",
      "\n",
      "The classification loss after processing this batch is:  0.13427361845970154\n",
      "The representation loss after processing this batch is:  0.0023912042379379272\n",
      "\n",
      "The classification loss after processing this batch is:  0.11361229419708252\n",
      "The representation loss after processing this batch is:  0.0024551227688789368\n",
      "\n",
      "The classification loss after processing this batch is:  0.08228551596403122\n",
      "The representation loss after processing this batch is:  0.002479739487171173\n",
      "\n",
      "The classification loss after processing this batch is:  0.11172747611999512\n",
      "The representation loss after processing this batch is:  0.0026630237698554993\n",
      "\n",
      "The classification loss after processing this batch is:  0.05917145684361458\n",
      "The representation loss after processing this batch is:  0.0024275407195091248\n",
      "\n",
      "The classification loss after processing this batch is:  0.05321071669459343\n",
      "The representation loss after processing this batch is:  0.0025001242756843567\n",
      "\n",
      "The classification loss after processing this batch is:  0.06050384044647217\n",
      "The representation loss after processing this batch is:  0.002345755696296692\n",
      "\n",
      "The classification loss after processing this batch is:  0.1578850895166397\n",
      "The representation loss after processing this batch is:  0.0025069788098335266\n",
      "\n",
      "The classification loss after processing this batch is:  0.12390395253896713\n",
      "The representation loss after processing this batch is:  0.00229722261428833\n",
      "\n",
      "The classification loss after processing this batch is:  0.1163630485534668\n",
      "The representation loss after processing this batch is:  0.0028575584292411804\n",
      "\n",
      "The classification loss after processing this batch is:  0.1506834477186203\n",
      "The representation loss after processing this batch is:  0.0024871118366718292\n",
      "\n",
      "The classification loss after processing this batch is:  0.1260136365890503\n",
      "The representation loss after processing this batch is:  0.0027017593383789062\n",
      "\n",
      "The classification loss after processing this batch is:  0.14005891978740692\n",
      "The representation loss after processing this batch is:  0.0024007782340049744\n",
      "\n",
      "The classification loss after processing this batch is:  0.24962863326072693\n",
      "The representation loss after processing this batch is:  0.0024136975407600403\n",
      "\n",
      "The classification loss after processing this batch is:  0.17400643229484558\n",
      "The representation loss after processing this batch is:  0.0023709796369075775\n",
      "\n",
      "The classification loss after processing this batch is:  0.09900137037038803\n",
      "The representation loss after processing this batch is:  0.0022216960787773132\n",
      "\n",
      "The classification loss after processing this batch is:  0.058193277567625046\n",
      "The representation loss after processing this batch is:  0.002407349646091461\n",
      "\n",
      "The classification loss after processing this batch is:  0.05576815456151962\n",
      "The representation loss after processing this batch is:  0.00224091112613678\n",
      "\n",
      "The classification loss after processing this batch is:  0.052319325506687164\n",
      "The representation loss after processing this batch is:  0.00249558687210083\n",
      "\n",
      "The classification loss after processing this batch is:  0.058901023119688034\n",
      "The representation loss after processing this batch is:  0.002825044095516205\n",
      "\n",
      "The classification loss after processing this batch is:  0.12236563116312027\n",
      "The representation loss after processing this batch is:  0.0024275556206703186\n",
      "\n",
      "The classification loss after processing this batch is:  0.07941759377717972\n",
      "The representation loss after processing this batch is:  0.0025622770190238953\n",
      "\n",
      "The classification loss after processing this batch is:  0.16705390810966492\n",
      "The representation loss after processing this batch is:  0.0024579502642154694\n",
      "\n",
      "The classification loss after processing this batch is:  0.12292177230119705\n",
      "The representation loss after processing this batch is:  0.002618648111820221\n",
      "\n",
      "The classification loss after processing this batch is:  0.1661897748708725\n",
      "The representation loss after processing this batch is:  0.0021550171077251434\n",
      "\n",
      "The classification loss after processing this batch is:  0.10724399238824844\n",
      "The representation loss after processing this batch is:  0.0022959262132644653\n",
      "\n",
      "The classification loss after processing this batch is:  0.1764506995677948\n",
      "The representation loss after processing this batch is:  0.002266671508550644\n",
      "\n",
      "The classification loss after processing this batch is:  0.10123439133167267\n",
      "The representation loss after processing this batch is:  0.0022449754178524017\n",
      "\n",
      "The classification loss after processing this batch is:  0.09120037406682968\n",
      "The representation loss after processing this batch is:  0.002476528286933899\n",
      "\n",
      "The classification loss after processing this batch is:  0.13547177612781525\n",
      "The representation loss after processing this batch is:  0.0022580623626708984\n",
      "\n",
      "The classification loss after processing this batch is:  0.05342497676610947\n",
      "The representation loss after processing this batch is:  0.0023207888007164\n",
      "\n",
      "The classification loss after processing this batch is:  0.04705647751688957\n",
      "The representation loss after processing this batch is:  0.0023250654339790344\n",
      "\n",
      "The classification loss after processing this batch is:  0.13105249404907227\n",
      "The representation loss after processing this batch is:  0.002634592354297638\n",
      "\n",
      "The classification loss after processing this batch is:  0.17147515714168549\n",
      "The representation loss after processing this batch is:  0.0023947134613990784\n",
      "\n",
      "The classification loss after processing this batch is:  0.12153299897909164\n",
      "The representation loss after processing this batch is:  0.0026405006647109985\n",
      "\n",
      "The classification loss after processing this batch is:  0.06213400885462761\n",
      "The representation loss after processing this batch is:  0.0026296451687812805\n",
      "\n",
      "The classification loss after processing this batch is:  0.09492448717355728\n",
      "The representation loss after processing this batch is:  0.0027127787470817566\n",
      "\n",
      "The classification loss after processing this batch is:  0.0812128335237503\n",
      "The representation loss after processing this batch is:  0.0025081560015678406\n",
      "\n",
      "The classification loss after processing this batch is:  0.2513781189918518\n",
      "The representation loss after processing this batch is:  0.0024165622889995575\n",
      "\n",
      "The classification loss after processing this batch is:  0.06516701728105545\n",
      "The representation loss after processing this batch is:  0.0023582428693771362\n",
      "\n",
      "The classification loss after processing this batch is:  0.041546087712049484\n",
      "The representation loss after processing this batch is:  0.0024881958961486816\n",
      "\n",
      "The classification loss after processing this batch is:  0.13664139807224274\n",
      "The representation loss after processing this batch is:  0.002855628728866577\n",
      "\n",
      "The classification loss after processing this batch is:  0.10535469651222229\n",
      "The representation loss after processing this batch is:  0.0026412010192871094\n",
      "\n",
      "The classification loss after processing this batch is:  0.06819907575845718\n",
      "The representation loss after processing this batch is:  0.002627916634082794\n",
      "\n",
      "The classification loss after processing this batch is:  0.04890960827469826\n",
      "The representation loss after processing this batch is:  0.0022105835378170013\n",
      "\n",
      "The classification loss after processing this batch is:  0.09970028698444366\n",
      "The representation loss after processing this batch is:  0.0029753074049949646\n",
      "\n",
      "The classification loss after processing this batch is:  0.15094082057476044\n",
      "The representation loss after processing this batch is:  0.0028244927525520325\n",
      "\n",
      "The classification loss after processing this batch is:  0.1991359144449234\n",
      "The representation loss after processing this batch is:  0.0022781528532505035\n",
      "\n",
      "The classification loss after processing this batch is:  0.15560974180698395\n",
      "The representation loss after processing this batch is:  0.002773955464363098\n",
      "\n",
      "The classification loss after processing this batch is:  0.05420096963644028\n",
      "The representation loss after processing this batch is:  0.002577483654022217\n",
      "\n",
      "The classification loss after processing this batch is:  0.06349264830350876\n",
      "The representation loss after processing this batch is:  0.0021929964423179626\n",
      "\n",
      "The classification loss after processing this batch is:  0.1382145881652832\n",
      "The representation loss after processing this batch is:  0.002650611102581024\n",
      "\n",
      "The classification loss after processing this batch is:  0.17775556445121765\n",
      "The representation loss after processing this batch is:  0.002650827169418335\n",
      "\n",
      "The classification loss after processing this batch is:  0.17649465799331665\n",
      "The representation loss after processing this batch is:  0.002725854516029358\n",
      "\n",
      "The classification loss after processing this batch is:  0.20932014286518097\n",
      "The representation loss after processing this batch is:  0.0022476911544799805\n",
      "\n",
      "The classification loss after processing this batch is:  0.09995375573635101\n",
      "The representation loss after processing this batch is:  0.0022709518671035767\n",
      "\n",
      "The classification loss after processing this batch is:  0.1692028045654297\n",
      "The representation loss after processing this batch is:  0.002252858132123947\n",
      "\n",
      "The classification loss after processing this batch is:  0.08466852456331253\n",
      "The representation loss after processing this batch is:  0.002123512327671051\n",
      "\n",
      "The classification loss after processing this batch is:  0.08623702824115753\n",
      "The representation loss after processing this batch is:  0.002502754330635071\n",
      "\n",
      "The classification loss after processing this batch is:  0.052274610847234726\n",
      "The representation loss after processing this batch is:  0.002430550754070282\n",
      "\n",
      "The classification loss after processing this batch is:  0.11755413562059402\n",
      "The representation loss after processing this batch is:  0.002495981752872467\n",
      "\n",
      "The classification loss after processing this batch is:  0.12269296497106552\n",
      "The representation loss after processing this batch is:  0.002295352518558502\n",
      "\n",
      "The classification loss after processing this batch is:  0.0838267132639885\n",
      "The representation loss after processing this batch is:  0.0024243444204330444\n",
      "\n",
      "The classification loss after processing this batch is:  0.15006831288337708\n",
      "The representation loss after processing this batch is:  0.002680353820323944\n",
      "\n",
      "The classification loss after processing this batch is:  0.043110910803079605\n",
      "The representation loss after processing this batch is:  0.002714298665523529\n",
      "\n",
      "The classification loss after processing this batch is:  0.09290976077318192\n",
      "The representation loss after processing this batch is:  0.0026451945304870605\n",
      "\n",
      "The classification loss after processing this batch is:  0.09698144346475601\n",
      "The representation loss after processing this batch is:  0.0023507028818130493\n",
      "\n",
      "The classification loss after processing this batch is:  0.17534305155277252\n",
      "The representation loss after processing this batch is:  0.002590995281934738\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.04903387278318405\n",
      "The representation loss after processing this batch is:  0.0030975714325904846\n",
      "\n",
      "The classification loss after processing this batch is:  0.07632878422737122\n",
      "The representation loss after processing this batch is:  0.0023098476231098175\n",
      "\n",
      "The classification loss after processing this batch is:  0.15928097069263458\n",
      "The representation loss after processing this batch is:  0.0026007667183876038\n",
      "\n",
      "The classification loss after processing this batch is:  0.1060427874326706\n",
      "The representation loss after processing this batch is:  0.002449389547109604\n",
      "\n",
      "The classification loss after processing this batch is:  0.14422495663166046\n",
      "The representation loss after processing this batch is:  0.0022895261645317078\n",
      "\n",
      "The classification loss after processing this batch is:  0.0977843850851059\n",
      "The representation loss after processing this batch is:  0.0022956132888793945\n",
      "\n",
      "The classification loss after processing this batch is:  0.05838073417544365\n",
      "The representation loss after processing this batch is:  0.002510957419872284\n",
      "\n",
      "The classification loss after processing this batch is:  0.12158562242984772\n",
      "The representation loss after processing this batch is:  0.0021076537668704987\n",
      "\n",
      "The classification loss after processing this batch is:  0.09054209291934967\n",
      "The representation loss after processing this batch is:  0.0025271251797676086\n",
      "\n",
      "The classification loss after processing this batch is:  0.11720357835292816\n",
      "The representation loss after processing this batch is:  0.002507708966732025\n",
      "\n",
      "The classification loss after processing this batch is:  0.11438394337892532\n",
      "The representation loss after processing this batch is:  0.0030323565006256104\n",
      "\n",
      "The classification loss after processing this batch is:  0.05825918912887573\n",
      "The representation loss after processing this batch is:  0.0024780333042144775\n",
      "\n",
      "The classification loss after processing this batch is:  0.13315555453300476\n",
      "The representation loss after processing this batch is:  0.0023958683013916016\n",
      "\n",
      "The classification loss after processing this batch is:  0.15542802214622498\n",
      "The representation loss after processing this batch is:  0.0027254149317741394\n",
      "\n",
      "The classification loss after processing this batch is:  0.03665369376540184\n",
      "The representation loss after processing this batch is:  0.002568945288658142\n",
      "\n",
      "The classification loss after processing this batch is:  0.0913068950176239\n",
      "The representation loss after processing this batch is:  0.002167578786611557\n",
      "\n",
      "The classification loss after processing this batch is:  0.15236040949821472\n",
      "The representation loss after processing this batch is:  0.002285633236169815\n",
      "\n",
      "The classification loss after processing this batch is:  0.15374621748924255\n",
      "The representation loss after processing this batch is:  0.0024774372577667236\n",
      "\n",
      "The classification loss after processing this batch is:  0.10370352864265442\n",
      "The representation loss after processing this batch is:  0.0023347586393356323\n",
      "\n",
      "The classification loss after processing this batch is:  0.16954907774925232\n",
      "The representation loss after processing this batch is:  0.0024174824357032776\n",
      "\n",
      "The classification loss after processing this batch is:  0.13028348982334137\n",
      "The representation loss after processing this batch is:  0.002420097589492798\n",
      "\n",
      "The classification loss after processing this batch is:  0.1731949746608734\n",
      "The representation loss after processing this batch is:  0.0027087628841400146\n",
      "\n",
      "The classification loss after processing this batch is:  0.08616935461759567\n",
      "The representation loss after processing this batch is:  0.002740330994129181\n",
      "\n",
      "The classification loss after processing this batch is:  0.1702793687582016\n",
      "The representation loss after processing this batch is:  0.0024390816688537598\n",
      "\n",
      "The classification loss after processing this batch is:  0.10450982302427292\n",
      "The representation loss after processing this batch is:  0.0034678876399993896\n",
      "\n",
      "The classification loss after processing this batch is:  0.06286820769309998\n",
      "The representation loss after processing this batch is:  0.0025060996413230896\n",
      "\n",
      "The classification loss after processing this batch is:  0.08521639555692673\n",
      "The representation loss after processing this batch is:  0.00247279554605484\n",
      "\n",
      "The classification loss after processing this batch is:  0.08227693289518356\n",
      "The representation loss after processing this batch is:  0.0022902153432369232\n",
      "\n",
      "The classification loss after processing this batch is:  0.10752201825380325\n",
      "The representation loss after processing this batch is:  0.002515070140361786\n",
      "\n",
      "The classification loss after processing this batch is:  0.09460677206516266\n",
      "The representation loss after processing this batch is:  0.002389676868915558\n",
      "\n",
      "The classification loss after processing this batch is:  0.1654042899608612\n",
      "The representation loss after processing this batch is:  0.002571500837802887\n",
      "\n",
      "The classification loss after processing this batch is:  0.040665123611688614\n",
      "The representation loss after processing this batch is:  0.002563662827014923\n",
      "\n",
      "The classification loss after processing this batch is:  0.06158101558685303\n",
      "The representation loss after processing this batch is:  0.002785913646221161\n",
      "\n",
      "The classification loss after processing this batch is:  0.15259891748428345\n",
      "The representation loss after processing this batch is:  0.0026911646127700806\n",
      "\n",
      "The classification loss after processing this batch is:  0.03013400174677372\n",
      "The representation loss after processing this batch is:  0.0024117454886436462\n",
      "\n",
      "The classification loss after processing this batch is:  0.07629714161157608\n",
      "The representation loss after processing this batch is:  0.0023648589849472046\n",
      "\n",
      "The classification loss after processing this batch is:  0.04518105089664459\n",
      "The representation loss after processing this batch is:  0.002597205340862274\n",
      "\n",
      "The classification loss after processing this batch is:  0.09000025689601898\n",
      "The representation loss after processing this batch is:  0.002290785312652588\n",
      "\n",
      "The classification loss after processing this batch is:  0.1479657143354416\n",
      "The representation loss after processing this batch is:  0.002814255654811859\n",
      "\n",
      "The classification loss after processing this batch is:  0.1539711356163025\n",
      "The representation loss after processing this batch is:  0.0034952908754348755\n",
      "\n",
      "The classification loss after processing this batch is:  0.1424291878938675\n",
      "The representation loss after processing this batch is:  0.0031215623021125793\n",
      "\n",
      "The classification loss after processing this batch is:  0.07184053212404251\n",
      "The representation loss after processing this batch is:  0.002696119248867035\n",
      "\n",
      "The classification loss after processing this batch is:  0.11839549243450165\n",
      "The representation loss after processing this batch is:  0.002327553927898407\n",
      "\n",
      "The classification loss after processing this batch is:  0.11238058656454086\n",
      "The representation loss after processing this batch is:  0.0025951340794563293\n",
      "\n",
      "The classification loss after processing this batch is:  0.054798778146505356\n",
      "The representation loss after processing this batch is:  0.002681884914636612\n",
      "\n",
      "The classification loss after processing this batch is:  0.05507485941052437\n",
      "The representation loss after processing this batch is:  0.0023569613695144653\n",
      "\n",
      "The classification loss after processing this batch is:  0.042658351361751556\n",
      "The representation loss after processing this batch is:  0.0027736276388168335\n",
      "\n",
      "The classification loss after processing this batch is:  0.08205114305019379\n",
      "The representation loss after processing this batch is:  0.002726711332798004\n",
      "\n",
      "The classification loss after processing this batch is:  0.17600955069065094\n",
      "The representation loss after processing this batch is:  0.002590034157037735\n",
      "\n",
      "The classification loss after processing this batch is:  0.1349940448999405\n",
      "The representation loss after processing this batch is:  0.0023435428738594055\n",
      "\n",
      "The classification loss after processing this batch is:  0.11984706670045853\n",
      "The representation loss after processing this batch is:  0.003190457820892334\n",
      "\n",
      "The classification loss after processing this batch is:  0.09097657352685928\n",
      "The representation loss after processing this batch is:  0.0028360188007354736\n",
      "\n",
      "The classification loss after processing this batch is:  0.11237217485904694\n",
      "The representation loss after processing this batch is:  0.0025599561631679535\n",
      "\n",
      "The classification loss after processing this batch is:  0.08171271532773972\n",
      "The representation loss after processing this batch is:  0.0023579075932502747\n",
      "\n",
      "The classification loss after processing this batch is:  0.34132513403892517\n",
      "The representation loss after processing this batch is:  0.002626195549964905\n",
      "\n",
      "The classification loss after processing this batch is:  0.0884222462773323\n",
      "The representation loss after processing this batch is:  0.0027693435549736023\n",
      "\n",
      "The classification loss after processing this batch is:  0.2250041365623474\n",
      "The representation loss after processing this batch is:  0.003176368772983551\n",
      "\n",
      "The classification loss after processing this batch is:  0.09709986299276352\n",
      "The representation loss after processing this batch is:  0.002316579222679138\n",
      "\n",
      "The classification loss after processing this batch is:  0.09808798134326935\n",
      "The representation loss after processing this batch is:  0.0024723410606384277\n",
      "\n",
      "The classification loss after processing this batch is:  0.1546904444694519\n",
      "The representation loss after processing this batch is:  0.0023284554481506348\n",
      "\n",
      "The classification loss after processing this batch is:  0.10304392874240875\n",
      "The representation loss after processing this batch is:  0.0025771036744117737\n",
      "\n",
      "The classification loss after processing this batch is:  0.17901763319969177\n",
      "The representation loss after processing this batch is:  0.0026225149631500244\n",
      "\n",
      "The classification loss after processing this batch is:  0.12211965769529343\n",
      "The representation loss after processing this batch is:  0.0028723254799842834\n",
      "\n",
      "The classification loss after processing this batch is:  0.13746508955955505\n",
      "The representation loss after processing this batch is:  0.0030706077814102173\n",
      "\n",
      "The classification loss after processing this batch is:  0.14663267135620117\n",
      "The representation loss after processing this batch is:  0.0027743056416511536\n",
      "\n",
      "The classification loss after processing this batch is:  0.03609280660748482\n",
      "The representation loss after processing this batch is:  0.0026476234197616577\n",
      "\n",
      "The classification loss after processing this batch is:  0.1254580020904541\n",
      "The representation loss after processing this batch is:  0.0023269392549991608\n",
      "\n",
      "The classification loss after processing this batch is:  0.11730222404003143\n",
      "The representation loss after processing this batch is:  0.00231768935918808\n",
      "\n",
      "The classification loss after processing this batch is:  0.04550458490848541\n",
      "The representation loss after processing this batch is:  0.0025921761989593506\n",
      "\n",
      "The classification loss after processing this batch is:  0.1367788016796112\n",
      "The representation loss after processing this batch is:  0.0023351311683654785\n",
      "\n",
      "The classification loss after processing this batch is:  0.2185465693473816\n",
      "The representation loss after processing this batch is:  0.002626076340675354\n",
      "\n",
      "The classification loss after processing this batch is:  0.09931770712137222\n",
      "The representation loss after processing this batch is:  0.002114389091730118\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.07944110780954361\n",
      "The representation loss after processing this batch is:  0.002595897763967514\n",
      "\n",
      "The classification loss after processing this batch is:  0.09179145842790604\n",
      "The representation loss after processing this batch is:  0.0023550763726234436\n",
      "\n",
      "The classification loss after processing this batch is:  0.07550346106290817\n",
      "The representation loss after processing this batch is:  0.0025216490030288696\n",
      "\n",
      "The classification loss after processing this batch is:  0.0975702777504921\n",
      "The representation loss after processing this batch is:  0.0027448460459709167\n",
      "\n",
      "The classification loss after processing this batch is:  0.049453459680080414\n",
      "The representation loss after processing this batch is:  0.002684168517589569\n",
      "\n",
      "The classification loss after processing this batch is:  0.12292160838842392\n",
      "The representation loss after processing this batch is:  0.0023281797766685486\n",
      "\n",
      "The classification loss after processing this batch is:  0.12932823598384857\n",
      "The representation loss after processing this batch is:  0.002174854278564453\n",
      "\n",
      "The classification loss after processing this batch is:  0.07316070050001144\n",
      "The representation loss after processing this batch is:  0.002631045877933502\n",
      "\n",
      "The classification loss after processing this batch is:  0.14228849112987518\n",
      "The representation loss after processing this batch is:  0.0022201016545295715\n",
      "\n",
      "The classification loss after processing this batch is:  0.11228079348802567\n",
      "The representation loss after processing this batch is:  0.002211138606071472\n",
      "\n",
      "The classification loss after processing this batch is:  0.06231071427464485\n",
      "The representation loss after processing this batch is:  0.0024599507451057434\n",
      "\n",
      "The classification loss after processing this batch is:  0.06958459317684174\n",
      "The representation loss after processing this batch is:  0.002517886459827423\n",
      "\n",
      "The classification loss after processing this batch is:  0.1213163211941719\n",
      "The representation loss after processing this batch is:  0.0023984387516975403\n",
      "\n",
      "The classification loss after processing this batch is:  0.0530310794711113\n",
      "The representation loss after processing this batch is:  0.002552919089794159\n",
      "\n",
      "The classification loss after processing this batch is:  0.3194727599620819\n",
      "The representation loss after processing this batch is:  0.002267099916934967\n",
      "\n",
      "The classification loss after processing this batch is:  0.1043439581990242\n",
      "The representation loss after processing this batch is:  0.002721525728702545\n",
      "\n",
      "The classification loss after processing this batch is:  0.16671758890151978\n",
      "The representation loss after processing this batch is:  0.00226689875125885\n",
      "\n",
      "The classification loss after processing this batch is:  0.0703352689743042\n",
      "The representation loss after processing this batch is:  0.002187281847000122\n",
      "\n",
      "The classification loss after processing this batch is:  0.11141625791788101\n",
      "The representation loss after processing this batch is:  0.0024563968181610107\n",
      "\n",
      "The classification loss after processing this batch is:  0.06873469799757004\n",
      "The representation loss after processing this batch is:  0.0022200606763362885\n",
      "\n",
      "The classification loss after processing this batch is:  0.08606336265802383\n",
      "The representation loss after processing this batch is:  0.0023551099002361298\n",
      "\n",
      "The classification loss after processing this batch is:  0.1676882654428482\n",
      "The representation loss after processing this batch is:  0.002460785210132599\n",
      "\n",
      "The classification loss after processing this batch is:  0.10555028915405273\n",
      "The representation loss after processing this batch is:  0.0030562467873096466\n",
      "\n",
      "The classification loss after processing this batch is:  0.14479297399520874\n",
      "The representation loss after processing this batch is:  0.002477101981639862\n",
      "\n",
      "The classification loss after processing this batch is:  0.09814076125621796\n",
      "The representation loss after processing this batch is:  0.002550937235355377\n",
      "\n",
      "The classification loss after processing this batch is:  0.1490958034992218\n",
      "The representation loss after processing this batch is:  0.0026924610137939453\n",
      "\n",
      "The classification loss after processing this batch is:  0.14813388884067535\n",
      "The representation loss after processing this batch is:  0.0025955289602279663\n",
      "\n",
      "The classification loss after processing this batch is:  0.17126503586769104\n",
      "The representation loss after processing this batch is:  0.002469457685947418\n",
      "\n",
      "The classification loss after processing this batch is:  0.0766410082578659\n",
      "The representation loss after processing this batch is:  0.002551361918449402\n",
      "\n",
      "The classification loss after processing this batch is:  0.09521497040987015\n",
      "The representation loss after processing this batch is:  0.0030589699745178223\n",
      "\n",
      "The classification loss after processing this batch is:  0.05045162886381149\n",
      "The representation loss after processing this batch is:  0.0024906620383262634\n",
      "\n",
      "The classification loss after processing this batch is:  0.1655891388654709\n",
      "The representation loss after processing this batch is:  0.0022556371986865997\n",
      "\n",
      "The classification loss after processing this batch is:  0.20363646745681763\n",
      "The representation loss after processing this batch is:  0.002544861286878586\n",
      "\n",
      "The classification loss after processing this batch is:  0.07941434532403946\n",
      "The representation loss after processing this batch is:  0.0029012709856033325\n",
      "\n",
      "The classification loss after processing this batch is:  0.14244255423545837\n",
      "The representation loss after processing this batch is:  0.0027865469455718994\n",
      "\n",
      "The classification loss after processing this batch is:  0.1514710932970047\n",
      "The representation loss after processing this batch is:  0.0024368129670619965\n",
      "\n",
      "The classification loss after processing this batch is:  0.16610956192016602\n",
      "The representation loss after processing this batch is:  0.002663232386112213\n",
      "\n",
      "The classification loss after processing this batch is:  0.05118166655302048\n",
      "The representation loss after processing this batch is:  0.002374831587076187\n",
      "\n",
      "The classification loss after processing this batch is:  0.13608649373054504\n",
      "The representation loss after processing this batch is:  0.002589598298072815\n",
      "\n",
      "The classification loss after processing this batch is:  0.15157148241996765\n",
      "The representation loss after processing this batch is:  0.0025844424962997437\n",
      "\n",
      "The classification loss after processing this batch is:  0.08065763115882874\n",
      "The representation loss after processing this batch is:  0.0026637911796569824\n",
      "\n",
      "The classification loss after processing this batch is:  0.042013220489025116\n",
      "The representation loss after processing this batch is:  0.002879232168197632\n",
      "\n",
      "The classification loss after processing this batch is:  0.09681089967489243\n",
      "The representation loss after processing this batch is:  0.002454005181789398\n",
      "\n",
      "The classification loss after processing this batch is:  0.08705219626426697\n",
      "The representation loss after processing this batch is:  0.0027135610580444336\n",
      "\n",
      "The classification loss after processing this batch is:  0.09856581687927246\n",
      "The representation loss after processing this batch is:  0.002380654215812683\n",
      "\n",
      "The classification loss after processing this batch is:  0.18911533057689667\n",
      "The representation loss after processing this batch is:  0.002624090760946274\n",
      "\n",
      "The classification loss after processing this batch is:  0.13169029355049133\n",
      "The representation loss after processing this batch is:  0.0022905543446540833\n",
      "\n",
      "The classification loss after processing this batch is:  0.10007242113351822\n",
      "The representation loss after processing this batch is:  0.0027768313884735107\n",
      "\n",
      "The classification loss after processing this batch is:  0.14494119584560394\n",
      "The representation loss after processing this batch is:  0.0026685111224651337\n",
      "\n",
      "The classification loss after processing this batch is:  0.09648558497428894\n",
      "The representation loss after processing this batch is:  0.0028691068291664124\n",
      "\n",
      "The classification loss after processing this batch is:  0.09301041811704636\n",
      "The representation loss after processing this batch is:  0.0024535059928894043\n",
      "\n",
      "The classification loss after processing this batch is:  0.16564780473709106\n",
      "The representation loss after processing this batch is:  0.002559475600719452\n",
      "\n",
      "The classification loss after processing this batch is:  0.16996978223323822\n",
      "The representation loss after processing this batch is:  0.0033357813954353333\n",
      "\n",
      "The classification loss after processing this batch is:  0.11702285706996918\n",
      "The representation loss after processing this batch is:  0.0026569217443466187\n",
      "\n",
      "The classification loss after processing this batch is:  0.06336689740419388\n",
      "The representation loss after processing this batch is:  0.00279945507645607\n",
      "\n",
      "The classification loss after processing this batch is:  0.09116892516613007\n",
      "The representation loss after processing this batch is:  0.002486463636159897\n",
      "\n",
      "The classification loss after processing this batch is:  0.0640745460987091\n",
      "The representation loss after processing this batch is:  0.002734735608100891\n",
      "\n",
      "The classification loss after processing this batch is:  0.11333596706390381\n",
      "The representation loss after processing this batch is:  0.002473834902048111\n",
      "\n",
      "The classification loss after processing this batch is:  0.2157871127128601\n",
      "The representation loss after processing this batch is:  0.002337820827960968\n",
      "\n",
      "The classification loss after processing this batch is:  0.2501598596572876\n",
      "The representation loss after processing this batch is:  0.0028572753071784973\n",
      "\n",
      "The classification loss after processing this batch is:  0.12193294614553452\n",
      "The representation loss after processing this batch is:  0.0022957883775234222\n",
      "\n",
      "The classification loss after processing this batch is:  0.11866123974323273\n",
      "The representation loss after processing this batch is:  0.0023287497460842133\n",
      "\n",
      "The classification loss after processing this batch is:  0.08841662108898163\n",
      "The representation loss after processing this batch is:  0.002595365047454834\n",
      "\n",
      "The classification loss after processing this batch is:  0.11550340056419373\n",
      "The representation loss after processing this batch is:  0.00249408558011055\n",
      "\n",
      "The classification loss after processing this batch is:  0.2016998827457428\n",
      "The representation loss after processing this batch is:  0.002804342657327652\n",
      "\n",
      "The classification loss after processing this batch is:  0.13222098350524902\n",
      "The representation loss after processing this batch is:  0.0023021213710308075\n",
      "\n",
      "The classification loss after processing this batch is:  0.29710012674331665\n",
      "The representation loss after processing this batch is:  0.0025199279189109802\n",
      "\n",
      "The classification loss after processing this batch is:  0.15096773207187653\n",
      "The representation loss after processing this batch is:  0.0026377514004707336\n",
      "\n",
      "The classification loss after processing this batch is:  0.04954659938812256\n",
      "The representation loss after processing this batch is:  0.0029645338654518127\n",
      "\n",
      "The classification loss after processing this batch is:  0.1281474381685257\n",
      "The representation loss after processing this batch is:  0.00243503600358963\n",
      "\n",
      "The classification loss after processing this batch is:  0.12168144434690475\n",
      "The representation loss after processing this batch is:  0.0023389719426631927\n",
      "\n",
      "The classification loss after processing this batch is:  0.16135482490062714\n",
      "The representation loss after processing this batch is:  0.0026002228260040283\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.105222187936306\n",
      "The representation loss after processing this batch is:  0.002261590212583542\n",
      "\n",
      "The classification loss after processing this batch is:  0.15515582263469696\n",
      "The representation loss after processing this batch is:  0.0022667348384857178\n",
      "\n",
      "The classification loss after processing this batch is:  0.11026223748922348\n",
      "The representation loss after processing this batch is:  0.0024068504571914673\n",
      "\n",
      "The classification loss after processing this batch is:  0.13576847314834595\n",
      "The representation loss after processing this batch is:  0.002403613179922104\n",
      "\n",
      "The classification loss after processing this batch is:  0.17723539471626282\n",
      "The representation loss after processing this batch is:  0.0025681406259536743\n",
      "\n",
      "The classification loss after processing this batch is:  0.21237272024154663\n",
      "The representation loss after processing this batch is:  0.002485804259777069\n",
      "\n",
      "The classification loss after processing this batch is:  0.12884385883808136\n",
      "The representation loss after processing this batch is:  0.002428881824016571\n",
      "\n",
      "The classification loss after processing this batch is:  0.04348498955368996\n",
      "The representation loss after processing this batch is:  0.002967923879623413\n",
      "\n",
      "The classification loss after processing this batch is:  0.02113352157175541\n",
      "The representation loss after processing this batch is:  0.002622358500957489\n",
      "\n",
      "The classification loss after processing this batch is:  0.09656042605638504\n",
      "The representation loss after processing this batch is:  0.002877570688724518\n",
      "\n",
      "The classification loss after processing this batch is:  0.08629467338323593\n",
      "The representation loss after processing this batch is:  0.004110284149646759\n",
      "\n",
      "The classification loss after processing this batch is:  0.15271803736686707\n",
      "The representation loss after processing this batch is:  0.0026655569672584534\n",
      "\n",
      "The classification loss after processing this batch is:  0.11042093485593796\n",
      "The representation loss after processing this batch is:  0.002861820161342621\n",
      "\n",
      "The classification loss after processing this batch is:  0.13509626686573029\n",
      "The representation loss after processing this batch is:  0.002436436712741852\n",
      "\n",
      "The classification loss after processing this batch is:  0.04989784210920334\n",
      "The representation loss after processing this batch is:  0.002713419497013092\n",
      "\n",
      "The classification loss after processing this batch is:  0.11749745905399323\n",
      "The representation loss after processing this batch is:  0.0025711357593536377\n",
      "\n",
      "The classification loss after processing this batch is:  0.10513053089380264\n",
      "The representation loss after processing this batch is:  0.0027070343494415283\n",
      "\n",
      "The classification loss after processing this batch is:  0.145967036485672\n",
      "The representation loss after processing this batch is:  0.002738557755947113\n",
      "\n",
      "The classification loss after processing this batch is:  0.07451987266540527\n",
      "The representation loss after processing this batch is:  0.002472825348377228\n",
      "\n",
      "The classification loss after processing this batch is:  0.06645217537879944\n",
      "The representation loss after processing this batch is:  0.002025548368692398\n",
      "\n",
      "The classification loss after processing this batch is:  0.11575587093830109\n",
      "The representation loss after processing this batch is:  0.0023713409900665283\n",
      "\n",
      "The classification loss after processing this batch is:  0.13384419679641724\n",
      "The representation loss after processing this batch is:  0.0024555176496505737\n",
      "\n",
      "The classification loss after processing this batch is:  0.10597947984933853\n",
      "The representation loss after processing this batch is:  0.0022657960653305054\n",
      "\n",
      "The classification loss after processing this batch is:  0.14430491626262665\n",
      "The representation loss after processing this batch is:  0.002712033689022064\n",
      "\n",
      "The classification loss after processing this batch is:  0.0897144004702568\n",
      "The representation loss after processing this batch is:  0.0025459229946136475\n",
      "\n",
      "The classification loss after processing this batch is:  0.027083134278655052\n",
      "The representation loss after processing this batch is:  0.0023739486932754517\n",
      "\n",
      "The classification loss after processing this batch is:  0.05704128369688988\n",
      "The representation loss after processing this batch is:  0.00289926677942276\n",
      "\n",
      "The classification loss after processing this batch is:  0.03939367085695267\n",
      "The representation loss after processing this batch is:  0.0025840625166893005\n",
      "\n",
      "The classification loss after processing this batch is:  0.10036835074424744\n",
      "The representation loss after processing this batch is:  0.002651907503604889\n",
      "\n",
      "The classification loss after processing this batch is:  0.05652457848191261\n",
      "The representation loss after processing this batch is:  0.0024826526641845703\n",
      "\n",
      "The classification loss after processing this batch is:  0.05898098275065422\n",
      "The representation loss after processing this batch is:  0.002443447709083557\n",
      "\n",
      "The classification loss after processing this batch is:  0.1010562852025032\n",
      "The representation loss after processing this batch is:  0.0028488263487815857\n",
      "\n",
      "The classification loss after processing this batch is:  0.09963592886924744\n",
      "The representation loss after processing this batch is:  0.0024661272764205933\n",
      "\n",
      "The classification loss after processing this batch is:  0.05626321956515312\n",
      "The representation loss after processing this batch is:  0.0023282766342163086\n",
      "\n",
      "The classification loss after processing this batch is:  0.04080018773674965\n",
      "The representation loss after processing this batch is:  0.0024259723722934723\n",
      "\n",
      "The classification loss after processing this batch is:  0.046643033623695374\n",
      "The representation loss after processing this batch is:  0.002590164542198181\n",
      "\n",
      "The classification loss after processing this batch is:  0.03541900962591171\n",
      "The representation loss after processing this batch is:  0.0026230663061141968\n",
      "\n",
      "The classification loss after processing this batch is:  0.12261691689491272\n",
      "The representation loss after processing this batch is:  0.0024953484535217285\n",
      "\n",
      "The classification loss after processing this batch is:  0.11750485748052597\n",
      "The representation loss after processing this batch is:  0.0027207955718040466\n",
      "\n",
      "The classification loss after processing this batch is:  0.052947647869586945\n",
      "The representation loss after processing this batch is:  0.0024527236819267273\n",
      "\n",
      "The classification loss after processing this batch is:  0.13562406599521637\n",
      "The representation loss after processing this batch is:  0.0025129057466983795\n",
      "\n",
      "The classification loss after processing this batch is:  0.057269804179668427\n",
      "The representation loss after processing this batch is:  0.0023450031876564026\n",
      "\n",
      "The classification loss after processing this batch is:  0.12691450119018555\n",
      "The representation loss after processing this batch is:  0.0023721307516098022\n",
      "\n",
      "The classification loss after processing this batch is:  0.16743426024913788\n",
      "The representation loss after processing this batch is:  0.002674482762813568\n",
      "\n",
      "The classification loss after processing this batch is:  0.08368311822414398\n",
      "The representation loss after processing this batch is:  0.002582438290119171\n",
      "\n",
      "The classification loss after processing this batch is:  0.16917340457439423\n",
      "The representation loss after processing this batch is:  0.0023306086659431458\n",
      "\n",
      "The classification loss after processing this batch is:  0.11662468314170837\n",
      "The representation loss after processing this batch is:  0.002215184271335602\n",
      "\n",
      "The classification loss after processing this batch is:  0.14825208485126495\n",
      "The representation loss after processing this batch is:  0.0023744776844978333\n",
      "\n",
      "The classification loss after processing this batch is:  0.11480115354061127\n",
      "The representation loss after processing this batch is:  0.002315431833267212\n",
      "\n",
      "The classification loss after processing this batch is:  0.06908595561981201\n",
      "The representation loss after processing this batch is:  0.0026348084211349487\n",
      "\n",
      "The classification loss after processing this batch is:  0.10701999813318253\n",
      "The representation loss after processing this batch is:  0.0021370835602283478\n",
      "\n",
      "The classification loss after processing this batch is:  0.10050778090953827\n",
      "The representation loss after processing this batch is:  0.002751089632511139\n",
      "\n",
      "The classification loss after processing this batch is:  0.15248793363571167\n",
      "The representation loss after processing this batch is:  0.0025842487812042236\n",
      "\n",
      "The classification loss after processing this batch is:  0.10693872720003128\n",
      "The representation loss after processing this batch is:  0.0024655312299728394\n",
      "\n",
      "The classification loss after processing this batch is:  0.06357646733522415\n",
      "The representation loss after processing this batch is:  0.002423122525215149\n",
      "\n",
      "The classification loss after processing this batch is:  0.09810115396976471\n",
      "The representation loss after processing this batch is:  0.0024296045303344727\n",
      "\n",
      "The classification loss after processing this batch is:  0.1901174634695053\n",
      "The representation loss after processing this batch is:  0.0023100078105926514\n",
      "\n",
      "The classification loss after processing this batch is:  0.07268750667572021\n",
      "The representation loss after processing this batch is:  0.0025510042905807495\n",
      "\n",
      "The classification loss after processing this batch is:  0.11137323826551437\n",
      "The representation loss after processing this batch is:  0.0023530200123786926\n",
      "\n",
      "The classification loss after processing this batch is:  0.09629093110561371\n",
      "The representation loss after processing this batch is:  0.0022082850337028503\n",
      "\n",
      "The classification loss after processing this batch is:  0.07526692748069763\n",
      "The representation loss after processing this batch is:  0.0028438717126846313\n",
      "\n",
      "The classification loss after processing this batch is:  0.04534837231040001\n",
      "The representation loss after processing this batch is:  0.0029106587171554565\n",
      "\n",
      "The classification loss after processing this batch is:  0.09195581823587418\n",
      "The representation loss after processing this batch is:  0.0028637275099754333\n",
      "\n",
      "The classification loss after processing this batch is:  0.09937730431556702\n",
      "The representation loss after processing this batch is:  0.00261533260345459\n",
      "\n",
      "The classification loss after processing this batch is:  0.09000632166862488\n",
      "The representation loss after processing this batch is:  0.0024067535996437073\n",
      "\n",
      "The classification loss after processing this batch is:  0.1367259919643402\n",
      "The representation loss after processing this batch is:  0.0027643218636512756\n",
      "\n",
      "The classification loss after processing this batch is:  0.12559464573860168\n",
      "The representation loss after processing this batch is:  0.002636462450027466\n",
      "\n",
      "The classification loss after processing this batch is:  0.13684839010238647\n",
      "The representation loss after processing this batch is:  0.0021422654390335083\n",
      "\n",
      "The classification loss after processing this batch is:  0.14428822696208954\n",
      "The representation loss after processing this batch is:  0.0028975605964660645\n",
      "\n",
      "The classification loss after processing this batch is:  0.048337116837501526\n",
      "The representation loss after processing this batch is:  0.002661481499671936\n",
      "\n",
      "The classification loss after processing this batch is:  0.04669065773487091\n",
      "The representation loss after processing this batch is:  0.0024428777396678925\n",
      "\n",
      "The classification loss after processing this batch is:  0.08470512181520462\n",
      "The representation loss after processing this batch is:  0.002475641667842865\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.09871505945920944\n",
      "The representation loss after processing this batch is:  0.002581387758255005\n",
      "\n",
      "The classification loss after processing this batch is:  0.0880156010389328\n",
      "The representation loss after processing this batch is:  0.002402663230895996\n",
      "\n",
      "The classification loss after processing this batch is:  0.10855700820684433\n",
      "The representation loss after processing this batch is:  0.0025469064712524414\n",
      "\n",
      "The classification loss after processing this batch is:  0.11282970756292343\n",
      "The representation loss after processing this batch is:  0.002898193895816803\n",
      "\n",
      "The classification loss after processing this batch is:  0.12595096230506897\n",
      "The representation loss after processing this batch is:  0.002748914062976837\n",
      "\n",
      "The classification loss after processing this batch is:  0.15457411110401154\n",
      "The representation loss after processing this batch is:  0.002410411834716797\n",
      "\n",
      "The classification loss after processing this batch is:  0.14169812202453613\n",
      "The representation loss after processing this batch is:  0.0024844929575920105\n",
      "\n",
      "The classification loss after processing this batch is:  0.14009317755699158\n",
      "The representation loss after processing this batch is:  0.002241067588329315\n",
      "\n",
      "The classification loss after processing this batch is:  0.06304109841585159\n",
      "The representation loss after processing this batch is:  0.0028530657291412354\n",
      "\n",
      "The classification loss after processing this batch is:  0.04017139598727226\n",
      "The representation loss after processing this batch is:  0.0026761889457702637\n",
      "\n",
      "The classification loss after processing this batch is:  0.13194799423217773\n",
      "The representation loss after processing this batch is:  0.0022597983479499817\n",
      "\n",
      "The classification loss after processing this batch is:  0.18030914664268494\n",
      "The representation loss after processing this batch is:  0.0022898614406585693\n",
      "\n",
      "The classification loss after processing this batch is:  0.1428777426481247\n",
      "The representation loss after processing this batch is:  0.002525418996810913\n",
      "\n",
      "The classification loss after processing this batch is:  0.13016363978385925\n",
      "The representation loss after processing this batch is:  0.0024493634700775146\n",
      "\n",
      "The classification loss after processing this batch is:  0.12443779408931732\n",
      "The representation loss after processing this batch is:  0.0024437308311462402\n",
      "\n",
      "The classification loss after processing this batch is:  0.1778685301542282\n",
      "The representation loss after processing this batch is:  0.002500683069229126\n",
      "\n",
      "The classification loss after processing this batch is:  0.18878643214702606\n",
      "The representation loss after processing this batch is:  0.0024476833641529083\n",
      "\n",
      "The classification loss after processing this batch is:  0.19313764572143555\n",
      "The representation loss after processing this batch is:  0.0026286691427230835\n",
      "\n",
      "The classification loss after processing this batch is:  0.14970555901527405\n",
      "The representation loss after processing this batch is:  0.0025752708315849304\n",
      "\n",
      "The classification loss after processing this batch is:  0.10493551939725876\n",
      "The representation loss after processing this batch is:  0.003178432583808899\n",
      "\n",
      "The classification loss after processing this batch is:  0.07264881581068039\n",
      "The representation loss after processing this batch is:  0.002936922013759613\n",
      "\n",
      "The classification loss after processing this batch is:  0.09966053813695908\n",
      "The representation loss after processing this batch is:  0.002544235438108444\n",
      "\n",
      "The classification loss after processing this batch is:  0.08380261063575745\n",
      "The representation loss after processing this batch is:  0.002252809703350067\n",
      "\n",
      "The classification loss after processing this batch is:  0.06315037608146667\n",
      "The representation loss after processing this batch is:  0.002384323626756668\n",
      "\n",
      "The classification loss after processing this batch is:  0.04067997261881828\n",
      "The representation loss after processing this batch is:  0.0024104565382003784\n",
      "\n",
      "The classification loss after processing this batch is:  0.12928853929042816\n",
      "The representation loss after processing this batch is:  0.0024199113249778748\n",
      "\n",
      "The classification loss after processing this batch is:  0.05989690497517586\n",
      "The representation loss after processing this batch is:  0.002603575587272644\n",
      "\n",
      "The classification loss after processing this batch is:  0.0853692963719368\n",
      "The representation loss after processing this batch is:  0.0027985386550426483\n",
      "\n",
      "The classification loss after processing this batch is:  0.08788199722766876\n",
      "The representation loss after processing this batch is:  0.0021128207445144653\n",
      "\n",
      "The classification loss after processing this batch is:  0.07246889173984528\n",
      "The representation loss after processing this batch is:  0.0023604296147823334\n",
      "\n",
      "The classification loss after processing this batch is:  0.07142875343561172\n",
      "The representation loss after processing this batch is:  0.0026393085718154907\n",
      "\n",
      "The classification loss after processing this batch is:  0.08197510242462158\n",
      "The representation loss after processing this batch is:  0.00241871178150177\n",
      "\n",
      "The classification loss after processing this batch is:  0.12450920790433884\n",
      "The representation loss after processing this batch is:  0.0028160586953163147\n",
      "\n",
      "The classification loss after processing this batch is:  0.032280635088682175\n",
      "The representation loss after processing this batch is:  0.002751484513282776\n",
      "\n",
      "The classification loss after processing this batch is:  0.03757264092564583\n",
      "The representation loss after processing this batch is:  0.0026816576719284058\n",
      "\n",
      "The classification loss after processing this batch is:  0.12908820807933807\n",
      "The representation loss after processing this batch is:  0.0024303868412971497\n",
      "\n",
      "The classification loss after processing this batch is:  0.16010917723178864\n",
      "The representation loss after processing this batch is:  0.0024313442409038544\n",
      "\n",
      "The classification loss after processing this batch is:  0.10138265788555145\n",
      "The representation loss after processing this batch is:  0.0025076791644096375\n",
      "\n",
      "The classification loss after processing this batch is:  0.042247552424669266\n",
      "The representation loss after processing this batch is:  0.0022617094218730927\n",
      "\n",
      "The classification loss after processing this batch is:  0.09895072132349014\n",
      "The representation loss after processing this batch is:  0.002404250204563141\n",
      "\n",
      "The classification loss after processing this batch is:  0.021747462451457977\n",
      "The representation loss after processing this batch is:  0.0025971904397010803\n",
      "\n",
      "The classification loss after processing this batch is:  0.11036261171102524\n",
      "The representation loss after processing this batch is:  0.002440527081489563\n",
      "\n",
      "The classification loss after processing this batch is:  0.09282811731100082\n",
      "The representation loss after processing this batch is:  0.0026264488697052\n",
      "\n",
      "The classification loss after processing this batch is:  0.06037352234125137\n",
      "The representation loss after processing this batch is:  0.002286061644554138\n",
      "\n",
      "The classification loss after processing this batch is:  0.059199556708335876\n",
      "The representation loss after processing this batch is:  0.002594493329524994\n",
      "\n",
      "The classification loss after processing this batch is:  0.08828452229499817\n",
      "The representation loss after processing this batch is:  0.0024809837341308594\n",
      "\n",
      "The classification loss after processing this batch is:  0.05959325656294823\n",
      "The representation loss after processing this batch is:  0.002396024763584137\n",
      "\n",
      "The classification loss after processing this batch is:  0.18288065493106842\n",
      "The representation loss after processing this batch is:  0.0025306567549705505\n",
      "\n",
      "The classification loss after processing this batch is:  0.24411895871162415\n",
      "The representation loss after processing this batch is:  0.002445947378873825\n",
      "\n",
      "The classification loss after processing this batch is:  0.17088550329208374\n",
      "The representation loss after processing this batch is:  0.0023368820548057556\n",
      "\n",
      "The classification loss after processing this batch is:  0.1888055056333542\n",
      "The representation loss after processing this batch is:  0.0024535804986953735\n",
      "\n",
      "The classification loss after processing this batch is:  0.11097244173288345\n",
      "The representation loss after processing this batch is:  0.0024823397397994995\n",
      "\n",
      "The classification loss after processing this batch is:  0.06579138338565826\n",
      "The representation loss after processing this batch is:  0.0023719295859336853\n",
      "\n",
      "The classification loss after processing this batch is:  0.16909722983837128\n",
      "The representation loss after processing this batch is:  0.0023202449083328247\n",
      "\n",
      "The classification loss after processing this batch is:  0.11903771013021469\n",
      "The representation loss after processing this batch is:  0.002557426691055298\n",
      "\n",
      "The classification loss after processing this batch is:  0.11052083969116211\n",
      "The representation loss after processing this batch is:  0.0025293566286563873\n",
      "\n",
      "The classification loss after processing this batch is:  0.12860816717147827\n",
      "The representation loss after processing this batch is:  0.0026931539177894592\n",
      "\n",
      "The classification loss after processing this batch is:  0.13766010105609894\n",
      "The representation loss after processing this batch is:  0.002415008842945099\n",
      "\n",
      "The classification loss after processing this batch is:  0.06776648014783859\n",
      "The representation loss after processing this batch is:  0.0024159736931324005\n",
      "\n",
      "The classification loss after processing this batch is:  0.0859045684337616\n",
      "The representation loss after processing this batch is:  0.0026266947388648987\n",
      "\n",
      "The classification loss after processing this batch is:  0.1227336898446083\n",
      "The representation loss after processing this batch is:  0.002447865903377533\n",
      "\n",
      "The classification loss after processing this batch is:  0.043553903698921204\n",
      "The representation loss after processing this batch is:  0.0025779902935028076\n",
      "\n",
      "The classification loss after processing this batch is:  0.04483567923307419\n",
      "The representation loss after processing this batch is:  0.0026021115481853485\n",
      "\n",
      "The classification loss after processing this batch is:  0.10275901854038239\n",
      "The representation loss after processing this batch is:  0.002381332218647003\n",
      "\n",
      "The classification loss after processing this batch is:  0.1601613610982895\n",
      "The representation loss after processing this batch is:  0.002410888671875\n",
      "\n",
      "The classification loss after processing this batch is:  0.04833171144127846\n",
      "The representation loss after processing this batch is:  0.0023039281368255615\n",
      "\n",
      "The classification loss after processing this batch is:  0.057198844850063324\n",
      "The representation loss after processing this batch is:  0.002284027636051178\n",
      "\n",
      "The classification loss after processing this batch is:  0.1429869383573532\n",
      "The representation loss after processing this batch is:  0.00235738605260849\n",
      "\n",
      "The classification loss after processing this batch is:  0.18036715686321259\n",
      "The representation loss after processing this batch is:  0.002300180494785309\n",
      "\n",
      "The classification loss after processing this batch is:  0.06998293846845627\n",
      "The representation loss after processing this batch is:  0.0022112205624580383\n",
      "\n",
      "The classification loss after processing this batch is:  0.166522815823555\n",
      "The representation loss after processing this batch is:  0.0022283345460891724\n",
      "\n",
      "The classification loss after processing this batch is:  0.05866895616054535\n",
      "The representation loss after processing this batch is:  0.0027062371373176575\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.03034580871462822\n",
      "The representation loss after processing this batch is:  0.002391993999481201\n",
      "\n",
      "The classification loss after processing this batch is:  0.0413304902613163\n",
      "The representation loss after processing this batch is:  0.002395942807197571\n",
      "\n",
      "The classification loss after processing this batch is:  0.12725792825222015\n",
      "The representation loss after processing this batch is:  0.002947300672531128\n",
      "\n",
      "The classification loss after processing this batch is:  0.14113740622997284\n",
      "The representation loss after processing this batch is:  0.002563163638114929\n",
      "\n",
      "The classification loss after processing this batch is:  0.06731978058815002\n",
      "The representation loss after processing this batch is:  0.0031537413597106934\n",
      "\n",
      "The classification loss after processing this batch is:  0.08672479540109634\n",
      "The representation loss after processing this batch is:  0.0022759661078453064\n",
      "\n",
      "The classification loss after processing this batch is:  0.05245495215058327\n",
      "The representation loss after processing this batch is:  0.0026073381304740906\n",
      "\n",
      "The classification loss after processing this batch is:  0.12573857605457306\n",
      "The representation loss after processing this batch is:  0.0025438517332077026\n",
      "\n",
      "The classification loss after processing this batch is:  0.09053104370832443\n",
      "The representation loss after processing this batch is:  0.0022560618817806244\n",
      "\n",
      "The classification loss after processing this batch is:  0.14244778454303741\n",
      "The representation loss after processing this batch is:  0.002389427274465561\n",
      "\n",
      "The classification loss after processing this batch is:  0.14069604873657227\n",
      "The representation loss after processing this batch is:  0.0026134848594665527\n",
      "\n",
      "The classification loss after processing this batch is:  0.2303219437599182\n",
      "The representation loss after processing this batch is:  0.0021527335047721863\n",
      "\n",
      "The classification loss after processing this batch is:  0.10580452531576157\n",
      "The representation loss after processing this batch is:  0.0022028014063835144\n",
      "\n",
      "The classification loss after processing this batch is:  0.15811491012573242\n",
      "The representation loss after processing this batch is:  0.002328529953956604\n",
      "\n",
      "The classification loss after processing this batch is:  0.15023747086524963\n",
      "The representation loss after processing this batch is:  0.0024731308221817017\n",
      "\n",
      "The classification loss after processing this batch is:  0.06914785504341125\n",
      "The representation loss after processing this batch is:  0.0024572908878326416\n",
      "\n",
      "The classification loss after processing this batch is:  0.09392783790826797\n",
      "The representation loss after processing this batch is:  0.002849724143743515\n",
      "\n",
      "The classification loss after processing this batch is:  0.05382617190480232\n",
      "The representation loss after processing this batch is:  0.002543807029724121\n",
      "\n",
      "The classification loss after processing this batch is:  0.1031109020113945\n",
      "The representation loss after processing this batch is:  0.0022880621254444122\n",
      "\n",
      "The classification loss after processing this batch is:  0.0964735895395279\n",
      "The representation loss after processing this batch is:  0.002097535878419876\n",
      "\n",
      "The classification loss after processing this batch is:  0.08949264138936996\n",
      "The representation loss after processing this batch is:  0.002297438681125641\n",
      "\n",
      "The classification loss after processing this batch is:  0.09637103974819183\n",
      "The representation loss after processing this batch is:  0.002440527081489563\n",
      "\n",
      "The classification loss after processing this batch is:  0.12235307693481445\n",
      "The representation loss after processing this batch is:  0.0023005902767181396\n",
      "\n",
      "The classification loss after processing this batch is:  0.09892386943101883\n",
      "The representation loss after processing this batch is:  0.0023169219493865967\n",
      "\n",
      "The classification loss after processing this batch is:  0.14482150971889496\n",
      "The representation loss after processing this batch is:  0.002461947500705719\n",
      "\n",
      "The classification loss after processing this batch is:  0.08003242313861847\n",
      "The representation loss after processing this batch is:  0.0026141852140426636\n",
      "\n",
      "The classification loss after processing this batch is:  0.08011791110038757\n",
      "The representation loss after processing this batch is:  0.002110682427883148\n",
      "\n",
      "The classification loss after processing this batch is:  0.07295751571655273\n",
      "The representation loss after processing this batch is:  0.002741403877735138\n",
      "\n",
      "The classification loss after processing this batch is:  0.1653381884098053\n",
      "The representation loss after processing this batch is:  0.00307561457157135\n",
      "\n",
      "The classification loss after processing this batch is:  0.25642678141593933\n",
      "The representation loss after processing this batch is:  0.0027462467551231384\n",
      "\n",
      "The classification loss after processing this batch is:  0.033228516578674316\n",
      "The representation loss after processing this batch is:  0.0023012906312942505\n",
      "\n",
      "The classification loss after processing this batch is:  0.058942362666130066\n",
      "The representation loss after processing this batch is:  0.002411492168903351\n",
      "\n",
      "The classification loss after processing this batch is:  0.18840520083904266\n",
      "The representation loss after processing this batch is:  0.002916526049375534\n",
      "\n",
      "The classification loss after processing this batch is:  0.04071174934506416\n",
      "The representation loss after processing this batch is:  0.002725042402744293\n",
      "\n",
      "The classification loss after processing this batch is:  0.0524260476231575\n",
      "The representation loss after processing this batch is:  0.002318546175956726\n",
      "\n",
      "The classification loss after processing this batch is:  0.11549755930900574\n",
      "The representation loss after processing this batch is:  0.00266459584236145\n",
      "\n",
      "The classification loss after processing this batch is:  0.06701996177434921\n",
      "The representation loss after processing this batch is:  0.0026665478944778442\n",
      "\n",
      "The classification loss after processing this batch is:  0.13903674483299255\n",
      "The representation loss after processing this batch is:  0.0030483752489089966\n",
      "\n",
      "The classification loss after processing this batch is:  0.10095904022455215\n",
      "The representation loss after processing this batch is:  0.0028826892375946045\n",
      "\n",
      "The classification loss after processing this batch is:  0.12040247768163681\n",
      "The representation loss after processing this batch is:  0.0028650909662246704\n",
      "\n",
      "The classification loss after processing this batch is:  0.08757340162992477\n",
      "The representation loss after processing this batch is:  0.002124570310115814\n",
      "\n",
      "The classification loss after processing this batch is:  0.13060890138149261\n",
      "The representation loss after processing this batch is:  0.00226544588804245\n",
      "\n",
      "The classification loss after processing this batch is:  0.032167237251996994\n",
      "The representation loss after processing this batch is:  0.00236472487449646\n",
      "\n",
      "The classification loss after processing this batch is:  0.03586500883102417\n",
      "The representation loss after processing this batch is:  0.0024794861674308777\n",
      "\n",
      "The classification loss after processing this batch is:  0.10293202102184296\n",
      "The representation loss after processing this batch is:  0.0025428608059883118\n",
      "\n",
      "The classification loss after processing this batch is:  0.0652448907494545\n",
      "The representation loss after processing this batch is:  0.002512328326702118\n",
      "\n",
      "The classification loss after processing this batch is:  0.09270892292261124\n",
      "The representation loss after processing this batch is:  0.002283599227666855\n",
      "\n",
      "The classification loss after processing this batch is:  0.054461877793073654\n",
      "The representation loss after processing this batch is:  0.0023274794220924377\n",
      "\n",
      "The classification loss after processing this batch is:  0.06462665647268295\n",
      "The representation loss after processing this batch is:  0.002501174807548523\n",
      "\n",
      "The classification loss after processing this batch is:  0.10412070155143738\n",
      "The representation loss after processing this batch is:  0.0023733600974082947\n",
      "\n",
      "The classification loss after processing this batch is:  0.15470574796199799\n",
      "The representation loss after processing this batch is:  0.002826482057571411\n",
      "\n",
      "The classification loss after processing this batch is:  0.16003964841365814\n",
      "The representation loss after processing this batch is:  0.0023733042180538177\n",
      "\n",
      "The classification loss after processing this batch is:  0.0669419914484024\n",
      "The representation loss after processing this batch is:  0.002666465938091278\n",
      "\n",
      "The classification loss after processing this batch is:  0.1689954400062561\n",
      "The representation loss after processing this batch is:  0.0023693107068538666\n",
      "\n",
      "The classification loss after processing this batch is:  0.05985131487250328\n",
      "The representation loss after processing this batch is:  0.002273149788379669\n",
      "\n",
      "The classification loss after processing this batch is:  0.1233174279332161\n",
      "The representation loss after processing this batch is:  0.0024221017956733704\n",
      "\n",
      "The classification loss after processing this batch is:  0.2101912796497345\n",
      "The representation loss after processing this batch is:  0.002818576991558075\n",
      "\n",
      "The classification loss after processing this batch is:  0.09309694916009903\n",
      "The representation loss after processing this batch is:  0.002304941415786743\n",
      "\n",
      "The classification loss after processing this batch is:  0.135851189494133\n",
      "The representation loss after processing this batch is:  0.002307537943124771\n",
      "\n",
      "The classification loss after processing this batch is:  0.10051249712705612\n",
      "The representation loss after processing this batch is:  0.002346031367778778\n",
      "\n",
      "The classification loss after processing this batch is:  0.16360297799110413\n",
      "The representation loss after processing this batch is:  0.002326603978872299\n",
      "\n",
      "The classification loss after processing this batch is:  0.09693817794322968\n",
      "The representation loss after processing this batch is:  0.002424180507659912\n",
      "\n",
      "The classification loss after processing this batch is:  0.07776443660259247\n",
      "The representation loss after processing this batch is:  0.0024400129914283752\n",
      "\n",
      "The classification loss after processing this batch is:  0.09497307986021042\n",
      "The representation loss after processing this batch is:  0.0025739669799804688\n",
      "\n",
      "The classification loss after processing this batch is:  0.0463232584297657\n",
      "The representation loss after processing this batch is:  0.0025218352675437927\n",
      "\n",
      "The classification loss after processing this batch is:  0.03711284324526787\n",
      "The representation loss after processing this batch is:  0.002208396792411804\n",
      "\n",
      "The classification loss after processing this batch is:  0.10733318328857422\n",
      "The representation loss after processing this batch is:  0.002856642007827759\n",
      "\n",
      "The classification loss after processing this batch is:  0.041580282151699066\n",
      "The representation loss after processing this batch is:  0.0027845650911331177\n",
      "\n",
      "The classification loss after processing this batch is:  0.17172005772590637\n",
      "The representation loss after processing this batch is:  0.0027778297662734985\n",
      "\n",
      "The classification loss after processing this batch is:  0.0792693942785263\n",
      "The representation loss after processing this batch is:  0.0023922473192214966\n",
      "\n",
      "The classification loss after processing this batch is:  0.1817718893289566\n",
      "The representation loss after processing this batch is:  0.0023924708366394043\n",
      "\n",
      "The classification loss after processing this batch is:  0.23800724744796753\n",
      "The representation loss after processing this batch is:  0.002268292009830475\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.12728027999401093\n",
      "The representation loss after processing this batch is:  0.0022283457219600677\n",
      "\n",
      "The classification loss after processing this batch is:  0.03878537565469742\n",
      "The representation loss after processing this batch is:  0.002687554806470871\n",
      "\n",
      "The classification loss after processing this batch is:  0.05858088657259941\n",
      "The representation loss after processing this batch is:  0.0026418641209602356\n",
      "\n",
      "The classification loss after processing this batch is:  0.04414888098835945\n",
      "The representation loss after processing this batch is:  0.0028552263975143433\n",
      "\n",
      "The classification loss after processing this batch is:  0.07230522483587265\n",
      "The representation loss after processing this batch is:  0.002681717276573181\n",
      "\n",
      "The classification loss after processing this batch is:  0.09054703265428543\n",
      "The representation loss after processing this batch is:  0.0020802393555641174\n",
      "\n",
      "The classification loss after processing this batch is:  0.228150874376297\n",
      "The representation loss after processing this batch is:  0.0023902319371700287\n",
      "\n",
      "The classification loss after processing this batch is:  0.1630839705467224\n",
      "The representation loss after processing this batch is:  0.00225675106048584\n",
      "\n",
      "The classification loss after processing this batch is:  0.09223343431949615\n",
      "The representation loss after processing this batch is:  0.002823777496814728\n",
      "\n",
      "The classification loss after processing this batch is:  0.20996178686618805\n",
      "The representation loss after processing this batch is:  0.002937406301498413\n",
      "\n",
      "The classification loss after processing this batch is:  0.05110417678952217\n",
      "The representation loss after processing this batch is:  0.002538233995437622\n",
      "\n",
      "The classification loss after processing this batch is:  0.08227851986885071\n",
      "The representation loss after processing this batch is:  0.0025412142276763916\n",
      "\n",
      "The classification loss after processing this batch is:  0.14686593413352966\n",
      "The representation loss after processing this batch is:  0.0024651624262332916\n",
      "\n",
      "The classification loss after processing this batch is:  0.08546523749828339\n",
      "The representation loss after processing this batch is:  0.00281514972448349\n",
      "\n",
      "The classification loss after processing this batch is:  0.1192929670214653\n",
      "The representation loss after processing this batch is:  0.003186821937561035\n",
      "\n",
      "The classification loss after processing this batch is:  0.07956529408693314\n",
      "The representation loss after processing this batch is:  0.0027311332523822784\n",
      "\n",
      "The classification loss after processing this batch is:  0.10267516225576401\n",
      "The representation loss after processing this batch is:  0.0030045732855796814\n",
      "\n",
      "The classification loss after processing this batch is:  0.16868847608566284\n",
      "The representation loss after processing this batch is:  0.0028228759765625\n",
      "\n",
      "The classification loss after processing this batch is:  0.06888330727815628\n",
      "The representation loss after processing this batch is:  0.002961955964565277\n",
      "\n",
      "The classification loss after processing this batch is:  0.15100784599781036\n",
      "The representation loss after processing this batch is:  0.0024066120386123657\n",
      "\n",
      "The classification loss after processing this batch is:  0.1829693764448166\n",
      "The representation loss after processing this batch is:  0.0022138357162475586\n",
      "\n",
      "The classification loss after processing this batch is:  0.10289125144481659\n",
      "The representation loss after processing this batch is:  0.00237119197845459\n",
      "\n",
      "The classification loss after processing this batch is:  0.12161394208669662\n",
      "The representation loss after processing this batch is:  0.002189159393310547\n",
      "\n",
      "The classification loss after processing this batch is:  0.07008005678653717\n",
      "The representation loss after processing this batch is:  0.0029201582074165344\n",
      "\n",
      "The classification loss after processing this batch is:  0.030930161476135254\n",
      "The representation loss after processing this batch is:  0.002550363540649414\n",
      "\n",
      "The classification loss after processing this batch is:  0.11018975079059601\n",
      "The representation loss after processing this batch is:  0.0027037113904953003\n",
      "\n",
      "The classification loss after processing this batch is:  0.05389996990561485\n",
      "The representation loss after processing this batch is:  0.0026934444904327393\n",
      "\n",
      "The classification loss after processing this batch is:  0.22820907831192017\n",
      "The representation loss after processing this batch is:  0.002258915454149246\n",
      "\n",
      "The classification loss after processing this batch is:  0.04048304632306099\n",
      "The representation loss after processing this batch is:  0.002737961709499359\n",
      "\n",
      "The classification loss after processing this batch is:  0.09650818258523941\n",
      "The representation loss after processing this batch is:  0.002281472086906433\n",
      "\n",
      "The classification loss after processing this batch is:  0.14567427337169647\n",
      "The representation loss after processing this batch is:  0.002465754747390747\n",
      "\n",
      "The classification loss after processing this batch is:  0.11502090841531754\n",
      "The representation loss after processing this batch is:  0.002308659255504608\n",
      "\n",
      "The classification loss after processing this batch is:  0.10304693132638931\n",
      "The representation loss after processing this batch is:  0.002504006028175354\n",
      "\n",
      "The classification loss after processing this batch is:  0.05477927625179291\n",
      "The representation loss after processing this batch is:  0.002428881824016571\n",
      "\n",
      "The classification loss after processing this batch is:  0.055635835975408554\n",
      "The representation loss after processing this batch is:  0.0022701770067214966\n",
      "\n",
      "The classification loss after processing this batch is:  0.04209158569574356\n",
      "The representation loss after processing this batch is:  0.002398185431957245\n",
      "\n",
      "The classification loss after processing this batch is:  0.142635315656662\n",
      "The representation loss after processing this batch is:  0.00338677316904068\n",
      "\n",
      "The classification loss after processing this batch is:  0.14932836592197418\n",
      "The representation loss after processing this batch is:  0.0026380233466625214\n",
      "\n",
      "The classification loss after processing this batch is:  0.13778969645500183\n",
      "The representation loss after processing this batch is:  0.002150803804397583\n",
      "\n",
      "The classification loss after processing this batch is:  0.15375962853431702\n",
      "The representation loss after processing this batch is:  0.002305328845977783\n",
      "\n",
      "The classification loss after processing this batch is:  0.27544212341308594\n",
      "The representation loss after processing this batch is:  0.002268899232149124\n",
      "\n",
      "The classification loss after processing this batch is:  0.0956258624792099\n",
      "The representation loss after processing this batch is:  0.0028518959879875183\n",
      "\n",
      "The classification loss after processing this batch is:  0.1892043948173523\n",
      "The representation loss after processing this batch is:  0.002523556351661682\n",
      "\n",
      "The classification loss after processing this batch is:  0.09910504519939423\n",
      "The representation loss after processing this batch is:  0.002499908208847046\n",
      "\n",
      "The classification loss after processing this batch is:  0.0774499699473381\n",
      "The representation loss after processing this batch is:  0.0024249404668807983\n",
      "\n",
      "The classification loss after processing this batch is:  0.044616520404815674\n",
      "The representation loss after processing this batch is:  0.0022474750876426697\n",
      "\n",
      "The classification loss after processing this batch is:  0.056815873831510544\n",
      "The representation loss after processing this batch is:  0.0025031492114067078\n",
      "\n",
      "The classification loss after processing this batch is:  0.21004413068294525\n",
      "The representation loss after processing this batch is:  0.0025793835520744324\n",
      "\n",
      "The classification loss after processing this batch is:  0.09109923243522644\n",
      "The representation loss after processing this batch is:  0.0025632083415985107\n",
      "\n",
      "The classification loss after processing this batch is:  0.1035541519522667\n",
      "The representation loss after processing this batch is:  0.0028657838702201843\n",
      "\n",
      "The classification loss after processing this batch is:  0.09265771508216858\n",
      "The representation loss after processing this batch is:  0.002863384783267975\n",
      "\n",
      "The classification loss after processing this batch is:  0.07651591300964355\n",
      "The representation loss after processing this batch is:  0.002634301781654358\n",
      "\n",
      "The classification loss after processing this batch is:  0.056811682879924774\n",
      "The representation loss after processing this batch is:  0.002498447895050049\n",
      "\n",
      "The classification loss after processing this batch is:  0.1507137417793274\n",
      "The representation loss after processing this batch is:  0.002334579825401306\n",
      "\n",
      "The classification loss after processing this batch is:  0.19000305235385895\n",
      "The representation loss after processing this batch is:  0.0024138502776622772\n",
      "\n",
      "The classification loss after processing this batch is:  0.15402092039585114\n",
      "The representation loss after processing this batch is:  0.002739354968070984\n",
      "\n",
      "The classification loss after processing this batch is:  0.10031728446483612\n",
      "The representation loss after processing this batch is:  0.0023464933037757874\n",
      "\n",
      "The classification loss after processing this batch is:  0.28615903854370117\n",
      "The representation loss after processing this batch is:  0.0021044984459877014\n",
      "\n",
      "The classification loss after processing this batch is:  0.07213146239519119\n",
      "The representation loss after processing this batch is:  0.002251420170068741\n",
      "\n",
      "The classification loss after processing this batch is:  0.09973860532045364\n",
      "The representation loss after processing this batch is:  0.002263162285089493\n",
      "\n",
      "The classification loss after processing this batch is:  0.10899534821510315\n",
      "The representation loss after processing this batch is:  0.0028695575892925262\n",
      "\n",
      "The classification loss after processing this batch is:  0.07409859448671341\n",
      "The representation loss after processing this batch is:  0.0023353099822998047\n",
      "\n",
      "The classification loss after processing this batch is:  0.12781420350074768\n",
      "The representation loss after processing this batch is:  0.002436041831970215\n",
      "\n",
      "The classification loss after processing this batch is:  0.06206747144460678\n",
      "The representation loss after processing this batch is:  0.002677217125892639\n",
      "\n",
      "The classification loss after processing this batch is:  0.13775093853473663\n",
      "The representation loss after processing this batch is:  0.0024607032537460327\n",
      "\n",
      "The classification loss after processing this batch is:  0.1771457940340042\n",
      "The representation loss after processing this batch is:  0.0027095600962638855\n",
      "\n",
      "The classification loss after processing this batch is:  0.17416070401668549\n",
      "The representation loss after processing this batch is:  0.0025713667273521423\n",
      "\n",
      "The classification loss after processing this batch is:  0.0969172865152359\n",
      "The representation loss after processing this batch is:  0.002649463713169098\n",
      "\n",
      "The classification loss after processing this batch is:  0.07203590869903564\n",
      "The representation loss after processing this batch is:  0.002862684428691864\n",
      "\n",
      "The classification loss after processing this batch is:  0.14246805012226105\n",
      "The representation loss after processing this batch is:  0.002369314432144165\n",
      "\n",
      "The classification loss after processing this batch is:  0.1218625158071518\n",
      "The representation loss after processing this batch is:  0.0024503767490386963\n",
      "\n",
      "The classification loss after processing this batch is:  0.022970501333475113\n",
      "The representation loss after processing this batch is:  0.0024320557713508606\n",
      "\n",
      "The classification loss after processing this batch is:  0.1076257973909378\n",
      "The representation loss after processing this batch is:  0.0023470893502235413\n",
      "\n",
      "The classification loss after processing this batch is:  0.2106848508119583\n",
      "The representation loss after processing this batch is:  0.002680383622646332\n",
      "\n",
      "The classification loss after processing this batch is:  0.23907355964183807\n",
      "The representation loss after processing this batch is:  0.0026846975088119507\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.21331484615802765\n",
      "The representation loss after processing this batch is:  0.0023377053439617157\n",
      "\n",
      "The classification loss after processing this batch is:  0.17114077508449554\n",
      "The representation loss after processing this batch is:  0.002219218760728836\n",
      "\n",
      "The classification loss after processing this batch is:  0.0671691745519638\n",
      "The representation loss after processing this batch is:  0.002309221774339676\n",
      "\n",
      "The classification loss after processing this batch is:  0.1051037609577179\n",
      "The representation loss after processing this batch is:  0.0022524669766426086\n",
      "\n",
      "The classification loss after processing this batch is:  0.0955883041024208\n",
      "The representation loss after processing this batch is:  0.002669975161552429\n",
      "\n",
      "The classification loss after processing this batch is:  0.16403451561927795\n",
      "The representation loss after processing this batch is:  0.0027765631675720215\n",
      "\n",
      "The classification loss after processing this batch is:  0.11296723037958145\n",
      "The representation loss after processing this batch is:  0.002810433506965637\n",
      "\n",
      "The classification loss after processing this batch is:  0.12460365146398544\n",
      "The representation loss after processing this batch is:  0.0028537586331367493\n",
      "\n",
      "The classification loss after processing this batch is:  0.08309917896986008\n",
      "The representation loss after processing this batch is:  0.0025099702179431915\n",
      "\n",
      "The classification loss after processing this batch is:  0.05813407897949219\n",
      "The representation loss after processing this batch is:  0.0025055930018424988\n",
      "\n",
      "The classification loss after processing this batch is:  0.17397275567054749\n",
      "The representation loss after processing this batch is:  0.002673014998435974\n",
      "\n",
      "The classification loss after processing this batch is:  0.14140351116657257\n",
      "The representation loss after processing this batch is:  0.0023881345987319946\n",
      "\n",
      "The classification loss after processing this batch is:  0.09666359424591064\n",
      "The representation loss after processing this batch is:  0.0024421848356723785\n",
      "\n",
      "The classification loss after processing this batch is:  0.2040441781282425\n",
      "The representation loss after processing this batch is:  0.0031864717602729797\n",
      "\n",
      "The classification loss after processing this batch is:  0.25440162420272827\n",
      "The representation loss after processing this batch is:  0.002829909324645996\n",
      "\n",
      "The classification loss after processing this batch is:  0.14546598494052887\n",
      "The representation loss after processing this batch is:  0.0025874078273773193\n",
      "\n",
      "The classification loss after processing this batch is:  0.07964568585157394\n",
      "The representation loss after processing this batch is:  0.002630069851875305\n",
      "\n",
      "The classification loss after processing this batch is:  0.11354061961174011\n",
      "The representation loss after processing this batch is:  0.00268438458442688\n",
      "\n",
      "The classification loss after processing this batch is:  0.06047992408275604\n",
      "The representation loss after processing this batch is:  0.002715766429901123\n",
      "\n",
      "The classification loss after processing this batch is:  0.163730651140213\n",
      "The representation loss after processing this batch is:  0.0027027428150177\n",
      "\n",
      "The classification loss after processing this batch is:  0.12115989625453949\n",
      "The representation loss after processing this batch is:  0.0028023570775985718\n",
      "\n",
      "The classification loss after processing this batch is:  0.09734711796045303\n",
      "The representation loss after processing this batch is:  0.002848289906978607\n",
      "\n",
      "The classification loss after processing this batch is:  0.24336488544940948\n",
      "The representation loss after processing this batch is:  0.002381347119808197\n",
      "\n",
      "The classification loss after processing this batch is:  0.047422099858522415\n",
      "The representation loss after processing this batch is:  0.0025434941053390503\n",
      "\n",
      "The classification loss after processing this batch is:  0.05432639643549919\n",
      "The representation loss after processing this batch is:  0.0028381794691085815\n",
      "\n",
      "The classification loss after processing this batch is:  0.05026968941092491\n",
      "The representation loss after processing this batch is:  0.002299182116985321\n",
      "\n",
      "The classification loss after processing this batch is:  0.1372278332710266\n",
      "The representation loss after processing this batch is:  0.002341020852327347\n",
      "\n",
      "The classification loss after processing this batch is:  0.19198766350746155\n",
      "The representation loss after processing this batch is:  0.002443060278892517\n",
      "\n",
      "The classification loss after processing this batch is:  0.10202904790639877\n",
      "The representation loss after processing this batch is:  0.0022729262709617615\n",
      "\n",
      "The classification loss after processing this batch is:  0.1031409502029419\n",
      "The representation loss after processing this batch is:  0.0025030598044395447\n",
      "\n",
      "The classification loss after processing this batch is:  0.03548338636755943\n",
      "The representation loss after processing this batch is:  0.002227388322353363\n",
      "\n",
      "The classification loss after processing this batch is:  0.0787019282579422\n",
      "The representation loss after processing this batch is:  0.0023616254329681396\n",
      "\n",
      "The classification loss after processing this batch is:  0.06711382418870926\n",
      "The representation loss after processing this batch is:  0.002544999122619629\n",
      "\n",
      "The classification loss after processing this batch is:  0.03696624934673309\n",
      "The representation loss after processing this batch is:  0.002564840018749237\n",
      "\n",
      "The classification loss after processing this batch is:  0.08859454095363617\n",
      "The representation loss after processing this batch is:  0.0024088621139526367\n",
      "\n",
      "The classification loss after processing this batch is:  0.1621973067522049\n",
      "The representation loss after processing this batch is:  0.002290204167366028\n",
      "\n",
      "The classification loss after processing this batch is:  0.1920059621334076\n",
      "The representation loss after processing this batch is:  0.0023956000804901123\n",
      "\n",
      "The classification loss after processing this batch is:  0.023027006536722183\n",
      "The representation loss after processing this batch is:  0.0022857896983623505\n",
      "\n",
      "The classification loss after processing this batch is:  0.038468677550554276\n",
      "The representation loss after processing this batch is:  0.0025123655796051025\n",
      "\n",
      "The classification loss after processing this batch is:  0.07057584822177887\n",
      "The representation loss after processing this batch is:  0.0027478858828544617\n",
      "\n",
      "The classification loss after processing this batch is:  0.14782479405403137\n",
      "The representation loss after processing this batch is:  0.002390928566455841\n",
      "\n",
      "The classification loss after processing this batch is:  0.057956039905548096\n",
      "The representation loss after processing this batch is:  0.002673238515853882\n",
      "\n",
      "The classification loss after processing this batch is:  0.1585121899843216\n",
      "The representation loss after processing this batch is:  0.0026142820715904236\n",
      "\n",
      "The classification loss after processing this batch is:  0.18001994490623474\n",
      "The representation loss after processing this batch is:  0.0026681609451770782\n",
      "\n",
      "The classification loss after processing this batch is:  0.13366463780403137\n",
      "The representation loss after processing this batch is:  0.002686362713575363\n",
      "\n",
      "The classification loss after processing this batch is:  0.10582903772592545\n",
      "The representation loss after processing this batch is:  0.0027235299348831177\n",
      "\n",
      "The classification loss after processing this batch is:  0.05466987192630768\n",
      "The representation loss after processing this batch is:  0.0025968700647354126\n",
      "\n",
      "The classification loss after processing this batch is:  0.1389632672071457\n",
      "The representation loss after processing this batch is:  0.0022097229957580566\n",
      "\n",
      "The classification loss after processing this batch is:  0.13593460619449615\n",
      "The representation loss after processing this batch is:  0.002396814525127411\n",
      "\n",
      "The classification loss after processing this batch is:  0.061069026589393616\n",
      "The representation loss after processing this batch is:  0.0025192052125930786\n",
      "\n",
      "The classification loss after processing this batch is:  0.04052775353193283\n",
      "The representation loss after processing this batch is:  0.0023465529084205627\n",
      "\n",
      "The classification loss after processing this batch is:  0.20972204208374023\n",
      "The representation loss after processing this batch is:  0.0024281367659568787\n",
      "\n",
      "The classification loss after processing this batch is:  0.19285517930984497\n",
      "The representation loss after processing this batch is:  0.002294357866048813\n",
      "\n",
      "The classification loss after processing this batch is:  0.07883621007204056\n",
      "The representation loss after processing this batch is:  0.0023378804326057434\n",
      "\n",
      "The classification loss after processing this batch is:  0.24348340928554535\n",
      "The representation loss after processing this batch is:  0.0024135038256645203\n",
      "\n",
      "The classification loss after processing this batch is:  0.21945777535438538\n",
      "The representation loss after processing this batch is:  0.0024712979793548584\n",
      "\n",
      "The classification loss after processing this batch is:  0.30139726400375366\n",
      "The representation loss after processing this batch is:  0.002378128468990326\n",
      "\n",
      "The classification loss after processing this batch is:  0.11933856457471848\n",
      "The representation loss after processing this batch is:  0.0026425793766975403\n",
      "\n",
      "The classification loss after processing this batch is:  0.07657372206449509\n",
      "The representation loss after processing this batch is:  0.002545684576034546\n",
      "\n",
      "The classification loss after processing this batch is:  0.14986076951026917\n",
      "The representation loss after processing this batch is:  0.002578645944595337\n",
      "\n",
      "The classification loss after processing this batch is:  0.07130192965269089\n",
      "The representation loss after processing this batch is:  0.0024797096848487854\n",
      "\n",
      "The classification loss after processing this batch is:  0.05489138886332512\n",
      "The representation loss after processing this batch is:  0.0028193145990371704\n",
      "\n",
      "The classification loss after processing this batch is:  0.08811549097299576\n",
      "The representation loss after processing this batch is:  0.0021767467260360718\n",
      "\n",
      "The classification loss after processing this batch is:  0.05266910418868065\n",
      "The representation loss after processing this batch is:  0.0024734660983085632\n",
      "\n",
      "The classification loss after processing this batch is:  0.019114216789603233\n",
      "The representation loss after processing this batch is:  0.002831794321537018\n",
      "\n",
      "The classification loss after processing this batch is:  0.09992258995771408\n",
      "The representation loss after processing this batch is:  0.002452325075864792\n",
      "\n",
      "The classification loss after processing this batch is:  0.12816961109638214\n",
      "The representation loss after processing this batch is:  0.0022876709699630737\n",
      "\n",
      "The classification loss after processing this batch is:  0.07270516455173492\n",
      "The representation loss after processing this batch is:  0.002627246081829071\n",
      "\n",
      "The classification loss after processing this batch is:  0.08468273282051086\n",
      "The representation loss after processing this batch is:  0.002347078174352646\n",
      "\n",
      "The classification loss after processing this batch is:  0.1273176223039627\n",
      "The representation loss after processing this batch is:  0.0024166181683540344\n",
      "\n",
      "The classification loss after processing this batch is:  0.03209381178021431\n",
      "The representation loss after processing this batch is:  0.002415992319583893\n",
      "\n",
      "The classification loss after processing this batch is:  0.14427536725997925\n",
      "The representation loss after processing this batch is:  0.00264585018157959\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.0781950056552887\n",
      "The representation loss after processing this batch is:  0.002263970673084259\n",
      "\n",
      "The classification loss after processing this batch is:  0.20059671998023987\n",
      "The representation loss after processing this batch is:  0.002379484474658966\n",
      "\n",
      "The classification loss after processing this batch is:  0.1353493332862854\n",
      "The representation loss after processing this batch is:  0.0023948177695274353\n",
      "\n",
      "The classification loss after processing this batch is:  0.13836683332920074\n",
      "The representation loss after processing this batch is:  0.0021441802382469177\n",
      "\n",
      "The classification loss after processing this batch is:  0.03164922446012497\n",
      "The representation loss after processing this batch is:  0.0022938475012779236\n",
      "\n",
      "The classification loss after processing this batch is:  0.03371940180659294\n",
      "The representation loss after processing this batch is:  0.002374991774559021\n",
      "\n",
      "The classification loss after processing this batch is:  0.1440286487340927\n",
      "The representation loss after processing this batch is:  0.0025069303810596466\n",
      "\n",
      "The classification loss after processing this batch is:  0.04092206805944443\n",
      "The representation loss after processing this batch is:  0.0025992095470428467\n",
      "\n",
      "The classification loss after processing this batch is:  0.11491575837135315\n",
      "The representation loss after processing this batch is:  0.0025057941675186157\n",
      "\n",
      "The classification loss after processing this batch is:  0.07096947729587555\n",
      "The representation loss after processing this batch is:  0.0027349069714546204\n",
      "\n",
      "The classification loss after processing this batch is:  0.0654955804347992\n",
      "The representation loss after processing this batch is:  0.002521529793739319\n",
      "\n",
      "The classification loss after processing this batch is:  0.10368414223194122\n",
      "The representation loss after processing this batch is:  0.0024447068572044373\n",
      "\n",
      "The classification loss after processing this batch is:  0.06075802817940712\n",
      "The representation loss after processing this batch is:  0.00252465158700943\n",
      "\n",
      "The classification loss after processing this batch is:  0.06544610857963562\n",
      "The representation loss after processing this batch is:  0.0029647648334503174\n",
      "\n",
      "The classification loss after processing this batch is:  0.18528001010417938\n",
      "The representation loss after processing this batch is:  0.0023783817887306213\n",
      "\n",
      "The classification loss after processing this batch is:  0.14611858129501343\n",
      "The representation loss after processing this batch is:  0.002697467803955078\n",
      "\n",
      "The classification loss after processing this batch is:  0.16911910474300385\n",
      "The representation loss after processing this batch is:  0.002646617591381073\n",
      "\n",
      "The classification loss after processing this batch is:  0.1875588446855545\n",
      "The representation loss after processing this batch is:  0.0026587173342704773\n",
      "\n",
      "The classification loss after processing this batch is:  0.09859355539083481\n",
      "The representation loss after processing this batch is:  0.002193950116634369\n",
      "\n",
      "The classification loss after processing this batch is:  0.09785961359739304\n",
      "The representation loss after processing this batch is:  0.002249486744403839\n",
      "\n",
      "The classification loss after processing this batch is:  0.04974373057484627\n",
      "The representation loss after processing this batch is:  0.0023355484008789062\n",
      "\n",
      "The classification loss after processing this batch is:  0.05927393585443497\n",
      "The representation loss after processing this batch is:  0.002439267933368683\n",
      "\n",
      "The classification loss after processing this batch is:  0.048760611563920975\n",
      "The representation loss after processing this batch is:  0.0025130286812782288\n",
      "\n",
      "The classification loss after processing this batch is:  0.09800184518098831\n",
      "The representation loss after processing this batch is:  0.002177588641643524\n",
      "\n",
      "The classification loss after processing this batch is:  0.08148559927940369\n",
      "The representation loss after processing this batch is:  0.0026737377047538757\n",
      "\n",
      "The classification loss after processing this batch is:  0.11460897326469421\n",
      "The representation loss after processing this batch is:  0.0025044307112693787\n",
      "\n",
      "The classification loss after processing this batch is:  0.05911843851208687\n",
      "The representation loss after processing this batch is:  0.002247162163257599\n",
      "\n",
      "The classification loss after processing this batch is:  0.15292318165302277\n",
      "The representation loss after processing this batch is:  0.0022039711475372314\n",
      "\n",
      "The classification loss after processing this batch is:  0.0683237835764885\n",
      "The representation loss after processing this batch is:  0.002570889890193939\n",
      "\n",
      "The classification loss after processing this batch is:  0.1439657211303711\n",
      "The representation loss after processing this batch is:  0.002329200506210327\n",
      "\n",
      "The classification loss after processing this batch is:  0.13052596151828766\n",
      "The representation loss after processing this batch is:  0.002545788884162903\n",
      "\n",
      "The classification loss after processing this batch is:  0.10612780600786209\n",
      "The representation loss after processing this batch is:  0.0025855228304862976\n",
      "\n",
      "The classification loss after processing this batch is:  0.07797954231500626\n",
      "The representation loss after processing this batch is:  0.0025277063250541687\n",
      "\n",
      "The classification loss after processing this batch is:  0.16963475942611694\n",
      "The representation loss after processing this batch is:  0.002488456666469574\n",
      "\n",
      "The classification loss after processing this batch is:  0.0802827849984169\n",
      "The representation loss after processing this batch is:  0.002512983977794647\n",
      "\n",
      "The classification loss after processing this batch is:  0.06453876942396164\n",
      "The representation loss after processing this batch is:  0.002276003360748291\n",
      "\n",
      "The classification loss after processing this batch is:  0.07487194985151291\n",
      "The representation loss after processing this batch is:  0.002415873110294342\n",
      "\n",
      "The classification loss after processing this batch is:  0.07010862231254578\n",
      "The representation loss after processing this batch is:  0.002348870038986206\n",
      "\n",
      "The classification loss after processing this batch is:  0.15831860899925232\n",
      "The representation loss after processing this batch is:  0.0023100823163986206\n",
      "\n",
      "The classification loss after processing this batch is:  0.1536674052476883\n",
      "The representation loss after processing this batch is:  0.0025705285370349884\n",
      "\n",
      "The classification loss after processing this batch is:  0.09414626657962799\n",
      "The representation loss after processing this batch is:  0.002912387251853943\n",
      "\n",
      "The classification loss after processing this batch is:  0.07121243327856064\n",
      "The representation loss after processing this batch is:  0.0025705844163894653\n",
      "\n",
      "The classification loss after processing this batch is:  0.07759463787078857\n",
      "The representation loss after processing this batch is:  0.002741888165473938\n",
      "\n",
      "The classification loss after processing this batch is:  0.17405714094638824\n",
      "The representation loss after processing this batch is:  0.002586033195257187\n",
      "\n",
      "The classification loss after processing this batch is:  0.050780829042196274\n",
      "The representation loss after processing this batch is:  0.0024115070700645447\n",
      "\n",
      "The classification loss after processing this batch is:  0.06821057945489883\n",
      "The representation loss after processing this batch is:  0.0028334856033325195\n",
      "\n",
      "The classification loss after processing this batch is:  0.16245082020759583\n",
      "The representation loss after processing this batch is:  0.0022411830723285675\n",
      "\n",
      "The classification loss after processing this batch is:  0.2897479832172394\n",
      "The representation loss after processing this batch is:  0.0024708956480026245\n",
      "\n",
      "The classification loss after processing this batch is:  0.0808102935552597\n",
      "The representation loss after processing this batch is:  0.0023187100887298584\n",
      "\n",
      "The classification loss after processing this batch is:  0.11241079121828079\n",
      "The representation loss after processing this batch is:  0.002383694052696228\n",
      "\n",
      "The classification loss after processing this batch is:  0.04329874366521835\n",
      "The representation loss after processing this batch is:  0.002424880862236023\n",
      "\n",
      "The classification loss after processing this batch is:  0.034485865384340286\n",
      "The representation loss after processing this batch is:  0.0022469796240329742\n",
      "\n",
      "The classification loss after processing this batch is:  0.09740754216909409\n",
      "The representation loss after processing this batch is:  0.0031298547983169556\n",
      "\n",
      "The classification loss after processing this batch is:  0.07176078110933304\n",
      "The representation loss after processing this batch is:  0.0033707842230796814\n",
      "\n",
      "The classification loss after processing this batch is:  0.05401887744665146\n",
      "The representation loss after processing this batch is:  0.00244932621717453\n",
      "\n",
      "The classification loss after processing this batch is:  0.0533452071249485\n",
      "The representation loss after processing this batch is:  0.0022634416818618774\n",
      "\n",
      "The classification loss after processing this batch is:  0.15733249485492706\n",
      "The representation loss after processing this batch is:  0.0023289546370506287\n",
      "\n",
      "The classification loss after processing this batch is:  0.11698166280984879\n",
      "The representation loss after processing this batch is:  0.0023446232080459595\n",
      "\n",
      "The classification loss after processing this batch is:  0.06195918098092079\n",
      "The representation loss after processing this batch is:  0.002085339277982712\n",
      "\n",
      "The classification loss after processing this batch is:  0.06438867747783661\n",
      "The representation loss after processing this batch is:  0.0024468526244163513\n",
      "\n",
      "The classification loss after processing this batch is:  0.21017540991306305\n",
      "The representation loss after processing this batch is:  0.0023449212312698364\n",
      "\n",
      "The classification loss after processing this batch is:  0.18947769701480865\n",
      "The representation loss after processing this batch is:  0.0026124417781829834\n",
      "\n",
      "The classification loss after processing this batch is:  0.14764374494552612\n",
      "The representation loss after processing this batch is:  0.002214621752500534\n",
      "\n",
      "The classification loss after processing this batch is:  0.11982973664999008\n",
      "The representation loss after processing this batch is:  0.002723604440689087\n",
      "\n",
      "The classification loss after processing this batch is:  0.15466637909412384\n",
      "The representation loss after processing this batch is:  0.0022845789790153503\n",
      "\n",
      "The classification loss after processing this batch is:  0.08429204672574997\n",
      "The representation loss after processing this batch is:  0.0029595419764518738\n",
      "\n",
      "The classification loss after processing this batch is:  0.07882687449455261\n",
      "The representation loss after processing this batch is:  0.002757646143436432\n",
      "\n",
      "The classification loss after processing this batch is:  0.03970751538872719\n",
      "The representation loss after processing this batch is:  0.002665095031261444\n",
      "\n",
      "The classification loss after processing this batch is:  0.0702810287475586\n",
      "The representation loss after processing this batch is:  0.002268768846988678\n",
      "\n",
      "The classification loss after processing this batch is:  0.1641644537448883\n",
      "The representation loss after processing this batch is:  0.002386864274740219\n",
      "\n",
      "The classification loss after processing this batch is:  0.07322333008050919\n",
      "The representation loss after processing this batch is:  0.0029300525784492493\n",
      "\n",
      "The classification loss after processing this batch is:  0.045014336705207825\n",
      "The representation loss after processing this batch is:  0.0024336278438568115\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.023675251752138138\n",
      "The representation loss after processing this batch is:  0.003066055476665497\n",
      "\n",
      "The classification loss after processing this batch is:  0.0310891754925251\n",
      "The representation loss after processing this batch is:  0.002860322594642639\n",
      "\n",
      "The classification loss after processing this batch is:  0.05303632840514183\n",
      "The representation loss after processing this batch is:  0.003003738820552826\n",
      "\n",
      "The classification loss after processing this batch is:  0.05949598550796509\n",
      "The representation loss after processing this batch is:  0.002933904528617859\n",
      "\n",
      "The classification loss after processing this batch is:  0.03783739358186722\n",
      "The representation loss after processing this batch is:  0.0025098174810409546\n",
      "\n",
      "The classification loss after processing this batch is:  0.018755190074443817\n",
      "The representation loss after processing this batch is:  0.0028571560978889465\n",
      "\n",
      "The classification loss after processing this batch is:  0.03135484457015991\n",
      "The representation loss after processing this batch is:  0.0036152005195617676\n",
      "\n",
      "The classification loss after processing this batch is:  0.07871022820472717\n",
      "The representation loss after processing this batch is:  0.0033804550766944885\n",
      "\n",
      "The classification loss after processing this batch is:  0.0114420335739851\n",
      "The representation loss after processing this batch is:  0.003512151539325714\n",
      "\n",
      "The classification loss after processing this batch is:  0.03340418264269829\n",
      "The representation loss after processing this batch is:  0.002825118601322174\n",
      "\n",
      "The classification loss after processing this batch is:  0.15753063559532166\n",
      "The representation loss after processing this batch is:  0.0027757659554481506\n",
      "\n",
      "The classification loss after processing this batch is:  0.023322319611907005\n",
      "The representation loss after processing this batch is:  0.003282874822616577\n",
      "\n",
      "The classification loss after processing this batch is:  0.010150345042347908\n",
      "The representation loss after processing this batch is:  0.003026537597179413\n",
      "\n",
      "The classification loss after processing this batch is:  0.0173442754894495\n",
      "The representation loss after processing this batch is:  0.002762116491794586\n",
      "\n",
      "The classification loss after processing this batch is:  0.026177477091550827\n",
      "The representation loss after processing this batch is:  0.003046862781047821\n",
      "\n",
      "The classification loss after processing this batch is:  0.020902346819639206\n",
      "The representation loss after processing this batch is:  0.003198981285095215\n",
      "\n",
      "The classification loss after processing this batch is:  0.018932683393359184\n",
      "The representation loss after processing this batch is:  0.003114961087703705\n",
      "\n",
      "The classification loss after processing this batch is:  0.016054367646574974\n",
      "The representation loss after processing this batch is:  0.003181181848049164\n",
      "\n",
      "The classification loss after processing this batch is:  0.14583659172058105\n",
      "The representation loss after processing this batch is:  0.003573477268218994\n",
      "\n",
      "The classification loss after processing this batch is:  0.28198400139808655\n",
      "The representation loss after processing this batch is:  0.0033372417092323303\n",
      "\n",
      "The classification loss after processing this batch is:  0.1711011379957199\n",
      "The representation loss after processing this batch is:  0.003639601171016693\n",
      "\n",
      "The classification loss after processing this batch is:  0.046135954558849335\n",
      "The representation loss after processing this batch is:  0.0026564300060272217\n",
      "\n",
      "The classification loss after processing this batch is:  0.016084520146250725\n",
      "The representation loss after processing this batch is:  0.0032389238476753235\n",
      "\n",
      "The classification loss after processing this batch is:  0.016640087589621544\n",
      "The representation loss after processing this batch is:  0.0024344027042388916\n",
      "\n",
      "The classification loss after processing this batch is:  0.13382063806056976\n",
      "The representation loss after processing this batch is:  0.0022369474172592163\n",
      "\n",
      "The classification loss after processing this batch is:  0.3267326354980469\n",
      "The representation loss after processing this batch is:  0.002830982208251953\n",
      "\n",
      "The classification loss after processing this batch is:  0.05259699746966362\n",
      "The representation loss after processing this batch is:  0.0025654956698417664\n",
      "\n",
      "The classification loss after processing this batch is:  0.037339530885219574\n",
      "The representation loss after processing this batch is:  0.0031828954815864563\n",
      "\n",
      "The classification loss after processing this batch is:  0.03839428350329399\n",
      "The representation loss after processing this batch is:  0.003087639808654785\n",
      "\n",
      "The classification loss after processing this batch is:  0.039933107793331146\n",
      "The representation loss after processing this batch is:  0.003536708652973175\n",
      "\n",
      "The classification loss after processing this batch is:  0.08613887429237366\n",
      "The representation loss after processing this batch is:  0.0024765245616436005\n",
      "\n",
      "The classification loss after processing this batch is:  0.039789389818906784\n",
      "The representation loss after processing this batch is:  0.002381652593612671\n",
      "\n",
      "The classification loss after processing this batch is:  0.0699554905295372\n",
      "The representation loss after processing this batch is:  0.0024491772055625916\n",
      "\n",
      "The classification loss after processing this batch is:  0.09734883904457092\n",
      "The representation loss after processing this batch is:  0.002221975475549698\n",
      "\n",
      "The classification loss after processing this batch is:  0.09380865842103958\n",
      "The representation loss after processing this batch is:  0.0026641152799129486\n",
      "\n",
      "The classification loss after processing this batch is:  0.06366893649101257\n",
      "The representation loss after processing this batch is:  0.002763092517852783\n",
      "\n",
      "The classification loss after processing this batch is:  0.07295754551887512\n",
      "The representation loss after processing this batch is:  0.0026925429701805115\n",
      "\n",
      "The classification loss after processing this batch is:  0.0957542359828949\n",
      "The representation loss after processing this batch is:  0.002286206930875778\n",
      "\n",
      "The classification loss after processing this batch is:  0.09587492793798447\n",
      "The representation loss after processing this batch is:  0.002297133207321167\n",
      "\n",
      "The classification loss after processing this batch is:  0.06563574820756912\n",
      "The representation loss after processing this batch is:  0.0024362988770008087\n",
      "\n",
      "The classification loss after processing this batch is:  0.1278347671031952\n",
      "The representation loss after processing this batch is:  0.002236943691968918\n",
      "\n",
      "The classification loss after processing this batch is:  0.13073745369911194\n",
      "The representation loss after processing this batch is:  0.002380192279815674\n",
      "\n",
      "The classification loss after processing this batch is:  0.12333397567272186\n",
      "The representation loss after processing this batch is:  0.003012746572494507\n",
      "\n",
      "The classification loss after processing this batch is:  0.06058287248015404\n",
      "The representation loss after processing this batch is:  0.002427704632282257\n",
      "\n",
      "The classification loss after processing this batch is:  0.22395554184913635\n",
      "The representation loss after processing this batch is:  0.00228206068277359\n",
      "\n",
      "The classification loss after processing this batch is:  0.12326899915933609\n",
      "The representation loss after processing this batch is:  0.0021998845040798187\n",
      "\n",
      "The classification loss after processing this batch is:  0.09383818507194519\n",
      "The representation loss after processing this batch is:  0.002277012914419174\n",
      "\n",
      "The classification loss after processing this batch is:  0.19861054420471191\n",
      "The representation loss after processing this batch is:  0.0024094022810459137\n",
      "\n",
      "The classification loss after processing this batch is:  0.11028529703617096\n",
      "The representation loss after processing this batch is:  0.0025882646441459656\n",
      "\n",
      "The classification loss after processing this batch is:  0.04172240570187569\n",
      "The representation loss after processing this batch is:  0.0024652481079101562\n",
      "\n",
      "The classification loss after processing this batch is:  0.18104109168052673\n",
      "The representation loss after processing this batch is:  0.002716362476348877\n",
      "\n",
      "The classification loss after processing this batch is:  0.1000380888581276\n",
      "The representation loss after processing this batch is:  0.0026524141430854797\n",
      "\n",
      "The classification loss after processing this batch is:  0.2370106428861618\n",
      "The representation loss after processing this batch is:  0.002269178628921509\n",
      "\n",
      "The classification loss after processing this batch is:  0.0668022632598877\n",
      "The representation loss after processing this batch is:  0.0022647976875305176\n",
      "\n",
      "The classification loss after processing this batch is:  0.048653777688741684\n",
      "The representation loss after processing this batch is:  0.0024302080273628235\n",
      "\n",
      "The classification loss after processing this batch is:  0.07615353912115097\n",
      "The representation loss after processing this batch is:  0.0023094750940799713\n",
      "\n",
      "The classification loss after processing this batch is:  0.0642867311835289\n",
      "The representation loss after processing this batch is:  0.0021135322749614716\n",
      "\n",
      "The classification loss after processing this batch is:  0.07847171276807785\n",
      "The representation loss after processing this batch is:  0.0023701079189777374\n",
      "\n",
      "The classification loss after processing this batch is:  0.039612893015146255\n",
      "The representation loss after processing this batch is:  0.002536207437515259\n",
      "\n",
      "The classification loss after processing this batch is:  0.03248629719018936\n",
      "The representation loss after processing this batch is:  0.002530992031097412\n",
      "\n",
      "The classification loss after processing this batch is:  0.05970244109630585\n",
      "The representation loss after processing this batch is:  0.0025259368121623993\n",
      "\n",
      "The classification loss after processing this batch is:  0.052527718245983124\n",
      "The representation loss after processing this batch is:  0.0027646757662296295\n",
      "\n",
      "The classification loss after processing this batch is:  0.1309373676776886\n",
      "The representation loss after processing this batch is:  0.002366352826356888\n",
      "\n",
      "The classification loss after processing this batch is:  0.059176668524742126\n",
      "The representation loss after processing this batch is:  0.002754751592874527\n",
      "\n",
      "The classification loss after processing this batch is:  0.07767996191978455\n",
      "The representation loss after processing this batch is:  0.0021790452301502228\n",
      "\n",
      "The classification loss after processing this batch is:  0.031157899647951126\n",
      "The representation loss after processing this batch is:  0.0024410560727119446\n",
      "\n",
      "The classification loss after processing this batch is:  0.04594937339425087\n",
      "The representation loss after processing this batch is:  0.0026860497891902924\n",
      "\n",
      "The classification loss after processing this batch is:  0.07729724049568176\n",
      "The representation loss after processing this batch is:  0.0023048035800457\n",
      "\n",
      "The classification loss after processing this batch is:  0.07029935717582703\n",
      "The representation loss after processing this batch is:  0.002676650881767273\n",
      "\n",
      "The classification loss after processing this batch is:  0.054912347346544266\n",
      "The representation loss after processing this batch is:  0.002446487545967102\n",
      "\n",
      "The classification loss after processing this batch is:  0.14503338932991028\n",
      "The representation loss after processing this batch is:  0.0025399699807167053\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.07995937019586563\n",
      "The representation loss after processing this batch is:  0.0024422481656074524\n",
      "\n",
      "The classification loss after processing this batch is:  0.06247232109308243\n",
      "The representation loss after processing this batch is:  0.0023565180599689484\n",
      "\n",
      "The classification loss after processing this batch is:  0.13020168244838715\n",
      "The representation loss after processing this batch is:  0.002593494951725006\n",
      "\n",
      "The classification loss after processing this batch is:  0.04851042851805687\n",
      "The representation loss after processing this batch is:  0.002252355217933655\n",
      "\n",
      "The classification loss after processing this batch is:  0.06453617662191391\n",
      "The representation loss after processing this batch is:  0.0022964663803577423\n",
      "\n",
      "The classification loss after processing this batch is:  0.1778138428926468\n",
      "The representation loss after processing this batch is:  0.0027562975883483887\n",
      "\n",
      "The classification loss after processing this batch is:  0.035514313727617264\n",
      "The representation loss after processing this batch is:  0.0023568272590637207\n",
      "\n",
      "The classification loss after processing this batch is:  0.12249302864074707\n",
      "The representation loss after processing this batch is:  0.002363450825214386\n",
      "\n",
      "The classification loss after processing this batch is:  0.07147515565156937\n",
      "The representation loss after processing this batch is:  0.002377912402153015\n",
      "\n",
      "The classification loss after processing this batch is:  0.07359612733125687\n",
      "The representation loss after processing this batch is:  0.0022988654673099518\n",
      "\n",
      "The classification loss after processing this batch is:  0.07813022285699844\n",
      "The representation loss after processing this batch is:  0.0022903531789779663\n",
      "\n",
      "The classification loss after processing this batch is:  0.043720830231904984\n",
      "The representation loss after processing this batch is:  0.002541176974773407\n",
      "\n",
      "The classification loss after processing this batch is:  0.13828738033771515\n",
      "The representation loss after processing this batch is:  0.002696484327316284\n",
      "\n",
      "The classification loss after processing this batch is:  0.09961018711328506\n",
      "The representation loss after processing this batch is:  0.00269162654876709\n",
      "\n",
      "The classification loss after processing this batch is:  0.10715650022029877\n",
      "The representation loss after processing this batch is:  0.0025285035371780396\n",
      "\n",
      "The classification loss after processing this batch is:  0.10633837431669235\n",
      "The representation loss after processing this batch is:  0.002256259322166443\n",
      "\n",
      "The classification loss after processing this batch is:  0.11447370797395706\n",
      "The representation loss after processing this batch is:  0.0025078952312469482\n",
      "\n",
      "The classification loss after processing this batch is:  0.10437724739313126\n",
      "The representation loss after processing this batch is:  0.002361677587032318\n",
      "\n",
      "The classification loss after processing this batch is:  0.0730578750371933\n",
      "The representation loss after processing this batch is:  0.002315044403076172\n",
      "\n",
      "The classification loss after processing this batch is:  0.0641372799873352\n",
      "The representation loss after processing this batch is:  0.002269461750984192\n",
      "\n",
      "The classification loss after processing this batch is:  0.15428224205970764\n",
      "The representation loss after processing this batch is:  0.0024642720818519592\n",
      "\n",
      "The classification loss after processing this batch is:  0.12997967004776\n",
      "The representation loss after processing this batch is:  0.0024236738681793213\n",
      "\n",
      "The classification loss after processing this batch is:  0.061379361897706985\n",
      "The representation loss after processing this batch is:  0.0023761317133903503\n",
      "\n",
      "The classification loss after processing this batch is:  0.0587732307612896\n",
      "The representation loss after processing this batch is:  0.0023763254284858704\n",
      "\n",
      "The classification loss after processing this batch is:  0.05669645220041275\n",
      "The representation loss after processing this batch is:  0.0023112744092941284\n",
      "\n",
      "The classification loss after processing this batch is:  0.06023509427905083\n",
      "The representation loss after processing this batch is:  0.0026777833700180054\n",
      "\n",
      "The classification loss after processing this batch is:  0.1304597109556198\n",
      "The representation loss after processing this batch is:  0.002150505781173706\n",
      "\n",
      "The classification loss after processing this batch is:  0.060022156685590744\n",
      "The representation loss after processing this batch is:  0.0023023784160614014\n",
      "\n",
      "The classification loss after processing this batch is:  0.1753356009721756\n",
      "The representation loss after processing this batch is:  0.002298261970281601\n",
      "\n",
      "The classification loss after processing this batch is:  0.11904348433017731\n",
      "The representation loss after processing this batch is:  0.0022919178009033203\n",
      "\n",
      "The classification loss after processing this batch is:  0.10544469952583313\n",
      "The representation loss after processing this batch is:  0.00231286883354187\n",
      "\n",
      "The classification loss after processing this batch is:  0.06385759264230728\n",
      "The representation loss after processing this batch is:  0.002057339996099472\n",
      "\n",
      "The classification loss after processing this batch is:  0.05269113555550575\n",
      "The representation loss after processing this batch is:  0.0025205686688423157\n",
      "\n",
      "The classification loss after processing this batch is:  0.07696786522865295\n",
      "The representation loss after processing this batch is:  0.0021665059030056\n",
      "\n",
      "The classification loss after processing this batch is:  0.15442141890525818\n",
      "The representation loss after processing this batch is:  0.002164967358112335\n",
      "\n",
      "The classification loss after processing this batch is:  0.06900664418935776\n",
      "The representation loss after processing this batch is:  0.002233736217021942\n",
      "\n",
      "The classification loss after processing this batch is:  0.2626914978027344\n",
      "The representation loss after processing this batch is:  0.0022655874490737915\n",
      "\n",
      "The classification loss after processing this batch is:  0.09037138521671295\n",
      "The representation loss after processing this batch is:  0.002160552889108658\n",
      "\n",
      "The classification loss after processing this batch is:  0.05105893686413765\n",
      "The representation loss after processing this batch is:  0.002903670072555542\n",
      "\n",
      "The classification loss after processing this batch is:  0.1438271552324295\n",
      "The representation loss after processing this batch is:  0.0025474950671195984\n",
      "\n",
      "The classification loss after processing this batch is:  0.04982013255357742\n",
      "The representation loss after processing this batch is:  0.0027351751923561096\n",
      "\n",
      "The classification loss after processing this batch is:  0.23557890951633453\n",
      "The representation loss after processing this batch is:  0.002650626003742218\n",
      "\n",
      "The classification loss after processing this batch is:  0.10476048290729523\n",
      "The representation loss after processing this batch is:  0.002215541899204254\n",
      "\n",
      "The classification loss after processing this batch is:  0.17280356585979462\n",
      "The representation loss after processing this batch is:  0.002405621111392975\n",
      "\n",
      "The classification loss after processing this batch is:  0.20547671616077423\n",
      "The representation loss after processing this batch is:  0.0024239197373390198\n",
      "\n",
      "The classification loss after processing this batch is:  0.1261991560459137\n",
      "The representation loss after processing this batch is:  0.002167150378227234\n",
      "\n",
      "The classification loss after processing this batch is:  0.04882819578051567\n",
      "The representation loss after processing this batch is:  0.00243571400642395\n",
      "\n",
      "The classification loss after processing this batch is:  0.12612515687942505\n",
      "The representation loss after processing this batch is:  0.0022799745202064514\n",
      "\n",
      "The classification loss after processing this batch is:  0.09685425460338593\n",
      "The representation loss after processing this batch is:  0.002493150532245636\n",
      "\n",
      "The classification loss after processing this batch is:  0.11249347031116486\n",
      "The representation loss after processing this batch is:  0.00237186998128891\n",
      "\n",
      "The classification loss after processing this batch is:  0.062376756221055984\n",
      "The representation loss after processing this batch is:  0.00221986323595047\n",
      "\n",
      "The classification loss after processing this batch is:  0.08086050301790237\n",
      "The representation loss after processing this batch is:  0.0023346543312072754\n",
      "\n",
      "The classification loss after processing this batch is:  0.15226790308952332\n",
      "The representation loss after processing this batch is:  0.0023899227380752563\n",
      "\n",
      "The classification loss after processing this batch is:  0.12776565551757812\n",
      "The representation loss after processing this batch is:  0.0026572570204734802\n",
      "\n",
      "The classification loss after processing this batch is:  0.1536731868982315\n",
      "The representation loss after processing this batch is:  0.00226486474275589\n",
      "\n",
      "The classification loss after processing this batch is:  0.21231478452682495\n",
      "The representation loss after processing this batch is:  0.002594098448753357\n",
      "\n",
      "The classification loss after processing this batch is:  0.12445545196533203\n",
      "The representation loss after processing this batch is:  0.0026143789291381836\n",
      "\n",
      "The classification loss after processing this batch is:  0.05766981467604637\n",
      "The representation loss after processing this batch is:  0.002564534544944763\n",
      "\n",
      "The classification loss after processing this batch is:  0.05949307605624199\n",
      "The representation loss after processing this batch is:  0.0023544877767562866\n",
      "\n",
      "The classification loss after processing this batch is:  0.03342941775918007\n",
      "The representation loss after processing this batch is:  0.002414688467979431\n",
      "\n",
      "The classification loss after processing this batch is:  0.1119648888707161\n",
      "The representation loss after processing this batch is:  0.0025053024291992188\n",
      "\n",
      "The classification loss after processing this batch is:  0.09451384842395782\n",
      "The representation loss after processing this batch is:  0.0024570226669311523\n",
      "\n",
      "The classification loss after processing this batch is:  0.23489652574062347\n",
      "The representation loss after processing this batch is:  0.002543240785598755\n",
      "\n",
      "The classification loss after processing this batch is:  0.23700939118862152\n",
      "The representation loss after processing this batch is:  0.0024300068616867065\n",
      "\n",
      "The classification loss after processing this batch is:  0.07170125842094421\n",
      "The representation loss after processing this batch is:  0.0026480183005332947\n",
      "\n",
      "The classification loss after processing this batch is:  0.09440691024065018\n",
      "The representation loss after processing this batch is:  0.0027039125561714172\n",
      "\n",
      "The classification loss after processing this batch is:  0.12748800218105316\n",
      "The representation loss after processing this batch is:  0.0022071003913879395\n",
      "\n",
      "The classification loss after processing this batch is:  0.043926749378442764\n",
      "The representation loss after processing this batch is:  0.0025546178221702576\n",
      "\n",
      "The classification loss after processing this batch is:  0.045900966972112656\n",
      "The representation loss after processing this batch is:  0.002563193440437317\n",
      "\n",
      "The classification loss after processing this batch is:  0.10683045536279678\n",
      "The representation loss after processing this batch is:  0.002241067588329315\n",
      "\n",
      "The classification loss after processing this batch is:  0.06519114971160889\n",
      "The representation loss after processing this batch is:  0.003044135868549347\n",
      "\n",
      "The classification loss after processing this batch is:  0.08238520473241806\n",
      "The representation loss after processing this batch is:  0.002774331718683243\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2045910507440567\n",
      "The representation loss after processing this batch is:  0.0032851509749889374\n",
      "\n",
      "The classification loss after processing this batch is:  0.20812982320785522\n",
      "The representation loss after processing this batch is:  0.002132054418325424\n",
      "\n",
      "The classification loss after processing this batch is:  0.08043114095926285\n",
      "The representation loss after processing this batch is:  0.002749629318714142\n",
      "\n",
      "The classification loss after processing this batch is:  0.16599518060684204\n",
      "The representation loss after processing this batch is:  0.002514868974685669\n",
      "\n",
      "The classification loss after processing this batch is:  0.17335711419582367\n",
      "The representation loss after processing this batch is:  0.0022943206131458282\n",
      "\n",
      "The classification loss after processing this batch is:  0.05627065524458885\n",
      "The representation loss after processing this batch is:  0.002390410751104355\n",
      "\n",
      "The classification loss after processing this batch is:  0.1094784215092659\n",
      "The representation loss after processing this batch is:  0.002232704311609268\n",
      "\n",
      "The classification loss after processing this batch is:  0.36495596170425415\n",
      "The representation loss after processing this batch is:  0.0029585734009742737\n",
      "\n",
      "The classification loss after processing this batch is:  0.13318707048892975\n",
      "The representation loss after processing this batch is:  0.0026413127779960632\n",
      "\n",
      "The classification loss after processing this batch is:  0.04352651908993721\n",
      "The representation loss after processing this batch is:  0.002793245017528534\n",
      "\n",
      "The classification loss after processing this batch is:  0.04946593567728996\n",
      "The representation loss after processing this batch is:  0.0027951449155807495\n",
      "\n",
      "The classification loss after processing this batch is:  0.049547452479600906\n",
      "The representation loss after processing this batch is:  0.0028214380145072937\n",
      "\n",
      "The classification loss after processing this batch is:  0.07765332609415054\n",
      "The representation loss after processing this batch is:  0.0026178359985351562\n",
      "\n",
      "The classification loss after processing this batch is:  0.05845783278346062\n",
      "The representation loss after processing this batch is:  0.0027466490864753723\n",
      "\n",
      "The classification loss after processing this batch is:  0.1107381209731102\n",
      "The representation loss after processing this batch is:  0.0023296140134334564\n",
      "\n",
      "The classification loss after processing this batch is:  0.08479923754930496\n",
      "The representation loss after processing this batch is:  0.0023464858531951904\n",
      "\n",
      "The classification loss after processing this batch is:  0.1570049673318863\n",
      "The representation loss after processing this batch is:  0.002266429364681244\n",
      "\n",
      "The classification loss after processing this batch is:  0.07246490567922592\n",
      "The representation loss after processing this batch is:  0.0021269768476486206\n",
      "\n",
      "The classification loss after processing this batch is:  0.08883045613765717\n",
      "The representation loss after processing this batch is:  0.0023240260779857635\n",
      "\n",
      "The classification loss after processing this batch is:  0.12261798977851868\n",
      "The representation loss after processing this batch is:  0.002369087189435959\n",
      "\n",
      "The classification loss after processing this batch is:  0.11752023547887802\n",
      "The representation loss after processing this batch is:  0.002463776618242264\n",
      "\n",
      "The classification loss after processing this batch is:  0.059575457125902176\n",
      "The representation loss after processing this batch is:  0.002253293991088867\n",
      "\n",
      "The classification loss after processing this batch is:  0.14463362097740173\n",
      "The representation loss after processing this batch is:  0.002315513789653778\n",
      "\n",
      "The classification loss after processing this batch is:  0.1596333533525467\n",
      "The representation loss after processing this batch is:  0.002398155629634857\n",
      "\n",
      "The classification loss after processing this batch is:  0.11754047870635986\n",
      "The representation loss after processing this batch is:  0.002237670123577118\n",
      "\n",
      "The classification loss after processing this batch is:  0.10855019837617874\n",
      "The representation loss after processing this batch is:  0.002616383135318756\n",
      "\n",
      "The classification loss after processing this batch is:  0.16899029910564423\n",
      "The representation loss after processing this batch is:  0.0024708136916160583\n",
      "\n",
      "The classification loss after processing this batch is:  0.18104928731918335\n",
      "The representation loss after processing this batch is:  0.0026556290686130524\n",
      "\n",
      "The classification loss after processing this batch is:  0.12987835705280304\n",
      "The representation loss after processing this batch is:  0.0026423782110214233\n",
      "\n",
      "The classification loss after processing this batch is:  0.0790141373872757\n",
      "The representation loss after processing this batch is:  0.0027387887239456177\n",
      "\n",
      "The classification loss after processing this batch is:  0.06901799142360687\n",
      "The representation loss after processing this batch is:  0.002717159688472748\n",
      "\n",
      "The classification loss after processing this batch is:  0.2104000747203827\n",
      "The representation loss after processing this batch is:  0.002362176775932312\n",
      "\n",
      "The classification loss after processing this batch is:  0.15455713868141174\n",
      "The representation loss after processing this batch is:  0.002232693135738373\n",
      "\n",
      "The classification loss after processing this batch is:  0.2516012191772461\n",
      "The representation loss after processing this batch is:  0.0024824589490890503\n",
      "\n",
      "The classification loss after processing this batch is:  0.261160671710968\n",
      "The representation loss after processing this batch is:  0.0022081583738327026\n",
      "\n",
      "The classification loss after processing this batch is:  0.14743217825889587\n",
      "The representation loss after processing this batch is:  0.0022107958793640137\n",
      "\n",
      "The classification loss after processing this batch is:  0.08233987540006638\n",
      "The representation loss after processing this batch is:  0.0022514313459396362\n",
      "\n",
      "The classification loss after processing this batch is:  0.062411848455667496\n",
      "The representation loss after processing this batch is:  0.002224750816822052\n",
      "\n",
      "The classification loss after processing this batch is:  0.04442077502608299\n",
      "The representation loss after processing this batch is:  0.002752050757408142\n",
      "\n",
      "The classification loss after processing this batch is:  0.09660147875547409\n",
      "The representation loss after processing this batch is:  0.0029814913868904114\n",
      "\n",
      "The classification loss after processing this batch is:  0.04702674597501755\n",
      "The representation loss after processing this batch is:  0.0025071725249290466\n",
      "\n",
      "The classification loss after processing this batch is:  0.1886027306318283\n",
      "The representation loss after processing this batch is:  0.003431282937526703\n",
      "\n",
      "The classification loss after processing this batch is:  0.09322508424520493\n",
      "The representation loss after processing this batch is:  0.002526022493839264\n",
      "\n",
      "The classification loss after processing this batch is:  0.07198378443717957\n",
      "The representation loss after processing this batch is:  0.0025858767330646515\n",
      "\n",
      "The classification loss after processing this batch is:  0.16218207776546478\n",
      "The representation loss after processing this batch is:  0.0023060813546180725\n",
      "\n",
      "The classification loss after processing this batch is:  0.06922872364521027\n",
      "The representation loss after processing this batch is:  0.0026981011033058167\n",
      "\n",
      "The classification loss after processing this batch is:  0.069578155875206\n",
      "The representation loss after processing this batch is:  0.0032517388463020325\n",
      "\n",
      "The classification loss after processing this batch is:  0.2419525533914566\n",
      "The representation loss after processing this batch is:  0.003175295889377594\n",
      "\n",
      "The classification loss after processing this batch is:  0.11187335848808289\n",
      "The representation loss after processing this batch is:  0.002751357853412628\n",
      "\n",
      "The classification loss after processing this batch is:  0.1177486926317215\n",
      "The representation loss after processing this batch is:  0.00234028697013855\n",
      "\n",
      "The classification loss after processing this batch is:  0.051423754543066025\n",
      "The representation loss after processing this batch is:  0.002221211791038513\n",
      "\n",
      "The classification loss after processing this batch is:  0.022019315510988235\n",
      "The representation loss after processing this batch is:  0.002713896334171295\n",
      "\n",
      "The classification loss after processing this batch is:  0.04950205609202385\n",
      "The representation loss after processing this batch is:  0.002790883183479309\n",
      "\n",
      "The classification loss after processing this batch is:  0.05088535696268082\n",
      "The representation loss after processing this batch is:  0.002433985471725464\n",
      "\n",
      "The classification loss after processing this batch is:  0.08537121117115021\n",
      "The representation loss after processing this batch is:  0.002257116138935089\n",
      "\n",
      "The classification loss after processing this batch is:  0.07854128628969193\n",
      "The representation loss after processing this batch is:  0.0026161745190620422\n",
      "\n",
      "The classification loss after processing this batch is:  0.09778368473052979\n",
      "The representation loss after processing this batch is:  0.002544678747653961\n",
      "\n",
      "The classification loss after processing this batch is:  0.27079343795776367\n",
      "The representation loss after processing this batch is:  0.0027391090989112854\n",
      "\n",
      "The classification loss after processing this batch is:  0.18967269361019135\n",
      "The representation loss after processing this batch is:  0.0025729984045028687\n",
      "\n",
      "The classification loss after processing this batch is:  0.08070553094148636\n",
      "The representation loss after processing this batch is:  0.002347327768802643\n",
      "\n",
      "The classification loss after processing this batch is:  0.05436067655682564\n",
      "The representation loss after processing this batch is:  0.002750806510448456\n",
      "\n",
      "The classification loss after processing this batch is:  0.08118825405836105\n",
      "The representation loss after processing this batch is:  0.00253913551568985\n",
      "\n",
      "The classification loss after processing this batch is:  0.07257159799337387\n",
      "The representation loss after processing this batch is:  0.002544321119785309\n",
      "\n",
      "The classification loss after processing this batch is:  0.027151798829436302\n",
      "The representation loss after processing this batch is:  0.0023734793066978455\n",
      "\n",
      "The classification loss after processing this batch is:  0.0390578955411911\n",
      "The representation loss after processing this batch is:  0.0025635696947574615\n",
      "\n",
      "The classification loss after processing this batch is:  0.07567758113145828\n",
      "The representation loss after processing this batch is:  0.002118319272994995\n",
      "\n",
      "The classification loss after processing this batch is:  0.09952042251825333\n",
      "The representation loss after processing this batch is:  0.0022574886679649353\n",
      "\n",
      "The classification loss after processing this batch is:  0.07522459328174591\n",
      "The representation loss after processing this batch is:  0.0026162192225456238\n",
      "\n",
      "The classification loss after processing this batch is:  0.05716917663812637\n",
      "The representation loss after processing this batch is:  0.0024735480546951294\n",
      "\n",
      "The classification loss after processing this batch is:  0.04972450062632561\n",
      "The representation loss after processing this batch is:  0.002334531396627426\n",
      "\n",
      "The classification loss after processing this batch is:  0.24645978212356567\n",
      "The representation loss after processing this batch is:  0.0022849924862384796\n",
      "\n",
      "The classification loss after processing this batch is:  0.09671665728092194\n",
      "The representation loss after processing this batch is:  0.002482965588569641\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.043013572692871094\n",
      "The representation loss after processing this batch is:  0.0025720372796058655\n",
      "\n",
      "The classification loss after processing this batch is:  0.09538466483354568\n",
      "The representation loss after processing this batch is:  0.0024802163243293762\n",
      "\n",
      "The classification loss after processing this batch is:  0.08347070217132568\n",
      "The representation loss after processing this batch is:  0.0022814758121967316\n",
      "\n",
      "The classification loss after processing this batch is:  0.04629552364349365\n",
      "The representation loss after processing this batch is:  0.0022043101489543915\n",
      "\n",
      "The classification loss after processing this batch is:  0.11742570251226425\n",
      "The representation loss after processing this batch is:  0.002379726618528366\n",
      "\n",
      "The classification loss after processing this batch is:  0.05067889764904976\n",
      "The representation loss after processing this batch is:  0.002301059663295746\n",
      "\n",
      "The classification loss after processing this batch is:  0.05345053970813751\n",
      "The representation loss after processing this batch is:  0.0024911388754844666\n",
      "\n",
      "The classification loss after processing this batch is:  0.09351303428411484\n",
      "The representation loss after processing this batch is:  0.0020064860582351685\n",
      "\n",
      "The classification loss after processing this batch is:  0.14691795408725739\n",
      "The representation loss after processing this batch is:  0.0025100037455558777\n",
      "\n",
      "The classification loss after processing this batch is:  0.1064441129565239\n",
      "The representation loss after processing this batch is:  0.0024881288409233093\n",
      "\n",
      "The classification loss after processing this batch is:  0.12793263792991638\n",
      "The representation loss after processing this batch is:  0.0022479817271232605\n",
      "\n",
      "The classification loss after processing this batch is:  0.0959269180893898\n",
      "The representation loss after processing this batch is:  0.0023749656975269318\n",
      "\n",
      "The classification loss after processing this batch is:  0.1644267737865448\n",
      "The representation loss after processing this batch is:  0.0023361817002296448\n",
      "\n",
      "The classification loss after processing this batch is:  0.06855539977550507\n",
      "The representation loss after processing this batch is:  0.0025321468710899353\n",
      "\n",
      "The classification loss after processing this batch is:  0.11276572197675705\n",
      "The representation loss after processing this batch is:  0.002284593880176544\n",
      "\n",
      "The classification loss after processing this batch is:  0.06262382119894028\n",
      "The representation loss after processing this batch is:  0.0022766441106796265\n",
      "\n",
      "The classification loss after processing this batch is:  0.17642006278038025\n",
      "The representation loss after processing this batch is:  0.0023068562150001526\n",
      "\n",
      "The classification loss after processing this batch is:  0.09413455426692963\n",
      "The representation loss after processing this batch is:  0.0025538653135299683\n",
      "\n",
      "The classification loss after processing this batch is:  0.14203542470932007\n",
      "The representation loss after processing this batch is:  0.002279050648212433\n",
      "\n",
      "The classification loss after processing this batch is:  0.08863190561532974\n",
      "The representation loss after processing this batch is:  0.002275649458169937\n",
      "\n",
      "The classification loss after processing this batch is:  0.09205150604248047\n",
      "The representation loss after processing this batch is:  0.0024612173438072205\n",
      "\n",
      "The classification loss after processing this batch is:  0.12974487245082855\n",
      "The representation loss after processing this batch is:  0.002262987196445465\n",
      "\n",
      "The classification loss after processing this batch is:  0.07858599722385406\n",
      "The representation loss after processing this batch is:  0.0022148936986923218\n",
      "\n",
      "The classification loss after processing this batch is:  0.11463411897420883\n",
      "The representation loss after processing this batch is:  0.002471618354320526\n",
      "\n",
      "The classification loss after processing this batch is:  0.18065223097801208\n",
      "The representation loss after processing this batch is:  0.002251323312520981\n",
      "\n",
      "The classification loss after processing this batch is:  0.2079612761735916\n",
      "The representation loss after processing this batch is:  0.002112593501806259\n",
      "\n",
      "The classification loss after processing this batch is:  0.1460508555173874\n",
      "The representation loss after processing this batch is:  0.0023021213710308075\n",
      "\n",
      "The classification loss after processing this batch is:  0.06621108204126358\n",
      "The representation loss after processing this batch is:  0.0024888068437576294\n",
      "\n",
      "The classification loss after processing this batch is:  0.151656374335289\n",
      "The representation loss after processing this batch is:  0.0025060176849365234\n",
      "\n",
      "The classification loss after processing this batch is:  0.09230921417474747\n",
      "The representation loss after processing this batch is:  0.002534635365009308\n",
      "\n",
      "The classification loss after processing this batch is:  0.07737764716148376\n",
      "The representation loss after processing this batch is:  0.0025532543659210205\n",
      "\n",
      "The classification loss after processing this batch is:  0.1485927402973175\n",
      "The representation loss after processing this batch is:  0.00276348739862442\n",
      "\n",
      "The classification loss after processing this batch is:  0.1980179101228714\n",
      "The representation loss after processing this batch is:  0.0024271011352539062\n",
      "\n",
      "The classification loss after processing this batch is:  0.27463358640670776\n",
      "The representation loss after processing this batch is:  0.002254728227853775\n",
      "\n",
      "The classification loss after processing this batch is:  0.12354365736246109\n",
      "The representation loss after processing this batch is:  0.0026060566306114197\n",
      "\n",
      "The classification loss after processing this batch is:  0.06297919154167175\n",
      "The representation loss after processing this batch is:  0.00245068222284317\n",
      "\n",
      "The classification loss after processing this batch is:  0.09143170714378357\n",
      "The representation loss after processing this batch is:  0.002686701714992523\n",
      "\n",
      "The classification loss after processing this batch is:  0.16985966265201569\n",
      "The representation loss after processing this batch is:  0.002394750714302063\n",
      "\n",
      "The classification loss after processing this batch is:  0.08565794676542282\n",
      "The representation loss after processing this batch is:  0.002573736011981964\n",
      "\n",
      "The classification loss after processing this batch is:  0.11033887416124344\n",
      "The representation loss after processing this batch is:  0.002359289675951004\n",
      "\n",
      "The classification loss after processing this batch is:  0.10186256468296051\n",
      "The representation loss after processing this batch is:  0.002404913306236267\n",
      "\n",
      "The classification loss after processing this batch is:  0.024762820452451706\n",
      "The representation loss after processing this batch is:  0.00254087895154953\n",
      "\n",
      "The classification loss after processing this batch is:  0.07467350363731384\n",
      "The representation loss after processing this batch is:  0.0026254579424858093\n",
      "\n",
      "The classification loss after processing this batch is:  0.11771472543478012\n",
      "The representation loss after processing this batch is:  0.002676345407962799\n",
      "\n",
      "The classification loss after processing this batch is:  0.13372454047203064\n",
      "The representation loss after processing this batch is:  0.0023414231836795807\n",
      "\n",
      "The classification loss after processing this batch is:  0.11124216765165329\n",
      "The representation loss after processing this batch is:  0.002334125339984894\n",
      "\n",
      "The classification loss after processing this batch is:  0.08663623780012131\n",
      "The representation loss after processing this batch is:  0.0025032535195350647\n",
      "\n",
      "The classification loss after processing this batch is:  0.14231880009174347\n",
      "The representation loss after processing this batch is:  0.002680756151676178\n",
      "\n",
      "The classification loss after processing this batch is:  0.06584066152572632\n",
      "The representation loss after processing this batch is:  0.0026092827320098877\n",
      "\n",
      "The classification loss after processing this batch is:  0.09222432225942612\n",
      "The representation loss after processing this batch is:  0.002819061279296875\n",
      "\n",
      "The classification loss after processing this batch is:  0.10617446154356003\n",
      "The representation loss after processing this batch is:  0.00267723947763443\n",
      "\n",
      "The classification loss after processing this batch is:  0.11391942203044891\n",
      "The representation loss after processing this batch is:  0.0024448782205581665\n",
      "\n",
      "The classification loss after processing this batch is:  0.13734070956707\n",
      "The representation loss after processing this batch is:  0.0022923797369003296\n",
      "\n",
      "The classification loss after processing this batch is:  0.2061259150505066\n",
      "The representation loss after processing this batch is:  0.0022611916065216064\n",
      "\n",
      "The classification loss after processing this batch is:  0.23586627840995789\n",
      "The representation loss after processing this batch is:  0.002399660646915436\n",
      "\n",
      "The classification loss after processing this batch is:  0.05633503571152687\n",
      "The representation loss after processing this batch is:  0.0022002197802066803\n",
      "\n",
      "The classification loss after processing this batch is:  0.09382261335849762\n",
      "The representation loss after processing this batch is:  0.0027515366673469543\n",
      "\n",
      "The classification loss after processing this batch is:  0.10550151020288467\n",
      "The representation loss after processing this batch is:  0.002519868314266205\n",
      "\n",
      "The classification loss after processing this batch is:  0.1253194361925125\n",
      "The representation loss after processing this batch is:  0.0023149102926254272\n",
      "\n",
      "The classification loss after processing this batch is:  0.1943809688091278\n",
      "The representation loss after processing this batch is:  0.0026095807552337646\n",
      "\n",
      "The classification loss after processing this batch is:  0.1722976416349411\n",
      "The representation loss after processing this batch is:  0.002770036458969116\n",
      "\n",
      "The classification loss after processing this batch is:  0.19531068205833435\n",
      "The representation loss after processing this batch is:  0.0029345378279685974\n",
      "\n",
      "The classification loss after processing this batch is:  0.09767045080661774\n",
      "The representation loss after processing this batch is:  0.002760767936706543\n",
      "\n",
      "The classification loss after processing this batch is:  0.14219613373279572\n",
      "The representation loss after processing this batch is:  0.002625860273838043\n",
      "\n",
      "The classification loss after processing this batch is:  0.1544235646724701\n",
      "The representation loss after processing this batch is:  0.0030374228954315186\n",
      "\n",
      "The classification loss after processing this batch is:  0.04880667105317116\n",
      "The representation loss after processing this batch is:  0.0024936944246292114\n",
      "\n",
      "The classification loss after processing this batch is:  0.19583898782730103\n",
      "The representation loss after processing this batch is:  0.0025667473673820496\n",
      "\n",
      "The classification loss after processing this batch is:  0.09939337521791458\n",
      "The representation loss after processing this batch is:  0.0022331178188323975\n",
      "\n",
      "The classification loss after processing this batch is:  0.04157641902565956\n",
      "The representation loss after processing this batch is:  0.0022327564656734467\n",
      "\n",
      "The classification loss after processing this batch is:  0.09947429597377777\n",
      "The representation loss after processing this batch is:  0.0022484883666038513\n",
      "\n",
      "The classification loss after processing this batch is:  0.10883388668298721\n",
      "The representation loss after processing this batch is:  0.002745509147644043\n",
      "\n",
      "The classification loss after processing this batch is:  0.1435427963733673\n",
      "The representation loss after processing this batch is:  0.002190660685300827\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.0762345939874649\n",
      "The representation loss after processing this batch is:  0.0023572519421577454\n",
      "\n",
      "The classification loss after processing this batch is:  0.07207688689231873\n",
      "The representation loss after processing this batch is:  0.00224950909614563\n",
      "\n",
      "The classification loss after processing this batch is:  0.035587992519140244\n",
      "The representation loss after processing this batch is:  0.002359621226787567\n",
      "\n",
      "The classification loss after processing this batch is:  0.14207082986831665\n",
      "The representation loss after processing this batch is:  0.0020651444792747498\n",
      "\n",
      "The classification loss after processing this batch is:  0.08717984706163406\n",
      "The representation loss after processing this batch is:  0.0021059028804302216\n",
      "\n",
      "The classification loss after processing this batch is:  0.4002562165260315\n",
      "The representation loss after processing this batch is:  0.002561904489994049\n",
      "\n",
      "The classification loss after processing this batch is:  0.09137685596942902\n",
      "The representation loss after processing this batch is:  0.0024833232164382935\n",
      "\n",
      "The classification loss after processing this batch is:  0.16506627202033997\n",
      "The representation loss after processing this batch is:  0.0021740607917308807\n",
      "\n",
      "The classification loss after processing this batch is:  0.21352481842041016\n",
      "The representation loss after processing this batch is:  0.0024969130754470825\n",
      "\n",
      "The classification loss after processing this batch is:  0.0733482763171196\n",
      "The representation loss after processing this batch is:  0.002253793179988861\n",
      "\n",
      "The classification loss after processing this batch is:  0.22456884384155273\n",
      "The representation loss after processing this batch is:  0.002563580870628357\n",
      "\n",
      "The classification loss after processing this batch is:  0.1147499829530716\n",
      "The representation loss after processing this batch is:  0.002591244876384735\n",
      "\n",
      "The classification loss after processing this batch is:  0.22411446273326874\n",
      "The representation loss after processing this batch is:  0.002185411751270294\n",
      "\n",
      "The classification loss after processing this batch is:  0.04586481675505638\n",
      "The representation loss after processing this batch is:  0.002136930823326111\n",
      "\n",
      "The classification loss after processing this batch is:  0.09528517723083496\n",
      "The representation loss after processing this batch is:  0.002541974186897278\n",
      "\n",
      "The classification loss after processing this batch is:  0.028847046196460724\n",
      "The representation loss after processing this batch is:  0.0024525895714759827\n",
      "\n",
      "The classification loss after processing this batch is:  0.028490494936704636\n",
      "The representation loss after processing this batch is:  0.0025272294878959656\n",
      "\n",
      "The classification loss after processing this batch is:  0.057715512812137604\n",
      "The representation loss after processing this batch is:  0.0023080632090568542\n",
      "\n",
      "The classification loss after processing this batch is:  0.050196573138237\n",
      "The representation loss after processing this batch is:  0.002301231026649475\n",
      "\n",
      "The classification loss after processing this batch is:  0.13174200057983398\n",
      "The representation loss after processing this batch is:  0.0026130899786949158\n",
      "\n",
      "The classification loss after processing this batch is:  0.08122192323207855\n",
      "The representation loss after processing this batch is:  0.0027899891138076782\n",
      "\n",
      "The classification loss after processing this batch is:  0.06706397235393524\n",
      "The representation loss after processing this batch is:  0.0022680312395095825\n",
      "\n",
      "The classification loss after processing this batch is:  0.12070158869028091\n",
      "The representation loss after processing this batch is:  0.0021638236939907074\n",
      "\n",
      "The classification loss after processing this batch is:  0.05688266083598137\n",
      "The representation loss after processing this batch is:  0.002711288630962372\n",
      "\n",
      "The classification loss after processing this batch is:  0.09490057826042175\n",
      "The representation loss after processing this batch is:  0.002523943781852722\n",
      "\n",
      "The classification loss after processing this batch is:  0.11453840136528015\n",
      "The representation loss after processing this batch is:  0.0024790167808532715\n",
      "\n",
      "The classification loss after processing this batch is:  0.16577164828777313\n",
      "The representation loss after processing this batch is:  0.0026265308260917664\n",
      "\n",
      "The classification loss after processing this batch is:  0.09970226138830185\n",
      "The representation loss after processing this batch is:  0.0022629648447036743\n",
      "\n",
      "The classification loss after processing this batch is:  0.07213049381971359\n",
      "The representation loss after processing this batch is:  0.002384353429079056\n",
      "\n",
      "The classification loss after processing this batch is:  0.17463164031505585\n",
      "The representation loss after processing this batch is:  0.002582170069217682\n",
      "\n",
      "The classification loss after processing this batch is:  0.14900042116641998\n",
      "The representation loss after processing this batch is:  0.002388380467891693\n",
      "\n",
      "The classification loss after processing this batch is:  0.1255721002817154\n",
      "The representation loss after processing this batch is:  0.002380192279815674\n",
      "\n",
      "The classification loss after processing this batch is:  0.0452379435300827\n",
      "The representation loss after processing this batch is:  0.0023584887385368347\n",
      "\n",
      "The classification loss after processing this batch is:  0.11825523525476456\n",
      "The representation loss after processing this batch is:  0.0026958584785461426\n",
      "\n",
      "The classification loss after processing this batch is:  0.11929801851511002\n",
      "The representation loss after processing this batch is:  0.002611059695482254\n",
      "\n",
      "The classification loss after processing this batch is:  0.11381129920482635\n",
      "The representation loss after processing this batch is:  0.00271538645029068\n",
      "\n",
      "The classification loss after processing this batch is:  0.11171923577785492\n",
      "The representation loss after processing this batch is:  0.003151997923851013\n",
      "\n",
      "The classification loss after processing this batch is:  0.07529637217521667\n",
      "The representation loss after processing this batch is:  0.003004368394613266\n",
      "\n",
      "The classification loss after processing this batch is:  0.12938816845417023\n",
      "The representation loss after processing this batch is:  0.0027346163988113403\n",
      "\n",
      "The classification loss after processing this batch is:  0.1969551146030426\n",
      "The representation loss after processing this batch is:  0.0026359371840953827\n",
      "\n",
      "The classification loss after processing this batch is:  0.10178633779287338\n",
      "The representation loss after processing this batch is:  0.0031444504857063293\n",
      "\n",
      "The classification loss after processing this batch is:  0.09210758656263351\n",
      "The representation loss after processing this batch is:  0.0025389492511749268\n",
      "\n",
      "The classification loss after processing this batch is:  0.03224194049835205\n",
      "The representation loss after processing this batch is:  0.0021324194967746735\n",
      "\n",
      "The classification loss after processing this batch is:  0.15818054974079132\n",
      "The representation loss after processing this batch is:  0.0022827833890914917\n",
      "\n",
      "The classification loss after processing this batch is:  0.06398890912532806\n",
      "The representation loss after processing this batch is:  0.0024473071098327637\n",
      "\n",
      "The classification loss after processing this batch is:  0.10698079317808151\n",
      "The representation loss after processing this batch is:  0.002452671527862549\n",
      "\n",
      "The classification loss after processing this batch is:  0.09830182045698166\n",
      "The representation loss after processing this batch is:  0.0028137266635894775\n",
      "\n",
      "The classification loss after processing this batch is:  0.08287646621465683\n",
      "The representation loss after processing this batch is:  0.002372249960899353\n",
      "\n",
      "The classification loss after processing this batch is:  0.09213493764400482\n",
      "The representation loss after processing this batch is:  0.0025752075016498566\n",
      "\n",
      "The classification loss after processing this batch is:  0.1219504103064537\n",
      "The representation loss after processing this batch is:  0.0029228031635284424\n",
      "\n",
      "The classification loss after processing this batch is:  0.12703843414783478\n",
      "The representation loss after processing this batch is:  0.0028377845883369446\n",
      "\n",
      "The classification loss after processing this batch is:  0.1103328987956047\n",
      "The representation loss after processing this batch is:  0.0023253001272678375\n",
      "\n",
      "The classification loss after processing this batch is:  0.13368424773216248\n",
      "The representation loss after processing this batch is:  0.0028670653700828552\n",
      "\n",
      "The classification loss after processing this batch is:  0.06716060638427734\n",
      "The representation loss after processing this batch is:  0.0022971779108047485\n",
      "\n",
      "The classification loss after processing this batch is:  0.07502608001232147\n",
      "The representation loss after processing this batch is:  0.0024115964770317078\n",
      "\n",
      "The classification loss after processing this batch is:  0.054965268820524216\n",
      "The representation loss after processing this batch is:  0.002831093966960907\n",
      "\n",
      "The classification loss after processing this batch is:  0.0758364275097847\n",
      "The representation loss after processing this batch is:  0.0025149472057819366\n",
      "\n",
      "The classification loss after processing this batch is:  0.05001802369952202\n",
      "The representation loss after processing this batch is:  0.0025059059262275696\n",
      "\n",
      "The classification loss after processing this batch is:  0.05157328397035599\n",
      "The representation loss after processing this batch is:  0.0022345930337905884\n",
      "\n",
      "The classification loss after processing this batch is:  0.049245163798332214\n",
      "The representation loss after processing this batch is:  0.0026736631989479065\n",
      "\n",
      "The classification loss after processing this batch is:  0.04468685761094093\n",
      "The representation loss after processing this batch is:  0.0026392564177513123\n",
      "\n",
      "The classification loss after processing this batch is:  0.11755567044019699\n",
      "The representation loss after processing this batch is:  0.002334892749786377\n",
      "\n",
      "The classification loss after processing this batch is:  0.0683707445859909\n",
      "The representation loss after processing this batch is:  0.0021509863436222076\n",
      "\n",
      "The classification loss after processing this batch is:  0.09443508088588715\n",
      "The representation loss after processing this batch is:  0.0024706944823265076\n",
      "\n",
      "The classification loss after processing this batch is:  0.054103098809719086\n",
      "The representation loss after processing this batch is:  0.002644360065460205\n",
      "\n",
      "The classification loss after processing this batch is:  0.15028683841228485\n",
      "The representation loss after processing this batch is:  0.002400524914264679\n",
      "\n",
      "The classification loss after processing this batch is:  0.13119859993457794\n",
      "The representation loss after processing this batch is:  0.002322778105735779\n",
      "\n",
      "The classification loss after processing this batch is:  0.10386238247156143\n",
      "The representation loss after processing this batch is:  0.002409830689430237\n",
      "\n",
      "The classification loss after processing this batch is:  0.07891087979078293\n",
      "The representation loss after processing this batch is:  0.002454012632369995\n",
      "\n",
      "The classification loss after processing this batch is:  0.10355851799249649\n",
      "The representation loss after processing this batch is:  0.002603694796562195\n",
      "\n",
      "The classification loss after processing this batch is:  0.05251658707857132\n",
      "The representation loss after processing this batch is:  0.002380847930908203\n",
      "\n",
      "The classification loss after processing this batch is:  0.050746433436870575\n",
      "The representation loss after processing this batch is:  0.0024427250027656555\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.0561179555952549\n",
      "The representation loss after processing this batch is:  0.002382814884185791\n",
      "\n",
      "The classification loss after processing this batch is:  0.14872010052204132\n",
      "The representation loss after processing this batch is:  0.0024422183632850647\n",
      "\n",
      "The classification loss after processing this batch is:  0.11557020246982574\n",
      "The representation loss after processing this batch is:  0.0022347457706928253\n",
      "\n",
      "The classification loss after processing this batch is:  0.11166661232709885\n",
      "The representation loss after processing this batch is:  0.002772189676761627\n",
      "\n",
      "The classification loss after processing this batch is:  0.13863107562065125\n",
      "The representation loss after processing this batch is:  0.002463698387145996\n",
      "\n",
      "The classification loss after processing this batch is:  0.12790341675281525\n",
      "The representation loss after processing this batch is:  0.0026193782687187195\n",
      "\n",
      "The classification loss after processing this batch is:  0.1300889253616333\n",
      "The representation loss after processing this batch is:  0.0023791566491127014\n",
      "\n",
      "The classification loss after processing this batch is:  0.22765454649925232\n",
      "The representation loss after processing this batch is:  0.0023422054946422577\n",
      "\n",
      "The classification loss after processing this batch is:  0.16582992672920227\n",
      "The representation loss after processing this batch is:  0.002316415309906006\n",
      "\n",
      "The classification loss after processing this batch is:  0.09108882397413254\n",
      "The representation loss after processing this batch is:  0.0021736547350883484\n",
      "\n",
      "The classification loss after processing this batch is:  0.05486123636364937\n",
      "The representation loss after processing this batch is:  0.0023822449147701263\n",
      "\n",
      "The classification loss after processing this batch is:  0.05446771904826164\n",
      "The representation loss after processing this batch is:  0.002203211188316345\n",
      "\n",
      "The classification loss after processing this batch is:  0.04650431498885155\n",
      "The representation loss after processing this batch is:  0.0024274885654449463\n",
      "\n",
      "The classification loss after processing this batch is:  0.05248722806572914\n",
      "The representation loss after processing this batch is:  0.0027885958552360535\n",
      "\n",
      "The classification loss after processing this batch is:  0.11504696309566498\n",
      "The representation loss after processing this batch is:  0.0023505017161369324\n",
      "\n",
      "The classification loss after processing this batch is:  0.07141044735908508\n",
      "The representation loss after processing this batch is:  0.002496764063835144\n",
      "\n",
      "The classification loss after processing this batch is:  0.1659177988767624\n",
      "The representation loss after processing this batch is:  0.0023841261863708496\n",
      "\n",
      "The classification loss after processing this batch is:  0.10985182225704193\n",
      "The representation loss after processing this batch is:  0.0026208609342575073\n",
      "\n",
      "The classification loss after processing this batch is:  0.15219683945178986\n",
      "The representation loss after processing this batch is:  0.002132970839738846\n",
      "\n",
      "The classification loss after processing this batch is:  0.10370979458093643\n",
      "The representation loss after processing this batch is:  0.002278462052345276\n",
      "\n",
      "The classification loss after processing this batch is:  0.16831114888191223\n",
      "The representation loss after processing this batch is:  0.002199523150920868\n",
      "\n",
      "The classification loss after processing this batch is:  0.08652906864881516\n",
      "The representation loss after processing this batch is:  0.0021925754845142365\n",
      "\n",
      "The classification loss after processing this batch is:  0.08843608945608139\n",
      "The representation loss after processing this batch is:  0.002495899796485901\n",
      "\n",
      "The classification loss after processing this batch is:  0.13454900681972504\n",
      "The representation loss after processing this batch is:  0.0022948607802391052\n",
      "\n",
      "The classification loss after processing this batch is:  0.04884357377886772\n",
      "The representation loss after processing this batch is:  0.002269003540277481\n",
      "\n",
      "The classification loss after processing this batch is:  0.04114435985684395\n",
      "The representation loss after processing this batch is:  0.0023047924041748047\n",
      "\n",
      "The classification loss after processing this batch is:  0.1240597665309906\n",
      "The representation loss after processing this batch is:  0.002706088125705719\n",
      "\n",
      "The classification loss after processing this batch is:  0.16828486323356628\n",
      "The representation loss after processing this batch is:  0.002358555793762207\n",
      "\n",
      "The classification loss after processing this batch is:  0.11248771101236343\n",
      "The representation loss after processing this batch is:  0.0026222392916679382\n",
      "\n",
      "The classification loss after processing this batch is:  0.0563635416328907\n",
      "The representation loss after processing this batch is:  0.0026108622550964355\n",
      "\n",
      "The classification loss after processing this batch is:  0.08658349514007568\n",
      "The representation loss after processing this batch is:  0.0027045905590057373\n",
      "\n",
      "The classification loss after processing this batch is:  0.07409028708934784\n",
      "The representation loss after processing this batch is:  0.0024965405464172363\n",
      "\n",
      "The classification loss after processing this batch is:  0.24222755432128906\n",
      "The representation loss after processing this batch is:  0.0024330057203769684\n",
      "\n",
      "The classification loss after processing this batch is:  0.06182818487286568\n",
      "The representation loss after processing this batch is:  0.002339467406272888\n",
      "\n",
      "The classification loss after processing this batch is:  0.03618418425321579\n",
      "The representation loss after processing this batch is:  0.0024440735578536987\n",
      "\n",
      "The classification loss after processing this batch is:  0.12718772888183594\n",
      "The representation loss after processing this batch is:  0.0028338953852653503\n",
      "\n",
      "The classification loss after processing this batch is:  0.09804142266511917\n",
      "The representation loss after processing this batch is:  0.0025856569409370422\n",
      "\n",
      "The classification loss after processing this batch is:  0.05923162028193474\n",
      "The representation loss after processing this batch is:  0.0026217028498649597\n",
      "\n",
      "The classification loss after processing this batch is:  0.044342849403619766\n",
      "The representation loss after processing this batch is:  0.0022148825228214264\n",
      "\n",
      "The classification loss after processing this batch is:  0.09123996645212173\n",
      "The representation loss after processing this batch is:  0.0029620304703712463\n",
      "\n",
      "The classification loss after processing this batch is:  0.1456478238105774\n",
      "The representation loss after processing this batch is:  0.002803586423397064\n",
      "\n",
      "The classification loss after processing this batch is:  0.1945321261882782\n",
      "The representation loss after processing this batch is:  0.002210024744272232\n",
      "\n",
      "The classification loss after processing this batch is:  0.1522744745016098\n",
      "The representation loss after processing this batch is:  0.0027033761143684387\n",
      "\n",
      "The classification loss after processing this batch is:  0.04693600907921791\n",
      "The representation loss after processing this batch is:  0.0025426074862480164\n",
      "\n",
      "The classification loss after processing this batch is:  0.0550321489572525\n",
      "The representation loss after processing this batch is:  0.002159368246793747\n",
      "\n",
      "The classification loss after processing this batch is:  0.11876635253429413\n",
      "The representation loss after processing this batch is:  0.0025652050971984863\n",
      "\n",
      "The classification loss after processing this batch is:  0.16577139496803284\n",
      "The representation loss after processing this batch is:  0.0025880932807922363\n",
      "\n",
      "The classification loss after processing this batch is:  0.17122681438922882\n",
      "The representation loss after processing this batch is:  0.002747572958469391\n",
      "\n",
      "The classification loss after processing this batch is:  0.1940317153930664\n",
      "The representation loss after processing this batch is:  0.002220515161752701\n",
      "\n",
      "The classification loss after processing this batch is:  0.09380129724740982\n",
      "The representation loss after processing this batch is:  0.0022171661257743835\n",
      "\n",
      "The classification loss after processing this batch is:  0.1643078476190567\n",
      "The representation loss after processing this batch is:  0.00223415344953537\n",
      "\n",
      "The classification loss after processing this batch is:  0.07595992833375931\n",
      "The representation loss after processing this batch is:  0.002085670828819275\n",
      "\n",
      "The classification loss after processing this batch is:  0.08032198995351791\n",
      "The representation loss after processing this batch is:  0.002457752823829651\n",
      "\n",
      "The classification loss after processing this batch is:  0.0470084547996521\n",
      "The representation loss after processing this batch is:  0.0023602619767189026\n",
      "\n",
      "The classification loss after processing this batch is:  0.10989408195018768\n",
      "The representation loss after processing this batch is:  0.002459883689880371\n",
      "\n",
      "The classification loss after processing this batch is:  0.10779210925102234\n",
      "The representation loss after processing this batch is:  0.002247937023639679\n",
      "\n",
      "The classification loss after processing this batch is:  0.07858148962259293\n",
      "The representation loss after processing this batch is:  0.0023982152342796326\n",
      "\n",
      "The classification loss after processing this batch is:  0.1455487757921219\n",
      "The representation loss after processing this batch is:  0.0026016682386398315\n",
      "\n",
      "The classification loss after processing this batch is:  0.03873016685247421\n",
      "The representation loss after processing this batch is:  0.002674773335456848\n",
      "\n",
      "The classification loss after processing this batch is:  0.08822129666805267\n",
      "The representation loss after processing this batch is:  0.0026109442114830017\n",
      "\n",
      "The classification loss after processing this batch is:  0.09136185795068741\n",
      "The representation loss after processing this batch is:  0.002316683530807495\n",
      "\n",
      "The classification loss after processing this batch is:  0.1688939929008484\n",
      "The representation loss after processing this batch is:  0.002557571977376938\n",
      "\n",
      "The classification loss after processing this batch is:  0.046280618757009506\n",
      "The representation loss after processing this batch is:  0.002999603748321533\n",
      "\n",
      "The classification loss after processing this batch is:  0.07330505549907684\n",
      "The representation loss after processing this batch is:  0.0022175125777721405\n",
      "\n",
      "The classification loss after processing this batch is:  0.15486739575862885\n",
      "The representation loss after processing this batch is:  0.002578146755695343\n",
      "\n",
      "The classification loss after processing this batch is:  0.09610245376825333\n",
      "The representation loss after processing this batch is:  0.0023377500474452972\n",
      "\n",
      "The classification loss after processing this batch is:  0.13891687989234924\n",
      "The representation loss after processing this batch is:  0.0022792965173721313\n",
      "\n",
      "The classification loss after processing this batch is:  0.10037294775247574\n",
      "The representation loss after processing this batch is:  0.0022601447999477386\n",
      "\n",
      "The classification loss after processing this batch is:  0.05454316362738609\n",
      "The representation loss after processing this batch is:  0.0024765878915786743\n",
      "\n",
      "The classification loss after processing this batch is:  0.12622523307800293\n",
      "The representation loss after processing this batch is:  0.0020035766065120697\n",
      "\n",
      "The classification loss after processing this batch is:  0.08660563081502914\n",
      "The representation loss after processing this batch is:  0.0024522021412849426\n",
      "\n",
      "The classification loss after processing this batch is:  0.11447521299123764\n",
      "The representation loss after processing this batch is:  0.0024374574422836304\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10664430260658264\n",
      "The representation loss after processing this batch is:  0.003004036843776703\n",
      "\n",
      "The classification loss after processing this batch is:  0.05119611695408821\n",
      "The representation loss after processing this batch is:  0.0024757906794548035\n",
      "\n",
      "The classification loss after processing this batch is:  0.120160311460495\n",
      "The representation loss after processing this batch is:  0.002356886863708496\n",
      "\n",
      "The classification loss after processing this batch is:  0.14507092535495758\n",
      "The representation loss after processing this batch is:  0.0026682615280151367\n",
      "\n",
      "The classification loss after processing this batch is:  0.033578936010599136\n",
      "The representation loss after processing this batch is:  0.002518393099308014\n",
      "\n",
      "The classification loss after processing this batch is:  0.08287166059017181\n",
      "The representation loss after processing this batch is:  0.002124771475791931\n",
      "\n",
      "The classification loss after processing this batch is:  0.1402546465396881\n",
      "The representation loss after processing this batch is:  0.002252712845802307\n",
      "\n",
      "The classification loss after processing this batch is:  0.14679813385009766\n",
      "The representation loss after processing this batch is:  0.00245802104473114\n",
      "\n",
      "The classification loss after processing this batch is:  0.09973010420799255\n",
      "The representation loss after processing this batch is:  0.002320796251296997\n",
      "\n",
      "The classification loss after processing this batch is:  0.15387548506259918\n",
      "The representation loss after processing this batch is:  0.002432800829410553\n",
      "\n",
      "The classification loss after processing this batch is:  0.11836306005716324\n",
      "The representation loss after processing this batch is:  0.0024593695998191833\n",
      "\n",
      "The classification loss after processing this batch is:  0.1628938466310501\n",
      "The representation loss after processing this batch is:  0.0026168152689933777\n",
      "\n",
      "The classification loss after processing this batch is:  0.07402658462524414\n",
      "The representation loss after processing this batch is:  0.002634882926940918\n",
      "\n",
      "The classification loss after processing this batch is:  0.1571323573589325\n",
      "The representation loss after processing this batch is:  0.0023930929601192474\n",
      "\n",
      "The classification loss after processing this batch is:  0.09678465873003006\n",
      "The representation loss after processing this batch is:  0.003359951078891754\n",
      "\n",
      "The classification loss after processing this batch is:  0.051947034895420074\n",
      "The representation loss after processing this batch is:  0.0024704113602638245\n",
      "\n",
      "The classification loss after processing this batch is:  0.07892663776874542\n",
      "The representation loss after processing this batch is:  0.0024369284510612488\n",
      "\n",
      "The classification loss after processing this batch is:  0.07516685128211975\n",
      "The representation loss after processing this batch is:  0.002280794084072113\n",
      "\n",
      "The classification loss after processing this batch is:  0.10004124045372009\n",
      "The representation loss after processing this batch is:  0.002444319427013397\n",
      "\n",
      "The classification loss after processing this batch is:  0.0868213102221489\n",
      "The representation loss after processing this batch is:  0.0023520663380622864\n",
      "\n",
      "The classification loss after processing this batch is:  0.1575240194797516\n",
      "The representation loss after processing this batch is:  0.0025153644382953644\n",
      "\n",
      "The classification loss after processing this batch is:  0.038259074091911316\n",
      "The representation loss after processing this batch is:  0.002444826066493988\n",
      "\n",
      "The classification loss after processing this batch is:  0.05549272522330284\n",
      "The representation loss after processing this batch is:  0.0026853904128074646\n",
      "\n",
      "The classification loss after processing this batch is:  0.1502414345741272\n",
      "The representation loss after processing this batch is:  0.0026460587978363037\n",
      "\n",
      "The classification loss after processing this batch is:  0.026194564998149872\n",
      "The representation loss after processing this batch is:  0.002371162176132202\n",
      "\n",
      "The classification loss after processing this batch is:  0.06814848631620407\n",
      "The representation loss after processing this batch is:  0.0023304596543312073\n",
      "\n",
      "The classification loss after processing this batch is:  0.04298752173781395\n",
      "The representation loss after processing this batch is:  0.002540692687034607\n",
      "\n",
      "The classification loss after processing this batch is:  0.0938011184334755\n",
      "The representation loss after processing this batch is:  0.0022855624556541443\n",
      "\n",
      "The classification loss after processing this batch is:  0.14560015499591827\n",
      "The representation loss after processing this batch is:  0.002807989716529846\n",
      "\n",
      "The classification loss after processing this batch is:  0.1450144350528717\n",
      "The representation loss after processing this batch is:  0.0034479647874832153\n",
      "\n",
      "The classification loss after processing this batch is:  0.13214945793151855\n",
      "The representation loss after processing this batch is:  0.003064475953578949\n",
      "\n",
      "The classification loss after processing this batch is:  0.0640503466129303\n",
      "The representation loss after processing this batch is:  0.0026989132165908813\n",
      "\n",
      "The classification loss after processing this batch is:  0.1089407280087471\n",
      "The representation loss after processing this batch is:  0.0022993534803390503\n",
      "\n",
      "The classification loss after processing this batch is:  0.1120993122458458\n",
      "The representation loss after processing this batch is:  0.0025184154510498047\n",
      "\n",
      "The classification loss after processing this batch is:  0.05039123818278313\n",
      "The representation loss after processing this batch is:  0.0026154108345508575\n",
      "\n",
      "The classification loss after processing this batch is:  0.0469670444726944\n",
      "The representation loss after processing this batch is:  0.0022723935544490814\n",
      "\n",
      "The classification loss after processing this batch is:  0.03802725300192833\n",
      "The representation loss after processing this batch is:  0.0027515962719917297\n",
      "\n",
      "The classification loss after processing this batch is:  0.07188538461923599\n",
      "The representation loss after processing this batch is:  0.0027141086757183075\n",
      "\n",
      "The classification loss after processing this batch is:  0.16557081043720245\n",
      "The representation loss after processing this batch is:  0.002618107944726944\n",
      "\n",
      "The classification loss after processing this batch is:  0.12416679412126541\n",
      "The representation loss after processing this batch is:  0.00234125554561615\n",
      "\n",
      "The classification loss after processing this batch is:  0.11317159980535507\n",
      "The representation loss after processing this batch is:  0.0030980184674263\n",
      "\n",
      "The classification loss after processing this batch is:  0.08229415118694305\n",
      "The representation loss after processing this batch is:  0.0028829574584960938\n",
      "\n",
      "The classification loss after processing this batch is:  0.10836751759052277\n",
      "The representation loss after processing this batch is:  0.0025278478860855103\n",
      "\n",
      "The classification loss after processing this batch is:  0.06962823122739792\n",
      "The representation loss after processing this batch is:  0.0023144111037254333\n",
      "\n",
      "The classification loss after processing this batch is:  0.31511369347572327\n",
      "The representation loss after processing this batch is:  0.0026695802807807922\n",
      "\n",
      "The classification loss after processing this batch is:  0.08400554209947586\n",
      "The representation loss after processing this batch is:  0.00278298556804657\n",
      "\n",
      "The classification loss after processing this batch is:  0.21088892221450806\n",
      "The representation loss after processing this batch is:  0.003189168870449066\n",
      "\n",
      "The classification loss after processing this batch is:  0.09383438527584076\n",
      "The representation loss after processing this batch is:  0.0022670328617095947\n",
      "\n",
      "The classification loss after processing this batch is:  0.09592773020267487\n",
      "The representation loss after processing this batch is:  0.0024127811193466187\n",
      "\n",
      "The classification loss after processing this batch is:  0.15120863914489746\n",
      "The representation loss after processing this batch is:  0.002346038818359375\n",
      "\n",
      "The classification loss after processing this batch is:  0.09402858465909958\n",
      "The representation loss after processing this batch is:  0.002525635063648224\n",
      "\n",
      "The classification loss after processing this batch is:  0.16841815412044525\n",
      "The representation loss after processing this batch is:  0.0026275217533111572\n",
      "\n",
      "The classification loss after processing this batch is:  0.11449538916349411\n",
      "The representation loss after processing this batch is:  0.0027642399072647095\n",
      "\n",
      "The classification loss after processing this batch is:  0.12838168442249298\n",
      "The representation loss after processing this batch is:  0.0030170679092407227\n",
      "\n",
      "The classification loss after processing this batch is:  0.14809688925743103\n",
      "The representation loss after processing this batch is:  0.0027405768632888794\n",
      "\n",
      "The classification loss after processing this batch is:  0.03272136300802231\n",
      "The representation loss after processing this batch is:  0.0025513991713523865\n",
      "\n",
      "The classification loss after processing this batch is:  0.11337710916996002\n",
      "The representation loss after processing this batch is:  0.0022557713091373444\n",
      "\n",
      "The classification loss after processing this batch is:  0.10989547520875931\n",
      "The representation loss after processing this batch is:  0.0022327378392219543\n",
      "\n",
      "The classification loss after processing this batch is:  0.040333762764930725\n",
      "The representation loss after processing this batch is:  0.0025306642055511475\n",
      "\n",
      "The classification loss after processing this batch is:  0.13203448057174683\n",
      "The representation loss after processing this batch is:  0.0022839754819869995\n",
      "\n",
      "The classification loss after processing this batch is:  0.2189747840166092\n",
      "The representation loss after processing this batch is:  0.0025806352496147156\n",
      "\n",
      "The classification loss after processing this batch is:  0.0971107929944992\n",
      "The representation loss after processing this batch is:  0.002060018479824066\n",
      "\n",
      "The classification loss after processing this batch is:  0.07145794481039047\n",
      "The representation loss after processing this batch is:  0.0025968700647354126\n",
      "\n",
      "The classification loss after processing this batch is:  0.08588109165430069\n",
      "The representation loss after processing this batch is:  0.0023358985781669617\n",
      "\n",
      "The classification loss after processing this batch is:  0.07270157337188721\n",
      "The representation loss after processing this batch is:  0.002465367317199707\n",
      "\n",
      "The classification loss after processing this batch is:  0.09094347804784775\n",
      "The representation loss after processing this batch is:  0.0027738213539123535\n",
      "\n",
      "The classification loss after processing this batch is:  0.04759443178772926\n",
      "The representation loss after processing this batch is:  0.002633415162563324\n",
      "\n",
      "The classification loss after processing this batch is:  0.11673438549041748\n",
      "The representation loss after processing this batch is:  0.0022788122296333313\n",
      "\n",
      "The classification loss after processing this batch is:  0.12363333255052567\n",
      "The representation loss after processing this batch is:  0.0021632909774780273\n",
      "\n",
      "The classification loss after processing this batch is:  0.06805311888456345\n",
      "The representation loss after processing this batch is:  0.002553701400756836\n",
      "\n",
      "The classification loss after processing this batch is:  0.13717414438724518\n",
      "The representation loss after processing this batch is:  0.002145159989595413\n",
      "\n",
      "The classification loss after processing this batch is:  0.11053140461444855\n",
      "The representation loss after processing this batch is:  0.0021626949310302734\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.061404749751091\n",
      "The representation loss after processing this batch is:  0.0024327486753463745\n",
      "\n",
      "The classification loss after processing this batch is:  0.062013447284698486\n",
      "The representation loss after processing this batch is:  0.002408847212791443\n",
      "\n",
      "The classification loss after processing this batch is:  0.1137370690703392\n",
      "The representation loss after processing this batch is:  0.002362869679927826\n",
      "\n",
      "The classification loss after processing this batch is:  0.0486435741186142\n",
      "The representation loss after processing this batch is:  0.0024733170866966248\n",
      "\n",
      "The classification loss after processing this batch is:  0.3196057081222534\n",
      "The representation loss after processing this batch is:  0.0022429488599300385\n",
      "\n",
      "The classification loss after processing this batch is:  0.09980213642120361\n",
      "The representation loss after processing this batch is:  0.002695903182029724\n",
      "\n",
      "The classification loss after processing this batch is:  0.16067011654376984\n",
      "The representation loss after processing this batch is:  0.002239629626274109\n",
      "\n",
      "The classification loss after processing this batch is:  0.06767479330301285\n",
      "The representation loss after processing this batch is:  0.0021323151886463165\n",
      "\n",
      "The classification loss after processing this batch is:  0.10130102187395096\n",
      "The representation loss after processing this batch is:  0.002409890294075012\n",
      "\n",
      "The classification loss after processing this batch is:  0.06374134123325348\n",
      "The representation loss after processing this batch is:  0.0021486282348632812\n",
      "\n",
      "The classification loss after processing this batch is:  0.07803032547235489\n",
      "The representation loss after processing this batch is:  0.0023002438247203827\n",
      "\n",
      "The classification loss after processing this batch is:  0.1576208621263504\n",
      "The representation loss after processing this batch is:  0.0023703686892986298\n",
      "\n",
      "The classification loss after processing this batch is:  0.10120349377393723\n",
      "The representation loss after processing this batch is:  0.003011804074048996\n",
      "\n",
      "The classification loss after processing this batch is:  0.13896605372428894\n",
      "The representation loss after processing this batch is:  0.0025090910494327545\n",
      "\n",
      "The classification loss after processing this batch is:  0.08789266645908356\n",
      "The representation loss after processing this batch is:  0.0025186687707901\n",
      "\n",
      "The classification loss after processing this batch is:  0.1393173635005951\n",
      "The representation loss after processing this batch is:  0.0026794150471687317\n",
      "\n",
      "The classification loss after processing this batch is:  0.1481439471244812\n",
      "The representation loss after processing this batch is:  0.0025503411889076233\n",
      "\n",
      "The classification loss after processing this batch is:  0.16532884538173676\n",
      "The representation loss after processing this batch is:  0.0024404600262641907\n",
      "\n",
      "The classification loss after processing this batch is:  0.07320253551006317\n",
      "The representation loss after processing this batch is:  0.0025336146354675293\n",
      "\n",
      "The classification loss after processing this batch is:  0.09044843167066574\n",
      "The representation loss after processing this batch is:  0.0029350146651268005\n",
      "\n",
      "The classification loss after processing this batch is:  0.042880818247795105\n",
      "The representation loss after processing this batch is:  0.002470351755619049\n",
      "\n",
      "The classification loss after processing this batch is:  0.16219298541545868\n",
      "The representation loss after processing this batch is:  0.0022511817514896393\n",
      "\n",
      "The classification loss after processing this batch is:  0.20359134674072266\n",
      "The representation loss after processing this batch is:  0.0025233961641788483\n",
      "\n",
      "The classification loss after processing this batch is:  0.07530924677848816\n",
      "The representation loss after processing this batch is:  0.0028740018606185913\n",
      "\n",
      "The classification loss after processing this batch is:  0.13078783452510834\n",
      "The representation loss after processing this batch is:  0.0027495697140693665\n",
      "\n",
      "The classification loss after processing this batch is:  0.1483595222234726\n",
      "The representation loss after processing this batch is:  0.0023725368082523346\n",
      "\n",
      "The classification loss after processing this batch is:  0.15860438346862793\n",
      "The representation loss after processing this batch is:  0.002594955265522003\n",
      "\n",
      "The classification loss after processing this batch is:  0.04387078434228897\n",
      "The representation loss after processing this batch is:  0.002321634441614151\n",
      "\n",
      "The classification loss after processing this batch is:  0.12565551698207855\n",
      "The representation loss after processing this batch is:  0.002535507082939148\n",
      "\n",
      "The classification loss after processing this batch is:  0.13820883631706238\n",
      "The representation loss after processing this batch is:  0.0025379955768585205\n",
      "\n",
      "The classification loss after processing this batch is:  0.07767622172832489\n",
      "The representation loss after processing this batch is:  0.002551298588514328\n",
      "\n",
      "The classification loss after processing this batch is:  0.039802927523851395\n",
      "The representation loss after processing this batch is:  0.00275488942861557\n",
      "\n",
      "The classification loss after processing this batch is:  0.08445741981267929\n",
      "The representation loss after processing this batch is:  0.0024302303791046143\n",
      "\n",
      "The classification loss after processing this batch is:  0.08416052907705307\n",
      "The representation loss after processing this batch is:  0.0026932507753372192\n",
      "\n",
      "The classification loss after processing this batch is:  0.09058827906847\n",
      "The representation loss after processing this batch is:  0.002284090965986252\n",
      "\n",
      "The classification loss after processing this batch is:  0.17439696192741394\n",
      "The representation loss after processing this batch is:  0.002538546919822693\n",
      "\n",
      "The classification loss after processing this batch is:  0.1204625591635704\n",
      "The representation loss after processing this batch is:  0.0022148117423057556\n",
      "\n",
      "The classification loss after processing this batch is:  0.09489666670560837\n",
      "The representation loss after processing this batch is:  0.0027436241507530212\n",
      "\n",
      "The classification loss after processing this batch is:  0.144106924533844\n",
      "The representation loss after processing this batch is:  0.0026939325034618378\n",
      "\n",
      "The classification loss after processing this batch is:  0.09383494406938553\n",
      "The representation loss after processing this batch is:  0.002829737961292267\n",
      "\n",
      "The classification loss after processing this batch is:  0.08504165709018707\n",
      "The representation loss after processing this batch is:  0.0023613721132278442\n",
      "\n",
      "The classification loss after processing this batch is:  0.15243230760097504\n",
      "The representation loss after processing this batch is:  0.0024790316820144653\n",
      "\n",
      "The classification loss after processing this batch is:  0.1671236902475357\n",
      "The representation loss after processing this batch is:  0.0031980201601982117\n",
      "\n",
      "The classification loss after processing this batch is:  0.11513812839984894\n",
      "The representation loss after processing this batch is:  0.0026122406125068665\n",
      "\n",
      "The classification loss after processing this batch is:  0.05570559576153755\n",
      "The representation loss after processing this batch is:  0.002666708081960678\n",
      "\n",
      "The classification loss after processing this batch is:  0.07938282936811447\n",
      "The representation loss after processing this batch is:  0.0023378953337669373\n",
      "\n",
      "The classification loss after processing this batch is:  0.056539297103881836\n",
      "The representation loss after processing this batch is:  0.002659350633621216\n",
      "\n",
      "The classification loss after processing this batch is:  0.10827865451574326\n",
      "The representation loss after processing this batch is:  0.0024738088250160217\n",
      "\n",
      "The classification loss after processing this batch is:  0.20462164282798767\n",
      "The representation loss after processing this batch is:  0.002264656126499176\n",
      "\n",
      "The classification loss after processing this batch is:  0.2410493642091751\n",
      "The representation loss after processing this batch is:  0.0027827471494674683\n",
      "\n",
      "The classification loss after processing this batch is:  0.12483306229114532\n",
      "The representation loss after processing this batch is:  0.0022240206599235535\n",
      "\n",
      "The classification loss after processing this batch is:  0.11685603111982346\n",
      "The representation loss after processing this batch is:  0.002265244722366333\n",
      "\n",
      "The classification loss after processing this batch is:  0.08218728750944138\n",
      "The representation loss after processing this batch is:  0.0025808513164520264\n",
      "\n",
      "The classification loss after processing this batch is:  0.11003810912370682\n",
      "The representation loss after processing this batch is:  0.002416204661130905\n",
      "\n",
      "The classification loss after processing this batch is:  0.20169183611869812\n",
      "The representation loss after processing this batch is:  0.0027123652398586273\n",
      "\n",
      "The classification loss after processing this batch is:  0.13131776452064514\n",
      "The representation loss after processing this batch is:  0.0022570081055164337\n",
      "\n",
      "The classification loss after processing this batch is:  0.2924521863460541\n",
      "The representation loss after processing this batch is:  0.002465672791004181\n",
      "\n",
      "The classification loss after processing this batch is:  0.14541973173618317\n",
      "The representation loss after processing this batch is:  0.0026036202907562256\n",
      "\n",
      "The classification loss after processing this batch is:  0.04802021011710167\n",
      "The representation loss after processing this batch is:  0.0029187723994255066\n",
      "\n",
      "The classification loss after processing this batch is:  0.12383101135492325\n",
      "The representation loss after processing this batch is:  0.002439849078655243\n",
      "\n",
      "The classification loss after processing this batch is:  0.11992354691028595\n",
      "The representation loss after processing this batch is:  0.0022514574229717255\n",
      "\n",
      "The classification loss after processing this batch is:  0.15139713883399963\n",
      "The representation loss after processing this batch is:  0.0025539547204971313\n",
      "\n",
      "The classification loss after processing this batch is:  0.09542917460203171\n",
      "The representation loss after processing this batch is:  0.0022134147584438324\n",
      "\n",
      "The classification loss after processing this batch is:  0.14532451331615448\n",
      "The representation loss after processing this batch is:  0.0022389888763427734\n",
      "\n",
      "The classification loss after processing this batch is:  0.09882350265979767\n",
      "The representation loss after processing this batch is:  0.002379022538661957\n",
      "\n",
      "The classification loss after processing this batch is:  0.1226678192615509\n",
      "The representation loss after processing this batch is:  0.0023431554436683655\n",
      "\n",
      "The classification loss after processing this batch is:  0.16827623546123505\n",
      "The representation loss after processing this batch is:  0.0024405866861343384\n",
      "\n",
      "The classification loss after processing this batch is:  0.1971089094877243\n",
      "The representation loss after processing this batch is:  0.0024898797273635864\n",
      "\n",
      "The classification loss after processing this batch is:  0.11710762232542038\n",
      "The representation loss after processing this batch is:  0.002384290099143982\n",
      "\n",
      "The classification loss after processing this batch is:  0.03771721199154854\n",
      "The representation loss after processing this batch is:  0.002882920205593109\n",
      "\n",
      "The classification loss after processing this batch is:  0.01745131053030491\n",
      "The representation loss after processing this batch is:  0.0026079416275024414\n",
      "\n",
      "The classification loss after processing this batch is:  0.09363056719303131\n",
      "The representation loss after processing this batch is:  0.0027588531374931335\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08892802894115448\n",
      "The representation loss after processing this batch is:  0.004002533853054047\n",
      "\n",
      "The classification loss after processing this batch is:  0.14840282499790192\n",
      "The representation loss after processing this batch is:  0.0026348307728767395\n",
      "\n",
      "The classification loss after processing this batch is:  0.11155284196138382\n",
      "The representation loss after processing this batch is:  0.0027689263224601746\n",
      "\n",
      "The classification loss after processing this batch is:  0.13004355132579803\n",
      "The representation loss after processing this batch is:  0.0024149492383003235\n",
      "\n",
      "The classification loss after processing this batch is:  0.04872787743806839\n",
      "The representation loss after processing this batch is:  0.0026696249842643738\n",
      "\n",
      "The classification loss after processing this batch is:  0.1041051372885704\n",
      "The representation loss after processing this batch is:  0.002539597451686859\n",
      "\n",
      "The classification loss after processing this batch is:  0.0942171961069107\n",
      "The representation loss after processing this batch is:  0.002625003457069397\n",
      "\n",
      "The classification loss after processing this batch is:  0.1421947479248047\n",
      "The representation loss after processing this batch is:  0.002712160348892212\n",
      "\n",
      "The classification loss after processing this batch is:  0.06818418204784393\n",
      "The representation loss after processing this batch is:  0.0023994222283363342\n",
      "\n",
      "The classification loss after processing this batch is:  0.06084567308425903\n",
      "The representation loss after processing this batch is:  0.0020112544298171997\n",
      "\n",
      "The classification loss after processing this batch is:  0.11466767638921738\n",
      "The representation loss after processing this batch is:  0.0022624433040618896\n",
      "\n",
      "The classification loss after processing this batch is:  0.12244175374507904\n",
      "The representation loss after processing this batch is:  0.002388492226600647\n",
      "\n",
      "The classification loss after processing this batch is:  0.09719062596559525\n",
      "The representation loss after processing this batch is:  0.002203032374382019\n",
      "\n",
      "The classification loss after processing this batch is:  0.14557288587093353\n",
      "The representation loss after processing this batch is:  0.002686716616153717\n",
      "\n",
      "The classification loss after processing this batch is:  0.08502813428640366\n",
      "The representation loss after processing this batch is:  0.002491690218448639\n",
      "\n",
      "The classification loss after processing this batch is:  0.0244143083691597\n",
      "The representation loss after processing this batch is:  0.0022996068000793457\n",
      "\n",
      "The classification loss after processing this batch is:  0.05367572233080864\n",
      "The representation loss after processing this batch is:  0.0028201043605804443\n",
      "\n",
      "The classification loss after processing this batch is:  0.03130337968468666\n",
      "The representation loss after processing this batch is:  0.002621077001094818\n",
      "\n",
      "The classification loss after processing this batch is:  0.09016824513673782\n",
      "The representation loss after processing this batch is:  0.00261756032705307\n",
      "\n",
      "The classification loss after processing this batch is:  0.0502343587577343\n",
      "The representation loss after processing this batch is:  0.002473302185535431\n",
      "\n",
      "The classification loss after processing this batch is:  0.05147456377744675\n",
      "The representation loss after processing this batch is:  0.0024124085903167725\n",
      "\n",
      "The classification loss after processing this batch is:  0.08944633603096008\n",
      "The representation loss after processing this batch is:  0.002748258411884308\n",
      "\n",
      "The classification loss after processing this batch is:  0.08801931887865067\n",
      "The representation loss after processing this batch is:  0.0025092661380767822\n",
      "\n",
      "The classification loss after processing this batch is:  0.04483902454376221\n",
      "The representation loss after processing this batch is:  0.002329505980014801\n",
      "\n",
      "The classification loss after processing this batch is:  0.03467811644077301\n",
      "The representation loss after processing this batch is:  0.002383872866630554\n",
      "\n",
      "The classification loss after processing this batch is:  0.04324955865740776\n",
      "The representation loss after processing this batch is:  0.002572380006313324\n",
      "\n",
      "The classification loss after processing this batch is:  0.029688676819205284\n",
      "The representation loss after processing this batch is:  0.0026056021451950073\n",
      "\n",
      "The classification loss after processing this batch is:  0.12248004972934723\n",
      "The representation loss after processing this batch is:  0.002455413341522217\n",
      "\n",
      "The classification loss after processing this batch is:  0.10981323570013046\n",
      "The representation loss after processing this batch is:  0.002630576491355896\n",
      "\n",
      "The classification loss after processing this batch is:  0.04342317581176758\n",
      "The representation loss after processing this batch is:  0.002382509410381317\n",
      "\n",
      "The classification loss after processing this batch is:  0.12981939315795898\n",
      "The representation loss after processing this batch is:  0.0024738945066928864\n",
      "\n",
      "The classification loss after processing this batch is:  0.05055684968829155\n",
      "The representation loss after processing this batch is:  0.002254597842693329\n",
      "\n",
      "The classification loss after processing this batch is:  0.12035005539655685\n",
      "The representation loss after processing this batch is:  0.002342376857995987\n",
      "\n",
      "The classification loss after processing this batch is:  0.15753121674060822\n",
      "The representation loss after processing this batch is:  0.0026383958756923676\n",
      "\n",
      "The classification loss after processing this batch is:  0.07603202760219574\n",
      "The representation loss after processing this batch is:  0.002603493630886078\n",
      "\n",
      "The classification loss after processing this batch is:  0.15605340898036957\n",
      "The representation loss after processing this batch is:  0.002298809587955475\n",
      "\n",
      "The classification loss after processing this batch is:  0.11586363613605499\n",
      "The representation loss after processing this batch is:  0.002236083149909973\n",
      "\n",
      "The classification loss after processing this batch is:  0.14120402932167053\n",
      "The representation loss after processing this batch is:  0.0023095905780792236\n",
      "\n",
      "The classification loss after processing this batch is:  0.10832217335700989\n",
      "The representation loss after processing this batch is:  0.002277195453643799\n",
      "\n",
      "The classification loss after processing this batch is:  0.06480571627616882\n",
      "The representation loss after processing this batch is:  0.002615988254547119\n",
      "\n",
      "The classification loss after processing this batch is:  0.09831155836582184\n",
      "The representation loss after processing this batch is:  0.0020907260477542877\n",
      "\n",
      "The classification loss after processing this batch is:  0.09910965710878372\n",
      "The representation loss after processing this batch is:  0.0027547329664230347\n",
      "\n",
      "The classification loss after processing this batch is:  0.13636177778244019\n",
      "The representation loss after processing this batch is:  0.0025447048246860504\n",
      "\n",
      "The classification loss after processing this batch is:  0.10388116538524628\n",
      "The representation loss after processing this batch is:  0.0023563727736473083\n",
      "\n",
      "The classification loss after processing this batch is:  0.06095124036073685\n",
      "The representation loss after processing this batch is:  0.002393588423728943\n",
      "\n",
      "The classification loss after processing this batch is:  0.08533398807048798\n",
      "The representation loss after processing this batch is:  0.002317085862159729\n",
      "\n",
      "The classification loss after processing this batch is:  0.18670634925365448\n",
      "The representation loss after processing this batch is:  0.002245701849460602\n",
      "\n",
      "The classification loss after processing this batch is:  0.07340048998594284\n",
      "The representation loss after processing this batch is:  0.0024499744176864624\n",
      "\n",
      "The classification loss after processing this batch is:  0.10890762507915497\n",
      "The representation loss after processing this batch is:  0.0022957101464271545\n",
      "\n",
      "The classification loss after processing this batch is:  0.08745662868022919\n",
      "The representation loss after processing this batch is:  0.002168402075767517\n",
      "\n",
      "The classification loss after processing this batch is:  0.07316955178976059\n",
      "The representation loss after processing this batch is:  0.0027847960591316223\n",
      "\n",
      "The classification loss after processing this batch is:  0.042224325239658356\n",
      "The representation loss after processing this batch is:  0.002769455313682556\n",
      "\n",
      "The classification loss after processing this batch is:  0.08577633649110794\n",
      "The representation loss after processing this batch is:  0.0028050169348716736\n",
      "\n",
      "The classification loss after processing this batch is:  0.09771794825792313\n",
      "The representation loss after processing this batch is:  0.002504650503396988\n",
      "\n",
      "The classification loss after processing this batch is:  0.08185823261737823\n",
      "The representation loss after processing this batch is:  0.002328917384147644\n",
      "\n",
      "The classification loss after processing this batch is:  0.1362646371126175\n",
      "The representation loss after processing this batch is:  0.0026945285499095917\n",
      "\n",
      "The classification loss after processing this batch is:  0.12579026818275452\n",
      "The representation loss after processing this batch is:  0.0025450624525547028\n",
      "\n",
      "The classification loss after processing this batch is:  0.13245750963687897\n",
      "The representation loss after processing this batch is:  0.0021258555352687836\n",
      "\n",
      "The classification loss after processing this batch is:  0.13672111928462982\n",
      "The representation loss after processing this batch is:  0.002856239676475525\n",
      "\n",
      "The classification loss after processing this batch is:  0.04574916511774063\n",
      "The representation loss after processing this batch is:  0.0026302188634872437\n",
      "\n",
      "The classification loss after processing this batch is:  0.04083768650889397\n",
      "The representation loss after processing this batch is:  0.0023920126259326935\n",
      "\n",
      "The classification loss after processing this batch is:  0.07642993330955505\n",
      "The representation loss after processing this batch is:  0.002501845359802246\n",
      "\n",
      "The classification loss after processing this batch is:  0.09630266577005386\n",
      "The representation loss after processing this batch is:  0.002471223473548889\n",
      "\n",
      "The classification loss after processing this batch is:  0.08746432512998581\n",
      "The representation loss after processing this batch is:  0.002290494740009308\n",
      "\n",
      "The classification loss after processing this batch is:  0.09947648644447327\n",
      "The representation loss after processing this batch is:  0.0024961084127426147\n",
      "\n",
      "The classification loss after processing this batch is:  0.10707318037748337\n",
      "The representation loss after processing this batch is:  0.0028455331921577454\n",
      "\n",
      "The classification loss after processing this batch is:  0.11972446739673615\n",
      "The representation loss after processing this batch is:  0.0026940256357192993\n",
      "\n",
      "The classification loss after processing this batch is:  0.15218313038349152\n",
      "The representation loss after processing this batch is:  0.0023866966366767883\n",
      "\n",
      "The classification loss after processing this batch is:  0.13285276293754578\n",
      "The representation loss after processing this batch is:  0.002449348568916321\n",
      "\n",
      "The classification loss after processing this batch is:  0.13062725961208344\n",
      "The representation loss after processing this batch is:  0.002237752079963684\n",
      "\n",
      "The classification loss after processing this batch is:  0.06079040467739105\n",
      "The representation loss after processing this batch is:  0.0027253106236457825\n",
      "\n",
      "The classification loss after processing this batch is:  0.03835567459464073\n",
      "The representation loss after processing this batch is:  0.002631261944770813\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.12143436819314957\n",
      "The representation loss after processing this batch is:  0.0021981187164783478\n",
      "\n",
      "The classification loss after processing this batch is:  0.17480550706386566\n",
      "The representation loss after processing this batch is:  0.0022543594241142273\n",
      "\n",
      "The classification loss after processing this batch is:  0.13288064301013947\n",
      "The representation loss after processing this batch is:  0.0024413764476776123\n",
      "\n",
      "The classification loss after processing this batch is:  0.11939678341150284\n",
      "The representation loss after processing this batch is:  0.002407848834991455\n",
      "\n",
      "The classification loss after processing this batch is:  0.1140163391828537\n",
      "The representation loss after processing this batch is:  0.0023496337234973907\n",
      "\n",
      "The classification loss after processing this batch is:  0.16173608601093292\n",
      "The representation loss after processing this batch is:  0.0024259015917778015\n",
      "\n",
      "The classification loss after processing this batch is:  0.18777495622634888\n",
      "The representation loss after processing this batch is:  0.002407461404800415\n",
      "\n",
      "The classification loss after processing this batch is:  0.1789431869983673\n",
      "The representation loss after processing this batch is:  0.002584412693977356\n",
      "\n",
      "The classification loss after processing this batch is:  0.13646024465560913\n",
      "The representation loss after processing this batch is:  0.00248650461435318\n",
      "\n",
      "The classification loss after processing this batch is:  0.09524918347597122\n",
      "The representation loss after processing this batch is:  0.0031239017844200134\n",
      "\n",
      "The classification loss after processing this batch is:  0.06851660460233688\n",
      "The representation loss after processing this batch is:  0.002889305353164673\n",
      "\n",
      "The classification loss after processing this batch is:  0.09139394760131836\n",
      "The representation loss after processing this batch is:  0.002459481358528137\n",
      "\n",
      "The classification loss after processing this batch is:  0.07664487510919571\n",
      "The representation loss after processing this batch is:  0.002260833978652954\n",
      "\n",
      "The classification loss after processing this batch is:  0.057087626308202744\n",
      "The representation loss after processing this batch is:  0.002284768968820572\n",
      "\n",
      "The classification loss after processing this batch is:  0.03598139062523842\n",
      "The representation loss after processing this batch is:  0.002387169748544693\n",
      "\n",
      "The classification loss after processing this batch is:  0.11947628110647202\n",
      "The representation loss after processing this batch is:  0.0023737624287605286\n",
      "\n",
      "The classification loss after processing this batch is:  0.05654381960630417\n",
      "The representation loss after processing this batch is:  0.0025870054960250854\n",
      "\n",
      "The classification loss after processing this batch is:  0.07732653617858887\n",
      "The representation loss after processing this batch is:  0.002700507640838623\n",
      "\n",
      "The classification loss after processing this batch is:  0.0781148299574852\n",
      "The representation loss after processing this batch is:  0.002091646194458008\n",
      "\n",
      "The classification loss after processing this batch is:  0.06631985306739807\n",
      "The representation loss after processing this batch is:  0.002310827374458313\n",
      "\n",
      "The classification loss after processing this batch is:  0.06788734346628189\n",
      "The representation loss after processing this batch is:  0.002598896622657776\n",
      "\n",
      "The classification loss after processing this batch is:  0.07819636166095734\n",
      "The representation loss after processing this batch is:  0.0023764558136463165\n",
      "\n",
      "The classification loss after processing this batch is:  0.11268415302038193\n",
      "The representation loss after processing this batch is:  0.0027068182826042175\n",
      "\n",
      "The classification loss after processing this batch is:  0.027126209810376167\n",
      "The representation loss after processing this batch is:  0.0026814714074134827\n",
      "\n",
      "The classification loss after processing this batch is:  0.03216079622507095\n",
      "The representation loss after processing this batch is:  0.0025853589177131653\n",
      "\n",
      "The classification loss after processing this batch is:  0.11737983673810959\n",
      "The representation loss after processing this batch is:  0.0023619383573532104\n",
      "\n",
      "The classification loss after processing this batch is:  0.1515120565891266\n",
      "The representation loss after processing this batch is:  0.002370651811361313\n",
      "\n",
      "The classification loss after processing this batch is:  0.0949695035815239\n",
      "The representation loss after processing this batch is:  0.002500593662261963\n",
      "\n",
      "The classification loss after processing this batch is:  0.03352760523557663\n",
      "The representation loss after processing this batch is:  0.002240654081106186\n",
      "\n",
      "The classification loss after processing this batch is:  0.09068746864795685\n",
      "The representation loss after processing this batch is:  0.0023903287947177887\n",
      "\n",
      "The classification loss after processing this batch is:  0.019421180710196495\n",
      "The representation loss after processing this batch is:  0.002535715699195862\n",
      "\n",
      "The classification loss after processing this batch is:  0.10637471824884415\n",
      "The representation loss after processing this batch is:  0.0023880302906036377\n",
      "\n",
      "The classification loss after processing this batch is:  0.09050305932760239\n",
      "The representation loss after processing this batch is:  0.00255710631608963\n",
      "\n",
      "The classification loss after processing this batch is:  0.06185680627822876\n",
      "The representation loss after processing this batch is:  0.0022989287972450256\n",
      "\n",
      "The classification loss after processing this batch is:  0.052572473883628845\n",
      "The representation loss after processing this batch is:  0.0025538206100463867\n",
      "\n",
      "The classification loss after processing this batch is:  0.0794699639081955\n",
      "The representation loss after processing this batch is:  0.002426736056804657\n",
      "\n",
      "The classification loss after processing this batch is:  0.051929771900177\n",
      "The representation loss after processing this batch is:  0.0023624300956726074\n",
      "\n",
      "The classification loss after processing this batch is:  0.1620025336742401\n",
      "The representation loss after processing this batch is:  0.002556219696998596\n",
      "\n",
      "The classification loss after processing this batch is:  0.2393583357334137\n",
      "The representation loss after processing this batch is:  0.0023589208722114563\n",
      "\n",
      "The classification loss after processing this batch is:  0.16065263748168945\n",
      "The representation loss after processing this batch is:  0.002248767763376236\n",
      "\n",
      "The classification loss after processing this batch is:  0.18118545413017273\n",
      "The representation loss after processing this batch is:  0.0023789778351783752\n",
      "\n",
      "The classification loss after processing this batch is:  0.10375717282295227\n",
      "The representation loss after processing this batch is:  0.0024531856179237366\n",
      "\n",
      "The classification loss after processing this batch is:  0.05803712084889412\n",
      "The representation loss after processing this batch is:  0.0023286789655685425\n",
      "\n",
      "The classification loss after processing this batch is:  0.16183637082576752\n",
      "The representation loss after processing this batch is:  0.0023495107889175415\n",
      "\n",
      "The classification loss after processing this batch is:  0.1079990491271019\n",
      "The representation loss after processing this batch is:  0.0025445260107517242\n",
      "\n",
      "The classification loss after processing this batch is:  0.0993136540055275\n",
      "The representation loss after processing this batch is:  0.0024621710181236267\n",
      "\n",
      "The classification loss after processing this batch is:  0.11520850658416748\n",
      "The representation loss after processing this batch is:  0.00266149640083313\n",
      "\n",
      "The classification loss after processing this batch is:  0.1293812394142151\n",
      "The representation loss after processing this batch is:  0.0023467689752578735\n",
      "\n",
      "The classification loss after processing this batch is:  0.059517551213502884\n",
      "The representation loss after processing this batch is:  0.0022854842245578766\n",
      "\n",
      "The classification loss after processing this batch is:  0.07845451682806015\n",
      "The representation loss after processing this batch is:  0.00257284939289093\n",
      "\n",
      "The classification loss after processing this batch is:  0.11150424927473068\n",
      "The representation loss after processing this batch is:  0.0023730099201202393\n",
      "\n",
      "The classification loss after processing this batch is:  0.03941485658288002\n",
      "The representation loss after processing this batch is:  0.002484329044818878\n",
      "\n",
      "The classification loss after processing this batch is:  0.04099390283226967\n",
      "The representation loss after processing this batch is:  0.0025369785726070404\n",
      "\n",
      "The classification loss after processing this batch is:  0.09742770344018936\n",
      "The representation loss after processing this batch is:  0.0023103058338165283\n",
      "\n",
      "The classification loss after processing this batch is:  0.16021260619163513\n",
      "The representation loss after processing this batch is:  0.002404250204563141\n",
      "\n",
      "The classification loss after processing this batch is:  0.04464597627520561\n",
      "The representation loss after processing this batch is:  0.002315342426300049\n",
      "\n",
      "The classification loss after processing this batch is:  0.05108032003045082\n",
      "The representation loss after processing this batch is:  0.002222791314125061\n",
      "\n",
      "The classification loss after processing this batch is:  0.13143032789230347\n",
      "The representation loss after processing this batch is:  0.0023060962557792664\n",
      "\n",
      "The classification loss after processing this batch is:  0.17851220071315765\n",
      "The representation loss after processing this batch is:  0.002285279333591461\n",
      "\n",
      "The classification loss after processing this batch is:  0.06547047942876816\n",
      "The representation loss after processing this batch is:  0.0021843910217285156\n",
      "\n",
      "The classification loss after processing this batch is:  0.1558733880519867\n",
      "The representation loss after processing this batch is:  0.0022103600203990936\n",
      "\n",
      "The classification loss after processing this batch is:  0.05493650212883949\n",
      "The representation loss after processing this batch is:  0.0026301145553588867\n",
      "\n",
      "The classification loss after processing this batch is:  0.026657676324248314\n",
      "The representation loss after processing this batch is:  0.002350885421037674\n",
      "\n",
      "The classification loss after processing this batch is:  0.036072734743356705\n",
      "The representation loss after processing this batch is:  0.0024221017956733704\n",
      "\n",
      "The classification loss after processing this batch is:  0.11524223536252975\n",
      "The representation loss after processing this batch is:  0.0028951317071914673\n",
      "\n",
      "The classification loss after processing this batch is:  0.131706103682518\n",
      "The representation loss after processing this batch is:  0.0025101006031036377\n",
      "\n",
      "The classification loss after processing this batch is:  0.06483691185712814\n",
      "The representation loss after processing this batch is:  0.0030222460627555847\n",
      "\n",
      "The classification loss after processing this batch is:  0.08665387332439423\n",
      "The representation loss after processing this batch is:  0.0022291429340839386\n",
      "\n",
      "The classification loss after processing this batch is:  0.0470309816300869\n",
      "The representation loss after processing this batch is:  0.0025369077920913696\n",
      "\n",
      "The classification loss after processing this batch is:  0.1221751719713211\n",
      "The representation loss after processing this batch is:  0.002486560493707657\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08240342140197754\n",
      "The representation loss after processing this batch is:  0.0021933913230895996\n",
      "\n",
      "The classification loss after processing this batch is:  0.1243116483092308\n",
      "The representation loss after processing this batch is:  0.0023737698793411255\n",
      "\n",
      "The classification loss after processing this batch is:  0.12516029179096222\n",
      "The representation loss after processing this batch is:  0.0026004090905189514\n",
      "\n",
      "The classification loss after processing this batch is:  0.225153386592865\n",
      "The representation loss after processing this batch is:  0.002125777304172516\n",
      "\n",
      "The classification loss after processing this batch is:  0.09719374030828476\n",
      "The representation loss after processing this batch is:  0.0021599531173706055\n",
      "\n",
      "The classification loss after processing this batch is:  0.14768320322036743\n",
      "The representation loss after processing this batch is:  0.0022547245025634766\n",
      "\n",
      "The classification loss after processing this batch is:  0.14523357152938843\n",
      "The representation loss after processing this batch is:  0.002397201955318451\n",
      "\n",
      "The classification loss after processing this batch is:  0.06916414201259613\n",
      "The representation loss after processing this batch is:  0.0023497454822063446\n",
      "\n",
      "The classification loss after processing this batch is:  0.08307704329490662\n",
      "The representation loss after processing this batch is:  0.0027658529579639435\n",
      "\n",
      "The classification loss after processing this batch is:  0.04959931597113609\n",
      "The representation loss after processing this batch is:  0.0025092512369155884\n",
      "\n",
      "The classification loss after processing this batch is:  0.09936270862817764\n",
      "The representation loss after processing this batch is:  0.0022659823298454285\n",
      "\n",
      "The classification loss after processing this batch is:  0.0866159200668335\n",
      "The representation loss after processing this batch is:  0.002039603888988495\n",
      "\n",
      "The classification loss after processing this batch is:  0.08045408129692078\n",
      "The representation loss after processing this batch is:  0.002247091382741928\n",
      "\n",
      "The classification loss after processing this batch is:  0.0924704447388649\n",
      "The representation loss after processing this batch is:  0.0024094954133033752\n",
      "\n",
      "The classification loss after processing this batch is:  0.10571152716875076\n",
      "The representation loss after processing this batch is:  0.002250760793685913\n",
      "\n",
      "The classification loss after processing this batch is:  0.09236322343349457\n",
      "The representation loss after processing this batch is:  0.0023274868726730347\n",
      "\n",
      "The classification loss after processing this batch is:  0.1391305774450302\n",
      "The representation loss after processing this batch is:  0.002438664436340332\n",
      "\n",
      "The classification loss after processing this batch is:  0.07383634895086288\n",
      "The representation loss after processing this batch is:  0.0025768131017684937\n",
      "\n",
      "The classification loss after processing this batch is:  0.07209201902151108\n",
      "The representation loss after processing this batch is:  0.0020461007952690125\n",
      "\n",
      "The classification loss after processing this batch is:  0.07003072649240494\n",
      "The representation loss after processing this batch is:  0.002677731215953827\n",
      "\n",
      "The classification loss after processing this batch is:  0.15637215971946716\n",
      "The representation loss after processing this batch is:  0.0029958300292491913\n",
      "\n",
      "The classification loss after processing this batch is:  0.25350549817085266\n",
      "The representation loss after processing this batch is:  0.0026550814509391785\n",
      "\n",
      "The classification loss after processing this batch is:  0.03005007840692997\n",
      "The representation loss after processing this batch is:  0.0022793076932430267\n",
      "\n",
      "The classification loss after processing this batch is:  0.0563645102083683\n",
      "The representation loss after processing this batch is:  0.0023840516805648804\n",
      "\n",
      "The classification loss after processing this batch is:  0.17173105478286743\n",
      "The representation loss after processing this batch is:  0.0029146708548069\n",
      "\n",
      "The classification loss after processing this batch is:  0.03688763454556465\n",
      "The representation loss after processing this batch is:  0.0026626139879226685\n",
      "\n",
      "The classification loss after processing this batch is:  0.04416341334581375\n",
      "The representation loss after processing this batch is:  0.0022882744669914246\n",
      "\n",
      "The classification loss after processing this batch is:  0.1025618463754654\n",
      "The representation loss after processing this batch is:  0.002681322395801544\n",
      "\n",
      "The classification loss after processing this batch is:  0.06069875881075859\n",
      "The representation loss after processing this batch is:  0.002578485757112503\n",
      "\n",
      "The classification loss after processing this batch is:  0.12195567041635513\n",
      "The representation loss after processing this batch is:  0.003018222749233246\n",
      "\n",
      "The classification loss after processing this batch is:  0.09776939451694489\n",
      "The representation loss after processing this batch is:  0.002746284008026123\n",
      "\n",
      "The classification loss after processing this batch is:  0.1134566143155098\n",
      "The representation loss after processing this batch is:  0.0028513148427009583\n",
      "\n",
      "The classification loss after processing this batch is:  0.08351623266935349\n",
      "The representation loss after processing this batch is:  0.002109341323375702\n",
      "\n",
      "The classification loss after processing this batch is:  0.1166776791214943\n",
      "The representation loss after processing this batch is:  0.002227276563644409\n",
      "\n",
      "The classification loss after processing this batch is:  0.028177689760923386\n",
      "The representation loss after processing this batch is:  0.0023255422711372375\n",
      "\n",
      "The classification loss after processing this batch is:  0.03330603986978531\n",
      "The representation loss after processing this batch is:  0.002429381012916565\n",
      "\n",
      "The classification loss after processing this batch is:  0.09594275057315826\n",
      "The representation loss after processing this batch is:  0.0025169923901557922\n",
      "\n",
      "The classification loss after processing this batch is:  0.061816513538360596\n",
      "The representation loss after processing this batch is:  0.0024359598755836487\n",
      "\n",
      "The classification loss after processing this batch is:  0.09106548875570297\n",
      "The representation loss after processing this batch is:  0.0023045875132083893\n",
      "\n",
      "The classification loss after processing this batch is:  0.05012460798025131\n",
      "The representation loss after processing this batch is:  0.0023208633065223694\n",
      "\n",
      "The classification loss after processing this batch is:  0.0604647733271122\n",
      "The representation loss after processing this batch is:  0.0024001523852348328\n",
      "\n",
      "The classification loss after processing this batch is:  0.0978393703699112\n",
      "The representation loss after processing this batch is:  0.002316948026418686\n",
      "\n",
      "The classification loss after processing this batch is:  0.15054315328598022\n",
      "The representation loss after processing this batch is:  0.00276387482881546\n",
      "\n",
      "The classification loss after processing this batch is:  0.1563873589038849\n",
      "The representation loss after processing this batch is:  0.0023415163159370422\n",
      "\n",
      "The classification loss after processing this batch is:  0.06535927951335907\n",
      "The representation loss after processing this batch is:  0.0025867000222206116\n",
      "\n",
      "The classification loss after processing this batch is:  0.156978577375412\n",
      "The representation loss after processing this batch is:  0.0023125074803829193\n",
      "\n",
      "The classification loss after processing this batch is:  0.05261524021625519\n",
      "The representation loss after processing this batch is:  0.0022064782679080963\n",
      "\n",
      "The classification loss after processing this batch is:  0.1118256077170372\n",
      "The representation loss after processing this batch is:  0.002375304698944092\n",
      "\n",
      "The classification loss after processing this batch is:  0.20220232009887695\n",
      "The representation loss after processing this batch is:  0.0028187409043312073\n",
      "\n",
      "The classification loss after processing this batch is:  0.08993701636791229\n",
      "The representation loss after processing this batch is:  0.0022272989153862\n",
      "\n",
      "The classification loss after processing this batch is:  0.12162169814109802\n",
      "The representation loss after processing this batch is:  0.002270638942718506\n",
      "\n",
      "The classification loss after processing this batch is:  0.09388849884271622\n",
      "The representation loss after processing this batch is:  0.0023524686694145203\n",
      "\n",
      "The classification loss after processing this batch is:  0.15818002820014954\n",
      "The representation loss after processing this batch is:  0.002287745475769043\n",
      "\n",
      "The classification loss after processing this batch is:  0.09215056151151657\n",
      "The representation loss after processing this batch is:  0.002416841685771942\n",
      "\n",
      "The classification loss after processing this batch is:  0.07142476737499237\n",
      "The representation loss after processing this batch is:  0.0023830458521842957\n",
      "\n",
      "The classification loss after processing this batch is:  0.09192056953907013\n",
      "The representation loss after processing this batch is:  0.002478383481502533\n",
      "\n",
      "The classification loss after processing this batch is:  0.03969806060194969\n",
      "The representation loss after processing this batch is:  0.002492479979991913\n",
      "\n",
      "The classification loss after processing this batch is:  0.03342621400952339\n",
      "The representation loss after processing this batch is:  0.0021664276719093323\n",
      "\n",
      "The classification loss after processing this batch is:  0.10123873502016068\n",
      "The representation loss after processing this batch is:  0.0027763843536376953\n",
      "\n",
      "The classification loss after processing this batch is:  0.03777346760034561\n",
      "The representation loss after processing this batch is:  0.002730049192905426\n",
      "\n",
      "The classification loss after processing this batch is:  0.1619565337896347\n",
      "The representation loss after processing this batch is:  0.0026333779096603394\n",
      "\n",
      "The classification loss after processing this batch is:  0.07059844583272934\n",
      "The representation loss after processing this batch is:  0.0023554563522338867\n",
      "\n",
      "The classification loss after processing this batch is:  0.17201796174049377\n",
      "The representation loss after processing this batch is:  0.0023688897490501404\n",
      "\n",
      "The classification loss after processing this batch is:  0.23797652125358582\n",
      "The representation loss after processing this batch is:  0.0022209249436855316\n",
      "\n",
      "The classification loss after processing this batch is:  0.11886944621801376\n",
      "The representation loss after processing this batch is:  0.0021814629435539246\n",
      "\n",
      "The classification loss after processing this batch is:  0.0336587056517601\n",
      "The representation loss after processing this batch is:  0.0026708096265792847\n",
      "\n",
      "The classification loss after processing this batch is:  0.05178224295377731\n",
      "The representation loss after processing this batch is:  0.002573944628238678\n",
      "\n",
      "The classification loss after processing this batch is:  0.03638448566198349\n",
      "The representation loss after processing this batch is:  0.002807535231113434\n",
      "\n",
      "The classification loss after processing this batch is:  0.06973661482334137\n",
      "The representation loss after processing this batch is:  0.0026387348771095276\n",
      "\n",
      "The classification loss after processing this batch is:  0.08505462855100632\n",
      "The representation loss after processing this batch is:  0.0020115114748477936\n",
      "\n",
      "The classification loss after processing this batch is:  0.2065814882516861\n",
      "The representation loss after processing this batch is:  0.0023651793599128723\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14696761965751648\n",
      "The representation loss after processing this batch is:  0.0022061094641685486\n",
      "\n",
      "The classification loss after processing this batch is:  0.08621793240308762\n",
      "The representation loss after processing this batch is:  0.002803295850753784\n",
      "\n",
      "The classification loss after processing this batch is:  0.1920132040977478\n",
      "The representation loss after processing this batch is:  0.0028706714510917664\n",
      "\n",
      "The classification loss after processing this batch is:  0.044844940304756165\n",
      "The representation loss after processing this batch is:  0.002513088285923004\n",
      "\n",
      "The classification loss after processing this batch is:  0.07945172488689423\n",
      "The representation loss after processing this batch is:  0.0025091543793678284\n",
      "\n",
      "The classification loss after processing this batch is:  0.1441822201013565\n",
      "The representation loss after processing this batch is:  0.0024029240012168884\n",
      "\n",
      "The classification loss after processing this batch is:  0.07435180991888046\n",
      "The representation loss after processing this batch is:  0.0027389079332351685\n",
      "\n",
      "The classification loss after processing this batch is:  0.11382807791233063\n",
      "The representation loss after processing this batch is:  0.003211483359336853\n",
      "\n",
      "The classification loss after processing this batch is:  0.07034523785114288\n",
      "The representation loss after processing this batch is:  0.002650156617164612\n",
      "\n",
      "The classification loss after processing this batch is:  0.09400801360607147\n",
      "The representation loss after processing this batch is:  0.003078356385231018\n",
      "\n",
      "The classification loss after processing this batch is:  0.16570539772510529\n",
      "The representation loss after processing this batch is:  0.0027553848922252655\n",
      "\n",
      "The classification loss after processing this batch is:  0.0640941932797432\n",
      "The representation loss after processing this batch is:  0.0029226690530776978\n",
      "\n",
      "The classification loss after processing this batch is:  0.14533337950706482\n",
      "The representation loss after processing this batch is:  0.0024084970355033875\n",
      "\n",
      "The classification loss after processing this batch is:  0.17838884890079498\n",
      "The representation loss after processing this batch is:  0.002187952399253845\n",
      "\n",
      "The classification loss after processing this batch is:  0.09490645676851273\n",
      "The representation loss after processing this batch is:  0.0023318901658058167\n",
      "\n",
      "The classification loss after processing this batch is:  0.12182588875293732\n",
      "The representation loss after processing this batch is:  0.0021784380078315735\n",
      "\n",
      "The classification loss after processing this batch is:  0.06887953728437424\n",
      "The representation loss after processing this batch is:  0.002850279211997986\n",
      "\n",
      "The classification loss after processing this batch is:  0.02918374165892601\n",
      "The representation loss after processing this batch is:  0.002478592097759247\n",
      "\n",
      "The classification loss after processing this batch is:  0.1038302332162857\n",
      "The representation loss after processing this batch is:  0.0026700198650360107\n",
      "\n",
      "The classification loss after processing this batch is:  0.04982684925198555\n",
      "The representation loss after processing this batch is:  0.0026414841413497925\n",
      "\n",
      "The classification loss after processing this batch is:  0.21411029994487762\n",
      "The representation loss after processing this batch is:  0.0022106878459453583\n",
      "\n",
      "The classification loss after processing this batch is:  0.03931701183319092\n",
      "The representation loss after processing this batch is:  0.0026799440383911133\n",
      "\n",
      "The classification loss after processing this batch is:  0.08959590643644333\n",
      "The representation loss after processing this batch is:  0.002271689474582672\n",
      "\n",
      "The classification loss after processing this batch is:  0.13812106847763062\n",
      "The representation loss after processing this batch is:  0.0023839548230171204\n",
      "\n",
      "The classification loss after processing this batch is:  0.11177973449230194\n",
      "The representation loss after processing this batch is:  0.0022913888096809387\n",
      "\n",
      "The classification loss after processing this batch is:  0.09579470753669739\n",
      "The representation loss after processing this batch is:  0.002420969307422638\n",
      "\n",
      "The classification loss after processing this batch is:  0.054341599345207214\n",
      "The representation loss after processing this batch is:  0.0023999735713005066\n",
      "\n",
      "The classification loss after processing this batch is:  0.05287466570734978\n",
      "The representation loss after processing this batch is:  0.0022016018629074097\n",
      "\n",
      "The classification loss after processing this batch is:  0.03871529921889305\n",
      "The representation loss after processing this batch is:  0.0023580938577651978\n",
      "\n",
      "The classification loss after processing this batch is:  0.1391461044549942\n",
      "The representation loss after processing this batch is:  0.003290332853794098\n",
      "\n",
      "The classification loss after processing this batch is:  0.1364244818687439\n",
      "The representation loss after processing this batch is:  0.0025780946016311646\n",
      "\n",
      "The classification loss after processing this batch is:  0.1308412402868271\n",
      "The representation loss after processing this batch is:  0.0020689330995082855\n",
      "\n",
      "The classification loss after processing this batch is:  0.13959366083145142\n",
      "The representation loss after processing this batch is:  0.002334311604499817\n",
      "\n",
      "The classification loss after processing this batch is:  0.26285648345947266\n",
      "The representation loss after processing this batch is:  0.0022306442260742188\n",
      "\n",
      "The classification loss after processing this batch is:  0.09095025807619095\n",
      "The representation loss after processing this batch is:  0.002803690731525421\n",
      "\n",
      "The classification loss after processing this batch is:  0.18030914664268494\n",
      "The representation loss after processing this batch is:  0.0024470090866088867\n",
      "\n",
      "The classification loss after processing this batch is:  0.09424066543579102\n",
      "The representation loss after processing this batch is:  0.0024553611874580383\n",
      "\n",
      "The classification loss after processing this batch is:  0.07022258639335632\n",
      "The representation loss after processing this batch is:  0.002379000186920166\n",
      "\n",
      "The classification loss after processing this batch is:  0.04237978532910347\n",
      "The representation loss after processing this batch is:  0.0022248923778533936\n",
      "\n",
      "The classification loss after processing this batch is:  0.05239680036902428\n",
      "The representation loss after processing this batch is:  0.0024660155177116394\n",
      "\n",
      "The classification loss after processing this batch is:  0.20261475443840027\n",
      "The representation loss after processing this batch is:  0.002563975751399994\n",
      "\n",
      "The classification loss after processing this batch is:  0.0851348340511322\n",
      "The representation loss after processing this batch is:  0.00251905620098114\n",
      "\n",
      "The classification loss after processing this batch is:  0.09150883555412292\n",
      "The representation loss after processing this batch is:  0.002906128764152527\n",
      "\n",
      "The classification loss after processing this batch is:  0.08384067565202713\n",
      "The representation loss after processing this batch is:  0.0028421133756637573\n",
      "\n",
      "The classification loss after processing this batch is:  0.06912422925233841\n",
      "The representation loss after processing this batch is:  0.0025963783264160156\n",
      "\n",
      "The classification loss after processing this batch is:  0.04824473708868027\n",
      "The representation loss after processing this batch is:  0.0024984031915664673\n",
      "\n",
      "The classification loss after processing this batch is:  0.1391202062368393\n",
      "The representation loss after processing this batch is:  0.002304382622241974\n",
      "\n",
      "The classification loss after processing this batch is:  0.1970548927783966\n",
      "The representation loss after processing this batch is:  0.0023934319615364075\n",
      "\n",
      "The classification loss after processing this batch is:  0.14602036774158478\n",
      "The representation loss after processing this batch is:  0.002684175968170166\n",
      "\n",
      "The classification loss after processing this batch is:  0.09663045406341553\n",
      "The representation loss after processing this batch is:  0.00231219083070755\n",
      "\n",
      "The classification loss after processing this batch is:  0.2840493321418762\n",
      "The representation loss after processing this batch is:  0.0021165981888771057\n",
      "\n",
      "The classification loss after processing this batch is:  0.06237740069627762\n",
      "The representation loss after processing this batch is:  0.002233840525150299\n",
      "\n",
      "The classification loss after processing this batch is:  0.09392289817333221\n",
      "The representation loss after processing this batch is:  0.0022286996245384216\n",
      "\n",
      "The classification loss after processing this batch is:  0.10607621818780899\n",
      "The representation loss after processing this batch is:  0.0028898604214191437\n",
      "\n",
      "The classification loss after processing this batch is:  0.06956551969051361\n",
      "The representation loss after processing this batch is:  0.002292860299348831\n",
      "\n",
      "The classification loss after processing this batch is:  0.12074875831604004\n",
      "The representation loss after processing this batch is:  0.002405129373073578\n",
      "\n",
      "The classification loss after processing this batch is:  0.05639364570379257\n",
      "The representation loss after processing this batch is:  0.002663247287273407\n",
      "\n",
      "The classification loss after processing this batch is:  0.1323929727077484\n",
      "The representation loss after processing this batch is:  0.002422705292701721\n",
      "\n",
      "The classification loss after processing this batch is:  0.171049565076828\n",
      "The representation loss after processing this batch is:  0.0026265084743499756\n",
      "\n",
      "The classification loss after processing this batch is:  0.16939575970172882\n",
      "The representation loss after processing this batch is:  0.0024159476161003113\n",
      "\n",
      "The classification loss after processing this batch is:  0.0848795548081398\n",
      "The representation loss after processing this batch is:  0.0025340691208839417\n",
      "\n",
      "The classification loss after processing this batch is:  0.06583208590745926\n",
      "The representation loss after processing this batch is:  0.0028285011649131775\n",
      "\n",
      "The classification loss after processing this batch is:  0.12903538346290588\n",
      "The representation loss after processing this batch is:  0.0022998303174972534\n",
      "\n",
      "The classification loss after processing this batch is:  0.12041998654603958\n",
      "The representation loss after processing this batch is:  0.0024294108152389526\n",
      "\n",
      "The classification loss after processing this batch is:  0.018727803602814674\n",
      "The representation loss after processing this batch is:  0.0023678913712501526\n",
      "\n",
      "The classification loss after processing this batch is:  0.10320326685905457\n",
      "The representation loss after processing this batch is:  0.002281792461872101\n",
      "\n",
      "The classification loss after processing this batch is:  0.20561809837818146\n",
      "The representation loss after processing this batch is:  0.002592477947473526\n",
      "\n",
      "The classification loss after processing this batch is:  0.2177399843931198\n",
      "The representation loss after processing this batch is:  0.0026515573263168335\n",
      "\n",
      "The classification loss after processing this batch is:  0.203367218375206\n",
      "The representation loss after processing this batch is:  0.0022860392928123474\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.16450674831867218\n",
      "The representation loss after processing this batch is:  0.002146616578102112\n",
      "\n",
      "The classification loss after processing this batch is:  0.058462873101234436\n",
      "The representation loss after processing this batch is:  0.0022991523146629333\n",
      "\n",
      "The classification loss after processing this batch is:  0.10507968068122864\n",
      "The representation loss after processing this batch is:  0.0022043734788894653\n",
      "\n",
      "The classification loss after processing this batch is:  0.09102749824523926\n",
      "The representation loss after processing this batch is:  0.00260065495967865\n",
      "\n",
      "The classification loss after processing this batch is:  0.15959689021110535\n",
      "The representation loss after processing this batch is:  0.0027162954211235046\n",
      "\n",
      "The classification loss after processing this batch is:  0.1071944311261177\n",
      "The representation loss after processing this batch is:  0.0027643218636512756\n",
      "\n",
      "The classification loss after processing this batch is:  0.11614297330379486\n",
      "The representation loss after processing this batch is:  0.0027584582567214966\n",
      "\n",
      "The classification loss after processing this batch is:  0.07399124652147293\n",
      "The representation loss after processing this batch is:  0.0024159327149391174\n",
      "\n",
      "The classification loss after processing this batch is:  0.05258869752287865\n",
      "The representation loss after processing this batch is:  0.0024387165904045105\n",
      "\n",
      "The classification loss after processing this batch is:  0.17250850796699524\n",
      "The representation loss after processing this batch is:  0.002608656883239746\n",
      "\n",
      "The classification loss after processing this batch is:  0.1341078281402588\n",
      "The representation loss after processing this batch is:  0.002355530858039856\n",
      "\n",
      "The classification loss after processing this batch is:  0.08864747732877731\n",
      "The representation loss after processing this batch is:  0.002405501902103424\n",
      "\n",
      "The classification loss after processing this batch is:  0.1933688223361969\n",
      "The representation loss after processing this batch is:  0.0030838996171951294\n",
      "\n",
      "The classification loss after processing this batch is:  0.24143169820308685\n",
      "The representation loss after processing this batch is:  0.0028241798281669617\n",
      "\n",
      "The classification loss after processing this batch is:  0.13677705824375153\n",
      "The representation loss after processing this batch is:  0.00255710631608963\n",
      "\n",
      "The classification loss after processing this batch is:  0.07298972457647324\n",
      "The representation loss after processing this batch is:  0.0025639981031417847\n",
      "\n",
      "The classification loss after processing this batch is:  0.1077483594417572\n",
      "The representation loss after processing this batch is:  0.0026504024863243103\n",
      "\n",
      "The classification loss after processing this batch is:  0.05880522355437279\n",
      "The representation loss after processing this batch is:  0.00266149640083313\n",
      "\n",
      "The classification loss after processing this batch is:  0.14901027083396912\n",
      "The representation loss after processing this batch is:  0.002717636525630951\n",
      "\n",
      "The classification loss after processing this batch is:  0.10851931571960449\n",
      "The representation loss after processing this batch is:  0.0027875974774360657\n",
      "\n",
      "The classification loss after processing this batch is:  0.08983876556158066\n",
      "The representation loss after processing this batch is:  0.0027844011783599854\n",
      "\n",
      "The classification loss after processing this batch is:  0.24173559248447418\n",
      "The representation loss after processing this batch is:  0.0023463591933250427\n",
      "\n",
      "The classification loss after processing this batch is:  0.0440540574491024\n",
      "The representation loss after processing this batch is:  0.002561114728450775\n",
      "\n",
      "The classification loss after processing this batch is:  0.04625615105032921\n",
      "The representation loss after processing this batch is:  0.0028178468346595764\n",
      "\n",
      "The classification loss after processing this batch is:  0.04696374014019966\n",
      "The representation loss after processing this batch is:  0.0023049116134643555\n",
      "\n",
      "The classification loss after processing this batch is:  0.12004342675209045\n",
      "The representation loss after processing this batch is:  0.002295255661010742\n",
      "\n",
      "The classification loss after processing this batch is:  0.18684977293014526\n",
      "The representation loss after processing this batch is:  0.0024373233318328857\n",
      "\n",
      "The classification loss after processing this batch is:  0.09891639649868011\n",
      "The representation loss after processing this batch is:  0.0022655874490737915\n",
      "\n",
      "The classification loss after processing this batch is:  0.09298892319202423\n",
      "The representation loss after processing this batch is:  0.002423129975795746\n",
      "\n",
      "The classification loss after processing this batch is:  0.030958179384469986\n",
      "The representation loss after processing this batch is:  0.0021554529666900635\n",
      "\n",
      "The classification loss after processing this batch is:  0.07737191021442413\n",
      "The representation loss after processing this batch is:  0.002355717122554779\n",
      "\n",
      "The classification loss after processing this batch is:  0.06584873050451279\n",
      "The representation loss after processing this batch is:  0.002472013235092163\n",
      "\n",
      "The classification loss after processing this batch is:  0.03247685357928276\n",
      "The representation loss after processing this batch is:  0.0025527551770210266\n",
      "\n",
      "The classification loss after processing this batch is:  0.08798948675394058\n",
      "The representation loss after processing this batch is:  0.0023591741919517517\n",
      "\n",
      "The classification loss after processing this batch is:  0.15717434883117676\n",
      "The representation loss after processing this batch is:  0.0021805614233016968\n",
      "\n",
      "The classification loss after processing this batch is:  0.18612608313560486\n",
      "The representation loss after processing this batch is:  0.0023334920406341553\n",
      "\n",
      "The classification loss after processing this batch is:  0.02081472799181938\n",
      "The representation loss after processing this batch is:  0.0022648200392723083\n",
      "\n",
      "The classification loss after processing this batch is:  0.0352814607322216\n",
      "The representation loss after processing this batch is:  0.002486184239387512\n",
      "\n",
      "The classification loss after processing this batch is:  0.06349639594554901\n",
      "The representation loss after processing this batch is:  0.0026910752058029175\n",
      "\n",
      "The classification loss after processing this batch is:  0.1381853222846985\n",
      "The representation loss after processing this batch is:  0.0023413002490997314\n",
      "\n",
      "The classification loss after processing this batch is:  0.04998988285660744\n",
      "The representation loss after processing this batch is:  0.0026294589042663574\n",
      "\n",
      "The classification loss after processing this batch is:  0.14593105018138885\n",
      "The representation loss after processing this batch is:  0.002589486539363861\n",
      "\n",
      "The classification loss after processing this batch is:  0.16452693939208984\n",
      "The representation loss after processing this batch is:  0.002584148198366165\n",
      "\n",
      "The classification loss after processing this batch is:  0.1276978999376297\n",
      "The representation loss after processing this batch is:  0.0026472732424736023\n",
      "\n",
      "The classification loss after processing this batch is:  0.0988851860165596\n",
      "The representation loss after processing this batch is:  0.0026709549129009247\n",
      "\n",
      "The classification loss after processing this batch is:  0.052242033183574677\n",
      "The representation loss after processing this batch is:  0.002550363540649414\n",
      "\n",
      "The classification loss after processing this batch is:  0.13586536049842834\n",
      "The representation loss after processing this batch is:  0.002202235162258148\n",
      "\n",
      "The classification loss after processing this batch is:  0.13718673586845398\n",
      "The representation loss after processing this batch is:  0.002414487302303314\n",
      "\n",
      "The classification loss after processing this batch is:  0.059518780559301376\n",
      "The representation loss after processing this batch is:  0.0024945735931396484\n",
      "\n",
      "The classification loss after processing this batch is:  0.035649534314870834\n",
      "The representation loss after processing this batch is:  0.0022866129875183105\n",
      "\n",
      "The classification loss after processing this batch is:  0.19997739791870117\n",
      "The representation loss after processing this batch is:  0.0023894570767879486\n",
      "\n",
      "The classification loss after processing this batch is:  0.1862841546535492\n",
      "The representation loss after processing this batch is:  0.0022589676082134247\n",
      "\n",
      "The classification loss after processing this batch is:  0.07457010447978973\n",
      "The representation loss after processing this batch is:  0.0022822245955467224\n",
      "\n",
      "The classification loss after processing this batch is:  0.23399190604686737\n",
      "The representation loss after processing this batch is:  0.0023926496505737305\n",
      "\n",
      "The classification loss after processing this batch is:  0.21811725199222565\n",
      "The representation loss after processing this batch is:  0.0024014264345169067\n",
      "\n",
      "The classification loss after processing this batch is:  0.2803662121295929\n",
      "The representation loss after processing this batch is:  0.0023748427629470825\n",
      "\n",
      "The classification loss after processing this batch is:  0.1083589568734169\n",
      "The representation loss after processing this batch is:  0.0026481151580810547\n",
      "\n",
      "The classification loss after processing this batch is:  0.06850127875804901\n",
      "The representation loss after processing this batch is:  0.0024558231234550476\n",
      "\n",
      "The classification loss after processing this batch is:  0.13678079843521118\n",
      "The representation loss after processing this batch is:  0.00256318598985672\n",
      "\n",
      "The classification loss after processing this batch is:  0.06691891700029373\n",
      "The representation loss after processing this batch is:  0.0024654269218444824\n",
      "\n",
      "The classification loss after processing this batch is:  0.04900551959872246\n",
      "The representation loss after processing this batch is:  0.002784125506877899\n",
      "\n",
      "The classification loss after processing this batch is:  0.08548858761787415\n",
      "The representation loss after processing this batch is:  0.0021583884954452515\n",
      "\n",
      "The classification loss after processing this batch is:  0.043932992964982986\n",
      "The representation loss after processing this batch is:  0.0024405568838119507\n",
      "\n",
      "The classification loss after processing this batch is:  0.015999842435121536\n",
      "The representation loss after processing this batch is:  0.002759493887424469\n",
      "\n",
      "The classification loss after processing this batch is:  0.09014803916215897\n",
      "The representation loss after processing this batch is:  0.002396676689386368\n",
      "\n",
      "The classification loss after processing this batch is:  0.11704736202955246\n",
      "The representation loss after processing this batch is:  0.0022236332297325134\n",
      "\n",
      "The classification loss after processing this batch is:  0.06460060924291611\n",
      "The representation loss after processing this batch is:  0.0026175379753112793\n",
      "\n",
      "The classification loss after processing this batch is:  0.07813598215579987\n",
      "The representation loss after processing this batch is:  0.0023549944162368774\n",
      "\n",
      "The classification loss after processing this batch is:  0.12388353049755096\n",
      "The representation loss after processing this batch is:  0.002376250922679901\n",
      "\n",
      "The classification loss after processing this batch is:  0.029500000178813934\n",
      "The representation loss after processing this batch is:  0.002406187355518341\n",
      "\n",
      "The classification loss after processing this batch is:  0.13782139122486115\n",
      "The representation loss after processing this batch is:  0.002606913447380066\n",
      "\n",
      "The classification loss after processing this batch is:  0.07146350294351578\n",
      "The representation loss after processing this batch is:  0.002221338450908661\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1840059757232666\n",
      "The representation loss after processing this batch is:  0.002329424023628235\n",
      "\n",
      "The classification loss after processing this batch is:  0.12306282669305801\n",
      "The representation loss after processing this batch is:  0.002407856285572052\n",
      "\n",
      "The classification loss after processing this batch is:  0.12087984383106232\n",
      "The representation loss after processing this batch is:  0.0021249279379844666\n",
      "\n",
      "The classification loss after processing this batch is:  0.030759891495108604\n",
      "The representation loss after processing this batch is:  0.002240411937236786\n",
      "\n",
      "The classification loss after processing this batch is:  0.03038361854851246\n",
      "The representation loss after processing this batch is:  0.002310618758201599\n",
      "\n",
      "The classification loss after processing this batch is:  0.1450481116771698\n",
      "The representation loss after processing this batch is:  0.0024621039628982544\n",
      "\n",
      "The classification loss after processing this batch is:  0.03589635714888573\n",
      "The representation loss after processing this batch is:  0.0025739669799804688\n",
      "\n",
      "The classification loss after processing this batch is:  0.10664908587932587\n",
      "The representation loss after processing this batch is:  0.0024484023451805115\n",
      "\n",
      "The classification loss after processing this batch is:  0.06488293409347534\n",
      "The representation loss after processing this batch is:  0.0026802271604537964\n",
      "\n",
      "The classification loss after processing this batch is:  0.06205582618713379\n",
      "The representation loss after processing this batch is:  0.0024974048137664795\n",
      "\n",
      "The classification loss after processing this batch is:  0.09521574527025223\n",
      "The representation loss after processing this batch is:  0.0024144724011421204\n",
      "\n",
      "The classification loss after processing this batch is:  0.05347075313329697\n",
      "The representation loss after processing this batch is:  0.002492055296897888\n",
      "\n",
      "The classification loss after processing this batch is:  0.059530965983867645\n",
      "The representation loss after processing this batch is:  0.0029109567403793335\n",
      "\n",
      "The classification loss after processing this batch is:  0.18127670884132385\n",
      "The representation loss after processing this batch is:  0.002358458936214447\n",
      "\n",
      "The classification loss after processing this batch is:  0.14350423216819763\n",
      "The representation loss after processing this batch is:  0.00264749675989151\n",
      "\n",
      "The classification loss after processing this batch is:  0.15618057548999786\n",
      "The representation loss after processing this batch is:  0.0026513412594795227\n",
      "\n",
      "The classification loss after processing this batch is:  0.18174587190151215\n",
      "The representation loss after processing this batch is:  0.002585768699645996\n",
      "\n",
      "The classification loss after processing this batch is:  0.0898662582039833\n",
      "The representation loss after processing this batch is:  0.0021598488092422485\n",
      "\n",
      "The classification loss after processing this batch is:  0.09021452814340591\n",
      "The representation loss after processing this batch is:  0.0022331997752189636\n",
      "\n",
      "The classification loss after processing this batch is:  0.04421422258019447\n",
      "The representation loss after processing this batch is:  0.0023261606693267822\n",
      "\n",
      "The classification loss after processing this batch is:  0.05645264685153961\n",
      "The representation loss after processing this batch is:  0.002348765730857849\n",
      "\n",
      "The classification loss after processing this batch is:  0.04411518946290016\n",
      "The representation loss after processing this batch is:  0.0024720653891563416\n",
      "\n",
      "The classification loss after processing this batch is:  0.09060470759868622\n",
      "The representation loss after processing this batch is:  0.0021492764353752136\n",
      "\n",
      "The classification loss after processing this batch is:  0.07808886468410492\n",
      "The representation loss after processing this batch is:  0.002627141773700714\n",
      "\n",
      "The classification loss after processing this batch is:  0.10581152141094208\n",
      "The representation loss after processing this batch is:  0.002491198480129242\n",
      "\n",
      "The classification loss after processing this batch is:  0.052857350558042526\n",
      "The representation loss after processing this batch is:  0.0022262632846832275\n",
      "\n",
      "The classification loss after processing this batch is:  0.14200147986412048\n",
      "The representation loss after processing this batch is:  0.0021690577268600464\n",
      "\n",
      "The classification loss after processing this batch is:  0.06486199051141739\n",
      "The representation loss after processing this batch is:  0.0025113001465797424\n",
      "\n",
      "The classification loss after processing this batch is:  0.13283756375312805\n",
      "The representation loss after processing this batch is:  0.0023088231682777405\n",
      "\n",
      "The classification loss after processing this batch is:  0.12544435262680054\n",
      "The representation loss after processing this batch is:  0.0025549009442329407\n",
      "\n",
      "The classification loss after processing this batch is:  0.10137877613306046\n",
      "The representation loss after processing this batch is:  0.0025585219264030457\n",
      "\n",
      "The classification loss after processing this batch is:  0.07148003578186035\n",
      "The representation loss after processing this batch is:  0.002498410642147064\n",
      "\n",
      "The classification loss after processing this batch is:  0.1721910685300827\n",
      "The representation loss after processing this batch is:  0.0024706050753593445\n",
      "\n",
      "The classification loss after processing this batch is:  0.07578200846910477\n",
      "The representation loss after processing this batch is:  0.002455487847328186\n",
      "\n",
      "The classification loss after processing this batch is:  0.06190866604447365\n",
      "The representation loss after processing this batch is:  0.0022396743297576904\n",
      "\n",
      "The classification loss after processing this batch is:  0.072734035551548\n",
      "The representation loss after processing this batch is:  0.00235087051987648\n",
      "\n",
      "The classification loss after processing this batch is:  0.06558521836996078\n",
      "The representation loss after processing this batch is:  0.0022959187626838684\n",
      "\n",
      "The classification loss after processing this batch is:  0.1554788202047348\n",
      "The representation loss after processing this batch is:  0.002294383943080902\n",
      "\n",
      "The classification loss after processing this batch is:  0.14579987525939941\n",
      "The representation loss after processing this batch is:  0.0025245919823646545\n",
      "\n",
      "The classification loss after processing this batch is:  0.08798287808895111\n",
      "The representation loss after processing this batch is:  0.002834804356098175\n",
      "\n",
      "The classification loss after processing this batch is:  0.06703463196754456\n",
      "The representation loss after processing this batch is:  0.0025196820497512817\n",
      "\n",
      "The classification loss after processing this batch is:  0.07481534779071808\n",
      "The representation loss after processing this batch is:  0.0026884451508522034\n",
      "\n",
      "The classification loss after processing this batch is:  0.1688387542963028\n",
      "The representation loss after processing this batch is:  0.002496112138032913\n",
      "\n",
      "The classification loss after processing this batch is:  0.04893063008785248\n",
      "The representation loss after processing this batch is:  0.0023643597960472107\n",
      "\n",
      "The classification loss after processing this batch is:  0.06334281712770462\n",
      "The representation loss after processing this batch is:  0.002743557095527649\n",
      "\n",
      "The classification loss after processing this batch is:  0.15209446847438812\n",
      "The representation loss after processing this batch is:  0.002201773226261139\n",
      "\n",
      "The classification loss after processing this batch is:  0.2864188551902771\n",
      "The representation loss after processing this batch is:  0.00244198739528656\n",
      "\n",
      "The classification loss after processing this batch is:  0.0790775865316391\n",
      "The representation loss after processing this batch is:  0.0022443607449531555\n",
      "\n",
      "The classification loss after processing this batch is:  0.10462164878845215\n",
      "The representation loss after processing this batch is:  0.002301327884197235\n",
      "\n",
      "The classification loss after processing this batch is:  0.03870314359664917\n",
      "The representation loss after processing this batch is:  0.0024195611476898193\n",
      "\n",
      "The classification loss after processing this batch is:  0.029300402849912643\n",
      "The representation loss after processing this batch is:  0.002222292125225067\n",
      "\n",
      "The classification loss after processing this batch is:  0.09005291759967804\n",
      "The representation loss after processing this batch is:  0.003084428608417511\n",
      "\n",
      "The classification loss after processing this batch is:  0.06712576001882553\n",
      "The representation loss after processing this batch is:  0.003407880663871765\n",
      "\n",
      "The classification loss after processing this batch is:  0.04872611537575722\n",
      "The representation loss after processing this batch is:  0.0023634470999240875\n",
      "\n",
      "The classification loss after processing this batch is:  0.046450283378362656\n",
      "The representation loss after processing this batch is:  0.0021883398294448853\n",
      "\n",
      "The classification loss after processing this batch is:  0.15091556310653687\n",
      "The representation loss after processing this batch is:  0.002273526042699814\n",
      "\n",
      "The classification loss after processing this batch is:  0.11056653410196304\n",
      "The representation loss after processing this batch is:  0.002300962805747986\n",
      "\n",
      "The classification loss after processing this batch is:  0.056503016501665115\n",
      "The representation loss after processing this batch is:  0.0020579658448696136\n",
      "\n",
      "The classification loss after processing this batch is:  0.059223685413599014\n",
      "The representation loss after processing this batch is:  0.002438649535179138\n",
      "\n",
      "The classification loss after processing this batch is:  0.19869709014892578\n",
      "The representation loss after processing this batch is:  0.00234820693731308\n",
      "\n",
      "The classification loss after processing this batch is:  0.18568375706672668\n",
      "The representation loss after processing this batch is:  0.0025428682565689087\n",
      "\n",
      "The classification loss after processing this batch is:  0.14470013976097107\n",
      "The representation loss after processing this batch is:  0.002196054905653\n",
      "\n",
      "The classification loss after processing this batch is:  0.11352793127298355\n",
      "The representation loss after processing this batch is:  0.0026661157608032227\n",
      "\n",
      "The classification loss after processing this batch is:  0.14532428979873657\n",
      "The representation loss after processing this batch is:  0.002284511923789978\n",
      "\n",
      "The classification loss after processing this batch is:  0.0834278017282486\n",
      "The representation loss after processing this batch is:  0.002878159284591675\n",
      "\n",
      "The classification loss after processing this batch is:  0.06784297525882721\n",
      "The representation loss after processing this batch is:  0.0026708245277404785\n",
      "\n",
      "The classification loss after processing this batch is:  0.035281240940093994\n",
      "The representation loss after processing this batch is:  0.002596452832221985\n",
      "\n",
      "The classification loss after processing this batch is:  0.06392687559127808\n",
      "The representation loss after processing this batch is:  0.0022667348384857178\n",
      "\n",
      "The classification loss after processing this batch is:  0.1638166457414627\n",
      "The representation loss after processing this batch is:  0.002353489398956299\n",
      "\n",
      "The classification loss after processing this batch is:  0.06878995895385742\n",
      "The representation loss after processing this batch is:  0.0029610320925712585\n",
      "\n",
      "The classification loss after processing this batch is:  0.03863595053553581\n",
      "The representation loss after processing this batch is:  0.002369984984397888\n",
      "\n",
      "The classification loss after processing this batch is:  0.021917708218097687\n",
      "The representation loss after processing this batch is:  0.0029972344636917114\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.026498941704630852\n",
      "The representation loss after processing this batch is:  0.002814449369907379\n",
      "\n",
      "The classification loss after processing this batch is:  0.051486168056726456\n",
      "The representation loss after processing this batch is:  0.002942226827144623\n",
      "\n",
      "The classification loss after processing this batch is:  0.05322132632136345\n",
      "The representation loss after processing this batch is:  0.002861693501472473\n",
      "\n",
      "The classification loss after processing this batch is:  0.03107479400932789\n",
      "The representation loss after processing this batch is:  0.002519868314266205\n",
      "\n",
      "The classification loss after processing this batch is:  0.016301529482007027\n",
      "The representation loss after processing this batch is:  0.002785138785839081\n",
      "\n",
      "The classification loss after processing this batch is:  0.02757047489285469\n",
      "The representation loss after processing this batch is:  0.0035825297236442566\n",
      "\n",
      "The classification loss after processing this batch is:  0.07410423457622528\n",
      "The representation loss after processing this batch is:  0.0033243075013160706\n",
      "\n",
      "The classification loss after processing this batch is:  0.010385830886662006\n",
      "The representation loss after processing this batch is:  0.0034870952367782593\n",
      "\n",
      "The classification loss after processing this batch is:  0.027157345786690712\n",
      "The representation loss after processing this batch is:  0.002749107778072357\n",
      "\n",
      "The classification loss after processing this batch is:  0.16089938580989838\n",
      "The representation loss after processing this batch is:  0.002781420946121216\n",
      "\n",
      "The classification loss after processing this batch is:  0.021682437509298325\n",
      "The representation loss after processing this batch is:  0.003203548491001129\n",
      "\n",
      "The classification loss after processing this batch is:  0.008497253991663456\n",
      "The representation loss after processing this batch is:  0.0029607564210891724\n",
      "\n",
      "The classification loss after processing this batch is:  0.017060009762644768\n",
      "The representation loss after processing this batch is:  0.0027545318007469177\n",
      "\n",
      "The classification loss after processing this batch is:  0.022102871909737587\n",
      "The representation loss after processing this batch is:  0.002952463924884796\n",
      "\n",
      "The classification loss after processing this batch is:  0.018900474533438683\n",
      "The representation loss after processing this batch is:  0.0031110718846321106\n",
      "\n",
      "The classification loss after processing this batch is:  0.017910519614815712\n",
      "The representation loss after processing this batch is:  0.0031156539916992188\n",
      "\n",
      "The classification loss after processing this batch is:  0.01422017440199852\n",
      "The representation loss after processing this batch is:  0.003144562244415283\n",
      "\n",
      "The classification loss after processing this batch is:  0.139969602227211\n",
      "The representation loss after processing this batch is:  0.003459364175796509\n",
      "\n",
      "The classification loss after processing this batch is:  0.2770529091358185\n",
      "The representation loss after processing this batch is:  0.0032072141766548157\n",
      "\n",
      "The classification loss after processing this batch is:  0.1697130799293518\n",
      "The representation loss after processing this batch is:  0.0035431385040283203\n",
      "\n",
      "The classification loss after processing this batch is:  0.0460917130112648\n",
      "The representation loss after processing this batch is:  0.002654626965522766\n",
      "\n",
      "The classification loss after processing this batch is:  0.014452465809881687\n",
      "The representation loss after processing this batch is:  0.003197900950908661\n",
      "\n",
      "The classification loss after processing this batch is:  0.014584040269255638\n",
      "The representation loss after processing this batch is:  0.0024081170558929443\n",
      "\n",
      "The classification loss after processing this batch is:  0.13266010582447052\n",
      "The representation loss after processing this batch is:  0.002220265567302704\n",
      "\n",
      "The classification loss after processing this batch is:  0.31333452463150024\n",
      "The representation loss after processing this batch is:  0.002752050757408142\n",
      "\n",
      "The classification loss after processing this batch is:  0.04762239381670952\n",
      "The representation loss after processing this batch is:  0.002519853413105011\n",
      "\n",
      "The classification loss after processing this batch is:  0.03438260406255722\n",
      "The representation loss after processing this batch is:  0.0031005889177322388\n",
      "\n",
      "The classification loss after processing this batch is:  0.03306855261325836\n",
      "The representation loss after processing this batch is:  0.003028571605682373\n",
      "\n",
      "The classification loss after processing this batch is:  0.03814605996012688\n",
      "The representation loss after processing this batch is:  0.0034430548548698425\n",
      "\n",
      "The classification loss after processing this batch is:  0.08206818252801895\n",
      "The representation loss after processing this batch is:  0.0024812407791614532\n",
      "\n",
      "The classification loss after processing this batch is:  0.03605002909898758\n",
      "The representation loss after processing this batch is:  0.0023512467741966248\n",
      "\n",
      "The classification loss after processing this batch is:  0.06678780168294907\n",
      "The representation loss after processing this batch is:  0.002352766692638397\n",
      "\n",
      "The classification loss after processing this batch is:  0.0959133431315422\n",
      "The representation loss after processing this batch is:  0.002188127487897873\n",
      "\n",
      "The classification loss after processing this batch is:  0.087618388235569\n",
      "The representation loss after processing this batch is:  0.002615004777908325\n",
      "\n",
      "The classification loss after processing this batch is:  0.06455313414335251\n",
      "The representation loss after processing this batch is:  0.002677150070667267\n",
      "\n",
      "The classification loss after processing this batch is:  0.06543691456317902\n",
      "The representation loss after processing this batch is:  0.002618230879306793\n",
      "\n",
      "The classification loss after processing this batch is:  0.09823182970285416\n",
      "The representation loss after processing this batch is:  0.002213273197412491\n",
      "\n",
      "The classification loss after processing this batch is:  0.08826997876167297\n",
      "The representation loss after processing this batch is:  0.0023120418190956116\n",
      "\n",
      "The classification loss after processing this batch is:  0.06045377999544144\n",
      "The representation loss after processing this batch is:  0.002389855682849884\n",
      "\n",
      "The classification loss after processing this batch is:  0.11632081866264343\n",
      "The representation loss after processing this batch is:  0.002204436808824539\n",
      "\n",
      "The classification loss after processing this batch is:  0.12183665484189987\n",
      "The representation loss after processing this batch is:  0.002340126782655716\n",
      "\n",
      "The classification loss after processing this batch is:  0.11344727128744125\n",
      "The representation loss after processing this batch is:  0.002934720367193222\n",
      "\n",
      "The classification loss after processing this batch is:  0.06013641506433487\n",
      "The representation loss after processing this batch is:  0.002440996468067169\n",
      "\n",
      "The classification loss after processing this batch is:  0.20983366668224335\n",
      "The representation loss after processing this batch is:  0.0022354163229465485\n",
      "\n",
      "The classification loss after processing this batch is:  0.12340618669986725\n",
      "The representation loss after processing this batch is:  0.0021525174379348755\n",
      "\n",
      "The classification loss after processing this batch is:  0.08364899456501007\n",
      "The representation loss after processing this batch is:  0.0022536255419254303\n",
      "\n",
      "The classification loss after processing this batch is:  0.1942492425441742\n",
      "The representation loss after processing this batch is:  0.0023532435297966003\n",
      "\n",
      "The classification loss after processing this batch is:  0.09836039692163467\n",
      "The representation loss after processing this batch is:  0.002526484429836273\n",
      "\n",
      "The classification loss after processing this batch is:  0.03865491598844528\n",
      "The representation loss after processing this batch is:  0.0024277977645397186\n",
      "\n",
      "The classification loss after processing this batch is:  0.17723137140274048\n",
      "The representation loss after processing this batch is:  0.0026842206716537476\n",
      "\n",
      "The classification loss after processing this batch is:  0.08587517589330673\n",
      "The representation loss after processing this batch is:  0.002599090337753296\n",
      "\n",
      "The classification loss after processing this batch is:  0.23453785479068756\n",
      "The representation loss after processing this batch is:  0.0022248774766921997\n",
      "\n",
      "The classification loss after processing this batch is:  0.06242161989212036\n",
      "The representation loss after processing this batch is:  0.002249188721179962\n",
      "\n",
      "The classification loss after processing this batch is:  0.04286472499370575\n",
      "The representation loss after processing this batch is:  0.002447172999382019\n",
      "\n",
      "The classification loss after processing this batch is:  0.06952014565467834\n",
      "The representation loss after processing this batch is:  0.002218920737504959\n",
      "\n",
      "The classification loss after processing this batch is:  0.058359019458293915\n",
      "The representation loss after processing this batch is:  0.002102002501487732\n",
      "\n",
      "The classification loss after processing this batch is:  0.07332918047904968\n",
      "The representation loss after processing this batch is:  0.0023628324270248413\n",
      "\n",
      "The classification loss after processing this batch is:  0.03348382189869881\n",
      "The representation loss after processing this batch is:  0.0025415122509002686\n",
      "\n",
      "The classification loss after processing this batch is:  0.029379654675722122\n",
      "The representation loss after processing this batch is:  0.0024535655975341797\n",
      "\n",
      "The classification loss after processing this batch is:  0.05406125634908676\n",
      "The representation loss after processing this batch is:  0.0025058016180992126\n",
      "\n",
      "The classification loss after processing this batch is:  0.04750998318195343\n",
      "The representation loss after processing this batch is:  0.0027291662991046906\n",
      "\n",
      "The classification loss after processing this batch is:  0.13516244292259216\n",
      "The representation loss after processing this batch is:  0.002357225865125656\n",
      "\n",
      "The classification loss after processing this batch is:  0.05684943497180939\n",
      "The representation loss after processing this batch is:  0.002652987837791443\n",
      "\n",
      "The classification loss after processing this batch is:  0.07190100103616714\n",
      "The representation loss after processing this batch is:  0.0021297484636306763\n",
      "\n",
      "The classification loss after processing this batch is:  0.02600686624646187\n",
      "The representation loss after processing this batch is:  0.0024552121758461\n",
      "\n",
      "The classification loss after processing this batch is:  0.04025155305862427\n",
      "The representation loss after processing this batch is:  0.0026311874389648438\n",
      "\n",
      "The classification loss after processing this batch is:  0.07035970687866211\n",
      "The representation loss after processing this batch is:  0.002300068736076355\n",
      "\n",
      "The classification loss after processing this batch is:  0.0671669989824295\n",
      "The representation loss after processing this batch is:  0.0026491060853004456\n",
      "\n",
      "The classification loss after processing this batch is:  0.05023229867219925\n",
      "The representation loss after processing this batch is:  0.0023673921823501587\n",
      "\n",
      "The classification loss after processing this batch is:  0.13284079730510712\n",
      "The representation loss after processing this batch is:  0.0024567395448684692\n",
      "\n",
      "The classification loss after processing this batch is:  0.07345840334892273\n",
      "The representation loss after processing this batch is:  0.002410508692264557\n",
      "\n",
      "The classification loss after processing this batch is:  0.05555101856589317\n",
      "The representation loss after processing this batch is:  0.0023316890001296997\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1358211636543274\n",
      "The representation loss after processing this batch is:  0.002559952437877655\n",
      "\n",
      "The classification loss after processing this batch is:  0.047270920127630234\n",
      "The representation loss after processing this batch is:  0.0022434815764427185\n",
      "\n",
      "The classification loss after processing this batch is:  0.06614723801612854\n",
      "The representation loss after processing this batch is:  0.002297639846801758\n",
      "\n",
      "The classification loss after processing this batch is:  0.17313283681869507\n",
      "The representation loss after processing this batch is:  0.002719864249229431\n",
      "\n",
      "The classification loss after processing this batch is:  0.034060288220644\n",
      "The representation loss after processing this batch is:  0.002341967076063156\n",
      "\n",
      "The classification loss after processing this batch is:  0.11916708201169968\n",
      "The representation loss after processing this batch is:  0.002313651144504547\n",
      "\n",
      "The classification loss after processing this batch is:  0.0682455524802208\n",
      "The representation loss after processing this batch is:  0.0022989436984062195\n",
      "\n",
      "The classification loss after processing this batch is:  0.06900691986083984\n",
      "The representation loss after processing this batch is:  0.0023360662162303925\n",
      "\n",
      "The classification loss after processing this batch is:  0.073029525578022\n",
      "The representation loss after processing this batch is:  0.0022964999079704285\n",
      "\n",
      "The classification loss after processing this batch is:  0.03872363641858101\n",
      "The representation loss after processing this batch is:  0.0024789832532405853\n",
      "\n",
      "The classification loss after processing this batch is:  0.13802558183670044\n",
      "The representation loss after processing this batch is:  0.0026211515069007874\n",
      "\n",
      "The classification loss after processing this batch is:  0.09167909622192383\n",
      "The representation loss after processing this batch is:  0.0026165321469306946\n",
      "\n",
      "The classification loss after processing this batch is:  0.0979696661233902\n",
      "The representation loss after processing this batch is:  0.0024500861763954163\n",
      "\n",
      "The classification loss after processing this batch is:  0.09804839640855789\n",
      "The representation loss after processing this batch is:  0.002234548330307007\n",
      "\n",
      "The classification loss after processing this batch is:  0.11220435053110123\n",
      "The representation loss after processing this batch is:  0.0024431347846984863\n",
      "\n",
      "The classification loss after processing this batch is:  0.10361944139003754\n",
      "The representation loss after processing this batch is:  0.002355054020881653\n",
      "\n",
      "The classification loss after processing this batch is:  0.0700569823384285\n",
      "The representation loss after processing this batch is:  0.002246662974357605\n",
      "\n",
      "The classification loss after processing this batch is:  0.05989329516887665\n",
      "The representation loss after processing this batch is:  0.0022813715040683746\n",
      "\n",
      "The classification loss after processing this batch is:  0.1432284712791443\n",
      "The representation loss after processing this batch is:  0.0024208538234233856\n",
      "\n",
      "The classification loss after processing this batch is:  0.11807079613208771\n",
      "The representation loss after processing this batch is:  0.002408944070339203\n",
      "\n",
      "The classification loss after processing this batch is:  0.054934512823820114\n",
      "The representation loss after processing this batch is:  0.0023697614669799805\n",
      "\n",
      "The classification loss after processing this batch is:  0.054137371480464935\n",
      "The representation loss after processing this batch is:  0.002319909632205963\n",
      "\n",
      "The classification loss after processing this batch is:  0.050362396985292435\n",
      "The representation loss after processing this batch is:  0.002308029681444168\n",
      "\n",
      "The classification loss after processing this batch is:  0.05485554784536362\n",
      "The representation loss after processing this batch is:  0.0025960057973861694\n",
      "\n",
      "The classification loss after processing this batch is:  0.12234625965356827\n",
      "The representation loss after processing this batch is:  0.002097778022289276\n",
      "\n",
      "The classification loss after processing this batch is:  0.058849528431892395\n",
      "The representation loss after processing this batch is:  0.0022741183638572693\n",
      "\n",
      "The classification loss after processing this batch is:  0.1634603589773178\n",
      "The representation loss after processing this batch is:  0.0022915713489055634\n",
      "\n",
      "The classification loss after processing this batch is:  0.10878828167915344\n",
      "The representation loss after processing this batch is:  0.0022930987179279327\n",
      "\n",
      "The classification loss after processing this batch is:  0.10136021673679352\n",
      "The representation loss after processing this batch is:  0.002262905240058899\n",
      "\n",
      "The classification loss after processing this batch is:  0.06127302721142769\n",
      "The representation loss after processing this batch is:  0.0019820109009742737\n",
      "\n",
      "The classification loss after processing this batch is:  0.05025918409228325\n",
      "The representation loss after processing this batch is:  0.0024929121136665344\n",
      "\n",
      "The classification loss after processing this batch is:  0.07199559360742569\n",
      "The representation loss after processing this batch is:  0.0020972304046154022\n",
      "\n",
      "The classification loss after processing this batch is:  0.1479877084493637\n",
      "The representation loss after processing this batch is:  0.002088017761707306\n",
      "\n",
      "The classification loss after processing this batch is:  0.061380647122859955\n",
      "The representation loss after processing this batch is:  0.0021870583295822144\n",
      "\n",
      "The classification loss after processing this batch is:  0.2492327094078064\n",
      "The representation loss after processing this batch is:  0.0021970421075820923\n",
      "\n",
      "The classification loss after processing this batch is:  0.08107313513755798\n",
      "The representation loss after processing this batch is:  0.002146981656551361\n",
      "\n",
      "The classification loss after processing this batch is:  0.04741304740309715\n",
      "The representation loss after processing this batch is:  0.002896241843700409\n",
      "\n",
      "The classification loss after processing this batch is:  0.13051217794418335\n",
      "The representation loss after processing this batch is:  0.0024158358573913574\n",
      "\n",
      "The classification loss after processing this batch is:  0.042952630668878555\n",
      "The representation loss after processing this batch is:  0.0026325657963752747\n",
      "\n",
      "The classification loss after processing this batch is:  0.22702869772911072\n",
      "The representation loss after processing this batch is:  0.0026197433471679688\n",
      "\n",
      "The classification loss after processing this batch is:  0.10004971921443939\n",
      "The representation loss after processing this batch is:  0.0021826252341270447\n",
      "\n",
      "The classification loss after processing this batch is:  0.16769057512283325\n",
      "The representation loss after processing this batch is:  0.002360604703426361\n",
      "\n",
      "The classification loss after processing this batch is:  0.18915043771266937\n",
      "The representation loss after processing this batch is:  0.002332579344511032\n",
      "\n",
      "The classification loss after processing this batch is:  0.12068445235490799\n",
      "The representation loss after processing this batch is:  0.0020949915051460266\n",
      "\n",
      "The classification loss after processing this batch is:  0.044115785509347916\n",
      "The representation loss after processing this batch is:  0.0023727640509605408\n",
      "\n",
      "The classification loss after processing this batch is:  0.11783390492200851\n",
      "The representation loss after processing this batch is:  0.002257697284221649\n",
      "\n",
      "The classification loss after processing this batch is:  0.08636553585529327\n",
      "The representation loss after processing this batch is:  0.002431347966194153\n",
      "\n",
      "The classification loss after processing this batch is:  0.10712400823831558\n",
      "The representation loss after processing this batch is:  0.0023839063942432404\n",
      "\n",
      "The classification loss after processing this batch is:  0.0589895024895668\n",
      "The representation loss after processing this batch is:  0.0022115781903266907\n",
      "\n",
      "The classification loss after processing this batch is:  0.07419777661561966\n",
      "The representation loss after processing this batch is:  0.002292148768901825\n",
      "\n",
      "The classification loss after processing this batch is:  0.14813324809074402\n",
      "The representation loss after processing this batch is:  0.0024036765098571777\n",
      "\n",
      "The classification loss after processing this batch is:  0.11954351514577866\n",
      "The representation loss after processing this batch is:  0.0025837644934654236\n",
      "\n",
      "The classification loss after processing this batch is:  0.14852997660636902\n",
      "The representation loss after processing this batch is:  0.002194121479988098\n",
      "\n",
      "The classification loss after processing this batch is:  0.20265713334083557\n",
      "The representation loss after processing this batch is:  0.0026233941316604614\n",
      "\n",
      "The classification loss after processing this batch is:  0.11453118920326233\n",
      "The representation loss after processing this batch is:  0.0025781169533729553\n",
      "\n",
      "The classification loss after processing this batch is:  0.05372099578380585\n",
      "The representation loss after processing this batch is:  0.002526111900806427\n",
      "\n",
      "The classification loss after processing this batch is:  0.05582183226943016\n",
      "The representation loss after processing this batch is:  0.0023634061217308044\n",
      "\n",
      "The classification loss after processing this batch is:  0.030012603849172592\n",
      "The representation loss after processing this batch is:  0.0024003684520721436\n",
      "\n",
      "The classification loss after processing this batch is:  0.1057780534029007\n",
      "The representation loss after processing this batch is:  0.0024613887071609497\n",
      "\n",
      "The classification loss after processing this batch is:  0.08660367876291275\n",
      "The representation loss after processing this batch is:  0.0024623125791549683\n",
      "\n",
      "The classification loss after processing this batch is:  0.2299780249595642\n",
      "The representation loss after processing this batch is:  0.002494722604751587\n",
      "\n",
      "The classification loss after processing this batch is:  0.2347354143857956\n",
      "The representation loss after processing this batch is:  0.002434253692626953\n",
      "\n",
      "The classification loss after processing this batch is:  0.06469108909368515\n",
      "The representation loss after processing this batch is:  0.0026090145111083984\n",
      "\n",
      "The classification loss after processing this batch is:  0.08381257951259613\n",
      "The representation loss after processing this batch is:  0.002700991928577423\n",
      "\n",
      "The classification loss after processing this batch is:  0.1186661422252655\n",
      "The representation loss after processing this batch is:  0.0021519623696804047\n",
      "\n",
      "The classification loss after processing this batch is:  0.04233618825674057\n",
      "The representation loss after processing this batch is:  0.0025482177734375\n",
      "\n",
      "The classification loss after processing this batch is:  0.042768944054841995\n",
      "The representation loss after processing this batch is:  0.002489633858203888\n",
      "\n",
      "The classification loss after processing this batch is:  0.10412023961544037\n",
      "The representation loss after processing this batch is:  0.002201385796070099\n",
      "\n",
      "The classification loss after processing this batch is:  0.06006603315472603\n",
      "The representation loss after processing this batch is:  0.002964034676551819\n",
      "\n",
      "The classification loss after processing this batch is:  0.08028607070446014\n",
      "The representation loss after processing this batch is:  0.0027389153838157654\n",
      "\n",
      "The classification loss after processing this batch is:  0.19275516271591187\n",
      "The representation loss after processing this batch is:  0.0032342523336410522\n",
      "\n",
      "The classification loss after processing this batch is:  0.2077704221010208\n",
      "The representation loss after processing this batch is:  0.0021118298172950745\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.07224830240011215\n",
      "The representation loss after processing this batch is:  0.0026890039443969727\n",
      "\n",
      "The classification loss after processing this batch is:  0.1568339765071869\n",
      "The representation loss after processing this batch is:  0.0024682804942131042\n",
      "\n",
      "The classification loss after processing this batch is:  0.16034790873527527\n",
      "The representation loss after processing this batch is:  0.0022347643971443176\n",
      "\n",
      "The classification loss after processing this batch is:  0.051227644085884094\n",
      "The representation loss after processing this batch is:  0.0023766569793224335\n",
      "\n",
      "The classification loss after processing this batch is:  0.09864261001348495\n",
      "The representation loss after processing this batch is:  0.002180676907300949\n",
      "\n",
      "The classification loss after processing this batch is:  0.36031609773635864\n",
      "The representation loss after processing this batch is:  0.0029737576842308044\n",
      "\n",
      "The classification loss after processing this batch is:  0.12371914833784103\n",
      "The representation loss after processing this batch is:  0.002622712403535843\n",
      "\n",
      "The classification loss after processing this batch is:  0.03944959491491318\n",
      "The representation loss after processing this batch is:  0.0026983246207237244\n",
      "\n",
      "The classification loss after processing this batch is:  0.040789127349853516\n",
      "The representation loss after processing this batch is:  0.002728492021560669\n",
      "\n",
      "The classification loss after processing this batch is:  0.04634178429841995\n",
      "The representation loss after processing this batch is:  0.002726428210735321\n",
      "\n",
      "The classification loss after processing this batch is:  0.07443726807832718\n",
      "The representation loss after processing this batch is:  0.002561010420322418\n",
      "\n",
      "The classification loss after processing this batch is:  0.055785976350307465\n",
      "The representation loss after processing this batch is:  0.002690061926841736\n",
      "\n",
      "The classification loss after processing this batch is:  0.11029759049415588\n",
      "The representation loss after processing this batch is:  0.0023253820836544037\n",
      "\n",
      "The classification loss after processing this batch is:  0.08303635567426682\n",
      "The representation loss after processing this batch is:  0.0022807344794273376\n",
      "\n",
      "The classification loss after processing this batch is:  0.1500106155872345\n",
      "The representation loss after processing this batch is:  0.0022409260272979736\n",
      "\n",
      "The classification loss after processing this batch is:  0.06596902757883072\n",
      "The representation loss after processing this batch is:  0.0020853541791439056\n",
      "\n",
      "The classification loss after processing this batch is:  0.0882742702960968\n",
      "The representation loss after processing this batch is:  0.0022139549255371094\n",
      "\n",
      "The classification loss after processing this batch is:  0.11783181875944138\n",
      "The representation loss after processing this batch is:  0.0023860521614551544\n",
      "\n",
      "The classification loss after processing this batch is:  0.11046785861253738\n",
      "The representation loss after processing this batch is:  0.0024710819125175476\n",
      "\n",
      "The classification loss after processing this batch is:  0.06391452252864838\n",
      "The representation loss after processing this batch is:  0.0022167563438415527\n",
      "\n",
      "The classification loss after processing this batch is:  0.1376657783985138\n",
      "The representation loss after processing this batch is:  0.0022194981575012207\n",
      "\n",
      "The classification loss after processing this batch is:  0.14670880138874054\n",
      "The representation loss after processing this batch is:  0.0023627355694770813\n",
      "\n",
      "The classification loss after processing this batch is:  0.1200452595949173\n",
      "The representation loss after processing this batch is:  0.0022642575204372406\n",
      "\n",
      "The classification loss after processing this batch is:  0.10616470873355865\n",
      "The representation loss after processing this batch is:  0.00259292870759964\n",
      "\n",
      "The classification loss after processing this batch is:  0.17006321251392365\n",
      "The representation loss after processing this batch is:  0.0024344027042388916\n",
      "\n",
      "The classification loss after processing this batch is:  0.1725587099790573\n",
      "The representation loss after processing this batch is:  0.002571605145931244\n",
      "\n",
      "The classification loss after processing this batch is:  0.12699533998966217\n",
      "The representation loss after processing this batch is:  0.0025840625166893005\n",
      "\n",
      "The classification loss after processing this batch is:  0.07281080633401871\n",
      "The representation loss after processing this batch is:  0.002693675458431244\n",
      "\n",
      "The classification loss after processing this batch is:  0.06554166227579117\n",
      "The representation loss after processing this batch is:  0.0026649683713912964\n",
      "\n",
      "The classification loss after processing this batch is:  0.20827604830265045\n",
      "The representation loss after processing this batch is:  0.0023079141974449158\n",
      "\n",
      "The classification loss after processing this batch is:  0.14344114065170288\n",
      "The representation loss after processing this batch is:  0.0021701157093048096\n",
      "\n",
      "The classification loss after processing this batch is:  0.24882173538208008\n",
      "The representation loss after processing this batch is:  0.0024630576372146606\n",
      "\n",
      "The classification loss after processing this batch is:  0.26295509934425354\n",
      "The representation loss after processing this batch is:  0.0022189393639564514\n",
      "\n",
      "The classification loss after processing this batch is:  0.13606640696525574\n",
      "The representation loss after processing this batch is:  0.0021490901708602905\n",
      "\n",
      "The classification loss after processing this batch is:  0.07480323314666748\n",
      "The representation loss after processing this batch is:  0.0022728517651557922\n",
      "\n",
      "The classification loss after processing this batch is:  0.0582321397960186\n",
      "The representation loss after processing this batch is:  0.0021823719143867493\n",
      "\n",
      "The classification loss after processing this batch is:  0.04390477389097214\n",
      "The representation loss after processing this batch is:  0.0027126073837280273\n",
      "\n",
      "The classification loss after processing this batch is:  0.08712465316057205\n",
      "The representation loss after processing this batch is:  0.00295451283454895\n",
      "\n",
      "The classification loss after processing this batch is:  0.04463630169630051\n",
      "The representation loss after processing this batch is:  0.0024926885962486267\n",
      "\n",
      "The classification loss after processing this batch is:  0.19426822662353516\n",
      "The representation loss after processing this batch is:  0.0033935680985450745\n",
      "\n",
      "The classification loss after processing this batch is:  0.08855952322483063\n",
      "The representation loss after processing this batch is:  0.0025175251066684723\n",
      "\n",
      "The classification loss after processing this batch is:  0.06696101278066635\n",
      "The representation loss after processing this batch is:  0.0025493986904621124\n",
      "\n",
      "The classification loss after processing this batch is:  0.15539976954460144\n",
      "The representation loss after processing this batch is:  0.002270631492137909\n",
      "\n",
      "The classification loss after processing this batch is:  0.061545442789793015\n",
      "The representation loss after processing this batch is:  0.0027004480361938477\n",
      "\n",
      "The classification loss after processing this batch is:  0.05791768804192543\n",
      "The representation loss after processing this batch is:  0.003154441714286804\n",
      "\n",
      "The classification loss after processing this batch is:  0.24225734174251556\n",
      "The representation loss after processing this batch is:  0.003109484910964966\n",
      "\n",
      "The classification loss after processing this batch is:  0.1052541583776474\n",
      "The representation loss after processing this batch is:  0.0027125179767608643\n",
      "\n",
      "The classification loss after processing this batch is:  0.110965296626091\n",
      "The representation loss after processing this batch is:  0.0022896379232406616\n",
      "\n",
      "The classification loss after processing this batch is:  0.04750017076730728\n",
      "The representation loss after processing this batch is:  0.0021870285272598267\n",
      "\n",
      "The classification loss after processing this batch is:  0.018352460116147995\n",
      "The representation loss after processing this batch is:  0.0026247426867485046\n",
      "\n",
      "The classification loss after processing this batch is:  0.0434659905731678\n",
      "The representation loss after processing this batch is:  0.0027398839592933655\n",
      "\n",
      "The classification loss after processing this batch is:  0.04863358289003372\n",
      "The representation loss after processing this batch is:  0.0023408792912960052\n",
      "\n",
      "The classification loss after processing this batch is:  0.0785360112786293\n",
      "The representation loss after processing this batch is:  0.002278447151184082\n",
      "\n",
      "The classification loss after processing this batch is:  0.07234154641628265\n",
      "The representation loss after processing this batch is:  0.0025646165013313293\n",
      "\n",
      "The classification loss after processing this batch is:  0.08235190808773041\n",
      "The representation loss after processing this batch is:  0.002475842833518982\n",
      "\n",
      "The classification loss after processing this batch is:  0.24678675830364227\n",
      "The representation loss after processing this batch is:  0.0026490166783332825\n",
      "\n",
      "The classification loss after processing this batch is:  0.171608105301857\n",
      "The representation loss after processing this batch is:  0.00258694589138031\n",
      "\n",
      "The classification loss after processing this batch is:  0.0648878663778305\n",
      "The representation loss after processing this batch is:  0.0023520365357398987\n",
      "\n",
      "The classification loss after processing this batch is:  0.049981601536273956\n",
      "The representation loss after processing this batch is:  0.0027078911662101746\n",
      "\n",
      "The classification loss after processing this batch is:  0.0733971893787384\n",
      "The representation loss after processing this batch is:  0.002490028738975525\n",
      "\n",
      "The classification loss after processing this batch is:  0.0639062449336052\n",
      "The representation loss after processing this batch is:  0.0025770440697669983\n",
      "\n",
      "The classification loss after processing this batch is:  0.021307460963726044\n",
      "The representation loss after processing this batch is:  0.002338416874408722\n",
      "\n",
      "The classification loss after processing this batch is:  0.03329811990261078\n",
      "The representation loss after processing this batch is:  0.00245555117726326\n",
      "\n",
      "The classification loss after processing this batch is:  0.07552017271518707\n",
      "The representation loss after processing this batch is:  0.002151288092136383\n",
      "\n",
      "The classification loss after processing this batch is:  0.08912006765604019\n",
      "The representation loss after processing this batch is:  0.0022006332874298096\n",
      "\n",
      "The classification loss after processing this batch is:  0.07320373505353928\n",
      "The representation loss after processing this batch is:  0.0025652125477790833\n",
      "\n",
      "The classification loss after processing this batch is:  0.051114581525325775\n",
      "The representation loss after processing this batch is:  0.002431310713291168\n",
      "\n",
      "The classification loss after processing this batch is:  0.048507921397686005\n",
      "The representation loss after processing this batch is:  0.002353556454181671\n",
      "\n",
      "The classification loss after processing this batch is:  0.23221366107463837\n",
      "The representation loss after processing this batch is:  0.002283092588186264\n",
      "\n",
      "The classification loss after processing this batch is:  0.09393789619207382\n",
      "The representation loss after processing this batch is:  0.002431608736515045\n",
      "\n",
      "The classification loss after processing this batch is:  0.03498448431491852\n",
      "The representation loss after processing this batch is:  0.002513006329536438\n",
      "\n",
      "The classification loss after processing this batch is:  0.081961490213871\n",
      "The representation loss after processing this batch is:  0.0024550482630729675\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.07652188092470169\n",
      "The representation loss after processing this batch is:  0.002226412296295166\n",
      "\n",
      "The classification loss after processing this batch is:  0.041376493871212006\n",
      "The representation loss after processing this batch is:  0.002224765717983246\n",
      "\n",
      "The classification loss after processing this batch is:  0.10490959137678146\n",
      "The representation loss after processing this batch is:  0.0022869594395160675\n",
      "\n",
      "The classification loss after processing this batch is:  0.050136808305978775\n",
      "The representation loss after processing this batch is:  0.0022343769669532776\n",
      "\n",
      "The classification loss after processing this batch is:  0.05066843703389168\n",
      "The representation loss after processing this batch is:  0.0024937912821769714\n",
      "\n",
      "The classification loss after processing this batch is:  0.08954671770334244\n",
      "The representation loss after processing this batch is:  0.0020365864038467407\n",
      "\n",
      "The classification loss after processing this batch is:  0.13693615794181824\n",
      "The representation loss after processing this batch is:  0.0024318769574165344\n",
      "\n",
      "The classification loss after processing this batch is:  0.10792980343103409\n",
      "The representation loss after processing this batch is:  0.0025013312697410583\n",
      "\n",
      "The classification loss after processing this batch is:  0.11258313804864883\n",
      "The representation loss after processing this batch is:  0.00218360498547554\n",
      "\n",
      "The classification loss after processing this batch is:  0.0865384116768837\n",
      "The representation loss after processing this batch is:  0.0023726150393486023\n",
      "\n",
      "The classification loss after processing this batch is:  0.15894873440265656\n",
      "The representation loss after processing this batch is:  0.002311490476131439\n",
      "\n",
      "The classification loss after processing this batch is:  0.059921275824308395\n",
      "The representation loss after processing this batch is:  0.002538807690143585\n",
      "\n",
      "The classification loss after processing this batch is:  0.10678578913211823\n",
      "The representation loss after processing this batch is:  0.0022337883710861206\n",
      "\n",
      "The classification loss after processing this batch is:  0.05882919952273369\n",
      "The representation loss after processing this batch is:  0.002253510057926178\n",
      "\n",
      "The classification loss after processing this batch is:  0.17839795351028442\n",
      "The representation loss after processing this batch is:  0.002294108271598816\n",
      "\n",
      "The classification loss after processing this batch is:  0.08963896334171295\n",
      "The representation loss after processing this batch is:  0.0025009959936141968\n",
      "\n",
      "The classification loss after processing this batch is:  0.12899383902549744\n",
      "The representation loss after processing this batch is:  0.0022237785160541534\n",
      "\n",
      "The classification loss after processing this batch is:  0.0815344899892807\n",
      "The representation loss after processing this batch is:  0.002243567258119583\n",
      "\n",
      "The classification loss after processing this batch is:  0.07911035418510437\n",
      "The representation loss after processing this batch is:  0.00239003449678421\n",
      "\n",
      "The classification loss after processing this batch is:  0.12229561805725098\n",
      "The representation loss after processing this batch is:  0.002223677933216095\n",
      "\n",
      "The classification loss after processing this batch is:  0.0677402913570404\n",
      "The representation loss after processing this batch is:  0.0021082349121570587\n",
      "\n",
      "The classification loss after processing this batch is:  0.10454507917165756\n",
      "The representation loss after processing this batch is:  0.0023821555078029633\n",
      "\n",
      "The classification loss after processing this batch is:  0.17783412337303162\n",
      "The representation loss after processing this batch is:  0.0022260770201683044\n",
      "\n",
      "The classification loss after processing this batch is:  0.1911010891199112\n",
      "The representation loss after processing this batch is:  0.0020675882697105408\n",
      "\n",
      "The classification loss after processing this batch is:  0.13167940080165863\n",
      "The representation loss after processing this batch is:  0.00226806104183197\n",
      "\n",
      "The classification loss after processing this batch is:  0.06253913044929504\n",
      "The representation loss after processing this batch is:  0.0024419501423835754\n",
      "\n",
      "The classification loss after processing this batch is:  0.1593249887228012\n",
      "The representation loss after processing this batch is:  0.0024882033467292786\n",
      "\n",
      "The classification loss after processing this batch is:  0.08941736072301865\n",
      "The representation loss after processing this batch is:  0.0025661587715148926\n",
      "\n",
      "The classification loss after processing this batch is:  0.06962094455957413\n",
      "The representation loss after processing this batch is:  0.0024754703044891357\n",
      "\n",
      "The classification loss after processing this batch is:  0.1383231282234192\n",
      "The representation loss after processing this batch is:  0.002727411687374115\n",
      "\n",
      "The classification loss after processing this batch is:  0.17769210040569305\n",
      "The representation loss after processing this batch is:  0.0023667365312576294\n",
      "\n",
      "The classification loss after processing this batch is:  0.2478211671113968\n",
      "The representation loss after processing this batch is:  0.002205364406108856\n",
      "\n",
      "The classification loss after processing this batch is:  0.11328470706939697\n",
      "The representation loss after processing this batch is:  0.0025694891810417175\n",
      "\n",
      "The classification loss after processing this batch is:  0.06312475353479385\n",
      "The representation loss after processing this batch is:  0.002350933849811554\n",
      "\n",
      "The classification loss after processing this batch is:  0.08773791044950485\n",
      "The representation loss after processing this batch is:  0.0025681406259536743\n",
      "\n",
      "The classification loss after processing this batch is:  0.16650183498859406\n",
      "The representation loss after processing this batch is:  0.002295229583978653\n",
      "\n",
      "The classification loss after processing this batch is:  0.08583378046751022\n",
      "The representation loss after processing this batch is:  0.0024493560194969177\n",
      "\n",
      "The classification loss after processing this batch is:  0.1097932755947113\n",
      "The representation loss after processing this batch is:  0.002318989485502243\n",
      "\n",
      "The classification loss after processing this batch is:  0.10097156465053558\n",
      "The representation loss after processing this batch is:  0.0023435428738594055\n",
      "\n",
      "The classification loss after processing this batch is:  0.02330539934337139\n",
      "The representation loss after processing this batch is:  0.002454809844493866\n",
      "\n",
      "The classification loss after processing this batch is:  0.07040447741746902\n",
      "The representation loss after processing this batch is:  0.0025508925318717957\n",
      "\n",
      "The classification loss after processing this batch is:  0.10948500782251358\n",
      "The representation loss after processing this batch is:  0.002609826624393463\n",
      "\n",
      "The classification loss after processing this batch is:  0.11690425127744675\n",
      "The representation loss after processing this batch is:  0.0023565441370010376\n",
      "\n",
      "The classification loss after processing this batch is:  0.1016310602426529\n",
      "The representation loss after processing this batch is:  0.0022835582494735718\n",
      "\n",
      "The classification loss after processing this batch is:  0.09009824693202972\n",
      "The representation loss after processing this batch is:  0.002436339855194092\n",
      "\n",
      "The classification loss after processing this batch is:  0.12735764682292938\n",
      "The representation loss after processing this batch is:  0.002656415104866028\n",
      "\n",
      "The classification loss after processing this batch is:  0.06610362231731415\n",
      "The representation loss after processing this batch is:  0.0025226660072803497\n",
      "\n",
      "The classification loss after processing this batch is:  0.09084677696228027\n",
      "The representation loss after processing this batch is:  0.002786286175251007\n",
      "\n",
      "The classification loss after processing this batch is:  0.0958591029047966\n",
      "The representation loss after processing this batch is:  0.0026470646262168884\n",
      "\n",
      "The classification loss after processing this batch is:  0.1120363101363182\n",
      "The representation loss after processing this batch is:  0.0024693384766578674\n",
      "\n",
      "The classification loss after processing this batch is:  0.13465897738933563\n",
      "The representation loss after processing this batch is:  0.002254977822303772\n",
      "\n",
      "The classification loss after processing this batch is:  0.20000509917736053\n",
      "The representation loss after processing this batch is:  0.002227187156677246\n",
      "\n",
      "The classification loss after processing this batch is:  0.21972014009952545\n",
      "The representation loss after processing this batch is:  0.0023727864027023315\n",
      "\n",
      "The classification loss after processing this batch is:  0.047713182866573334\n",
      "The representation loss after processing this batch is:  0.0021798275411128998\n",
      "\n",
      "The classification loss after processing this batch is:  0.08596757054328918\n",
      "The representation loss after processing this batch is:  0.002675246447324753\n",
      "\n",
      "The classification loss after processing this batch is:  0.09923625737428665\n",
      "The representation loss after processing this batch is:  0.0024907439947128296\n",
      "\n",
      "The classification loss after processing this batch is:  0.11666703224182129\n",
      "The representation loss after processing this batch is:  0.002263598144054413\n",
      "\n",
      "The classification loss after processing this batch is:  0.19103071093559265\n",
      "The representation loss after processing this batch is:  0.0025330856442451477\n",
      "\n",
      "The classification loss after processing this batch is:  0.16437700390815735\n",
      "The representation loss after processing this batch is:  0.0027486681938171387\n",
      "\n",
      "The classification loss after processing this batch is:  0.1696702539920807\n",
      "The representation loss after processing this batch is:  0.002859070897102356\n",
      "\n",
      "The classification loss after processing this batch is:  0.08496222645044327\n",
      "The representation loss after processing this batch is:  0.002656295895576477\n",
      "\n",
      "The classification loss after processing this batch is:  0.12948264181613922\n",
      "The representation loss after processing this batch is:  0.002546701580286026\n",
      "\n",
      "The classification loss after processing this batch is:  0.1611853986978531\n",
      "The representation loss after processing this batch is:  0.0029597878456115723\n",
      "\n",
      "The classification loss after processing this batch is:  0.042008284479379654\n",
      "The representation loss after processing this batch is:  0.0024362727999687195\n",
      "\n",
      "The classification loss after processing this batch is:  0.18458686769008636\n",
      "The representation loss after processing this batch is:  0.0025773532688617706\n",
      "\n",
      "The classification loss after processing this batch is:  0.09181700646877289\n",
      "The representation loss after processing this batch is:  0.002193756401538849\n",
      "\n",
      "The classification loss after processing this batch is:  0.03896006569266319\n",
      "The representation loss after processing this batch is:  0.0021840371191501617\n",
      "\n",
      "The classification loss after processing this batch is:  0.09381994605064392\n",
      "The representation loss after processing this batch is:  0.0022319331765174866\n",
      "\n",
      "The classification loss after processing this batch is:  0.10326113551855087\n",
      "The representation loss after processing this batch is:  0.002739265561103821\n",
      "\n",
      "The classification loss after processing this batch is:  0.1436052918434143\n",
      "The representation loss after processing this batch is:  0.002177450805902481\n",
      "\n",
      "The classification loss after processing this batch is:  0.06719107180833817\n",
      "The representation loss after processing this batch is:  0.002382837235927582\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.06107999384403229\n",
      "The representation loss after processing this batch is:  0.0022234469652175903\n",
      "\n",
      "The classification loss after processing this batch is:  0.03183136135339737\n",
      "The representation loss after processing this batch is:  0.0022762268781661987\n",
      "\n",
      "The classification loss after processing this batch is:  0.1428993046283722\n",
      "The representation loss after processing this batch is:  0.002060502767562866\n",
      "\n",
      "The classification loss after processing this batch is:  0.08178167790174484\n",
      "The representation loss after processing this batch is:  0.002058945596218109\n",
      "\n",
      "The classification loss after processing this batch is:  0.37515679001808167\n",
      "The representation loss after processing this batch is:  0.0025122836232185364\n",
      "\n",
      "The classification loss after processing this batch is:  0.08863405883312225\n",
      "The representation loss after processing this batch is:  0.002406962215900421\n",
      "\n",
      "The classification loss after processing this batch is:  0.1622946709394455\n",
      "The representation loss after processing this batch is:  0.0021852217614650726\n",
      "\n",
      "The classification loss after processing this batch is:  0.20534344017505646\n",
      "The representation loss after processing this batch is:  0.002463884651660919\n",
      "\n",
      "The classification loss after processing this batch is:  0.06164652854204178\n",
      "The representation loss after processing this batch is:  0.0022546201944351196\n",
      "\n",
      "The classification loss after processing this batch is:  0.20864072442054749\n",
      "The representation loss after processing this batch is:  0.0025154203176498413\n",
      "\n",
      "The classification loss after processing this batch is:  0.11301268637180328\n",
      "The representation loss after processing this batch is:  0.0025982223451137543\n",
      "\n",
      "The classification loss after processing this batch is:  0.22112327814102173\n",
      "The representation loss after processing this batch is:  0.0021027661859989166\n",
      "\n",
      "The classification loss after processing this batch is:  0.04295079782605171\n",
      "The representation loss after processing this batch is:  0.00212705135345459\n",
      "\n",
      "The classification loss after processing this batch is:  0.08955211937427521\n",
      "The representation loss after processing this batch is:  0.0024799853563308716\n",
      "\n",
      "The classification loss after processing this batch is:  0.026780307292938232\n",
      "The representation loss after processing this batch is:  0.002397783100605011\n",
      "\n",
      "The classification loss after processing this batch is:  0.024816131219267845\n",
      "The representation loss after processing this batch is:  0.002505265176296234\n",
      "\n",
      "The classification loss after processing this batch is:  0.05108946934342384\n",
      "The representation loss after processing this batch is:  0.002259954810142517\n",
      "\n",
      "The classification loss after processing this batch is:  0.04530275613069534\n",
      "The representation loss after processing this batch is:  0.002241089940071106\n",
      "\n",
      "The classification loss after processing this batch is:  0.12031421810388565\n",
      "The representation loss after processing this batch is:  0.0025585144758224487\n",
      "\n",
      "The classification loss after processing this batch is:  0.07325925678014755\n",
      "The representation loss after processing this batch is:  0.002792045474052429\n",
      "\n",
      "The classification loss after processing this batch is:  0.06093500927090645\n",
      "The representation loss after processing this batch is:  0.0022679567337036133\n",
      "\n",
      "The classification loss after processing this batch is:  0.11248309910297394\n",
      "The representation loss after processing this batch is:  0.002115599811077118\n",
      "\n",
      "The classification loss after processing this batch is:  0.049575988203287125\n",
      "The representation loss after processing this batch is:  0.002712041139602661\n",
      "\n",
      "The classification loss after processing this batch is:  0.08884334564208984\n",
      "The representation loss after processing this batch is:  0.0025221779942512512\n",
      "\n",
      "The classification loss after processing this batch is:  0.10422702133655548\n",
      "The representation loss after processing this batch is:  0.0024185925722122192\n",
      "\n",
      "The classification loss after processing this batch is:  0.16169613599777222\n",
      "The representation loss after processing this batch is:  0.0026385635137557983\n",
      "\n",
      "The classification loss after processing this batch is:  0.0937650054693222\n",
      "The representation loss after processing this batch is:  0.002244170755147934\n",
      "\n",
      "The classification loss after processing this batch is:  0.0690302923321724\n",
      "The representation loss after processing this batch is:  0.00235077366232872\n",
      "\n",
      "The classification loss after processing this batch is:  0.17272676527500153\n",
      "The representation loss after processing this batch is:  0.0025680288672447205\n",
      "\n",
      "The classification loss after processing this batch is:  0.13890261948108673\n",
      "The representation loss after processing this batch is:  0.002355903387069702\n",
      "\n",
      "The classification loss after processing this batch is:  0.12212706357240677\n",
      "The representation loss after processing this batch is:  0.0023596957325935364\n",
      "\n",
      "The classification loss after processing this batch is:  0.04025835171341896\n",
      "The representation loss after processing this batch is:  0.0023574084043502808\n",
      "\n",
      "The classification loss after processing this batch is:  0.1150083988904953\n",
      "The representation loss after processing this batch is:  0.0025976672768592834\n",
      "\n",
      "The classification loss after processing this batch is:  0.11028356105089188\n",
      "The representation loss after processing this batch is:  0.002599123865365982\n",
      "\n",
      "The classification loss after processing this batch is:  0.10354774445295334\n",
      "The representation loss after processing this batch is:  0.002652917057275772\n",
      "\n",
      "The classification loss after processing this batch is:  0.11067613959312439\n",
      "The representation loss after processing this batch is:  0.0031305067241191864\n",
      "\n",
      "The classification loss after processing this batch is:  0.07258711755275726\n",
      "The representation loss after processing this batch is:  0.003090701997280121\n",
      "\n",
      "The classification loss after processing this batch is:  0.12813511490821838\n",
      "The representation loss after processing this batch is:  0.0027223601937294006\n",
      "\n",
      "The classification loss after processing this batch is:  0.19283409416675568\n",
      "The representation loss after processing this batch is:  0.0025989674031734467\n",
      "\n",
      "The classification loss after processing this batch is:  0.10236480087041855\n",
      "The representation loss after processing this batch is:  0.003018587827682495\n",
      "\n",
      "The classification loss after processing this batch is:  0.087135910987854\n",
      "The representation loss after processing this batch is:  0.0023802369832992554\n",
      "\n",
      "The classification loss after processing this batch is:  0.02987336367368698\n",
      "The representation loss after processing this batch is:  0.002098914235830307\n",
      "\n",
      "The classification loss after processing this batch is:  0.14239364862442017\n",
      "The representation loss after processing this batch is:  0.0022408515214920044\n",
      "\n",
      "The classification loss after processing this batch is:  0.05888795852661133\n",
      "The representation loss after processing this batch is:  0.0024083033204078674\n",
      "\n",
      "The classification loss after processing this batch is:  0.10612495243549347\n",
      "The representation loss after processing this batch is:  0.0023621320724487305\n",
      "\n",
      "The classification loss after processing this batch is:  0.0885559469461441\n",
      "The representation loss after processing this batch is:  0.0027831271290779114\n",
      "\n",
      "The classification loss after processing this batch is:  0.08078442513942719\n",
      "The representation loss after processing this batch is:  0.002329491078853607\n",
      "\n",
      "The classification loss after processing this batch is:  0.09234192967414856\n",
      "The representation loss after processing this batch is:  0.0025035664439201355\n",
      "\n",
      "The classification loss after processing this batch is:  0.11367614567279816\n",
      "The representation loss after processing this batch is:  0.0028600692749023438\n",
      "\n",
      "The classification loss after processing this batch is:  0.12653569877147675\n",
      "The representation loss after processing this batch is:  0.002795100212097168\n",
      "\n",
      "The classification loss after processing this batch is:  0.10623086243867874\n",
      "The representation loss after processing this batch is:  0.0022984519600868225\n",
      "\n",
      "The classification loss after processing this batch is:  0.13311690092086792\n",
      "The representation loss after processing this batch is:  0.0027809441089630127\n",
      "\n",
      "The classification loss after processing this batch is:  0.06419647485017776\n",
      "The representation loss after processing this batch is:  0.0022865459322929382\n",
      "\n",
      "The classification loss after processing this batch is:  0.07169023901224136\n",
      "The representation loss after processing this batch is:  0.002374619245529175\n",
      "\n",
      "The classification loss after processing this batch is:  0.04767929017543793\n",
      "The representation loss after processing this batch is:  0.0027262717485427856\n",
      "\n",
      "The classification loss after processing this batch is:  0.06918379664421082\n",
      "The representation loss after processing this batch is:  0.002491425722837448\n",
      "\n",
      "The classification loss after processing this batch is:  0.04303110018372536\n",
      "The representation loss after processing this batch is:  0.0024453699588775635\n",
      "\n",
      "The classification loss after processing this batch is:  0.04844406619668007\n",
      "The representation loss after processing this batch is:  0.0021884366869926453\n",
      "\n",
      "The classification loss after processing this batch is:  0.04129040613770485\n",
      "The representation loss after processing this batch is:  0.002723380923271179\n",
      "\n",
      "The classification loss after processing this batch is:  0.044889625161886215\n",
      "The representation loss after processing this batch is:  0.0026242733001708984\n",
      "\n",
      "The classification loss after processing this batch is:  0.10441704094409943\n",
      "The representation loss after processing this batch is:  0.0022812560200691223\n",
      "\n",
      "The classification loss after processing this batch is:  0.0629323422908783\n",
      "The representation loss after processing this batch is:  0.0021370984613895416\n",
      "\n",
      "The classification loss after processing this batch is:  0.08102332055568695\n",
      "The representation loss after processing this batch is:  0.0024977102875709534\n",
      "\n",
      "The classification loss after processing this batch is:  0.05231267586350441\n",
      "The representation loss after processing this batch is:  0.00260857492685318\n",
      "\n",
      "The classification loss after processing this batch is:  0.14355379343032837\n",
      "The representation loss after processing this batch is:  0.002435237169265747\n",
      "\n",
      "The classification loss after processing this batch is:  0.1288338303565979\n",
      "The representation loss after processing this batch is:  0.0022517740726470947\n",
      "\n",
      "The classification loss after processing this batch is:  0.10070884227752686\n",
      "The representation loss after processing this batch is:  0.002380058169364929\n",
      "\n",
      "The classification loss after processing this batch is:  0.07139115780591965\n",
      "The representation loss after processing this batch is:  0.0024270042777061462\n",
      "\n",
      "The classification loss after processing this batch is:  0.09202031791210175\n",
      "The representation loss after processing this batch is:  0.0025910958647727966\n",
      "\n",
      "The classification loss after processing this batch is:  0.04524333029985428\n",
      "The representation loss after processing this batch is:  0.0022969618439674377\n",
      "\n",
      "The classification loss after processing this batch is:  0.046278730034828186\n",
      "The representation loss after processing this batch is:  0.002421371638774872\n",
      "\n",
      "The classification loss after processing this batch is:  0.04939647018909454\n",
      "The representation loss after processing this batch is:  0.002407848834991455\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14377646148204803\n",
      "The representation loss after processing this batch is:  0.0023879483342170715\n",
      "\n",
      "The classification loss after processing this batch is:  0.11746253818273544\n",
      "The representation loss after processing this batch is:  0.0022066347301006317\n",
      "\n",
      "The classification loss after processing this batch is:  0.10313379019498825\n",
      "The representation loss after processing this batch is:  0.002742491662502289\n",
      "\n",
      "The classification loss after processing this batch is:  0.1372557133436203\n",
      "The representation loss after processing this batch is:  0.0024171024560928345\n",
      "\n",
      "The classification loss after processing this batch is:  0.12236665189266205\n",
      "The representation loss after processing this batch is:  0.0025695711374282837\n",
      "\n",
      "The classification loss after processing this batch is:  0.1218404620885849\n",
      "The representation loss after processing this batch is:  0.0024011507630348206\n",
      "\n",
      "The classification loss after processing this batch is:  0.21098750829696655\n",
      "The representation loss after processing this batch is:  0.002334773540496826\n",
      "\n",
      "The classification loss after processing this batch is:  0.15956981480121613\n",
      "The representation loss after processing this batch is:  0.0022531189024448395\n",
      "\n",
      "The classification loss after processing this batch is:  0.08127883076667786\n",
      "The representation loss after processing this batch is:  0.002161756157875061\n",
      "\n",
      "The classification loss after processing this batch is:  0.052518486976623535\n",
      "The representation loss after processing this batch is:  0.002392645925283432\n",
      "\n",
      "The classification loss after processing this batch is:  0.05093630775809288\n",
      "The representation loss after processing this batch is:  0.0021587014198303223\n",
      "\n",
      "The classification loss after processing this batch is:  0.041517142206430435\n",
      "The representation loss after processing this batch is:  0.002382837235927582\n",
      "\n",
      "The classification loss after processing this batch is:  0.04804842919111252\n",
      "The representation loss after processing this batch is:  0.0027431026101112366\n",
      "\n",
      "The classification loss after processing this batch is:  0.11057884991168976\n",
      "The representation loss after processing this batch is:  0.002296924591064453\n",
      "\n",
      "The classification loss after processing this batch is:  0.06452663242816925\n",
      "The representation loss after processing this batch is:  0.0024429932236671448\n",
      "\n",
      "The classification loss after processing this batch is:  0.15752533078193665\n",
      "The representation loss after processing this batch is:  0.0023254603147506714\n",
      "\n",
      "The classification loss after processing this batch is:  0.10106193274259567\n",
      "The representation loss after processing this batch is:  0.0025718435645103455\n",
      "\n",
      "The classification loss after processing this batch is:  0.1483476608991623\n",
      "The representation loss after processing this batch is:  0.0021256282925605774\n",
      "\n",
      "The classification loss after processing this batch is:  0.10051468014717102\n",
      "The representation loss after processing this batch is:  0.0022347643971443176\n",
      "\n",
      "The classification loss after processing this batch is:  0.16294445097446442\n",
      "The representation loss after processing this batch is:  0.0021652504801750183\n",
      "\n",
      "The classification loss after processing this batch is:  0.07361796498298645\n",
      "The representation loss after processing this batch is:  0.002157174050807953\n",
      "\n",
      "The classification loss after processing this batch is:  0.08538029342889786\n",
      "The representation loss after processing this batch is:  0.0024930983781814575\n",
      "\n",
      "The classification loss after processing this batch is:  0.12609899044036865\n",
      "The representation loss after processing this batch is:  0.0022745877504348755\n",
      "\n",
      "The classification loss after processing this batch is:  0.043343257158994675\n",
      "The representation loss after processing this batch is:  0.002239648252725601\n",
      "\n",
      "The classification loss after processing this batch is:  0.036667220294475555\n",
      "The representation loss after processing this batch is:  0.0022690147161483765\n",
      "\n",
      "The classification loss after processing this batch is:  0.11697439849376678\n",
      "The representation loss after processing this batch is:  0.002710394561290741\n",
      "\n",
      "The classification loss after processing this batch is:  0.15155090391635895\n",
      "The representation loss after processing this batch is:  0.002316392958164215\n",
      "\n",
      "The classification loss after processing this batch is:  0.10654280334711075\n",
      "The representation loss after processing this batch is:  0.0025698021054267883\n",
      "\n",
      "The classification loss after processing this batch is:  0.051136307418346405\n",
      "The representation loss after processing this batch is:  0.002578228712081909\n",
      "\n",
      "The classification loss after processing this batch is:  0.08062899857759476\n",
      "The representation loss after processing this batch is:  0.0026857107877731323\n",
      "\n",
      "The classification loss after processing this batch is:  0.07338093221187592\n",
      "The representation loss after processing this batch is:  0.002470158040523529\n",
      "\n",
      "The classification loss after processing this batch is:  0.23543331027030945\n",
      "The representation loss after processing this batch is:  0.002468608319759369\n",
      "\n",
      "The classification loss after processing this batch is:  0.06083318218588829\n",
      "The representation loss after processing this batch is:  0.0023288503289222717\n",
      "\n",
      "The classification loss after processing this batch is:  0.03192560002207756\n",
      "The representation loss after processing this batch is:  0.0024216994643211365\n",
      "\n",
      "The classification loss after processing this batch is:  0.11521102488040924\n",
      "The representation loss after processing this batch is:  0.0028259307146072388\n",
      "\n",
      "The classification loss after processing this batch is:  0.09241979569196701\n",
      "The representation loss after processing this batch is:  0.0025556236505508423\n",
      "\n",
      "The classification loss after processing this batch is:  0.05177365988492966\n",
      "The representation loss after processing this batch is:  0.002565130591392517\n",
      "\n",
      "The classification loss after processing this batch is:  0.043245136737823486\n",
      "The representation loss after processing this batch is:  0.002161223441362381\n",
      "\n",
      "The classification loss after processing this batch is:  0.08822716772556305\n",
      "The representation loss after processing this batch is:  0.0029267892241477966\n",
      "\n",
      "The classification loss after processing this batch is:  0.13651128113269806\n",
      "The representation loss after processing this batch is:  0.002691395580768585\n",
      "\n",
      "The classification loss after processing this batch is:  0.19066676497459412\n",
      "The representation loss after processing this batch is:  0.00220547616481781\n",
      "\n",
      "The classification loss after processing this batch is:  0.141413152217865\n",
      "The representation loss after processing this batch is:  0.0025642141699790955\n",
      "\n",
      "The classification loss after processing this batch is:  0.04114201292395592\n",
      "The representation loss after processing this batch is:  0.0025069639086723328\n",
      "\n",
      "The classification loss after processing this batch is:  0.049105770885944366\n",
      "The representation loss after processing this batch is:  0.0021305643022060394\n",
      "\n",
      "The classification loss after processing this batch is:  0.1069008931517601\n",
      "The representation loss after processing this batch is:  0.002495020627975464\n",
      "\n",
      "The classification loss after processing this batch is:  0.15048544108867645\n",
      "The representation loss after processing this batch is:  0.002559185028076172\n",
      "\n",
      "The classification loss after processing this batch is:  0.16935332119464874\n",
      "The representation loss after processing this batch is:  0.0027488023042678833\n",
      "\n",
      "The classification loss after processing this batch is:  0.18512922525405884\n",
      "The representation loss after processing this batch is:  0.0022058114409446716\n",
      "\n",
      "The classification loss after processing this batch is:  0.08571259677410126\n",
      "The representation loss after processing this batch is:  0.0022220611572265625\n",
      "\n",
      "The classification loss after processing this batch is:  0.1506897360086441\n",
      "The representation loss after processing this batch is:  0.0021914616227149963\n",
      "\n",
      "The classification loss after processing this batch is:  0.06935133039951324\n",
      "The representation loss after processing this batch is:  0.0020975694060325623\n",
      "\n",
      "The classification loss after processing this batch is:  0.07481624186038971\n",
      "The representation loss after processing this batch is:  0.002414792776107788\n",
      "\n",
      "The classification loss after processing this batch is:  0.03923257067799568\n",
      "The representation loss after processing this batch is:  0.002323068678379059\n",
      "\n",
      "The classification loss after processing this batch is:  0.10889880359172821\n",
      "The representation loss after processing this batch is:  0.002359911799430847\n",
      "\n",
      "The classification loss after processing this batch is:  0.10106714069843292\n",
      "The representation loss after processing this batch is:  0.002215176820755005\n",
      "\n",
      "The classification loss after processing this batch is:  0.07101897895336151\n",
      "The representation loss after processing this batch is:  0.002376507967710495\n",
      "\n",
      "The classification loss after processing this batch is:  0.1442088931798935\n",
      "The representation loss after processing this batch is:  0.002566136419773102\n",
      "\n",
      "The classification loss after processing this batch is:  0.033966049551963806\n",
      "The representation loss after processing this batch is:  0.002608567476272583\n",
      "\n",
      "The classification loss after processing this batch is:  0.0827488973736763\n",
      "The representation loss after processing this batch is:  0.002604268491268158\n",
      "\n",
      "The classification loss after processing this batch is:  0.08558820933103561\n",
      "The representation loss after processing this batch is:  0.002279624342918396\n",
      "\n",
      "The classification loss after processing this batch is:  0.1581144630908966\n",
      "The representation loss after processing this batch is:  0.002545151859521866\n",
      "\n",
      "The classification loss after processing this batch is:  0.04356970638036728\n",
      "The representation loss after processing this batch is:  0.002932317554950714\n",
      "\n",
      "The classification loss after processing this batch is:  0.0713157132267952\n",
      "The representation loss after processing this batch is:  0.002136494964361191\n",
      "\n",
      "The classification loss after processing this batch is:  0.14744284749031067\n",
      "The representation loss after processing this batch is:  0.0025581270456314087\n",
      "\n",
      "The classification loss after processing this batch is:  0.09462276101112366\n",
      "The representation loss after processing this batch is:  0.00224100798368454\n",
      "\n",
      "The classification loss after processing this batch is:  0.13534393906593323\n",
      "The representation loss after processing this batch is:  0.002250976860523224\n",
      "\n",
      "The classification loss after processing this batch is:  0.10018912702798843\n",
      "The representation loss after processing this batch is:  0.0022394172847270966\n",
      "\n",
      "The classification loss after processing this batch is:  0.05508469045162201\n",
      "The representation loss after processing this batch is:  0.0024373456835746765\n",
      "\n",
      "The classification loss after processing this batch is:  0.13110478222370148\n",
      "The representation loss after processing this batch is:  0.001971714198589325\n",
      "\n",
      "The classification loss after processing this batch is:  0.0897020548582077\n",
      "The representation loss after processing this batch is:  0.002447664737701416\n",
      "\n",
      "The classification loss after processing this batch is:  0.10688471794128418\n",
      "The representation loss after processing this batch is:  0.002384379506111145\n",
      "\n",
      "The classification loss after processing this batch is:  0.10009888559579849\n",
      "The representation loss after processing this batch is:  0.0029273703694343567\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.04690622538328171\n",
      "The representation loss after processing this batch is:  0.002432890236377716\n",
      "\n",
      "The classification loss after processing this batch is:  0.1194181963801384\n",
      "The representation loss after processing this batch is:  0.002347297966480255\n",
      "\n",
      "The classification loss after processing this batch is:  0.13452476263046265\n",
      "The representation loss after processing this batch is:  0.002588711678981781\n",
      "\n",
      "The classification loss after processing this batch is:  0.031741444021463394\n",
      "The representation loss after processing this batch is:  0.002494595944881439\n",
      "\n",
      "The classification loss after processing this batch is:  0.07580020278692245\n",
      "The representation loss after processing this batch is:  0.002106688916683197\n",
      "\n",
      "The classification loss after processing this batch is:  0.13715091347694397\n",
      "The representation loss after processing this batch is:  0.0022245198488235474\n",
      "\n",
      "The classification loss after processing this batch is:  0.13919585943222046\n",
      "The representation loss after processing this batch is:  0.0024634897708892822\n",
      "\n",
      "The classification loss after processing this batch is:  0.09596607089042664\n",
      "The representation loss after processing this batch is:  0.002321377396583557\n",
      "\n",
      "The classification loss after processing this batch is:  0.14046911895275116\n",
      "The representation loss after processing this batch is:  0.002395614981651306\n",
      "\n",
      "The classification loss after processing this batch is:  0.10762140899896622\n",
      "The representation loss after processing this batch is:  0.0024270862340927124\n",
      "\n",
      "The classification loss after processing this batch is:  0.1604182869195938\n",
      "The representation loss after processing this batch is:  0.0024770572781562805\n",
      "\n",
      "The classification loss after processing this batch is:  0.0673835277557373\n",
      "The representation loss after processing this batch is:  0.002538539469242096\n",
      "\n",
      "The classification loss after processing this batch is:  0.1485745906829834\n",
      "The representation loss after processing this batch is:  0.0023336261510849\n",
      "\n",
      "The classification loss after processing this batch is:  0.09215191006660461\n",
      "The representation loss after processing this batch is:  0.003197610378265381\n",
      "\n",
      "The classification loss after processing this batch is:  0.0471915602684021\n",
      "The representation loss after processing this batch is:  0.0024190396070480347\n",
      "\n",
      "The classification loss after processing this batch is:  0.06958531588315964\n",
      "The representation loss after processing this batch is:  0.002374619245529175\n",
      "\n",
      "The classification loss after processing this batch is:  0.07302559912204742\n",
      "The representation loss after processing this batch is:  0.0022310130298137665\n",
      "\n",
      "The classification loss after processing this batch is:  0.09375608712434769\n",
      "The representation loss after processing this batch is:  0.002421937882900238\n",
      "\n",
      "The classification loss after processing this batch is:  0.07579679042100906\n",
      "The representation loss after processing this batch is:  0.0023415982723236084\n",
      "\n",
      "The classification loss after processing this batch is:  0.15168508887290955\n",
      "The representation loss after processing this batch is:  0.0024280138313770294\n",
      "\n",
      "The classification loss after processing this batch is:  0.03570980951189995\n",
      "The representation loss after processing this batch is:  0.0023813024163246155\n",
      "\n",
      "The classification loss after processing this batch is:  0.05025189742445946\n",
      "The representation loss after processing this batch is:  0.002645745873451233\n",
      "\n",
      "The classification loss after processing this batch is:  0.1459030658006668\n",
      "The representation loss after processing this batch is:  0.002625696361064911\n",
      "\n",
      "The classification loss after processing this batch is:  0.024564504623413086\n",
      "The representation loss after processing this batch is:  0.0022984370589256287\n",
      "\n",
      "The classification loss after processing this batch is:  0.063371941447258\n",
      "The representation loss after processing this batch is:  0.0023231804370880127\n",
      "\n",
      "The classification loss after processing this batch is:  0.04128779470920563\n",
      "The representation loss after processing this batch is:  0.002519451081752777\n",
      "\n",
      "The classification loss after processing this batch is:  0.09079618752002716\n",
      "The representation loss after processing this batch is:  0.0022738873958587646\n",
      "\n",
      "The classification loss after processing this batch is:  0.1413871794939041\n",
      "The representation loss after processing this batch is:  0.0027912333607673645\n",
      "\n",
      "The classification loss after processing this batch is:  0.1337839961051941\n",
      "The representation loss after processing this batch is:  0.0034921765327453613\n",
      "\n",
      "The classification loss after processing this batch is:  0.12407883256673813\n",
      "The representation loss after processing this batch is:  0.0030554533004760742\n",
      "\n",
      "The classification loss after processing this batch is:  0.05573706701397896\n",
      "The representation loss after processing this batch is:  0.002648293972015381\n",
      "\n",
      "The classification loss after processing this batch is:  0.10012423247098923\n",
      "The representation loss after processing this batch is:  0.0022609271109104156\n",
      "\n",
      "The classification loss after processing this batch is:  0.11309095472097397\n",
      "The representation loss after processing this batch is:  0.0024585649371147156\n",
      "\n",
      "The classification loss after processing this batch is:  0.04607716575264931\n",
      "The representation loss after processing this batch is:  0.0026380345225334167\n",
      "\n",
      "The classification loss after processing this batch is:  0.04147213324904442\n",
      "The representation loss after processing this batch is:  0.00221807137131691\n",
      "\n",
      "The classification loss after processing this batch is:  0.03419991955161095\n",
      "The representation loss after processing this batch is:  0.002671577036380768\n",
      "\n",
      "The classification loss after processing this batch is:  0.07151541113853455\n",
      "The representation loss after processing this batch is:  0.002705845981836319\n",
      "\n",
      "The classification loss after processing this batch is:  0.15909597277641296\n",
      "The representation loss after processing this batch is:  0.002621598541736603\n",
      "\n",
      "The classification loss after processing this batch is:  0.12287203967571259\n",
      "The representation loss after processing this batch is:  0.0023688077926635742\n",
      "\n",
      "The classification loss after processing this batch is:  0.11171295493841171\n",
      "The representation loss after processing this batch is:  0.0029871463775634766\n",
      "\n",
      "The classification loss after processing this batch is:  0.07706877589225769\n",
      "The representation loss after processing this batch is:  0.0029029175639152527\n",
      "\n",
      "The classification loss after processing this batch is:  0.11011314392089844\n",
      "The representation loss after processing this batch is:  0.0025258995592594147\n",
      "\n",
      "The classification loss after processing this batch is:  0.06035546958446503\n",
      "The representation loss after processing this batch is:  0.0023343637585639954\n",
      "\n",
      "The classification loss after processing this batch is:  0.3164406716823578\n",
      "The representation loss after processing this batch is:  0.0026480481028556824\n",
      "\n",
      "The classification loss after processing this batch is:  0.0776582732796669\n",
      "The representation loss after processing this batch is:  0.0027402862906455994\n",
      "\n",
      "The classification loss after processing this batch is:  0.21115893125534058\n",
      "The representation loss after processing this batch is:  0.0031036362051963806\n",
      "\n",
      "The classification loss after processing this batch is:  0.08938676863908768\n",
      "The representation loss after processing this batch is:  0.0022183209657669067\n",
      "\n",
      "The classification loss after processing this batch is:  0.099062480032444\n",
      "The representation loss after processing this batch is:  0.002397783100605011\n",
      "\n",
      "The classification loss after processing this batch is:  0.14912919700145721\n",
      "The representation loss after processing this batch is:  0.0022827014327049255\n",
      "\n",
      "The classification loss after processing this batch is:  0.08782251924276352\n",
      "The representation loss after processing this batch is:  0.0024325810372829437\n",
      "\n",
      "The classification loss after processing this batch is:  0.16290982067584991\n",
      "The representation loss after processing this batch is:  0.0025714263319969177\n",
      "\n",
      "The classification loss after processing this batch is:  0.10488882660865784\n",
      "The representation loss after processing this batch is:  0.0027587786316871643\n",
      "\n",
      "The classification loss after processing this batch is:  0.11948922276496887\n",
      "The representation loss after processing this batch is:  0.0029494985938072205\n",
      "\n",
      "The classification loss after processing this batch is:  0.14769330620765686\n",
      "The representation loss after processing this batch is:  0.0026784315705299377\n",
      "\n",
      "The classification loss after processing this batch is:  0.029910854995250702\n",
      "The representation loss after processing this batch is:  0.0024747103452682495\n",
      "\n",
      "The classification loss after processing this batch is:  0.10348875820636749\n",
      "The representation loss after processing this batch is:  0.0021557435393333435\n",
      "\n",
      "The classification loss after processing this batch is:  0.10182811319828033\n",
      "The representation loss after processing this batch is:  0.0022248178720474243\n",
      "\n",
      "The classification loss after processing this batch is:  0.038516148924827576\n",
      "The representation loss after processing this batch is:  0.0025117844343185425\n",
      "\n",
      "The classification loss after processing this batch is:  0.1299779862165451\n",
      "The representation loss after processing this batch is:  0.0022611021995544434\n",
      "\n",
      "The classification loss after processing this batch is:  0.22196409106254578\n",
      "The representation loss after processing this batch is:  0.0024873390793800354\n",
      "\n",
      "The classification loss after processing this batch is:  0.09274038672447205\n",
      "The representation loss after processing this batch is:  0.0020084381103515625\n",
      "\n",
      "The classification loss after processing this batch is:  0.06585218757390976\n",
      "The representation loss after processing this batch is:  0.0025389157235622406\n",
      "\n",
      "The classification loss after processing this batch is:  0.08214391767978668\n",
      "The representation loss after processing this batch is:  0.002307675778865814\n",
      "\n",
      "The classification loss after processing this batch is:  0.07038423418998718\n",
      "The representation loss after processing this batch is:  0.0024543553590774536\n",
      "\n",
      "The classification loss after processing this batch is:  0.08360908180475235\n",
      "The representation loss after processing this batch is:  0.0027370303869247437\n",
      "\n",
      "The classification loss after processing this batch is:  0.04940474033355713\n",
      "The representation loss after processing this batch is:  0.0026118382811546326\n",
      "\n",
      "The classification loss after processing this batch is:  0.10625756531953812\n",
      "The representation loss after processing this batch is:  0.0022639036178588867\n",
      "\n",
      "The classification loss after processing this batch is:  0.11899575591087341\n",
      "The representation loss after processing this batch is:  0.002179037779569626\n",
      "\n",
      "The classification loss after processing this batch is:  0.060173891484737396\n",
      "The representation loss after processing this batch is:  0.002516545355319977\n",
      "\n",
      "The classification loss after processing this batch is:  0.1345231533050537\n",
      "The representation loss after processing this batch is:  0.0021205805242061615\n",
      "\n",
      "The classification loss after processing this batch is:  0.10901226103305817\n",
      "The representation loss after processing this batch is:  0.0021329298615455627\n",
      "\n",
      "The classification loss after processing this batch is:  0.06268728524446487\n",
      "The representation loss after processing this batch is:  0.0024255216121673584\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.05645019933581352\n",
      "The representation loss after processing this batch is:  0.0024130791425704956\n",
      "\n",
      "The classification loss after processing this batch is:  0.10638224333524704\n",
      "The representation loss after processing this batch is:  0.0023562833666801453\n",
      "\n",
      "The classification loss after processing this batch is:  0.045774124562740326\n",
      "The representation loss after processing this batch is:  0.0024598613381385803\n",
      "\n",
      "The classification loss after processing this batch is:  0.31605011224746704\n",
      "The representation loss after processing this batch is:  0.0021910332143306732\n",
      "\n",
      "The classification loss after processing this batch is:  0.08814103156328201\n",
      "The representation loss after processing this batch is:  0.002601310610771179\n",
      "\n",
      "The classification loss after processing this batch is:  0.15338115394115448\n",
      "The representation loss after processing this batch is:  0.0022157058119773865\n",
      "\n",
      "The classification loss after processing this batch is:  0.06115157902240753\n",
      "The representation loss after processing this batch is:  0.002083025872707367\n",
      "\n",
      "The classification loss after processing this batch is:  0.09361357986927032\n",
      "The representation loss after processing this batch is:  0.002363920211791992\n",
      "\n",
      "The classification loss after processing this batch is:  0.05813764035701752\n",
      "The representation loss after processing this batch is:  0.0021281950175762177\n",
      "\n",
      "The classification loss after processing this batch is:  0.07261396199464798\n",
      "The representation loss after processing this batch is:  0.0022507794201374054\n",
      "\n",
      "The classification loss after processing this batch is:  0.1486264020204544\n",
      "The representation loss after processing this batch is:  0.0023198314011096954\n",
      "\n",
      "The classification loss after processing this batch is:  0.09901739656925201\n",
      "The representation loss after processing this batch is:  0.0029691755771636963\n",
      "\n",
      "The classification loss after processing this batch is:  0.13132239878177643\n",
      "The representation loss after processing this batch is:  0.0024453438818454742\n",
      "\n",
      "The classification loss after processing this batch is:  0.07728099822998047\n",
      "The representation loss after processing this batch is:  0.0024807751178741455\n",
      "\n",
      "The classification loss after processing this batch is:  0.13222388923168182\n",
      "The representation loss after processing this batch is:  0.0026225969195365906\n",
      "\n",
      "The classification loss after processing this batch is:  0.1382541060447693\n",
      "The representation loss after processing this batch is:  0.002509675920009613\n",
      "\n",
      "The classification loss after processing this batch is:  0.15825846791267395\n",
      "The representation loss after processing this batch is:  0.0023659467697143555\n",
      "\n",
      "The classification loss after processing this batch is:  0.0673605278134346\n",
      "The representation loss after processing this batch is:  0.002469107508659363\n",
      "\n",
      "The classification loss after processing this batch is:  0.07627318799495697\n",
      "The representation loss after processing this batch is:  0.002840466797351837\n",
      "\n",
      "The classification loss after processing this batch is:  0.037459276616573334\n",
      "The representation loss after processing this batch is:  0.002469036728143692\n",
      "\n",
      "The classification loss after processing this batch is:  0.15360933542251587\n",
      "The representation loss after processing this batch is:  0.002254374325275421\n",
      "\n",
      "The classification loss after processing this batch is:  0.19667650759220123\n",
      "The representation loss after processing this batch is:  0.002458658069372177\n",
      "\n",
      "The classification loss after processing this batch is:  0.07847288995981216\n",
      "The representation loss after processing this batch is:  0.00289202481508255\n",
      "\n",
      "The classification loss after processing this batch is:  0.1249779686331749\n",
      "The representation loss after processing this batch is:  0.002738252282142639\n",
      "\n",
      "The classification loss after processing this batch is:  0.13501249253749847\n",
      "The representation loss after processing this batch is:  0.002334579825401306\n",
      "\n",
      "The classification loss after processing this batch is:  0.15254344046115875\n",
      "The representation loss after processing this batch is:  0.0025906935334205627\n",
      "\n",
      "The classification loss after processing this batch is:  0.035978980362415314\n",
      "The representation loss after processing this batch is:  0.0022824443876743317\n",
      "\n",
      "The classification loss after processing this batch is:  0.11426853388547897\n",
      "The representation loss after processing this batch is:  0.002526119351387024\n",
      "\n",
      "The classification loss after processing this batch is:  0.12880252301692963\n",
      "The representation loss after processing this batch is:  0.002496875822544098\n",
      "\n",
      "The classification loss after processing this batch is:  0.07373356819152832\n",
      "The representation loss after processing this batch is:  0.0024918057024478912\n",
      "\n",
      "The classification loss after processing this batch is:  0.036411769688129425\n",
      "The representation loss after processing this batch is:  0.0027521178126335144\n",
      "\n",
      "The classification loss after processing this batch is:  0.07267918437719345\n",
      "The representation loss after processing this batch is:  0.002422623336315155\n",
      "\n",
      "The classification loss after processing this batch is:  0.07990037649869919\n",
      "The representation loss after processing this batch is:  0.0026555508375167847\n",
      "\n",
      "The classification loss after processing this batch is:  0.08678028732538223\n",
      "The representation loss after processing this batch is:  0.002235502004623413\n",
      "\n",
      "The classification loss after processing this batch is:  0.16324563324451447\n",
      "The representation loss after processing this batch is:  0.002490624785423279\n",
      "\n",
      "The classification loss after processing this batch is:  0.1127011626958847\n",
      "The representation loss after processing this batch is:  0.002193894237279892\n",
      "\n",
      "The classification loss after processing this batch is:  0.09191670268774033\n",
      "The representation loss after processing this batch is:  0.0027100853621959686\n",
      "\n",
      "The classification loss after processing this batch is:  0.1449587643146515\n",
      "The representation loss after processing this batch is:  0.0027142390608787537\n",
      "\n",
      "The classification loss after processing this batch is:  0.08976259082555771\n",
      "The representation loss after processing this batch is:  0.002827361226081848\n",
      "\n",
      "The classification loss after processing this batch is:  0.07568954676389694\n",
      "The representation loss after processing this batch is:  0.0023152977228164673\n",
      "\n",
      "The classification loss after processing this batch is:  0.1431165486574173\n",
      "The representation loss after processing this batch is:  0.002423115074634552\n",
      "\n",
      "The classification loss after processing this batch is:  0.1595025509595871\n",
      "The representation loss after processing this batch is:  0.0030990466475486755\n",
      "\n",
      "The classification loss after processing this batch is:  0.11523278057575226\n",
      "The representation loss after processing this batch is:  0.0025671347975730896\n",
      "\n",
      "The classification loss after processing this batch is:  0.05354510247707367\n",
      "The representation loss after processing this batch is:  0.002548161894083023\n",
      "\n",
      "The classification loss after processing this batch is:  0.06874454021453857\n",
      "The representation loss after processing this batch is:  0.002221226692199707\n",
      "\n",
      "The classification loss after processing this batch is:  0.05129203945398331\n",
      "The representation loss after processing this batch is:  0.0025460198521614075\n",
      "\n",
      "The classification loss after processing this batch is:  0.10461435467004776\n",
      "The representation loss after processing this batch is:  0.0023950524628162384\n",
      "\n",
      "The classification loss after processing this batch is:  0.19855579733848572\n",
      "The representation loss after processing this batch is:  0.0022015757858753204\n",
      "\n",
      "The classification loss after processing this batch is:  0.23813432455062866\n",
      "The representation loss after processing this batch is:  0.0027507618069648743\n",
      "\n",
      "The classification loss after processing this batch is:  0.12263808399438858\n",
      "The representation loss after processing this batch is:  0.0021320804953575134\n",
      "\n",
      "The classification loss after processing this batch is:  0.1117430105805397\n",
      "The representation loss after processing this batch is:  0.0022493302822113037\n",
      "\n",
      "The classification loss after processing this batch is:  0.0777214914560318\n",
      "The representation loss after processing this batch is:  0.0025652386248111725\n",
      "\n",
      "The classification loss after processing this batch is:  0.10760784894227982\n",
      "The representation loss after processing this batch is:  0.0023313388228416443\n",
      "\n",
      "The classification loss after processing this batch is:  0.20503026247024536\n",
      "The representation loss after processing this batch is:  0.0026096701622009277\n",
      "\n",
      "The classification loss after processing this batch is:  0.1360979825258255\n",
      "The representation loss after processing this batch is:  0.0022102147340774536\n",
      "\n",
      "The classification loss after processing this batch is:  0.28653427958488464\n",
      "The representation loss after processing this batch is:  0.002442173659801483\n",
      "\n",
      "The classification loss after processing this batch is:  0.1405867487192154\n",
      "The representation loss after processing this batch is:  0.0025502219796180725\n",
      "\n",
      "The classification loss after processing this batch is:  0.0477667860686779\n",
      "The representation loss after processing this batch is:  0.0027878955006599426\n",
      "\n",
      "The classification loss after processing this batch is:  0.12063141167163849\n",
      "The representation loss after processing this batch is:  0.0024072714149951935\n",
      "\n",
      "The classification loss after processing this batch is:  0.11497785151004791\n",
      "The representation loss after processing this batch is:  0.0022131092846393585\n",
      "\n",
      "The classification loss after processing this batch is:  0.1503347009420395\n",
      "The representation loss after processing this batch is:  0.0025489479303359985\n",
      "\n",
      "The classification loss after processing this batch is:  0.08657380938529968\n",
      "The representation loss after processing this batch is:  0.0021582022309303284\n",
      "\n",
      "The classification loss after processing this batch is:  0.13810093700885773\n",
      "The representation loss after processing this batch is:  0.0021770894527435303\n",
      "\n",
      "The classification loss after processing this batch is:  0.08566716313362122\n",
      "The representation loss after processing this batch is:  0.0024125799536705017\n",
      "\n",
      "The classification loss after processing this batch is:  0.11674647778272629\n",
      "The representation loss after processing this batch is:  0.002324353903532028\n",
      "\n",
      "The classification loss after processing this batch is:  0.15518712997436523\n",
      "The representation loss after processing this batch is:  0.0023626387119293213\n",
      "\n",
      "The classification loss after processing this batch is:  0.18655754625797272\n",
      "The representation loss after processing this batch is:  0.0024406462907791138\n",
      "\n",
      "The classification loss after processing this batch is:  0.1098911315202713\n",
      "The representation loss after processing this batch is:  0.0023193061351776123\n",
      "\n",
      "The classification loss after processing this batch is:  0.03520827367901802\n",
      "The representation loss after processing this batch is:  0.002864755690097809\n",
      "\n",
      "The classification loss after processing this batch is:  0.015904566273093224\n",
      "The representation loss after processing this batch is:  0.0025080591440200806\n",
      "\n",
      "The classification loss after processing this batch is:  0.09670044481754303\n",
      "The representation loss after processing this batch is:  0.002669423818588257\n",
      "\n",
      "The classification loss after processing this batch is:  0.08945982903242111\n",
      "The representation loss after processing this batch is:  0.003819964826107025\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14677737653255463\n",
      "The representation loss after processing this batch is:  0.0025527626276016235\n",
      "\n",
      "The classification loss after processing this batch is:  0.1105736568570137\n",
      "The representation loss after processing this batch is:  0.002670295536518097\n",
      "\n",
      "The classification loss after processing this batch is:  0.12809094786643982\n",
      "The representation loss after processing this batch is:  0.002399437129497528\n",
      "\n",
      "The classification loss after processing this batch is:  0.04579189792275429\n",
      "The representation loss after processing this batch is:  0.0026178881525993347\n",
      "\n",
      "The classification loss after processing this batch is:  0.09847581386566162\n",
      "The representation loss after processing this batch is:  0.0025242939591407776\n",
      "\n",
      "The classification loss after processing this batch is:  0.08481405675411224\n",
      "The representation loss after processing this batch is:  0.0025998204946517944\n",
      "\n",
      "The classification loss after processing this batch is:  0.13762839138507843\n",
      "The representation loss after processing this batch is:  0.0026012957096099854\n",
      "\n",
      "The classification loss after processing this batch is:  0.05924586206674576\n",
      "The representation loss after processing this batch is:  0.0023534148931503296\n",
      "\n",
      "The classification loss after processing this batch is:  0.055503930896520615\n",
      "The representation loss after processing this batch is:  0.0019613318145275116\n",
      "\n",
      "The classification loss after processing this batch is:  0.11479542404413223\n",
      "The representation loss after processing this batch is:  0.0022420287132263184\n",
      "\n",
      "The classification loss after processing this batch is:  0.10991646349430084\n",
      "The representation loss after processing this batch is:  0.002371571958065033\n",
      "\n",
      "The classification loss after processing this batch is:  0.09410075098276138\n",
      "The representation loss after processing this batch is:  0.0021735280752182007\n",
      "\n",
      "The classification loss after processing this batch is:  0.14789550006389618\n",
      "The representation loss after processing this batch is:  0.0025932788848876953\n",
      "\n",
      "The classification loss after processing this batch is:  0.08355986326932907\n",
      "The representation loss after processing this batch is:  0.002439640462398529\n",
      "\n",
      "The classification loss after processing this batch is:  0.021423690021038055\n",
      "The representation loss after processing this batch is:  0.0022598356008529663\n",
      "\n",
      "The classification loss after processing this batch is:  0.04739006236195564\n",
      "The representation loss after processing this batch is:  0.0027259662747383118\n",
      "\n",
      "The classification loss after processing this batch is:  0.026807108893990517\n",
      "The representation loss after processing this batch is:  0.002656280994415283\n",
      "\n",
      "The classification loss after processing this batch is:  0.08048036694526672\n",
      "The representation loss after processing this batch is:  0.0025615692138671875\n",
      "\n",
      "The classification loss after processing this batch is:  0.046040233224630356\n",
      "The representation loss after processing this batch is:  0.0024347007274627686\n",
      "\n",
      "The classification loss after processing this batch is:  0.043728191405534744\n",
      "The representation loss after processing this batch is:  0.002347029745578766\n",
      "\n",
      "The classification loss after processing this batch is:  0.08277254551649094\n",
      "The representation loss after processing this batch is:  0.0026912763714790344\n",
      "\n",
      "The classification loss after processing this batch is:  0.08142515271902084\n",
      "The representation loss after processing this batch is:  0.002530030906200409\n",
      "\n",
      "The classification loss after processing this batch is:  0.03750837221741676\n",
      "The representation loss after processing this batch is:  0.0022496432065963745\n",
      "\n",
      "The classification loss after processing this batch is:  0.03349824622273445\n",
      "The representation loss after processing this batch is:  0.0022783055901527405\n",
      "\n",
      "The classification loss after processing this batch is:  0.03829294070601463\n",
      "The representation loss after processing this batch is:  0.0025115013122558594\n",
      "\n",
      "The classification loss after processing this batch is:  0.02578229084610939\n",
      "The representation loss after processing this batch is:  0.0025251880288124084\n",
      "\n",
      "The classification loss after processing this batch is:  0.11456167697906494\n",
      "The representation loss after processing this batch is:  0.0024159252643585205\n",
      "\n",
      "The classification loss after processing this batch is:  0.10611207783222198\n",
      "The representation loss after processing this batch is:  0.0025474652647972107\n",
      "\n",
      "The classification loss after processing this batch is:  0.03718509525060654\n",
      "The representation loss after processing this batch is:  0.002342730760574341\n",
      "\n",
      "The classification loss after processing this batch is:  0.12378863990306854\n",
      "The representation loss after processing this batch is:  0.0024291202425956726\n",
      "\n",
      "The classification loss after processing this batch is:  0.04455893859267235\n",
      "The representation loss after processing this batch is:  0.00221455842256546\n",
      "\n",
      "The classification loss after processing this batch is:  0.12430773675441742\n",
      "The representation loss after processing this batch is:  0.002343650907278061\n",
      "\n",
      "The classification loss after processing this batch is:  0.14920397102832794\n",
      "The representation loss after processing this batch is:  0.0026503391563892365\n",
      "\n",
      "The classification loss after processing this batch is:  0.06600375473499298\n",
      "The representation loss after processing this batch is:  0.0025906190276145935\n",
      "\n",
      "The classification loss after processing this batch is:  0.1471298187971115\n",
      "The representation loss after processing this batch is:  0.0022461414337158203\n",
      "\n",
      "The classification loss after processing this batch is:  0.11986446380615234\n",
      "The representation loss after processing this batch is:  0.002224966883659363\n",
      "\n",
      "The classification loss after processing this batch is:  0.1393822580575943\n",
      "The representation loss after processing this batch is:  0.0022760704159736633\n",
      "\n",
      "The classification loss after processing this batch is:  0.1050056591629982\n",
      "The representation loss after processing this batch is:  0.002252921462059021\n",
      "\n",
      "The classification loss after processing this batch is:  0.060947611927986145\n",
      "The representation loss after processing this batch is:  0.0025791525840759277\n",
      "\n",
      "The classification loss after processing this batch is:  0.09122398495674133\n",
      "The representation loss after processing this batch is:  0.0020801275968551636\n",
      "\n",
      "The classification loss after processing this batch is:  0.1015230193734169\n",
      "The representation loss after processing this batch is:  0.0026528239250183105\n",
      "\n",
      "The classification loss after processing this batch is:  0.13299186527729034\n",
      "The representation loss after processing this batch is:  0.0025006532669067383\n",
      "\n",
      "The classification loss after processing this batch is:  0.1034589484333992\n",
      "The representation loss after processing this batch is:  0.002329103648662567\n",
      "\n",
      "The classification loss after processing this batch is:  0.05588361993432045\n",
      "The representation loss after processing this batch is:  0.002333246171474457\n",
      "\n",
      "The classification loss after processing this batch is:  0.08067988604307175\n",
      "The representation loss after processing this batch is:  0.0022519677877426147\n",
      "\n",
      "The classification loss after processing this batch is:  0.17938193678855896\n",
      "The representation loss after processing this batch is:  0.0021700747311115265\n",
      "\n",
      "The classification loss after processing this batch is:  0.06948044896125793\n",
      "The representation loss after processing this batch is:  0.00238761305809021\n",
      "\n",
      "The classification loss after processing this batch is:  0.10500764101743698\n",
      "The representation loss after processing this batch is:  0.002268455922603607\n",
      "\n",
      "The classification loss after processing this batch is:  0.08147989958524704\n",
      "The representation loss after processing this batch is:  0.0021303072571754456\n",
      "\n",
      "The classification loss after processing this batch is:  0.07213813811540604\n",
      "The representation loss after processing this batch is:  0.0027305930852890015\n",
      "\n",
      "The classification loss after processing this batch is:  0.04000195115804672\n",
      "The representation loss after processing this batch is:  0.0027061477303504944\n",
      "\n",
      "The classification loss after processing this batch is:  0.08210017532110214\n",
      "The representation loss after processing this batch is:  0.0026684999465942383\n",
      "\n",
      "The classification loss after processing this batch is:  0.09586859494447708\n",
      "The representation loss after processing this batch is:  0.0024168528616428375\n",
      "\n",
      "The classification loss after processing this batch is:  0.07513441145420074\n",
      "The representation loss after processing this batch is:  0.0022913366556167603\n",
      "\n",
      "The classification loss after processing this batch is:  0.13638406991958618\n",
      "The representation loss after processing this batch is:  0.002587921917438507\n",
      "\n",
      "The classification loss after processing this batch is:  0.1271587312221527\n",
      "The representation loss after processing this batch is:  0.002514362335205078\n",
      "\n",
      "The classification loss after processing this batch is:  0.1294293999671936\n",
      "The representation loss after processing this batch is:  0.0021047070622444153\n",
      "\n",
      "The classification loss after processing this batch is:  0.12969885766506195\n",
      "The representation loss after processing this batch is:  0.00283098965883255\n",
      "\n",
      "The classification loss after processing this batch is:  0.04503489285707474\n",
      "The representation loss after processing this batch is:  0.002581484615802765\n",
      "\n",
      "The classification loss after processing this batch is:  0.03427797183394432\n",
      "The representation loss after processing this batch is:  0.0023406147956848145\n",
      "\n",
      "The classification loss after processing this batch is:  0.07068798691034317\n",
      "The representation loss after processing this batch is:  0.0025276243686676025\n",
      "\n",
      "The classification loss after processing this batch is:  0.09422001242637634\n",
      "The representation loss after processing this batch is:  0.0024152621626853943\n",
      "\n",
      "The classification loss after processing this batch is:  0.08428093791007996\n",
      "The representation loss after processing this batch is:  0.002241171896457672\n",
      "\n",
      "The classification loss after processing this batch is:  0.0877414420247078\n",
      "The representation loss after processing this batch is:  0.002506650984287262\n",
      "\n",
      "The classification loss after processing this batch is:  0.0982300341129303\n",
      "The representation loss after processing this batch is:  0.0028132274746894836\n",
      "\n",
      "The classification loss after processing this batch is:  0.11602278053760529\n",
      "The representation loss after processing this batch is:  0.002608977258205414\n",
      "\n",
      "The classification loss after processing this batch is:  0.15195980668067932\n",
      "The representation loss after processing this batch is:  0.002351902425289154\n",
      "\n",
      "The classification loss after processing this batch is:  0.12972894310951233\n",
      "The representation loss after processing this batch is:  0.0024217069149017334\n",
      "\n",
      "The classification loss after processing this batch is:  0.1242305263876915\n",
      "The representation loss after processing this batch is:  0.00223657488822937\n",
      "\n",
      "The classification loss after processing this batch is:  0.0561705082654953\n",
      "The representation loss after processing this batch is:  0.0026580095291137695\n",
      "\n",
      "The classification loss after processing this batch is:  0.03344743326306343\n",
      "The representation loss after processing this batch is:  0.0025627389550209045\n",
      "\n",
      "The classification loss after processing this batch is:  0.11011373996734619\n",
      "The representation loss after processing this batch is:  0.0021568648517131805\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1660175323486328\n",
      "The representation loss after processing this batch is:  0.0022422149777412415\n",
      "\n",
      "The classification loss after processing this batch is:  0.12245211750268936\n",
      "The representation loss after processing this batch is:  0.002407260239124298\n",
      "\n",
      "The classification loss after processing this batch is:  0.10819117724895477\n",
      "The representation loss after processing this batch is:  0.002383783459663391\n",
      "\n",
      "The classification loss after processing this batch is:  0.09866372495889664\n",
      "The representation loss after processing this batch is:  0.002281438559293747\n",
      "\n",
      "The classification loss after processing this batch is:  0.1479429453611374\n",
      "The representation loss after processing this batch is:  0.002429664134979248\n",
      "\n",
      "The classification loss after processing this batch is:  0.18575257062911987\n",
      "The representation loss after processing this batch is:  0.002363581210374832\n",
      "\n",
      "The classification loss after processing this batch is:  0.17247486114501953\n",
      "The representation loss after processing this batch is:  0.0025717541575431824\n",
      "\n",
      "The classification loss after processing this batch is:  0.13013887405395508\n",
      "The representation loss after processing this batch is:  0.0024279579520225525\n",
      "\n",
      "The classification loss after processing this batch is:  0.08494697511196136\n",
      "The representation loss after processing this batch is:  0.003041796386241913\n",
      "\n",
      "The classification loss after processing this batch is:  0.06498415768146515\n",
      "The representation loss after processing this batch is:  0.002858877182006836\n",
      "\n",
      "The classification loss after processing this batch is:  0.08654201030731201\n",
      "The representation loss after processing this batch is:  0.002391774207353592\n",
      "\n",
      "The classification loss after processing this batch is:  0.06797594577074051\n",
      "The representation loss after processing this batch is:  0.0022464320063591003\n",
      "\n",
      "The classification loss after processing this batch is:  0.0511108860373497\n",
      "The representation loss after processing this batch is:  0.0022544674575328827\n",
      "\n",
      "The classification loss after processing this batch is:  0.031872350722551346\n",
      "The representation loss after processing this batch is:  0.0023596882820129395\n",
      "\n",
      "The classification loss after processing this batch is:  0.10979662835597992\n",
      "The representation loss after processing this batch is:  0.0023436620831489563\n",
      "\n",
      "The classification loss after processing this batch is:  0.05411548167467117\n",
      "The representation loss after processing this batch is:  0.002522006630897522\n",
      "\n",
      "The classification loss after processing this batch is:  0.07393819838762283\n",
      "The representation loss after processing this batch is:  0.002596445381641388\n",
      "\n",
      "The classification loss after processing this batch is:  0.07412953674793243\n",
      "The representation loss after processing this batch is:  0.002055257558822632\n",
      "\n",
      "The classification loss after processing this batch is:  0.06038902327418327\n",
      "The representation loss after processing this batch is:  0.002280835062265396\n",
      "\n",
      "The classification loss after processing this batch is:  0.061578311026096344\n",
      "The representation loss after processing this batch is:  0.002571582794189453\n",
      "\n",
      "The classification loss after processing this batch is:  0.07584737986326218\n",
      "The representation loss after processing this batch is:  0.0023831091821193695\n",
      "\n",
      "The classification loss after processing this batch is:  0.10234638303518295\n",
      "The representation loss after processing this batch is:  0.0026155710220336914\n",
      "\n",
      "The classification loss after processing this batch is:  0.02262348309159279\n",
      "The representation loss after processing this batch is:  0.0025934651494026184\n",
      "\n",
      "The classification loss after processing this batch is:  0.02880455181002617\n",
      "The representation loss after processing this batch is:  0.0025147944688796997\n",
      "\n",
      "The classification loss after processing this batch is:  0.11041366308927536\n",
      "The representation loss after processing this batch is:  0.0022862404584884644\n",
      "\n",
      "The classification loss after processing this batch is:  0.14464861154556274\n",
      "The representation loss after processing this batch is:  0.0023265033960342407\n",
      "\n",
      "The classification loss after processing this batch is:  0.09027095139026642\n",
      "The representation loss after processing this batch is:  0.0024815648794174194\n",
      "\n",
      "The classification loss after processing this batch is:  0.02969767339527607\n",
      "The representation loss after processing this batch is:  0.0021947063505649567\n",
      "\n",
      "The classification loss after processing this batch is:  0.08906778693199158\n",
      "The representation loss after processing this batch is:  0.002349264919757843\n",
      "\n",
      "The classification loss after processing this batch is:  0.017585722729563713\n",
      "The representation loss after processing this batch is:  0.002458512783050537\n",
      "\n",
      "The classification loss after processing this batch is:  0.09880281984806061\n",
      "The representation loss after processing this batch is:  0.002356328070163727\n",
      "\n",
      "The classification loss after processing this batch is:  0.08898245543241501\n",
      "The representation loss after processing this batch is:  0.0024836882948875427\n",
      "\n",
      "The classification loss after processing this batch is:  0.06390764564275742\n",
      "The representation loss after processing this batch is:  0.002263769507408142\n",
      "\n",
      "The classification loss after processing this batch is:  0.051232967525720596\n",
      "The representation loss after processing this batch is:  0.0025237351655960083\n",
      "\n",
      "The classification loss after processing this batch is:  0.07735379785299301\n",
      "The representation loss after processing this batch is:  0.00239456444978714\n",
      "\n",
      "The classification loss after processing this batch is:  0.042893946170806885\n",
      "The representation loss after processing this batch is:  0.0023112595081329346\n",
      "\n",
      "The classification loss after processing this batch is:  0.14939217269420624\n",
      "The representation loss after processing this batch is:  0.0025163963437080383\n",
      "\n",
      "The classification loss after processing this batch is:  0.22986994683742523\n",
      "The representation loss after processing this batch is:  0.0023357272148132324\n",
      "\n",
      "The classification loss after processing this batch is:  0.14714612066745758\n",
      "The representation loss after processing this batch is:  0.0021784789860248566\n",
      "\n",
      "The classification loss after processing this batch is:  0.17107854783535004\n",
      "The representation loss after processing this batch is:  0.0023459047079086304\n",
      "\n",
      "The classification loss after processing this batch is:  0.09162673354148865\n",
      "The representation loss after processing this batch is:  0.0024321451783180237\n",
      "\n",
      "The classification loss after processing this batch is:  0.05265221744775772\n",
      "The representation loss after processing this batch is:  0.0022621378302574158\n",
      "\n",
      "The classification loss after processing this batch is:  0.15443529188632965\n",
      "The representation loss after processing this batch is:  0.002347990870475769\n",
      "\n",
      "The classification loss after processing this batch is:  0.10475269705057144\n",
      "The representation loss after processing this batch is:  0.0024895407259464264\n",
      "\n",
      "The classification loss after processing this batch is:  0.09473720192909241\n",
      "The representation loss after processing this batch is:  0.0024178586900234222\n",
      "\n",
      "The classification loss after processing this batch is:  0.10441675037145615\n",
      "The representation loss after processing this batch is:  0.0025841891765594482\n",
      "\n",
      "The classification loss after processing this batch is:  0.12242114543914795\n",
      "The representation loss after processing this batch is:  0.0022935718297958374\n",
      "\n",
      "The classification loss after processing this batch is:  0.053515613079071045\n",
      "The representation loss after processing this batch is:  0.0022590123116970062\n",
      "\n",
      "The classification loss after processing this batch is:  0.07146772742271423\n",
      "The representation loss after processing this batch is:  0.002524830400943756\n",
      "\n",
      "The classification loss after processing this batch is:  0.10283806174993515\n",
      "The representation loss after processing this batch is:  0.0023270174860954285\n",
      "\n",
      "The classification loss after processing this batch is:  0.0332137756049633\n",
      "The representation loss after processing this batch is:  0.0024601593613624573\n",
      "\n",
      "The classification loss after processing this batch is:  0.03701990470290184\n",
      "The representation loss after processing this batch is:  0.002529282122850418\n",
      "\n",
      "The classification loss after processing this batch is:  0.09090948849916458\n",
      "The representation loss after processing this batch is:  0.0022505521774291992\n",
      "\n",
      "The classification loss after processing this batch is:  0.1582377403974533\n",
      "The representation loss after processing this batch is:  0.002385839819908142\n",
      "\n",
      "The classification loss after processing this batch is:  0.03927351534366608\n",
      "The representation loss after processing this batch is:  0.002258896827697754\n",
      "\n",
      "The classification loss after processing this batch is:  0.04833370819687843\n",
      "The representation loss after processing this batch is:  0.002194821834564209\n",
      "\n",
      "The classification loss after processing this batch is:  0.12819118797779083\n",
      "The representation loss after processing this batch is:  0.002285197377204895\n",
      "\n",
      "The classification loss after processing this batch is:  0.17299550771713257\n",
      "The representation loss after processing this batch is:  0.0022365152835845947\n",
      "\n",
      "The classification loss after processing this batch is:  0.060425613075494766\n",
      "The representation loss after processing this batch is:  0.0021781474351882935\n",
      "\n",
      "The classification loss after processing this batch is:  0.13932350277900696\n",
      "The representation loss after processing this batch is:  0.0021681152284145355\n",
      "\n",
      "The classification loss after processing this batch is:  0.053737688809633255\n",
      "The representation loss after processing this batch is:  0.002561613917350769\n",
      "\n",
      "The classification loss after processing this batch is:  0.023296432569622993\n",
      "The representation loss after processing this batch is:  0.0023074038326740265\n",
      "\n",
      "The classification loss after processing this batch is:  0.03219354897737503\n",
      "The representation loss after processing this batch is:  0.002423614263534546\n",
      "\n",
      "The classification loss after processing this batch is:  0.10290596634149551\n",
      "The representation loss after processing this batch is:  0.0028133317828178406\n",
      "\n",
      "The classification loss after processing this batch is:  0.1218155100941658\n",
      "The representation loss after processing this batch is:  0.002501070499420166\n",
      "\n",
      "The classification loss after processing this batch is:  0.05907389149069786\n",
      "The representation loss after processing this batch is:  0.0029510781168937683\n",
      "\n",
      "The classification loss after processing this batch is:  0.08346350491046906\n",
      "The representation loss after processing this batch is:  0.0022241920232772827\n",
      "\n",
      "The classification loss after processing this batch is:  0.04301735386252403\n",
      "The representation loss after processing this batch is:  0.0024551451206207275\n",
      "\n",
      "The classification loss after processing this batch is:  0.11673878133296967\n",
      "The representation loss after processing this batch is:  0.002448074519634247\n",
      "\n",
      "The classification loss after processing this batch is:  0.07748695462942123\n",
      "The representation loss after processing this batch is:  0.002150554209947586\n",
      "\n",
      "The classification loss after processing this batch is:  0.11595513671636581\n",
      "The representation loss after processing this batch is:  0.002395268529653549\n",
      "\n",
      "The classification loss after processing this batch is:  0.11779581755399704\n",
      "The representation loss after processing this batch is:  0.002589412033557892\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.21854223310947418\n",
      "The representation loss after processing this batch is:  0.0020983070135116577\n",
      "\n",
      "The classification loss after processing this batch is:  0.08846087008714676\n",
      "The representation loss after processing this batch is:  0.002112552523612976\n",
      "\n",
      "The classification loss after processing this batch is:  0.1413513869047165\n",
      "The representation loss after processing this batch is:  0.002181127667427063\n",
      "\n",
      "The classification loss after processing this batch is:  0.1432810127735138\n",
      "The representation loss after processing this batch is:  0.002338416874408722\n",
      "\n",
      "The classification loss after processing this batch is:  0.06604447215795517\n",
      "The representation loss after processing this batch is:  0.0023545846343040466\n",
      "\n",
      "The classification loss after processing this batch is:  0.07577654719352722\n",
      "The representation loss after processing this batch is:  0.0026970356702804565\n",
      "\n",
      "The classification loss after processing this batch is:  0.04321073368191719\n",
      "The representation loss after processing this batch is:  0.0025414153933525085\n",
      "\n",
      "The classification loss after processing this batch is:  0.10281748324632645\n",
      "The representation loss after processing this batch is:  0.002272244542837143\n",
      "\n",
      "The classification loss after processing this batch is:  0.08472580462694168\n",
      "The representation loss after processing this batch is:  0.002011377364397049\n",
      "\n",
      "The classification loss after processing this batch is:  0.0745888501405716\n",
      "The representation loss after processing this batch is:  0.002207458019256592\n",
      "\n",
      "The classification loss after processing this batch is:  0.08756936341524124\n",
      "The representation loss after processing this batch is:  0.0024038702249526978\n",
      "\n",
      "The classification loss after processing this batch is:  0.09591507166624069\n",
      "The representation loss after processing this batch is:  0.0022305697202682495\n",
      "\n",
      "The classification loss after processing this batch is:  0.08284995704889297\n",
      "The representation loss after processing this batch is:  0.0023110955953598022\n",
      "\n",
      "The classification loss after processing this batch is:  0.13249048590660095\n",
      "The representation loss after processing this batch is:  0.002386234700679779\n",
      "\n",
      "The classification loss after processing this batch is:  0.072120800614357\n",
      "The representation loss after processing this batch is:  0.002445131540298462\n",
      "\n",
      "The classification loss after processing this batch is:  0.06425394862890244\n",
      "The representation loss after processing this batch is:  0.0019963085651397705\n",
      "\n",
      "The classification loss after processing this batch is:  0.06728670746088028\n",
      "The representation loss after processing this batch is:  0.002646327018737793\n",
      "\n",
      "The classification loss after processing this batch is:  0.14989012479782104\n",
      "The representation loss after processing this batch is:  0.0029019564390182495\n",
      "\n",
      "The classification loss after processing this batch is:  0.24893073737621307\n",
      "The representation loss after processing this batch is:  0.00263010710477829\n",
      "\n",
      "The classification loss after processing this batch is:  0.025541551411151886\n",
      "The representation loss after processing this batch is:  0.0022287294268608093\n",
      "\n",
      "The classification loss after processing this batch is:  0.05233227089047432\n",
      "The representation loss after processing this batch is:  0.0023471415042877197\n",
      "\n",
      "The classification loss after processing this batch is:  0.16072937846183777\n",
      "The representation loss after processing this batch is:  0.002765234559774399\n",
      "\n",
      "The classification loss after processing this batch is:  0.03479238227009773\n",
      "The representation loss after processing this batch is:  0.002544023096561432\n",
      "\n",
      "The classification loss after processing this batch is:  0.041606929153203964\n",
      "The representation loss after processing this batch is:  0.002266623079776764\n",
      "\n",
      "The classification loss after processing this batch is:  0.1019010841846466\n",
      "The representation loss after processing this batch is:  0.002602599561214447\n",
      "\n",
      "The classification loss after processing this batch is:  0.0571766123175621\n",
      "The representation loss after processing this batch is:  0.002564694732427597\n",
      "\n",
      "The classification loss after processing this batch is:  0.11246698349714279\n",
      "The representation loss after processing this batch is:  0.002937786281108856\n",
      "\n",
      "The classification loss after processing this batch is:  0.09660793840885162\n",
      "The representation loss after processing this batch is:  0.002705417573451996\n",
      "\n",
      "The classification loss after processing this batch is:  0.10671278089284897\n",
      "The representation loss after processing this batch is:  0.002866484224796295\n",
      "\n",
      "The classification loss after processing this batch is:  0.08403853327035904\n",
      "The representation loss after processing this batch is:  0.0020895972847938538\n",
      "\n",
      "The classification loss after processing this batch is:  0.10821432620286942\n",
      "The representation loss after processing this batch is:  0.0022104978561401367\n",
      "\n",
      "The classification loss after processing this batch is:  0.025453615933656693\n",
      "The representation loss after processing this batch is:  0.0022927895188331604\n",
      "\n",
      "The classification loss after processing this batch is:  0.032024845480918884\n",
      "The representation loss after processing this batch is:  0.002393953502178192\n",
      "\n",
      "The classification loss after processing this batch is:  0.09078696370124817\n",
      "The representation loss after processing this batch is:  0.0024650655686855316\n",
      "\n",
      "The classification loss after processing this batch is:  0.059950120747089386\n",
      "The representation loss after processing this batch is:  0.002435632050037384\n",
      "\n",
      "The classification loss after processing this batch is:  0.08953198790550232\n",
      "The representation loss after processing this batch is:  0.0023284517228603363\n",
      "\n",
      "The classification loss after processing this batch is:  0.04337469860911369\n",
      "The representation loss after processing this batch is:  0.002286389470100403\n",
      "\n",
      "The classification loss after processing this batch is:  0.05759810283780098\n",
      "The representation loss after processing this batch is:  0.0023651234805583954\n",
      "\n",
      "The classification loss after processing this batch is:  0.09682957828044891\n",
      "The representation loss after processing this batch is:  0.002273857593536377\n",
      "\n",
      "The classification loss after processing this batch is:  0.14511363208293915\n",
      "The representation loss after processing this batch is:  0.002675481140613556\n",
      "\n",
      "The classification loss after processing this batch is:  0.15738633275032043\n",
      "The representation loss after processing this batch is:  0.0022780820727348328\n",
      "\n",
      "The classification loss after processing this batch is:  0.06354798376560211\n",
      "The representation loss after processing this batch is:  0.0025372877717018127\n",
      "\n",
      "The classification loss after processing this batch is:  0.15057030320167542\n",
      "The representation loss after processing this batch is:  0.0022540688514709473\n",
      "\n",
      "The classification loss after processing this batch is:  0.04627375304698944\n",
      "The representation loss after processing this batch is:  0.00217379629611969\n",
      "\n",
      "The classification loss after processing this batch is:  0.10515569150447845\n",
      "The representation loss after processing this batch is:  0.002355016767978668\n",
      "\n",
      "The classification loss after processing this batch is:  0.1947811245918274\n",
      "The representation loss after processing this batch is:  0.002811715006828308\n",
      "\n",
      "The classification loss after processing this batch is:  0.088015116751194\n",
      "The representation loss after processing this batch is:  0.0021732524037361145\n",
      "\n",
      "The classification loss after processing this batch is:  0.11319852620363235\n",
      "The representation loss after processing this batch is:  0.002202644944190979\n",
      "\n",
      "The classification loss after processing this batch is:  0.08897744864225388\n",
      "The representation loss after processing this batch is:  0.0023118332028388977\n",
      "\n",
      "The classification loss after processing this batch is:  0.15494738519191742\n",
      "The representation loss after processing this batch is:  0.0023025162518024445\n",
      "\n",
      "The classification loss after processing this batch is:  0.09206391870975494\n",
      "The representation loss after processing this batch is:  0.002465188503265381\n",
      "\n",
      "The classification loss after processing this batch is:  0.06993851065635681\n",
      "The representation loss after processing this batch is:  0.00231015682220459\n",
      "\n",
      "The classification loss after processing this batch is:  0.08902052789926529\n",
      "The representation loss after processing this batch is:  0.002411097288131714\n",
      "\n",
      "The classification loss after processing this batch is:  0.03550729900598526\n",
      "The representation loss after processing this batch is:  0.0024623796343803406\n",
      "\n",
      "The classification loss after processing this batch is:  0.02998504601418972\n",
      "The representation loss after processing this batch is:  0.002122454345226288\n",
      "\n",
      "The classification loss after processing this batch is:  0.09808571636676788\n",
      "The representation loss after processing this batch is:  0.0027122274041175842\n",
      "\n",
      "The classification loss after processing this batch is:  0.03405959904193878\n",
      "The representation loss after processing this batch is:  0.0026647374033927917\n",
      "\n",
      "The classification loss after processing this batch is:  0.15303964912891388\n",
      "The representation loss after processing this batch is:  0.002548135817050934\n",
      "\n",
      "The classification loss after processing this batch is:  0.06548185646533966\n",
      "The representation loss after processing this batch is:  0.002335280179977417\n",
      "\n",
      "The classification loss after processing this batch is:  0.16900651156902313\n",
      "The representation loss after processing this batch is:  0.00234106183052063\n",
      "\n",
      "The classification loss after processing this batch is:  0.2392425835132599\n",
      "The representation loss after processing this batch is:  0.0021784529089927673\n",
      "\n",
      "The classification loss after processing this batch is:  0.10823865234851837\n",
      "The representation loss after processing this batch is:  0.0021665580570697784\n",
      "\n",
      "The classification loss after processing this batch is:  0.030744127929210663\n",
      "The representation loss after processing this batch is:  0.0026201382279396057\n",
      "\n",
      "The classification loss after processing this batch is:  0.04592999443411827\n",
      "The representation loss after processing this batch is:  0.002524763345718384\n",
      "\n",
      "The classification loss after processing this batch is:  0.03350100293755531\n",
      "The representation loss after processing this batch is:  0.002733983099460602\n",
      "\n",
      "The classification loss after processing this batch is:  0.07215915620326996\n",
      "The representation loss after processing this batch is:  0.002607874572277069\n",
      "\n",
      "The classification loss after processing this batch is:  0.08283527195453644\n",
      "The representation loss after processing this batch is:  0.002006739377975464\n",
      "\n",
      "The classification loss after processing this batch is:  0.19322167336940765\n",
      "The representation loss after processing this batch is:  0.0023539699614048004\n",
      "\n",
      "The classification loss after processing this batch is:  0.13799479603767395\n",
      "The representation loss after processing this batch is:  0.0021839700639247894\n",
      "\n",
      "The classification loss after processing this batch is:  0.08285529911518097\n",
      "The representation loss after processing this batch is:  0.002760060131549835\n",
      "\n",
      "The classification loss after processing this batch is:  0.1879683881998062\n",
      "The representation loss after processing this batch is:  0.00287434458732605\n",
      "\n",
      "The classification loss after processing this batch is:  0.04239381104707718\n",
      "The representation loss after processing this batch is:  0.002479270100593567\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.078771211206913\n",
      "The representation loss after processing this batch is:  0.002478610724210739\n",
      "\n",
      "The classification loss after processing this batch is:  0.13207003474235535\n",
      "The representation loss after processing this batch is:  0.002359215170145035\n",
      "\n",
      "The classification loss after processing this batch is:  0.06756064295768738\n",
      "The representation loss after processing this batch is:  0.002699621021747589\n",
      "\n",
      "The classification loss after processing this batch is:  0.11120858043432236\n",
      "The representation loss after processing this batch is:  0.003153957426548004\n",
      "\n",
      "The classification loss after processing this batch is:  0.0652022436261177\n",
      "The representation loss after processing this batch is:  0.0025641359388828278\n",
      "\n",
      "The classification loss after processing this batch is:  0.08524496853351593\n",
      "The representation loss after processing this batch is:  0.003139182925224304\n",
      "\n",
      "The classification loss after processing this batch is:  0.16185003519058228\n",
      "The representation loss after processing this batch is:  0.002752833068370819\n",
      "\n",
      "The classification loss after processing this batch is:  0.06125931814312935\n",
      "The representation loss after processing this batch is:  0.0028818994760513306\n",
      "\n",
      "The classification loss after processing this batch is:  0.1411091536283493\n",
      "The representation loss after processing this batch is:  0.0024212971329689026\n",
      "\n",
      "The classification loss after processing this batch is:  0.1805451363325119\n",
      "The representation loss after processing this batch is:  0.002146787941455841\n",
      "\n",
      "The classification loss after processing this batch is:  0.09030976891517639\n",
      "The representation loss after processing this batch is:  0.002303779125213623\n",
      "\n",
      "The classification loss after processing this batch is:  0.11927516013383865\n",
      "The representation loss after processing this batch is:  0.0021529421210289\n",
      "\n",
      "The classification loss after processing this batch is:  0.06622324883937836\n",
      "The representation loss after processing this batch is:  0.00276077538728714\n",
      "\n",
      "The classification loss after processing this batch is:  0.02730906382203102\n",
      "The representation loss after processing this batch is:  0.0024014264345169067\n",
      "\n",
      "The classification loss after processing this batch is:  0.09188783168792725\n",
      "The representation loss after processing this batch is:  0.0025807246565818787\n",
      "\n",
      "The classification loss after processing this batch is:  0.046205904334783554\n",
      "The representation loss after processing this batch is:  0.0026364102959632874\n",
      "\n",
      "The classification loss after processing this batch is:  0.20507806539535522\n",
      "The representation loss after processing this batch is:  0.002196170389652252\n",
      "\n",
      "The classification loss after processing this batch is:  0.03917759656906128\n",
      "The representation loss after processing this batch is:  0.002675190567970276\n",
      "\n",
      "The classification loss after processing this batch is:  0.08672424405813217\n",
      "The representation loss after processing this batch is:  0.0022571682929992676\n",
      "\n",
      "The classification loss after processing this batch is:  0.14026448130607605\n",
      "The representation loss after processing this batch is:  0.0023368671536445618\n",
      "\n",
      "The classification loss after processing this batch is:  0.10496412962675095\n",
      "The representation loss after processing this batch is:  0.0022691115736961365\n",
      "\n",
      "The classification loss after processing this batch is:  0.09377966821193695\n",
      "The representation loss after processing this batch is:  0.0023753196001052856\n",
      "\n",
      "The classification loss after processing this batch is:  0.0523642897605896\n",
      "The representation loss after processing this batch is:  0.0023531466722488403\n",
      "\n",
      "The classification loss after processing this batch is:  0.050838932394981384\n",
      "The representation loss after processing this batch is:  0.0021643489599227905\n",
      "\n",
      "The classification loss after processing this batch is:  0.036167871206998825\n",
      "The representation loss after processing this batch is:  0.0023205503821372986\n",
      "\n",
      "The classification loss after processing this batch is:  0.13523320853710175\n",
      "The representation loss after processing this batch is:  0.003214232623577118\n",
      "\n",
      "The classification loss after processing this batch is:  0.13170498609542847\n",
      "The representation loss after processing this batch is:  0.002507343888282776\n",
      "\n",
      "The classification loss after processing this batch is:  0.12971509993076324\n",
      "The representation loss after processing this batch is:  0.00199982151389122\n",
      "\n",
      "The classification loss after processing this batch is:  0.12571260333061218\n",
      "The representation loss after processing this batch is:  0.002284180372953415\n",
      "\n",
      "The classification loss after processing this batch is:  0.25608715415000916\n",
      "The representation loss after processing this batch is:  0.0021727941930294037\n",
      "\n",
      "The classification loss after processing this batch is:  0.09135091304779053\n",
      "The representation loss after processing this batch is:  0.0027763396501541138\n",
      "\n",
      "The classification loss after processing this batch is:  0.1762876659631729\n",
      "The representation loss after processing this batch is:  0.002399533987045288\n",
      "\n",
      "The classification loss after processing this batch is:  0.09166686981916428\n",
      "The representation loss after processing this batch is:  0.002453751862049103\n",
      "\n",
      "The classification loss after processing this batch is:  0.06446310132741928\n",
      "The representation loss after processing this batch is:  0.00231064110994339\n",
      "\n",
      "The classification loss after processing this batch is:  0.04037398844957352\n",
      "The representation loss after processing this batch is:  0.002209089696407318\n",
      "\n",
      "The classification loss after processing this batch is:  0.050663650035858154\n",
      "The representation loss after processing this batch is:  0.002434566617012024\n",
      "\n",
      "The classification loss after processing this batch is:  0.19987599551677704\n",
      "The representation loss after processing this batch is:  0.0025194361805915833\n",
      "\n",
      "The classification loss after processing this batch is:  0.0820159763097763\n",
      "The representation loss after processing this batch is:  0.0025016292929649353\n",
      "\n",
      "The classification loss after processing this batch is:  0.08519889414310455\n",
      "The representation loss after processing this batch is:  0.0029033273458480835\n",
      "\n",
      "The classification loss after processing this batch is:  0.07892487198114395\n",
      "The representation loss after processing this batch is:  0.0027752965688705444\n",
      "\n",
      "The classification loss after processing this batch is:  0.060774970799684525\n",
      "The representation loss after processing this batch is:  0.0025097355246543884\n",
      "\n",
      "The classification loss after processing this batch is:  0.04459432139992714\n",
      "The representation loss after processing this batch is:  0.0024541690945625305\n",
      "\n",
      "The classification loss after processing this batch is:  0.13352862000465393\n",
      "The representation loss after processing this batch is:  0.0022555366158485413\n",
      "\n",
      "The classification loss after processing this batch is:  0.20170845091342926\n",
      "The representation loss after processing this batch is:  0.002383306622505188\n",
      "\n",
      "The classification loss after processing this batch is:  0.1422136425971985\n",
      "The representation loss after processing this batch is:  0.0026318728923797607\n",
      "\n",
      "The classification loss after processing this batch is:  0.09771113842725754\n",
      "The representation loss after processing this batch is:  0.0022330358624458313\n",
      "\n",
      "The classification loss after processing this batch is:  0.2837037444114685\n",
      "The representation loss after processing this batch is:  0.0021136775612831116\n",
      "\n",
      "The classification loss after processing this batch is:  0.05481935665011406\n",
      "The representation loss after processing this batch is:  0.00222952663898468\n",
      "\n",
      "The classification loss after processing this batch is:  0.09298422932624817\n",
      "The representation loss after processing this batch is:  0.0022121071815490723\n",
      "\n",
      "The classification loss after processing this batch is:  0.10331224650144577\n",
      "The representation loss after processing this batch is:  0.0028199031949043274\n",
      "\n",
      "The classification loss after processing this batch is:  0.06440269201993942\n",
      "The representation loss after processing this batch is:  0.002238962799310684\n",
      "\n",
      "The classification loss after processing this batch is:  0.11487238854169846\n",
      "The representation loss after processing this batch is:  0.0023456141352653503\n",
      "\n",
      "The classification loss after processing this batch is:  0.053389955312013626\n",
      "The representation loss after processing this batch is:  0.002656213939189911\n",
      "\n",
      "The classification loss after processing this batch is:  0.12586422264575958\n",
      "The representation loss after processing this batch is:  0.002403873950242996\n",
      "\n",
      "The classification loss after processing this batch is:  0.1540653109550476\n",
      "The representation loss after processing this batch is:  0.002606786787509918\n",
      "\n",
      "The classification loss after processing this batch is:  0.1654844582080841\n",
      "The representation loss after processing this batch is:  0.0023541152477264404\n",
      "\n",
      "The classification loss after processing this batch is:  0.07917051762342453\n",
      "The representation loss after processing this batch is:  0.002492167055606842\n",
      "\n",
      "The classification loss after processing this batch is:  0.06027153506875038\n",
      "The representation loss after processing this batch is:  0.0027576200664043427\n",
      "\n",
      "The classification loss after processing this batch is:  0.1215081661939621\n",
      "The representation loss after processing this batch is:  0.002270922064781189\n",
      "\n",
      "The classification loss after processing this batch is:  0.12007360905408859\n",
      "The representation loss after processing this batch is:  0.0024084746837615967\n",
      "\n",
      "The classification loss after processing this batch is:  0.015720749273896217\n",
      "The representation loss after processing this batch is:  0.0023458749055862427\n",
      "\n",
      "The classification loss after processing this batch is:  0.09439525753259659\n",
      "The representation loss after processing this batch is:  0.0022271908819675446\n",
      "\n",
      "The classification loss after processing this batch is:  0.20228536427021027\n",
      "The representation loss after processing this batch is:  0.0025931932032108307\n",
      "\n",
      "The classification loss after processing this batch is:  0.20683875679969788\n",
      "The representation loss after processing this batch is:  0.0026313289999961853\n",
      "\n",
      "The classification loss after processing this batch is:  0.19625908136367798\n",
      "The representation loss after processing this batch is:  0.002239339053630829\n",
      "\n",
      "The classification loss after processing this batch is:  0.1537351906299591\n",
      "The representation loss after processing this batch is:  0.0021412596106529236\n",
      "\n",
      "The classification loss after processing this batch is:  0.04981241002678871\n",
      "The representation loss after processing this batch is:  0.0023220181465148926\n",
      "\n",
      "The classification loss after processing this batch is:  0.10106419771909714\n",
      "The representation loss after processing this batch is:  0.002183586359024048\n",
      "\n",
      "The classification loss after processing this batch is:  0.08001964539289474\n",
      "The representation loss after processing this batch is:  0.0025444403290748596\n",
      "\n",
      "The classification loss after processing this batch is:  0.14979353547096252\n",
      "The representation loss after processing this batch is:  0.0026741251349449158\n",
      "\n",
      "The classification loss after processing this batch is:  0.10410086065530777\n",
      "The representation loss after processing this batch is:  0.0026978999376296997\n",
      "\n",
      "The classification loss after processing this batch is:  0.10521923750638962\n",
      "The representation loss after processing this batch is:  0.0027122795581817627\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.06515049189329147\n",
      "The representation loss after processing this batch is:  0.002371419221162796\n",
      "\n",
      "The classification loss after processing this batch is:  0.046959053725004196\n",
      "The representation loss after processing this batch is:  0.0023813173174858093\n",
      "\n",
      "The classification loss after processing this batch is:  0.17098501324653625\n",
      "The representation loss after processing this batch is:  0.0025998950004577637\n",
      "\n",
      "The classification loss after processing this batch is:  0.12721484899520874\n",
      "The representation loss after processing this batch is:  0.002300553023815155\n",
      "\n",
      "The classification loss after processing this batch is:  0.08379893004894257\n",
      "The representation loss after processing this batch is:  0.00235908105969429\n",
      "\n",
      "The classification loss after processing this batch is:  0.18958379328250885\n",
      "The representation loss after processing this batch is:  0.0030775852501392365\n",
      "\n",
      "The classification loss after processing this batch is:  0.22816766798496246\n",
      "The representation loss after processing this batch is:  0.0027921460568904877\n",
      "\n",
      "The classification loss after processing this batch is:  0.1384027749300003\n",
      "The representation loss after processing this batch is:  0.0025913864374160767\n",
      "\n",
      "The classification loss after processing this batch is:  0.0648450031876564\n",
      "The representation loss after processing this batch is:  0.0025143027305603027\n",
      "\n",
      "The classification loss after processing this batch is:  0.10319164395332336\n",
      "The representation loss after processing this batch is:  0.0026107579469680786\n",
      "\n",
      "The classification loss after processing this batch is:  0.053668852895498276\n",
      "The representation loss after processing this batch is:  0.0026427656412124634\n",
      "\n",
      "The classification loss after processing this batch is:  0.1491067111492157\n",
      "The representation loss after processing this batch is:  0.002672329545021057\n",
      "\n",
      "The classification loss after processing this batch is:  0.10379026085138321\n",
      "The representation loss after processing this batch is:  0.002772010862827301\n",
      "\n",
      "The classification loss after processing this batch is:  0.08717381954193115\n",
      "The representation loss after processing this batch is:  0.002768278121948242\n",
      "\n",
      "The classification loss after processing this batch is:  0.22449930012226105\n",
      "The representation loss after processing this batch is:  0.0023028478026390076\n",
      "\n",
      "The classification loss after processing this batch is:  0.044815439730882645\n",
      "The representation loss after processing this batch is:  0.0025348961353302\n",
      "\n",
      "The classification loss after processing this batch is:  0.0415956936776638\n",
      "The representation loss after processing this batch is:  0.002783849835395813\n",
      "\n",
      "The classification loss after processing this batch is:  0.04384968429803848\n",
      "The representation loss after processing this batch is:  0.0022810325026512146\n",
      "\n",
      "The classification loss after processing this batch is:  0.10928986221551895\n",
      "The representation loss after processing this batch is:  0.002232801169157028\n",
      "\n",
      "The classification loss after processing this batch is:  0.17918995022773743\n",
      "The representation loss after processing this batch is:  0.002437204122543335\n",
      "\n",
      "The classification loss after processing this batch is:  0.09790149331092834\n",
      "The representation loss after processing this batch is:  0.0022894442081451416\n",
      "\n",
      "The classification loss after processing this batch is:  0.09322777390480042\n",
      "The representation loss after processing this batch is:  0.002360500395298004\n",
      "\n",
      "The classification loss after processing this batch is:  0.026968713849782944\n",
      "The representation loss after processing this batch is:  0.0021618232131004333\n",
      "\n",
      "The classification loss after processing this batch is:  0.06970240920782089\n",
      "The representation loss after processing this batch is:  0.002321898937225342\n",
      "\n",
      "The classification loss after processing this batch is:  0.06409377604722977\n",
      "The representation loss after processing this batch is:  0.0025014728307724\n",
      "\n",
      "The classification loss after processing this batch is:  0.028345655649900436\n",
      "The representation loss after processing this batch is:  0.0025394707918167114\n",
      "\n",
      "The classification loss after processing this batch is:  0.08468511700630188\n",
      "The representation loss after processing this batch is:  0.0022961460053920746\n",
      "\n",
      "The classification loss after processing this batch is:  0.14948418736457825\n",
      "The representation loss after processing this batch is:  0.0021796971559524536\n",
      "\n",
      "The classification loss after processing this batch is:  0.1861308217048645\n",
      "The representation loss after processing this batch is:  0.002299390733242035\n",
      "\n",
      "The classification loss after processing this batch is:  0.01962403394281864\n",
      "The representation loss after processing this batch is:  0.0022256895899772644\n",
      "\n",
      "The classification loss after processing this batch is:  0.031314969062805176\n",
      "The representation loss after processing this batch is:  0.0024010390043258667\n",
      "\n",
      "The classification loss after processing this batch is:  0.05707966163754463\n",
      "The representation loss after processing this batch is:  0.0026442185044288635\n",
      "\n",
      "The classification loss after processing this batch is:  0.13048464059829712\n",
      "The representation loss after processing this batch is:  0.0022886469960212708\n",
      "\n",
      "The classification loss after processing this batch is:  0.04488736391067505\n",
      "The representation loss after processing this batch is:  0.002556033432483673\n",
      "\n",
      "The classification loss after processing this batch is:  0.13467653095722198\n",
      "The representation loss after processing this batch is:  0.0025650784373283386\n",
      "\n",
      "The classification loss after processing this batch is:  0.15170592069625854\n",
      "The representation loss after processing this batch is:  0.002494402229785919\n",
      "\n",
      "The classification loss after processing this batch is:  0.12291203439235687\n",
      "The representation loss after processing this batch is:  0.002648528665304184\n",
      "\n",
      "The classification loss after processing this batch is:  0.09231633692979813\n",
      "The representation loss after processing this batch is:  0.0026388019323349\n",
      "\n",
      "The classification loss after processing this batch is:  0.049743376672267914\n",
      "The representation loss after processing this batch is:  0.002518691122531891\n",
      "\n",
      "The classification loss after processing this batch is:  0.12388642132282257\n",
      "The representation loss after processing this batch is:  0.00219157338142395\n",
      "\n",
      "The classification loss after processing this batch is:  0.1377386748790741\n",
      "The representation loss after processing this batch is:  0.00237216055393219\n",
      "\n",
      "The classification loss after processing this batch is:  0.056967757642269135\n",
      "The representation loss after processing this batch is:  0.002424873411655426\n",
      "\n",
      "The classification loss after processing this batch is:  0.03125188127160072\n",
      "The representation loss after processing this batch is:  0.0022636577486991882\n",
      "\n",
      "The classification loss after processing this batch is:  0.1918850541114807\n",
      "The representation loss after processing this batch is:  0.002383355051279068\n",
      "\n",
      "The classification loss after processing this batch is:  0.1842106133699417\n",
      "The representation loss after processing this batch is:  0.0022144392132759094\n",
      "\n",
      "The classification loss after processing this batch is:  0.07009519636631012\n",
      "The representation loss after processing this batch is:  0.0022370368242263794\n",
      "\n",
      "The classification loss after processing this batch is:  0.22200940549373627\n",
      "The representation loss after processing this batch is:  0.0024048015475273132\n",
      "\n",
      "The classification loss after processing this batch is:  0.21671488881111145\n",
      "The representation loss after processing this batch is:  0.0023666098713874817\n",
      "\n",
      "The classification loss after processing this batch is:  0.2777235805988312\n",
      "The representation loss after processing this batch is:  0.002354040741920471\n",
      "\n",
      "The classification loss after processing this batch is:  0.10916350036859512\n",
      "The representation loss after processing this batch is:  0.002595968544483185\n",
      "\n",
      "The classification loss after processing this batch is:  0.06433282792568207\n",
      "The representation loss after processing this batch is:  0.0023075640201568604\n",
      "\n",
      "The classification loss after processing this batch is:  0.1332559436559677\n",
      "The representation loss after processing this batch is:  0.002518497407436371\n",
      "\n",
      "The classification loss after processing this batch is:  0.0641515925526619\n",
      "The representation loss after processing this batch is:  0.0024540573358535767\n",
      "\n",
      "The classification loss after processing this batch is:  0.04638544097542763\n",
      "The representation loss after processing this batch is:  0.0027516111731529236\n",
      "\n",
      "The classification loss after processing this batch is:  0.08214481174945831\n",
      "The representation loss after processing this batch is:  0.002140682190656662\n",
      "\n",
      "The classification loss after processing this batch is:  0.03985418379306793\n",
      "The representation loss after processing this batch is:  0.0023983195424079895\n",
      "\n",
      "The classification loss after processing this batch is:  0.013245209120213985\n",
      "The representation loss after processing this batch is:  0.002714388072490692\n",
      "\n",
      "The classification loss after processing this batch is:  0.08153869956731796\n",
      "The representation loss after processing this batch is:  0.0023261457681655884\n",
      "\n",
      "The classification loss after processing this batch is:  0.1117764338850975\n",
      "The representation loss after processing this batch is:  0.002157650887966156\n",
      "\n",
      "The classification loss after processing this batch is:  0.06189389154314995\n",
      "The representation loss after processing this batch is:  0.0025877878069877625\n",
      "\n",
      "The classification loss after processing this batch is:  0.07705170661211014\n",
      "The representation loss after processing this batch is:  0.002317514270544052\n",
      "\n",
      "The classification loss after processing this batch is:  0.11801592260599136\n",
      "The representation loss after processing this batch is:  0.002344585955142975\n",
      "\n",
      "The classification loss after processing this batch is:  0.027061128988862038\n",
      "The representation loss after processing this batch is:  0.002400219440460205\n",
      "\n",
      "The classification loss after processing this batch is:  0.1344870775938034\n",
      "The representation loss after processing this batch is:  0.0025459080934524536\n",
      "\n",
      "The classification loss after processing this batch is:  0.06607534736394882\n",
      "The representation loss after processing this batch is:  0.0022068284451961517\n",
      "\n",
      "The classification loss after processing this batch is:  0.17999835312366486\n",
      "The representation loss after processing this batch is:  0.0022612810134887695\n",
      "\n",
      "The classification loss after processing this batch is:  0.1135965883731842\n",
      "The representation loss after processing this batch is:  0.0024389848113059998\n",
      "\n",
      "The classification loss after processing this batch is:  0.10414329171180725\n",
      "The representation loss after processing this batch is:  0.002109963446855545\n",
      "\n",
      "The classification loss after processing this batch is:  0.029512040317058563\n",
      "The representation loss after processing this batch is:  0.0021950677037239075\n",
      "\n",
      "The classification loss after processing this batch is:  0.028479961678385735\n",
      "The representation loss after processing this batch is:  0.002284504473209381\n",
      "\n",
      "The classification loss after processing this batch is:  0.14228495955467224\n",
      "The representation loss after processing this batch is:  0.0024642087519168854\n",
      "\n",
      "The classification loss after processing this batch is:  0.03486614674329758\n",
      "The representation loss after processing this batch is:  0.002554960548877716\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10301462560892105\n",
      "The representation loss after processing this batch is:  0.0024209916591644287\n",
      "\n",
      "The classification loss after processing this batch is:  0.06084770709276199\n",
      "The representation loss after processing this batch is:  0.0026685893535614014\n",
      "\n",
      "The classification loss after processing this batch is:  0.05938362330198288\n",
      "The representation loss after processing this batch is:  0.0025046169757843018\n",
      "\n",
      "The classification loss after processing this batch is:  0.08866753429174423\n",
      "The representation loss after processing this batch is:  0.0023706257343292236\n",
      "\n",
      "The classification loss after processing this batch is:  0.04836149886250496\n",
      "The representation loss after processing this batch is:  0.00247819721698761\n",
      "\n",
      "The classification loss after processing this batch is:  0.057938240468502045\n",
      "The representation loss after processing this batch is:  0.0028914064168930054\n",
      "\n",
      "The classification loss after processing this batch is:  0.17928320169448853\n",
      "The representation loss after processing this batch is:  0.0023686662316322327\n",
      "\n",
      "The classification loss after processing this batch is:  0.14638061821460724\n",
      "The representation loss after processing this batch is:  0.002603404223918915\n",
      "\n",
      "The classification loss after processing this batch is:  0.14672155678272247\n",
      "The representation loss after processing this batch is:  0.002594955265522003\n",
      "\n",
      "The classification loss after processing this batch is:  0.17731793224811554\n",
      "The representation loss after processing this batch is:  0.0025246739387512207\n",
      "\n",
      "The classification loss after processing this batch is:  0.08059225976467133\n",
      "The representation loss after processing this batch is:  0.00216655433177948\n",
      "\n",
      "The classification loss after processing this batch is:  0.08641310036182404\n",
      "The representation loss after processing this batch is:  0.0022192373871803284\n",
      "\n",
      "The classification loss after processing this batch is:  0.042199961841106415\n",
      "The representation loss after processing this batch is:  0.0023096054792404175\n",
      "\n",
      "The classification loss after processing this batch is:  0.05195092782378197\n",
      "The representation loss after processing this batch is:  0.0023273974657058716\n",
      "\n",
      "The classification loss after processing this batch is:  0.04033975303173065\n",
      "The representation loss after processing this batch is:  0.0024473443627357483\n",
      "\n",
      "The classification loss after processing this batch is:  0.08516797423362732\n",
      "The representation loss after processing this batch is:  0.0021086223423480988\n",
      "\n",
      "The classification loss after processing this batch is:  0.0748957172036171\n",
      "The representation loss after processing this batch is:  0.002579241991043091\n",
      "\n",
      "The classification loss after processing this batch is:  0.10291091352701187\n",
      "The representation loss after processing this batch is:  0.0024304240942001343\n",
      "\n",
      "The classification loss after processing this batch is:  0.04886290058493614\n",
      "The representation loss after processing this batch is:  0.0022585391998291016\n",
      "\n",
      "The classification loss after processing this batch is:  0.1310429722070694\n",
      "The representation loss after processing this batch is:  0.0021569132804870605\n",
      "\n",
      "The classification loss after processing this batch is:  0.05966959521174431\n",
      "The representation loss after processing this batch is:  0.0024736449122428894\n",
      "\n",
      "The classification loss after processing this batch is:  0.12424848228693008\n",
      "The representation loss after processing this batch is:  0.0023029372096061707\n",
      "\n",
      "The classification loss after processing this batch is:  0.11980891227722168\n",
      "The representation loss after processing this batch is:  0.00256318598985672\n",
      "\n",
      "The classification loss after processing this batch is:  0.09401068836450577\n",
      "The representation loss after processing this batch is:  0.0025509223341941833\n",
      "\n",
      "The classification loss after processing this batch is:  0.06249278411269188\n",
      "The representation loss after processing this batch is:  0.0025014281272888184\n",
      "\n",
      "The classification loss after processing this batch is:  0.1713072508573532\n",
      "The representation loss after processing this batch is:  0.002460092306137085\n",
      "\n",
      "The classification loss after processing this batch is:  0.06688234210014343\n",
      "The representation loss after processing this batch is:  0.0024494901299476624\n",
      "\n",
      "The classification loss after processing this batch is:  0.0587029792368412\n",
      "The representation loss after processing this batch is:  0.002198934555053711\n",
      "\n",
      "The classification loss after processing this batch is:  0.06990515440702438\n",
      "The representation loss after processing this batch is:  0.002304505556821823\n",
      "\n",
      "The classification loss after processing this batch is:  0.05981462076306343\n",
      "The representation loss after processing this batch is:  0.002262793481349945\n",
      "\n",
      "The classification loss after processing this batch is:  0.15070994198322296\n",
      "The representation loss after processing this batch is:  0.002285648137331009\n",
      "\n",
      "The classification loss after processing this batch is:  0.13930247724056244\n",
      "The representation loss after processing this batch is:  0.0025033317506313324\n",
      "\n",
      "The classification loss after processing this batch is:  0.08229777216911316\n",
      "The representation loss after processing this batch is:  0.002774961292743683\n",
      "\n",
      "The classification loss after processing this batch is:  0.06073524057865143\n",
      "The representation loss after processing this batch is:  0.002486124634742737\n",
      "\n",
      "The classification loss after processing this batch is:  0.07425729185342789\n",
      "The representation loss after processing this batch is:  0.002627454698085785\n",
      "\n",
      "The classification loss after processing this batch is:  0.16136473417282104\n",
      "The representation loss after processing this batch is:  0.0024279020726680756\n",
      "\n",
      "The classification loss after processing this batch is:  0.04712359979748726\n",
      "The representation loss after processing this batch is:  0.002347111701965332\n",
      "\n",
      "The classification loss after processing this batch is:  0.06195153295993805\n",
      "The representation loss after processing this batch is:  0.0026430338621139526\n",
      "\n",
      "The classification loss after processing this batch is:  0.14463932812213898\n",
      "The representation loss after processing this batch is:  0.0021777749061584473\n",
      "\n",
      "The classification loss after processing this batch is:  0.28273823857307434\n",
      "The representation loss after processing this batch is:  0.0023908019065856934\n",
      "\n",
      "The classification loss after processing this batch is:  0.08019503951072693\n",
      "The representation loss after processing this batch is:  0.0022156015038490295\n",
      "\n",
      "The classification loss after processing this batch is:  0.09979763627052307\n",
      "The representation loss after processing this batch is:  0.0022341422736644745\n",
      "\n",
      "The classification loss after processing this batch is:  0.03614265099167824\n",
      "The representation loss after processing this batch is:  0.0024266690015792847\n",
      "\n",
      "The classification loss after processing this batch is:  0.024220744147896767\n",
      "The representation loss after processing this batch is:  0.0021950677037239075\n",
      "\n",
      "The classification loss after processing this batch is:  0.08172493427991867\n",
      "The representation loss after processing this batch is:  0.0030510202050209045\n",
      "\n",
      "The classification loss after processing this batch is:  0.06277813017368317\n",
      "The representation loss after processing this batch is:  0.003368876874446869\n",
      "\n",
      "The classification loss after processing this batch is:  0.04143960401415825\n",
      "The representation loss after processing this batch is:  0.0023232772946357727\n",
      "\n",
      "The classification loss after processing this batch is:  0.042471278458833694\n",
      "The representation loss after processing this batch is:  0.00214395672082901\n",
      "\n",
      "The classification loss after processing this batch is:  0.14415337145328522\n",
      "The representation loss after processing this batch is:  0.0022331438958644867\n",
      "\n",
      "The classification loss after processing this batch is:  0.10556242614984512\n",
      "The representation loss after processing this batch is:  0.0022575557231903076\n",
      "\n",
      "The classification loss after processing this batch is:  0.052201639860868454\n",
      "The representation loss after processing this batch is:  0.0020460039377212524\n",
      "\n",
      "The classification loss after processing this batch is:  0.05479966849088669\n",
      "The representation loss after processing this batch is:  0.002418801188468933\n",
      "\n",
      "The classification loss after processing this batch is:  0.18569259345531464\n",
      "The representation loss after processing this batch is:  0.002280488610267639\n",
      "\n",
      "The classification loss after processing this batch is:  0.17391222715377808\n",
      "The representation loss after processing this batch is:  0.0025319159030914307\n",
      "\n",
      "The classification loss after processing this batch is:  0.13883914053440094\n",
      "The representation loss after processing this batch is:  0.0021481774747371674\n",
      "\n",
      "The classification loss after processing this batch is:  0.1099649965763092\n",
      "The representation loss after processing this batch is:  0.0026042982935905457\n",
      "\n",
      "The classification loss after processing this batch is:  0.1322852373123169\n",
      "The representation loss after processing this batch is:  0.0023100487887859344\n",
      "\n",
      "The classification loss after processing this batch is:  0.08048154413700104\n",
      "The representation loss after processing this batch is:  0.0027886107563972473\n",
      "\n",
      "The classification loss after processing this batch is:  0.060315441340208054\n",
      "The representation loss after processing this batch is:  0.0026540011167526245\n",
      "\n",
      "The classification loss after processing this batch is:  0.03253353387117386\n",
      "The representation loss after processing this batch is:  0.0025731995701789856\n",
      "\n",
      "The classification loss after processing this batch is:  0.061096057295799255\n",
      "The representation loss after processing this batch is:  0.0022410303354263306\n",
      "\n",
      "The classification loss after processing this batch is:  0.15470190346240997\n",
      "The representation loss after processing this batch is:  0.002310771495103836\n",
      "\n",
      "The classification loss after processing this batch is:  0.06363668292760849\n",
      "The representation loss after processing this batch is:  0.002994149923324585\n",
      "\n",
      "The classification loss after processing this batch is:  0.03401780128479004\n",
      "The representation loss after processing this batch is:  0.002335570752620697\n",
      "\n",
      "The classification loss after processing this batch is:  0.019768381491303444\n",
      "The representation loss after processing this batch is:  0.002983570098876953\n",
      "\n",
      "The classification loss after processing this batch is:  0.022715231403708458\n",
      "The representation loss after processing this batch is:  0.002752155065536499\n",
      "\n",
      "The classification loss after processing this batch is:  0.05031678453087807\n",
      "The representation loss after processing this batch is:  0.0028901174664497375\n",
      "\n",
      "The classification loss after processing this batch is:  0.048917368054389954\n",
      "The representation loss after processing this batch is:  0.002802640199661255\n",
      "\n",
      "The classification loss after processing this batch is:  0.028483131900429726\n",
      "The representation loss after processing this batch is:  0.0025302916765213013\n",
      "\n",
      "The classification loss after processing this batch is:  0.014131482690572739\n",
      "The representation loss after processing this batch is:  0.002740636467933655\n",
      "\n",
      "The classification loss after processing this batch is:  0.02465859241783619\n",
      "The representation loss after processing this batch is:  0.0034938976168632507\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.07119815796613693\n",
      "The representation loss after processing this batch is:  0.003327496349811554\n",
      "\n",
      "The classification loss after processing this batch is:  0.008802135474979877\n",
      "The representation loss after processing this batch is:  0.003412485122680664\n",
      "\n",
      "The classification loss after processing this batch is:  0.02150244265794754\n",
      "The representation loss after processing this batch is:  0.002725452184677124\n",
      "\n",
      "The classification loss after processing this batch is:  0.15833038091659546\n",
      "The representation loss after processing this batch is:  0.002741590142250061\n",
      "\n",
      "The classification loss after processing this batch is:  0.019061842933297157\n",
      "The representation loss after processing this batch is:  0.003146544098854065\n",
      "\n",
      "The classification loss after processing this batch is:  0.008229604922235012\n",
      "The representation loss after processing this batch is:  0.0029346495866775513\n",
      "\n",
      "The classification loss after processing this batch is:  0.016462786123156548\n",
      "The representation loss after processing this batch is:  0.0027760565280914307\n",
      "\n",
      "The classification loss after processing this batch is:  0.01910206489264965\n",
      "The representation loss after processing this batch is:  0.0029045715928077698\n",
      "\n",
      "The classification loss after processing this batch is:  0.01578250713646412\n",
      "The representation loss after processing this batch is:  0.0030632242560386658\n",
      "\n",
      "The classification loss after processing this batch is:  0.01608080044388771\n",
      "The representation loss after processing this batch is:  0.003082275390625\n",
      "\n",
      "The classification loss after processing this batch is:  0.012618557550013065\n",
      "The representation loss after processing this batch is:  0.0031163617968559265\n",
      "\n",
      "The classification loss after processing this batch is:  0.13683804869651794\n",
      "The representation loss after processing this batch is:  0.0033774077892303467\n",
      "\n",
      "The classification loss after processing this batch is:  0.273478627204895\n",
      "The representation loss after processing this batch is:  0.00315123051404953\n",
      "\n",
      "The classification loss after processing this batch is:  0.16645781695842743\n",
      "The representation loss after processing this batch is:  0.0034911781549453735\n",
      "\n",
      "The classification loss after processing this batch is:  0.040950097143650055\n",
      "The representation loss after processing this batch is:  0.0026431679725646973\n",
      "\n",
      "The classification loss after processing this batch is:  0.012644966132938862\n",
      "The representation loss after processing this batch is:  0.003183230757713318\n",
      "\n",
      "The classification loss after processing this batch is:  0.013695033267140388\n",
      "The representation loss after processing this batch is:  0.0023711472749710083\n",
      "\n",
      "The classification loss after processing this batch is:  0.1333588808774948\n",
      "The representation loss after processing this batch is:  0.0021832063794136047\n",
      "\n",
      "The classification loss after processing this batch is:  0.30521681904792786\n",
      "The representation loss after processing this batch is:  0.002705998718738556\n",
      "\n",
      "The classification loss after processing this batch is:  0.043486956506967545\n",
      "The representation loss after processing this batch is:  0.002464786171913147\n",
      "\n",
      "The classification loss after processing this batch is:  0.03431849926710129\n",
      "The representation loss after processing this batch is:  0.0030677393078804016\n",
      "\n",
      "The classification loss after processing this batch is:  0.0295767430216074\n",
      "The representation loss after processing this batch is:  0.002938985824584961\n",
      "\n",
      "The classification loss after processing this batch is:  0.03707469254732132\n",
      "The representation loss after processing this batch is:  0.003317117691040039\n",
      "\n",
      "The classification loss after processing this batch is:  0.07776784896850586\n",
      "The representation loss after processing this batch is:  0.0024594515562057495\n",
      "\n",
      "The classification loss after processing this batch is:  0.036338865756988525\n",
      "The representation loss after processing this batch is:  0.002325601875782013\n",
      "\n",
      "The classification loss after processing this batch is:  0.06785915791988373\n",
      "The representation loss after processing this batch is:  0.0022761598229408264\n",
      "\n",
      "The classification loss after processing this batch is:  0.0905245915055275\n",
      "The representation loss after processing this batch is:  0.0021995045244693756\n",
      "\n",
      "The classification loss after processing this batch is:  0.07840954512357712\n",
      "The representation loss after processing this batch is:  0.0025542601943016052\n",
      "\n",
      "The classification loss after processing this batch is:  0.06686102598905563\n",
      "The representation loss after processing this batch is:  0.002594597637653351\n",
      "\n",
      "The classification loss after processing this batch is:  0.06358834356069565\n",
      "The representation loss after processing this batch is:  0.0025306865572929382\n",
      "\n",
      "The classification loss after processing this batch is:  0.09480132907629013\n",
      "The representation loss after processing this batch is:  0.0021624453365802765\n",
      "\n",
      "The classification loss after processing this batch is:  0.08297290652990341\n",
      "The representation loss after processing this batch is:  0.0022774524986743927\n",
      "\n",
      "The classification loss after processing this batch is:  0.056840308010578156\n",
      "The representation loss after processing this batch is:  0.002376880496740341\n",
      "\n",
      "The classification loss after processing this batch is:  0.10967275500297546\n",
      "The representation loss after processing this batch is:  0.002222824841737747\n",
      "\n",
      "The classification loss after processing this batch is:  0.11790447682142258\n",
      "The representation loss after processing this batch is:  0.0023115724325180054\n",
      "\n",
      "The classification loss after processing this batch is:  0.10288112610578537\n",
      "The representation loss after processing this batch is:  0.002842899411916733\n",
      "\n",
      "The classification loss after processing this batch is:  0.057355284690856934\n",
      "The representation loss after processing this batch is:  0.002387993037700653\n",
      "\n",
      "The classification loss after processing this batch is:  0.19825053215026855\n",
      "The representation loss after processing this batch is:  0.002216983586549759\n",
      "\n",
      "The classification loss after processing this batch is:  0.12317248433828354\n",
      "The representation loss after processing this batch is:  0.0021217018365859985\n",
      "\n",
      "The classification loss after processing this batch is:  0.07642724364995956\n",
      "The representation loss after processing this batch is:  0.0022221729159355164\n",
      "\n",
      "The classification loss after processing this batch is:  0.18550044298171997\n",
      "The representation loss after processing this batch is:  0.00237375870347023\n",
      "\n",
      "The classification loss after processing this batch is:  0.09085436165332794\n",
      "The representation loss after processing this batch is:  0.002442706376314163\n",
      "\n",
      "The classification loss after processing this batch is:  0.039357226341962814\n",
      "The representation loss after processing this batch is:  0.0024159178137779236\n",
      "\n",
      "The classification loss after processing this batch is:  0.1735495924949646\n",
      "The representation loss after processing this batch is:  0.002574913203716278\n",
      "\n",
      "The classification loss after processing this batch is:  0.07963689416646957\n",
      "The representation loss after processing this batch is:  0.002523675560951233\n",
      "\n",
      "The classification loss after processing this batch is:  0.22343036532402039\n",
      "The representation loss after processing this batch is:  0.002160586416721344\n",
      "\n",
      "The classification loss after processing this batch is:  0.06070380657911301\n",
      "The representation loss after processing this batch is:  0.0022411122918128967\n",
      "\n",
      "The classification loss after processing this batch is:  0.03863729164004326\n",
      "The representation loss after processing this batch is:  0.00243222713470459\n",
      "\n",
      "The classification loss after processing this batch is:  0.06471230089664459\n",
      "The representation loss after processing this batch is:  0.002176426351070404\n",
      "\n",
      "The classification loss after processing this batch is:  0.057545702904462814\n",
      "The representation loss after processing this batch is:  0.002079412341117859\n",
      "\n",
      "The classification loss after processing this batch is:  0.07150044292211533\n",
      "The representation loss after processing this batch is:  0.0023585110902786255\n",
      "\n",
      "The classification loss after processing this batch is:  0.03172249719500542\n",
      "The representation loss after processing this batch is:  0.0025076717138290405\n",
      "\n",
      "The classification loss after processing this batch is:  0.028709912672638893\n",
      "The representation loss after processing this batch is:  0.002395816147327423\n",
      "\n",
      "The classification loss after processing this batch is:  0.051274582743644714\n",
      "The representation loss after processing this batch is:  0.002486899495124817\n",
      "\n",
      "The classification loss after processing this batch is:  0.045135702937841415\n",
      "The representation loss after processing this batch is:  0.002675294876098633\n",
      "\n",
      "The classification loss after processing this batch is:  0.1412535309791565\n",
      "The representation loss after processing this batch is:  0.0023369193077087402\n",
      "\n",
      "The classification loss after processing this batch is:  0.05593922361731529\n",
      "The representation loss after processing this batch is:  0.0025635473430156708\n",
      "\n",
      "The classification loss after processing this batch is:  0.07289943099021912\n",
      "The representation loss after processing this batch is:  0.00208301842212677\n",
      "\n",
      "The classification loss after processing this batch is:  0.023333748802542686\n",
      "The representation loss after processing this batch is:  0.0024212226271629333\n",
      "\n",
      "The classification loss after processing this batch is:  0.03586752340197563\n",
      "The representation loss after processing this batch is:  0.00258738175034523\n",
      "\n",
      "The classification loss after processing this batch is:  0.06885216385126114\n",
      "The representation loss after processing this batch is:  0.0022428594529628754\n",
      "\n",
      "The classification loss after processing this batch is:  0.06864530593156815\n",
      "The representation loss after processing this batch is:  0.002647966146469116\n",
      "\n",
      "The classification loss after processing this batch is:  0.045266348868608475\n",
      "The representation loss after processing this batch is:  0.0023490265011787415\n",
      "\n",
      "The classification loss after processing this batch is:  0.12185081094503403\n",
      "The representation loss after processing this batch is:  0.0024184733629226685\n",
      "\n",
      "The classification loss after processing this batch is:  0.0698968693614006\n",
      "The representation loss after processing this batch is:  0.0023487284779548645\n",
      "\n",
      "The classification loss after processing this batch is:  0.05085137113928795\n",
      "The representation loss after processing this batch is:  0.0022921860218048096\n",
      "\n",
      "The classification loss after processing this batch is:  0.1367332488298416\n",
      "The representation loss after processing this batch is:  0.002479657530784607\n",
      "\n",
      "The classification loss after processing this batch is:  0.04279714077711105\n",
      "The representation loss after processing this batch is:  0.002239920198917389\n",
      "\n",
      "The classification loss after processing this batch is:  0.06537909805774689\n",
      "The representation loss after processing this batch is:  0.0023020952939987183\n",
      "\n",
      "The classification loss after processing this batch is:  0.17027685046195984\n",
      "The representation loss after processing this batch is:  0.0027241967618465424\n",
      "\n",
      "The classification loss after processing this batch is:  0.03277505561709404\n",
      "The representation loss after processing this batch is:  0.0023398101329803467\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1103864461183548\n",
      "The representation loss after processing this batch is:  0.002283446490764618\n",
      "\n",
      "The classification loss after processing this batch is:  0.06354067474603653\n",
      "The representation loss after processing this batch is:  0.002250097692012787\n",
      "\n",
      "The classification loss after processing this batch is:  0.06426025182008743\n",
      "The representation loss after processing this batch is:  0.002287875860929489\n",
      "\n",
      "The classification loss after processing this batch is:  0.06894928961992264\n",
      "The representation loss after processing this batch is:  0.0022543445229530334\n",
      "\n",
      "The classification loss after processing this batch is:  0.0360892228782177\n",
      "The representation loss after processing this batch is:  0.002451881766319275\n",
      "\n",
      "The classification loss after processing this batch is:  0.13539616763591766\n",
      "The representation loss after processing this batch is:  0.002587929368019104\n",
      "\n",
      "The classification loss after processing this batch is:  0.08650460094213486\n",
      "The representation loss after processing this batch is:  0.0025265365839004517\n",
      "\n",
      "The classification loss after processing this batch is:  0.09306304156780243\n",
      "The representation loss after processing this batch is:  0.0024211108684539795\n",
      "\n",
      "The classification loss after processing this batch is:  0.09127270430326462\n",
      "The representation loss after processing this batch is:  0.0022392570972442627\n",
      "\n",
      "The classification loss after processing this batch is:  0.10597164183855057\n",
      "The representation loss after processing this batch is:  0.002442978322505951\n",
      "\n",
      "The classification loss after processing this batch is:  0.09700893610715866\n",
      "The representation loss after processing this batch is:  0.002359554171562195\n",
      "\n",
      "The classification loss after processing this batch is:  0.06776590645313263\n",
      "The representation loss after processing this batch is:  0.002235710620880127\n",
      "\n",
      "The classification loss after processing this batch is:  0.05553757771849632\n",
      "The representation loss after processing this batch is:  0.0022468119859695435\n",
      "\n",
      "The classification loss after processing this batch is:  0.13973955810070038\n",
      "The representation loss after processing this batch is:  0.0023484118282794952\n",
      "\n",
      "The classification loss after processing this batch is:  0.11294804513454437\n",
      "The representation loss after processing this batch is:  0.0023813769221305847\n",
      "\n",
      "The classification loss after processing this batch is:  0.048471156507730484\n",
      "The representation loss after processing this batch is:  0.0023064054548740387\n",
      "\n",
      "The classification loss after processing this batch is:  0.05213450640439987\n",
      "The representation loss after processing this batch is:  0.0022764354944229126\n",
      "\n",
      "The classification loss after processing this batch is:  0.04378430172801018\n",
      "The representation loss after processing this batch is:  0.0023163817822933197\n",
      "\n",
      "The classification loss after processing this batch is:  0.05049687996506691\n",
      "The representation loss after processing this batch is:  0.002531088888645172\n",
      "\n",
      "The classification loss after processing this batch is:  0.11666083335876465\n",
      "The representation loss after processing this batch is:  0.0020463578402996063\n",
      "\n",
      "The classification loss after processing this batch is:  0.061254408210515976\n",
      "The representation loss after processing this batch is:  0.002201661467552185\n",
      "\n",
      "The classification loss after processing this batch is:  0.15889181196689606\n",
      "The representation loss after processing this batch is:  0.002320762723684311\n",
      "\n",
      "The classification loss after processing this batch is:  0.10722672194242477\n",
      "The representation loss after processing this batch is:  0.0022628270089626312\n",
      "\n",
      "The classification loss after processing this batch is:  0.09503122419118881\n",
      "The representation loss after processing this batch is:  0.0022107958793640137\n",
      "\n",
      "The classification loss after processing this batch is:  0.06173389032483101\n",
      "The representation loss after processing this batch is:  0.0019509084522724152\n",
      "\n",
      "The classification loss after processing this batch is:  0.04814161732792854\n",
      "The representation loss after processing this batch is:  0.0024875104427337646\n",
      "\n",
      "The classification loss after processing this batch is:  0.07090038806200027\n",
      "The representation loss after processing this batch is:  0.0020610131323337555\n",
      "\n",
      "The classification loss after processing this batch is:  0.14231856167316437\n",
      "The representation loss after processing this batch is:  0.002085469663143158\n",
      "\n",
      "The classification loss after processing this batch is:  0.0591416135430336\n",
      "The representation loss after processing this batch is:  0.002178087830543518\n",
      "\n",
      "The classification loss after processing this batch is:  0.244278684258461\n",
      "The representation loss after processing this batch is:  0.002150021493434906\n",
      "\n",
      "The classification loss after processing this batch is:  0.07708636671304703\n",
      "The representation loss after processing this batch is:  0.0021619386970996857\n",
      "\n",
      "The classification loss after processing this batch is:  0.04410212114453316\n",
      "The representation loss after processing this batch is:  0.0028655454516410828\n",
      "\n",
      "The classification loss after processing this batch is:  0.12418172508478165\n",
      "The representation loss after processing this batch is:  0.00237390398979187\n",
      "\n",
      "The classification loss after processing this batch is:  0.039474114775657654\n",
      "The representation loss after processing this batch is:  0.00254957377910614\n",
      "\n",
      "The classification loss after processing this batch is:  0.2265319526195526\n",
      "The representation loss after processing this batch is:  0.002576589584350586\n",
      "\n",
      "The classification loss after processing this batch is:  0.09638439118862152\n",
      "The representation loss after processing this batch is:  0.002168431878089905\n",
      "\n",
      "The classification loss after processing this batch is:  0.15751226246356964\n",
      "The representation loss after processing this batch is:  0.0023367777466773987\n",
      "\n",
      "The classification loss after processing this batch is:  0.17748168110847473\n",
      "The representation loss after processing this batch is:  0.002298343926668167\n",
      "\n",
      "The classification loss after processing this batch is:  0.11489324271678925\n",
      "The representation loss after processing this batch is:  0.002045862376689911\n",
      "\n",
      "The classification loss after processing this batch is:  0.03977762535214424\n",
      "The representation loss after processing this batch is:  0.002306506037712097\n",
      "\n",
      "The classification loss after processing this batch is:  0.10850298404693604\n",
      "The representation loss after processing this batch is:  0.002251211553812027\n",
      "\n",
      "The classification loss after processing this batch is:  0.0760786235332489\n",
      "The representation loss after processing this batch is:  0.0023663491010665894\n",
      "\n",
      "The classification loss after processing this batch is:  0.10087933391332626\n",
      "The representation loss after processing this batch is:  0.002370458096265793\n",
      "\n",
      "The classification loss after processing this batch is:  0.05602894723415375\n",
      "The representation loss after processing this batch is:  0.0021890029311180115\n",
      "\n",
      "The classification loss after processing this batch is:  0.06887567788362503\n",
      "The representation loss after processing this batch is:  0.0022768229246139526\n",
      "\n",
      "The classification loss after processing this batch is:  0.13821588456630707\n",
      "The representation loss after processing this batch is:  0.0024051740765571594\n",
      "\n",
      "The classification loss after processing this batch is:  0.11432182043790817\n",
      "The representation loss after processing this batch is:  0.0025624483823776245\n",
      "\n",
      "The classification loss after processing this batch is:  0.146214559674263\n",
      "The representation loss after processing this batch is:  0.002140183001756668\n",
      "\n",
      "The classification loss after processing this batch is:  0.1856483668088913\n",
      "The representation loss after processing this batch is:  0.002643488347530365\n",
      "\n",
      "The classification loss after processing this batch is:  0.1040685847401619\n",
      "The representation loss after processing this batch is:  0.002525709569454193\n",
      "\n",
      "The classification loss after processing this batch is:  0.05003710836172104\n",
      "The representation loss after processing this batch is:  0.0024796202778816223\n",
      "\n",
      "The classification loss after processing this batch is:  0.05286358296871185\n",
      "The representation loss after processing this batch is:  0.0023541226983070374\n",
      "\n",
      "The classification loss after processing this batch is:  0.02782919444143772\n",
      "The representation loss after processing this batch is:  0.0023649483919143677\n",
      "\n",
      "The classification loss after processing this batch is:  0.099303238093853\n",
      "The representation loss after processing this batch is:  0.0024555474519729614\n",
      "\n",
      "The classification loss after processing this batch is:  0.0813746452331543\n",
      "The representation loss after processing this batch is:  0.0024597272276878357\n",
      "\n",
      "The classification loss after processing this batch is:  0.2223363220691681\n",
      "The representation loss after processing this batch is:  0.0024530217051506042\n",
      "\n",
      "The classification loss after processing this batch is:  0.22524748742580414\n",
      "The representation loss after processing this batch is:  0.0024109184741973877\n",
      "\n",
      "The classification loss after processing this batch is:  0.05913675203919411\n",
      "The representation loss after processing this batch is:  0.00260944664478302\n",
      "\n",
      "The classification loss after processing this batch is:  0.07833738625049591\n",
      "The representation loss after processing this batch is:  0.0026729777455329895\n",
      "\n",
      "The classification loss after processing this batch is:  0.12038949131965637\n",
      "The representation loss after processing this batch is:  0.002103060483932495\n",
      "\n",
      "The classification loss after processing this batch is:  0.038295846432447433\n",
      "The representation loss after processing this batch is:  0.00252474844455719\n",
      "\n",
      "The classification loss after processing this batch is:  0.039513107389211655\n",
      "The representation loss after processing this batch is:  0.0024622157216072083\n",
      "\n",
      "The classification loss after processing this batch is:  0.10260637104511261\n",
      "The representation loss after processing this batch is:  0.0021871328353881836\n",
      "\n",
      "The classification loss after processing this batch is:  0.057113051414489746\n",
      "The representation loss after processing this batch is:  0.002914145588874817\n",
      "\n",
      "The classification loss after processing this batch is:  0.07740245759487152\n",
      "The representation loss after processing this batch is:  0.0026788152754306793\n",
      "\n",
      "The classification loss after processing this batch is:  0.18174085021018982\n",
      "The representation loss after processing this batch is:  0.0031718909740448\n",
      "\n",
      "The classification loss after processing this batch is:  0.205078125\n",
      "The representation loss after processing this batch is:  0.002088073641061783\n",
      "\n",
      "The classification loss after processing this batch is:  0.06693477928638458\n",
      "The representation loss after processing this batch is:  0.0026402249932289124\n",
      "\n",
      "The classification loss after processing this batch is:  0.1436181664466858\n",
      "The representation loss after processing this batch is:  0.0024385452270507812\n",
      "\n",
      "The classification loss after processing this batch is:  0.1491275280714035\n",
      "The representation loss after processing this batch is:  0.002244226634502411\n",
      "\n",
      "The classification loss after processing this batch is:  0.04803936183452606\n",
      "The representation loss after processing this batch is:  0.0022949539124965668\n",
      "\n",
      "The classification loss after processing this batch is:  0.08701972663402557\n",
      "The representation loss after processing this batch is:  0.002164918929338455\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.35842952132225037\n",
      "The representation loss after processing this batch is:  0.002894662320613861\n",
      "\n",
      "The classification loss after processing this batch is:  0.11860097944736481\n",
      "The representation loss after processing this batch is:  0.00258641317486763\n",
      "\n",
      "The classification loss after processing this batch is:  0.038026388734579086\n",
      "The representation loss after processing this batch is:  0.0026391446590423584\n",
      "\n",
      "The classification loss after processing this batch is:  0.03737831115722656\n",
      "The representation loss after processing this batch is:  0.0026706866919994354\n",
      "\n",
      "The classification loss after processing this batch is:  0.0437491312623024\n",
      "The representation loss after processing this batch is:  0.002627141773700714\n",
      "\n",
      "The classification loss after processing this batch is:  0.07106590270996094\n",
      "The representation loss after processing this batch is:  0.0025198832154273987\n",
      "\n",
      "The classification loss after processing this batch is:  0.05158904567360878\n",
      "The representation loss after processing this batch is:  0.0026098787784576416\n",
      "\n",
      "The classification loss after processing this batch is:  0.10479415208101273\n",
      "The representation loss after processing this batch is:  0.002273302525281906\n",
      "\n",
      "The classification loss after processing this batch is:  0.08025100082159042\n",
      "The representation loss after processing this batch is:  0.0022521689534187317\n",
      "\n",
      "The classification loss after processing this batch is:  0.14650146663188934\n",
      "The representation loss after processing this batch is:  0.0022431612014770508\n",
      "\n",
      "The classification loss after processing this batch is:  0.06456565111875534\n",
      "The representation loss after processing this batch is:  0.002067107707262039\n",
      "\n",
      "The classification loss after processing this batch is:  0.08200833201408386\n",
      "The representation loss after processing this batch is:  0.002167385071516037\n",
      "\n",
      "The classification loss after processing this batch is:  0.11168861389160156\n",
      "The representation loss after processing this batch is:  0.0023559853434562683\n",
      "\n",
      "The classification loss after processing this batch is:  0.10734249651432037\n",
      "The representation loss after processing this batch is:  0.002405446022748947\n",
      "\n",
      "The classification loss after processing this batch is:  0.06726871430873871\n",
      "The representation loss after processing this batch is:  0.0021938905119895935\n",
      "\n",
      "The classification loss after processing this batch is:  0.13263076543807983\n",
      "The representation loss after processing this batch is:  0.0021624043583869934\n",
      "\n",
      "The classification loss after processing this batch is:  0.14241038262844086\n",
      "The representation loss after processing this batch is:  0.002339594066143036\n",
      "\n",
      "The classification loss after processing this batch is:  0.11405182629823685\n",
      "The representation loss after processing this batch is:  0.0022608190774917603\n",
      "\n",
      "The classification loss after processing this batch is:  0.1012076586484909\n",
      "The representation loss after processing this batch is:  0.0025691837072372437\n",
      "\n",
      "The classification loss after processing this batch is:  0.17014768719673157\n",
      "The representation loss after processing this batch is:  0.0024032294750213623\n",
      "\n",
      "The classification loss after processing this batch is:  0.16862453520298004\n",
      "The representation loss after processing this batch is:  0.002568315714597702\n",
      "\n",
      "The classification loss after processing this batch is:  0.12492623180150986\n",
      "The representation loss after processing this batch is:  0.0025214776396751404\n",
      "\n",
      "The classification loss after processing this batch is:  0.06960638612508774\n",
      "The representation loss after processing this batch is:  0.002623036503791809\n",
      "\n",
      "The classification loss after processing this batch is:  0.06154053285717964\n",
      "The representation loss after processing this batch is:  0.002598874270915985\n",
      "\n",
      "The classification loss after processing this batch is:  0.205938920378685\n",
      "The representation loss after processing this batch is:  0.0022643283009529114\n",
      "\n",
      "The classification loss after processing this batch is:  0.13590119779109955\n",
      "The representation loss after processing this batch is:  0.0021533221006393433\n",
      "\n",
      "The classification loss after processing this batch is:  0.24419714510440826\n",
      "The representation loss after processing this batch is:  0.0023912861943244934\n",
      "\n",
      "The classification loss after processing this batch is:  0.26245853304862976\n",
      "The representation loss after processing this batch is:  0.002229735255241394\n",
      "\n",
      "The classification loss after processing this batch is:  0.13144145905971527\n",
      "The representation loss after processing this batch is:  0.002119738608598709\n",
      "\n",
      "The classification loss after processing this batch is:  0.06936901062726974\n",
      "The representation loss after processing this batch is:  0.002239428460597992\n",
      "\n",
      "The classification loss after processing this batch is:  0.053608935326337814\n",
      "The representation loss after processing this batch is:  0.0021349117159843445\n",
      "\n",
      "The classification loss after processing this batch is:  0.04200315102934837\n",
      "The representation loss after processing this batch is:  0.00267704576253891\n",
      "\n",
      "The classification loss after processing this batch is:  0.08150132745504379\n",
      "The representation loss after processing this batch is:  0.002940751612186432\n",
      "\n",
      "The classification loss after processing this batch is:  0.03981674835085869\n",
      "The representation loss after processing this batch is:  0.0024271160364151\n",
      "\n",
      "The classification loss after processing this batch is:  0.19502057135105133\n",
      "The representation loss after processing this batch is:  0.003291316330432892\n",
      "\n",
      "The classification loss after processing this batch is:  0.08809665590524673\n",
      "The representation loss after processing this batch is:  0.0024851448833942413\n",
      "\n",
      "The classification loss after processing this batch is:  0.06255577504634857\n",
      "The representation loss after processing this batch is:  0.002525072544813156\n",
      "\n",
      "The classification loss after processing this batch is:  0.14534921944141388\n",
      "The representation loss after processing this batch is:  0.00224284827709198\n",
      "\n",
      "The classification loss after processing this batch is:  0.056764449924230576\n",
      "The representation loss after processing this batch is:  0.002698168158531189\n",
      "\n",
      "The classification loss after processing this batch is:  0.05052129924297333\n",
      "The representation loss after processing this batch is:  0.0031390562653541565\n",
      "\n",
      "The classification loss after processing this batch is:  0.23516517877578735\n",
      "The representation loss after processing this batch is:  0.0030305683612823486\n",
      "\n",
      "The classification loss after processing this batch is:  0.09926814585924149\n",
      "The representation loss after processing this batch is:  0.002698175609111786\n",
      "\n",
      "The classification loss after processing this batch is:  0.1068134605884552\n",
      "The representation loss after processing this batch is:  0.0022725798189640045\n",
      "\n",
      "The classification loss after processing this batch is:  0.041055310517549515\n",
      "The representation loss after processing this batch is:  0.0021559149026870728\n",
      "\n",
      "The classification loss after processing this batch is:  0.015414523892104626\n",
      "The representation loss after processing this batch is:  0.0025802478194236755\n",
      "\n",
      "The classification loss after processing this batch is:  0.04286777973175049\n",
      "The representation loss after processing this batch is:  0.0027197524905204773\n",
      "\n",
      "The classification loss after processing this batch is:  0.046532969921827316\n",
      "The representation loss after processing this batch is:  0.0022778846323490143\n",
      "\n",
      "The classification loss after processing this batch is:  0.07564046233892441\n",
      "The representation loss after processing this batch is:  0.002274703234434128\n",
      "\n",
      "The classification loss after processing this batch is:  0.07120974361896515\n",
      "The representation loss after processing this batch is:  0.002487778663635254\n",
      "\n",
      "The classification loss after processing this batch is:  0.07174647599458694\n",
      "The representation loss after processing this batch is:  0.0024094581604003906\n",
      "\n",
      "The classification loss after processing this batch is:  0.23815253376960754\n",
      "The representation loss after processing this batch is:  0.0026067793369293213\n",
      "\n",
      "The classification loss after processing this batch is:  0.162711039185524\n",
      "The representation loss after processing this batch is:  0.0025995001196861267\n",
      "\n",
      "The classification loss after processing this batch is:  0.06031915917992592\n",
      "The representation loss after processing this batch is:  0.002330988645553589\n",
      "\n",
      "The classification loss after processing this batch is:  0.047817859798669815\n",
      "The representation loss after processing this batch is:  0.0027071386575698853\n",
      "\n",
      "The classification loss after processing this batch is:  0.07161173224449158\n",
      "The representation loss after processing this batch is:  0.00244266539812088\n",
      "\n",
      "The classification loss after processing this batch is:  0.057805124670267105\n",
      "The representation loss after processing this batch is:  0.002581872045993805\n",
      "\n",
      "The classification loss after processing this batch is:  0.019303567707538605\n",
      "The representation loss after processing this batch is:  0.002330563962459564\n",
      "\n",
      "The classification loss after processing this batch is:  0.030079420655965805\n",
      "The representation loss after processing this batch is:  0.002390991896390915\n",
      "\n",
      "The classification loss after processing this batch is:  0.07100732624530792\n",
      "The representation loss after processing this batch is:  0.0021438375115394592\n",
      "\n",
      "The classification loss after processing this batch is:  0.0822906494140625\n",
      "The representation loss after processing this batch is:  0.002179838716983795\n",
      "\n",
      "The classification loss after processing this batch is:  0.0759676992893219\n",
      "The representation loss after processing this batch is:  0.002559840679168701\n",
      "\n",
      "The classification loss after processing this batch is:  0.04738452658057213\n",
      "The representation loss after processing this batch is:  0.002370297908782959\n",
      "\n",
      "The classification loss after processing this batch is:  0.04489070922136307\n",
      "The representation loss after processing this batch is:  0.002325192093849182\n",
      "\n",
      "The classification loss after processing this batch is:  0.22896139323711395\n",
      "The representation loss after processing this batch is:  0.002218257635831833\n",
      "\n",
      "The classification loss after processing this batch is:  0.08646655082702637\n",
      "The representation loss after processing this batch is:  0.002372957766056061\n",
      "\n",
      "The classification loss after processing this batch is:  0.029817381873726845\n",
      "The representation loss after processing this batch is:  0.002453714609146118\n",
      "\n",
      "The classification loss after processing this batch is:  0.07834316045045853\n",
      "The representation loss after processing this batch is:  0.002447456121444702\n",
      "\n",
      "The classification loss after processing this batch is:  0.06819339096546173\n",
      "The representation loss after processing this batch is:  0.002102341502904892\n",
      "\n",
      "The classification loss after processing this batch is:  0.03776473179459572\n",
      "The representation loss after processing this batch is:  0.002193290740251541\n",
      "\n",
      "The classification loss after processing this batch is:  0.09921668469905853\n",
      "The representation loss after processing this batch is:  0.0022302307188510895\n",
      "\n",
      "The classification loss after processing this batch is:  0.049247123301029205\n",
      "The representation loss after processing this batch is:  0.0021985918283462524\n",
      "\n",
      "The classification loss after processing this batch is:  0.04885692894458771\n",
      "The representation loss after processing this batch is:  0.0024021565914154053\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08303363621234894\n",
      "The representation loss after processing this batch is:  0.0020363032817840576\n",
      "\n",
      "The classification loss after processing this batch is:  0.12760834395885468\n",
      "The representation loss after processing this batch is:  0.0024205297231674194\n",
      "\n",
      "The classification loss after processing this batch is:  0.09628277271986008\n",
      "The representation loss after processing this batch is:  0.0024677589535713196\n",
      "\n",
      "The classification loss after processing this batch is:  0.10575879365205765\n",
      "The representation loss after processing this batch is:  0.00214487686753273\n",
      "\n",
      "The classification loss after processing this batch is:  0.08278970420360565\n",
      "The representation loss after processing this batch is:  0.0023449771106243134\n",
      "\n",
      "The classification loss after processing this batch is:  0.15636049211025238\n",
      "The representation loss after processing this batch is:  0.002266034483909607\n",
      "\n",
      "The classification loss after processing this batch is:  0.057381752878427505\n",
      "The representation loss after processing this batch is:  0.0025715455412864685\n",
      "\n",
      "The classification loss after processing this batch is:  0.1035308837890625\n",
      "The representation loss after processing this batch is:  0.002205498516559601\n",
      "\n",
      "The classification loss after processing this batch is:  0.0546659417450428\n",
      "The representation loss after processing this batch is:  0.00222662091255188\n",
      "\n",
      "The classification loss after processing this batch is:  0.18007595837116241\n",
      "The representation loss after processing this batch is:  0.0022680312395095825\n",
      "\n",
      "The classification loss after processing this batch is:  0.08531667292118073\n",
      "The representation loss after processing this batch is:  0.0024179667234420776\n",
      "\n",
      "The classification loss after processing this batch is:  0.11803781986236572\n",
      "The representation loss after processing this batch is:  0.0021840371191501617\n",
      "\n",
      "The classification loss after processing this batch is:  0.0751008614897728\n",
      "The representation loss after processing this batch is:  0.0022405683994293213\n",
      "\n",
      "The classification loss after processing this batch is:  0.07240156084299088\n",
      "The representation loss after processing this batch is:  0.0023385658860206604\n",
      "\n",
      "The classification loss after processing this batch is:  0.11801623553037643\n",
      "The representation loss after processing this batch is:  0.002203740179538727\n",
      "\n",
      "The classification loss after processing this batch is:  0.06034431234002113\n",
      "The representation loss after processing this batch is:  0.0020887590944767\n",
      "\n",
      "The classification loss after processing this batch is:  0.10237764567136765\n",
      "The representation loss after processing this batch is:  0.002313874661922455\n",
      "\n",
      "The classification loss after processing this batch is:  0.172905832529068\n",
      "The representation loss after processing this batch is:  0.0022384487092494965\n",
      "\n",
      "The classification loss after processing this batch is:  0.17865726351737976\n",
      "The representation loss after processing this batch is:  0.0020591579377651215\n",
      "\n",
      "The classification loss after processing this batch is:  0.12452403455972672\n",
      "The representation loss after processing this batch is:  0.002256777137517929\n",
      "\n",
      "The classification loss after processing this batch is:  0.059780072420835495\n",
      "The representation loss after processing this batch is:  0.00240408256649971\n",
      "\n",
      "The classification loss after processing this batch is:  0.15518411993980408\n",
      "The representation loss after processing this batch is:  0.002500958740711212\n",
      "\n",
      "The classification loss after processing this batch is:  0.08482354134321213\n",
      "The representation loss after processing this batch is:  0.0026027485728263855\n",
      "\n",
      "The classification loss after processing this batch is:  0.06254813820123672\n",
      "The representation loss after processing this batch is:  0.0024449974298477173\n",
      "\n",
      "The classification loss after processing this batch is:  0.12735004723072052\n",
      "The representation loss after processing this batch is:  0.0027140751481056213\n",
      "\n",
      "The classification loss after processing this batch is:  0.1653071939945221\n",
      "The representation loss after processing this batch is:  0.0023409202694892883\n",
      "\n",
      "The classification loss after processing this batch is:  0.2322692573070526\n",
      "The representation loss after processing this batch is:  0.002196364104747772\n",
      "\n",
      "The classification loss after processing this batch is:  0.10689972341060638\n",
      "The representation loss after processing this batch is:  0.0025068670511245728\n",
      "\n",
      "The classification loss after processing this batch is:  0.0583370104432106\n",
      "The representation loss after processing this batch is:  0.002355959266424179\n",
      "\n",
      "The classification loss after processing this batch is:  0.08842179924249649\n",
      "The representation loss after processing this batch is:  0.0024946704506874084\n",
      "\n",
      "The classification loss after processing this batch is:  0.15654638409614563\n",
      "The representation loss after processing this batch is:  0.0022263377904891968\n",
      "\n",
      "The classification loss after processing this batch is:  0.08132711797952652\n",
      "The representation loss after processing this batch is:  0.0024002492427825928\n",
      "\n",
      "The classification loss after processing this batch is:  0.10949800163507462\n",
      "The representation loss after processing this batch is:  0.002291884273290634\n",
      "\n",
      "The classification loss after processing this batch is:  0.10118154436349869\n",
      "The representation loss after processing this batch is:  0.0022793859243392944\n",
      "\n",
      "The classification loss after processing this batch is:  0.021026158705353737\n",
      "The representation loss after processing this batch is:  0.0023873373866081238\n",
      "\n",
      "The classification loss after processing this batch is:  0.06751875579357147\n",
      "The representation loss after processing this batch is:  0.0024980008602142334\n",
      "\n",
      "The classification loss after processing this batch is:  0.10435482114553452\n",
      "The representation loss after processing this batch is:  0.002610068768262863\n",
      "\n",
      "The classification loss after processing this batch is:  0.10638216137886047\n",
      "The representation loss after processing this batch is:  0.002350594848394394\n",
      "\n",
      "The classification loss after processing this batch is:  0.09535931795835495\n",
      "The representation loss after processing this batch is:  0.0022571496665477753\n",
      "\n",
      "The classification loss after processing this batch is:  0.0874815359711647\n",
      "The representation loss after processing this batch is:  0.002387702465057373\n",
      "\n",
      "The classification loss after processing this batch is:  0.12393058091402054\n",
      "The representation loss after processing this batch is:  0.002610154449939728\n",
      "\n",
      "The classification loss after processing this batch is:  0.06048977002501488\n",
      "The representation loss after processing this batch is:  0.00252470001578331\n",
      "\n",
      "The classification loss after processing this batch is:  0.08575411885976791\n",
      "The representation loss after processing this batch is:  0.002754978835582733\n",
      "\n",
      "The classification loss after processing this batch is:  0.08584227412939072\n",
      "The representation loss after processing this batch is:  0.0026173964142799377\n",
      "\n",
      "The classification loss after processing this batch is:  0.1036720797419548\n",
      "The representation loss after processing this batch is:  0.002448625862598419\n",
      "\n",
      "The classification loss after processing this batch is:  0.12654821574687958\n",
      "The representation loss after processing this batch is:  0.0022287070751190186\n",
      "\n",
      "The classification loss after processing this batch is:  0.1886308640241623\n",
      "The representation loss after processing this batch is:  0.0022102929651737213\n",
      "\n",
      "The classification loss after processing this batch is:  0.2115914523601532\n",
      "The representation loss after processing this batch is:  0.0023367926478385925\n",
      "\n",
      "The classification loss after processing this batch is:  0.04280642792582512\n",
      "The representation loss after processing this batch is:  0.0021560117602348328\n",
      "\n",
      "The classification loss after processing this batch is:  0.08453543484210968\n",
      "The representation loss after processing this batch is:  0.002636454999446869\n",
      "\n",
      "The classification loss after processing this batch is:  0.09459329396486282\n",
      "The representation loss after processing this batch is:  0.002421099692583084\n",
      "\n",
      "The classification loss after processing this batch is:  0.10858621448278427\n",
      "The representation loss after processing this batch is:  0.0022049136459827423\n",
      "\n",
      "The classification loss after processing this batch is:  0.18161030113697052\n",
      "The representation loss after processing this batch is:  0.0025065913796424866\n",
      "\n",
      "The classification loss after processing this batch is:  0.15668335556983948\n",
      "The representation loss after processing this batch is:  0.002695612609386444\n",
      "\n",
      "The classification loss after processing this batch is:  0.1602145880460739\n",
      "The representation loss after processing this batch is:  0.0028178244829177856\n",
      "\n",
      "The classification loss after processing this batch is:  0.0801798403263092\n",
      "The representation loss after processing this batch is:  0.002589002251625061\n",
      "\n",
      "The classification loss after processing this batch is:  0.1210358589887619\n",
      "The representation loss after processing this batch is:  0.0025199726223945618\n",
      "\n",
      "The classification loss after processing this batch is:  0.1525510847568512\n",
      "The representation loss after processing this batch is:  0.002921782433986664\n",
      "\n",
      "The classification loss after processing this batch is:  0.037068840116262436\n",
      "The representation loss after processing this batch is:  0.0024073123931884766\n",
      "\n",
      "The classification loss after processing this batch is:  0.1752951741218567\n",
      "The representation loss after processing this batch is:  0.0025577768683433533\n",
      "\n",
      "The classification loss after processing this batch is:  0.08437526971101761\n",
      "The representation loss after processing this batch is:  0.002178199589252472\n",
      "\n",
      "The classification loss after processing this batch is:  0.035305652767419815\n",
      "The representation loss after processing this batch is:  0.0021828189492225647\n",
      "\n",
      "The classification loss after processing this batch is:  0.09160963445901871\n",
      "The representation loss after processing this batch is:  0.002226322889328003\n",
      "\n",
      "The classification loss after processing this batch is:  0.10071118175983429\n",
      "The representation loss after processing this batch is:  0.0027462244033813477\n",
      "\n",
      "The classification loss after processing this batch is:  0.1447894424200058\n",
      "The representation loss after processing this batch is:  0.0021758191287517548\n",
      "\n",
      "The classification loss after processing this batch is:  0.061049290001392365\n",
      "The representation loss after processing this batch is:  0.0023622512817382812\n",
      "\n",
      "The classification loss after processing this batch is:  0.05588852986693382\n",
      "The representation loss after processing this batch is:  0.002232559025287628\n",
      "\n",
      "The classification loss after processing this batch is:  0.02878679521381855\n",
      "The representation loss after processing this batch is:  0.002260766923427582\n",
      "\n",
      "The classification loss after processing this batch is:  0.1406094878911972\n",
      "The representation loss after processing this batch is:  0.0020308904349803925\n",
      "\n",
      "The classification loss after processing this batch is:  0.07771813869476318\n",
      "The representation loss after processing this batch is:  0.0020253919064998627\n",
      "\n",
      "The classification loss after processing this batch is:  0.34825336933135986\n",
      "The representation loss after processing this batch is:  0.002470739185810089\n",
      "\n",
      "The classification loss after processing this batch is:  0.08121432363986969\n",
      "The representation loss after processing this batch is:  0.0023561716079711914\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1560085266828537\n",
      "The representation loss after processing this batch is:  0.00219060480594635\n",
      "\n",
      "The classification loss after processing this batch is:  0.2063646763563156\n",
      "The representation loss after processing this batch is:  0.002423122525215149\n",
      "\n",
      "The classification loss after processing this batch is:  0.05486217513680458\n",
      "The representation loss after processing this batch is:  0.0022709667682647705\n",
      "\n",
      "The classification loss after processing this batch is:  0.19370515644550323\n",
      "The representation loss after processing this batch is:  0.00252552330493927\n",
      "\n",
      "The classification loss after processing this batch is:  0.10811055451631546\n",
      "The representation loss after processing this batch is:  0.002531498670578003\n",
      "\n",
      "The classification loss after processing this batch is:  0.21878477931022644\n",
      "The representation loss after processing this batch is:  0.002066519111394882\n",
      "\n",
      "The classification loss after processing this batch is:  0.04006770998239517\n",
      "The representation loss after processing this batch is:  0.002102777361869812\n",
      "\n",
      "The classification loss after processing this batch is:  0.0852966159582138\n",
      "The representation loss after processing this batch is:  0.002429381012916565\n",
      "\n",
      "The classification loss after processing this batch is:  0.02614235132932663\n",
      "The representation loss after processing this batch is:  0.002380847930908203\n",
      "\n",
      "The classification loss after processing this batch is:  0.021706024184823036\n",
      "The representation loss after processing this batch is:  0.002472825348377228\n",
      "\n",
      "The classification loss after processing this batch is:  0.04712560027837753\n",
      "The representation loss after processing this batch is:  0.0022421032190322876\n",
      "\n",
      "The classification loss after processing this batch is:  0.03876978158950806\n",
      "The representation loss after processing this batch is:  0.0021935924887657166\n",
      "\n",
      "The classification loss after processing this batch is:  0.11659492552280426\n",
      "The representation loss after processing this batch is:  0.0025202184915542603\n",
      "\n",
      "The classification loss after processing this batch is:  0.07170868664979935\n",
      "The representation loss after processing this batch is:  0.0027258098125457764\n",
      "\n",
      "The classification loss after processing this batch is:  0.05559184029698372\n",
      "The representation loss after processing this batch is:  0.0022752955555915833\n",
      "\n",
      "The classification loss after processing this batch is:  0.10576560348272324\n",
      "The representation loss after processing this batch is:  0.00209629163146019\n",
      "\n",
      "The classification loss after processing this batch is:  0.045339956879615784\n",
      "The representation loss after processing this batch is:  0.0026908814907073975\n",
      "\n",
      "The classification loss after processing this batch is:  0.08626358211040497\n",
      "The representation loss after processing this batch is:  0.002518564462661743\n",
      "\n",
      "The classification loss after processing this batch is:  0.09827961772680283\n",
      "The representation loss after processing this batch is:  0.002392999827861786\n",
      "\n",
      "The classification loss after processing this batch is:  0.16198037564754486\n",
      "The representation loss after processing this batch is:  0.002637907862663269\n",
      "\n",
      "The classification loss after processing this batch is:  0.08663614094257355\n",
      "The representation loss after processing this batch is:  0.0022389553487300873\n",
      "\n",
      "The classification loss after processing this batch is:  0.0651489794254303\n",
      "The representation loss after processing this batch is:  0.0023117363452911377\n",
      "\n",
      "The classification loss after processing this batch is:  0.16577571630477905\n",
      "The representation loss after processing this batch is:  0.002536579966545105\n",
      "\n",
      "The classification loss after processing this batch is:  0.13221804797649384\n",
      "The representation loss after processing this batch is:  0.0023430362343788147\n",
      "\n",
      "The classification loss after processing this batch is:  0.11928753554821014\n",
      "The representation loss after processing this batch is:  0.0023213401436805725\n",
      "\n",
      "The classification loss after processing this batch is:  0.03823288530111313\n",
      "The representation loss after processing this batch is:  0.002369500696659088\n",
      "\n",
      "The classification loss after processing this batch is:  0.11397754400968552\n",
      "The representation loss after processing this batch is:  0.0025395527482032776\n",
      "\n",
      "The classification loss after processing this batch is:  0.10463633388280869\n",
      "The representation loss after processing this batch is:  0.0025216490030288696\n",
      "\n",
      "The classification loss after processing this batch is:  0.09200659394264221\n",
      "The representation loss after processing this batch is:  0.0026041753590106964\n",
      "\n",
      "The classification loss after processing this batch is:  0.11489441245794296\n",
      "The representation loss after processing this batch is:  0.003064483404159546\n",
      "\n",
      "The classification loss after processing this batch is:  0.07111850380897522\n",
      "The representation loss after processing this batch is:  0.0030216649174690247\n",
      "\n",
      "The classification loss after processing this batch is:  0.12799929082393646\n",
      "The representation loss after processing this batch is:  0.0027001947164535522\n",
      "\n",
      "The classification loss after processing this batch is:  0.18391819298267365\n",
      "The representation loss after processing this batch is:  0.00254213809967041\n",
      "\n",
      "The classification loss after processing this batch is:  0.09692295640707016\n",
      "The representation loss after processing this batch is:  0.0029820576310157776\n",
      "\n",
      "The classification loss after processing this batch is:  0.08232351392507553\n",
      "The representation loss after processing this batch is:  0.0023067444562911987\n",
      "\n",
      "The classification loss after processing this batch is:  0.027897130697965622\n",
      "The representation loss after processing this batch is:  0.0020890459418296814\n",
      "\n",
      "The classification loss after processing this batch is:  0.1330387443304062\n",
      "The representation loss after processing this batch is:  0.002203218638896942\n",
      "\n",
      "The classification loss after processing this batch is:  0.05237909033894539\n",
      "The representation loss after processing this batch is:  0.0023484453558921814\n",
      "\n",
      "The classification loss after processing this batch is:  0.11023735255002975\n",
      "The representation loss after processing this batch is:  0.0023049190640449524\n",
      "\n",
      "The classification loss after processing this batch is:  0.08317416161298752\n",
      "The representation loss after processing this batch is:  0.002697758376598358\n",
      "\n",
      "The classification loss after processing this batch is:  0.08071006834506989\n",
      "The representation loss after processing this batch is:  0.002278335392475128\n",
      "\n",
      "The classification loss after processing this batch is:  0.09323481470346451\n",
      "The representation loss after processing this batch is:  0.00246303528547287\n",
      "\n",
      "The classification loss after processing this batch is:  0.11448594182729721\n",
      "The representation loss after processing this batch is:  0.0028043389320373535\n",
      "\n",
      "The classification loss after processing this batch is:  0.1265474557876587\n",
      "The representation loss after processing this batch is:  0.0027302727103233337\n",
      "\n",
      "The classification loss after processing this batch is:  0.10358020663261414\n",
      "The representation loss after processing this batch is:  0.002257365733385086\n",
      "\n",
      "The classification loss after processing this batch is:  0.12726065516471863\n",
      "The representation loss after processing this batch is:  0.002698715776205063\n",
      "\n",
      "The classification loss after processing this batch is:  0.059371065348386765\n",
      "The representation loss after processing this batch is:  0.0022269412875175476\n",
      "\n",
      "The classification loss after processing this batch is:  0.06944666802883148\n",
      "The representation loss after processing this batch is:  0.0023458749055862427\n",
      "\n",
      "The classification loss after processing this batch is:  0.04177037626504898\n",
      "The representation loss after processing this batch is:  0.0026939809322357178\n",
      "\n",
      "The classification loss after processing this batch is:  0.06600388884544373\n",
      "The representation loss after processing this batch is:  0.0024028904736042023\n",
      "\n",
      "The classification loss after processing this batch is:  0.040993351489305496\n",
      "The representation loss after processing this batch is:  0.0023701079189777374\n",
      "\n",
      "The classification loss after processing this batch is:  0.0475752018392086\n",
      "The representation loss after processing this batch is:  0.0021422728896141052\n",
      "\n",
      "The classification loss after processing this batch is:  0.038743581622838974\n",
      "The representation loss after processing this batch is:  0.0026992112398147583\n",
      "\n",
      "The classification loss after processing this batch is:  0.04105575382709503\n",
      "The representation loss after processing this batch is:  0.0025840401649475098\n",
      "\n",
      "The classification loss after processing this batch is:  0.09322277456521988\n",
      "The representation loss after processing this batch is:  0.0022437945008277893\n",
      "\n",
      "The classification loss after processing this batch is:  0.056848812848329544\n",
      "The representation loss after processing this batch is:  0.0020858049392700195\n",
      "\n",
      "The classification loss after processing this batch is:  0.07398241013288498\n",
      "The representation loss after processing this batch is:  0.0024728551506996155\n",
      "\n",
      "The classification loss after processing this batch is:  0.05196712166070938\n",
      "The representation loss after processing this batch is:  0.0025911927223205566\n",
      "\n",
      "The classification loss after processing this batch is:  0.1392708420753479\n",
      "The representation loss after processing this batch is:  0.002433132380247116\n",
      "\n",
      "The classification loss after processing this batch is:  0.12379003316164017\n",
      "The representation loss after processing this batch is:  0.002207525074481964\n",
      "\n",
      "The classification loss after processing this batch is:  0.09552799165248871\n",
      "The representation loss after processing this batch is:  0.0023423507809638977\n",
      "\n",
      "The classification loss after processing this batch is:  0.06742020696401596\n",
      "The representation loss after processing this batch is:  0.002422034740447998\n",
      "\n",
      "The classification loss after processing this batch is:  0.08554680645465851\n",
      "The representation loss after processing this batch is:  0.0025531724095344543\n",
      "\n",
      "The classification loss after processing this batch is:  0.04054852947592735\n",
      "The representation loss after processing this batch is:  0.002237938344478607\n",
      "\n",
      "The classification loss after processing this batch is:  0.043195176869630814\n",
      "The representation loss after processing this batch is:  0.0024107173085212708\n",
      "\n",
      "The classification loss after processing this batch is:  0.04426274076104164\n",
      "The representation loss after processing this batch is:  0.002407386898994446\n",
      "\n",
      "The classification loss after processing this batch is:  0.14075122773647308\n",
      "The representation loss after processing this batch is:  0.0023544132709503174\n",
      "\n",
      "The classification loss after processing this batch is:  0.11832068860530853\n",
      "The representation loss after processing this batch is:  0.002181731164455414\n",
      "\n",
      "The classification loss after processing this batch is:  0.10404069721698761\n",
      "The representation loss after processing this batch is:  0.002693481743335724\n",
      "\n",
      "The classification loss after processing this batch is:  0.1339365690946579\n",
      "The representation loss after processing this batch is:  0.0024088695645332336\n",
      "\n",
      "The classification loss after processing this batch is:  0.1240791380405426\n",
      "The representation loss after processing this batch is:  0.0025596171617507935\n",
      "\n",
      "The classification loss after processing this batch is:  0.11392554640769958\n",
      "The representation loss after processing this batch is:  0.0023872703313827515\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.20577575266361237\n",
      "The representation loss after processing this batch is:  0.0023435205221176147\n",
      "\n",
      "The classification loss after processing this batch is:  0.15069618821144104\n",
      "The representation loss after processing this batch is:  0.0022097788751125336\n",
      "\n",
      "The classification loss after processing this batch is:  0.0777936652302742\n",
      "The representation loss after processing this batch is:  0.0021338611841201782\n",
      "\n",
      "The classification loss after processing this batch is:  0.051070135086774826\n",
      "The representation loss after processing this batch is:  0.0023867152631282806\n",
      "\n",
      "The classification loss after processing this batch is:  0.047992054373025894\n",
      "The representation loss after processing this batch is:  0.0021259859204292297\n",
      "\n",
      "The classification loss after processing this batch is:  0.03755606338381767\n",
      "The representation loss after processing this batch is:  0.002343893051147461\n",
      "\n",
      "The classification loss after processing this batch is:  0.04363194480538368\n",
      "The representation loss after processing this batch is:  0.0026939809322357178\n",
      "\n",
      "The classification loss after processing this batch is:  0.10681778937578201\n",
      "The representation loss after processing this batch is:  0.002242736518383026\n",
      "\n",
      "The classification loss after processing this batch is:  0.061859130859375\n",
      "The representation loss after processing this batch is:  0.0024369359016418457\n",
      "\n",
      "The classification loss after processing this batch is:  0.15008950233459473\n",
      "The representation loss after processing this batch is:  0.002316657453775406\n",
      "\n",
      "The classification loss after processing this batch is:  0.09021374583244324\n",
      "The representation loss after processing this batch is:  0.00254947692155838\n",
      "\n",
      "The classification loss after processing this batch is:  0.13849703967571259\n",
      "The representation loss after processing this batch is:  0.002108372747898102\n",
      "\n",
      "The classification loss after processing this batch is:  0.09594575315713882\n",
      "The representation loss after processing this batch is:  0.0022331923246383667\n",
      "\n",
      "The classification loss after processing this batch is:  0.1634073555469513\n",
      "The representation loss after processing this batch is:  0.0021456442773342133\n",
      "\n",
      "The classification loss after processing this batch is:  0.06029653921723366\n",
      "The representation loss after processing this batch is:  0.00218215212225914\n",
      "\n",
      "The classification loss after processing this batch is:  0.08497165888547897\n",
      "The representation loss after processing this batch is:  0.002469204366207123\n",
      "\n",
      "The classification loss after processing this batch is:  0.11937221139669418\n",
      "The representation loss after processing this batch is:  0.002272173762321472\n",
      "\n",
      "The classification loss after processing this batch is:  0.04029102995991707\n",
      "The representation loss after processing this batch is:  0.0022095926105976105\n",
      "\n",
      "The classification loss after processing this batch is:  0.034033313393592834\n",
      "The representation loss after processing this batch is:  0.0022348500788211823\n",
      "\n",
      "The classification loss after processing this batch is:  0.11161172389984131\n",
      "The representation loss after processing this batch is:  0.0027153566479682922\n",
      "\n",
      "The classification loss after processing this batch is:  0.14541207253932953\n",
      "The representation loss after processing this batch is:  0.0023252293467521667\n",
      "\n",
      "The classification loss after processing this batch is:  0.09879355877637863\n",
      "The representation loss after processing this batch is:  0.0025443434715270996\n",
      "\n",
      "The classification loss after processing this batch is:  0.046733371913433075\n",
      "The representation loss after processing this batch is:  0.0025808364152908325\n",
      "\n",
      "The classification loss after processing this batch is:  0.07450319081544876\n",
      "The representation loss after processing this batch is:  0.002638310194015503\n",
      "\n",
      "The classification loss after processing this batch is:  0.070655457675457\n",
      "The representation loss after processing this batch is:  0.0024505481123924255\n",
      "\n",
      "The classification loss after processing this batch is:  0.22281937301158905\n",
      "The representation loss after processing this batch is:  0.002453099936246872\n",
      "\n",
      "The classification loss after processing this batch is:  0.060993555933237076\n",
      "The representation loss after processing this batch is:  0.002268590033054352\n",
      "\n",
      "The classification loss after processing this batch is:  0.030629610642790794\n",
      "The representation loss after processing this batch is:  0.0023884549736976624\n",
      "\n",
      "The classification loss after processing this batch is:  0.10579948872327805\n",
      "The representation loss after processing this batch is:  0.0028586089611053467\n",
      "\n",
      "The classification loss after processing this batch is:  0.08544222265481949\n",
      "The representation loss after processing this batch is:  0.002505384385585785\n",
      "\n",
      "The classification loss after processing this batch is:  0.051425036042928696\n",
      "The representation loss after processing this batch is:  0.0025739893317222595\n",
      "\n",
      "The classification loss after processing this batch is:  0.042127784341573715\n",
      "The representation loss after processing this batch is:  0.0021511055529117584\n",
      "\n",
      "The classification loss after processing this batch is:  0.08464835584163666\n",
      "The representation loss after processing this batch is:  0.002856642007827759\n",
      "\n",
      "The classification loss after processing this batch is:  0.13620933890342712\n",
      "The representation loss after processing this batch is:  0.002594277262687683\n",
      "\n",
      "The classification loss after processing this batch is:  0.18931208550930023\n",
      "The representation loss after processing this batch is:  0.0021730735898017883\n",
      "\n",
      "The classification loss after processing this batch is:  0.13533054292201996\n",
      "The representation loss after processing this batch is:  0.002525113523006439\n",
      "\n",
      "The classification loss after processing this batch is:  0.03964613378047943\n",
      "The representation loss after processing this batch is:  0.0024798214435577393\n",
      "\n",
      "The classification loss after processing this batch is:  0.04577424377202988\n",
      "The representation loss after processing this batch is:  0.0021232254803180695\n",
      "\n",
      "The classification loss after processing this batch is:  0.09901007264852524\n",
      "The representation loss after processing this batch is:  0.0024645552039146423\n",
      "\n",
      "The classification loss after processing this batch is:  0.1462561935186386\n",
      "The representation loss after processing this batch is:  0.0025751590728759766\n",
      "\n",
      "The classification loss after processing this batch is:  0.1662122756242752\n",
      "The representation loss after processing this batch is:  0.0027623623609542847\n",
      "\n",
      "The classification loss after processing this batch is:  0.18099257349967957\n",
      "The representation loss after processing this batch is:  0.0021799877285957336\n",
      "\n",
      "The classification loss after processing this batch is:  0.07957375049591064\n",
      "The representation loss after processing this batch is:  0.0021862946450710297\n",
      "\n",
      "The classification loss after processing this batch is:  0.14595374464988708\n",
      "The representation loss after processing this batch is:  0.0021637603640556335\n",
      "\n",
      "The classification loss after processing this batch is:  0.06286564469337463\n",
      "The representation loss after processing this batch is:  0.0021097734570503235\n",
      "\n",
      "The classification loss after processing this batch is:  0.07330349087715149\n",
      "The representation loss after processing this batch is:  0.0023835748434066772\n",
      "\n",
      "The classification loss after processing this batch is:  0.032611969858407974\n",
      "The representation loss after processing this batch is:  0.0022984519600868225\n",
      "\n",
      "The classification loss after processing this batch is:  0.10513179004192352\n",
      "The representation loss after processing this batch is:  0.002299971878528595\n",
      "\n",
      "The classification loss after processing this batch is:  0.09254603087902069\n",
      "The representation loss after processing this batch is:  0.002148926258087158\n",
      "\n",
      "The classification loss after processing this batch is:  0.06600107997655869\n",
      "The representation loss after processing this batch is:  0.002304334193468094\n",
      "\n",
      "The classification loss after processing this batch is:  0.14268535375595093\n",
      "The representation loss after processing this batch is:  0.002553112804889679\n",
      "\n",
      "The classification loss after processing this batch is:  0.03070458583533764\n",
      "The representation loss after processing this batch is:  0.0025689229369163513\n",
      "\n",
      "The classification loss after processing this batch is:  0.07854597270488739\n",
      "The representation loss after processing this batch is:  0.002563074231147766\n",
      "\n",
      "The classification loss after processing this batch is:  0.0810064896941185\n",
      "The representation loss after processing this batch is:  0.00224091112613678\n",
      "\n",
      "The classification loss after processing this batch is:  0.15150317549705505\n",
      "The representation loss after processing this batch is:  0.0025008022785186768\n",
      "\n",
      "The classification loss after processing this batch is:  0.04202348366379738\n",
      "The representation loss after processing this batch is:  0.0028875917196273804\n",
      "\n",
      "The classification loss after processing this batch is:  0.07176712900400162\n",
      "The representation loss after processing this batch is:  0.0020967908203601837\n",
      "\n",
      "The classification loss after processing this batch is:  0.1418582946062088\n",
      "The representation loss after processing this batch is:  0.0025469809770584106\n",
      "\n",
      "The classification loss after processing this batch is:  0.09365550428628922\n",
      "The representation loss after processing this batch is:  0.002147052437067032\n",
      "\n",
      "The classification loss after processing this batch is:  0.1331162005662918\n",
      "The representation loss after processing this batch is:  0.0022398382425308228\n",
      "\n",
      "The classification loss after processing this batch is:  0.09790454804897308\n",
      "The representation loss after processing this batch is:  0.0022292397916316986\n",
      "\n",
      "The classification loss after processing this batch is:  0.0530012771487236\n",
      "The representation loss after processing this batch is:  0.0024260058999061584\n",
      "\n",
      "The classification loss after processing this batch is:  0.13384120166301727\n",
      "The representation loss after processing this batch is:  0.001973181962966919\n",
      "\n",
      "The classification loss after processing this batch is:  0.08681508898735046\n",
      "The representation loss after processing this batch is:  0.0024436935782432556\n",
      "\n",
      "The classification loss after processing this batch is:  0.10042247921228409\n",
      "The representation loss after processing this batch is:  0.0023616626858711243\n",
      "\n",
      "The classification loss after processing this batch is:  0.09462417662143707\n",
      "The representation loss after processing this batch is:  0.002841733396053314\n",
      "\n",
      "The classification loss after processing this batch is:  0.04478966072201729\n",
      "The representation loss after processing this batch is:  0.002386532723903656\n",
      "\n",
      "The classification loss after processing this batch is:  0.11143697053194046\n",
      "The representation loss after processing this batch is:  0.0023376569151878357\n",
      "\n",
      "The classification loss after processing this batch is:  0.12567190825939178\n",
      "The representation loss after processing this batch is:  0.0025401487946510315\n",
      "\n",
      "The classification loss after processing this batch is:  0.029517944902181625\n",
      "The representation loss after processing this batch is:  0.00247906893491745\n",
      "\n",
      "The classification loss after processing this batch is:  0.07343025505542755\n",
      "The representation loss after processing this batch is:  0.0020980164408683777\n",
      "\n",
      "The classification loss after processing this batch is:  0.13307349383831024\n",
      "The representation loss after processing this batch is:  0.0021789781749248505\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.13513466715812683\n",
      "The representation loss after processing this batch is:  0.0024894103407859802\n",
      "\n",
      "The classification loss after processing this batch is:  0.09419150650501251\n",
      "The representation loss after processing this batch is:  0.0023115873336791992\n",
      "\n",
      "The classification loss after processing this batch is:  0.1249246746301651\n",
      "The representation loss after processing this batch is:  0.0024028122425079346\n",
      "\n",
      "The classification loss after processing this batch is:  0.09971528500318527\n",
      "The representation loss after processing this batch is:  0.002409696578979492\n",
      "\n",
      "The classification loss after processing this batch is:  0.15580107271671295\n",
      "The representation loss after processing this batch is:  0.0024040937423706055\n",
      "\n",
      "The classification loss after processing this batch is:  0.06051800400018692\n",
      "The representation loss after processing this batch is:  0.0024745166301727295\n",
      "\n",
      "The classification loss after processing this batch is:  0.1434967815876007\n",
      "The representation loss after processing this batch is:  0.0022727325558662415\n",
      "\n",
      "The classification loss after processing this batch is:  0.09160014241933823\n",
      "The representation loss after processing this batch is:  0.003142140805721283\n",
      "\n",
      "The classification loss after processing this batch is:  0.04299263656139374\n",
      "The representation loss after processing this batch is:  0.0023754313588142395\n",
      "\n",
      "The classification loss after processing this batch is:  0.062030814588069916\n",
      "The representation loss after processing this batch is:  0.0023276805877685547\n",
      "\n",
      "The classification loss after processing this batch is:  0.06937163323163986\n",
      "The representation loss after processing this batch is:  0.0021583102643489838\n",
      "\n",
      "The classification loss after processing this batch is:  0.08973534405231476\n",
      "The representation loss after processing this batch is:  0.002389959990978241\n",
      "\n",
      "The classification loss after processing this batch is:  0.07055315375328064\n",
      "The representation loss after processing this batch is:  0.0022956952452659607\n",
      "\n",
      "The classification loss after processing this batch is:  0.14608325064182281\n",
      "The representation loss after processing this batch is:  0.0023809783160686493\n",
      "\n",
      "The classification loss after processing this batch is:  0.034307558089494705\n",
      "The representation loss after processing this batch is:  0.002334877848625183\n",
      "\n",
      "The classification loss after processing this batch is:  0.04811471328139305\n",
      "The representation loss after processing this batch is:  0.00259438157081604\n",
      "\n",
      "The classification loss after processing this batch is:  0.1468636393547058\n",
      "The representation loss after processing this batch is:  0.0026052892208099365\n",
      "\n",
      "The classification loss after processing this batch is:  0.023177949711680412\n",
      "The representation loss after processing this batch is:  0.0022682398557662964\n",
      "\n",
      "The classification loss after processing this batch is:  0.05895524099469185\n",
      "The representation loss after processing this batch is:  0.0023087337613105774\n",
      "\n",
      "The classification loss after processing this batch is:  0.03742476925253868\n",
      "The representation loss after processing this batch is:  0.002518247812986374\n",
      "\n",
      "The classification loss after processing this batch is:  0.09163301438093185\n",
      "The representation loss after processing this batch is:  0.0022863075137138367\n",
      "\n",
      "The classification loss after processing this batch is:  0.1367689073085785\n",
      "The representation loss after processing this batch is:  0.0028006955981254578\n",
      "\n",
      "The classification loss after processing this batch is:  0.13001057505607605\n",
      "The representation loss after processing this batch is:  0.0033445656299591064\n",
      "\n",
      "The classification loss after processing this batch is:  0.11366693675518036\n",
      "The representation loss after processing this batch is:  0.002999350428581238\n",
      "\n",
      "The classification loss after processing this batch is:  0.05018679425120354\n",
      "The representation loss after processing this batch is:  0.0026058293879032135\n",
      "\n",
      "The classification loss after processing this batch is:  0.08620775490999222\n",
      "The representation loss after processing this batch is:  0.0022364072501659393\n",
      "\n",
      "The classification loss after processing this batch is:  0.11492716521024704\n",
      "The representation loss after processing this batch is:  0.002371661365032196\n",
      "\n",
      "The classification loss after processing this batch is:  0.044016655534505844\n",
      "The representation loss after processing this batch is:  0.00261513888835907\n",
      "\n",
      "The classification loss after processing this batch is:  0.03980004042387009\n",
      "The representation loss after processing this batch is:  0.0021934695541858673\n",
      "\n",
      "The classification loss after processing this batch is:  0.031457144767045975\n",
      "The representation loss after processing this batch is:  0.0026020631194114685\n",
      "\n",
      "The classification loss after processing this batch is:  0.06518124788999557\n",
      "The representation loss after processing this batch is:  0.002610180526971817\n",
      "\n",
      "The classification loss after processing this batch is:  0.14888975024223328\n",
      "The representation loss after processing this batch is:  0.0025678910315036774\n",
      "\n",
      "The classification loss after processing this batch is:  0.11863245069980621\n",
      "The representation loss after processing this batch is:  0.0023727938532829285\n",
      "\n",
      "The classification loss after processing this batch is:  0.1037495955824852\n",
      "The representation loss after processing this batch is:  0.0029562637209892273\n",
      "\n",
      "The classification loss after processing this batch is:  0.07394116371870041\n",
      "The representation loss after processing this batch is:  0.002901114523410797\n",
      "\n",
      "The classification loss after processing this batch is:  0.11189818382263184\n",
      "The representation loss after processing this batch is:  0.0025172531604766846\n",
      "\n",
      "The classification loss after processing this batch is:  0.055064935237169266\n",
      "The representation loss after processing this batch is:  0.0023174285888671875\n",
      "\n",
      "The classification loss after processing this batch is:  0.2986394762992859\n",
      "The representation loss after processing this batch is:  0.0026312097907066345\n",
      "\n",
      "The classification loss after processing this batch is:  0.07564195990562439\n",
      "The representation loss after processing this batch is:  0.0027382448315620422\n",
      "\n",
      "The classification loss after processing this batch is:  0.20380578935146332\n",
      "The representation loss after processing this batch is:  0.0031163617968559265\n",
      "\n",
      "The classification loss after processing this batch is:  0.0844876691699028\n",
      "The representation loss after processing this batch is:  0.0021793022751808167\n",
      "\n",
      "The classification loss after processing this batch is:  0.09773768484592438\n",
      "The representation loss after processing this batch is:  0.002368740737438202\n",
      "\n",
      "The classification loss after processing this batch is:  0.14502359926700592\n",
      "The representation loss after processing this batch is:  0.002227999269962311\n",
      "\n",
      "The classification loss after processing this batch is:  0.0833112820982933\n",
      "The representation loss after processing this batch is:  0.0023953765630722046\n",
      "\n",
      "The classification loss after processing this batch is:  0.15636149048805237\n",
      "The representation loss after processing this batch is:  0.002540186047554016\n",
      "\n",
      "The classification loss after processing this batch is:  0.09300084412097931\n",
      "The representation loss after processing this batch is:  0.002761468291282654\n",
      "\n",
      "The classification loss after processing this batch is:  0.11208568513393402\n",
      "The representation loss after processing this batch is:  0.002910315990447998\n",
      "\n",
      "The classification loss after processing this batch is:  0.14891766011714935\n",
      "The representation loss after processing this batch is:  0.0026349052786827087\n",
      "\n",
      "The classification loss after processing this batch is:  0.02725565806031227\n",
      "The representation loss after processing this batch is:  0.0024344176054000854\n",
      "\n",
      "The classification loss after processing this batch is:  0.09951002150774002\n",
      "The representation loss after processing this batch is:  0.0020999424159526825\n",
      "\n",
      "The classification loss after processing this batch is:  0.09580149501562119\n",
      "The representation loss after processing this batch is:  0.002232275903224945\n",
      "\n",
      "The classification loss after processing this batch is:  0.0369037464261055\n",
      "The representation loss after processing this batch is:  0.0025089383125305176\n",
      "\n",
      "The classification loss after processing this batch is:  0.12701497972011566\n",
      "The representation loss after processing this batch is:  0.0022466927766799927\n",
      "\n",
      "The classification loss after processing this batch is:  0.224095419049263\n",
      "The representation loss after processing this batch is:  0.0024408772587776184\n",
      "\n",
      "The classification loss after processing this batch is:  0.08615341037511826\n",
      "The representation loss after processing this batch is:  0.001985248178243637\n",
      "\n",
      "The classification loss after processing this batch is:  0.06426993012428284\n",
      "The representation loss after processing this batch is:  0.00247965008020401\n",
      "\n",
      "The classification loss after processing this batch is:  0.07720474153757095\n",
      "The representation loss after processing this batch is:  0.0023407042026519775\n",
      "\n",
      "The classification loss after processing this batch is:  0.06603426486253738\n",
      "The representation loss after processing this batch is:  0.0024522095918655396\n",
      "\n",
      "The classification loss after processing this batch is:  0.08113418519496918\n",
      "The representation loss after processing this batch is:  0.002695538103580475\n",
      "\n",
      "The classification loss after processing this batch is:  0.049919381737709045\n",
      "The representation loss after processing this batch is:  0.002611614763736725\n",
      "\n",
      "The classification loss after processing this batch is:  0.0961981862783432\n",
      "The representation loss after processing this batch is:  0.0022666603326797485\n",
      "\n",
      "The classification loss after processing this batch is:  0.11814721673727036\n",
      "The representation loss after processing this batch is:  0.0021891817450523376\n",
      "\n",
      "The classification loss after processing this batch is:  0.05674973502755165\n",
      "The representation loss after processing this batch is:  0.0024332404136657715\n",
      "\n",
      "The classification loss after processing this batch is:  0.1351863592863083\n",
      "The representation loss after processing this batch is:  0.0021046139299869537\n",
      "\n",
      "The classification loss after processing this batch is:  0.10846976935863495\n",
      "The representation loss after processing this batch is:  0.0021324530243873596\n",
      "\n",
      "The classification loss after processing this batch is:  0.0649571567773819\n",
      "The representation loss after processing this batch is:  0.0024006441235542297\n",
      "\n",
      "The classification loss after processing this batch is:  0.05409013852477074\n",
      "The representation loss after processing this batch is:  0.0023967698216438293\n",
      "\n",
      "The classification loss after processing this batch is:  0.10195057839155197\n",
      "The representation loss after processing this batch is:  0.0023270323872566223\n",
      "\n",
      "The classification loss after processing this batch is:  0.043502021580934525\n",
      "The representation loss after processing this batch is:  0.0024547725915908813\n",
      "\n",
      "The classification loss after processing this batch is:  0.31166189908981323\n",
      "The representation loss after processing this batch is:  0.0021836236119270325\n",
      "\n",
      "The classification loss after processing this batch is:  0.0810835137963295\n",
      "The representation loss after processing this batch is:  0.0025686323642730713\n",
      "\n",
      "The classification loss after processing this batch is:  0.1487903594970703\n",
      "The representation loss after processing this batch is:  0.0022154003381729126\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.057192716747522354\n",
      "The representation loss after processing this batch is:  0.002054136246442795\n",
      "\n",
      "The classification loss after processing this batch is:  0.08743540197610855\n",
      "The representation loss after processing this batch is:  0.002316199243068695\n",
      "\n",
      "The classification loss after processing this batch is:  0.051812902092933655\n",
      "The representation loss after processing this batch is:  0.0021146945655345917\n",
      "\n",
      "The classification loss after processing this batch is:  0.07037787139415741\n",
      "The representation loss after processing this batch is:  0.002217605710029602\n",
      "\n",
      "The classification loss after processing this batch is:  0.13788731396198273\n",
      "The representation loss after processing this batch is:  0.002297062426805496\n",
      "\n",
      "The classification loss after processing this batch is:  0.09665437042713165\n",
      "The representation loss after processing this batch is:  0.0029395706951618195\n",
      "\n",
      "The classification loss after processing this batch is:  0.1236993595957756\n",
      "The representation loss after processing this batch is:  0.0023770779371261597\n",
      "\n",
      "The classification loss after processing this batch is:  0.06967738270759583\n",
      "The representation loss after processing this batch is:  0.0024504512548446655\n",
      "\n",
      "The classification loss after processing this batch is:  0.12568959593772888\n",
      "The representation loss after processing this batch is:  0.0025696158409118652\n",
      "\n",
      "The classification loss after processing this batch is:  0.13601404428482056\n",
      "The representation loss after processing this batch is:  0.002485126256942749\n",
      "\n",
      "The classification loss after processing this batch is:  0.15521100163459778\n",
      "The representation loss after processing this batch is:  0.0023029595613479614\n",
      "\n",
      "The classification loss after processing this batch is:  0.06444624066352844\n",
      "The representation loss after processing this batch is:  0.0024412870407104492\n",
      "\n",
      "The classification loss after processing this batch is:  0.07226916402578354\n",
      "The representation loss after processing this batch is:  0.002804994583129883\n",
      "\n",
      "The classification loss after processing this batch is:  0.03257189691066742\n",
      "The representation loss after processing this batch is:  0.002427831292152405\n",
      "\n",
      "The classification loss after processing this batch is:  0.14530865848064423\n",
      "The representation loss after processing this batch is:  0.00226636603474617\n",
      "\n",
      "The classification loss after processing this batch is:  0.18999049067497253\n",
      "The representation loss after processing this batch is:  0.00241248682141304\n",
      "\n",
      "The classification loss after processing this batch is:  0.0795312449336052\n",
      "The representation loss after processing this batch is:  0.0028880834579467773\n",
      "\n",
      "The classification loss after processing this batch is:  0.11885127425193787\n",
      "The representation loss after processing this batch is:  0.002731338143348694\n",
      "\n",
      "The classification loss after processing this batch is:  0.12246433645486832\n",
      "The representation loss after processing this batch is:  0.00230475515127182\n",
      "\n",
      "The classification loss after processing this batch is:  0.14119590818881989\n",
      "The representation loss after processing this batch is:  0.0025841668248176575\n",
      "\n",
      "The classification loss after processing this batch is:  0.032527875155210495\n",
      "The representation loss after processing this batch is:  0.0022478215396404266\n",
      "\n",
      "The classification loss after processing this batch is:  0.10950584709644318\n",
      "The representation loss after processing this batch is:  0.002494014799594879\n",
      "\n",
      "The classification loss after processing this batch is:  0.12068304419517517\n",
      "The representation loss after processing this batch is:  0.002457760274410248\n",
      "\n",
      "The classification loss after processing this batch is:  0.06980516761541367\n",
      "The representation loss after processing this batch is:  0.002444155514240265\n",
      "\n",
      "The classification loss after processing this batch is:  0.03335775434970856\n",
      "The representation loss after processing this batch is:  0.00273025780916214\n",
      "\n",
      "The classification loss after processing this batch is:  0.06153857707977295\n",
      "The representation loss after processing this batch is:  0.002415582537651062\n",
      "\n",
      "The classification loss after processing this batch is:  0.07854700088500977\n",
      "The representation loss after processing this batch is:  0.0026312246918678284\n",
      "\n",
      "The classification loss after processing this batch is:  0.08099248260259628\n",
      "The representation loss after processing this batch is:  0.0022182688117027283\n",
      "\n",
      "The classification loss after processing this batch is:  0.1478528529405594\n",
      "The representation loss after processing this batch is:  0.0024258866906166077\n",
      "\n",
      "The classification loss after processing this batch is:  0.11431021988391876\n",
      "The representation loss after processing this batch is:  0.002165168523788452\n",
      "\n",
      "The classification loss after processing this batch is:  0.08679917454719543\n",
      "The representation loss after processing this batch is:  0.0026309750974178314\n",
      "\n",
      "The classification loss after processing this batch is:  0.14564411342144012\n",
      "The representation loss after processing this batch is:  0.0026934295892715454\n",
      "\n",
      "The classification loss after processing this batch is:  0.08594021201133728\n",
      "The representation loss after processing this batch is:  0.002807408571243286\n",
      "\n",
      "The classification loss after processing this batch is:  0.07239066064357758\n",
      "The representation loss after processing this batch is:  0.0022903159260749817\n",
      "\n",
      "The classification loss after processing this batch is:  0.12873397767543793\n",
      "The representation loss after processing this batch is:  0.002395041286945343\n",
      "\n",
      "The classification loss after processing this batch is:  0.14855729043483734\n",
      "The representation loss after processing this batch is:  0.003063291311264038\n",
      "\n",
      "The classification loss after processing this batch is:  0.11361189186573029\n",
      "The representation loss after processing this batch is:  0.002514392137527466\n",
      "\n",
      "The classification loss after processing this batch is:  0.051056742668151855\n",
      "The representation loss after processing this batch is:  0.002455543726682663\n",
      "\n",
      "The classification loss after processing this batch is:  0.059430256485939026\n",
      "The representation loss after processing this batch is:  0.002179577946662903\n",
      "\n",
      "The classification loss after processing this batch is:  0.046425700187683105\n",
      "The representation loss after processing this batch is:  0.0024749860167503357\n",
      "\n",
      "The classification loss after processing this batch is:  0.10122794657945633\n",
      "The representation loss after processing this batch is:  0.0023340731859207153\n",
      "\n",
      "The classification loss after processing this batch is:  0.1882016807794571\n",
      "The representation loss after processing this batch is:  0.0021809227764606476\n",
      "\n",
      "The classification loss after processing this batch is:  0.22910860180854797\n",
      "The representation loss after processing this batch is:  0.002712041139602661\n",
      "\n",
      "The classification loss after processing this batch is:  0.11838104575872421\n",
      "The representation loss after processing this batch is:  0.002071734517812729\n",
      "\n",
      "The classification loss after processing this batch is:  0.10805884748697281\n",
      "The representation loss after processing this batch is:  0.002253856509923935\n",
      "\n",
      "The classification loss after processing this batch is:  0.06949004530906677\n",
      "The representation loss after processing this batch is:  0.0025503523647785187\n",
      "\n",
      "The classification loss after processing this batch is:  0.10364678502082825\n",
      "The representation loss after processing this batch is:  0.002265937626361847\n",
      "\n",
      "The classification loss after processing this batch is:  0.20075471699237823\n",
      "The representation loss after processing this batch is:  0.0025519877672195435\n",
      "\n",
      "The classification loss after processing this batch is:  0.13400596380233765\n",
      "The representation loss after processing this batch is:  0.002184532582759857\n",
      "\n",
      "The classification loss after processing this batch is:  0.28289058804512024\n",
      "The representation loss after processing this batch is:  0.002413146197795868\n",
      "\n",
      "The classification loss after processing this batch is:  0.13883399963378906\n",
      "The representation loss after processing this batch is:  0.0025303512811660767\n",
      "\n",
      "The classification loss after processing this batch is:  0.04951559007167816\n",
      "The representation loss after processing this batch is:  0.002734862267971039\n",
      "\n",
      "The classification loss after processing this batch is:  0.11925596743822098\n",
      "The representation loss after processing this batch is:  0.0023909881711006165\n",
      "\n",
      "The classification loss after processing this batch is:  0.10517589002847672\n",
      "The representation loss after processing this batch is:  0.0021991729736328125\n",
      "\n",
      "The classification loss after processing this batch is:  0.14430469274520874\n",
      "The representation loss after processing this batch is:  0.0025474131107330322\n",
      "\n",
      "The classification loss after processing this batch is:  0.08086546510457993\n",
      "The representation loss after processing this batch is:  0.00214511901140213\n",
      "\n",
      "The classification loss after processing this batch is:  0.12937334179878235\n",
      "The representation loss after processing this batch is:  0.002155676484107971\n",
      "\n",
      "The classification loss after processing this batch is:  0.07960879057645798\n",
      "The representation loss after processing this batch is:  0.0024266690015792847\n",
      "\n",
      "The classification loss after processing this batch is:  0.11181811988353729\n",
      "The representation loss after processing this batch is:  0.0022808127105236053\n",
      "\n",
      "The classification loss after processing this batch is:  0.1467510163784027\n",
      "The representation loss after processing this batch is:  0.002327360212802887\n",
      "\n",
      "The classification loss after processing this batch is:  0.18198947608470917\n",
      "The representation loss after processing this batch is:  0.0024177134037017822\n",
      "\n",
      "The classification loss after processing this batch is:  0.10338791459798813\n",
      "The representation loss after processing this batch is:  0.0022862330079078674\n",
      "\n",
      "The classification loss after processing this batch is:  0.0325794443488121\n",
      "The representation loss after processing this batch is:  0.002853572368621826\n",
      "\n",
      "The classification loss after processing this batch is:  0.015396337024867535\n",
      "The representation loss after processing this batch is:  0.002486318349838257\n",
      "\n",
      "The classification loss after processing this batch is:  0.0942666158080101\n",
      "The representation loss after processing this batch is:  0.0026189982891082764\n",
      "\n",
      "The classification loss after processing this batch is:  0.08992527425289154\n",
      "The representation loss after processing this batch is:  0.003701247274875641\n",
      "\n",
      "The classification loss after processing this batch is:  0.14349859952926636\n",
      "The representation loss after processing this batch is:  0.002510271966457367\n",
      "\n",
      "The classification loss after processing this batch is:  0.10628759860992432\n",
      "The representation loss after processing this batch is:  0.002591922879219055\n",
      "\n",
      "The classification loss after processing this batch is:  0.12901514768600464\n",
      "The representation loss after processing this batch is:  0.00236356258392334\n",
      "\n",
      "The classification loss after processing this batch is:  0.04591918736696243\n",
      "The representation loss after processing this batch is:  0.0025901347398757935\n",
      "\n",
      "The classification loss after processing this batch is:  0.09829068928956985\n",
      "The representation loss after processing this batch is:  0.002487771213054657\n",
      "\n",
      "The classification loss after processing this batch is:  0.07570537179708481\n",
      "The representation loss after processing this batch is:  0.0025800541043281555\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.13649138808250427\n",
      "The representation loss after processing this batch is:  0.0025368332862854004\n",
      "\n",
      "The classification loss after processing this batch is:  0.05418059974908829\n",
      "The representation loss after processing this batch is:  0.0023574456572532654\n",
      "\n",
      "The classification loss after processing this batch is:  0.05018003284931183\n",
      "The representation loss after processing this batch is:  0.001955892890691757\n",
      "\n",
      "The classification loss after processing this batch is:  0.11564776301383972\n",
      "The representation loss after processing this batch is:  0.0022474676370620728\n",
      "\n",
      "The classification loss after processing this batch is:  0.09893333911895752\n",
      "The representation loss after processing this batch is:  0.002356298267841339\n",
      "\n",
      "The classification loss after processing this batch is:  0.08556009083986282\n",
      "The representation loss after processing this batch is:  0.002136632800102234\n",
      "\n",
      "The classification loss after processing this batch is:  0.14887668192386627\n",
      "The representation loss after processing this batch is:  0.002546839416027069\n",
      "\n",
      "The classification loss after processing this batch is:  0.08164861053228378\n",
      "The representation loss after processing this batch is:  0.0024049803614616394\n",
      "\n",
      "The classification loss after processing this batch is:  0.01901213265955448\n",
      "The representation loss after processing this batch is:  0.0022339820861816406\n",
      "\n",
      "The classification loss after processing this batch is:  0.04664850980043411\n",
      "The representation loss after processing this batch is:  0.0026545822620391846\n",
      "\n",
      "The classification loss after processing this batch is:  0.02434220351278782\n",
      "The representation loss after processing this batch is:  0.0026743561029434204\n",
      "\n",
      "The classification loss after processing this batch is:  0.07284273207187653\n",
      "The representation loss after processing this batch is:  0.0024997368454933167\n",
      "\n",
      "The classification loss after processing this batch is:  0.04369921609759331\n",
      "The representation loss after processing this batch is:  0.0023850426077842712\n",
      "\n",
      "The classification loss after processing this batch is:  0.0419042743742466\n",
      "The representation loss after processing this batch is:  0.0022816285490989685\n",
      "\n",
      "The classification loss after processing this batch is:  0.07815137505531311\n",
      "The representation loss after processing this batch is:  0.0026630982756614685\n",
      "\n",
      "The classification loss after processing this batch is:  0.07329448312520981\n",
      "The representation loss after processing this batch is:  0.002537146210670471\n",
      "\n",
      "The classification loss after processing this batch is:  0.032578062266111374\n",
      "The representation loss after processing this batch is:  0.0022521093487739563\n",
      "\n",
      "The classification loss after processing this batch is:  0.031104207038879395\n",
      "The representation loss after processing this batch is:  0.002246212214231491\n",
      "\n",
      "The classification loss after processing this batch is:  0.03807332366704941\n",
      "The representation loss after processing this batch is:  0.0025031864643096924\n",
      "\n",
      "The classification loss after processing this batch is:  0.02281762845814228\n",
      "The representation loss after processing this batch is:  0.002539709210395813\n",
      "\n",
      "The classification loss after processing this batch is:  0.10789451748132706\n",
      "The representation loss after processing this batch is:  0.002376161515712738\n",
      "\n",
      "The classification loss after processing this batch is:  0.10321713238954544\n",
      "The representation loss after processing this batch is:  0.0025070980191230774\n",
      "\n",
      "The classification loss after processing this batch is:  0.03365451470017433\n",
      "The representation loss after processing this batch is:  0.002340175211429596\n",
      "\n",
      "The classification loss after processing this batch is:  0.11945600062608719\n",
      "The representation loss after processing this batch is:  0.002405136823654175\n",
      "\n",
      "The classification loss after processing this batch is:  0.0407266765832901\n",
      "The representation loss after processing this batch is:  0.0021826326847076416\n",
      "\n",
      "The classification loss after processing this batch is:  0.11983861029148102\n",
      "The representation loss after processing this batch is:  0.002338893711566925\n",
      "\n",
      "The classification loss after processing this batch is:  0.14642634987831116\n",
      "The representation loss after processing this batch is:  0.002685829997062683\n",
      "\n",
      "The classification loss after processing this batch is:  0.06080164015293121\n",
      "The representation loss after processing this batch is:  0.002593196928501129\n",
      "\n",
      "The classification loss after processing this batch is:  0.14174066483974457\n",
      "The representation loss after processing this batch is:  0.002215169370174408\n",
      "\n",
      "The classification loss after processing this batch is:  0.12110237777233124\n",
      "The representation loss after processing this batch is:  0.0022296682000160217\n",
      "\n",
      "The classification loss after processing this batch is:  0.1348404437303543\n",
      "The representation loss after processing this batch is:  0.002256333827972412\n",
      "\n",
      "The classification loss after processing this batch is:  0.10315752774477005\n",
      "The representation loss after processing this batch is:  0.002227216958999634\n",
      "\n",
      "The classification loss after processing this batch is:  0.05777648463845253\n",
      "The representation loss after processing this batch is:  0.002513408660888672\n",
      "\n",
      "The classification loss after processing this batch is:  0.08944928646087646\n",
      "The representation loss after processing this batch is:  0.0020578987896442413\n",
      "\n",
      "The classification loss after processing this batch is:  0.10130377113819122\n",
      "The representation loss after processing this batch is:  0.0026303231716156006\n",
      "\n",
      "The classification loss after processing this batch is:  0.12382429093122482\n",
      "The representation loss after processing this batch is:  0.002476990222930908\n",
      "\n",
      "The classification loss after processing this batch is:  0.10610770434141159\n",
      "The representation loss after processing this batch is:  0.002314262092113495\n",
      "\n",
      "The classification loss after processing this batch is:  0.05091359466314316\n",
      "The representation loss after processing this batch is:  0.00229441374540329\n",
      "\n",
      "The classification loss after processing this batch is:  0.07463636249303818\n",
      "The representation loss after processing this batch is:  0.002230897545814514\n",
      "\n",
      "The classification loss after processing this batch is:  0.17543676495552063\n",
      "The representation loss after processing this batch is:  0.002133600413799286\n",
      "\n",
      "The classification loss after processing this batch is:  0.0674181804060936\n",
      "The representation loss after processing this batch is:  0.0023454874753952026\n",
      "\n",
      "The classification loss after processing this batch is:  0.10406513512134552\n",
      "The representation loss after processing this batch is:  0.002256840467453003\n",
      "\n",
      "The classification loss after processing this batch is:  0.07668405026197433\n",
      "The representation loss after processing this batch is:  0.002150513231754303\n",
      "\n",
      "The classification loss after processing this batch is:  0.07080509513616562\n",
      "The representation loss after processing this batch is:  0.002677619457244873\n",
      "\n",
      "The classification loss after processing this batch is:  0.035335756838321686\n",
      "The representation loss after processing this batch is:  0.0026682987809181213\n",
      "\n",
      "The classification loss after processing this batch is:  0.07701277732849121\n",
      "The representation loss after processing this batch is:  0.0025950297713279724\n",
      "\n",
      "The classification loss after processing this batch is:  0.0927329808473587\n",
      "The representation loss after processing this batch is:  0.0023530572652816772\n",
      "\n",
      "The classification loss after processing this batch is:  0.07330586761236191\n",
      "The representation loss after processing this batch is:  0.002266496419906616\n",
      "\n",
      "The classification loss after processing this batch is:  0.1390955150127411\n",
      "The representation loss after processing this batch is:  0.0025395192205905914\n",
      "\n",
      "The classification loss after processing this batch is:  0.12402905523777008\n",
      "The representation loss after processing this batch is:  0.002496093511581421\n",
      "\n",
      "The classification loss after processing this batch is:  0.12752044200897217\n",
      "The representation loss after processing this batch is:  0.0021029487252235413\n",
      "\n",
      "The classification loss after processing this batch is:  0.1255197525024414\n",
      "The representation loss after processing this batch is:  0.002819530665874481\n",
      "\n",
      "The classification loss after processing this batch is:  0.04459763318300247\n",
      "The representation loss after processing this batch is:  0.0025764405727386475\n",
      "\n",
      "The classification loss after processing this batch is:  0.03163425624370575\n",
      "The representation loss after processing this batch is:  0.0023065097630023956\n",
      "\n",
      "The classification loss after processing this batch is:  0.06502088904380798\n",
      "The representation loss after processing this batch is:  0.002487175166606903\n",
      "\n",
      "The classification loss after processing this batch is:  0.09512310475111008\n",
      "The representation loss after processing this batch is:  0.0023804306983947754\n",
      "\n",
      "The classification loss after processing this batch is:  0.08412980288267136\n",
      "The representation loss after processing this batch is:  0.0022154226899147034\n",
      "\n",
      "The classification loss after processing this batch is:  0.08185312151908875\n",
      "The representation loss after processing this batch is:  0.0024980008602142334\n",
      "\n",
      "The classification loss after processing this batch is:  0.09542568773031235\n",
      "The representation loss after processing this batch is:  0.002851717174053192\n",
      "\n",
      "The classification loss after processing this batch is:  0.11136792600154877\n",
      "The representation loss after processing this batch is:  0.0025635212659835815\n",
      "\n",
      "The classification loss after processing this batch is:  0.1557653248310089\n",
      "The representation loss after processing this batch is:  0.002316385507583618\n",
      "\n",
      "The classification loss after processing this batch is:  0.12503479421138763\n",
      "The representation loss after processing this batch is:  0.0023989230394363403\n",
      "\n",
      "The classification loss after processing this batch is:  0.11780207604169846\n",
      "The representation loss after processing this batch is:  0.0022700130939483643\n",
      "\n",
      "The classification loss after processing this batch is:  0.05527980253100395\n",
      "The representation loss after processing this batch is:  0.0026218369603157043\n",
      "\n",
      "The classification loss after processing this batch is:  0.03044680692255497\n",
      "The representation loss after processing this batch is:  0.0025031939148902893\n",
      "\n",
      "The classification loss after processing this batch is:  0.10243582725524902\n",
      "The representation loss after processing this batch is:  0.0021370984613895416\n",
      "\n",
      "The classification loss after processing this batch is:  0.16161291301250458\n",
      "The representation loss after processing this batch is:  0.0022415220737457275\n",
      "\n",
      "The classification loss after processing this batch is:  0.11451368033885956\n",
      "The representation loss after processing this batch is:  0.00238974392414093\n",
      "\n",
      "The classification loss after processing this batch is:  0.1020561158657074\n",
      "The representation loss after processing this batch is:  0.0023823603987693787\n",
      "\n",
      "The classification loss after processing this batch is:  0.08876129239797592\n",
      "The representation loss after processing this batch is:  0.0022402331233024597\n",
      "\n",
      "The classification loss after processing this batch is:  0.1429242193698883\n",
      "The representation loss after processing this batch is:  0.0023767277598381042\n",
      "\n",
      "The classification loss after processing this batch is:  0.1843881905078888\n",
      "The representation loss after processing this batch is:  0.002338577061891556\n",
      "\n",
      "The classification loss after processing this batch is:  0.16819976270198822\n",
      "The representation loss after processing this batch is:  0.0025249719619750977\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1266026645898819\n",
      "The representation loss after processing this batch is:  0.0023960471153259277\n",
      "\n",
      "The classification loss after processing this batch is:  0.08038198947906494\n",
      "The representation loss after processing this batch is:  0.0030252039432525635\n",
      "\n",
      "The classification loss after processing this batch is:  0.05969579890370369\n",
      "The representation loss after processing this batch is:  0.002805955708026886\n",
      "\n",
      "The classification loss after processing this batch is:  0.08340180665254593\n",
      "The representation loss after processing this batch is:  0.002356927841901779\n",
      "\n",
      "The classification loss after processing this batch is:  0.06345978379249573\n",
      "The representation loss after processing this batch is:  0.002218089997768402\n",
      "\n",
      "The classification loss after processing this batch is:  0.04858450964093208\n",
      "The representation loss after processing this batch is:  0.002216823399066925\n",
      "\n",
      "The classification loss after processing this batch is:  0.02845027483999729\n",
      "The representation loss after processing this batch is:  0.002320416271686554\n",
      "\n",
      "The classification loss after processing this batch is:  0.10296691209077835\n",
      "The representation loss after processing this batch is:  0.002301633358001709\n",
      "\n",
      "The classification loss after processing this batch is:  0.05298979952931404\n",
      "The representation loss after processing this batch is:  0.00252532958984375\n",
      "\n",
      "The classification loss after processing this batch is:  0.07093335688114166\n",
      "The representation loss after processing this batch is:  0.002532549202442169\n",
      "\n",
      "The classification loss after processing this batch is:  0.07166311889886856\n",
      "The representation loss after processing this batch is:  0.0020428746938705444\n",
      "\n",
      "The classification loss after processing this batch is:  0.055970218032598495\n",
      "The representation loss after processing this batch is:  0.002282850444316864\n",
      "\n",
      "The classification loss after processing this batch is:  0.05819081887602806\n",
      "The representation loss after processing this batch is:  0.002556160092353821\n",
      "\n",
      "The classification loss after processing this batch is:  0.07237625122070312\n",
      "The representation loss after processing this batch is:  0.002343803644180298\n",
      "\n",
      "The classification loss after processing this batch is:  0.09698357433080673\n",
      "The representation loss after processing this batch is:  0.002595558762550354\n",
      "\n",
      "The classification loss after processing this batch is:  0.019267169758677483\n",
      "The representation loss after processing this batch is:  0.002536967396736145\n",
      "\n",
      "The classification loss after processing this batch is:  0.026843253523111343\n",
      "The representation loss after processing this batch is:  0.0025047436356544495\n",
      "\n",
      "The classification loss after processing this batch is:  0.11153842508792877\n",
      "The representation loss after processing this batch is:  0.0022352933883666992\n",
      "\n",
      "The classification loss after processing this batch is:  0.1343575417995453\n",
      "The representation loss after processing this batch is:  0.002277541905641556\n",
      "\n",
      "The classification loss after processing this batch is:  0.08634860068559647\n",
      "The representation loss after processing this batch is:  0.002479568123817444\n",
      "\n",
      "The classification loss after processing this batch is:  0.026927534490823746\n",
      "The representation loss after processing this batch is:  0.0021465234458446503\n",
      "\n",
      "The classification loss after processing this batch is:  0.08967336267232895\n",
      "The representation loss after processing this batch is:  0.002343185245990753\n",
      "\n",
      "The classification loss after processing this batch is:  0.01668214052915573\n",
      "The representation loss after processing this batch is:  0.0024231821298599243\n",
      "\n",
      "The classification loss after processing this batch is:  0.09398562461137772\n",
      "The representation loss after processing this batch is:  0.002367161214351654\n",
      "\n",
      "The classification loss after processing this batch is:  0.08604887127876282\n",
      "The representation loss after processing this batch is:  0.002431221306324005\n",
      "\n",
      "The classification loss after processing this batch is:  0.0672120675444603\n",
      "The representation loss after processing this batch is:  0.0022420138120651245\n",
      "\n",
      "The classification loss after processing this batch is:  0.04615875706076622\n",
      "The representation loss after processing this batch is:  0.002482287585735321\n",
      "\n",
      "The classification loss after processing this batch is:  0.07141343504190445\n",
      "The representation loss after processing this batch is:  0.002348475158214569\n",
      "\n",
      "The classification loss after processing this batch is:  0.03837967664003372\n",
      "The representation loss after processing this batch is:  0.0022852569818496704\n",
      "\n",
      "The classification loss after processing this batch is:  0.14264535903930664\n",
      "The representation loss after processing this batch is:  0.0024603307247161865\n",
      "\n",
      "The classification loss after processing this batch is:  0.22095447778701782\n",
      "The representation loss after processing this batch is:  0.002350207418203354\n",
      "\n",
      "The classification loss after processing this batch is:  0.14001692831516266\n",
      "The representation loss after processing this batch is:  0.002175215631723404\n",
      "\n",
      "The classification loss after processing this batch is:  0.16844739019870758\n",
      "The representation loss after processing this batch is:  0.002290245145559311\n",
      "\n",
      "The classification loss after processing this batch is:  0.08618945628404617\n",
      "The representation loss after processing this batch is:  0.0023935288190841675\n",
      "\n",
      "The classification loss after processing this batch is:  0.04744920879602432\n",
      "The representation loss after processing this batch is:  0.0022163093090057373\n",
      "\n",
      "The classification loss after processing this batch is:  0.15355834364891052\n",
      "The representation loss after processing this batch is:  0.002316907048225403\n",
      "\n",
      "The classification loss after processing this batch is:  0.10068931430578232\n",
      "The representation loss after processing this batch is:  0.0024425461888313293\n",
      "\n",
      "The classification loss after processing this batch is:  0.0888475626707077\n",
      "The representation loss after processing this batch is:  0.002384185791015625\n",
      "\n",
      "The classification loss after processing this batch is:  0.09457103163003922\n",
      "The representation loss after processing this batch is:  0.0025265440344810486\n",
      "\n",
      "The classification loss after processing this batch is:  0.11603179574012756\n",
      "The representation loss after processing this batch is:  0.0022501014173030853\n",
      "\n",
      "The classification loss after processing this batch is:  0.04838305711746216\n",
      "The representation loss after processing this batch is:  0.002251937985420227\n",
      "\n",
      "The classification loss after processing this batch is:  0.06532672047615051\n",
      "The representation loss after processing this batch is:  0.0025069937109947205\n",
      "\n",
      "The classification loss after processing this batch is:  0.09586867690086365\n",
      "The representation loss after processing this batch is:  0.002294182777404785\n",
      "\n",
      "The classification loss after processing this batch is:  0.02964305877685547\n",
      "The representation loss after processing this batch is:  0.0024715811014175415\n",
      "\n",
      "The classification loss after processing this batch is:  0.03372704237699509\n",
      "The representation loss after processing this batch is:  0.0024935342371463776\n",
      "\n",
      "The classification loss after processing this batch is:  0.09249836951494217\n",
      "The representation loss after processing this batch is:  0.0022255927324295044\n",
      "\n",
      "The classification loss after processing this batch is:  0.16192886233329773\n",
      "The representation loss after processing this batch is:  0.0023715347051620483\n",
      "\n",
      "The classification loss after processing this batch is:  0.03442725911736488\n",
      "The representation loss after processing this batch is:  0.0022233128547668457\n",
      "\n",
      "The classification loss after processing this batch is:  0.04453592374920845\n",
      "The representation loss after processing this batch is:  0.0021769292652606964\n",
      "\n",
      "The classification loss after processing this batch is:  0.12142308056354523\n",
      "The representation loss after processing this batch is:  0.002283945679664612\n",
      "\n",
      "The classification loss after processing this batch is:  0.1711912900209427\n",
      "The representation loss after processing this batch is:  0.0021983087062835693\n",
      "\n",
      "The classification loss after processing this batch is:  0.054079215973615646\n",
      "The representation loss after processing this batch is:  0.002185605466365814\n",
      "\n",
      "The classification loss after processing this batch is:  0.12972180545330048\n",
      "The representation loss after processing this batch is:  0.0021755732595920563\n",
      "\n",
      "The classification loss after processing this batch is:  0.05320189148187637\n",
      "The representation loss after processing this batch is:  0.00251595675945282\n",
      "\n",
      "The classification loss after processing this batch is:  0.021303225308656693\n",
      "The representation loss after processing this batch is:  0.002293728291988373\n",
      "\n",
      "The classification loss after processing this batch is:  0.02984655648469925\n",
      "The representation loss after processing this batch is:  0.002376250922679901\n",
      "\n",
      "The classification loss after processing this batch is:  0.09977301210165024\n",
      "The representation loss after processing this batch is:  0.002784229815006256\n",
      "\n",
      "The classification loss after processing this batch is:  0.11372251063585281\n",
      "The representation loss after processing this batch is:  0.0024606287479400635\n",
      "\n",
      "The classification loss after processing this batch is:  0.05793368071317673\n",
      "The representation loss after processing this batch is:  0.002892434597015381\n",
      "\n",
      "The classification loss after processing this batch is:  0.08609545975923538\n",
      "The representation loss after processing this batch is:  0.002187378704547882\n",
      "\n",
      "The classification loss after processing this batch is:  0.037589240819215775\n",
      "The representation loss after processing this batch is:  0.0023888573050498962\n",
      "\n",
      "The classification loss after processing this batch is:  0.11390639841556549\n",
      "The representation loss after processing this batch is:  0.0024455375969409943\n",
      "\n",
      "The classification loss after processing this batch is:  0.06880585849285126\n",
      "The representation loss after processing this batch is:  0.0021274611353874207\n",
      "\n",
      "The classification loss after processing this batch is:  0.1135060265660286\n",
      "The representation loss after processing this batch is:  0.0023731403052806854\n",
      "\n",
      "The classification loss after processing this batch is:  0.11610398441553116\n",
      "The representation loss after processing this batch is:  0.0025772079825401306\n",
      "\n",
      "The classification loss after processing this batch is:  0.21396544575691223\n",
      "The representation loss after processing this batch is:  0.0020778030157089233\n",
      "\n",
      "The classification loss after processing this batch is:  0.0854046493768692\n",
      "The representation loss after processing this batch is:  0.0020688772201538086\n",
      "\n",
      "The classification loss after processing this batch is:  0.13668832182884216\n",
      "The representation loss after processing this batch is:  0.0021450892090797424\n",
      "\n",
      "The classification loss after processing this batch is:  0.1349649429321289\n",
      "The representation loss after processing this batch is:  0.002272181212902069\n",
      "\n",
      "The classification loss after processing this batch is:  0.06396083533763885\n",
      "The representation loss after processing this batch is:  0.002302907407283783\n",
      "\n",
      "The classification loss after processing this batch is:  0.07313411682844162\n",
      "The representation loss after processing this batch is:  0.002652175724506378\n",
      "\n",
      "The classification loss after processing this batch is:  0.03944537788629532\n",
      "The representation loss after processing this batch is:  0.0025300905108451843\n",
      "\n",
      "The classification loss after processing this batch is:  0.10651662200689316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.0022190622985363007\n",
      "\n",
      "The classification loss after processing this batch is:  0.08316237479448318\n",
      "The representation loss after processing this batch is:  0.002003788948059082\n",
      "\n",
      "The classification loss after processing this batch is:  0.07134296000003815\n",
      "The representation loss after processing this batch is:  0.0021820515394210815\n",
      "\n",
      "The classification loss after processing this batch is:  0.08307339996099472\n",
      "The representation loss after processing this batch is:  0.0024132058024406433\n",
      "\n",
      "The classification loss after processing this batch is:  0.09098409116268158\n",
      "The representation loss after processing this batch is:  0.0022106319665908813\n",
      "\n",
      "The classification loss after processing this batch is:  0.08082924783229828\n",
      "The representation loss after processing this batch is:  0.0022709742188453674\n",
      "\n",
      "The classification loss after processing this batch is:  0.12832416594028473\n",
      "The representation loss after processing this batch is:  0.0023680850863456726\n",
      "\n",
      "The classification loss after processing this batch is:  0.07238611578941345\n",
      "The representation loss after processing this batch is:  0.002373836934566498\n",
      "\n",
      "The classification loss after processing this batch is:  0.06013865768909454\n",
      "The representation loss after processing this batch is:  0.00197785347700119\n",
      "\n",
      "The classification loss after processing this batch is:  0.06658459454774857\n",
      "The representation loss after processing this batch is:  0.002602122724056244\n",
      "\n",
      "The classification loss after processing this batch is:  0.1426510214805603\n",
      "The representation loss after processing this batch is:  0.0027766749262809753\n",
      "\n",
      "The classification loss after processing this batch is:  0.24934786558151245\n",
      "The representation loss after processing this batch is:  0.0026030242443084717\n",
      "\n",
      "The classification loss after processing this batch is:  0.0229774322360754\n",
      "The representation loss after processing this batch is:  0.002208452671766281\n",
      "\n",
      "The classification loss after processing this batch is:  0.0475674644112587\n",
      "The representation loss after processing this batch is:  0.0023219063878059387\n",
      "\n",
      "The classification loss after processing this batch is:  0.1555379033088684\n",
      "The representation loss after processing this batch is:  0.0026816800236701965\n",
      "\n",
      "The classification loss after processing this batch is:  0.03261939063668251\n",
      "The representation loss after processing this batch is:  0.002486810088157654\n",
      "\n",
      "The classification loss after processing this batch is:  0.03896333649754524\n",
      "The representation loss after processing this batch is:  0.0022750124335289\n",
      "\n",
      "The classification loss after processing this batch is:  0.09965724498033524\n",
      "The representation loss after processing this batch is:  0.0025681406259536743\n",
      "\n",
      "The classification loss after processing this batch is:  0.05369717255234718\n",
      "The representation loss after processing this batch is:  0.0025199800729751587\n",
      "\n",
      "The classification loss after processing this batch is:  0.10800499469041824\n",
      "The representation loss after processing this batch is:  0.002911515533924103\n",
      "\n",
      "The classification loss after processing this batch is:  0.09748038649559021\n",
      "The representation loss after processing this batch is:  0.0026899799704551697\n",
      "\n",
      "The classification loss after processing this batch is:  0.10253427922725677\n",
      "The representation loss after processing this batch is:  0.0028858333826065063\n",
      "\n",
      "The classification loss after processing this batch is:  0.08251111209392548\n",
      "The representation loss after processing this batch is:  0.0020875781774520874\n",
      "\n",
      "The classification loss after processing this batch is:  0.09952282160520554\n",
      "The representation loss after processing this batch is:  0.002177182585000992\n",
      "\n",
      "The classification loss after processing this batch is:  0.02321559563279152\n",
      "The representation loss after processing this batch is:  0.0022717565298080444\n",
      "\n",
      "The classification loss after processing this batch is:  0.028980553150177002\n",
      "The representation loss after processing this batch is:  0.0023663341999053955\n",
      "\n",
      "The classification loss after processing this batch is:  0.09034474939107895\n",
      "The representation loss after processing this batch is:  0.0024530142545700073\n",
      "\n",
      "The classification loss after processing this batch is:  0.05499766021966934\n",
      "The representation loss after processing this batch is:  0.002409428358078003\n",
      "\n",
      "The classification loss after processing this batch is:  0.08347126841545105\n",
      "The representation loss after processing this batch is:  0.0023410767316818237\n",
      "\n",
      "The classification loss after processing this batch is:  0.039806727319955826\n",
      "The representation loss after processing this batch is:  0.002300448715686798\n",
      "\n",
      "The classification loss after processing this batch is:  0.05496292933821678\n",
      "The representation loss after processing this batch is:  0.002347659319639206\n",
      "\n",
      "The classification loss after processing this batch is:  0.09648240357637405\n",
      "The representation loss after processing this batch is:  0.002281583845615387\n",
      "\n",
      "The classification loss after processing this batch is:  0.13744671642780304\n",
      "The representation loss after processing this batch is:  0.002608858048915863\n",
      "\n",
      "The classification loss after processing this batch is:  0.1585419923067093\n",
      "The representation loss after processing this batch is:  0.0022677481174468994\n",
      "\n",
      "The classification loss after processing this batch is:  0.06327665597200394\n",
      "The representation loss after processing this batch is:  0.0025550276041030884\n",
      "\n",
      "The classification loss after processing this batch is:  0.1471882313489914\n",
      "The representation loss after processing this batch is:  0.002234354615211487\n",
      "\n",
      "The classification loss after processing this batch is:  0.041586145758628845\n",
      "The representation loss after processing this batch is:  0.002151530236005783\n",
      "\n",
      "The classification loss after processing this batch is:  0.10061398148536682\n",
      "The representation loss after processing this batch is:  0.002346716821193695\n",
      "\n",
      "The classification loss after processing this batch is:  0.1894126981496811\n",
      "The representation loss after processing this batch is:  0.002790302038192749\n",
      "\n",
      "The classification loss after processing this batch is:  0.08420944958925247\n",
      "The representation loss after processing this batch is:  0.0021516308188438416\n",
      "\n",
      "The classification loss after processing this batch is:  0.10742350667715073\n",
      "The representation loss after processing this batch is:  0.002180013805627823\n",
      "\n",
      "The classification loss after processing this batch is:  0.08499810844659805\n",
      "The representation loss after processing this batch is:  0.0022885799407958984\n",
      "\n",
      "The classification loss after processing this batch is:  0.14966583251953125\n",
      "The representation loss after processing this batch is:  0.0022724904119968414\n",
      "\n",
      "The classification loss after processing this batch is:  0.08984985947608948\n",
      "The representation loss after processing this batch is:  0.0024688243865966797\n",
      "\n",
      "The classification loss after processing this batch is:  0.0694841668009758\n",
      "The representation loss after processing this batch is:  0.002307221293449402\n",
      "\n",
      "The classification loss after processing this batch is:  0.08459355682134628\n",
      "The representation loss after processing this batch is:  0.002374023199081421\n",
      "\n",
      "The classification loss after processing this batch is:  0.03212632238864899\n",
      "The representation loss after processing this batch is:  0.0024404674768447876\n",
      "\n",
      "The classification loss after processing this batch is:  0.028800297528505325\n",
      "The representation loss after processing this batch is:  0.0020926520228385925\n",
      "\n",
      "The classification loss after processing this batch is:  0.09341192245483398\n",
      "The representation loss after processing this batch is:  0.0026619210839271545\n",
      "\n",
      "The classification loss after processing this batch is:  0.032847560942173004\n",
      "The representation loss after processing this batch is:  0.00262518972158432\n",
      "\n",
      "The classification loss after processing this batch is:  0.151083841919899\n",
      "The representation loss after processing this batch is:  0.002496950328350067\n",
      "\n",
      "The classification loss after processing this batch is:  0.06253155320882797\n",
      "The representation loss after processing this batch is:  0.002311795949935913\n",
      "\n",
      "The classification loss after processing this batch is:  0.17001886665821075\n",
      "The representation loss after processing this batch is:  0.002336472272872925\n",
      "\n",
      "The classification loss after processing this batch is:  0.23937956988811493\n",
      "The representation loss after processing this batch is:  0.0021323226392269135\n",
      "\n",
      "The classification loss after processing this batch is:  0.09867262840270996\n",
      "The representation loss after processing this batch is:  0.002144336700439453\n",
      "\n",
      "The classification loss after processing this batch is:  0.027206087484955788\n",
      "The representation loss after processing this batch is:  0.002605114132165909\n",
      "\n",
      "The classification loss after processing this batch is:  0.04471995681524277\n",
      "The representation loss after processing this batch is:  0.0024927854537963867\n",
      "\n",
      "The classification loss after processing this batch is:  0.03140587732195854\n",
      "The representation loss after processing this batch is:  0.002707451581954956\n",
      "\n",
      "The classification loss after processing this batch is:  0.07369264960289001\n",
      "The representation loss after processing this batch is:  0.0025723204016685486\n",
      "\n",
      "The classification loss after processing this batch is:  0.08164170384407043\n",
      "The representation loss after processing this batch is:  0.0019827894866466522\n",
      "\n",
      "The classification loss after processing this batch is:  0.18392778933048248\n",
      "The representation loss after processing this batch is:  0.0023367367684841156\n",
      "\n",
      "The classification loss after processing this batch is:  0.1296481341123581\n",
      "The representation loss after processing this batch is:  0.0021605156362056732\n",
      "\n",
      "The classification loss after processing this batch is:  0.07905902713537216\n",
      "The representation loss after processing this batch is:  0.002733275294303894\n",
      "\n",
      "The classification loss after processing this batch is:  0.18112049996852875\n",
      "The representation loss after processing this batch is:  0.002849489450454712\n",
      "\n",
      "The classification loss after processing this batch is:  0.04133748263120651\n",
      "The representation loss after processing this batch is:  0.0024580880999565125\n",
      "\n",
      "The classification loss after processing this batch is:  0.07970236986875534\n",
      "The representation loss after processing this batch is:  0.002453688532114029\n",
      "\n",
      "The classification loss after processing this batch is:  0.12204543501138687\n",
      "The representation loss after processing this batch is:  0.0023161955177783966\n",
      "\n",
      "The classification loss after processing this batch is:  0.06160043552517891\n",
      "The representation loss after processing this batch is:  0.0026651769876480103\n",
      "\n",
      "The classification loss after processing this batch is:  0.11027710139751434\n",
      "The representation loss after processing this batch is:  0.0031094998121261597\n",
      "\n",
      "The classification loss after processing this batch is:  0.06384800374507904\n",
      "The representation loss after processing this batch is:  0.002529080957174301\n",
      "\n",
      "The classification loss after processing this batch is:  0.07851099222898483\n",
      "The representation loss after processing this batch is:  0.003188706934452057\n",
      "\n",
      "The classification loss after processing this batch is:  0.1615840643644333\n",
      "The representation loss after processing this batch is:  0.0027277059853076935\n",
      "\n",
      "The classification loss after processing this batch is:  0.057778771966695786\n",
      "The representation loss after processing this batch is:  0.0028386563062667847\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.13520580530166626\n",
      "The representation loss after processing this batch is:  0.002428025007247925\n",
      "\n",
      "The classification loss after processing this batch is:  0.18675632774829865\n",
      "The representation loss after processing this batch is:  0.0021427571773529053\n",
      "\n",
      "The classification loss after processing this batch is:  0.0841040387749672\n",
      "The representation loss after processing this batch is:  0.002313479781150818\n",
      "\n",
      "The classification loss after processing this batch is:  0.11403323709964752\n",
      "The representation loss after processing this batch is:  0.0021426528692245483\n",
      "\n",
      "The classification loss after processing this batch is:  0.06085457280278206\n",
      "The representation loss after processing this batch is:  0.0027312040328979492\n",
      "\n",
      "The classification loss after processing this batch is:  0.026000920683145523\n",
      "The representation loss after processing this batch is:  0.0023274198174476624\n",
      "\n",
      "The classification loss after processing this batch is:  0.08942622691392899\n",
      "The representation loss after processing this batch is:  0.0025351792573928833\n",
      "\n",
      "The classification loss after processing this batch is:  0.045101914554834366\n",
      "The representation loss after processing this batch is:  0.0026171058416366577\n",
      "\n",
      "The classification loss after processing this batch is:  0.19816279411315918\n",
      "The representation loss after processing this batch is:  0.002179645001888275\n",
      "\n",
      "The classification loss after processing this batch is:  0.0386679582297802\n",
      "The representation loss after processing this batch is:  0.002641148865222931\n",
      "\n",
      "The classification loss after processing this batch is:  0.08471149951219559\n",
      "The representation loss after processing this batch is:  0.0022766515612602234\n",
      "\n",
      "The classification loss after processing this batch is:  0.13796518743038177\n",
      "The representation loss after processing this batch is:  0.00230967253446579\n",
      "\n",
      "The classification loss after processing this batch is:  0.10284863412380219\n",
      "The representation loss after processing this batch is:  0.002278551459312439\n",
      "\n",
      "The classification loss after processing this batch is:  0.09175776690244675\n",
      "The representation loss after processing this batch is:  0.0023445338010787964\n",
      "\n",
      "The classification loss after processing this batch is:  0.051108501851558685\n",
      "The representation loss after processing this batch is:  0.0023417621850967407\n",
      "\n",
      "The classification loss after processing this batch is:  0.05140912905335426\n",
      "The representation loss after processing this batch is:  0.002136021852493286\n",
      "\n",
      "The classification loss after processing this batch is:  0.03293175250291824\n",
      "The representation loss after processing this batch is:  0.0022537410259246826\n",
      "\n",
      "The classification loss after processing this batch is:  0.13604339957237244\n",
      "The representation loss after processing this batch is:  0.0031293556094169617\n",
      "\n",
      "The classification loss after processing this batch is:  0.12671713531017303\n",
      "The representation loss after processing this batch is:  0.0024359039962291718\n",
      "\n",
      "The classification loss after processing this batch is:  0.12123627960681915\n",
      "The representation loss after processing this batch is:  0.0019513070583343506\n",
      "\n",
      "The classification loss after processing this batch is:  0.11866395175457001\n",
      "The representation loss after processing this batch is:  0.002239830791950226\n",
      "\n",
      "The classification loss after processing this batch is:  0.2575058043003082\n",
      "The representation loss after processing this batch is:  0.0021271146833896637\n",
      "\n",
      "The classification loss after processing this batch is:  0.08724164217710495\n",
      "The representation loss after processing this batch is:  0.0027512088418006897\n",
      "\n",
      "The classification loss after processing this batch is:  0.1675717979669571\n",
      "The representation loss after processing this batch is:  0.002396136522293091\n",
      "\n",
      "The classification loss after processing this batch is:  0.0864918902516365\n",
      "The representation loss after processing this batch is:  0.0024866461753845215\n",
      "\n",
      "The classification loss after processing this batch is:  0.061185240745544434\n",
      "The representation loss after processing this batch is:  0.00225859135389328\n",
      "\n",
      "The classification loss after processing this batch is:  0.037673238664865494\n",
      "The representation loss after processing this batch is:  0.0021809563040733337\n",
      "\n",
      "The classification loss after processing this batch is:  0.04910159856081009\n",
      "The representation loss after processing this batch is:  0.002423681318759918\n",
      "\n",
      "The classification loss after processing this batch is:  0.194758340716362\n",
      "The representation loss after processing this batch is:  0.0024865642189979553\n",
      "\n",
      "The classification loss after processing this batch is:  0.079661063849926\n",
      "The representation loss after processing this batch is:  0.0024783387780189514\n",
      "\n",
      "The classification loss after processing this batch is:  0.07975491136312485\n",
      "The representation loss after processing this batch is:  0.002912089228630066\n",
      "\n",
      "The classification loss after processing this batch is:  0.07414290308952332\n",
      "The representation loss after processing this batch is:  0.0027267783880233765\n",
      "\n",
      "The classification loss after processing this batch is:  0.056510888040065765\n",
      "The representation loss after processing this batch is:  0.0024846643209457397\n",
      "\n",
      "The classification loss after processing this batch is:  0.041418857872486115\n",
      "The representation loss after processing this batch is:  0.0024281740188598633\n",
      "\n",
      "The classification loss after processing this batch is:  0.12795673310756683\n",
      "The representation loss after processing this batch is:  0.002227962017059326\n",
      "\n",
      "The classification loss after processing this batch is:  0.2045903205871582\n",
      "The representation loss after processing this batch is:  0.00237114354968071\n",
      "\n",
      "The classification loss after processing this batch is:  0.13791997730731964\n",
      "The representation loss after processing this batch is:  0.0026579201221466064\n",
      "\n",
      "The classification loss after processing this batch is:  0.09584765136241913\n",
      "The representation loss after processing this batch is:  0.0021961182355880737\n",
      "\n",
      "The classification loss after processing this batch is:  0.2810475528240204\n",
      "The representation loss after processing this batch is:  0.00210484117269516\n",
      "\n",
      "The classification loss after processing this batch is:  0.04979012906551361\n",
      "The representation loss after processing this batch is:  0.0022449493408203125\n",
      "\n",
      "The classification loss after processing this batch is:  0.08890564739704132\n",
      "The representation loss after processing this batch is:  0.0021799132227897644\n",
      "\n",
      "The classification loss after processing this batch is:  0.10350009053945541\n",
      "The representation loss after processing this batch is:  0.0027607157826423645\n",
      "\n",
      "The classification loss after processing this batch is:  0.05956967920064926\n",
      "The representation loss after processing this batch is:  0.002232886850833893\n",
      "\n",
      "The classification loss after processing this batch is:  0.10984381288290024\n",
      "The representation loss after processing this batch is:  0.002335585653781891\n",
      "\n",
      "The classification loss after processing this batch is:  0.05165109783411026\n",
      "The representation loss after processing this batch is:  0.0026613622903823853\n",
      "\n",
      "The classification loss after processing this batch is:  0.12316145747900009\n",
      "The representation loss after processing this batch is:  0.0023729056119918823\n",
      "\n",
      "The classification loss after processing this batch is:  0.14627036452293396\n",
      "The representation loss after processing this batch is:  0.002553686499595642\n",
      "\n",
      "The classification loss after processing this batch is:  0.15870101749897003\n",
      "The representation loss after processing this batch is:  0.002280913293361664\n",
      "\n",
      "The classification loss after processing this batch is:  0.07589808851480484\n",
      "The representation loss after processing this batch is:  0.002485141158103943\n",
      "\n",
      "The classification loss after processing this batch is:  0.05261549726128578\n",
      "The representation loss after processing this batch is:  0.0027432814240455627\n",
      "\n",
      "The classification loss after processing this batch is:  0.11799004673957825\n",
      "The representation loss after processing this batch is:  0.002258390188217163\n",
      "\n",
      "The classification loss after processing this batch is:  0.11842004954814911\n",
      "The representation loss after processing this batch is:  0.002393733710050583\n",
      "\n",
      "The classification loss after processing this batch is:  0.01339862309396267\n",
      "The representation loss after processing this batch is:  0.0023359134793281555\n",
      "\n",
      "The classification loss after processing this batch is:  0.09004195034503937\n",
      "The representation loss after processing this batch is:  0.0021998994052410126\n",
      "\n",
      "The classification loss after processing this batch is:  0.1946985125541687\n",
      "The representation loss after processing this batch is:  0.002582468092441559\n",
      "\n",
      "The classification loss after processing this batch is:  0.1937943994998932\n",
      "The representation loss after processing this batch is:  0.0026327967643737793\n",
      "\n",
      "The classification loss after processing this batch is:  0.1863422989845276\n",
      "The representation loss after processing this batch is:  0.002234283834695816\n",
      "\n",
      "The classification loss after processing this batch is:  0.15229544043540955\n",
      "The representation loss after processing this batch is:  0.0021490752696990967\n",
      "\n",
      "The classification loss after processing this batch is:  0.04374328628182411\n",
      "The representation loss after processing this batch is:  0.002328529953956604\n",
      "\n",
      "The classification loss after processing this batch is:  0.09872400015592575\n",
      "The representation loss after processing this batch is:  0.0021447166800498962\n",
      "\n",
      "The classification loss after processing this batch is:  0.07814755290746689\n",
      "The representation loss after processing this batch is:  0.002528224140405655\n",
      "\n",
      "The classification loss after processing this batch is:  0.1477634757757187\n",
      "The representation loss after processing this batch is:  0.0026295706629753113\n",
      "\n",
      "The classification loss after processing this batch is:  0.1079697385430336\n",
      "The representation loss after processing this batch is:  0.0026365071535110474\n",
      "\n",
      "The classification loss after processing this batch is:  0.10475926101207733\n",
      "The representation loss after processing this batch is:  0.002643898129463196\n",
      "\n",
      "The classification loss after processing this batch is:  0.05774499475955963\n",
      "The representation loss after processing this batch is:  0.0023454315960407257\n",
      "\n",
      "The classification loss after processing this batch is:  0.043720707297325134\n",
      "The representation loss after processing this batch is:  0.002338513731956482\n",
      "\n",
      "The classification loss after processing this batch is:  0.16930599510669708\n",
      "The representation loss after processing this batch is:  0.002549991011619568\n",
      "\n",
      "The classification loss after processing this batch is:  0.11958322674036026\n",
      "The representation loss after processing this batch is:  0.0022637248039245605\n",
      "\n",
      "The classification loss after processing this batch is:  0.0785297080874443\n",
      "The representation loss after processing this batch is:  0.002269584685564041\n",
      "\n",
      "The classification loss after processing this batch is:  0.18637995421886444\n",
      "The representation loss after processing this batch is:  0.0030446648597717285\n",
      "\n",
      "The classification loss after processing this batch is:  0.2247876673936844\n",
      "The representation loss after processing this batch is:  0.0027497000992298126\n",
      "\n",
      "The classification loss after processing this batch is:  0.13812536001205444\n",
      "The representation loss after processing this batch is:  0.002583444118499756\n",
      "\n",
      "The classification loss after processing this batch is:  0.06201884523034096\n",
      "The representation loss after processing this batch is:  0.002487979829311371\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10090724378824234\n",
      "The representation loss after processing this batch is:  0.002592235803604126\n",
      "\n",
      "The classification loss after processing this batch is:  0.048163462430238724\n",
      "The representation loss after processing this batch is:  0.0025658831000328064\n",
      "\n",
      "The classification loss after processing this batch is:  0.1389656662940979\n",
      "The representation loss after processing this batch is:  0.0026180967688560486\n",
      "\n",
      "The classification loss after processing this batch is:  0.09381452202796936\n",
      "The representation loss after processing this batch is:  0.0027462467551231384\n",
      "\n",
      "The classification loss after processing this batch is:  0.08365596830844879\n",
      "The representation loss after processing this batch is:  0.002742268145084381\n",
      "\n",
      "The classification loss after processing this batch is:  0.21613234281539917\n",
      "The representation loss after processing this batch is:  0.002268552780151367\n",
      "\n",
      "The classification loss after processing this batch is:  0.04451131075620651\n",
      "The representation loss after processing this batch is:  0.002503909170627594\n",
      "\n",
      "The classification loss after processing this batch is:  0.037084244191646576\n",
      "The representation loss after processing this batch is:  0.0027673542499542236\n",
      "\n",
      "The classification loss after processing this batch is:  0.04187830910086632\n",
      "The representation loss after processing this batch is:  0.0022652670741081238\n",
      "\n",
      "The classification loss after processing this batch is:  0.09337002784013748\n",
      "The representation loss after processing this batch is:  0.002202104777097702\n",
      "\n",
      "The classification loss after processing this batch is:  0.17182333767414093\n",
      "The representation loss after processing this batch is:  0.002427525818347931\n",
      "\n",
      "The classification loss after processing this batch is:  0.09390173107385635\n",
      "The representation loss after processing this batch is:  0.002277784049510956\n",
      "\n",
      "The classification loss after processing this batch is:  0.08738924562931061\n",
      "The representation loss after processing this batch is:  0.0023584887385368347\n",
      "\n",
      "The classification loss after processing this batch is:  0.023625755682587624\n",
      "The representation loss after processing this batch is:  0.0021554678678512573\n",
      "\n",
      "The classification loss after processing this batch is:  0.06787899136543274\n",
      "The representation loss after processing this batch is:  0.0023035407066345215\n",
      "\n",
      "The classification loss after processing this batch is:  0.06428620219230652\n",
      "The representation loss after processing this batch is:  0.002455197274684906\n",
      "\n",
      "The classification loss after processing this batch is:  0.025209767743945122\n",
      "The representation loss after processing this batch is:  0.0025144964456558228\n",
      "\n",
      "The classification loss after processing this batch is:  0.08527624607086182\n",
      "The representation loss after processing this batch is:  0.0022290870547294617\n",
      "\n",
      "The classification loss after processing this batch is:  0.14244651794433594\n",
      "The representation loss after processing this batch is:  0.0021942928433418274\n",
      "\n",
      "The classification loss after processing this batch is:  0.17935749888420105\n",
      "The representation loss after processing this batch is:  0.002298980951309204\n",
      "\n",
      "The classification loss after processing this batch is:  0.019620807841420174\n",
      "The representation loss after processing this batch is:  0.0022009722888469696\n",
      "\n",
      "The classification loss after processing this batch is:  0.02896273136138916\n",
      "The representation loss after processing this batch is:  0.0023431330919265747\n",
      "\n",
      "The classification loss after processing this batch is:  0.05478968098759651\n",
      "The representation loss after processing this batch is:  0.002629615366458893\n",
      "\n",
      "The classification loss after processing this batch is:  0.12228219956159592\n",
      "The representation loss after processing this batch is:  0.0022733546793460846\n",
      "\n",
      "The classification loss after processing this batch is:  0.04113539680838585\n",
      "The representation loss after processing this batch is:  0.0025493353605270386\n",
      "\n",
      "The classification loss after processing this batch is:  0.1260794997215271\n",
      "The representation loss after processing this batch is:  0.0025489553809165955\n",
      "\n",
      "The classification loss after processing this batch is:  0.13949862122535706\n",
      "The representation loss after processing this batch is:  0.002431679517030716\n",
      "\n",
      "The classification loss after processing this batch is:  0.1204986646771431\n",
      "The representation loss after processing this batch is:  0.0026552602648735046\n",
      "\n",
      "The classification loss after processing this batch is:  0.09028498083353043\n",
      "The representation loss after processing this batch is:  0.002578388899564743\n",
      "\n",
      "The classification loss after processing this batch is:  0.04225444793701172\n",
      "The representation loss after processing this batch is:  0.002525821328163147\n",
      "\n",
      "The classification loss after processing this batch is:  0.11393558979034424\n",
      "The representation loss after processing this batch is:  0.002199307084083557\n",
      "\n",
      "The classification loss after processing this batch is:  0.13637153804302216\n",
      "The representation loss after processing this batch is:  0.0023795515298843384\n",
      "\n",
      "The classification loss after processing this batch is:  0.05246507376432419\n",
      "The representation loss after processing this batch is:  0.0023866593837738037\n",
      "\n",
      "The classification loss after processing this batch is:  0.029522299766540527\n",
      "The representation loss after processing this batch is:  0.002245970070362091\n",
      "\n",
      "The classification loss after processing this batch is:  0.18910656869411469\n",
      "The representation loss after processing this batch is:  0.0023371651768684387\n",
      "\n",
      "The classification loss after processing this batch is:  0.17820720374584198\n",
      "The representation loss after processing this batch is:  0.0021984800696372986\n",
      "\n",
      "The classification loss after processing this batch is:  0.06754383444786072\n",
      "The representation loss after processing this batch is:  0.002243146300315857\n",
      "\n",
      "The classification loss after processing this batch is:  0.21465761959552765\n",
      "The representation loss after processing this batch is:  0.0024266988039016724\n",
      "\n",
      "The classification loss after processing this batch is:  0.20804689824581146\n",
      "The representation loss after processing this batch is:  0.0023451820015907288\n",
      "\n",
      "The classification loss after processing this batch is:  0.2778763175010681\n",
      "The representation loss after processing this batch is:  0.0023460760712623596\n",
      "\n",
      "The classification loss after processing this batch is:  0.10626403987407684\n",
      "The representation loss after processing this batch is:  0.002602003514766693\n",
      "\n",
      "The classification loss after processing this batch is:  0.06087108701467514\n",
      "The representation loss after processing this batch is:  0.0022523105144500732\n",
      "\n",
      "The classification loss after processing this batch is:  0.12438169121742249\n",
      "The representation loss after processing this batch is:  0.002528741955757141\n",
      "\n",
      "The classification loss after processing this batch is:  0.06211858615279198\n",
      "The representation loss after processing this batch is:  0.002444721758365631\n",
      "\n",
      "The classification loss after processing this batch is:  0.043733034282922745\n",
      "The representation loss after processing this batch is:  0.0026933327317237854\n",
      "\n",
      "The classification loss after processing this batch is:  0.07287272810935974\n",
      "The representation loss after processing this batch is:  0.0021166056394577026\n",
      "\n",
      "The classification loss after processing this batch is:  0.03801380842924118\n",
      "The representation loss after processing this batch is:  0.002360999584197998\n",
      "\n",
      "The classification loss after processing this batch is:  0.011602417565882206\n",
      "The representation loss after processing this batch is:  0.00267096608877182\n",
      "\n",
      "The classification loss after processing this batch is:  0.07572747766971588\n",
      "The representation loss after processing this batch is:  0.0022784285247325897\n",
      "\n",
      "The classification loss after processing this batch is:  0.10854029655456543\n",
      "The representation loss after processing this batch is:  0.0021310076117515564\n",
      "\n",
      "The classification loss after processing this batch is:  0.05859522894024849\n",
      "The representation loss after processing this batch is:  0.002556845545768738\n",
      "\n",
      "The classification loss after processing this batch is:  0.0745968148112297\n",
      "The representation loss after processing this batch is:  0.0023190975189208984\n",
      "\n",
      "The classification loss after processing this batch is:  0.10961856693029404\n",
      "The representation loss after processing this batch is:  0.0023331567645072937\n",
      "\n",
      "The classification loss after processing this batch is:  0.02515387535095215\n",
      "The representation loss after processing this batch is:  0.0023621171712875366\n",
      "\n",
      "The classification loss after processing this batch is:  0.13266649842262268\n",
      "The representation loss after processing this batch is:  0.0025052130222320557\n",
      "\n",
      "The classification loss after processing this batch is:  0.06102064996957779\n",
      "The representation loss after processing this batch is:  0.002157926559448242\n",
      "\n",
      "The classification loss after processing this batch is:  0.17068073153495789\n",
      "The representation loss after processing this batch is:  0.0022347792983055115\n",
      "\n",
      "The classification loss after processing this batch is:  0.1116015762090683\n",
      "The representation loss after processing this batch is:  0.0024002566933631897\n",
      "\n",
      "The classification loss after processing this batch is:  0.09505270421504974\n",
      "The representation loss after processing this batch is:  0.0020938292145729065\n",
      "\n",
      "The classification loss after processing this batch is:  0.02926633320748806\n",
      "The representation loss after processing this batch is:  0.0021645426750183105\n",
      "\n",
      "The classification loss after processing this batch is:  0.02724086120724678\n",
      "The representation loss after processing this batch is:  0.0022810325026512146\n",
      "\n",
      "The classification loss after processing this batch is:  0.1388256549835205\n",
      "The representation loss after processing this batch is:  0.002470884472131729\n",
      "\n",
      "The classification loss after processing this batch is:  0.03260352090001106\n",
      "The representation loss after processing this batch is:  0.0025396347045898438\n",
      "\n",
      "The classification loss after processing this batch is:  0.09645936638116837\n",
      "The representation loss after processing this batch is:  0.0024312734603881836\n",
      "\n",
      "The classification loss after processing this batch is:  0.056099794805049896\n",
      "The representation loss after processing this batch is:  0.002642333507537842\n",
      "\n",
      "The classification loss after processing this batch is:  0.056849535554647446\n",
      "The representation loss after processing this batch is:  0.0024766921997070312\n",
      "\n",
      "The classification loss after processing this batch is:  0.08118225634098053\n",
      "The representation loss after processing this batch is:  0.002356134355068207\n",
      "\n",
      "The classification loss after processing this batch is:  0.04346640035510063\n",
      "The representation loss after processing this batch is:  0.002477794885635376\n",
      "\n",
      "The classification loss after processing this batch is:  0.055710624903440475\n",
      "The representation loss after processing this batch is:  0.0028629153966903687\n",
      "\n",
      "The classification loss after processing this batch is:  0.18038848042488098\n",
      "The representation loss after processing this batch is:  0.0023475363850593567\n",
      "\n",
      "The classification loss after processing this batch is:  0.14484241604804993\n",
      "The representation loss after processing this batch is:  0.0025833100080490112\n",
      "\n",
      "The classification loss after processing this batch is:  0.1417238861322403\n",
      "The representation loss after processing this batch is:  0.002552434802055359\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1737825721502304\n",
      "The representation loss after processing this batch is:  0.002501249313354492\n",
      "\n",
      "The classification loss after processing this batch is:  0.07257010042667389\n",
      "The representation loss after processing this batch is:  0.002170935273170471\n",
      "\n",
      "The classification loss after processing this batch is:  0.08377205580472946\n",
      "The representation loss after processing this batch is:  0.002221234142780304\n",
      "\n",
      "The classification loss after processing this batch is:  0.0418982170522213\n",
      "The representation loss after processing this batch is:  0.002287536859512329\n",
      "\n",
      "The classification loss after processing this batch is:  0.050523094832897186\n",
      "The representation loss after processing this batch is:  0.0023141130805015564\n",
      "\n",
      "The classification loss after processing this batch is:  0.03546712547540665\n",
      "The representation loss after processing this batch is:  0.0024379342794418335\n",
      "\n",
      "The classification loss after processing this batch is:  0.08110497146844864\n",
      "The representation loss after processing this batch is:  0.002084333449602127\n",
      "\n",
      "The classification loss after processing this batch is:  0.07481877505779266\n",
      "The representation loss after processing this batch is:  0.0025057047605514526\n",
      "\n",
      "The classification loss after processing this batch is:  0.09515237808227539\n",
      "The representation loss after processing this batch is:  0.0024170801043510437\n",
      "\n",
      "The classification loss after processing this batch is:  0.04457710683345795\n",
      "The representation loss after processing this batch is:  0.0022190287709236145\n",
      "\n",
      "The classification loss after processing this batch is:  0.13262537121772766\n",
      "The representation loss after processing this batch is:  0.0021585077047348022\n",
      "\n",
      "The classification loss after processing this batch is:  0.05487227067351341\n",
      "The representation loss after processing this batch is:  0.002490609884262085\n",
      "\n",
      "The classification loss after processing this batch is:  0.11744323372840881\n",
      "The representation loss after processing this batch is:  0.0023105591535568237\n",
      "\n",
      "The classification loss after processing this batch is:  0.11974707990884781\n",
      "The representation loss after processing this batch is:  0.002530418336391449\n",
      "\n",
      "The classification loss after processing this batch is:  0.09095823764801025\n",
      "The representation loss after processing this batch is:  0.0025399327278137207\n",
      "\n",
      "The classification loss after processing this batch is:  0.05775374919176102\n",
      "The representation loss after processing this batch is:  0.0024906620383262634\n",
      "\n",
      "The classification loss after processing this batch is:  0.17631825804710388\n",
      "The representation loss after processing this batch is:  0.0024188533425331116\n",
      "\n",
      "The classification loss after processing this batch is:  0.0622091218829155\n",
      "The representation loss after processing this batch is:  0.002427302300930023\n",
      "\n",
      "The classification loss after processing this batch is:  0.05447350814938545\n",
      "The representation loss after processing this batch is:  0.0021962225437164307\n",
      "\n",
      "The classification loss after processing this batch is:  0.06766603142023087\n",
      "The representation loss after processing this batch is:  0.0022678934037685394\n",
      "\n",
      "The classification loss after processing this batch is:  0.05404834821820259\n",
      "The representation loss after processing this batch is:  0.0022114142775535583\n",
      "\n",
      "The classification loss after processing this batch is:  0.14388208091259003\n",
      "The representation loss after processing this batch is:  0.0022743307054042816\n",
      "\n",
      "The classification loss after processing this batch is:  0.13499552011489868\n",
      "The representation loss after processing this batch is:  0.0024734660983085632\n",
      "\n",
      "The classification loss after processing this batch is:  0.07434521615505219\n",
      "The representation loss after processing this batch is:  0.0027550682425498962\n",
      "\n",
      "The classification loss after processing this batch is:  0.06030894070863724\n",
      "The representation loss after processing this batch is:  0.002485044300556183\n",
      "\n",
      "The classification loss after processing this batch is:  0.07384464889764786\n",
      "The representation loss after processing this batch is:  0.002610735595226288\n",
      "\n",
      "The classification loss after processing this batch is:  0.1519262045621872\n",
      "The representation loss after processing this batch is:  0.0023995637893676758\n",
      "\n",
      "The classification loss after processing this batch is:  0.04543600231409073\n",
      "The representation loss after processing this batch is:  0.0023187845945358276\n",
      "\n",
      "The classification loss after processing this batch is:  0.05645466595888138\n",
      "The representation loss after processing this batch is:  0.002612009644508362\n",
      "\n",
      "The classification loss after processing this batch is:  0.137409970164299\n",
      "The representation loss after processing this batch is:  0.0021851398050785065\n",
      "\n",
      "The classification loss after processing this batch is:  0.275905042886734\n",
      "The representation loss after processing this batch is:  0.002362683415412903\n",
      "\n",
      "The classification loss after processing this batch is:  0.08300735056400299\n",
      "The representation loss after processing this batch is:  0.0021958351135253906\n",
      "\n",
      "The classification loss after processing this batch is:  0.09428904950618744\n",
      "The representation loss after processing this batch is:  0.0021825507283210754\n",
      "\n",
      "The classification loss after processing this batch is:  0.03438995033502579\n",
      "The representation loss after processing this batch is:  0.00243571400642395\n",
      "\n",
      "The classification loss after processing this batch is:  0.020678123459219933\n",
      "The representation loss after processing this batch is:  0.0021731965243816376\n",
      "\n",
      "The classification loss after processing this batch is:  0.07778746634721756\n",
      "The representation loss after processing this batch is:  0.003057621419429779\n",
      "\n",
      "The classification loss after processing this batch is:  0.06003088131546974\n",
      "The representation loss after processing this batch is:  0.003307446837425232\n",
      "\n",
      "The classification loss after processing this batch is:  0.03663691505789757\n",
      "The representation loss after processing this batch is:  0.002306077629327774\n",
      "\n",
      "The classification loss after processing this batch is:  0.04033640772104263\n",
      "The representation loss after processing this batch is:  0.0021231696009635925\n",
      "\n",
      "The classification loss after processing this batch is:  0.13917095959186554\n",
      "The representation loss after processing this batch is:  0.002198483794927597\n",
      "\n",
      "The classification loss after processing this batch is:  0.09979395568370819\n",
      "The representation loss after processing this batch is:  0.0022524818778038025\n",
      "\n",
      "The classification loss after processing this batch is:  0.04585733264684677\n",
      "The representation loss after processing this batch is:  0.0020231306552886963\n",
      "\n",
      "The classification loss after processing this batch is:  0.05086944252252579\n",
      "The representation loss after processing this batch is:  0.0024227946996688843\n",
      "\n",
      "The classification loss after processing this batch is:  0.17889514565467834\n",
      "The representation loss after processing this batch is:  0.0022546127438545227\n",
      "\n",
      "The classification loss after processing this batch is:  0.16136257350444794\n",
      "The representation loss after processing this batch is:  0.002524331212043762\n",
      "\n",
      "The classification loss after processing this batch is:  0.13458481431007385\n",
      "The representation loss after processing this batch is:  0.0021213144063949585\n",
      "\n",
      "The classification loss after processing this batch is:  0.10413482040166855\n",
      "The representation loss after processing this batch is:  0.002540692687034607\n",
      "\n",
      "The classification loss after processing this batch is:  0.12471672892570496\n",
      "The representation loss after processing this batch is:  0.0023271553218364716\n",
      "\n",
      "The classification loss after processing this batch is:  0.07760824263095856\n",
      "The representation loss after processing this batch is:  0.002734765410423279\n",
      "\n",
      "The classification loss after processing this batch is:  0.05455070734024048\n",
      "The representation loss after processing this batch is:  0.002672150731086731\n",
      "\n",
      "The classification loss after processing this batch is:  0.030350958928465843\n",
      "The representation loss after processing this batch is:  0.0025504380464553833\n",
      "\n",
      "The classification loss after processing this batch is:  0.05576058477163315\n",
      "The representation loss after processing this batch is:  0.0022113099694252014\n",
      "\n",
      "The classification loss after processing this batch is:  0.1468154937028885\n",
      "The representation loss after processing this batch is:  0.0023422949016094208\n",
      "\n",
      "The classification loss after processing this batch is:  0.06206519156694412\n",
      "The representation loss after processing this batch is:  0.0030044913291931152\n",
      "\n",
      "The classification loss after processing this batch is:  0.03011615201830864\n",
      "The representation loss after processing this batch is:  0.0023002326488494873\n",
      "\n",
      "The classification loss after processing this batch is:  0.018616389483213425\n",
      "The representation loss after processing this batch is:  0.002973593771457672\n",
      "\n",
      "The classification loss after processing this batch is:  0.019899781793355942\n",
      "The representation loss after processing this batch is:  0.0027116090059280396\n",
      "\n",
      "The classification loss after processing this batch is:  0.05139872059226036\n",
      "The representation loss after processing this batch is:  0.002866111695766449\n",
      "\n",
      "The classification loss after processing this batch is:  0.0442415326833725\n",
      "The representation loss after processing this batch is:  0.0027548596262931824\n",
      "\n",
      "The classification loss after processing this batch is:  0.02665010280907154\n",
      "The representation loss after processing this batch is:  0.002524137496948242\n",
      "\n",
      "The classification loss after processing this batch is:  0.01251507643610239\n",
      "The representation loss after processing this batch is:  0.002714909613132477\n",
      "\n",
      "The classification loss after processing this batch is:  0.02224980667233467\n",
      "The representation loss after processing this batch is:  0.0034719184041023254\n",
      "\n",
      "The classification loss after processing this batch is:  0.06839869171380997\n",
      "The representation loss after processing this batch is:  0.0033031851053237915\n",
      "\n",
      "The classification loss after processing this batch is:  0.008024636656045914\n",
      "The representation loss after processing this batch is:  0.003376014530658722\n",
      "\n",
      "The classification loss after processing this batch is:  0.01981491595506668\n",
      "The representation loss after processing this batch is:  0.002741791307926178\n",
      "\n",
      "The classification loss after processing this batch is:  0.15622442960739136\n",
      "The representation loss after processing this batch is:  0.00272243469953537\n",
      "\n",
      "The classification loss after processing this batch is:  0.016984479501843452\n",
      "The representation loss after processing this batch is:  0.0031167715787887573\n",
      "\n",
      "The classification loss after processing this batch is:  0.006989947985857725\n",
      "The representation loss after processing this batch is:  0.002856209874153137\n",
      "\n",
      "The classification loss after processing this batch is:  0.014415565878152847\n",
      "The representation loss after processing this batch is:  0.0027563869953155518\n",
      "\n",
      "The classification loss after processing this batch is:  0.017077064141631126\n",
      "The representation loss after processing this batch is:  0.0028617531061172485\n",
      "\n",
      "The classification loss after processing this batch is:  0.014376131817698479\n",
      "The representation loss after processing this batch is:  0.003069087862968445\n",
      "\n",
      "The classification loss after processing this batch is:  0.015385810285806656\n",
      "The representation loss after processing this batch is:  0.003075025975704193\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.012099528685212135\n",
      "The representation loss after processing this batch is:  0.0031099915504455566\n",
      "\n",
      "The classification loss after processing this batch is:  0.13231204450130463\n",
      "The representation loss after processing this batch is:  0.0033548176288604736\n",
      "\n",
      "The classification loss after processing this batch is:  0.2723830044269562\n",
      "The representation loss after processing this batch is:  0.0031415820121765137\n",
      "\n",
      "The classification loss after processing this batch is:  0.16421392560005188\n",
      "The representation loss after processing this batch is:  0.003527313470840454\n",
      "\n",
      "The classification loss after processing this batch is:  0.039155106991529465\n",
      "The representation loss after processing this batch is:  0.00264054536819458\n",
      "\n",
      "The classification loss after processing this batch is:  0.011813354678452015\n",
      "The representation loss after processing this batch is:  0.003160335123538971\n",
      "\n",
      "The classification loss after processing this batch is:  0.012071569450199604\n",
      "The representation loss after processing this batch is:  0.002335280179977417\n",
      "\n",
      "The classification loss after processing this batch is:  0.12591448426246643\n",
      "The representation loss after processing this batch is:  0.002156071364879608\n",
      "\n",
      "The classification loss after processing this batch is:  0.29216042160987854\n",
      "The representation loss after processing this batch is:  0.002716459333896637\n",
      "\n",
      "The classification loss after processing this batch is:  0.045935459434986115\n",
      "The representation loss after processing this batch is:  0.0024214237928390503\n",
      "\n",
      "The classification loss after processing this batch is:  0.032175734639167786\n",
      "The representation loss after processing this batch is:  0.0030637606978416443\n",
      "\n",
      "The classification loss after processing this batch is:  0.025500809773802757\n",
      "The representation loss after processing this batch is:  0.002836965024471283\n",
      "\n",
      "The classification loss after processing this batch is:  0.03337724134325981\n",
      "The representation loss after processing this batch is:  0.0032529309391975403\n",
      "\n",
      "Done training..\n",
      "=*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*=\n"
     ]
    }
   ],
   "source": [
    "modelMM = NeuralModel()\n",
    "model = train_model(modelMM, training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_data):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "\n",
    "    for batch in test_data:\n",
    "        batch_images, batch_labels = batch\n",
    "\n",
    "        batch_images = batch_images.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        predictions = model(batch_images)\n",
    "       \n",
    "        predictions = predictions.data.max(1, keepdim=True)[1]\n",
    "       \n",
    "        correct += predictions.eq(batch_labels.data.view_as(predictions)).sum()\n",
    "       \n",
    "\n",
    "    accuracy = float(correct.item() / len(test_data.dataset))\n",
    "    \n",
    "    print(\"The classifier accuracy is: \", 100 * accuracy)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier accuracy is:  96.67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9667"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64)\n",
    "test_model(modelMM, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.3\tTest Accuracy = 6144 / 10000 = 0.6144\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=512)\n",
    "acc, _ = test_attack(modelMM, device, test_loader, epsilon=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
