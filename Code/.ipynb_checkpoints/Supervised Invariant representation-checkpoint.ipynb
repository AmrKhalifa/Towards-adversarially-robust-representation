{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import data_loader\n",
    "from multiple_attacks import * \n",
    "import pickle\n",
    "from utils.viewer import show_batch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.mmd import MMD_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = data_loader.get_data()\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_channels = 8\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(1, num_channels, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(num_channels, eps=1e-05, momentum=0.5, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_channels, eps=1e-05, momentum=0.5, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(num_channels, num_channels, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(num_channels, eps=1e-05, momentum=0.5, affine=True),\n",
    "            nn.ReLU(inplace=True)\n",
    "\n",
    "        )\n",
    "        self.fc1 = nn.Linear(num_channels * 4 ** 2, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        convolved = self.conv(x)\n",
    "        after_fc1 = self.fc1(convolved.view(convolved.size(0), -1))\n",
    "        output = self.fc2(after_fc1)\n",
    "        return output\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \n",
    "        convolved = self.conv(x)\n",
    "        code = self.fc1(convolved.view(convolved.size(0), -1))\n",
    "        \n",
    "        return code\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=512)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=512)\n",
    "\n",
    "first_batch = next(iter(train_loader))\n",
    "first_images, first_labels = first_batch \n",
    "\n",
    "print(first_images.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = NeuralModel()\n",
    "#train_model(model, train_loader)\n",
    "#test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = torch.utils.data.DataLoader(test_set, batch_size=1)\n",
    "# train_loader = torch.utils.data.DataLoader(train_set, batch_size=1)\n",
    "# #acc, adv_examples = test_attack(model, device, train_loader, epsilon=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(adv_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('models/train_adv_examples.pkl', 'wb') as f:\n",
    "#     pickle.dump(adv_examples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/train_adv_examples.pkl', 'rb') as f:\n",
    "    adv_examples = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels =[]\n",
    "adv_labels = [] \n",
    "adv_images =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in adv_examples:\n",
    "    true_l, adv_l, adv_img = example\n",
    "    \n",
    "    true_labels.append(true_l)\n",
    "    adv_labels.append(adv_l)\n",
    "    adv_images.append(adv_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = torch.Tensor(true_labels).long()\n",
    "adv_images = torch.Tensor(adv_images).reshape(-1,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "b_size = 60\n",
    "training_data = []\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=b_size)\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_iter = iter(train_loader)\n",
    "\n",
    "for b in range (0, len(train_loader)*b_size, b_size):\n",
    "    batch_images, batch_labels = next(train_loader_iter)\n",
    "    training_data.append((batch_images, adv_images[b: b+b_size], true_labels[b: b+b_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "60\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 0, 2, 7, 1, 8, 6, 4, 1, 6, 3, 4, 1, 9, 1, 3, 3, 8, 5, 4, 7, 7, 4, 2,\n",
      "        8, 5, 8, 6, 9, 3, 4, 6, 1, 9, 9, 6, 0, 3, 7, 2, 8, 2, 9, 4, 4, 6, 4, 9,\n",
      "        7, 0, 9, 2, 7, 5, 1, 5, 9, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "training_data_iter = iter(training_data)\n",
    "b1 = next(training_data_iter)\n",
    "b1 = next(training_data_iter)\n",
    "b1 = next(training_data_iter)\n",
    "a,b,c = b1\n",
    "\n",
    "print(len(a))\n",
    "print(len(b))\n",
    "print(len(c))\n",
    "\n",
    "show_batch(a)\n",
    "show_batch(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    n_epochs = 10\n",
    "    model.train()\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    print(\"training ...\")\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch in train_data:\n",
    "            batch_images, adv_images, batch_labels = batch\n",
    "\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            adv_images = adv_images.to(device)\n",
    "            \n",
    "            batch_output = model(batch_images)\n",
    "            \n",
    "            latent_1 = model.encode(batch_images)\n",
    "            latent_2 = model.encode(adv_images)\n",
    "            \n",
    "            down_stream_loss = criterion(batch_output, batch_labels)\n",
    "            representation_loss = MMD_Loss(latent_1, latent_2)\n",
    "            \n",
    "            total_loss = down_stream_loss + 100*representation_loss\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(\"The classification loss after processing this batch is: \", down_stream_loss.item())\n",
    "            print(\"The representation loss after processing this batch is: \", representation_loss.item())\n",
    "            print(\"\")\n",
    "            \n",
    "    print(\"Done training..\")\n",
    "    print(\"=*=\"*20)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MMD_Loss(x, y):\n",
    "    \n",
    "    alpha =1\n",
    "    B=b_size\n",
    "\n",
    "    x = x.view(x.size(0), x.size(1) * 1)\n",
    "    y = y.view(y.size(0), y.size(1) * 1)\n",
    "\n",
    "    xx, yy, zz = torch.mm(x,x.t()), torch.mm(y,y.t()), torch.mm(x,y.t())\n",
    "\n",
    "    rx = (xx.diag().unsqueeze(0).expand_as(xx))\n",
    "    ry = (yy.diag().unsqueeze(0).expand_as(yy))\n",
    "\n",
    "    K = torch.exp(- alpha * (rx.t() + rx - 2*xx))\n",
    "    L = torch.exp(- alpha * (ry.t() + ry - 2*yy))\n",
    "    P = torch.exp(- alpha * (rx.t() + ry - 2*zz))\n",
    "\n",
    "    beta = (1./(B*(B-1)))\n",
    "    gamma = (2./(B*B)) \n",
    "\n",
    "    return beta * (torch.sum(K)+torch.sum(L)) - gamma * torch.sum(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ...\n",
      "The classification loss after processing this batch is:  2.321028232574463\n",
      "The representation loss after processing this batch is:  0.03902006149291992\n",
      "\n",
      "The classification loss after processing this batch is:  2.2999541759490967\n",
      "The representation loss after processing this batch is:  0.035895586013793945\n",
      "\n",
      "The classification loss after processing this batch is:  2.3489716053009033\n",
      "The representation loss after processing this batch is:  0.04436624050140381\n",
      "\n",
      "The classification loss after processing this batch is:  2.310011625289917\n",
      "The representation loss after processing this batch is:  0.03585779666900635\n",
      "\n",
      "The classification loss after processing this batch is:  2.305407762527466\n",
      "The representation loss after processing this batch is:  0.026587843894958496\n",
      "\n",
      "The classification loss after processing this batch is:  2.3219268321990967\n",
      "The representation loss after processing this batch is:  0.026927411556243896\n",
      "\n",
      "The classification loss after processing this batch is:  2.337002754211426\n",
      "The representation loss after processing this batch is:  0.024752438068389893\n",
      "\n",
      "The classification loss after processing this batch is:  2.2655081748962402\n",
      "The representation loss after processing this batch is:  0.035362422466278076\n",
      "\n",
      "The classification loss after processing this batch is:  2.3051934242248535\n",
      "The representation loss after processing this batch is:  0.027370840311050415\n",
      "\n",
      "The classification loss after processing this batch is:  2.3097665309906006\n",
      "The representation loss after processing this batch is:  0.027917474508285522\n",
      "\n",
      "The classification loss after processing this batch is:  2.3050646781921387\n",
      "The representation loss after processing this batch is:  0.02676260471343994\n",
      "\n",
      "The classification loss after processing this batch is:  2.3246798515319824\n",
      "The representation loss after processing this batch is:  0.02801746129989624\n",
      "\n",
      "The classification loss after processing this batch is:  2.292374610900879\n",
      "The representation loss after processing this batch is:  0.03281807899475098\n",
      "\n",
      "The classification loss after processing this batch is:  2.3288543224334717\n",
      "The representation loss after processing this batch is:  0.028194129467010498\n",
      "\n",
      "The classification loss after processing this batch is:  2.279010057449341\n",
      "The representation loss after processing this batch is:  0.027067571878433228\n",
      "\n",
      "The classification loss after processing this batch is:  2.2510833740234375\n",
      "The representation loss after processing this batch is:  0.026789307594299316\n",
      "\n",
      "The classification loss after processing this batch is:  2.291836738586426\n",
      "The representation loss after processing this batch is:  0.029429197311401367\n",
      "\n",
      "The classification loss after processing this batch is:  2.3088953495025635\n",
      "The representation loss after processing this batch is:  0.02840876579284668\n",
      "\n",
      "The classification loss after processing this batch is:  2.299975633621216\n",
      "The representation loss after processing this batch is:  0.029415816068649292\n",
      "\n",
      "The classification loss after processing this batch is:  2.3047471046447754\n",
      "The representation loss after processing this batch is:  0.0260888934135437\n",
      "\n",
      "The classification loss after processing this batch is:  2.3437156677246094\n",
      "The representation loss after processing this batch is:  0.025876402854919434\n",
      "\n",
      "The classification loss after processing this batch is:  2.286175489425659\n",
      "The representation loss after processing this batch is:  0.025722205638885498\n",
      "\n",
      "The classification loss after processing this batch is:  2.289984941482544\n",
      "The representation loss after processing this batch is:  0.028971433639526367\n",
      "\n",
      "The classification loss after processing this batch is:  2.2703499794006348\n",
      "The representation loss after processing this batch is:  0.02467074990272522\n",
      "\n",
      "The classification loss after processing this batch is:  2.3179104328155518\n",
      "The representation loss after processing this batch is:  0.03244999051094055\n",
      "\n",
      "The classification loss after processing this batch is:  2.3039937019348145\n",
      "The representation loss after processing this batch is:  0.02485877275466919\n",
      "\n",
      "The classification loss after processing this batch is:  2.278273105621338\n",
      "The representation loss after processing this batch is:  0.025789707899093628\n",
      "\n",
      "The classification loss after processing this batch is:  2.272533655166626\n",
      "The representation loss after processing this batch is:  0.03136783838272095\n",
      "\n",
      "The classification loss after processing this batch is:  2.282744884490967\n",
      "The representation loss after processing this batch is:  0.030981242656707764\n",
      "\n",
      "The classification loss after processing this batch is:  2.2741200923919678\n",
      "The representation loss after processing this batch is:  0.026266634464263916\n",
      "\n",
      "The classification loss after processing this batch is:  2.2855782508850098\n",
      "The representation loss after processing this batch is:  0.028407275676727295\n",
      "\n",
      "The classification loss after processing this batch is:  2.2799558639526367\n",
      "The representation loss after processing this batch is:  0.023291021585464478\n",
      "\n",
      "The classification loss after processing this batch is:  2.296983003616333\n",
      "The representation loss after processing this batch is:  0.028885722160339355\n",
      "\n",
      "The classification loss after processing this batch is:  2.2799391746520996\n",
      "The representation loss after processing this batch is:  0.030674397945404053\n",
      "\n",
      "The classification loss after processing this batch is:  2.288421869277954\n",
      "The representation loss after processing this batch is:  0.02819645404815674\n",
      "\n",
      "The classification loss after processing this batch is:  2.2699027061462402\n",
      "The representation loss after processing this batch is:  0.026696741580963135\n",
      "\n",
      "The classification loss after processing this batch is:  2.3036839962005615\n",
      "The representation loss after processing this batch is:  0.03193432092666626\n",
      "\n",
      "The classification loss after processing this batch is:  2.241034984588623\n",
      "The representation loss after processing this batch is:  0.025493860244750977\n",
      "\n",
      "The classification loss after processing this batch is:  2.262550115585327\n",
      "The representation loss after processing this batch is:  0.024579167366027832\n",
      "\n",
      "The classification loss after processing this batch is:  2.2935855388641357\n",
      "The representation loss after processing this batch is:  0.02830970287322998\n",
      "\n",
      "The classification loss after processing this batch is:  2.286207437515259\n",
      "The representation loss after processing this batch is:  0.02770209312438965\n",
      "\n",
      "The classification loss after processing this batch is:  2.2530126571655273\n",
      "The representation loss after processing this batch is:  0.026740729808807373\n",
      "\n",
      "The classification loss after processing this batch is:  2.2444756031036377\n",
      "The representation loss after processing this batch is:  0.02687358856201172\n",
      "\n",
      "The classification loss after processing this batch is:  2.2324728965759277\n",
      "The representation loss after processing this batch is:  0.02773606777191162\n",
      "\n",
      "The classification loss after processing this batch is:  2.2839789390563965\n",
      "The representation loss after processing this batch is:  0.024180829524993896\n",
      "\n",
      "The classification loss after processing this batch is:  2.2671990394592285\n",
      "The representation loss after processing this batch is:  0.026343166828155518\n",
      "\n",
      "The classification loss after processing this batch is:  2.279087781906128\n",
      "The representation loss after processing this batch is:  0.027457386255264282\n",
      "\n",
      "The classification loss after processing this batch is:  2.2962329387664795\n",
      "The representation loss after processing this batch is:  0.026122957468032837\n",
      "\n",
      "The classification loss after processing this batch is:  2.2703564167022705\n",
      "The representation loss after processing this batch is:  0.029018938541412354\n",
      "\n",
      "The classification loss after processing this batch is:  2.254014253616333\n",
      "The representation loss after processing this batch is:  0.026181846857070923\n",
      "\n",
      "The classification loss after processing this batch is:  2.257262706756592\n",
      "The representation loss after processing this batch is:  0.022769004106521606\n",
      "\n",
      "The classification loss after processing this batch is:  2.2742812633514404\n",
      "The representation loss after processing this batch is:  0.025255709886550903\n",
      "\n",
      "The classification loss after processing this batch is:  2.2497944831848145\n",
      "The representation loss after processing this batch is:  0.02601224184036255\n",
      "\n",
      "The classification loss after processing this batch is:  2.247286796569824\n",
      "The representation loss after processing this batch is:  0.028412699699401855\n",
      "\n",
      "The classification loss after processing this batch is:  2.2332305908203125\n",
      "The representation loss after processing this batch is:  0.022433340549468994\n",
      "\n",
      "The classification loss after processing this batch is:  2.2863306999206543\n",
      "The representation loss after processing this batch is:  0.028284907341003418\n",
      "\n",
      "The classification loss after processing this batch is:  2.2473127841949463\n",
      "The representation loss after processing this batch is:  0.021934807300567627\n",
      "\n",
      "The classification loss after processing this batch is:  2.232398271560669\n",
      "The representation loss after processing this batch is:  0.025811851024627686\n",
      "\n",
      "The classification loss after processing this batch is:  2.2318339347839355\n",
      "The representation loss after processing this batch is:  0.028892844915390015\n",
      "\n",
      "The classification loss after processing this batch is:  2.2689473628997803\n",
      "The representation loss after processing this batch is:  0.021998047828674316\n",
      "\n",
      "The classification loss after processing this batch is:  2.239638090133667\n",
      "The representation loss after processing this batch is:  0.022227704524993896\n",
      "\n",
      "The classification loss after processing this batch is:  2.228257417678833\n",
      "The representation loss after processing this batch is:  0.023738235235214233\n",
      "\n",
      "The classification loss after processing this batch is:  2.2386891841888428\n",
      "The representation loss after processing this batch is:  0.02279144525527954\n",
      "\n",
      "The classification loss after processing this batch is:  2.2361562252044678\n",
      "The representation loss after processing this batch is:  0.027107983827590942\n",
      "\n",
      "The classification loss after processing this batch is:  2.2429590225219727\n",
      "The representation loss after processing this batch is:  0.021700382232666016\n",
      "\n",
      "The classification loss after processing this batch is:  2.248821973800659\n",
      "The representation loss after processing this batch is:  0.02210375666618347\n",
      "\n",
      "The classification loss after processing this batch is:  2.232024908065796\n",
      "The representation loss after processing this batch is:  0.024524062871932983\n",
      "\n",
      "The classification loss after processing this batch is:  2.234097957611084\n",
      "The representation loss after processing this batch is:  0.022667646408081055\n",
      "\n",
      "The classification loss after processing this batch is:  2.245607614517212\n",
      "The representation loss after processing this batch is:  0.028406262397766113\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  2.241546392440796\n",
      "The representation loss after processing this batch is:  0.026256263256072998\n",
      "\n",
      "The classification loss after processing this batch is:  2.2036163806915283\n",
      "The representation loss after processing this batch is:  0.026196956634521484\n",
      "\n",
      "The classification loss after processing this batch is:  2.232673406600952\n",
      "The representation loss after processing this batch is:  0.02695128321647644\n",
      "\n",
      "The classification loss after processing this batch is:  2.2012131214141846\n",
      "The representation loss after processing this batch is:  0.0239560604095459\n",
      "\n",
      "The classification loss after processing this batch is:  2.2535951137542725\n",
      "The representation loss after processing this batch is:  0.020803213119506836\n",
      "\n",
      "The classification loss after processing this batch is:  2.2262065410614014\n",
      "The representation loss after processing this batch is:  0.023197442293167114\n",
      "\n",
      "The classification loss after processing this batch is:  2.217569589614868\n",
      "The representation loss after processing this batch is:  0.0209217369556427\n",
      "\n",
      "The classification loss after processing this batch is:  2.1846303939819336\n",
      "The representation loss after processing this batch is:  0.021307796239852905\n",
      "\n",
      "The classification loss after processing this batch is:  2.1904237270355225\n",
      "The representation loss after processing this batch is:  0.021800339221954346\n",
      "\n",
      "The classification loss after processing this batch is:  2.21710205078125\n",
      "The representation loss after processing this batch is:  0.023058056831359863\n",
      "\n",
      "The classification loss after processing this batch is:  2.219846487045288\n",
      "The representation loss after processing this batch is:  0.021802157163619995\n",
      "\n",
      "The classification loss after processing this batch is:  2.2291321754455566\n",
      "The representation loss after processing this batch is:  0.02617591619491577\n",
      "\n",
      "The classification loss after processing this batch is:  2.193190813064575\n",
      "The representation loss after processing this batch is:  0.023514926433563232\n",
      "\n",
      "The classification loss after processing this batch is:  2.2125768661499023\n",
      "The representation loss after processing this batch is:  0.02024349570274353\n",
      "\n",
      "The classification loss after processing this batch is:  2.1916556358337402\n",
      "The representation loss after processing this batch is:  0.02015364170074463\n",
      "\n",
      "The classification loss after processing this batch is:  2.1711080074310303\n",
      "The representation loss after processing this batch is:  0.024097532033920288\n",
      "\n",
      "The classification loss after processing this batch is:  2.205350399017334\n",
      "The representation loss after processing this batch is:  0.02098900079727173\n",
      "\n",
      "The classification loss after processing this batch is:  2.162419557571411\n",
      "The representation loss after processing this batch is:  0.02103489637374878\n",
      "\n",
      "The classification loss after processing this batch is:  2.1881051063537598\n",
      "The representation loss after processing this batch is:  0.022008061408996582\n",
      "\n",
      "The classification loss after processing this batch is:  2.1726396083831787\n",
      "The representation loss after processing this batch is:  0.018373101949691772\n",
      "\n",
      "The classification loss after processing this batch is:  2.1693196296691895\n",
      "The representation loss after processing this batch is:  0.021973520517349243\n",
      "\n",
      "The classification loss after processing this batch is:  2.169884443283081\n",
      "The representation loss after processing this batch is:  0.020978927612304688\n",
      "\n",
      "The classification loss after processing this batch is:  2.1727027893066406\n",
      "The representation loss after processing this batch is:  0.02114802598953247\n",
      "\n",
      "The classification loss after processing this batch is:  2.150954246520996\n",
      "The representation loss after processing this batch is:  0.022712677717208862\n",
      "\n",
      "The classification loss after processing this batch is:  2.114253520965576\n",
      "The representation loss after processing this batch is:  0.02164033055305481\n",
      "\n",
      "The classification loss after processing this batch is:  2.150620937347412\n",
      "The representation loss after processing this batch is:  0.024509906768798828\n",
      "\n",
      "The classification loss after processing this batch is:  2.1918063163757324\n",
      "The representation loss after processing this batch is:  0.02406403422355652\n",
      "\n",
      "The classification loss after processing this batch is:  2.1740193367004395\n",
      "The representation loss after processing this batch is:  0.021450966596603394\n",
      "\n",
      "The classification loss after processing this batch is:  2.1713333129882812\n",
      "The representation loss after processing this batch is:  0.023788422346115112\n",
      "\n",
      "The classification loss after processing this batch is:  2.1621882915496826\n",
      "The representation loss after processing this batch is:  0.02194395661354065\n",
      "\n",
      "The classification loss after processing this batch is:  2.1754238605499268\n",
      "The representation loss after processing this batch is:  0.020282775163650513\n",
      "\n",
      "The classification loss after processing this batch is:  2.1635100841522217\n",
      "The representation loss after processing this batch is:  0.019841909408569336\n",
      "\n",
      "The classification loss after processing this batch is:  2.1638782024383545\n",
      "The representation loss after processing this batch is:  0.018329739570617676\n",
      "\n",
      "The classification loss after processing this batch is:  2.1947646141052246\n",
      "The representation loss after processing this batch is:  0.02232077717781067\n",
      "\n",
      "The classification loss after processing this batch is:  2.169055223464966\n",
      "The representation loss after processing this batch is:  0.0213262140750885\n",
      "\n",
      "The classification loss after processing this batch is:  2.142362356185913\n",
      "The representation loss after processing this batch is:  0.019641876220703125\n",
      "\n",
      "The classification loss after processing this batch is:  2.159619092941284\n",
      "The representation loss after processing this batch is:  0.020535707473754883\n",
      "\n",
      "The classification loss after processing this batch is:  2.1401846408843994\n",
      "The representation loss after processing this batch is:  0.02133077383041382\n",
      "\n",
      "The classification loss after processing this batch is:  2.1359059810638428\n",
      "The representation loss after processing this batch is:  0.01956087350845337\n",
      "\n",
      "The classification loss after processing this batch is:  2.1028335094451904\n",
      "The representation loss after processing this batch is:  0.018400222063064575\n",
      "\n",
      "The classification loss after processing this batch is:  2.0778963565826416\n",
      "The representation loss after processing this batch is:  0.01856398582458496\n",
      "\n",
      "The classification loss after processing this batch is:  2.1433827877044678\n",
      "The representation loss after processing this batch is:  0.019911468029022217\n",
      "\n",
      "The classification loss after processing this batch is:  2.0944478511810303\n",
      "The representation loss after processing this batch is:  0.026246190071105957\n",
      "\n",
      "The classification loss after processing this batch is:  2.1161508560180664\n",
      "The representation loss after processing this batch is:  0.024232327938079834\n",
      "\n",
      "The classification loss after processing this batch is:  2.1161201000213623\n",
      "The representation loss after processing this batch is:  0.020133525133132935\n",
      "\n",
      "The classification loss after processing this batch is:  2.1424760818481445\n",
      "The representation loss after processing this batch is:  0.02018597722053528\n",
      "\n",
      "The classification loss after processing this batch is:  2.131913661956787\n",
      "The representation loss after processing this batch is:  0.020778268575668335\n",
      "\n",
      "The classification loss after processing this batch is:  2.162091016769409\n",
      "The representation loss after processing this batch is:  0.019434064626693726\n",
      "\n",
      "The classification loss after processing this batch is:  2.1089413166046143\n",
      "The representation loss after processing this batch is:  0.01671662926673889\n",
      "\n",
      "The classification loss after processing this batch is:  2.093611001968384\n",
      "The representation loss after processing this batch is:  0.01892969012260437\n",
      "\n",
      "The classification loss after processing this batch is:  2.156104564666748\n",
      "The representation loss after processing this batch is:  0.019083768129348755\n",
      "\n",
      "The classification loss after processing this batch is:  2.1183881759643555\n",
      "The representation loss after processing this batch is:  0.02139398455619812\n",
      "\n",
      "The classification loss after processing this batch is:  2.135103940963745\n",
      "The representation loss after processing this batch is:  0.018287241458892822\n",
      "\n",
      "The classification loss after processing this batch is:  2.1080360412597656\n",
      "The representation loss after processing this batch is:  0.020868808031082153\n",
      "\n",
      "The classification loss after processing this batch is:  2.1253647804260254\n",
      "The representation loss after processing this batch is:  0.01790747046470642\n",
      "\n",
      "The classification loss after processing this batch is:  2.069542169570923\n",
      "The representation loss after processing this batch is:  0.01802811026573181\n",
      "\n",
      "The classification loss after processing this batch is:  2.0740513801574707\n",
      "The representation loss after processing this batch is:  0.01730594038963318\n",
      "\n",
      "The classification loss after processing this batch is:  2.041703224182129\n",
      "The representation loss after processing this batch is:  0.020504891872406006\n",
      "\n",
      "The classification loss after processing this batch is:  2.112532138824463\n",
      "The representation loss after processing this batch is:  0.019187450408935547\n",
      "\n",
      "The classification loss after processing this batch is:  2.0623536109924316\n",
      "The representation loss after processing this batch is:  0.020840108394622803\n",
      "\n",
      "The classification loss after processing this batch is:  2.133331060409546\n",
      "The representation loss after processing this batch is:  0.018531590700149536\n",
      "\n",
      "The classification loss after processing this batch is:  2.102299690246582\n",
      "The representation loss after processing this batch is:  0.016999512910842896\n",
      "\n",
      "The classification loss after processing this batch is:  2.1035654544830322\n",
      "The representation loss after processing this batch is:  0.017081499099731445\n",
      "\n",
      "The classification loss after processing this batch is:  2.0843546390533447\n",
      "The representation loss after processing this batch is:  0.015908032655715942\n",
      "\n",
      "The classification loss after processing this batch is:  2.097433567047119\n",
      "The representation loss after processing this batch is:  0.019978880882263184\n",
      "\n",
      "The classification loss after processing this batch is:  2.075251817703247\n",
      "The representation loss after processing this batch is:  0.01741117238998413\n",
      "\n",
      "The classification loss after processing this batch is:  2.0148425102233887\n",
      "The representation loss after processing this batch is:  0.016647279262542725\n",
      "\n",
      "The classification loss after processing this batch is:  2.0882139205932617\n",
      "The representation loss after processing this batch is:  0.019364625215530396\n",
      "\n",
      "The classification loss after processing this batch is:  2.0984864234924316\n",
      "The representation loss after processing this batch is:  0.020376533269882202\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  2.0201382637023926\n",
      "The representation loss after processing this batch is:  0.017597079277038574\n",
      "\n",
      "The classification loss after processing this batch is:  2.007007122039795\n",
      "The representation loss after processing this batch is:  0.01628682017326355\n",
      "\n",
      "The classification loss after processing this batch is:  2.1211044788360596\n",
      "The representation loss after processing this batch is:  0.02180725336074829\n",
      "\n",
      "The classification loss after processing this batch is:  2.0787503719329834\n",
      "The representation loss after processing this batch is:  0.016749173402786255\n",
      "\n",
      "The classification loss after processing this batch is:  2.0181987285614014\n",
      "The representation loss after processing this batch is:  0.016603946685791016\n",
      "\n",
      "The classification loss after processing this batch is:  2.132784366607666\n",
      "The representation loss after processing this batch is:  0.017755717039108276\n",
      "\n",
      "The classification loss after processing this batch is:  2.041926860809326\n",
      "The representation loss after processing this batch is:  0.015902608633041382\n",
      "\n",
      "The classification loss after processing this batch is:  2.0773496627807617\n",
      "The representation loss after processing this batch is:  0.01684015989303589\n",
      "\n",
      "The classification loss after processing this batch is:  2.0474178791046143\n",
      "The representation loss after processing this batch is:  0.018100053071975708\n",
      "\n",
      "The classification loss after processing this batch is:  2.071505069732666\n",
      "The representation loss after processing this batch is:  0.017191320657730103\n",
      "\n",
      "The classification loss after processing this batch is:  2.046776294708252\n",
      "The representation loss after processing this batch is:  0.01633569598197937\n",
      "\n",
      "The classification loss after processing this batch is:  2.0005600452423096\n",
      "The representation loss after processing this batch is:  0.014994829893112183\n",
      "\n",
      "The classification loss after processing this batch is:  1.9876097440719604\n",
      "The representation loss after processing this batch is:  0.01540917158126831\n",
      "\n",
      "The classification loss after processing this batch is:  1.9724611043930054\n",
      "The representation loss after processing this batch is:  0.017250746488571167\n",
      "\n",
      "The classification loss after processing this batch is:  2.009448766708374\n",
      "The representation loss after processing this batch is:  0.01671081781387329\n",
      "\n",
      "The classification loss after processing this batch is:  1.9899367094039917\n",
      "The representation loss after processing this batch is:  0.015959560871124268\n",
      "\n",
      "The classification loss after processing this batch is:  2.053731679916382\n",
      "The representation loss after processing this batch is:  0.015506178140640259\n",
      "\n",
      "The classification loss after processing this batch is:  1.9901808500289917\n",
      "The representation loss after processing this batch is:  0.01610240340232849\n",
      "\n",
      "The classification loss after processing this batch is:  1.994701623916626\n",
      "The representation loss after processing this batch is:  0.014016777276992798\n",
      "\n",
      "The classification loss after processing this batch is:  2.0092203617095947\n",
      "The representation loss after processing this batch is:  0.015307813882827759\n",
      "\n",
      "The classification loss after processing this batch is:  2.015324592590332\n",
      "The representation loss after processing this batch is:  0.014686048030853271\n",
      "\n",
      "The classification loss after processing this batch is:  2.0270183086395264\n",
      "The representation loss after processing this batch is:  0.014463245868682861\n",
      "\n",
      "The classification loss after processing this batch is:  2.006155252456665\n",
      "The representation loss after processing this batch is:  0.01740404963493347\n",
      "\n",
      "The classification loss after processing this batch is:  1.9269860982894897\n",
      "The representation loss after processing this batch is:  0.015120595693588257\n",
      "\n",
      "The classification loss after processing this batch is:  2.030646324157715\n",
      "The representation loss after processing this batch is:  0.01436278223991394\n",
      "\n",
      "The classification loss after processing this batch is:  1.9332371950149536\n",
      "The representation loss after processing this batch is:  0.01650291681289673\n",
      "\n",
      "The classification loss after processing this batch is:  1.9871914386749268\n",
      "The representation loss after processing this batch is:  0.014308542013168335\n",
      "\n",
      "The classification loss after processing this batch is:  1.916091799736023\n",
      "The representation loss after processing this batch is:  0.015289247035980225\n",
      "\n",
      "The classification loss after processing this batch is:  1.955668568611145\n",
      "The representation loss after processing this batch is:  0.01348567008972168\n",
      "\n",
      "The classification loss after processing this batch is:  1.9474666118621826\n",
      "The representation loss after processing this batch is:  0.015223801136016846\n",
      "\n",
      "The classification loss after processing this batch is:  1.9995665550231934\n",
      "The representation loss after processing this batch is:  0.017242878675460815\n",
      "\n",
      "The classification loss after processing this batch is:  1.9481691122055054\n",
      "The representation loss after processing this batch is:  0.015801310539245605\n",
      "\n",
      "The classification loss after processing this batch is:  2.0143325328826904\n",
      "The representation loss after processing this batch is:  0.018044233322143555\n",
      "\n",
      "The classification loss after processing this batch is:  1.9933950901031494\n",
      "The representation loss after processing this batch is:  0.014760136604309082\n",
      "\n",
      "The classification loss after processing this batch is:  1.8801310062408447\n",
      "The representation loss after processing this batch is:  0.01454123854637146\n",
      "\n",
      "The classification loss after processing this batch is:  1.9102338552474976\n",
      "The representation loss after processing this batch is:  0.014418721199035645\n",
      "\n",
      "The classification loss after processing this batch is:  1.9258307218551636\n",
      "The representation loss after processing this batch is:  0.012999504804611206\n",
      "\n",
      "The classification loss after processing this batch is:  1.9110124111175537\n",
      "The representation loss after processing this batch is:  0.01602676510810852\n",
      "\n",
      "The classification loss after processing this batch is:  1.8970739841461182\n",
      "The representation loss after processing this batch is:  0.014878928661346436\n",
      "\n",
      "The classification loss after processing this batch is:  1.9347862005233765\n",
      "The representation loss after processing this batch is:  0.013499915599822998\n",
      "\n",
      "The classification loss after processing this batch is:  1.8880187273025513\n",
      "The representation loss after processing this batch is:  0.01342746615409851\n",
      "\n",
      "The classification loss after processing this batch is:  1.9380264282226562\n",
      "The representation loss after processing this batch is:  0.013151466846466064\n",
      "\n",
      "The classification loss after processing this batch is:  1.8953509330749512\n",
      "The representation loss after processing this batch is:  0.013332009315490723\n",
      "\n",
      "The classification loss after processing this batch is:  1.8488609790802002\n",
      "The representation loss after processing this batch is:  0.01343730092048645\n",
      "\n",
      "The classification loss after processing this batch is:  1.9478728771209717\n",
      "The representation loss after processing this batch is:  0.011980623006820679\n",
      "\n",
      "The classification loss after processing this batch is:  1.920878291130066\n",
      "The representation loss after processing this batch is:  0.015186101198196411\n",
      "\n",
      "The classification loss after processing this batch is:  1.820132851600647\n",
      "The representation loss after processing this batch is:  0.014830946922302246\n",
      "\n",
      "The classification loss after processing this batch is:  1.892627477645874\n",
      "The representation loss after processing this batch is:  0.015302121639251709\n",
      "\n",
      "The classification loss after processing this batch is:  1.9245026111602783\n",
      "The representation loss after processing this batch is:  0.013224124908447266\n",
      "\n",
      "The classification loss after processing this batch is:  1.8640210628509521\n",
      "The representation loss after processing this batch is:  0.011227518320083618\n",
      "\n",
      "The classification loss after processing this batch is:  1.8324549198150635\n",
      "The representation loss after processing this batch is:  0.01166921854019165\n",
      "\n",
      "The classification loss after processing this batch is:  1.8283181190490723\n",
      "The representation loss after processing this batch is:  0.013322383165359497\n",
      "\n",
      "The classification loss after processing this batch is:  1.804463267326355\n",
      "The representation loss after processing this batch is:  0.013912200927734375\n",
      "\n",
      "The classification loss after processing this batch is:  1.9090752601623535\n",
      "The representation loss after processing this batch is:  0.013346493244171143\n",
      "\n",
      "The classification loss after processing this batch is:  1.8888468742370605\n",
      "The representation loss after processing this batch is:  0.014945626258850098\n",
      "\n",
      "The classification loss after processing this batch is:  1.8890372514724731\n",
      "The representation loss after processing this batch is:  0.011888742446899414\n",
      "\n",
      "The classification loss after processing this batch is:  1.8703291416168213\n",
      "The representation loss after processing this batch is:  0.011993438005447388\n",
      "\n",
      "The classification loss after processing this batch is:  1.919763207435608\n",
      "The representation loss after processing this batch is:  0.013628661632537842\n",
      "\n",
      "The classification loss after processing this batch is:  1.8665120601654053\n",
      "The representation loss after processing this batch is:  0.012481093406677246\n",
      "\n",
      "The classification loss after processing this batch is:  1.8200947046279907\n",
      "The representation loss after processing this batch is:  0.013231396675109863\n",
      "\n",
      "The classification loss after processing this batch is:  1.8193631172180176\n",
      "The representation loss after processing this batch is:  0.014350354671478271\n",
      "\n",
      "The classification loss after processing this batch is:  1.8565064668655396\n",
      "The representation loss after processing this batch is:  0.011899590492248535\n",
      "\n",
      "The classification loss after processing this batch is:  1.8133165836334229\n",
      "The representation loss after processing this batch is:  0.013537019491195679\n",
      "\n",
      "The classification loss after processing this batch is:  1.893632173538208\n",
      "The representation loss after processing this batch is:  0.014059662818908691\n",
      "\n",
      "The classification loss after processing this batch is:  1.7406457662582397\n",
      "The representation loss after processing this batch is:  0.013014957308769226\n",
      "\n",
      "The classification loss after processing this batch is:  1.8219234943389893\n",
      "The representation loss after processing this batch is:  0.011012837290763855\n",
      "\n",
      "The classification loss after processing this batch is:  1.8662976026535034\n",
      "The representation loss after processing this batch is:  0.012309417128562927\n",
      "\n",
      "The classification loss after processing this batch is:  1.9039100408554077\n",
      "The representation loss after processing this batch is:  0.012715041637420654\n",
      "\n",
      "The classification loss after processing this batch is:  1.7300984859466553\n",
      "The representation loss after processing this batch is:  0.012075722217559814\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  1.7809020280838013\n",
      "The representation loss after processing this batch is:  0.010790005326271057\n",
      "\n",
      "The classification loss after processing this batch is:  1.782267689704895\n",
      "The representation loss after processing this batch is:  0.011951714754104614\n",
      "\n",
      "The classification loss after processing this batch is:  1.8216233253479004\n",
      "The representation loss after processing this batch is:  0.010100036859512329\n",
      "\n",
      "The classification loss after processing this batch is:  1.8006664514541626\n",
      "The representation loss after processing this batch is:  0.009083852171897888\n",
      "\n",
      "The classification loss after processing this batch is:  1.76680326461792\n",
      "The representation loss after processing this batch is:  0.010738328099250793\n",
      "\n",
      "The classification loss after processing this batch is:  1.7922358512878418\n",
      "The representation loss after processing this batch is:  0.01394614577293396\n",
      "\n",
      "The classification loss after processing this batch is:  1.837177038192749\n",
      "The representation loss after processing this batch is:  0.010822519659996033\n",
      "\n",
      "The classification loss after processing this batch is:  1.8205883502960205\n",
      "The representation loss after processing this batch is:  0.0120248943567276\n",
      "\n",
      "The classification loss after processing this batch is:  1.8168659210205078\n",
      "The representation loss after processing this batch is:  0.013286113739013672\n",
      "\n",
      "The classification loss after processing this batch is:  1.7617878913879395\n",
      "The representation loss after processing this batch is:  0.012416064739227295\n",
      "\n",
      "The classification loss after processing this batch is:  1.8641101121902466\n",
      "The representation loss after processing this batch is:  0.013402655720710754\n",
      "\n",
      "The classification loss after processing this batch is:  1.741169810295105\n",
      "The representation loss after processing this batch is:  0.010464981198310852\n",
      "\n",
      "The classification loss after processing this batch is:  1.7900937795639038\n",
      "The representation loss after processing this batch is:  0.011770471930503845\n",
      "\n",
      "The classification loss after processing this batch is:  1.7772341966629028\n",
      "The representation loss after processing this batch is:  0.010062456130981445\n",
      "\n",
      "The classification loss after processing this batch is:  1.7477574348449707\n",
      "The representation loss after processing this batch is:  0.009667351841926575\n",
      "\n",
      "The classification loss after processing this batch is:  1.748106598854065\n",
      "The representation loss after processing this batch is:  0.009957581758499146\n",
      "\n",
      "The classification loss after processing this batch is:  1.692236304283142\n",
      "The representation loss after processing this batch is:  0.012938886880874634\n",
      "\n",
      "The classification loss after processing this batch is:  1.6820982694625854\n",
      "The representation loss after processing this batch is:  0.01017831265926361\n",
      "\n",
      "The classification loss after processing this batch is:  1.6573764085769653\n",
      "The representation loss after processing this batch is:  0.008751928806304932\n",
      "\n",
      "The classification loss after processing this batch is:  1.5856268405914307\n",
      "The representation loss after processing this batch is:  0.011136576533317566\n",
      "\n",
      "The classification loss after processing this batch is:  1.758697748184204\n",
      "The representation loss after processing this batch is:  0.01019507646560669\n",
      "\n",
      "The classification loss after processing this batch is:  1.715541124343872\n",
      "The representation loss after processing this batch is:  0.010703787207603455\n",
      "\n",
      "The classification loss after processing this batch is:  1.824202299118042\n",
      "The representation loss after processing this batch is:  0.011600956320762634\n",
      "\n",
      "The classification loss after processing this batch is:  1.6642158031463623\n",
      "The representation loss after processing this batch is:  0.010594755411148071\n",
      "\n",
      "The classification loss after processing this batch is:  1.710062861442566\n",
      "The representation loss after processing this batch is:  0.0114249587059021\n",
      "\n",
      "The classification loss after processing this batch is:  1.6881183385849\n",
      "The representation loss after processing this batch is:  0.009718731045722961\n",
      "\n",
      "The classification loss after processing this batch is:  1.7966707944869995\n",
      "The representation loss after processing this batch is:  0.010593891143798828\n",
      "\n",
      "The classification loss after processing this batch is:  1.7101480960845947\n",
      "The representation loss after processing this batch is:  0.010853782296180725\n",
      "\n",
      "The classification loss after processing this batch is:  1.765748381614685\n",
      "The representation loss after processing this batch is:  0.011260643601417542\n",
      "\n",
      "The classification loss after processing this batch is:  1.7925727367401123\n",
      "The representation loss after processing this batch is:  0.010637909173965454\n",
      "\n",
      "The classification loss after processing this batch is:  1.6796200275421143\n",
      "The representation loss after processing this batch is:  0.009465232491493225\n",
      "\n",
      "The classification loss after processing this batch is:  1.6075185537338257\n",
      "The representation loss after processing this batch is:  0.010011419653892517\n",
      "\n",
      "The classification loss after processing this batch is:  1.7515206336975098\n",
      "The representation loss after processing this batch is:  0.010037675499916077\n",
      "\n",
      "The classification loss after processing this batch is:  1.692741870880127\n",
      "The representation loss after processing this batch is:  0.010672986507415771\n",
      "\n",
      "The classification loss after processing this batch is:  1.6929422616958618\n",
      "The representation loss after processing this batch is:  0.00863996148109436\n",
      "\n",
      "The classification loss after processing this batch is:  1.7239586114883423\n",
      "The representation loss after processing this batch is:  0.010378092527389526\n",
      "\n",
      "The classification loss after processing this batch is:  1.6886199712753296\n",
      "The representation loss after processing this batch is:  0.00986751914024353\n",
      "\n",
      "The classification loss after processing this batch is:  1.739158034324646\n",
      "The representation loss after processing this batch is:  0.010899797081947327\n",
      "\n",
      "The classification loss after processing this batch is:  1.6293424367904663\n",
      "The representation loss after processing this batch is:  0.010769739747047424\n",
      "\n",
      "The classification loss after processing this batch is:  1.7816755771636963\n",
      "The representation loss after processing this batch is:  0.010838210582733154\n",
      "\n",
      "The classification loss after processing this batch is:  1.641879677772522\n",
      "The representation loss after processing this batch is:  0.008579954504966736\n",
      "\n",
      "The classification loss after processing this batch is:  1.6501108407974243\n",
      "The representation loss after processing this batch is:  0.00949975848197937\n",
      "\n",
      "The classification loss after processing this batch is:  1.4529815912246704\n",
      "The representation loss after processing this batch is:  0.009551793336868286\n",
      "\n",
      "The classification loss after processing this batch is:  1.6461013555526733\n",
      "The representation loss after processing this batch is:  0.010304585099220276\n",
      "\n",
      "The classification loss after processing this batch is:  1.599484920501709\n",
      "The representation loss after processing this batch is:  0.010533526539802551\n",
      "\n",
      "The classification loss after processing this batch is:  1.5664199590682983\n",
      "The representation loss after processing this batch is:  0.009372219443321228\n",
      "\n",
      "The classification loss after processing this batch is:  1.6378391981124878\n",
      "The representation loss after processing this batch is:  0.008664146065711975\n",
      "\n",
      "The classification loss after processing this batch is:  1.546372652053833\n",
      "The representation loss after processing this batch is:  0.00860828161239624\n",
      "\n",
      "The classification loss after processing this batch is:  1.4760409593582153\n",
      "The representation loss after processing this batch is:  0.010057583451271057\n",
      "\n",
      "The classification loss after processing this batch is:  1.6078741550445557\n",
      "The representation loss after processing this batch is:  0.011112317442893982\n",
      "\n",
      "The classification loss after processing this batch is:  1.5247604846954346\n",
      "The representation loss after processing this batch is:  0.0090656578540802\n",
      "\n",
      "The classification loss after processing this batch is:  1.5726407766342163\n",
      "The representation loss after processing this batch is:  0.01009395718574524\n",
      "\n",
      "The classification loss after processing this batch is:  1.5205397605895996\n",
      "The representation loss after processing this batch is:  0.009376510977745056\n",
      "\n",
      "The classification loss after processing this batch is:  1.5890662670135498\n",
      "The representation loss after processing this batch is:  0.009569212794303894\n",
      "\n",
      "The classification loss after processing this batch is:  1.5192104578018188\n",
      "The representation loss after processing this batch is:  0.010031014680862427\n",
      "\n",
      "The classification loss after processing this batch is:  1.7379186153411865\n",
      "The representation loss after processing this batch is:  0.008531779050827026\n",
      "\n",
      "The classification loss after processing this batch is:  1.510456919670105\n",
      "The representation loss after processing this batch is:  0.010099470615386963\n",
      "\n",
      "The classification loss after processing this batch is:  1.6477738618850708\n",
      "The representation loss after processing this batch is:  0.009287133812904358\n",
      "\n",
      "The classification loss after processing this batch is:  1.5203040838241577\n",
      "The representation loss after processing this batch is:  0.008573591709136963\n",
      "\n",
      "The classification loss after processing this batch is:  1.6110371351242065\n",
      "The representation loss after processing this batch is:  0.0088520348072052\n",
      "\n",
      "The classification loss after processing this batch is:  1.725409984588623\n",
      "The representation loss after processing this batch is:  0.009416475892066956\n",
      "\n",
      "The classification loss after processing this batch is:  1.5861483812332153\n",
      "The representation loss after processing this batch is:  0.007726386189460754\n",
      "\n",
      "The classification loss after processing this batch is:  1.6616997718811035\n",
      "The representation loss after processing this batch is:  0.008724555373191833\n",
      "\n",
      "The classification loss after processing this batch is:  1.383115530014038\n",
      "The representation loss after processing this batch is:  0.007145941257476807\n",
      "\n",
      "The classification loss after processing this batch is:  1.4221423864364624\n",
      "The representation loss after processing this batch is:  0.008134916424751282\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  1.501625895500183\n",
      "The representation loss after processing this batch is:  0.009296029806137085\n",
      "\n",
      "The classification loss after processing this batch is:  1.4976801872253418\n",
      "The representation loss after processing this batch is:  0.00842195749282837\n",
      "\n",
      "The classification loss after processing this batch is:  1.4988924264907837\n",
      "The representation loss after processing this batch is:  0.007884025573730469\n",
      "\n",
      "The classification loss after processing this batch is:  1.4227217435836792\n",
      "The representation loss after processing this batch is:  0.008914954960346222\n",
      "\n",
      "The classification loss after processing this batch is:  1.3621509075164795\n",
      "The representation loss after processing this batch is:  0.008167237043380737\n",
      "\n",
      "The classification loss after processing this batch is:  1.4284199476242065\n",
      "The representation loss after processing this batch is:  0.007760822772979736\n",
      "\n",
      "The classification loss after processing this batch is:  1.451815128326416\n",
      "The representation loss after processing this batch is:  0.008373171091079712\n",
      "\n",
      "The classification loss after processing this batch is:  1.580479383468628\n",
      "The representation loss after processing this batch is:  0.009269274771213531\n",
      "\n",
      "The classification loss after processing this batch is:  1.645745873451233\n",
      "The representation loss after processing this batch is:  0.010468408465385437\n",
      "\n",
      "The classification loss after processing this batch is:  1.4241489171981812\n",
      "The representation loss after processing this batch is:  0.009066835045814514\n",
      "\n",
      "The classification loss after processing this batch is:  1.4388309717178345\n",
      "The representation loss after processing this batch is:  0.009673908352851868\n",
      "\n",
      "The classification loss after processing this batch is:  1.4252408742904663\n",
      "The representation loss after processing this batch is:  0.007221899926662445\n",
      "\n",
      "The classification loss after processing this batch is:  1.7110495567321777\n",
      "The representation loss after processing this batch is:  0.008371464908123016\n",
      "\n",
      "The classification loss after processing this batch is:  1.5608999729156494\n",
      "The representation loss after processing this batch is:  0.0084238201379776\n",
      "\n",
      "The classification loss after processing this batch is:  1.5726913213729858\n",
      "The representation loss after processing this batch is:  0.009252041578292847\n",
      "\n",
      "The classification loss after processing this batch is:  1.3995717763900757\n",
      "The representation loss after processing this batch is:  0.008077003061771393\n",
      "\n",
      "The classification loss after processing this batch is:  1.49064302444458\n",
      "The representation loss after processing this batch is:  0.007572554051876068\n",
      "\n",
      "The classification loss after processing this batch is:  1.5342198610305786\n",
      "The representation loss after processing this batch is:  0.008849531412124634\n",
      "\n",
      "The classification loss after processing this batch is:  1.4251984357833862\n",
      "The representation loss after processing this batch is:  0.00730559229850769\n",
      "\n",
      "The classification loss after processing this batch is:  1.656887412071228\n",
      "The representation loss after processing this batch is:  0.007941260933876038\n",
      "\n",
      "The classification loss after processing this batch is:  1.5649333000183105\n",
      "The representation loss after processing this batch is:  0.010007515549659729\n",
      "\n",
      "The classification loss after processing this batch is:  1.3409689664840698\n",
      "The representation loss after processing this batch is:  0.00762910395860672\n",
      "\n",
      "The classification loss after processing this batch is:  1.5780398845672607\n",
      "The representation loss after processing this batch is:  0.008526727557182312\n",
      "\n",
      "The classification loss after processing this batch is:  1.559069037437439\n",
      "The representation loss after processing this batch is:  0.00995539128780365\n",
      "\n",
      "The classification loss after processing this batch is:  1.3914858102798462\n",
      "The representation loss after processing this batch is:  0.00901312381029129\n",
      "\n",
      "The classification loss after processing this batch is:  1.4541486501693726\n",
      "The representation loss after processing this batch is:  0.008358478546142578\n",
      "\n",
      "The classification loss after processing this batch is:  1.3983445167541504\n",
      "The representation loss after processing this batch is:  0.008113957941532135\n",
      "\n",
      "The classification loss after processing this batch is:  1.4276134967803955\n",
      "The representation loss after processing this batch is:  0.007373623549938202\n",
      "\n",
      "The classification loss after processing this batch is:  1.5367107391357422\n",
      "The representation loss after processing this batch is:  0.00884905457496643\n",
      "\n",
      "The classification loss after processing this batch is:  1.366854190826416\n",
      "The representation loss after processing this batch is:  0.0074523985385894775\n",
      "\n",
      "The classification loss after processing this batch is:  1.3047102689743042\n",
      "The representation loss after processing this batch is:  0.008587852120399475\n",
      "\n",
      "The classification loss after processing this batch is:  1.382083773612976\n",
      "The representation loss after processing this batch is:  0.007617861032485962\n",
      "\n",
      "The classification loss after processing this batch is:  1.3263341188430786\n",
      "The representation loss after processing this batch is:  0.007730141282081604\n",
      "\n",
      "The classification loss after processing this batch is:  1.3011338710784912\n",
      "The representation loss after processing this batch is:  0.008174270391464233\n",
      "\n",
      "The classification loss after processing this batch is:  1.5198522806167603\n",
      "The representation loss after processing this batch is:  0.008752062916755676\n",
      "\n",
      "The classification loss after processing this batch is:  1.4066097736358643\n",
      "The representation loss after processing this batch is:  0.008595116436481476\n",
      "\n",
      "The classification loss after processing this batch is:  1.499618411064148\n",
      "The representation loss after processing this batch is:  0.008331246674060822\n",
      "\n",
      "The classification loss after processing this batch is:  1.3320426940917969\n",
      "The representation loss after processing this batch is:  0.008492052555084229\n",
      "\n",
      "The classification loss after processing this batch is:  1.3832058906555176\n",
      "The representation loss after processing this batch is:  0.00933404266834259\n",
      "\n",
      "The classification loss after processing this batch is:  1.4144461154937744\n",
      "The representation loss after processing this batch is:  0.007466822862625122\n",
      "\n",
      "The classification loss after processing this batch is:  1.351464033126831\n",
      "The representation loss after processing this batch is:  0.0075541287660598755\n",
      "\n",
      "The classification loss after processing this batch is:  1.3938311338424683\n",
      "The representation loss after processing this batch is:  0.008471466600894928\n",
      "\n",
      "The classification loss after processing this batch is:  1.3893685340881348\n",
      "The representation loss after processing this batch is:  0.0074501559138298035\n",
      "\n",
      "The classification loss after processing this batch is:  1.299902319908142\n",
      "The representation loss after processing this batch is:  0.009081237018108368\n",
      "\n",
      "The classification loss after processing this batch is:  1.4268430471420288\n",
      "The representation loss after processing this batch is:  0.008207663893699646\n",
      "\n",
      "The classification loss after processing this batch is:  1.4202584028244019\n",
      "The representation loss after processing this batch is:  0.008152574300765991\n",
      "\n",
      "The classification loss after processing this batch is:  1.304610013961792\n",
      "The representation loss after processing this batch is:  0.00795850157737732\n",
      "\n",
      "The classification loss after processing this batch is:  1.4434406757354736\n",
      "The representation loss after processing this batch is:  0.00804176926612854\n",
      "\n",
      "The classification loss after processing this batch is:  1.4635950326919556\n",
      "The representation loss after processing this batch is:  0.008021339774131775\n",
      "\n",
      "The classification loss after processing this batch is:  1.3006393909454346\n",
      "The representation loss after processing this batch is:  0.007043212652206421\n",
      "\n",
      "The classification loss after processing this batch is:  1.4406682252883911\n",
      "The representation loss after processing this batch is:  0.006720811128616333\n",
      "\n",
      "The classification loss after processing this batch is:  1.2317713499069214\n",
      "The representation loss after processing this batch is:  0.006009191274642944\n",
      "\n",
      "The classification loss after processing this batch is:  1.2925734519958496\n",
      "The representation loss after processing this batch is:  0.006557032465934753\n",
      "\n",
      "The classification loss after processing this batch is:  1.3019118309020996\n",
      "The representation loss after processing this batch is:  0.0061669424176216125\n",
      "\n",
      "The classification loss after processing this batch is:  1.4185664653778076\n",
      "The representation loss after processing this batch is:  0.0071335360407829285\n",
      "\n",
      "The classification loss after processing this batch is:  1.1379599571228027\n",
      "The representation loss after processing this batch is:  0.007470659911632538\n",
      "\n",
      "The classification loss after processing this batch is:  1.3003730773925781\n",
      "The representation loss after processing this batch is:  0.006630018353462219\n",
      "\n",
      "The classification loss after processing this batch is:  1.2180430889129639\n",
      "The representation loss after processing this batch is:  0.006457105278968811\n",
      "\n",
      "The classification loss after processing this batch is:  1.289827585220337\n",
      "The representation loss after processing this batch is:  0.007392190396785736\n",
      "\n",
      "The classification loss after processing this batch is:  1.3525890111923218\n",
      "The representation loss after processing this batch is:  0.008677713572978973\n",
      "\n",
      "The classification loss after processing this batch is:  1.3416216373443604\n",
      "The representation loss after processing this batch is:  0.008452445268630981\n",
      "\n",
      "The classification loss after processing this batch is:  1.4755593538284302\n",
      "The representation loss after processing this batch is:  0.008944928646087646\n",
      "\n",
      "The classification loss after processing this batch is:  1.3229237794876099\n",
      "The representation loss after processing this batch is:  0.0069303810596466064\n",
      "\n",
      "The classification loss after processing this batch is:  1.2462782859802246\n",
      "The representation loss after processing this batch is:  0.007227666676044464\n",
      "\n",
      "The classification loss after processing this batch is:  1.4918557405471802\n",
      "The representation loss after processing this batch is:  0.007201269268989563\n",
      "\n",
      "The classification loss after processing this batch is:  1.3443340063095093\n",
      "The representation loss after processing this batch is:  0.007014334201812744\n",
      "\n",
      "The classification loss after processing this batch is:  1.3411688804626465\n",
      "The representation loss after processing this batch is:  0.007124744355678558\n",
      "\n",
      "The classification loss after processing this batch is:  1.167859673500061\n",
      "The representation loss after processing this batch is:  0.006075993180274963\n",
      "\n",
      "The classification loss after processing this batch is:  1.29442298412323\n",
      "The representation loss after processing this batch is:  0.007212534546852112\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  1.3064051866531372\n",
      "The representation loss after processing this batch is:  0.006991192698478699\n",
      "\n",
      "The classification loss after processing this batch is:  1.408437728881836\n",
      "The representation loss after processing this batch is:  0.009036153554916382\n",
      "\n",
      "The classification loss after processing this batch is:  1.2944977283477783\n",
      "The representation loss after processing this batch is:  0.00717463344335556\n",
      "\n",
      "The classification loss after processing this batch is:  1.1912959814071655\n",
      "The representation loss after processing this batch is:  0.0070342570543289185\n",
      "\n",
      "The classification loss after processing this batch is:  1.2764594554901123\n",
      "The representation loss after processing this batch is:  0.007364116609096527\n",
      "\n",
      "The classification loss after processing this batch is:  1.2963155508041382\n",
      "The representation loss after processing this batch is:  0.007217146456241608\n",
      "\n",
      "The classification loss after processing this batch is:  1.2940585613250732\n",
      "The representation loss after processing this batch is:  0.006204284727573395\n",
      "\n",
      "The classification loss after processing this batch is:  1.3238162994384766\n",
      "The representation loss after processing this batch is:  0.006687544286251068\n",
      "\n",
      "The classification loss after processing this batch is:  1.3450977802276611\n",
      "The representation loss after processing this batch is:  0.006754353642463684\n",
      "\n",
      "The classification loss after processing this batch is:  1.2969037294387817\n",
      "The representation loss after processing this batch is:  0.0073241740465164185\n",
      "\n",
      "The classification loss after processing this batch is:  1.0938717126846313\n",
      "The representation loss after processing this batch is:  0.007772259414196014\n",
      "\n",
      "The classification loss after processing this batch is:  1.2419315576553345\n",
      "The representation loss after processing this batch is:  0.006928063929080963\n",
      "\n",
      "The classification loss after processing this batch is:  1.1724109649658203\n",
      "The representation loss after processing this batch is:  0.0064231231808662415\n",
      "\n",
      "The classification loss after processing this batch is:  1.0643846988677979\n",
      "The representation loss after processing this batch is:  0.007090091705322266\n",
      "\n",
      "The classification loss after processing this batch is:  1.1805826425552368\n",
      "The representation loss after processing this batch is:  0.006681092083454132\n",
      "\n",
      "The classification loss after processing this batch is:  1.156873106956482\n",
      "The representation loss after processing this batch is:  0.006380997598171234\n",
      "\n",
      "The classification loss after processing this batch is:  1.3468619585037231\n",
      "The representation loss after processing this batch is:  0.00621495395898819\n",
      "\n",
      "The classification loss after processing this batch is:  1.2680609226226807\n",
      "The representation loss after processing this batch is:  0.0064527541399002075\n",
      "\n",
      "The classification loss after processing this batch is:  1.169646978378296\n",
      "The representation loss after processing this batch is:  0.006492160260677338\n",
      "\n",
      "The classification loss after processing this batch is:  1.2954462766647339\n",
      "The representation loss after processing this batch is:  0.008688651025295258\n",
      "\n",
      "The classification loss after processing this batch is:  1.1450570821762085\n",
      "The representation loss after processing this batch is:  0.007258914411067963\n",
      "\n",
      "The classification loss after processing this batch is:  1.0444813966751099\n",
      "The representation loss after processing this batch is:  0.006586499512195587\n",
      "\n",
      "The classification loss after processing this batch is:  1.0723578929901123\n",
      "The representation loss after processing this batch is:  0.007011972367763519\n",
      "\n",
      "The classification loss after processing this batch is:  1.2091182470321655\n",
      "The representation loss after processing this batch is:  0.008411809802055359\n",
      "\n",
      "The classification loss after processing this batch is:  1.0603588819503784\n",
      "The representation loss after processing this batch is:  0.0066732242703437805\n",
      "\n",
      "The classification loss after processing this batch is:  1.042960286140442\n",
      "The representation loss after processing this batch is:  0.00791238248348236\n",
      "\n",
      "The classification loss after processing this batch is:  1.2476551532745361\n",
      "The representation loss after processing this batch is:  0.007729813456535339\n",
      "\n",
      "The classification loss after processing this batch is:  1.2713849544525146\n",
      "The representation loss after processing this batch is:  0.00787326693534851\n",
      "\n",
      "The classification loss after processing this batch is:  1.2866339683532715\n",
      "The representation loss after processing this batch is:  0.009062618017196655\n",
      "\n",
      "The classification loss after processing this batch is:  1.2224041223526\n",
      "The representation loss after processing this batch is:  0.00745633989572525\n",
      "\n",
      "The classification loss after processing this batch is:  1.2941088676452637\n",
      "The representation loss after processing this batch is:  0.006829380989074707\n",
      "\n",
      "The classification loss after processing this batch is:  0.999249279499054\n",
      "The representation loss after processing this batch is:  0.008140802383422852\n",
      "\n",
      "The classification loss after processing this batch is:  1.1760622262954712\n",
      "The representation loss after processing this batch is:  0.007236063480377197\n",
      "\n",
      "The classification loss after processing this batch is:  1.3778024911880493\n",
      "The representation loss after processing this batch is:  0.006989814341068268\n",
      "\n",
      "The classification loss after processing this batch is:  1.397598147392273\n",
      "The representation loss after processing this batch is:  0.006772227585315704\n",
      "\n",
      "The classification loss after processing this batch is:  1.394158959388733\n",
      "The representation loss after processing this batch is:  0.007151328027248383\n",
      "\n",
      "The classification loss after processing this batch is:  1.3047395944595337\n",
      "The representation loss after processing this batch is:  0.005753792822360992\n",
      "\n",
      "The classification loss after processing this batch is:  1.274501085281372\n",
      "The representation loss after processing this batch is:  0.006019867956638336\n",
      "\n",
      "The classification loss after processing this batch is:  1.1561838388442993\n",
      "The representation loss after processing this batch is:  0.006480135023593903\n",
      "\n",
      "The classification loss after processing this batch is:  1.1874549388885498\n",
      "The representation loss after processing this batch is:  0.005883120000362396\n",
      "\n",
      "The classification loss after processing this batch is:  1.1604008674621582\n",
      "The representation loss after processing this batch is:  0.006083175539970398\n",
      "\n",
      "The classification loss after processing this batch is:  1.149710774421692\n",
      "The representation loss after processing this batch is:  0.007377631962299347\n",
      "\n",
      "The classification loss after processing this batch is:  1.1195014715194702\n",
      "The representation loss after processing this batch is:  0.006452925503253937\n",
      "\n",
      "The classification loss after processing this batch is:  1.2758387327194214\n",
      "The representation loss after processing this batch is:  0.007119655609130859\n",
      "\n",
      "The classification loss after processing this batch is:  1.129733920097351\n",
      "The representation loss after processing this batch is:  0.006393611431121826\n",
      "\n",
      "The classification loss after processing this batch is:  1.1456272602081299\n",
      "The representation loss after processing this batch is:  0.005629226565361023\n",
      "\n",
      "The classification loss after processing this batch is:  1.087921380996704\n",
      "The representation loss after processing this batch is:  0.0063155218958854675\n",
      "\n",
      "The classification loss after processing this batch is:  1.0917704105377197\n",
      "The representation loss after processing this batch is:  0.006853066384792328\n",
      "\n",
      "The classification loss after processing this batch is:  0.9964094758033752\n",
      "The representation loss after processing this batch is:  0.006839483976364136\n",
      "\n",
      "The classification loss after processing this batch is:  1.2828260660171509\n",
      "The representation loss after processing this batch is:  0.008891887962818146\n",
      "\n",
      "The classification loss after processing this batch is:  1.1047440767288208\n",
      "The representation loss after processing this batch is:  0.006960161030292511\n",
      "\n",
      "The classification loss after processing this batch is:  1.0356926918029785\n",
      "The representation loss after processing this batch is:  0.007280521094799042\n",
      "\n",
      "The classification loss after processing this batch is:  1.0926363468170166\n",
      "The representation loss after processing this batch is:  0.007921934127807617\n",
      "\n",
      "The classification loss after processing this batch is:  1.1221071481704712\n",
      "The representation loss after processing this batch is:  0.0078004226088523865\n",
      "\n",
      "The classification loss after processing this batch is:  1.1518362760543823\n",
      "The representation loss after processing this batch is:  0.0075414106249809265\n",
      "\n",
      "The classification loss after processing this batch is:  1.1453382968902588\n",
      "The representation loss after processing this batch is:  0.007251620292663574\n",
      "\n",
      "The classification loss after processing this batch is:  1.061471700668335\n",
      "The representation loss after processing this batch is:  0.0060346052050590515\n",
      "\n",
      "The classification loss after processing this batch is:  0.9930499792098999\n",
      "The representation loss after processing this batch is:  0.006265625357627869\n",
      "\n",
      "The classification loss after processing this batch is:  1.0462521314620972\n",
      "The representation loss after processing this batch is:  0.00772172212600708\n",
      "\n",
      "The classification loss after processing this batch is:  1.104612946510315\n",
      "The representation loss after processing this batch is:  0.006969153881072998\n",
      "\n",
      "The classification loss after processing this batch is:  1.1186479330062866\n",
      "The representation loss after processing this batch is:  0.006137914955615997\n",
      "\n",
      "The classification loss after processing this batch is:  0.9207360744476318\n",
      "The representation loss after processing this batch is:  0.006587237119674683\n",
      "\n",
      "The classification loss after processing this batch is:  1.1906660795211792\n",
      "The representation loss after processing this batch is:  0.005513638257980347\n",
      "\n",
      "The classification loss after processing this batch is:  1.161699891090393\n",
      "The representation loss after processing this batch is:  0.005639359354972839\n",
      "\n",
      "The classification loss after processing this batch is:  1.0237305164337158\n",
      "The representation loss after processing this batch is:  0.005716584622859955\n",
      "\n",
      "The classification loss after processing this batch is:  1.0846965312957764\n",
      "The representation loss after processing this batch is:  0.005277842283248901\n",
      "\n",
      "The classification loss after processing this batch is:  1.129167079925537\n",
      "The representation loss after processing this batch is:  0.006075702607631683\n",
      "\n",
      "The classification loss after processing this batch is:  1.2105655670166016\n",
      "The representation loss after processing this batch is:  0.006824485957622528\n",
      "\n",
      "The classification loss after processing this batch is:  1.1308940649032593\n",
      "The representation loss after processing this batch is:  0.006986051797866821\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  1.2015578746795654\n",
      "The representation loss after processing this batch is:  0.0054181963205337524\n",
      "\n",
      "The classification loss after processing this batch is:  1.1901872158050537\n",
      "The representation loss after processing this batch is:  0.00653211772441864\n",
      "\n",
      "The classification loss after processing this batch is:  1.304692029953003\n",
      "The representation loss after processing this batch is:  0.0068346112966537476\n",
      "\n",
      "The classification loss after processing this batch is:  1.0672515630722046\n",
      "The representation loss after processing this batch is:  0.0063431113958358765\n",
      "\n",
      "The classification loss after processing this batch is:  1.0667839050292969\n",
      "The representation loss after processing this batch is:  0.006507217884063721\n",
      "\n",
      "The classification loss after processing this batch is:  1.0416171550750732\n",
      "The representation loss after processing this batch is:  0.008298516273498535\n",
      "\n",
      "The classification loss after processing this batch is:  1.0225390195846558\n",
      "The representation loss after processing this batch is:  0.006070740520954132\n",
      "\n",
      "The classification loss after processing this batch is:  0.9111926555633545\n",
      "The representation loss after processing this batch is:  0.005522102117538452\n",
      "\n",
      "The classification loss after processing this batch is:  0.9906715154647827\n",
      "The representation loss after processing this batch is:  0.007021404802799225\n",
      "\n",
      "The classification loss after processing this batch is:  0.9496124386787415\n",
      "The representation loss after processing this batch is:  0.0064033567905426025\n",
      "\n",
      "The classification loss after processing this batch is:  0.9521363377571106\n",
      "The representation loss after processing this batch is:  0.006101682782173157\n",
      "\n",
      "The classification loss after processing this batch is:  1.1221474409103394\n",
      "The representation loss after processing this batch is:  0.00570109486579895\n",
      "\n",
      "The classification loss after processing this batch is:  1.0251845121383667\n",
      "The representation loss after processing this batch is:  0.005994707345962524\n",
      "\n",
      "The classification loss after processing this batch is:  0.9247793555259705\n",
      "The representation loss after processing this batch is:  0.006836250424385071\n",
      "\n",
      "The classification loss after processing this batch is:  0.9743068218231201\n",
      "The representation loss after processing this batch is:  0.00748433917760849\n",
      "\n",
      "The classification loss after processing this batch is:  0.828445553779602\n",
      "The representation loss after processing this batch is:  0.005806528031826019\n",
      "\n",
      "The classification loss after processing this batch is:  0.9446929693222046\n",
      "The representation loss after processing this batch is:  0.006157197058200836\n",
      "\n",
      "The classification loss after processing this batch is:  0.9950892329216003\n",
      "The representation loss after processing this batch is:  0.006660401821136475\n",
      "\n",
      "The classification loss after processing this batch is:  0.8107999563217163\n",
      "The representation loss after processing this batch is:  0.006427563726902008\n",
      "\n",
      "The classification loss after processing this batch is:  0.8438811898231506\n",
      "The representation loss after processing this batch is:  0.006163373589515686\n",
      "\n",
      "The classification loss after processing this batch is:  0.9923800826072693\n",
      "The representation loss after processing this batch is:  0.007398098707199097\n",
      "\n",
      "The classification loss after processing this batch is:  0.9917852282524109\n",
      "The representation loss after processing this batch is:  0.008821837604045868\n",
      "\n",
      "The classification loss after processing this batch is:  0.9864420294761658\n",
      "The representation loss after processing this batch is:  0.0064452216029167175\n",
      "\n",
      "The classification loss after processing this batch is:  0.9005627036094666\n",
      "The representation loss after processing this batch is:  0.006333008408546448\n",
      "\n",
      "The classification loss after processing this batch is:  0.863481342792511\n",
      "The representation loss after processing this batch is:  0.006108015775680542\n",
      "\n",
      "The classification loss after processing this batch is:  0.9305207133293152\n",
      "The representation loss after processing this batch is:  0.00568930059671402\n",
      "\n",
      "The classification loss after processing this batch is:  0.9406033158302307\n",
      "The representation loss after processing this batch is:  0.005569778382778168\n",
      "\n",
      "The classification loss after processing this batch is:  0.9339727163314819\n",
      "The representation loss after processing this batch is:  0.006416819989681244\n",
      "\n",
      "The classification loss after processing this batch is:  0.9697886109352112\n",
      "The representation loss after processing this batch is:  0.006700277328491211\n",
      "\n",
      "The classification loss after processing this batch is:  1.114414930343628\n",
      "The representation loss after processing this batch is:  0.007083002477884293\n",
      "\n",
      "The classification loss after processing this batch is:  1.0509427785873413\n",
      "The representation loss after processing this batch is:  0.006586380302906036\n",
      "\n",
      "The classification loss after processing this batch is:  0.944669783115387\n",
      "The representation loss after processing this batch is:  0.007133394479751587\n",
      "\n",
      "The classification loss after processing this batch is:  1.0391916036605835\n",
      "The representation loss after processing this batch is:  0.006962820887565613\n",
      "\n",
      "The classification loss after processing this batch is:  1.0221142768859863\n",
      "The representation loss after processing this batch is:  0.006543852388858795\n",
      "\n",
      "The classification loss after processing this batch is:  0.9331462383270264\n",
      "The representation loss after processing this batch is:  0.007199786603450775\n",
      "\n",
      "The classification loss after processing this batch is:  1.0469138622283936\n",
      "The representation loss after processing this batch is:  0.006813250482082367\n",
      "\n",
      "The classification loss after processing this batch is:  0.818854570388794\n",
      "The representation loss after processing this batch is:  0.007735162973403931\n",
      "\n",
      "The classification loss after processing this batch is:  1.0471237897872925\n",
      "The representation loss after processing this batch is:  0.007420718669891357\n",
      "\n",
      "The classification loss after processing this batch is:  0.9373130798339844\n",
      "The representation loss after processing this batch is:  0.006400853395462036\n",
      "\n",
      "The classification loss after processing this batch is:  0.921267569065094\n",
      "The representation loss after processing this batch is:  0.005766429007053375\n",
      "\n",
      "The classification loss after processing this batch is:  0.9352214336395264\n",
      "The representation loss after processing this batch is:  0.006360478699207306\n",
      "\n",
      "The classification loss after processing this batch is:  1.0083929300308228\n",
      "The representation loss after processing this batch is:  0.006449222564697266\n",
      "\n",
      "The classification loss after processing this batch is:  1.0452953577041626\n",
      "The representation loss after processing this batch is:  0.00610341876745224\n",
      "\n",
      "The classification loss after processing this batch is:  1.1708354949951172\n",
      "The representation loss after processing this batch is:  0.005973115563392639\n",
      "\n",
      "The classification loss after processing this batch is:  0.9862092733383179\n",
      "The representation loss after processing this batch is:  0.006217151880264282\n",
      "\n",
      "The classification loss after processing this batch is:  0.8498480319976807\n",
      "The representation loss after processing this batch is:  0.006029903888702393\n",
      "\n",
      "The classification loss after processing this batch is:  0.8392921686172485\n",
      "The representation loss after processing this batch is:  0.005898699164390564\n",
      "\n",
      "The classification loss after processing this batch is:  0.8983596563339233\n",
      "The representation loss after processing this batch is:  0.007057111710309982\n",
      "\n",
      "The classification loss after processing this batch is:  0.8565221428871155\n",
      "The representation loss after processing this batch is:  0.006509803235530853\n",
      "\n",
      "The classification loss after processing this batch is:  0.7677106261253357\n",
      "The representation loss after processing this batch is:  0.006429582834243774\n",
      "\n",
      "The classification loss after processing this batch is:  0.9250576496124268\n",
      "The representation loss after processing this batch is:  0.006203420460224152\n",
      "\n",
      "The classification loss after processing this batch is:  0.9603620171546936\n",
      "The representation loss after processing this batch is:  0.007047712802886963\n",
      "\n",
      "The classification loss after processing this batch is:  1.000974416732788\n",
      "The representation loss after processing this batch is:  0.005873367190361023\n",
      "\n",
      "The classification loss after processing this batch is:  1.0277299880981445\n",
      "The representation loss after processing this batch is:  0.0067054107785224915\n",
      "\n",
      "The classification loss after processing this batch is:  0.8928312659263611\n",
      "The representation loss after processing this batch is:  0.006302736699581146\n",
      "\n",
      "The classification loss after processing this batch is:  0.8456892371177673\n",
      "The representation loss after processing this batch is:  0.006425328552722931\n",
      "\n",
      "The classification loss after processing this batch is:  0.7990014553070068\n",
      "The representation loss after processing this batch is:  0.006186075508594513\n",
      "\n",
      "The classification loss after processing this batch is:  0.7836745381355286\n",
      "The representation loss after processing this batch is:  0.006466791033744812\n",
      "\n",
      "The classification loss after processing this batch is:  0.7773131132125854\n",
      "The representation loss after processing this batch is:  0.0051661282777786255\n",
      "\n",
      "The classification loss after processing this batch is:  0.936000406742096\n",
      "The representation loss after processing this batch is:  0.00547819584608078\n",
      "\n",
      "The classification loss after processing this batch is:  0.7604081630706787\n",
      "The representation loss after processing this batch is:  0.005673564970493317\n",
      "\n",
      "The classification loss after processing this batch is:  1.026466727256775\n",
      "The representation loss after processing this batch is:  0.004344135522842407\n",
      "\n",
      "The classification loss after processing this batch is:  1.0219041109085083\n",
      "The representation loss after processing this batch is:  0.005924016237258911\n",
      "\n",
      "The classification loss after processing this batch is:  0.7772083282470703\n",
      "The representation loss after processing this batch is:  0.005721352994441986\n",
      "\n",
      "The classification loss after processing this batch is:  0.8334941267967224\n",
      "The representation loss after processing this batch is:  0.005479976534843445\n",
      "\n",
      "The classification loss after processing this batch is:  0.9283202886581421\n",
      "The representation loss after processing this batch is:  0.005755394697189331\n",
      "\n",
      "The classification loss after processing this batch is:  0.8641042113304138\n",
      "The representation loss after processing this batch is:  0.005547262728214264\n",
      "\n",
      "The classification loss after processing this batch is:  1.0432989597320557\n",
      "The representation loss after processing this batch is:  0.006231948733329773\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.9465147852897644\n",
      "The representation loss after processing this batch is:  0.006362207233905792\n",
      "\n",
      "The classification loss after processing this batch is:  0.9125062227249146\n",
      "The representation loss after processing this batch is:  0.006221167743206024\n",
      "\n",
      "The classification loss after processing this batch is:  0.866244912147522\n",
      "The representation loss after processing this batch is:  0.004889152944087982\n",
      "\n",
      "The classification loss after processing this batch is:  0.9308235049247742\n",
      "The representation loss after processing this batch is:  0.005390673875808716\n",
      "\n",
      "The classification loss after processing this batch is:  0.8750340938568115\n",
      "The representation loss after processing this batch is:  0.005001381039619446\n",
      "\n",
      "The classification loss after processing this batch is:  1.0029152631759644\n",
      "The representation loss after processing this batch is:  0.0060088783502578735\n",
      "\n",
      "The classification loss after processing this batch is:  0.8743060827255249\n",
      "The representation loss after processing this batch is:  0.006030522286891937\n",
      "\n",
      "The classification loss after processing this batch is:  1.1005284786224365\n",
      "The representation loss after processing this batch is:  0.0061761438846588135\n",
      "\n",
      "The classification loss after processing this batch is:  0.9384396076202393\n",
      "The representation loss after processing this batch is:  0.006887447088956833\n",
      "\n",
      "The classification loss after processing this batch is:  0.8102348446846008\n",
      "The representation loss after processing this batch is:  0.005911298096179962\n",
      "\n",
      "The classification loss after processing this batch is:  0.9378028512001038\n",
      "The representation loss after processing this batch is:  0.006407015025615692\n",
      "\n",
      "The classification loss after processing this batch is:  0.8871168494224548\n",
      "The representation loss after processing this batch is:  0.00532088428735733\n",
      "\n",
      "The classification loss after processing this batch is:  0.7159024477005005\n",
      "The representation loss after processing this batch is:  0.005564413964748383\n",
      "\n",
      "The classification loss after processing this batch is:  0.7095712423324585\n",
      "The representation loss after processing this batch is:  0.005850210785865784\n",
      "\n",
      "The classification loss after processing this batch is:  0.7747467160224915\n",
      "The representation loss after processing this batch is:  0.005875140428543091\n",
      "\n",
      "The classification loss after processing this batch is:  0.8244704008102417\n",
      "The representation loss after processing this batch is:  0.007176905870437622\n",
      "\n",
      "The classification loss after processing this batch is:  0.8128684163093567\n",
      "The representation loss after processing this batch is:  0.005822315812110901\n",
      "\n",
      "The classification loss after processing this batch is:  1.1474334001541138\n",
      "The representation loss after processing this batch is:  0.005463063716888428\n",
      "\n",
      "The classification loss after processing this batch is:  0.885141909122467\n",
      "The representation loss after processing this batch is:  0.00644393265247345\n",
      "\n",
      "The classification loss after processing this batch is:  1.0930137634277344\n",
      "The representation loss after processing this batch is:  0.006059460341930389\n",
      "\n",
      "The classification loss after processing this batch is:  1.0689231157302856\n",
      "The representation loss after processing this batch is:  0.006128832697868347\n",
      "\n",
      "The classification loss after processing this batch is:  0.9663674831390381\n",
      "The representation loss after processing this batch is:  0.006876364350318909\n",
      "\n",
      "The classification loss after processing this batch is:  0.8223953247070312\n",
      "The representation loss after processing this batch is:  0.005546167492866516\n",
      "\n",
      "The classification loss after processing this batch is:  1.1736177206039429\n",
      "The representation loss after processing this batch is:  0.006421402096748352\n",
      "\n",
      "The classification loss after processing this batch is:  1.145987629890442\n",
      "The representation loss after processing this batch is:  0.0072645097970962524\n",
      "\n",
      "The classification loss after processing this batch is:  0.8420504927635193\n",
      "The representation loss after processing this batch is:  0.007083285599946976\n",
      "\n",
      "The classification loss after processing this batch is:  0.7016910910606384\n",
      "The representation loss after processing this batch is:  0.006300725042819977\n",
      "\n",
      "The classification loss after processing this batch is:  0.8760468363761902\n",
      "The representation loss after processing this batch is:  0.0061458200216293335\n",
      "\n",
      "The classification loss after processing this batch is:  0.9598548412322998\n",
      "The representation loss after processing this batch is:  0.006369754672050476\n",
      "\n",
      "The classification loss after processing this batch is:  0.9959267377853394\n",
      "The representation loss after processing this batch is:  0.0061719417572021484\n",
      "\n",
      "The classification loss after processing this batch is:  1.0024224519729614\n",
      "The representation loss after processing this batch is:  0.005657747387886047\n",
      "\n",
      "The classification loss after processing this batch is:  0.8923936486244202\n",
      "The representation loss after processing this batch is:  0.00490715354681015\n",
      "\n",
      "The classification loss after processing this batch is:  0.8716799020767212\n",
      "The representation loss after processing this batch is:  0.007306970655918121\n",
      "\n",
      "The classification loss after processing this batch is:  0.9879108667373657\n",
      "The representation loss after processing this batch is:  0.006991058588027954\n",
      "\n",
      "The classification loss after processing this batch is:  0.8422237634658813\n",
      "The representation loss after processing this batch is:  0.006842277944087982\n",
      "\n",
      "The classification loss after processing this batch is:  0.8099720478057861\n",
      "The representation loss after processing this batch is:  0.005727872252464294\n",
      "\n",
      "The classification loss after processing this batch is:  1.085074782371521\n",
      "The representation loss after processing this batch is:  0.006161123514175415\n",
      "\n",
      "The classification loss after processing this batch is:  0.8185061812400818\n",
      "The representation loss after processing this batch is:  0.00774480402469635\n",
      "\n",
      "The classification loss after processing this batch is:  0.7685348987579346\n",
      "The representation loss after processing this batch is:  0.006568849086761475\n",
      "\n",
      "The classification loss after processing this batch is:  0.8020479083061218\n",
      "The representation loss after processing this batch is:  0.005336441099643707\n",
      "\n",
      "The classification loss after processing this batch is:  0.6574512720108032\n",
      "The representation loss after processing this batch is:  0.005732491612434387\n",
      "\n",
      "The classification loss after processing this batch is:  0.6539624333381653\n",
      "The representation loss after processing this batch is:  0.005881503224372864\n",
      "\n",
      "The classification loss after processing this batch is:  0.8187514543533325\n",
      "The representation loss after processing this batch is:  0.005154106765985489\n",
      "\n",
      "The classification loss after processing this batch is:  0.9508755803108215\n",
      "The representation loss after processing this batch is:  0.0054780468344688416\n",
      "\n",
      "The classification loss after processing this batch is:  0.9174475073814392\n",
      "The representation loss after processing this batch is:  0.006019227206707001\n",
      "\n",
      "The classification loss after processing this batch is:  0.888257622718811\n",
      "The representation loss after processing this batch is:  0.005755200982093811\n",
      "\n",
      "The classification loss after processing this batch is:  0.8274856805801392\n",
      "The representation loss after processing this batch is:  0.00539795309305191\n",
      "\n",
      "The classification loss after processing this batch is:  0.8415492177009583\n",
      "The representation loss after processing this batch is:  0.005489591509103775\n",
      "\n",
      "The classification loss after processing this batch is:  0.7715614438056946\n",
      "The representation loss after processing this batch is:  0.0062051862478256226\n",
      "\n",
      "The classification loss after processing this batch is:  0.9271175265312195\n",
      "The representation loss after processing this batch is:  0.006341494619846344\n",
      "\n",
      "The classification loss after processing this batch is:  0.9193254113197327\n",
      "The representation loss after processing this batch is:  0.006057087332010269\n",
      "\n",
      "The classification loss after processing this batch is:  0.8770626783370972\n",
      "The representation loss after processing this batch is:  0.006041832268238068\n",
      "\n",
      "The classification loss after processing this batch is:  0.8541487455368042\n",
      "The representation loss after processing this batch is:  0.005568444728851318\n",
      "\n",
      "The classification loss after processing this batch is:  0.6674312353134155\n",
      "The representation loss after processing this batch is:  0.00603330135345459\n",
      "\n",
      "The classification loss after processing this batch is:  0.8669055700302124\n",
      "The representation loss after processing this batch is:  0.0056260377168655396\n",
      "\n",
      "The classification loss after processing this batch is:  0.7848144173622131\n",
      "The representation loss after processing this batch is:  0.005189023911952972\n",
      "\n",
      "The classification loss after processing this batch is:  0.8916689157485962\n",
      "The representation loss after processing this batch is:  0.005930371582508087\n",
      "\n",
      "The classification loss after processing this batch is:  0.9268926978111267\n",
      "The representation loss after processing this batch is:  0.005023784935474396\n",
      "\n",
      "The classification loss after processing this batch is:  0.9834719896316528\n",
      "The representation loss after processing this batch is:  0.0054761916399002075\n",
      "\n",
      "The classification loss after processing this batch is:  1.0432004928588867\n",
      "The representation loss after processing this batch is:  0.006104715168476105\n",
      "\n",
      "The classification loss after processing this batch is:  0.970119833946228\n",
      "The representation loss after processing this batch is:  0.005250804126262665\n",
      "\n",
      "The classification loss after processing this batch is:  1.0045734643936157\n",
      "The representation loss after processing this batch is:  0.004907183349132538\n",
      "\n",
      "The classification loss after processing this batch is:  1.0239893198013306\n",
      "The representation loss after processing this batch is:  0.005351833999156952\n",
      "\n",
      "The classification loss after processing this batch is:  1.0257359743118286\n",
      "The representation loss after processing this batch is:  0.004937708377838135\n",
      "\n",
      "The classification loss after processing this batch is:  0.758010983467102\n",
      "The representation loss after processing this batch is:  0.0057661086320877075\n",
      "\n",
      "The classification loss after processing this batch is:  0.6610321402549744\n",
      "The representation loss after processing this batch is:  0.00573817640542984\n",
      "\n",
      "The classification loss after processing this batch is:  0.8129385113716125\n",
      "The representation loss after processing this batch is:  0.005953200161457062\n",
      "\n",
      "The classification loss after processing this batch is:  0.7770357728004456\n",
      "The representation loss after processing this batch is:  0.007370851933956146\n",
      "\n",
      "The classification loss after processing this batch is:  0.7469741106033325\n",
      "The representation loss after processing this batch is:  0.006638534367084503\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.6088964343070984\n",
      "The representation loss after processing this batch is:  0.0055856853723526\n",
      "\n",
      "The classification loss after processing this batch is:  0.8745652437210083\n",
      "The representation loss after processing this batch is:  0.005927786231040955\n",
      "\n",
      "The classification loss after processing this batch is:  0.6383997797966003\n",
      "The representation loss after processing this batch is:  0.006074719130992889\n",
      "\n",
      "The classification loss after processing this batch is:  1.0486242771148682\n",
      "The representation loss after processing this batch is:  0.005483865737915039\n",
      "\n",
      "The classification loss after processing this batch is:  0.7197826504707336\n",
      "The representation loss after processing this batch is:  0.005813203752040863\n",
      "\n",
      "The classification loss after processing this batch is:  0.8625180125236511\n",
      "The representation loss after processing this batch is:  0.006758332252502441\n",
      "\n",
      "The classification loss after processing this batch is:  0.9148956537246704\n",
      "The representation loss after processing this batch is:  0.0053572505712509155\n",
      "\n",
      "The classification loss after processing this batch is:  0.7431660890579224\n",
      "The representation loss after processing this batch is:  0.004963811486959457\n",
      "\n",
      "The classification loss after processing this batch is:  0.7746414542198181\n",
      "The representation loss after processing this batch is:  0.005152948200702667\n",
      "\n",
      "The classification loss after processing this batch is:  0.7901173830032349\n",
      "The representation loss after processing this batch is:  0.005788832902908325\n",
      "\n",
      "The classification loss after processing this batch is:  0.7952471375465393\n",
      "The representation loss after processing this batch is:  0.005596190690994263\n",
      "\n",
      "The classification loss after processing this batch is:  0.6214619278907776\n",
      "The representation loss after processing this batch is:  0.00517803430557251\n",
      "\n",
      "The classification loss after processing this batch is:  0.6302757263183594\n",
      "The representation loss after processing this batch is:  0.006028816103935242\n",
      "\n",
      "The classification loss after processing this batch is:  0.5722376108169556\n",
      "The representation loss after processing this batch is:  0.005982197821140289\n",
      "\n",
      "The classification loss after processing this batch is:  0.6119123697280884\n",
      "The representation loss after processing this batch is:  0.005569778382778168\n",
      "\n",
      "The classification loss after processing this batch is:  0.666969895362854\n",
      "The representation loss after processing this batch is:  0.005283378064632416\n",
      "\n",
      "The classification loss after processing this batch is:  0.8255824446678162\n",
      "The representation loss after processing this batch is:  0.005514264106750488\n",
      "\n",
      "The classification loss after processing this batch is:  0.6295804381370544\n",
      "The representation loss after processing this batch is:  0.005114756524562836\n",
      "\n",
      "The classification loss after processing this batch is:  0.6199222207069397\n",
      "The representation loss after processing this batch is:  0.005082227289676666\n",
      "\n",
      "The classification loss after processing this batch is:  0.7440410852432251\n",
      "The representation loss after processing this batch is:  0.006380543112754822\n",
      "\n",
      "The classification loss after processing this batch is:  0.7759588360786438\n",
      "The representation loss after processing this batch is:  0.005418948829174042\n",
      "\n",
      "The classification loss after processing this batch is:  0.8327837586402893\n",
      "The representation loss after processing this batch is:  0.006154827773571014\n",
      "\n",
      "The classification loss after processing this batch is:  0.6974904537200928\n",
      "The representation loss after processing this batch is:  0.005393035709857941\n",
      "\n",
      "The classification loss after processing this batch is:  0.5707973837852478\n",
      "The representation loss after processing this batch is:  0.004448153078556061\n",
      "\n",
      "The classification loss after processing this batch is:  0.5838005542755127\n",
      "The representation loss after processing this batch is:  0.005165785551071167\n",
      "\n",
      "The classification loss after processing this batch is:  0.7161144018173218\n",
      "The representation loss after processing this batch is:  0.005775190889835358\n",
      "\n",
      "The classification loss after processing this batch is:  0.7231960296630859\n",
      "The representation loss after processing this batch is:  0.005445793271064758\n",
      "\n",
      "The classification loss after processing this batch is:  0.6590074300765991\n",
      "The representation loss after processing this batch is:  0.005242921411991119\n",
      "\n",
      "The classification loss after processing this batch is:  0.7692514061927795\n",
      "The representation loss after processing this batch is:  0.005124617367982864\n",
      "\n",
      "The classification loss after processing this batch is:  0.6584354043006897\n",
      "The representation loss after processing this batch is:  0.005080647766590118\n",
      "\n",
      "The classification loss after processing this batch is:  0.7611719965934753\n",
      "The representation loss after processing this batch is:  0.005522090941667557\n",
      "\n",
      "The classification loss after processing this batch is:  0.8017063140869141\n",
      "The representation loss after processing this batch is:  0.00649048388004303\n",
      "\n",
      "The classification loss after processing this batch is:  0.6956068873405457\n",
      "The representation loss after processing this batch is:  0.004999816417694092\n",
      "\n",
      "The classification loss after processing this batch is:  0.9675648808479309\n",
      "The representation loss after processing this batch is:  0.006159581243991852\n",
      "\n",
      "The classification loss after processing this batch is:  0.7955621480941772\n",
      "The representation loss after processing this batch is:  0.004997864365577698\n",
      "\n",
      "The classification loss after processing this batch is:  0.7462804317474365\n",
      "The representation loss after processing this batch is:  0.005257226526737213\n",
      "\n",
      "The classification loss after processing this batch is:  0.7261484265327454\n",
      "The representation loss after processing this batch is:  0.005066528916358948\n",
      "\n",
      "The classification loss after processing this batch is:  0.7218607068061829\n",
      "The representation loss after processing this batch is:  0.0058938562870025635\n",
      "\n",
      "The classification loss after processing this batch is:  0.7865219116210938\n",
      "The representation loss after processing this batch is:  0.005210116505622864\n",
      "\n",
      "The classification loss after processing this batch is:  0.758222758769989\n",
      "The representation loss after processing this batch is:  0.005596831440925598\n",
      "\n",
      "The classification loss after processing this batch is:  0.7488074898719788\n",
      "The representation loss after processing this batch is:  0.00636763870716095\n",
      "\n",
      "The classification loss after processing this batch is:  0.6137530207633972\n",
      "The representation loss after processing this batch is:  0.005541756749153137\n",
      "\n",
      "The classification loss after processing this batch is:  0.6680381894111633\n",
      "The representation loss after processing this batch is:  0.004858195781707764\n",
      "\n",
      "The classification loss after processing this batch is:  0.7568355202674866\n",
      "The representation loss after processing this batch is:  0.006121672689914703\n",
      "\n",
      "The classification loss after processing this batch is:  0.7315988540649414\n",
      "The representation loss after processing this batch is:  0.00536804273724556\n",
      "\n",
      "The classification loss after processing this batch is:  0.7025038599967957\n",
      "The representation loss after processing this batch is:  0.005790777504444122\n",
      "\n",
      "The classification loss after processing this batch is:  0.7483758330345154\n",
      "The representation loss after processing this batch is:  0.006096549332141876\n",
      "\n",
      "The classification loss after processing this batch is:  0.6918571591377258\n",
      "The representation loss after processing this batch is:  0.005446895956993103\n",
      "\n",
      "The classification loss after processing this batch is:  0.6371193528175354\n",
      "The representation loss after processing this batch is:  0.005719080567359924\n",
      "\n",
      "The classification loss after processing this batch is:  0.6419176459312439\n",
      "The representation loss after processing this batch is:  0.006383359432220459\n",
      "\n",
      "The classification loss after processing this batch is:  0.6392917633056641\n",
      "The representation loss after processing this batch is:  0.006043381989002228\n",
      "\n",
      "The classification loss after processing this batch is:  0.6205188035964966\n",
      "The representation loss after processing this batch is:  0.006208781152963638\n",
      "\n",
      "The classification loss after processing this batch is:  0.7146036624908447\n",
      "The representation loss after processing this batch is:  0.006036289036273956\n",
      "\n",
      "The classification loss after processing this batch is:  0.7645502090454102\n",
      "The representation loss after processing this batch is:  0.005847401916980743\n",
      "\n",
      "The classification loss after processing this batch is:  0.7111793160438538\n",
      "The representation loss after processing this batch is:  0.005818061530590057\n",
      "\n",
      "The classification loss after processing this batch is:  0.6368368864059448\n",
      "The representation loss after processing this batch is:  0.0046294257044792175\n",
      "\n",
      "The classification loss after processing this batch is:  0.6405080556869507\n",
      "The representation loss after processing this batch is:  0.005760587751865387\n",
      "\n",
      "The classification loss after processing this batch is:  0.4834105670452118\n",
      "The representation loss after processing this batch is:  0.006795547902584076\n",
      "\n",
      "The classification loss after processing this batch is:  0.6286764740943909\n",
      "The representation loss after processing this batch is:  0.005247794091701508\n",
      "\n",
      "The classification loss after processing this batch is:  0.6618785858154297\n",
      "The representation loss after processing this batch is:  0.004533439874649048\n",
      "\n",
      "The classification loss after processing this batch is:  0.7535762190818787\n",
      "The representation loss after processing this batch is:  0.0052234455943107605\n",
      "\n",
      "The classification loss after processing this batch is:  0.7119472026824951\n",
      "The representation loss after processing this batch is:  0.0051177069544792175\n",
      "\n",
      "The classification loss after processing this batch is:  0.6810007095336914\n",
      "The representation loss after processing this batch is:  0.005784280598163605\n",
      "\n",
      "The classification loss after processing this batch is:  0.6947987675666809\n",
      "The representation loss after processing this batch is:  0.0063965171575546265\n",
      "\n",
      "The classification loss after processing this batch is:  0.6594917178153992\n",
      "The representation loss after processing this batch is:  0.006245709955692291\n",
      "\n",
      "The classification loss after processing this batch is:  0.8325251340866089\n",
      "The representation loss after processing this batch is:  0.006248541176319122\n",
      "\n",
      "The classification loss after processing this batch is:  0.686815619468689\n",
      "The representation loss after processing this batch is:  0.005071021616458893\n",
      "\n",
      "The classification loss after processing this batch is:  0.6730260252952576\n",
      "The representation loss after processing this batch is:  0.005517259240150452\n",
      "\n",
      "The classification loss after processing this batch is:  0.5394741296768188\n",
      "The representation loss after processing this batch is:  0.005427151918411255\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.5628960728645325\n",
      "The representation loss after processing this batch is:  0.005657307803630829\n",
      "\n",
      "The classification loss after processing this batch is:  0.7908246517181396\n",
      "The representation loss after processing this batch is:  0.005200475454330444\n",
      "\n",
      "The classification loss after processing this batch is:  0.8109177947044373\n",
      "The representation loss after processing this batch is:  0.005132615566253662\n",
      "\n",
      "The classification loss after processing this batch is:  0.7380945086479187\n",
      "The representation loss after processing this batch is:  0.005834572017192841\n",
      "\n",
      "The classification loss after processing this batch is:  0.7150686383247375\n",
      "The representation loss after processing this batch is:  0.004902966320514679\n",
      "\n",
      "The classification loss after processing this batch is:  0.7588294148445129\n",
      "The representation loss after processing this batch is:  0.006221011281013489\n",
      "\n",
      "The classification loss after processing this batch is:  0.7624087929725647\n",
      "The representation loss after processing this batch is:  0.004799172282218933\n",
      "\n",
      "The classification loss after processing this batch is:  0.7698137760162354\n",
      "The representation loss after processing this batch is:  0.005532212555408478\n",
      "\n",
      "The classification loss after processing this batch is:  0.7633019685745239\n",
      "The representation loss after processing this batch is:  0.005306892096996307\n",
      "\n",
      "The classification loss after processing this batch is:  0.7752039432525635\n",
      "The representation loss after processing this batch is:  0.006008066236972809\n",
      "\n",
      "The classification loss after processing this batch is:  0.7207251191139221\n",
      "The representation loss after processing this batch is:  0.006058149039745331\n",
      "\n",
      "The classification loss after processing this batch is:  0.45338475704193115\n",
      "The representation loss after processing this batch is:  0.005114361643791199\n",
      "\n",
      "The classification loss after processing this batch is:  0.6219393610954285\n",
      "The representation loss after processing this batch is:  0.0055560097098350525\n",
      "\n",
      "The classification loss after processing this batch is:  0.6714255809783936\n",
      "The representation loss after processing this batch is:  0.004818301647901535\n",
      "\n",
      "The classification loss after processing this batch is:  0.6113590002059937\n",
      "The representation loss after processing this batch is:  0.005354892462491989\n",
      "\n",
      "The classification loss after processing this batch is:  0.7168410420417786\n",
      "The representation loss after processing this batch is:  0.00539793074131012\n",
      "\n",
      "The classification loss after processing this batch is:  0.5737030506134033\n",
      "The representation loss after processing this batch is:  0.005461469292640686\n",
      "\n",
      "The classification loss after processing this batch is:  0.6030197739601135\n",
      "The representation loss after processing this batch is:  0.005149759352207184\n",
      "\n",
      "The classification loss after processing this batch is:  0.6815369129180908\n",
      "The representation loss after processing this batch is:  0.005627788603305817\n",
      "\n",
      "The classification loss after processing this batch is:  0.6011574864387512\n",
      "The representation loss after processing this batch is:  0.00487171858549118\n",
      "\n",
      "The classification loss after processing this batch is:  0.6666842699050903\n",
      "The representation loss after processing this batch is:  0.005192197859287262\n",
      "\n",
      "The classification loss after processing this batch is:  0.7507607936859131\n",
      "The representation loss after processing this batch is:  0.005302272737026215\n",
      "\n",
      "The classification loss after processing this batch is:  0.7233182191848755\n",
      "The representation loss after processing this batch is:  0.005911722779273987\n",
      "\n",
      "The classification loss after processing this batch is:  0.5664204359054565\n",
      "The representation loss after processing this batch is:  0.006720446050167084\n",
      "\n",
      "The classification loss after processing this batch is:  0.53006911277771\n",
      "The representation loss after processing this batch is:  0.004874132573604584\n",
      "\n",
      "The classification loss after processing this batch is:  0.487248033285141\n",
      "The representation loss after processing this batch is:  0.004981130361557007\n",
      "\n",
      "The classification loss after processing this batch is:  0.6698847413063049\n",
      "The representation loss after processing this batch is:  0.005181916058063507\n",
      "\n",
      "The classification loss after processing this batch is:  0.8046606779098511\n",
      "The representation loss after processing this batch is:  0.004824686795473099\n",
      "\n",
      "The classification loss after processing this batch is:  0.6298220157623291\n",
      "The representation loss after processing this batch is:  0.004557304084300995\n",
      "\n",
      "The classification loss after processing this batch is:  0.44234853982925415\n",
      "The representation loss after processing this batch is:  0.005686681717634201\n",
      "\n",
      "The classification loss after processing this batch is:  0.6250566244125366\n",
      "The representation loss after processing this batch is:  0.004871118813753128\n",
      "\n",
      "The classification loss after processing this batch is:  0.4325551986694336\n",
      "The representation loss after processing this batch is:  0.0059874653816223145\n",
      "\n",
      "The classification loss after processing this batch is:  0.535890519618988\n",
      "The representation loss after processing this batch is:  0.0049700140953063965\n",
      "\n",
      "The classification loss after processing this batch is:  0.47000423073768616\n",
      "The representation loss after processing this batch is:  0.005680851638317108\n",
      "\n",
      "The classification loss after processing this batch is:  0.4492930769920349\n",
      "The representation loss after processing this batch is:  0.005018852651119232\n",
      "\n",
      "The classification loss after processing this batch is:  0.476774662733078\n",
      "The representation loss after processing this batch is:  0.0049275681376457214\n",
      "\n",
      "The classification loss after processing this batch is:  0.591940701007843\n",
      "The representation loss after processing this batch is:  0.005409441888332367\n",
      "\n",
      "The classification loss after processing this batch is:  0.5021392107009888\n",
      "The representation loss after processing this batch is:  0.005101919174194336\n",
      "\n",
      "The classification loss after processing this batch is:  0.7336781620979309\n",
      "The representation loss after processing this batch is:  0.0051034316420555115\n",
      "\n",
      "The classification loss after processing this batch is:  0.7622756958007812\n",
      "The representation loss after processing this batch is:  0.005140446126461029\n",
      "\n",
      "The classification loss after processing this batch is:  0.6852967739105225\n",
      "The representation loss after processing this batch is:  0.005290672183036804\n",
      "\n",
      "The classification loss after processing this batch is:  0.7381610870361328\n",
      "The representation loss after processing this batch is:  0.005294676870107651\n",
      "\n",
      "The classification loss after processing this batch is:  0.6179344058036804\n",
      "The representation loss after processing this batch is:  0.004960585385560989\n",
      "\n",
      "The classification loss after processing this batch is:  0.5894771218299866\n",
      "The representation loss after processing this batch is:  0.005058556795120239\n",
      "\n",
      "The classification loss after processing this batch is:  0.6375828385353088\n",
      "The representation loss after processing this batch is:  0.004991956055164337\n",
      "\n",
      "The classification loss after processing this batch is:  0.5820046067237854\n",
      "The representation loss after processing this batch is:  0.005239672958850861\n",
      "\n",
      "The classification loss after processing this batch is:  0.7128368616104126\n",
      "The representation loss after processing this batch is:  0.006379425525665283\n",
      "\n",
      "The classification loss after processing this batch is:  0.5932163596153259\n",
      "The representation loss after processing this batch is:  0.005266502499580383\n",
      "\n",
      "The classification loss after processing this batch is:  0.6345013380050659\n",
      "The representation loss after processing this batch is:  0.005424831062555313\n",
      "\n",
      "The classification loss after processing this batch is:  0.6963681578636169\n",
      "The representation loss after processing this batch is:  0.00525694340467453\n",
      "\n",
      "The classification loss after processing this batch is:  0.6089572906494141\n",
      "The representation loss after processing this batch is:  0.005537495017051697\n",
      "\n",
      "The classification loss after processing this batch is:  0.7165051102638245\n",
      "The representation loss after processing this batch is:  0.004736870527267456\n",
      "\n",
      "The classification loss after processing this batch is:  0.5668871998786926\n",
      "The representation loss after processing this batch is:  0.005304425954818726\n",
      "\n",
      "The classification loss after processing this batch is:  0.5009786486625671\n",
      "The representation loss after processing this batch is:  0.004270367324352264\n",
      "\n",
      "The classification loss after processing this batch is:  0.6255136132240295\n",
      "The representation loss after processing this batch is:  0.005486376583576202\n",
      "\n",
      "The classification loss after processing this batch is:  0.6256749629974365\n",
      "The representation loss after processing this batch is:  0.005049817264080048\n",
      "\n",
      "The classification loss after processing this batch is:  0.41160818934440613\n",
      "The representation loss after processing this batch is:  0.004950806498527527\n",
      "\n",
      "The classification loss after processing this batch is:  0.5922628045082092\n",
      "The representation loss after processing this batch is:  0.004524797201156616\n",
      "\n",
      "The classification loss after processing this batch is:  0.7392523884773254\n",
      "The representation loss after processing this batch is:  0.004887565970420837\n",
      "\n",
      "The classification loss after processing this batch is:  0.5917779803276062\n",
      "The representation loss after processing this batch is:  0.004774361848831177\n",
      "\n",
      "The classification loss after processing this batch is:  0.5615606904029846\n",
      "The representation loss after processing this batch is:  0.005713742226362228\n",
      "\n",
      "The classification loss after processing this batch is:  0.6725373864173889\n",
      "The representation loss after processing this batch is:  0.004603404551744461\n",
      "\n",
      "The classification loss after processing this batch is:  0.4857654273509979\n",
      "The representation loss after processing this batch is:  0.005517162382602692\n",
      "\n",
      "The classification loss after processing this batch is:  0.4757901430130005\n",
      "The representation loss after processing this batch is:  0.00498652458190918\n",
      "\n",
      "The classification loss after processing this batch is:  0.5008676052093506\n",
      "The representation loss after processing this batch is:  0.004721127450466156\n",
      "\n",
      "The classification loss after processing this batch is:  0.4930872619152069\n",
      "The representation loss after processing this batch is:  0.006008073687553406\n",
      "\n",
      "The classification loss after processing this batch is:  0.5393983125686646\n",
      "The representation loss after processing this batch is:  0.0056767091155052185\n",
      "\n",
      "The classification loss after processing this batch is:  0.5515235662460327\n",
      "The representation loss after processing this batch is:  0.005148276686668396\n",
      "\n",
      "The classification loss after processing this batch is:  0.5615350604057312\n",
      "The representation loss after processing this batch is:  0.005334481596946716\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.6385582685470581\n",
      "The representation loss after processing this batch is:  0.005069606006145477\n",
      "\n",
      "The classification loss after processing this batch is:  0.551762044429779\n",
      "The representation loss after processing this batch is:  0.004823312163352966\n",
      "\n",
      "The classification loss after processing this batch is:  0.6141067147254944\n",
      "The representation loss after processing this batch is:  0.005453471094369888\n",
      "\n",
      "The classification loss after processing this batch is:  0.8114084005355835\n",
      "The representation loss after processing this batch is:  0.005888685584068298\n",
      "\n",
      "The classification loss after processing this batch is:  0.7341282963752747\n",
      "The representation loss after processing this batch is:  0.005352891981601715\n",
      "\n",
      "The classification loss after processing this batch is:  0.7418359518051147\n",
      "The representation loss after processing this batch is:  0.004761781543493271\n",
      "\n",
      "The classification loss after processing this batch is:  0.6517708897590637\n",
      "The representation loss after processing this batch is:  0.005186352878808975\n",
      "\n",
      "The classification loss after processing this batch is:  0.7087894678115845\n",
      "The representation loss after processing this batch is:  0.005623750388622284\n",
      "\n",
      "The classification loss after processing this batch is:  0.6934928297996521\n",
      "The representation loss after processing this batch is:  0.004691861569881439\n",
      "\n",
      "The classification loss after processing this batch is:  0.3901626169681549\n",
      "The representation loss after processing this batch is:  0.005264695733785629\n",
      "\n",
      "The classification loss after processing this batch is:  0.5906068682670593\n",
      "The representation loss after processing this batch is:  0.005847770720720291\n",
      "\n",
      "The classification loss after processing this batch is:  0.5716283321380615\n",
      "The representation loss after processing this batch is:  0.007139377295970917\n",
      "\n",
      "The classification loss after processing this batch is:  0.43928542733192444\n",
      "The representation loss after processing this batch is:  0.005360446870326996\n",
      "\n",
      "The classification loss after processing this batch is:  0.6479074358940125\n",
      "The representation loss after processing this batch is:  0.0048909299075603485\n",
      "\n",
      "The classification loss after processing this batch is:  0.6292117238044739\n",
      "The representation loss after processing this batch is:  0.005115773528814316\n",
      "\n",
      "The classification loss after processing this batch is:  0.5642403960227966\n",
      "The representation loss after processing this batch is:  0.004768006503582001\n",
      "\n",
      "The classification loss after processing this batch is:  0.6859285235404968\n",
      "The representation loss after processing this batch is:  0.004607826471328735\n",
      "\n",
      "The classification loss after processing this batch is:  0.6801134943962097\n",
      "The representation loss after processing this batch is:  0.0049255117774009705\n",
      "\n",
      "The classification loss after processing this batch is:  0.832028329372406\n",
      "The representation loss after processing this batch is:  0.004671610891819\n",
      "\n",
      "The classification loss after processing this batch is:  0.7111856937408447\n",
      "The representation loss after processing this batch is:  0.006104923784732819\n",
      "\n",
      "The classification loss after processing this batch is:  0.7665054202079773\n",
      "The representation loss after processing this batch is:  0.004468709230422974\n",
      "\n",
      "The classification loss after processing this batch is:  0.6060207486152649\n",
      "The representation loss after processing this batch is:  0.005255550146102905\n",
      "\n",
      "The classification loss after processing this batch is:  0.6115261912345886\n",
      "The representation loss after processing this batch is:  0.005267735570669174\n",
      "\n",
      "The classification loss after processing this batch is:  0.704883337020874\n",
      "The representation loss after processing this batch is:  0.0062055885791778564\n",
      "\n",
      "The classification loss after processing this batch is:  0.4263007342815399\n",
      "The representation loss after processing this batch is:  0.004387505352497101\n",
      "\n",
      "The classification loss after processing this batch is:  0.4004843831062317\n",
      "The representation loss after processing this batch is:  0.005769312381744385\n",
      "\n",
      "The classification loss after processing this batch is:  0.7111485004425049\n",
      "The representation loss after processing this batch is:  0.005105331540107727\n",
      "\n",
      "The classification loss after processing this batch is:  0.42795076966285706\n",
      "The representation loss after processing this batch is:  0.004833824932575226\n",
      "\n",
      "The classification loss after processing this batch is:  0.5342305302619934\n",
      "The representation loss after processing this batch is:  0.004667762666940689\n",
      "\n",
      "The classification loss after processing this batch is:  0.5516061186790466\n",
      "The representation loss after processing this batch is:  0.004836924374103546\n",
      "\n",
      "The classification loss after processing this batch is:  0.5926599502563477\n",
      "The representation loss after processing this batch is:  0.005454957485198975\n",
      "\n",
      "The classification loss after processing this batch is:  0.7775595188140869\n",
      "The representation loss after processing this batch is:  0.0058103203773498535\n",
      "\n",
      "The classification loss after processing this batch is:  0.8228350281715393\n",
      "The representation loss after processing this batch is:  0.004833616316318512\n",
      "\n",
      "The classification loss after processing this batch is:  0.7078924179077148\n",
      "The representation loss after processing this batch is:  0.00581340491771698\n",
      "\n",
      "The classification loss after processing this batch is:  0.5210930109024048\n",
      "The representation loss after processing this batch is:  0.004855882376432419\n",
      "\n",
      "The classification loss after processing this batch is:  0.6213448643684387\n",
      "The representation loss after processing this batch is:  0.004358958452939987\n",
      "\n",
      "The classification loss after processing this batch is:  0.47147688269615173\n",
      "The representation loss after processing this batch is:  0.004622556269168854\n",
      "\n",
      "The classification loss after processing this batch is:  0.4735512435436249\n",
      "The representation loss after processing this batch is:  0.004572063684463501\n",
      "\n",
      "The classification loss after processing this batch is:  0.5076850056648254\n",
      "The representation loss after processing this batch is:  0.004937823861837387\n",
      "\n",
      "The classification loss after processing this batch is:  0.3708368241786957\n",
      "The representation loss after processing this batch is:  0.004401803016662598\n",
      "\n",
      "The classification loss after processing this batch is:  0.5490270256996155\n",
      "The representation loss after processing this batch is:  0.004551678895950317\n",
      "\n",
      "The classification loss after processing this batch is:  0.40855592489242554\n",
      "The representation loss after processing this batch is:  0.004721928387880325\n",
      "\n",
      "The classification loss after processing this batch is:  0.4818342924118042\n",
      "The representation loss after processing this batch is:  0.004686862230300903\n",
      "\n",
      "The classification loss after processing this batch is:  0.5194082856178284\n",
      "The representation loss after processing this batch is:  0.00461234524846077\n",
      "\n",
      "The classification loss after processing this batch is:  0.5836178064346313\n",
      "The representation loss after processing this batch is:  0.0059079453349113464\n",
      "\n",
      "The classification loss after processing this batch is:  0.6865043044090271\n",
      "The representation loss after processing this batch is:  0.0045852698385715485\n",
      "\n",
      "The classification loss after processing this batch is:  0.5323275327682495\n",
      "The representation loss after processing this batch is:  0.00564149022102356\n",
      "\n",
      "The classification loss after processing this batch is:  0.603380560874939\n",
      "The representation loss after processing this batch is:  0.0052461326122283936\n",
      "\n",
      "The classification loss after processing this batch is:  0.47970545291900635\n",
      "The representation loss after processing this batch is:  0.005215644836425781\n",
      "\n",
      "The classification loss after processing this batch is:  0.577463686466217\n",
      "The representation loss after processing this batch is:  0.005121655762195587\n",
      "\n",
      "The classification loss after processing this batch is:  0.8343289494514465\n",
      "The representation loss after processing this batch is:  0.005137421190738678\n",
      "\n",
      "The classification loss after processing this batch is:  0.6812571883201599\n",
      "The representation loss after processing this batch is:  0.0048568397760391235\n",
      "\n",
      "The classification loss after processing this batch is:  0.6627070307731628\n",
      "The representation loss after processing this batch is:  0.004475891590118408\n",
      "\n",
      "The classification loss after processing this batch is:  0.5927727222442627\n",
      "The representation loss after processing this batch is:  0.004855707287788391\n",
      "\n",
      "The classification loss after processing this batch is:  0.6552045941352844\n",
      "The representation loss after processing this batch is:  0.004768259823322296\n",
      "\n",
      "The classification loss after processing this batch is:  0.5237478613853455\n",
      "The representation loss after processing this batch is:  0.005001269280910492\n",
      "\n",
      "The classification loss after processing this batch is:  0.4590083360671997\n",
      "The representation loss after processing this batch is:  0.004613250494003296\n",
      "\n",
      "The classification loss after processing this batch is:  0.4038175642490387\n",
      "The representation loss after processing this batch is:  0.00519823282957077\n",
      "\n",
      "The classification loss after processing this batch is:  0.4598148763179779\n",
      "The representation loss after processing this batch is:  0.004813499748706818\n",
      "\n",
      "The classification loss after processing this batch is:  0.4085755944252014\n",
      "The representation loss after processing this batch is:  0.004483208060264587\n",
      "\n",
      "The classification loss after processing this batch is:  0.5577123761177063\n",
      "The representation loss after processing this batch is:  0.005172375589609146\n",
      "\n",
      "The classification loss after processing this batch is:  0.4489253759384155\n",
      "The representation loss after processing this batch is:  0.005524985492229462\n",
      "\n",
      "The classification loss after processing this batch is:  0.7248010039329529\n",
      "The representation loss after processing this batch is:  0.0049330852925777435\n",
      "\n",
      "The classification loss after processing this batch is:  0.5676257610321045\n",
      "The representation loss after processing this batch is:  0.005284227430820465\n",
      "\n",
      "The classification loss after processing this batch is:  0.5092421770095825\n",
      "The representation loss after processing this batch is:  0.004676375538110733\n",
      "\n",
      "The classification loss after processing this batch is:  0.7311747670173645\n",
      "The representation loss after processing this batch is:  0.004271417856216431\n",
      "\n",
      "The classification loss after processing this batch is:  0.6359705328941345\n",
      "The representation loss after processing this batch is:  0.004574190825223923\n",
      "\n",
      "The classification loss after processing this batch is:  0.49653470516204834\n",
      "The representation loss after processing this batch is:  0.004244066774845123\n",
      "\n",
      "The classification loss after processing this batch is:  0.37424057722091675\n",
      "The representation loss after processing this batch is:  0.005831725895404816\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.4589027166366577\n",
      "The representation loss after processing this batch is:  0.004915915429592133\n",
      "\n",
      "The classification loss after processing this batch is:  0.4311680793762207\n",
      "The representation loss after processing this batch is:  0.0048034414649009705\n",
      "\n",
      "The classification loss after processing this batch is:  0.5325857400894165\n",
      "The representation loss after processing this batch is:  0.003914836794137955\n",
      "\n",
      "The classification loss after processing this batch is:  0.7000176310539246\n",
      "The representation loss after processing this batch is:  0.005101453512907028\n",
      "\n",
      "The classification loss after processing this batch is:  0.6984103322029114\n",
      "The representation loss after processing this batch is:  0.005141198635101318\n",
      "\n",
      "The classification loss after processing this batch is:  0.4446788430213928\n",
      "The representation loss after processing this batch is:  0.005406409502029419\n",
      "\n",
      "The classification loss after processing this batch is:  0.5892475843429565\n",
      "The representation loss after processing this batch is:  0.005264930427074432\n",
      "\n",
      "The classification loss after processing this batch is:  0.3563237190246582\n",
      "The representation loss after processing this batch is:  0.004689715802669525\n",
      "\n",
      "The classification loss after processing this batch is:  0.5214969515800476\n",
      "The representation loss after processing this batch is:  0.0048626624047756195\n",
      "\n",
      "The classification loss after processing this batch is:  0.6865042448043823\n",
      "The representation loss after processing this batch is:  0.004461068660020828\n",
      "\n",
      "The classification loss after processing this batch is:  0.5805490016937256\n",
      "The representation loss after processing this batch is:  0.006403222680091858\n",
      "\n",
      "The classification loss after processing this batch is:  0.49918708205223083\n",
      "The representation loss after processing this batch is:  0.005513250827789307\n",
      "\n",
      "The classification loss after processing this batch is:  0.5074414610862732\n",
      "The representation loss after processing this batch is:  0.005889851599931717\n",
      "\n",
      "The classification loss after processing this batch is:  0.6408087611198425\n",
      "The representation loss after processing this batch is:  0.005610533058643341\n",
      "\n",
      "The classification loss after processing this batch is:  0.5912243723869324\n",
      "The representation loss after processing this batch is:  0.005434099584817886\n",
      "\n",
      "The classification loss after processing this batch is:  0.5305261015892029\n",
      "The representation loss after processing this batch is:  0.004759982228279114\n",
      "\n",
      "The classification loss after processing this batch is:  0.48889750242233276\n",
      "The representation loss after processing this batch is:  0.004900604486465454\n",
      "\n",
      "The classification loss after processing this batch is:  0.6501929759979248\n",
      "The representation loss after processing this batch is:  0.004482075572013855\n",
      "\n",
      "The classification loss after processing this batch is:  0.648479700088501\n",
      "The representation loss after processing this batch is:  0.004431523382663727\n",
      "\n",
      "The classification loss after processing this batch is:  0.5404760241508484\n",
      "The representation loss after processing this batch is:  0.0049298107624053955\n",
      "\n",
      "The classification loss after processing this batch is:  0.4527021646499634\n",
      "The representation loss after processing this batch is:  0.005080476403236389\n",
      "\n",
      "The classification loss after processing this batch is:  0.3884115517139435\n",
      "The representation loss after processing this batch is:  0.005195841193199158\n",
      "\n",
      "The classification loss after processing this batch is:  0.5450966358184814\n",
      "The representation loss after processing this batch is:  0.005640998482704163\n",
      "\n",
      "The classification loss after processing this batch is:  0.47153645753860474\n",
      "The representation loss after processing this batch is:  0.00508832186460495\n",
      "\n",
      "The classification loss after processing this batch is:  0.5955812335014343\n",
      "The representation loss after processing this batch is:  0.003970511257648468\n",
      "\n",
      "The classification loss after processing this batch is:  0.3922037184238434\n",
      "The representation loss after processing this batch is:  0.005748368799686432\n",
      "\n",
      "The classification loss after processing this batch is:  0.45975735783576965\n",
      "The representation loss after processing this batch is:  0.004441507160663605\n",
      "\n",
      "The classification loss after processing this batch is:  0.5406364798545837\n",
      "The representation loss after processing this batch is:  0.005439400672912598\n",
      "\n",
      "The classification loss after processing this batch is:  0.4161977469921112\n",
      "The representation loss after processing this batch is:  0.004871271550655365\n",
      "\n",
      "The classification loss after processing this batch is:  0.6103975772857666\n",
      "The representation loss after processing this batch is:  0.004726767539978027\n",
      "\n",
      "The classification loss after processing this batch is:  0.4059022068977356\n",
      "The representation loss after processing this batch is:  0.004739239811897278\n",
      "\n",
      "The classification loss after processing this batch is:  0.42917266488075256\n",
      "The representation loss after processing this batch is:  0.004489824175834656\n",
      "\n",
      "The classification loss after processing this batch is:  0.3679473102092743\n",
      "The representation loss after processing this batch is:  0.0050142668187618256\n",
      "\n",
      "The classification loss after processing this batch is:  0.5255762338638306\n",
      "The representation loss after processing this batch is:  0.005551859736442566\n",
      "\n",
      "The classification loss after processing this batch is:  0.5464547872543335\n",
      "The representation loss after processing this batch is:  0.0052416883409023285\n",
      "\n",
      "The classification loss after processing this batch is:  0.5337312817573547\n",
      "The representation loss after processing this batch is:  0.004082392901182175\n",
      "\n",
      "The classification loss after processing this batch is:  0.63113933801651\n",
      "The representation loss after processing this batch is:  0.004545368254184723\n",
      "\n",
      "The classification loss after processing this batch is:  0.7268146276473999\n",
      "The representation loss after processing this batch is:  0.00476272776722908\n",
      "\n",
      "The classification loss after processing this batch is:  0.5573726892471313\n",
      "The representation loss after processing this batch is:  0.00550851970911026\n",
      "\n",
      "The classification loss after processing this batch is:  0.6463014483451843\n",
      "The representation loss after processing this batch is:  0.004651591181755066\n",
      "\n",
      "The classification loss after processing this batch is:  0.48041781783103943\n",
      "The representation loss after processing this batch is:  0.004529207944869995\n",
      "\n",
      "The classification loss after processing this batch is:  0.4027627110481262\n",
      "The representation loss after processing this batch is:  0.004696108400821686\n",
      "\n",
      "The classification loss after processing this batch is:  0.3928489685058594\n",
      "The representation loss after processing this batch is:  0.004729375243186951\n",
      "\n",
      "The classification loss after processing this batch is:  0.4231288731098175\n",
      "The representation loss after processing this batch is:  0.004987858235836029\n",
      "\n",
      "The classification loss after processing this batch is:  0.6396654844284058\n",
      "The representation loss after processing this batch is:  0.005565471947193146\n",
      "\n",
      "The classification loss after processing this batch is:  0.4894469976425171\n",
      "The representation loss after processing this batch is:  0.0047696903347969055\n",
      "\n",
      "The classification loss after processing this batch is:  0.49139535427093506\n",
      "The representation loss after processing this batch is:  0.004617270082235336\n",
      "\n",
      "The classification loss after processing this batch is:  0.4585341811180115\n",
      "The representation loss after processing this batch is:  0.005253605544567108\n",
      "\n",
      "The classification loss after processing this batch is:  0.4635215401649475\n",
      "The representation loss after processing this batch is:  0.004758872091770172\n",
      "\n",
      "The classification loss after processing this batch is:  0.3903581500053406\n",
      "The representation loss after processing this batch is:  0.0048682838678359985\n",
      "\n",
      "The classification loss after processing this batch is:  0.4404503107070923\n",
      "The representation loss after processing this batch is:  0.003824658691883087\n",
      "\n",
      "The classification loss after processing this batch is:  0.5330337285995483\n",
      "The representation loss after processing this batch is:  0.004602871835231781\n",
      "\n",
      "The classification loss after processing this batch is:  0.5012403130531311\n",
      "The representation loss after processing this batch is:  0.004996530711650848\n",
      "\n",
      "The classification loss after processing this batch is:  0.36634546518325806\n",
      "The representation loss after processing this batch is:  0.004200838506221771\n",
      "\n",
      "The classification loss after processing this batch is:  0.5376640558242798\n",
      "The representation loss after processing this batch is:  0.004066403955221176\n",
      "\n",
      "The classification loss after processing this batch is:  0.5251134634017944\n",
      "The representation loss after processing this batch is:  0.0047236233949661255\n",
      "\n",
      "The classification loss after processing this batch is:  0.47070255875587463\n",
      "The representation loss after processing this batch is:  0.0041537657380104065\n",
      "\n",
      "The classification loss after processing this batch is:  0.405824214220047\n",
      "The representation loss after processing this batch is:  0.0047586411237716675\n",
      "\n",
      "The classification loss after processing this batch is:  0.3905397653579712\n",
      "The representation loss after processing this batch is:  0.004271738231182098\n",
      "\n",
      "The classification loss after processing this batch is:  0.4053480327129364\n",
      "The representation loss after processing this batch is:  0.004845038056373596\n",
      "\n",
      "The classification loss after processing this batch is:  0.3816317915916443\n",
      "The representation loss after processing this batch is:  0.005231238901615143\n",
      "\n",
      "The classification loss after processing this batch is:  0.5577743053436279\n",
      "The representation loss after processing this batch is:  0.00487808883190155\n",
      "\n",
      "The classification loss after processing this batch is:  0.7068255543708801\n",
      "The representation loss after processing this batch is:  0.005468197166919708\n",
      "\n",
      "The classification loss after processing this batch is:  0.6133237481117249\n",
      "The representation loss after processing this batch is:  0.005198277533054352\n",
      "\n",
      "The classification loss after processing this batch is:  0.600543200969696\n",
      "The representation loss after processing this batch is:  0.00542425736784935\n",
      "\n",
      "The classification loss after processing this batch is:  0.577706515789032\n",
      "The representation loss after processing this batch is:  0.00574897974729538\n",
      "\n",
      "The classification loss after processing this batch is:  0.6262052655220032\n",
      "The representation loss after processing this batch is:  0.004371233284473419\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.44866427779197693\n",
      "The representation loss after processing this batch is:  0.004569068551063538\n",
      "\n",
      "The classification loss after processing this batch is:  0.3174886107444763\n",
      "The representation loss after processing this batch is:  0.00484815239906311\n",
      "\n",
      "The classification loss after processing this batch is:  0.41130104660987854\n",
      "The representation loss after processing this batch is:  0.004546329379081726\n",
      "\n",
      "The classification loss after processing this batch is:  0.6797171235084534\n",
      "The representation loss after processing this batch is:  0.005137033760547638\n",
      "\n",
      "The classification loss after processing this batch is:  0.7255175113677979\n",
      "The representation loss after processing this batch is:  0.004928193986415863\n",
      "\n",
      "The classification loss after processing this batch is:  0.6979909539222717\n",
      "The representation loss after processing this batch is:  0.004784028977155685\n",
      "\n",
      "The classification loss after processing this batch is:  0.5007038712501526\n",
      "The representation loss after processing this batch is:  0.004808049649000168\n",
      "\n",
      "The classification loss after processing this batch is:  0.5090545415878296\n",
      "The representation loss after processing this batch is:  0.004543285816907883\n",
      "\n",
      "The classification loss after processing this batch is:  0.43818342685699463\n",
      "The representation loss after processing this batch is:  0.004346668720245361\n",
      "\n",
      "The classification loss after processing this batch is:  0.4462736248970032\n",
      "The representation loss after processing this batch is:  0.0054910145699977875\n",
      "\n",
      "The classification loss after processing this batch is:  0.5036172270774841\n",
      "The representation loss after processing this batch is:  0.005254343152046204\n",
      "\n",
      "The classification loss after processing this batch is:  0.43394750356674194\n",
      "The representation loss after processing this batch is:  0.0055346861481666565\n",
      "\n",
      "The classification loss after processing this batch is:  0.5301409363746643\n",
      "The representation loss after processing this batch is:  0.006199531257152557\n",
      "\n",
      "The classification loss after processing this batch is:  0.4789225459098816\n",
      "The representation loss after processing this batch is:  0.0050451308488845825\n",
      "\n",
      "The classification loss after processing this batch is:  0.42309442162513733\n",
      "The representation loss after processing this batch is:  0.004413902759552002\n",
      "\n",
      "The classification loss after processing this batch is:  0.46468305587768555\n",
      "The representation loss after processing this batch is:  0.005154937505722046\n",
      "\n",
      "The classification loss after processing this batch is:  0.5068418383598328\n",
      "The representation loss after processing this batch is:  0.004743397235870361\n",
      "\n",
      "The classification loss after processing this batch is:  0.4526086747646332\n",
      "The representation loss after processing this batch is:  0.0044279322028160095\n",
      "\n",
      "The classification loss after processing this batch is:  0.7123502492904663\n",
      "The representation loss after processing this batch is:  0.0052340105175971985\n",
      "\n",
      "The classification loss after processing this batch is:  0.6848529577255249\n",
      "The representation loss after processing this batch is:  0.004858564585447311\n",
      "\n",
      "The classification loss after processing this batch is:  0.5085152983665466\n",
      "The representation loss after processing this batch is:  0.005100704729557037\n",
      "\n",
      "The classification loss after processing this batch is:  0.5100200176239014\n",
      "The representation loss after processing this batch is:  0.005182400345802307\n",
      "\n",
      "The classification loss after processing this batch is:  0.4020380675792694\n",
      "The representation loss after processing this batch is:  0.0048422664403915405\n",
      "\n",
      "The classification loss after processing this batch is:  0.37274542450904846\n",
      "The representation loss after processing this batch is:  0.004679955542087555\n",
      "\n",
      "The classification loss after processing this batch is:  0.627117931842804\n",
      "The representation loss after processing this batch is:  0.005104821175336838\n",
      "\n",
      "The classification loss after processing this batch is:  0.4723224341869354\n",
      "The representation loss after processing this batch is:  0.0049598440527915955\n",
      "\n",
      "The classification loss after processing this batch is:  0.40656211972236633\n",
      "The representation loss after processing this batch is:  0.0049511343240737915\n",
      "\n",
      "The classification loss after processing this batch is:  0.5790001153945923\n",
      "The representation loss after processing this batch is:  0.004630357027053833\n",
      "\n",
      "The classification loss after processing this batch is:  0.3595699369907379\n",
      "The representation loss after processing this batch is:  0.004276882857084274\n",
      "\n",
      "The classification loss after processing this batch is:  0.4154467284679413\n",
      "The representation loss after processing this batch is:  0.005511067807674408\n",
      "\n",
      "The classification loss after processing this batch is:  0.48062384128570557\n",
      "The representation loss after processing this batch is:  0.004184611141681671\n",
      "\n",
      "The classification loss after processing this batch is:  0.5313544869422913\n",
      "The representation loss after processing this batch is:  0.004261333495378494\n",
      "\n",
      "The classification loss after processing this batch is:  0.5278807282447815\n",
      "The representation loss after processing this batch is:  0.004365108907222748\n",
      "\n",
      "The classification loss after processing this batch is:  0.49455082416534424\n",
      "The representation loss after processing this batch is:  0.0044181495904922485\n",
      "\n",
      "The classification loss after processing this batch is:  0.4570651948451996\n",
      "The representation loss after processing this batch is:  0.0043183788657188416\n",
      "\n",
      "The classification loss after processing this batch is:  0.3200368881225586\n",
      "The representation loss after processing this batch is:  0.004285525530576706\n",
      "\n",
      "The classification loss after processing this batch is:  0.36506226658821106\n",
      "The representation loss after processing this batch is:  0.004411488771438599\n",
      "\n",
      "The classification loss after processing this batch is:  0.3435843884944916\n",
      "The representation loss after processing this batch is:  0.004718504846096039\n",
      "\n",
      "The classification loss after processing this batch is:  0.34825706481933594\n",
      "The representation loss after processing this batch is:  0.0044076815247535706\n",
      "\n",
      "The classification loss after processing this batch is:  0.46148964762687683\n",
      "The representation loss after processing this batch is:  0.004382483661174774\n",
      "\n",
      "The classification loss after processing this batch is:  0.4164343774318695\n",
      "The representation loss after processing this batch is:  0.004069603979587555\n",
      "\n",
      "The classification loss after processing this batch is:  0.5300964117050171\n",
      "The representation loss after processing this batch is:  0.004783317446708679\n",
      "\n",
      "The classification loss after processing this batch is:  0.35038864612579346\n",
      "The representation loss after processing this batch is:  0.004099681973457336\n",
      "\n",
      "The classification loss after processing this batch is:  0.4028593897819519\n",
      "The representation loss after processing this batch is:  0.004152107983827591\n",
      "\n",
      "The classification loss after processing this batch is:  0.3860093951225281\n",
      "The representation loss after processing this batch is:  0.005153045058250427\n",
      "\n",
      "The classification loss after processing this batch is:  0.5064201951026917\n",
      "The representation loss after processing this batch is:  0.004313945770263672\n",
      "\n",
      "The classification loss after processing this batch is:  0.3280138671398163\n",
      "The representation loss after processing this batch is:  0.004865780472755432\n",
      "\n",
      "The classification loss after processing this batch is:  0.7976256608963013\n",
      "The representation loss after processing this batch is:  0.0048757195472717285\n",
      "\n",
      "The classification loss after processing this batch is:  0.616017758846283\n",
      "The representation loss after processing this batch is:  0.005182340741157532\n",
      "\n",
      "The classification loss after processing this batch is:  0.6087903380393982\n",
      "The representation loss after processing this batch is:  0.004426784813404083\n",
      "\n",
      "The classification loss after processing this batch is:  0.432157039642334\n",
      "The representation loss after processing this batch is:  0.004114992916584015\n",
      "\n",
      "The classification loss after processing this batch is:  0.3601146638393402\n",
      "The representation loss after processing this batch is:  0.004716634750366211\n",
      "\n",
      "The classification loss after processing this batch is:  0.4084762930870056\n",
      "The representation loss after processing this batch is:  0.004510954022407532\n",
      "\n",
      "The classification loss after processing this batch is:  0.421772301197052\n",
      "The representation loss after processing this batch is:  0.004592355340719223\n",
      "\n",
      "The classification loss after processing this batch is:  0.32640090584754944\n",
      "The representation loss after processing this batch is:  0.004542835056781769\n",
      "\n",
      "The classification loss after processing this batch is:  0.2849833071231842\n",
      "The representation loss after processing this batch is:  0.004130654036998749\n",
      "\n",
      "The classification loss after processing this batch is:  0.47063514590263367\n",
      "The representation loss after processing this batch is:  0.004479639232158661\n",
      "\n",
      "The classification loss after processing this batch is:  0.5385557413101196\n",
      "The representation loss after processing this batch is:  0.004413630813360214\n",
      "\n",
      "The classification loss after processing this batch is:  0.5245051383972168\n",
      "The representation loss after processing this batch is:  0.004625312983989716\n",
      "\n",
      "The classification loss after processing this batch is:  0.524993896484375\n",
      "The representation loss after processing this batch is:  0.004116490483283997\n",
      "\n",
      "The classification loss after processing this batch is:  0.6240174770355225\n",
      "The representation loss after processing this batch is:  0.0048845186829566956\n",
      "\n",
      "The classification loss after processing this batch is:  0.7293142080307007\n",
      "The representation loss after processing this batch is:  0.004461389034986496\n",
      "\n",
      "The classification loss after processing this batch is:  0.5729385614395142\n",
      "The representation loss after processing this batch is:  0.004166893661022186\n",
      "\n",
      "The classification loss after processing this batch is:  0.415115088224411\n",
      "The representation loss after processing this batch is:  0.0044026561081409454\n",
      "\n",
      "The classification loss after processing this batch is:  0.5002461075782776\n",
      "The representation loss after processing this batch is:  0.00480380654335022\n",
      "\n",
      "The classification loss after processing this batch is:  0.4375079572200775\n",
      "The representation loss after processing this batch is:  0.004514656960964203\n",
      "\n",
      "The classification loss after processing this batch is:  0.5159775018692017\n",
      "The representation loss after processing this batch is:  0.004197381436824799\n",
      "\n",
      "The classification loss after processing this batch is:  0.32658645510673523\n",
      "The representation loss after processing this batch is:  0.00479719415307045\n",
      "\n",
      "The classification loss after processing this batch is:  0.3390868902206421\n",
      "The representation loss after processing this batch is:  0.004458412528038025\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.30189862847328186\n",
      "The representation loss after processing this batch is:  0.004385992884635925\n",
      "\n",
      "The classification loss after processing this batch is:  0.4907871186733246\n",
      "The representation loss after processing this batch is:  0.0043974220752716064\n",
      "\n",
      "The classification loss after processing this batch is:  0.5641287565231323\n",
      "The representation loss after processing this batch is:  0.00400533527135849\n",
      "\n",
      "The classification loss after processing this batch is:  0.37708956003189087\n",
      "The representation loss after processing this batch is:  0.004844397306442261\n",
      "\n",
      "The classification loss after processing this batch is:  0.41585788130760193\n",
      "The representation loss after processing this batch is:  0.004225637763738632\n",
      "\n",
      "The classification loss after processing this batch is:  0.41849184036254883\n",
      "The representation loss after processing this batch is:  0.004434105008840561\n",
      "\n",
      "The classification loss after processing this batch is:  0.2556169927120209\n",
      "The representation loss after processing this batch is:  0.004314899444580078\n",
      "\n",
      "The classification loss after processing this batch is:  0.520847499370575\n",
      "The representation loss after processing this batch is:  0.004034847021102905\n",
      "\n",
      "The classification loss after processing this batch is:  0.412594735622406\n",
      "The representation loss after processing this batch is:  0.0045350342988967896\n",
      "\n",
      "The classification loss after processing this batch is:  0.4999784529209137\n",
      "The representation loss after processing this batch is:  0.0048770904541015625\n",
      "\n",
      "The classification loss after processing this batch is:  0.5434045195579529\n",
      "The representation loss after processing this batch is:  0.00457938015460968\n",
      "\n",
      "The classification loss after processing this batch is:  0.5467264652252197\n",
      "The representation loss after processing this batch is:  0.004231665283441544\n",
      "\n",
      "The classification loss after processing this batch is:  0.2636067271232605\n",
      "The representation loss after processing this batch is:  0.0046576038002967834\n",
      "\n",
      "The classification loss after processing this batch is:  0.31394556164741516\n",
      "The representation loss after processing this batch is:  0.005325570702552795\n",
      "\n",
      "The classification loss after processing this batch is:  0.39933398365974426\n",
      "The representation loss after processing this batch is:  0.004246499389410019\n",
      "\n",
      "The classification loss after processing this batch is:  0.30024364590644836\n",
      "The representation loss after processing this batch is:  0.004051759839057922\n",
      "\n",
      "The classification loss after processing this batch is:  0.4712825119495392\n",
      "The representation loss after processing this batch is:  0.005165018141269684\n",
      "\n",
      "The classification loss after processing this batch is:  0.3540698289871216\n",
      "The representation loss after processing this batch is:  0.004929360002279282\n",
      "\n",
      "The classification loss after processing this batch is:  0.4988209009170532\n",
      "The representation loss after processing this batch is:  0.004460576921701431\n",
      "\n",
      "The classification loss after processing this batch is:  0.5414577126502991\n",
      "The representation loss after processing this batch is:  0.004763573408126831\n",
      "\n",
      "The classification loss after processing this batch is:  0.35848861932754517\n",
      "The representation loss after processing this batch is:  0.004307180643081665\n",
      "\n",
      "The classification loss after processing this batch is:  0.3425634205341339\n",
      "The representation loss after processing this batch is:  0.004709571599960327\n",
      "\n",
      "The classification loss after processing this batch is:  0.44462820887565613\n",
      "The representation loss after processing this batch is:  0.004917412996292114\n",
      "\n",
      "The classification loss after processing this batch is:  0.4106237590312958\n",
      "The representation loss after processing this batch is:  0.005014538764953613\n",
      "\n",
      "The classification loss after processing this batch is:  0.5950687527656555\n",
      "The representation loss after processing this batch is:  0.005202259868383408\n",
      "\n",
      "The classification loss after processing this batch is:  0.6348647475242615\n",
      "The representation loss after processing this batch is:  0.005299918353557587\n",
      "\n",
      "The classification loss after processing this batch is:  0.6119137406349182\n",
      "The representation loss after processing this batch is:  0.004456423223018646\n",
      "\n",
      "The classification loss after processing this batch is:  0.3674195408821106\n",
      "The representation loss after processing this batch is:  0.004533924162387848\n",
      "\n",
      "The classification loss after processing this batch is:  0.3167822062969208\n",
      "The representation loss after processing this batch is:  0.004580497741699219\n",
      "\n",
      "The classification loss after processing this batch is:  0.3129054605960846\n",
      "The representation loss after processing this batch is:  0.004635989665985107\n",
      "\n",
      "The classification loss after processing this batch is:  0.3483528196811676\n",
      "The representation loss after processing this batch is:  0.004922002553939819\n",
      "\n",
      "The classification loss after processing this batch is:  0.4866253435611725\n",
      "The representation loss after processing this batch is:  0.004195049405097961\n",
      "\n",
      "The classification loss after processing this batch is:  0.391946017742157\n",
      "The representation loss after processing this batch is:  0.004934072494506836\n",
      "\n",
      "The classification loss after processing this batch is:  0.4424670338630676\n",
      "The representation loss after processing this batch is:  0.004933387041091919\n",
      "\n",
      "The classification loss after processing this batch is:  0.3687613308429718\n",
      "The representation loss after processing this batch is:  0.004221320152282715\n",
      "\n",
      "The classification loss after processing this batch is:  0.3892500698566437\n",
      "The representation loss after processing this batch is:  0.003985017538070679\n",
      "\n",
      "The classification loss after processing this batch is:  0.3894057273864746\n",
      "The representation loss after processing this batch is:  0.004230208694934845\n",
      "\n",
      "The classification loss after processing this batch is:  0.474612832069397\n",
      "The representation loss after processing this batch is:  0.004090368747711182\n",
      "\n",
      "The classification loss after processing this batch is:  0.44129353761672974\n",
      "The representation loss after processing this batch is:  0.0042309388518333435\n",
      "\n",
      "The classification loss after processing this batch is:  0.38245290517807007\n",
      "The representation loss after processing this batch is:  0.004394911229610443\n",
      "\n",
      "The classification loss after processing this batch is:  0.37949445843696594\n",
      "The representation loss after processing this batch is:  0.0042391493916511536\n",
      "\n",
      "The classification loss after processing this batch is:  0.45237061381340027\n",
      "The representation loss after processing this batch is:  0.0048043131828308105\n",
      "\n",
      "The classification loss after processing this batch is:  0.31178486347198486\n",
      "The representation loss after processing this batch is:  0.0045221298933029175\n",
      "\n",
      "The classification loss after processing this batch is:  0.3359202444553375\n",
      "The representation loss after processing this batch is:  0.0037472695112228394\n",
      "\n",
      "The classification loss after processing this batch is:  0.41812342405319214\n",
      "The representation loss after processing this batch is:  0.004635713994503021\n",
      "\n",
      "The classification loss after processing this batch is:  0.34648770093917847\n",
      "The representation loss after processing this batch is:  0.0043582916259765625\n",
      "\n",
      "The classification loss after processing this batch is:  0.4964338541030884\n",
      "The representation loss after processing this batch is:  0.0039202980697155\n",
      "\n",
      "The classification loss after processing this batch is:  0.43360260128974915\n",
      "The representation loss after processing this batch is:  0.00398755818605423\n",
      "\n",
      "The classification loss after processing this batch is:  0.444221168756485\n",
      "The representation loss after processing this batch is:  0.005897261202335358\n",
      "\n",
      "The classification loss after processing this batch is:  0.34801873564720154\n",
      "The representation loss after processing this batch is:  0.004853881895542145\n",
      "\n",
      "The classification loss after processing this batch is:  0.34568890929222107\n",
      "The representation loss after processing this batch is:  0.004615068435668945\n",
      "\n",
      "The classification loss after processing this batch is:  0.5519306063652039\n",
      "The representation loss after processing this batch is:  0.004733540117740631\n",
      "\n",
      "The classification loss after processing this batch is:  0.26521652936935425\n",
      "The representation loss after processing this batch is:  0.004985339939594269\n",
      "\n",
      "The classification loss after processing this batch is:  0.3664163649082184\n",
      "The representation loss after processing this batch is:  0.004553169012069702\n",
      "\n",
      "The classification loss after processing this batch is:  0.4227748513221741\n",
      "The representation loss after processing this batch is:  0.004029683768749237\n",
      "\n",
      "The classification loss after processing this batch is:  0.5445041656494141\n",
      "The representation loss after processing this batch is:  0.0045517198741436005\n",
      "\n",
      "The classification loss after processing this batch is:  0.3737587034702301\n",
      "The representation loss after processing this batch is:  0.004555419087409973\n",
      "\n",
      "The classification loss after processing this batch is:  0.4469781816005707\n",
      "The representation loss after processing this batch is:  0.003913354128599167\n",
      "\n",
      "The classification loss after processing this batch is:  0.35449355840682983\n",
      "The representation loss after processing this batch is:  0.0039650872349739075\n",
      "\n",
      "The classification loss after processing this batch is:  0.2858823239803314\n",
      "The representation loss after processing this batch is:  0.004176437854766846\n",
      "\n",
      "The classification loss after processing this batch is:  0.45863255858421326\n",
      "The representation loss after processing this batch is:  0.0045867785811424255\n",
      "\n",
      "The classification loss after processing this batch is:  0.38494011759757996\n",
      "The representation loss after processing this batch is:  0.005386918783187866\n",
      "\n",
      "The classification loss after processing this batch is:  0.27059516310691833\n",
      "The representation loss after processing this batch is:  0.004501424729824066\n",
      "\n",
      "The classification loss after processing this batch is:  0.4544915556907654\n",
      "The representation loss after processing this batch is:  0.004811033606529236\n",
      "\n",
      "The classification loss after processing this batch is:  0.5015707015991211\n",
      "The representation loss after processing this batch is:  0.004212077707052231\n",
      "\n",
      "The classification loss after processing this batch is:  0.5009597539901733\n",
      "The representation loss after processing this batch is:  0.0044023990631103516\n",
      "\n",
      "The classification loss after processing this batch is:  0.37164410948753357\n",
      "The representation loss after processing this batch is:  0.00405864417552948\n",
      "\n",
      "The classification loss after processing this batch is:  0.5063038468360901\n",
      "The representation loss after processing this batch is:  0.003989711403846741\n",
      "\n",
      "The classification loss after processing this batch is:  0.4981521666049957\n",
      "The representation loss after processing this batch is:  0.00421915203332901\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.4770078659057617\n",
      "The representation loss after processing this batch is:  0.0046501606702804565\n",
      "\n",
      "The classification loss after processing this batch is:  0.4739300310611725\n",
      "The representation loss after processing this batch is:  0.003887750208377838\n",
      "\n",
      "The classification loss after processing this batch is:  0.47684386372566223\n",
      "The representation loss after processing this batch is:  0.005018778145313263\n",
      "\n",
      "The classification loss after processing this batch is:  0.5883773565292358\n",
      "The representation loss after processing this batch is:  0.0039842501282691956\n",
      "\n",
      "The classification loss after processing this batch is:  0.3080628216266632\n",
      "The representation loss after processing this batch is:  0.004258677363395691\n",
      "\n",
      "The classification loss after processing this batch is:  0.29710838198661804\n",
      "The representation loss after processing this batch is:  0.004872433841228485\n",
      "\n",
      "The classification loss after processing this batch is:  0.3456224501132965\n",
      "The representation loss after processing this batch is:  0.003803163766860962\n",
      "\n",
      "The classification loss after processing this batch is:  0.3426534831523895\n",
      "The representation loss after processing this batch is:  0.0037264153361320496\n",
      "\n",
      "The classification loss after processing this batch is:  0.43729573488235474\n",
      "The representation loss after processing this batch is:  0.0042160190641880035\n",
      "\n",
      "The classification loss after processing this batch is:  0.3829697072505951\n",
      "The representation loss after processing this batch is:  0.004731126129627228\n",
      "\n",
      "The classification loss after processing this batch is:  0.2159097045660019\n",
      "The representation loss after processing this batch is:  0.004170812666416168\n",
      "\n",
      "The classification loss after processing this batch is:  0.22406145930290222\n",
      "The representation loss after processing this batch is:  0.004284173250198364\n",
      "\n",
      "The classification loss after processing this batch is:  0.32728078961372375\n",
      "The representation loss after processing this batch is:  0.004882931709289551\n",
      "\n",
      "The classification loss after processing this batch is:  0.42495840787887573\n",
      "The representation loss after processing this batch is:  0.005605459213256836\n",
      "\n",
      "The classification loss after processing this batch is:  0.3794119954109192\n",
      "The representation loss after processing this batch is:  0.004749305546283722\n",
      "\n",
      "The classification loss after processing this batch is:  0.28066742420196533\n",
      "The representation loss after processing this batch is:  0.004138223826885223\n",
      "\n",
      "The classification loss after processing this batch is:  0.3047618269920349\n",
      "The representation loss after processing this batch is:  0.0050084516406059265\n",
      "\n",
      "The classification loss after processing this batch is:  0.3659283220767975\n",
      "The representation loss after processing this batch is:  0.005252718925476074\n",
      "\n",
      "The classification loss after processing this batch is:  0.321017324924469\n",
      "The representation loss after processing this batch is:  0.005419299006462097\n",
      "\n",
      "The classification loss after processing this batch is:  0.23240773379802704\n",
      "The representation loss after processing this batch is:  0.005890563130378723\n",
      "\n",
      "The classification loss after processing this batch is:  0.31266313791275024\n",
      "The representation loss after processing this batch is:  0.0049922168254852295\n",
      "\n",
      "The classification loss after processing this batch is:  0.3407802879810333\n",
      "The representation loss after processing this batch is:  0.00503993034362793\n",
      "\n",
      "The classification loss after processing this batch is:  0.19995777308940887\n",
      "The representation loss after processing this batch is:  0.004943490028381348\n",
      "\n",
      "The classification loss after processing this batch is:  0.18261393904685974\n",
      "The representation loss after processing this batch is:  0.004269763827323914\n",
      "\n",
      "The classification loss after processing this batch is:  0.23743365705013275\n",
      "The representation loss after processing this batch is:  0.0049873217940330505\n",
      "\n",
      "The classification loss after processing this batch is:  0.26216697692871094\n",
      "The representation loss after processing this batch is:  0.004512079060077667\n",
      "\n",
      "The classification loss after processing this batch is:  0.1883714348077774\n",
      "The representation loss after processing this batch is:  0.00431988388299942\n",
      "\n",
      "The classification loss after processing this batch is:  0.2435186505317688\n",
      "The representation loss after processing this batch is:  0.005205005407333374\n",
      "\n",
      "The classification loss after processing this batch is:  0.2305172234773636\n",
      "The representation loss after processing this batch is:  0.005332879722118378\n",
      "\n",
      "The classification loss after processing this batch is:  0.5332719683647156\n",
      "The representation loss after processing this batch is:  0.005620434880256653\n",
      "\n",
      "The classification loss after processing this batch is:  0.5329435467720032\n",
      "The representation loss after processing this batch is:  0.0049737244844436646\n",
      "\n",
      "The classification loss after processing this batch is:  0.43719929456710815\n",
      "The representation loss after processing this batch is:  0.0059008002281188965\n",
      "\n",
      "The classification loss after processing this batch is:  0.2195572555065155\n",
      "The representation loss after processing this batch is:  0.0046869441866874695\n",
      "\n",
      "The classification loss after processing this batch is:  0.19506867229938507\n",
      "The representation loss after processing this batch is:  0.0051111578941345215\n",
      "\n",
      "The classification loss after processing this batch is:  0.2643415629863739\n",
      "The representation loss after processing this batch is:  0.00428018718957901\n",
      "\n",
      "The classification loss after processing this batch is:  0.30387407541275024\n",
      "The representation loss after processing this batch is:  0.004044026136398315\n",
      "\n",
      "The classification loss after processing this batch is:  0.5945096611976624\n",
      "The representation loss after processing this batch is:  0.004679925739765167\n",
      "\n",
      "The classification loss after processing this batch is:  0.3057606816291809\n",
      "The representation loss after processing this batch is:  0.003937572240829468\n",
      "\n",
      "The classification loss after processing this batch is:  0.1949940323829651\n",
      "The representation loss after processing this batch is:  0.0049803853034973145\n",
      "\n",
      "The classification loss after processing this batch is:  0.3090978264808655\n",
      "The representation loss after processing this batch is:  0.0045857056975364685\n",
      "\n",
      "The classification loss after processing this batch is:  0.25764545798301697\n",
      "The representation loss after processing this batch is:  0.005293101072311401\n",
      "\n",
      "The classification loss after processing this batch is:  0.3970543146133423\n",
      "The representation loss after processing this batch is:  0.003743179142475128\n",
      "\n",
      "The classification loss after processing this batch is:  0.23679786920547485\n",
      "The representation loss after processing this batch is:  0.004258982837200165\n",
      "\n",
      "The classification loss after processing this batch is:  0.3879311680793762\n",
      "The representation loss after processing this batch is:  0.0039497315883636475\n",
      "\n",
      "The classification loss after processing this batch is:  0.3274797201156616\n",
      "The representation loss after processing this batch is:  0.004737969487905502\n",
      "\n",
      "The classification loss after processing this batch is:  0.36011654138565063\n",
      "The representation loss after processing this batch is:  0.004277117550373077\n",
      "\n",
      "The classification loss after processing this batch is:  0.2694886326789856\n",
      "The representation loss after processing this batch is:  0.004453383386135101\n",
      "\n",
      "The classification loss after processing this batch is:  0.3653900921344757\n",
      "The representation loss after processing this batch is:  0.004994414746761322\n",
      "\n",
      "The classification loss after processing this batch is:  0.3436535894870758\n",
      "The representation loss after processing this batch is:  0.003919616341590881\n",
      "\n",
      "The classification loss after processing this batch is:  0.4441686272621155\n",
      "The representation loss after processing this batch is:  0.004130233079195023\n",
      "\n",
      "The classification loss after processing this batch is:  0.4304509460926056\n",
      "The representation loss after processing this batch is:  0.003946762531995773\n",
      "\n",
      "The classification loss after processing this batch is:  0.5531666278839111\n",
      "The representation loss after processing this batch is:  0.003558345139026642\n",
      "\n",
      "The classification loss after processing this batch is:  0.3660835027694702\n",
      "The representation loss after processing this batch is:  0.0037599317729473114\n",
      "\n",
      "The classification loss after processing this batch is:  0.44919222593307495\n",
      "The representation loss after processing this batch is:  0.004743050783872604\n",
      "\n",
      "The classification loss after processing this batch is:  0.3105579614639282\n",
      "The representation loss after processing this batch is:  0.004090301692485809\n",
      "\n",
      "The classification loss after processing this batch is:  0.6127352118492126\n",
      "The representation loss after processing this batch is:  0.0039614662528038025\n",
      "\n",
      "The classification loss after processing this batch is:  0.45858901739120483\n",
      "The representation loss after processing this batch is:  0.00363965705037117\n",
      "\n",
      "The classification loss after processing this batch is:  0.39934825897216797\n",
      "The representation loss after processing this batch is:  0.00391412153840065\n",
      "\n",
      "The classification loss after processing this batch is:  0.5144433379173279\n",
      "The representation loss after processing this batch is:  0.004620745778083801\n",
      "\n",
      "The classification loss after processing this batch is:  0.49628108739852905\n",
      "The representation loss after processing this batch is:  0.004492819309234619\n",
      "\n",
      "The classification loss after processing this batch is:  0.3217325210571289\n",
      "The representation loss after processing this batch is:  0.0044257789850234985\n",
      "\n",
      "The classification loss after processing this batch is:  0.522931694984436\n",
      "The representation loss after processing this batch is:  0.00466320663690567\n",
      "\n",
      "The classification loss after processing this batch is:  0.4887830317020416\n",
      "The representation loss after processing this batch is:  0.004629191011190414\n",
      "\n",
      "The classification loss after processing this batch is:  0.527948260307312\n",
      "The representation loss after processing this batch is:  0.0038340874016284943\n",
      "\n",
      "The classification loss after processing this batch is:  0.3444156348705292\n",
      "The representation loss after processing this batch is:  0.0035576634109020233\n",
      "\n",
      "The classification loss after processing this batch is:  0.29143625497817993\n",
      "The representation loss after processing this batch is:  0.004204615950584412\n",
      "\n",
      "The classification loss after processing this batch is:  0.34293505549430847\n",
      "The representation loss after processing this batch is:  0.0039106011390686035\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.46029990911483765\n",
      "The representation loss after processing this batch is:  0.0038757584989070892\n",
      "\n",
      "The classification loss after processing this batch is:  0.29214149713516235\n",
      "The representation loss after processing this batch is:  0.004210062325000763\n",
      "\n",
      "The classification loss after processing this batch is:  0.2137208878993988\n",
      "The representation loss after processing this batch is:  0.004400670528411865\n",
      "\n",
      "The classification loss after processing this batch is:  0.23692293465137482\n",
      "The representation loss after processing this batch is:  0.004225939512252808\n",
      "\n",
      "The classification loss after processing this batch is:  0.31117621064186096\n",
      "The representation loss after processing this batch is:  0.004312843084335327\n",
      "\n",
      "The classification loss after processing this batch is:  0.33077970147132874\n",
      "The representation loss after processing this batch is:  0.0046043843030929565\n",
      "\n",
      "The classification loss after processing this batch is:  0.4159816801548004\n",
      "The representation loss after processing this batch is:  0.00451994314789772\n",
      "\n",
      "The classification loss after processing this batch is:  0.377347469329834\n",
      "The representation loss after processing this batch is:  0.00460805743932724\n",
      "\n",
      "The classification loss after processing this batch is:  0.30884069204330444\n",
      "The representation loss after processing this batch is:  0.004225514829158783\n",
      "\n",
      "The classification loss after processing this batch is:  0.2377150058746338\n",
      "The representation loss after processing this batch is:  0.004107668995857239\n",
      "\n",
      "The classification loss after processing this batch is:  0.34387585520744324\n",
      "The representation loss after processing this batch is:  0.004194516688585281\n",
      "\n",
      "The classification loss after processing this batch is:  0.3326466679573059\n",
      "The representation loss after processing this batch is:  0.004202328622341156\n",
      "\n",
      "The classification loss after processing this batch is:  0.2443070113658905\n",
      "The representation loss after processing this batch is:  0.004291132092475891\n",
      "\n",
      "The classification loss after processing this batch is:  0.353640079498291\n",
      "The representation loss after processing this batch is:  0.004713967442512512\n",
      "\n",
      "The classification loss after processing this batch is:  0.5579646825790405\n",
      "The representation loss after processing this batch is:  0.00481472909450531\n",
      "\n",
      "The classification loss after processing this batch is:  0.3573547303676605\n",
      "The representation loss after processing this batch is:  0.004277855157852173\n",
      "\n",
      "The classification loss after processing this batch is:  0.3816796541213989\n",
      "The representation loss after processing this batch is:  0.0036749616265296936\n",
      "\n",
      "The classification loss after processing this batch is:  0.31698963046073914\n",
      "The representation loss after processing this batch is:  0.004246577620506287\n",
      "\n",
      "The classification loss after processing this batch is:  0.29590556025505066\n",
      "The representation loss after processing this batch is:  0.0038655586540699005\n",
      "\n",
      "The classification loss after processing this batch is:  0.34260714054107666\n",
      "The representation loss after processing this batch is:  0.003590792417526245\n",
      "\n",
      "The classification loss after processing this batch is:  0.42798376083374023\n",
      "The representation loss after processing this batch is:  0.004226215183734894\n",
      "\n",
      "The classification loss after processing this batch is:  0.2754204571247101\n",
      "The representation loss after processing this batch is:  0.004145719110965729\n",
      "\n",
      "The classification loss after processing this batch is:  0.33826372027397156\n",
      "The representation loss after processing this batch is:  0.004008196294307709\n",
      "\n",
      "The classification loss after processing this batch is:  0.34749290347099304\n",
      "The representation loss after processing this batch is:  0.004346765577793121\n",
      "\n",
      "The classification loss after processing this batch is:  0.42339152097702026\n",
      "The representation loss after processing this batch is:  0.003857135772705078\n",
      "\n",
      "The classification loss after processing this batch is:  0.4076921045780182\n",
      "The representation loss after processing this batch is:  0.004250943660736084\n",
      "\n",
      "The classification loss after processing this batch is:  0.33097681403160095\n",
      "The representation loss after processing this batch is:  0.004136059433221817\n",
      "\n",
      "The classification loss after processing this batch is:  0.30045250058174133\n",
      "The representation loss after processing this batch is:  0.004412032663822174\n",
      "\n",
      "The classification loss after processing this batch is:  0.3919396698474884\n",
      "The representation loss after processing this batch is:  0.004259228706359863\n",
      "\n",
      "The classification loss after processing this batch is:  0.375627338886261\n",
      "The representation loss after processing this batch is:  0.003899138420820236\n",
      "\n",
      "The classification loss after processing this batch is:  0.4356459975242615\n",
      "The representation loss after processing this batch is:  0.0037716850638389587\n",
      "\n",
      "The classification loss after processing this batch is:  0.3229183256626129\n",
      "The representation loss after processing this batch is:  0.005005046725273132\n",
      "\n",
      "The classification loss after processing this batch is:  0.46482887864112854\n",
      "The representation loss after processing this batch is:  0.004143409430980682\n",
      "\n",
      "The classification loss after processing this batch is:  0.2752526104450226\n",
      "The representation loss after processing this batch is:  0.0037452951073646545\n",
      "\n",
      "The classification loss after processing this batch is:  0.2641981542110443\n",
      "The representation loss after processing this batch is:  0.004191473126411438\n",
      "\n",
      "The classification loss after processing this batch is:  0.3525012731552124\n",
      "The representation loss after processing this batch is:  0.003833543509244919\n",
      "\n",
      "The classification loss after processing this batch is:  0.3852868378162384\n",
      "The representation loss after processing this batch is:  0.004054836928844452\n",
      "\n",
      "The classification loss after processing this batch is:  0.3333267271518707\n",
      "The representation loss after processing this batch is:  0.003964599221944809\n",
      "\n",
      "The classification loss after processing this batch is:  0.3327242136001587\n",
      "The representation loss after processing this batch is:  0.004428304731845856\n",
      "\n",
      "The classification loss after processing this batch is:  0.3099461793899536\n",
      "The representation loss after processing this batch is:  0.004667755216360092\n",
      "\n",
      "The classification loss after processing this batch is:  0.4711315929889679\n",
      "The representation loss after processing this batch is:  0.005084998905658722\n",
      "\n",
      "The classification loss after processing this batch is:  0.35396507382392883\n",
      "The representation loss after processing this batch is:  0.003923282027244568\n",
      "\n",
      "The classification loss after processing this batch is:  0.260843962430954\n",
      "The representation loss after processing this batch is:  0.0041732341051101685\n",
      "\n",
      "The classification loss after processing this batch is:  0.49153316020965576\n",
      "The representation loss after processing this batch is:  0.003970719873905182\n",
      "\n",
      "The classification loss after processing this batch is:  0.3505053222179413\n",
      "The representation loss after processing this batch is:  0.0037899017333984375\n",
      "\n",
      "The classification loss after processing this batch is:  0.4241707921028137\n",
      "The representation loss after processing this batch is:  0.00452578067779541\n",
      "\n",
      "The classification loss after processing this batch is:  0.37972337007522583\n",
      "The representation loss after processing this batch is:  0.0034553296864032745\n",
      "\n",
      "The classification loss after processing this batch is:  0.3197275698184967\n",
      "The representation loss after processing this batch is:  0.003979392349720001\n",
      "\n",
      "The classification loss after processing this batch is:  0.35493627190589905\n",
      "The representation loss after processing this batch is:  0.0038548558950424194\n",
      "\n",
      "The classification loss after processing this batch is:  0.3248719871044159\n",
      "The representation loss after processing this batch is:  0.00359499454498291\n",
      "\n",
      "The classification loss after processing this batch is:  0.2963128387928009\n",
      "The representation loss after processing this batch is:  0.003182109445333481\n",
      "\n",
      "The classification loss after processing this batch is:  0.5146108865737915\n",
      "The representation loss after processing this batch is:  0.0035943500697612762\n",
      "\n",
      "The classification loss after processing this batch is:  0.3661150634288788\n",
      "The representation loss after processing this batch is:  0.0036842897534370422\n",
      "\n",
      "The classification loss after processing this batch is:  0.2980251908302307\n",
      "The representation loss after processing this batch is:  0.004554674029350281\n",
      "\n",
      "The classification loss after processing this batch is:  0.41858941316604614\n",
      "The representation loss after processing this batch is:  0.004027694463729858\n",
      "\n",
      "The classification loss after processing this batch is:  0.3601550757884979\n",
      "The representation loss after processing this batch is:  0.004261046648025513\n",
      "\n",
      "The classification loss after processing this batch is:  0.4623795747756958\n",
      "The representation loss after processing this batch is:  0.004329860210418701\n",
      "\n",
      "The classification loss after processing this batch is:  0.3814998269081116\n",
      "The representation loss after processing this batch is:  0.004234232008457184\n",
      "\n",
      "The classification loss after processing this batch is:  0.39197054505348206\n",
      "The representation loss after processing this batch is:  0.0039215609431266785\n",
      "\n",
      "The classification loss after processing this batch is:  0.6090863347053528\n",
      "The representation loss after processing this batch is:  0.004202641546726227\n",
      "\n",
      "The classification loss after processing this batch is:  0.3977777361869812\n",
      "The representation loss after processing this batch is:  0.0036994926631450653\n",
      "\n",
      "The classification loss after processing this batch is:  0.31013190746307373\n",
      "The representation loss after processing this batch is:  0.004022635519504547\n",
      "\n",
      "The classification loss after processing this batch is:  0.42349541187286377\n",
      "The representation loss after processing this batch is:  0.003825221210718155\n",
      "\n",
      "The classification loss after processing this batch is:  0.3778514862060547\n",
      "The representation loss after processing this batch is:  0.00411500409245491\n",
      "\n",
      "The classification loss after processing this batch is:  0.3573252558708191\n",
      "The representation loss after processing this batch is:  0.004332989454269409\n",
      "\n",
      "The classification loss after processing this batch is:  0.27240628004074097\n",
      "The representation loss after processing this batch is:  0.004030466079711914\n",
      "\n",
      "The classification loss after processing this batch is:  0.40668097138404846\n",
      "The representation loss after processing this batch is:  0.003909759223461151\n",
      "\n",
      "The classification loss after processing this batch is:  0.414002925157547\n",
      "The representation loss after processing this batch is:  0.0038987919688224792\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.3669317066669464\n",
      "The representation loss after processing this batch is:  0.004551917314529419\n",
      "\n",
      "The classification loss after processing this batch is:  0.4431600272655487\n",
      "The representation loss after processing this batch is:  0.003926798701286316\n",
      "\n",
      "The classification loss after processing this batch is:  0.41931289434432983\n",
      "The representation loss after processing this batch is:  0.004297934472560883\n",
      "\n",
      "The classification loss after processing this batch is:  0.4953157305717468\n",
      "The representation loss after processing this batch is:  0.00453900545835495\n",
      "\n",
      "The classification loss after processing this batch is:  0.3701424300670624\n",
      "The representation loss after processing this batch is:  0.004469573497772217\n",
      "\n",
      "The classification loss after processing this batch is:  0.2892797589302063\n",
      "The representation loss after processing this batch is:  0.0039038509130477905\n",
      "\n",
      "The classification loss after processing this batch is:  0.2373691201210022\n",
      "The representation loss after processing this batch is:  0.003926485776901245\n",
      "\n",
      "The classification loss after processing this batch is:  0.31623026728630066\n",
      "The representation loss after processing this batch is:  0.003552265465259552\n",
      "\n",
      "The classification loss after processing this batch is:  0.2985309958457947\n",
      "The representation loss after processing this batch is:  0.0036933645606040955\n",
      "\n",
      "The classification loss after processing this batch is:  0.43551814556121826\n",
      "The representation loss after processing this batch is:  0.004108019173145294\n",
      "\n",
      "The classification loss after processing this batch is:  0.5397690534591675\n",
      "The representation loss after processing this batch is:  0.0043353065848350525\n",
      "\n",
      "The classification loss after processing this batch is:  0.3489263355731964\n",
      "The representation loss after processing this batch is:  0.00434768944978714\n",
      "\n",
      "The classification loss after processing this batch is:  0.3259983956813812\n",
      "The representation loss after processing this batch is:  0.004281662404537201\n",
      "\n",
      "The classification loss after processing this batch is:  0.35354211926460266\n",
      "The representation loss after processing this batch is:  0.003455299884080887\n",
      "\n",
      "The classification loss after processing this batch is:  0.25576093792915344\n",
      "The representation loss after processing this batch is:  0.004374116659164429\n",
      "\n",
      "The classification loss after processing this batch is:  0.23017382621765137\n",
      "The representation loss after processing this batch is:  0.003769978880882263\n",
      "\n",
      "The classification loss after processing this batch is:  0.36367350816726685\n",
      "The representation loss after processing this batch is:  0.0037764087319374084\n",
      "\n",
      "The classification loss after processing this batch is:  0.3385997414588928\n",
      "The representation loss after processing this batch is:  0.005291149020195007\n",
      "\n",
      "The classification loss after processing this batch is:  0.2516527771949768\n",
      "The representation loss after processing this batch is:  0.004430755972862244\n",
      "\n",
      "The classification loss after processing this batch is:  0.5287500619888306\n",
      "The representation loss after processing this batch is:  0.005256786942481995\n",
      "\n",
      "The classification loss after processing this batch is:  0.45170772075653076\n",
      "The representation loss after processing this batch is:  0.004129413515329361\n",
      "\n",
      "The classification loss after processing this batch is:  0.5221707224845886\n",
      "The representation loss after processing this batch is:  0.0041566044092178345\n",
      "\n",
      "The classification loss after processing this batch is:  0.473632276058197\n",
      "The representation loss after processing this batch is:  0.0037766993045806885\n",
      "\n",
      "The classification loss after processing this batch is:  0.3871231973171234\n",
      "The representation loss after processing this batch is:  0.0036449506878852844\n",
      "\n",
      "The classification loss after processing this batch is:  0.2547836899757385\n",
      "The representation loss after processing this batch is:  0.004474256187677383\n",
      "\n",
      "The classification loss after processing this batch is:  0.43748146295547485\n",
      "The representation loss after processing this batch is:  0.003572605550289154\n",
      "\n",
      "The classification loss after processing this batch is:  0.683435320854187\n",
      "The representation loss after processing this batch is:  0.006127245724201202\n",
      "\n",
      "The classification loss after processing this batch is:  0.4838464856147766\n",
      "The representation loss after processing this batch is:  0.004568621516227722\n",
      "\n",
      "The classification loss after processing this batch is:  0.3388976752758026\n",
      "The representation loss after processing this batch is:  0.0044012293219566345\n",
      "\n",
      "The classification loss after processing this batch is:  0.3491472005844116\n",
      "The representation loss after processing this batch is:  0.003845810890197754\n",
      "\n",
      "The classification loss after processing this batch is:  0.3335658311843872\n",
      "The representation loss after processing this batch is:  0.004117779433727264\n",
      "\n",
      "The classification loss after processing this batch is:  0.39505335688591003\n",
      "The representation loss after processing this batch is:  0.004022784531116486\n",
      "\n",
      "The classification loss after processing this batch is:  0.2616351842880249\n",
      "The representation loss after processing this batch is:  0.0038150176405906677\n",
      "\n",
      "The classification loss after processing this batch is:  0.41133883595466614\n",
      "The representation loss after processing this batch is:  0.003900177776813507\n",
      "\n",
      "The classification loss after processing this batch is:  0.3333132863044739\n",
      "The representation loss after processing this batch is:  0.004046127200126648\n",
      "\n",
      "The classification loss after processing this batch is:  0.48867014050483704\n",
      "The representation loss after processing this batch is:  0.0043010413646698\n",
      "\n",
      "The classification loss after processing this batch is:  0.33028703927993774\n",
      "The representation loss after processing this batch is:  0.00373946875333786\n",
      "\n",
      "The classification loss after processing this batch is:  0.4117722809314728\n",
      "The representation loss after processing this batch is:  0.003520522266626358\n",
      "\n",
      "The classification loss after processing this batch is:  0.35148125886917114\n",
      "The representation loss after processing this batch is:  0.003941111266613007\n",
      "\n",
      "The classification loss after processing this batch is:  0.4239756166934967\n",
      "The representation loss after processing this batch is:  0.004362024366855621\n",
      "\n",
      "The classification loss after processing this batch is:  0.2939358651638031\n",
      "The representation loss after processing this batch is:  0.003572724759578705\n",
      "\n",
      "The classification loss after processing this batch is:  0.45004597306251526\n",
      "The representation loss after processing this batch is:  0.0035247281193733215\n",
      "\n",
      "The classification loss after processing this batch is:  0.4699738323688507\n",
      "The representation loss after processing this batch is:  0.0037966519594192505\n",
      "\n",
      "The classification loss after processing this batch is:  0.3891599774360657\n",
      "The representation loss after processing this batch is:  0.0035868845880031586\n",
      "\n",
      "The classification loss after processing this batch is:  0.38949960470199585\n",
      "The representation loss after processing this batch is:  0.00374477356672287\n",
      "\n",
      "The classification loss after processing this batch is:  0.3461621105670929\n",
      "The representation loss after processing this batch is:  0.004410266876220703\n",
      "\n",
      "The classification loss after processing this batch is:  0.4589296281337738\n",
      "The representation loss after processing this batch is:  0.0037681348621845245\n",
      "\n",
      "The classification loss after processing this batch is:  0.4510723054409027\n",
      "The representation loss after processing this batch is:  0.0044444650411605835\n",
      "\n",
      "The classification loss after processing this batch is:  0.30305835604667664\n",
      "The representation loss after processing this batch is:  0.004406459629535675\n",
      "\n",
      "The classification loss after processing this batch is:  0.3431647717952728\n",
      "The representation loss after processing this batch is:  0.004053249955177307\n",
      "\n",
      "The classification loss after processing this batch is:  0.577800989151001\n",
      "The representation loss after processing this batch is:  0.00453268364071846\n",
      "\n",
      "The classification loss after processing this batch is:  0.49035581946372986\n",
      "The representation loss after processing this batch is:  0.0038709938526153564\n",
      "\n",
      "The classification loss after processing this batch is:  0.5206777453422546\n",
      "The representation loss after processing this batch is:  0.0041042231023311615\n",
      "\n",
      "The classification loss after processing this batch is:  0.6140695810317993\n",
      "The representation loss after processing this batch is:  0.00393185019493103\n",
      "\n",
      "The classification loss after processing this batch is:  0.48372429609298706\n",
      "The representation loss after processing this batch is:  0.0036091431975364685\n",
      "\n",
      "The classification loss after processing this batch is:  0.28467556834220886\n",
      "The representation loss after processing this batch is:  0.0037852972745895386\n",
      "\n",
      "The classification loss after processing this batch is:  0.2848891019821167\n",
      "The representation loss after processing this batch is:  0.0041695237159729\n",
      "\n",
      "The classification loss after processing this batch is:  0.25986629724502563\n",
      "The representation loss after processing this batch is:  0.004878543317317963\n",
      "\n",
      "The classification loss after processing this batch is:  0.34616929292678833\n",
      "The representation loss after processing this batch is:  0.005526788532733917\n",
      "\n",
      "The classification loss after processing this batch is:  0.2252574861049652\n",
      "The representation loss after processing this batch is:  0.0040455833077430725\n",
      "\n",
      "The classification loss after processing this batch is:  0.46372756361961365\n",
      "The representation loss after processing this batch is:  0.004949383437633514\n",
      "\n",
      "The classification loss after processing this batch is:  0.28047800064086914\n",
      "The representation loss after processing this batch is:  0.004077445715665817\n",
      "\n",
      "The classification loss after processing this batch is:  0.2796976864337921\n",
      "The representation loss after processing this batch is:  0.00409325584769249\n",
      "\n",
      "The classification loss after processing this batch is:  0.4216330647468567\n",
      "The representation loss after processing this batch is:  0.0032548531889915466\n",
      "\n",
      "The classification loss after processing this batch is:  0.3267945647239685\n",
      "The representation loss after processing this batch is:  0.003993779420852661\n",
      "\n",
      "The classification loss after processing this batch is:  0.44786790013313293\n",
      "The representation loss after processing this batch is:  0.0042527541518211365\n",
      "\n",
      "The classification loss after processing this batch is:  0.4132794141769409\n",
      "The representation loss after processing this batch is:  0.005270190536975861\n",
      "\n",
      "The classification loss after processing this batch is:  0.3007349371910095\n",
      "The representation loss after processing this batch is:  0.004219271242618561\n",
      "\n",
      "The classification loss after processing this batch is:  0.3344656527042389\n",
      "The representation loss after processing this batch is:  0.0033475644886493683\n",
      "\n",
      "The classification loss after processing this batch is:  0.30853208899497986\n",
      "The representation loss after processing this batch is:  0.003778398036956787\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2600002884864807\n",
      "The representation loss after processing this batch is:  0.0038065239787101746\n",
      "\n",
      "The classification loss after processing this batch is:  0.24319304525852203\n",
      "The representation loss after processing this batch is:  0.004098080098628998\n",
      "\n",
      "The classification loss after processing this batch is:  0.2645944654941559\n",
      "The representation loss after processing this batch is:  0.004151895642280579\n",
      "\n",
      "The classification loss after processing this batch is:  0.32883819937705994\n",
      "The representation loss after processing this batch is:  0.0032464303076267242\n",
      "\n",
      "The classification loss after processing this batch is:  0.31048959493637085\n",
      "The representation loss after processing this batch is:  0.0036386623978614807\n",
      "\n",
      "The classification loss after processing this batch is:  0.4019225537776947\n",
      "The representation loss after processing this batch is:  0.003984697163105011\n",
      "\n",
      "The classification loss after processing this batch is:  0.5864439010620117\n",
      "The representation loss after processing this batch is:  0.004160098731517792\n",
      "\n",
      "The classification loss after processing this batch is:  0.49177825450897217\n",
      "The representation loss after processing this batch is:  0.004424981772899628\n",
      "\n",
      "The classification loss after processing this batch is:  0.21576595306396484\n",
      "The representation loss after processing this batch is:  0.00345446914434433\n",
      "\n",
      "The classification loss after processing this batch is:  0.30783984065055847\n",
      "The representation loss after processing this batch is:  0.004153218120336533\n",
      "\n",
      "The classification loss after processing this batch is:  0.33381447196006775\n",
      "The representation loss after processing this batch is:  0.0035833120346069336\n",
      "\n",
      "The classification loss after processing this batch is:  0.29496097564697266\n",
      "The representation loss after processing this batch is:  0.003819771111011505\n",
      "\n",
      "The classification loss after processing this batch is:  0.24850203096866608\n",
      "The representation loss after processing this batch is:  0.0040511563420295715\n",
      "\n",
      "The classification loss after processing this batch is:  0.2970375120639801\n",
      "The representation loss after processing this batch is:  0.004731960594654083\n",
      "\n",
      "The classification loss after processing this batch is:  0.3543301820755005\n",
      "The representation loss after processing this batch is:  0.0037643983960151672\n",
      "\n",
      "The classification loss after processing this batch is:  0.4509337246417999\n",
      "The representation loss after processing this batch is:  0.004213158041238785\n",
      "\n",
      "The classification loss after processing this batch is:  0.20740245282649994\n",
      "The representation loss after processing this batch is:  0.0045180246233940125\n",
      "\n",
      "The classification loss after processing this batch is:  0.2531033456325531\n",
      "The representation loss after processing this batch is:  0.003481931984424591\n",
      "\n",
      "The classification loss after processing this batch is:  0.2516760528087616\n",
      "The representation loss after processing this batch is:  0.003734886646270752\n",
      "\n",
      "The classification loss after processing this batch is:  0.37355944514274597\n",
      "The representation loss after processing this batch is:  0.0042022354900836945\n",
      "\n",
      "The classification loss after processing this batch is:  0.2658325731754303\n",
      "The representation loss after processing this batch is:  0.0038546323776245117\n",
      "\n",
      "The classification loss after processing this batch is:  0.21999423205852509\n",
      "The representation loss after processing this batch is:  0.004473671317100525\n",
      "\n",
      "The classification loss after processing this batch is:  0.47936776280403137\n",
      "The representation loss after processing this batch is:  0.004200682044029236\n",
      "\n",
      "The classification loss after processing this batch is:  0.3201899230480194\n",
      "The representation loss after processing this batch is:  0.003748565912246704\n",
      "\n",
      "The classification loss after processing this batch is:  0.26974165439605713\n",
      "The representation loss after processing this batch is:  0.003719240427017212\n",
      "\n",
      "The classification loss after processing this batch is:  0.37679216265678406\n",
      "The representation loss after processing this batch is:  0.003889620304107666\n",
      "\n",
      "The classification loss after processing this batch is:  0.2705962061882019\n",
      "The representation loss after processing this batch is:  0.0035256966948509216\n",
      "\n",
      "The classification loss after processing this batch is:  0.3285864591598511\n",
      "The representation loss after processing this batch is:  0.003595784306526184\n",
      "\n",
      "The classification loss after processing this batch is:  0.40994420647621155\n",
      "The representation loss after processing this batch is:  0.003724910318851471\n",
      "\n",
      "The classification loss after processing this batch is:  0.44103100895881653\n",
      "The representation loss after processing this batch is:  0.00419529527425766\n",
      "\n",
      "The classification loss after processing this batch is:  0.3532520830631256\n",
      "The representation loss after processing this batch is:  0.003904968500137329\n",
      "\n",
      "The classification loss after processing this batch is:  0.47867709398269653\n",
      "The representation loss after processing this batch is:  0.003770887851715088\n",
      "\n",
      "The classification loss after processing this batch is:  0.3310643434524536\n",
      "The representation loss after processing this batch is:  0.0043302737176418304\n",
      "\n",
      "The classification loss after processing this batch is:  0.3560117781162262\n",
      "The representation loss after processing this batch is:  0.0039848387241363525\n",
      "\n",
      "The classification loss after processing this batch is:  0.3184296786785126\n",
      "The representation loss after processing this batch is:  0.004440248012542725\n",
      "\n",
      "The classification loss after processing this batch is:  0.3914773762226105\n",
      "The representation loss after processing this batch is:  0.0042038485407829285\n",
      "\n",
      "The classification loss after processing this batch is:  0.30161046981811523\n",
      "The representation loss after processing this batch is:  0.00389987975358963\n",
      "\n",
      "The classification loss after processing this batch is:  0.34599319100379944\n",
      "The representation loss after processing this batch is:  0.0036949068307876587\n",
      "\n",
      "The classification loss after processing this batch is:  0.2944644093513489\n",
      "The representation loss after processing this batch is:  0.003940194845199585\n",
      "\n",
      "The classification loss after processing this batch is:  0.40441563725471497\n",
      "The representation loss after processing this batch is:  0.003920648247003555\n",
      "\n",
      "The classification loss after processing this batch is:  0.31853237748146057\n",
      "The representation loss after processing this batch is:  0.0031755976378917694\n",
      "\n",
      "The classification loss after processing this batch is:  0.40042972564697266\n",
      "The representation loss after processing this batch is:  0.0039502158761024475\n",
      "\n",
      "The classification loss after processing this batch is:  0.3821144104003906\n",
      "The representation loss after processing this batch is:  0.0034811198711395264\n",
      "\n",
      "The classification loss after processing this batch is:  0.4227679371833801\n",
      "The representation loss after processing this batch is:  0.0038805827498435974\n",
      "\n",
      "The classification loss after processing this batch is:  0.4587678015232086\n",
      "The representation loss after processing this batch is:  0.0037424303591251373\n",
      "\n",
      "The classification loss after processing this batch is:  0.49058112502098083\n",
      "The representation loss after processing this batch is:  0.003596622496843338\n",
      "\n",
      "The classification loss after processing this batch is:  0.5786805748939514\n",
      "The representation loss after processing this batch is:  0.003840167075395584\n",
      "\n",
      "The classification loss after processing this batch is:  0.4730391204357147\n",
      "The representation loss after processing this batch is:  0.0031812451779842377\n",
      "\n",
      "The classification loss after processing this batch is:  0.2950572967529297\n",
      "The representation loss after processing this batch is:  0.003991890698671341\n",
      "\n",
      "The classification loss after processing this batch is:  0.343288391828537\n",
      "The representation loss after processing this batch is:  0.00356462225317955\n",
      "\n",
      "The classification loss after processing this batch is:  0.24604883790016174\n",
      "The representation loss after processing this batch is:  0.003961622714996338\n",
      "\n",
      "The classification loss after processing this batch is:  0.42828789353370667\n",
      "The representation loss after processing this batch is:  0.004209216684103012\n",
      "\n",
      "The classification loss after processing this batch is:  0.4568996727466583\n",
      "The representation loss after processing this batch is:  0.004318602383136749\n",
      "\n",
      "The classification loss after processing this batch is:  0.57218337059021\n",
      "The representation loss after processing this batch is:  0.0037534087896347046\n",
      "\n",
      "The classification loss after processing this batch is:  0.5476124286651611\n",
      "The representation loss after processing this batch is:  0.003381788730621338\n",
      "\n",
      "The classification loss after processing this batch is:  0.4434158504009247\n",
      "The representation loss after processing this batch is:  0.003819197416305542\n",
      "\n",
      "The classification loss after processing this batch is:  0.250826895236969\n",
      "The representation loss after processing this batch is:  0.0037000030279159546\n",
      "\n",
      "The classification loss after processing this batch is:  0.2851145565509796\n",
      "The representation loss after processing this batch is:  0.004115886986255646\n",
      "\n",
      "The classification loss after processing this batch is:  0.42465755343437195\n",
      "The representation loss after processing this batch is:  0.003267597407102585\n",
      "\n",
      "The classification loss after processing this batch is:  0.27000749111175537\n",
      "The representation loss after processing this batch is:  0.0036956146359443665\n",
      "\n",
      "The classification loss after processing this batch is:  0.24538736045360565\n",
      "The representation loss after processing this batch is:  0.0034076422452926636\n",
      "\n",
      "The classification loss after processing this batch is:  0.26899394392967224\n",
      "The representation loss after processing this batch is:  0.0036602914333343506\n",
      "\n",
      "The classification loss after processing this batch is:  0.19419178366661072\n",
      "The representation loss after processing this batch is:  0.003910273313522339\n",
      "\n",
      "The classification loss after processing this batch is:  0.37130454182624817\n",
      "The representation loss after processing this batch is:  0.004133928567171097\n",
      "\n",
      "The classification loss after processing this batch is:  0.3094179928302765\n",
      "The representation loss after processing this batch is:  0.004116028547286987\n",
      "\n",
      "The classification loss after processing this batch is:  0.41240233182907104\n",
      "The representation loss after processing this batch is:  0.0038893669843673706\n",
      "\n",
      "The classification loss after processing this batch is:  0.35510388016700745\n",
      "The representation loss after processing this batch is:  0.0038683079183101654\n",
      "\n",
      "The classification loss after processing this batch is:  0.3322862386703491\n",
      "The representation loss after processing this batch is:  0.004179365932941437\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.40256011486053467\n",
      "The representation loss after processing this batch is:  0.004064679145812988\n",
      "\n",
      "The classification loss after processing this batch is:  0.3225983679294586\n",
      "The representation loss after processing this batch is:  0.0040778107941150665\n",
      "\n",
      "The classification loss after processing this batch is:  0.31473883986473083\n",
      "The representation loss after processing this batch is:  0.0038511157035827637\n",
      "\n",
      "The classification loss after processing this batch is:  0.3553171753883362\n",
      "The representation loss after processing this batch is:  0.004259571433067322\n",
      "\n",
      "The classification loss after processing this batch is:  0.3763912618160248\n",
      "The representation loss after processing this batch is:  0.00420127809047699\n",
      "\n",
      "The classification loss after processing this batch is:  0.33497557044029236\n",
      "The representation loss after processing this batch is:  0.0037411265075206757\n",
      "\n",
      "The classification loss after processing this batch is:  0.4525720775127411\n",
      "The representation loss after processing this batch is:  0.0034629441797733307\n",
      "\n",
      "The classification loss after processing this batch is:  0.5153713822364807\n",
      "The representation loss after processing this batch is:  0.00414566695690155\n",
      "\n",
      "The classification loss after processing this batch is:  0.23662643134593964\n",
      "The representation loss after processing this batch is:  0.0036922916769981384\n",
      "\n",
      "The classification loss after processing this batch is:  0.3313961625099182\n",
      "The representation loss after processing this batch is:  0.0037074722349643707\n",
      "\n",
      "The classification loss after processing this batch is:  0.39264610409736633\n",
      "The representation loss after processing this batch is:  0.00441177561879158\n",
      "\n",
      "The classification loss after processing this batch is:  0.43121373653411865\n",
      "The representation loss after processing this batch is:  0.004081077873706818\n",
      "\n",
      "The classification loss after processing this batch is:  0.5018728971481323\n",
      "The representation loss after processing this batch is:  0.005015425384044647\n",
      "\n",
      "The classification loss after processing this batch is:  0.4403308928012848\n",
      "The representation loss after processing this batch is:  0.004577971994876862\n",
      "\n",
      "The classification loss after processing this batch is:  0.4999605715274811\n",
      "The representation loss after processing this batch is:  0.00455416738986969\n",
      "\n",
      "The classification loss after processing this batch is:  0.4495816230773926\n",
      "The representation loss after processing this batch is:  0.004306696355342865\n",
      "\n",
      "The classification loss after processing this batch is:  0.32674941420555115\n",
      "The representation loss after processing this batch is:  0.003658190369606018\n",
      "\n",
      "The classification loss after processing this batch is:  0.33796361088752747\n",
      "The representation loss after processing this batch is:  0.0053040459752082825\n",
      "\n",
      "The classification loss after processing this batch is:  0.29324081540107727\n",
      "The representation loss after processing this batch is:  0.0041997358202934265\n",
      "\n",
      "The classification loss after processing this batch is:  0.36219364404678345\n",
      "The representation loss after processing this batch is:  0.004525516182184219\n",
      "\n",
      "The classification loss after processing this batch is:  0.34234124422073364\n",
      "The representation loss after processing this batch is:  0.004149883985519409\n",
      "\n",
      "The classification loss after processing this batch is:  0.3090597689151764\n",
      "The representation loss after processing this batch is:  0.0036802999675273895\n",
      "\n",
      "The classification loss after processing this batch is:  0.2704198956489563\n",
      "The representation loss after processing this batch is:  0.0033454373478889465\n",
      "\n",
      "The classification loss after processing this batch is:  0.29214996099472046\n",
      "The representation loss after processing this batch is:  0.0041538625955581665\n",
      "\n",
      "The classification loss after processing this batch is:  0.30155640840530396\n",
      "The representation loss after processing this batch is:  0.0036894045770168304\n",
      "\n",
      "The classification loss after processing this batch is:  0.24680230021476746\n",
      "The representation loss after processing this batch is:  0.0034495964646339417\n",
      "\n",
      "The classification loss after processing this batch is:  0.3277914822101593\n",
      "The representation loss after processing this batch is:  0.003571242094039917\n",
      "\n",
      "The classification loss after processing this batch is:  0.26041048765182495\n",
      "The representation loss after processing this batch is:  0.0035768598318099976\n",
      "\n",
      "The classification loss after processing this batch is:  0.2962973415851593\n",
      "The representation loss after processing this batch is:  0.0032785795629024506\n",
      "\n",
      "The classification loss after processing this batch is:  0.2846927344799042\n",
      "The representation loss after processing this batch is:  0.003538958728313446\n",
      "\n",
      "The classification loss after processing this batch is:  0.788874626159668\n",
      "The representation loss after processing this batch is:  0.004183180630207062\n",
      "\n",
      "The classification loss after processing this batch is:  0.3731763958930969\n",
      "The representation loss after processing this batch is:  0.0035356134176254272\n",
      "\n",
      "The classification loss after processing this batch is:  0.4515872001647949\n",
      "The representation loss after processing this batch is:  0.003595612943172455\n",
      "\n",
      "The classification loss after processing this batch is:  0.4313136339187622\n",
      "The representation loss after processing this batch is:  0.003475368022918701\n",
      "\n",
      "The classification loss after processing this batch is:  0.3954647481441498\n",
      "The representation loss after processing this batch is:  0.0036660432815551758\n",
      "\n",
      "The classification loss after processing this batch is:  0.5356941223144531\n",
      "The representation loss after processing this batch is:  0.0040870606899261475\n",
      "\n",
      "The classification loss after processing this batch is:  0.32449856400489807\n",
      "The representation loss after processing this batch is:  0.004243694245815277\n",
      "\n",
      "The classification loss after processing this batch is:  0.46280384063720703\n",
      "The representation loss after processing this batch is:  0.0033424869179725647\n",
      "\n",
      "The classification loss after processing this batch is:  0.2615179121494293\n",
      "The representation loss after processing this batch is:  0.00371706485748291\n",
      "\n",
      "The classification loss after processing this batch is:  0.29075607657432556\n",
      "The representation loss after processing this batch is:  0.0037037134170532227\n",
      "\n",
      "The classification loss after processing this batch is:  0.2166755646467209\n",
      "The representation loss after processing this batch is:  0.004733093082904816\n",
      "\n",
      "The classification loss after processing this batch is:  0.2011091411113739\n",
      "The representation loss after processing this batch is:  0.004377491772174835\n",
      "\n",
      "The classification loss after processing this batch is:  0.2794732451438904\n",
      "The representation loss after processing this batch is:  0.003620445728302002\n",
      "\n",
      "The classification loss after processing this batch is:  0.20806270837783813\n",
      "The representation loss after processing this batch is:  0.003498546779155731\n",
      "\n",
      "The classification loss after processing this batch is:  0.2575269341468811\n",
      "The representation loss after processing this batch is:  0.003879047930240631\n",
      "\n",
      "The classification loss after processing this batch is:  0.2997133135795593\n",
      "The representation loss after processing this batch is:  0.004273183643817902\n",
      "\n",
      "The classification loss after processing this batch is:  0.27963364124298096\n",
      "The representation loss after processing this batch is:  0.0035076141357421875\n",
      "\n",
      "The classification loss after processing this batch is:  0.3349997401237488\n",
      "The representation loss after processing this batch is:  0.0034992657601833344\n",
      "\n",
      "The classification loss after processing this batch is:  0.32511061429977417\n",
      "The representation loss after processing this batch is:  0.004195861518383026\n",
      "\n",
      "The classification loss after processing this batch is:  0.32631269097328186\n",
      "The representation loss after processing this batch is:  0.0037005990743637085\n",
      "\n",
      "The classification loss after processing this batch is:  0.34343624114990234\n",
      "The representation loss after processing this batch is:  0.004221878945827484\n",
      "\n",
      "The classification loss after processing this batch is:  0.43074485659599304\n",
      "The representation loss after processing this batch is:  0.004058383405208588\n",
      "\n",
      "The classification loss after processing this batch is:  0.3675794005393982\n",
      "The representation loss after processing this batch is:  0.0036958493292331696\n",
      "\n",
      "The classification loss after processing this batch is:  0.2792605757713318\n",
      "The representation loss after processing this batch is:  0.003515046089887619\n",
      "\n",
      "The classification loss after processing this batch is:  0.39442452788352966\n",
      "The representation loss after processing this batch is:  0.00432446226477623\n",
      "\n",
      "The classification loss after processing this batch is:  0.3761264681816101\n",
      "The representation loss after processing this batch is:  0.0036010146141052246\n",
      "\n",
      "The classification loss after processing this batch is:  0.33951839804649353\n",
      "The representation loss after processing this batch is:  0.0035603195428848267\n",
      "\n",
      "The classification loss after processing this batch is:  0.3148961067199707\n",
      "The representation loss after processing this batch is:  0.003511384129524231\n",
      "\n",
      "The classification loss after processing this batch is:  0.325440913438797\n",
      "The representation loss after processing this batch is:  0.00412769615650177\n",
      "\n",
      "The classification loss after processing this batch is:  0.39218705892562866\n",
      "The representation loss after processing this batch is:  0.003697715699672699\n",
      "\n",
      "The classification loss after processing this batch is:  0.35651907324790955\n",
      "The representation loss after processing this batch is:  0.004249755293130875\n",
      "\n",
      "The classification loss after processing this batch is:  0.3149203062057495\n",
      "The representation loss after processing this batch is:  0.004060070961713791\n",
      "\n",
      "The classification loss after processing this batch is:  0.33868852257728577\n",
      "The representation loss after processing this batch is:  0.005062062293291092\n",
      "\n",
      "The classification loss after processing this batch is:  0.4069835841655731\n",
      "The representation loss after processing this batch is:  0.003933124244213104\n",
      "\n",
      "The classification loss after processing this batch is:  0.44648653268814087\n",
      "The representation loss after processing this batch is:  0.003631293773651123\n",
      "\n",
      "The classification loss after processing this batch is:  0.28761354088783264\n",
      "The representation loss after processing this batch is:  0.005479484796524048\n",
      "\n",
      "The classification loss after processing this batch is:  0.3073595464229584\n",
      "The representation loss after processing this batch is:  0.0036835968494415283\n",
      "\n",
      "The classification loss after processing this batch is:  0.27120745182037354\n",
      "The representation loss after processing this batch is:  0.0031049735844135284\n",
      "\n",
      "The classification loss after processing this batch is:  0.39686405658721924\n",
      "The representation loss after processing this batch is:  0.0033292770385742188\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.229685977101326\n",
      "The representation loss after processing this batch is:  0.004194252192974091\n",
      "\n",
      "The classification loss after processing this batch is:  0.261789470911026\n",
      "The representation loss after processing this batch is:  0.004241853952407837\n",
      "\n",
      "The classification loss after processing this batch is:  0.23162128031253815\n",
      "The representation loss after processing this batch is:  0.003773726522922516\n",
      "\n",
      "The classification loss after processing this batch is:  0.23923467099666595\n",
      "The representation loss after processing this batch is:  0.00378340482711792\n",
      "\n",
      "The classification loss after processing this batch is:  0.23225899040699005\n",
      "The representation loss after processing this batch is:  0.004099756479263306\n",
      "\n",
      "The classification loss after processing this batch is:  0.42960822582244873\n",
      "The representation loss after processing this batch is:  0.004120089113712311\n",
      "\n",
      "The classification loss after processing this batch is:  0.3462306261062622\n",
      "The representation loss after processing this batch is:  0.004112109541893005\n",
      "\n",
      "The classification loss after processing this batch is:  0.3725833594799042\n",
      "The representation loss after processing this batch is:  0.004218332469463348\n",
      "\n",
      "The classification loss after processing this batch is:  0.24626854062080383\n",
      "The representation loss after processing this batch is:  0.004445012658834457\n",
      "\n",
      "The classification loss after processing this batch is:  0.24084977805614471\n",
      "The representation loss after processing this batch is:  0.003929883241653442\n",
      "\n",
      "The classification loss after processing this batch is:  0.2785037159919739\n",
      "The representation loss after processing this batch is:  0.0038583874702453613\n",
      "\n",
      "The classification loss after processing this batch is:  0.27970239520072937\n",
      "The representation loss after processing this batch is:  0.003909546881914139\n",
      "\n",
      "The classification loss after processing this batch is:  0.2785370647907257\n",
      "The representation loss after processing this batch is:  0.0036776103079319\n",
      "\n",
      "The classification loss after processing this batch is:  0.2276938110589981\n",
      "The representation loss after processing this batch is:  0.003997214138507843\n",
      "\n",
      "The classification loss after processing this batch is:  0.18646183609962463\n",
      "The representation loss after processing this batch is:  0.003650140017271042\n",
      "\n",
      "The classification loss after processing this batch is:  0.30497509241104126\n",
      "The representation loss after processing this batch is:  0.0042414069175720215\n",
      "\n",
      "The classification loss after processing this batch is:  0.2640834152698517\n",
      "The representation loss after processing this batch is:  0.004366476088762283\n",
      "\n",
      "The classification loss after processing this batch is:  0.37466585636138916\n",
      "The representation loss after processing this batch is:  0.004275016486644745\n",
      "\n",
      "The classification loss after processing this batch is:  0.35816821455955505\n",
      "The representation loss after processing this batch is:  0.0032748132944107056\n",
      "\n",
      "The classification loss after processing this batch is:  0.34383270144462585\n",
      "The representation loss after processing this batch is:  0.0034829415380954742\n",
      "\n",
      "The classification loss after processing this batch is:  0.21702797710895538\n",
      "The representation loss after processing this batch is:  0.004194572567939758\n",
      "\n",
      "The classification loss after processing this batch is:  0.4363761842250824\n",
      "The representation loss after processing this batch is:  0.0035803355276584625\n",
      "\n",
      "The classification loss after processing this batch is:  0.2926214635372162\n",
      "The representation loss after processing this batch is:  0.0037041157484054565\n",
      "\n",
      "The classification loss after processing this batch is:  0.24621576070785522\n",
      "The representation loss after processing this batch is:  0.004048794507980347\n",
      "\n",
      "The classification loss after processing this batch is:  0.3597627580165863\n",
      "The representation loss after processing this batch is:  0.0037561431527137756\n",
      "\n",
      "The classification loss after processing this batch is:  0.3610145151615143\n",
      "The representation loss after processing this batch is:  0.004253089427947998\n",
      "\n",
      "The classification loss after processing this batch is:  0.22082997858524323\n",
      "The representation loss after processing this batch is:  0.003603018820285797\n",
      "\n",
      "The classification loss after processing this batch is:  0.2346876710653305\n",
      "The representation loss after processing this batch is:  0.0034738779067993164\n",
      "\n",
      "The classification loss after processing this batch is:  0.2322513908147812\n",
      "The representation loss after processing this batch is:  0.003401137888431549\n",
      "\n",
      "The classification loss after processing this batch is:  0.373338520526886\n",
      "The representation loss after processing this batch is:  0.0036062896251678467\n",
      "\n",
      "The classification loss after processing this batch is:  0.33130982518196106\n",
      "The representation loss after processing this batch is:  0.003622189164161682\n",
      "\n",
      "The classification loss after processing this batch is:  0.34412816166877747\n",
      "The representation loss after processing this batch is:  0.004945918917655945\n",
      "\n",
      "The classification loss after processing this batch is:  0.3418262302875519\n",
      "The representation loss after processing this batch is:  0.003962337970733643\n",
      "\n",
      "The classification loss after processing this batch is:  0.39996275305747986\n",
      "The representation loss after processing this batch is:  0.004179812967777252\n",
      "\n",
      "The classification loss after processing this batch is:  0.3342703580856323\n",
      "The representation loss after processing this batch is:  0.0035097822546958923\n",
      "\n",
      "The classification loss after processing this batch is:  0.5456482172012329\n",
      "The representation loss after processing this batch is:  0.003543056547641754\n",
      "\n",
      "The classification loss after processing this batch is:  0.39332637190818787\n",
      "The representation loss after processing this batch is:  0.0035479962825775146\n",
      "\n",
      "The classification loss after processing this batch is:  0.3779149651527405\n",
      "The representation loss after processing this batch is:  0.0034368112683296204\n",
      "\n",
      "The classification loss after processing this batch is:  0.2729778587818146\n",
      "The representation loss after processing this batch is:  0.003384239971637726\n",
      "\n",
      "The classification loss after processing this batch is:  0.27569419145584106\n",
      "The representation loss after processing this batch is:  0.0032313987612724304\n",
      "\n",
      "The classification loss after processing this batch is:  0.24219022691249847\n",
      "The representation loss after processing this batch is:  0.0035429447889328003\n",
      "\n",
      "The classification loss after processing this batch is:  0.3549706041812897\n",
      "The representation loss after processing this batch is:  0.00393565371632576\n",
      "\n",
      "The classification loss after processing this batch is:  0.31831181049346924\n",
      "The representation loss after processing this batch is:  0.0037048831582069397\n",
      "\n",
      "The classification loss after processing this batch is:  0.2371194064617157\n",
      "The representation loss after processing this batch is:  0.0038138851523399353\n",
      "\n",
      "The classification loss after processing this batch is:  0.350811630487442\n",
      "The representation loss after processing this batch is:  0.003535442054271698\n",
      "\n",
      "The classification loss after processing this batch is:  0.29694855213165283\n",
      "The representation loss after processing this batch is:  0.0036674588918685913\n",
      "\n",
      "The classification loss after processing this batch is:  0.36098480224609375\n",
      "The representation loss after processing this batch is:  0.0037302859127521515\n",
      "\n",
      "The classification loss after processing this batch is:  0.3405960500240326\n",
      "The representation loss after processing this batch is:  0.0035454295575618744\n",
      "\n",
      "The classification loss after processing this batch is:  0.4465818703174591\n",
      "The representation loss after processing this batch is:  0.0031166113913059235\n",
      "\n",
      "The classification loss after processing this batch is:  0.3259529769420624\n",
      "The representation loss after processing this batch is:  0.003709748387336731\n",
      "\n",
      "The classification loss after processing this batch is:  0.2059631645679474\n",
      "The representation loss after processing this batch is:  0.003810971975326538\n",
      "\n",
      "The classification loss after processing this batch is:  0.32914555072784424\n",
      "The representation loss after processing this batch is:  0.003316253423690796\n",
      "\n",
      "The classification loss after processing this batch is:  0.21649602055549622\n",
      "The representation loss after processing this batch is:  0.0037281736731529236\n",
      "\n",
      "The classification loss after processing this batch is:  0.19740861654281616\n",
      "The representation loss after processing this batch is:  0.0034950897097587585\n",
      "\n",
      "The classification loss after processing this batch is:  0.271009236574173\n",
      "The representation loss after processing this batch is:  0.003849901258945465\n",
      "\n",
      "The classification loss after processing this batch is:  0.328558087348938\n",
      "The representation loss after processing this batch is:  0.003202691674232483\n",
      "\n",
      "The classification loss after processing this batch is:  0.3605691194534302\n",
      "The representation loss after processing this batch is:  0.0037587732076644897\n",
      "\n",
      "The classification loss after processing this batch is:  0.25030335783958435\n",
      "The representation loss after processing this batch is:  0.0037772804498672485\n",
      "\n",
      "The classification loss after processing this batch is:  0.2819233536720276\n",
      "The representation loss after processing this batch is:  0.004017099738121033\n",
      "\n",
      "The classification loss after processing this batch is:  0.20315366983413696\n",
      "The representation loss after processing this batch is:  0.0037723705172538757\n",
      "\n",
      "The classification loss after processing this batch is:  0.3545738458633423\n",
      "The representation loss after processing this batch is:  0.0038022100925445557\n",
      "\n",
      "The classification loss after processing this batch is:  0.18862830102443695\n",
      "The representation loss after processing this batch is:  0.0032667964696884155\n",
      "\n",
      "The classification loss after processing this batch is:  0.17177531123161316\n",
      "The representation loss after processing this batch is:  0.0038193687796592712\n",
      "\n",
      "The classification loss after processing this batch is:  0.27229514718055725\n",
      "The representation loss after processing this batch is:  0.004950359463691711\n",
      "\n",
      "The classification loss after processing this batch is:  0.26135361194610596\n",
      "The representation loss after processing this batch is:  0.00359131395816803\n",
      "\n",
      "The classification loss after processing this batch is:  0.24951209127902985\n",
      "The representation loss after processing this batch is:  0.004206039011478424\n",
      "\n",
      "The classification loss after processing this batch is:  0.21636724472045898\n",
      "The representation loss after processing this batch is:  0.0036046430468559265\n",
      "\n",
      "The classification loss after processing this batch is:  0.32122382521629333\n",
      "The representation loss after processing this batch is:  0.004056856036186218\n",
      "\n",
      "The classification loss after processing this batch is:  0.38379770517349243\n",
      "The representation loss after processing this batch is:  0.004126489162445068\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.36929091811180115\n",
      "The representation loss after processing this batch is:  0.0032913759350776672\n",
      "\n",
      "The classification loss after processing this batch is:  0.38942021131515503\n",
      "The representation loss after processing this batch is:  0.00413396954536438\n",
      "\n",
      "The classification loss after processing this batch is:  0.2073116898536682\n",
      "The representation loss after processing this batch is:  0.003859870135784149\n",
      "\n",
      "The classification loss after processing this batch is:  0.26297417283058167\n",
      "The representation loss after processing this batch is:  0.0034370310604572296\n",
      "\n",
      "The classification loss after processing this batch is:  0.4608396887779236\n",
      "The representation loss after processing this batch is:  0.003882482647895813\n",
      "\n",
      "The classification loss after processing this batch is:  0.5122905969619751\n",
      "The representation loss after processing this batch is:  0.004044003784656525\n",
      "\n",
      "The classification loss after processing this batch is:  0.43060749769210815\n",
      "The representation loss after processing this batch is:  0.004196345806121826\n",
      "\n",
      "The classification loss after processing this batch is:  0.499851793050766\n",
      "The representation loss after processing this batch is:  0.0038615092635154724\n",
      "\n",
      "The classification loss after processing this batch is:  0.2877107262611389\n",
      "The representation loss after processing this batch is:  0.003328334540128708\n",
      "\n",
      "The classification loss after processing this batch is:  0.38304126262664795\n",
      "The representation loss after processing this batch is:  0.0036851316690444946\n",
      "\n",
      "The classification loss after processing this batch is:  0.2976294755935669\n",
      "The representation loss after processing this batch is:  0.003433607518672943\n",
      "\n",
      "The classification loss after processing this batch is:  0.29731225967407227\n",
      "The representation loss after processing this batch is:  0.0033490657806396484\n",
      "\n",
      "The classification loss after processing this batch is:  0.2680652439594269\n",
      "The representation loss after processing this batch is:  0.0036943629384040833\n",
      "\n",
      "The classification loss after processing this batch is:  0.29795506596565247\n",
      "The representation loss after processing this batch is:  0.003348909318447113\n",
      "\n",
      "The classification loss after processing this batch is:  0.33148086071014404\n",
      "The representation loss after processing this batch is:  0.003939162939786911\n",
      "\n",
      "The classification loss after processing this batch is:  0.2645060420036316\n",
      "The representation loss after processing this batch is:  0.0038860999047756195\n",
      "\n",
      "The classification loss after processing this batch is:  0.37295517325401306\n",
      "The representation loss after processing this batch is:  0.0035266131162643433\n",
      "\n",
      "The classification loss after processing this batch is:  0.19528238475322723\n",
      "The representation loss after processing this batch is:  0.004244789481163025\n",
      "\n",
      "The classification loss after processing this batch is:  0.2467174381017685\n",
      "The representation loss after processing this batch is:  0.004038207232952118\n",
      "\n",
      "The classification loss after processing this batch is:  0.27063924074172974\n",
      "The representation loss after processing this batch is:  0.00357876718044281\n",
      "\n",
      "The classification loss after processing this batch is:  0.29980283975601196\n",
      "The representation loss after processing this batch is:  0.004336066544055939\n",
      "\n",
      "The classification loss after processing this batch is:  0.22896936535835266\n",
      "The representation loss after processing this batch is:  0.004650004208087921\n",
      "\n",
      "The classification loss after processing this batch is:  0.22910095751285553\n",
      "The representation loss after processing this batch is:  0.003367803990840912\n",
      "\n",
      "The classification loss after processing this batch is:  0.3559323847293854\n",
      "The representation loss after processing this batch is:  0.004041232168674469\n",
      "\n",
      "The classification loss after processing this batch is:  0.3667879104614258\n",
      "The representation loss after processing this batch is:  0.003856923431158066\n",
      "\n",
      "The classification loss after processing this batch is:  0.3272324502468109\n",
      "The representation loss after processing this batch is:  0.003935813903808594\n",
      "\n",
      "The classification loss after processing this batch is:  0.27427202463150024\n",
      "The representation loss after processing this batch is:  0.0033524371683597565\n",
      "\n",
      "The classification loss after processing this batch is:  0.25890588760375977\n",
      "The representation loss after processing this batch is:  0.003746025264263153\n",
      "\n",
      "The classification loss after processing this batch is:  0.22447071969509125\n",
      "The representation loss after processing this batch is:  0.0036862939596176147\n",
      "\n",
      "The classification loss after processing this batch is:  0.33316469192504883\n",
      "The representation loss after processing this batch is:  0.0035885944962501526\n",
      "\n",
      "The classification loss after processing this batch is:  0.3459378182888031\n",
      "The representation loss after processing this batch is:  0.003742426633834839\n",
      "\n",
      "The classification loss after processing this batch is:  0.33127492666244507\n",
      "The representation loss after processing this batch is:  0.003671981394290924\n",
      "\n",
      "The classification loss after processing this batch is:  0.2749877870082855\n",
      "The representation loss after processing this batch is:  0.0038167834281921387\n",
      "\n",
      "The classification loss after processing this batch is:  0.4056035578250885\n",
      "The representation loss after processing this batch is:  0.0034420154988765717\n",
      "\n",
      "The classification loss after processing this batch is:  0.44431889057159424\n",
      "The representation loss after processing this batch is:  0.003817867487668991\n",
      "\n",
      "The classification loss after processing this batch is:  0.21931934356689453\n",
      "The representation loss after processing this batch is:  0.003880634903907776\n",
      "\n",
      "The classification loss after processing this batch is:  0.26414188742637634\n",
      "The representation loss after processing this batch is:  0.0033550821244716644\n",
      "\n",
      "The classification loss after processing this batch is:  0.42401087284088135\n",
      "The representation loss after processing this batch is:  0.0035213306546211243\n",
      "\n",
      "The classification loss after processing this batch is:  0.40977928042411804\n",
      "The representation loss after processing this batch is:  0.0034632831811904907\n",
      "\n",
      "The classification loss after processing this batch is:  0.2882155179977417\n",
      "The representation loss after processing this batch is:  0.0036837011575698853\n",
      "\n",
      "The classification loss after processing this batch is:  0.48203498125076294\n",
      "The representation loss after processing this batch is:  0.002933196723461151\n",
      "\n",
      "The classification loss after processing this batch is:  0.36958226561546326\n",
      "The representation loss after processing this batch is:  0.003981925547122955\n",
      "\n",
      "The classification loss after processing this batch is:  0.4395027160644531\n",
      "The representation loss after processing this batch is:  0.004143994301557541\n",
      "\n",
      "The classification loss after processing this batch is:  0.328652948141098\n",
      "The representation loss after processing this batch is:  0.003964655101299286\n",
      "\n",
      "The classification loss after processing this batch is:  0.35672155022621155\n",
      "The representation loss after processing this batch is:  0.0033736974000930786\n",
      "\n",
      "The classification loss after processing this batch is:  0.2529105842113495\n",
      "The representation loss after processing this batch is:  0.005065560340881348\n",
      "\n",
      "The classification loss after processing this batch is:  0.3274238407611847\n",
      "The representation loss after processing this batch is:  0.0032723918557167053\n",
      "\n",
      "The classification loss after processing this batch is:  0.26330462098121643\n",
      "The representation loss after processing this batch is:  0.003251209855079651\n",
      "\n",
      "The classification loss after processing this batch is:  0.33262354135513306\n",
      "The representation loss after processing this batch is:  0.003187078982591629\n",
      "\n",
      "The classification loss after processing this batch is:  0.26472628116607666\n",
      "The representation loss after processing this batch is:  0.003863394260406494\n",
      "\n",
      "The classification loss after processing this batch is:  0.27874311804771423\n",
      "The representation loss after processing this batch is:  0.003401555120944977\n",
      "\n",
      "The classification loss after processing this batch is:  0.37101370096206665\n",
      "The representation loss after processing this batch is:  0.0035871677100658417\n",
      "\n",
      "The classification loss after processing this batch is:  0.22879353165626526\n",
      "The representation loss after processing this batch is:  0.004105903208255768\n",
      "\n",
      "The classification loss after processing this batch is:  0.2223622351884842\n",
      "The representation loss after processing this batch is:  0.00456739217042923\n",
      "\n",
      "The classification loss after processing this batch is:  0.2846713364124298\n",
      "The representation loss after processing this batch is:  0.004066199064254761\n",
      "\n",
      "The classification loss after processing this batch is:  0.17439188063144684\n",
      "The representation loss after processing this batch is:  0.003664545714855194\n",
      "\n",
      "The classification loss after processing this batch is:  0.2827121913433075\n",
      "The representation loss after processing this batch is:  0.0033693984150886536\n",
      "\n",
      "The classification loss after processing this batch is:  0.2066689133644104\n",
      "The representation loss after processing this batch is:  0.003994807600975037\n",
      "\n",
      "The classification loss after processing this batch is:  0.20444990694522858\n",
      "The representation loss after processing this batch is:  0.0036393925547599792\n",
      "\n",
      "The classification loss after processing this batch is:  0.27773359417915344\n",
      "The representation loss after processing this batch is:  0.0035125091671943665\n",
      "\n",
      "The classification loss after processing this batch is:  0.3734782636165619\n",
      "The representation loss after processing this batch is:  0.004257425665855408\n",
      "\n",
      "The classification loss after processing this batch is:  0.2959316372871399\n",
      "The representation loss after processing this batch is:  0.004439689218997955\n",
      "\n",
      "The classification loss after processing this batch is:  0.27109062671661377\n",
      "The representation loss after processing this batch is:  0.003289882093667984\n",
      "\n",
      "The classification loss after processing this batch is:  0.27091628313064575\n",
      "The representation loss after processing this batch is:  0.00403938814997673\n",
      "\n",
      "The classification loss after processing this batch is:  0.2083163857460022\n",
      "The representation loss after processing this batch is:  0.003442518413066864\n",
      "\n",
      "The classification loss after processing this batch is:  0.20129574835300446\n",
      "The representation loss after processing this batch is:  0.003954663872718811\n",
      "\n",
      "The classification loss after processing this batch is:  0.22304686903953552\n",
      "The representation loss after processing this batch is:  0.003347732126712799\n",
      "\n",
      "The classification loss after processing this batch is:  0.19690735638141632\n",
      "The representation loss after processing this batch is:  0.004041463136672974\n",
      "\n",
      "The classification loss after processing this batch is:  0.25769251585006714\n",
      "The representation loss after processing this batch is:  0.0038054101169109344\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.3637191653251648\n",
      "The representation loss after processing this batch is:  0.0036543793976306915\n",
      "\n",
      "The classification loss after processing this batch is:  0.3407379686832428\n",
      "The representation loss after processing this batch is:  0.0031027570366859436\n",
      "\n",
      "The classification loss after processing this batch is:  0.21774159371852875\n",
      "The representation loss after processing this batch is:  0.003752201795578003\n",
      "\n",
      "The classification loss after processing this batch is:  0.28303220868110657\n",
      "The representation loss after processing this batch is:  0.00416158139705658\n",
      "\n",
      "The classification loss after processing this batch is:  0.3564583361148834\n",
      "The representation loss after processing this batch is:  0.00394786149263382\n",
      "\n",
      "The classification loss after processing this batch is:  0.2746336758136749\n",
      "The representation loss after processing this batch is:  0.0039479658007621765\n",
      "\n",
      "The classification loss after processing this batch is:  0.591605007648468\n",
      "The representation loss after processing this batch is:  0.004281453788280487\n",
      "\n",
      "The classification loss after processing this batch is:  0.30300718545913696\n",
      "The representation loss after processing this batch is:  0.004097260534763336\n",
      "\n",
      "The classification loss after processing this batch is:  0.35914745926856995\n",
      "The representation loss after processing this batch is:  0.004657380282878876\n",
      "\n",
      "The classification loss after processing this batch is:  0.28922566771507263\n",
      "The representation loss after processing this batch is:  0.003233514726161957\n",
      "\n",
      "The classification loss after processing this batch is:  0.26877862215042114\n",
      "The representation loss after processing this batch is:  0.003726668655872345\n",
      "\n",
      "The classification loss after processing this batch is:  0.27421098947525024\n",
      "The representation loss after processing this batch is:  0.0034049972891807556\n",
      "\n",
      "The classification loss after processing this batch is:  0.32001227140426636\n",
      "The representation loss after processing this batch is:  0.0039808303117752075\n",
      "\n",
      "The classification loss after processing this batch is:  0.394110769033432\n",
      "The representation loss after processing this batch is:  0.003763750195503235\n",
      "\n",
      "The classification loss after processing this batch is:  0.436035692691803\n",
      "The representation loss after processing this batch is:  0.004974596202373505\n",
      "\n",
      "The classification loss after processing this batch is:  0.32780584692955017\n",
      "The representation loss after processing this batch is:  0.004658013582229614\n",
      "\n",
      "The classification loss after processing this batch is:  0.29881811141967773\n",
      "The representation loss after processing this batch is:  0.004105418920516968\n",
      "\n",
      "The classification loss after processing this batch is:  0.17194542288780212\n",
      "The representation loss after processing this batch is:  0.003861747682094574\n",
      "\n",
      "The classification loss after processing this batch is:  0.2697184681892395\n",
      "The representation loss after processing this batch is:  0.003985721617937088\n",
      "\n",
      "The classification loss after processing this batch is:  0.2301943451166153\n",
      "The representation loss after processing this batch is:  0.0035263225436210632\n",
      "\n",
      "The classification loss after processing this batch is:  0.210408553481102\n",
      "The representation loss after processing this batch is:  0.004045106470584869\n",
      "\n",
      "The classification loss after processing this batch is:  0.31850776076316833\n",
      "The representation loss after processing this batch is:  0.0034343600273132324\n",
      "\n",
      "The classification loss after processing this batch is:  0.3824084997177124\n",
      "The representation loss after processing this batch is:  0.0036417990922927856\n",
      "\n",
      "The classification loss after processing this batch is:  0.31235867738723755\n",
      "The representation loss after processing this batch is:  0.0031459033489227295\n",
      "\n",
      "The classification loss after processing this batch is:  0.33010634779930115\n",
      "The representation loss after processing this batch is:  0.0039708539843559265\n",
      "\n",
      "The classification loss after processing this batch is:  0.278588205575943\n",
      "The representation loss after processing this batch is:  0.003326907753944397\n",
      "\n",
      "The classification loss after processing this batch is:  0.23829157650470734\n",
      "The representation loss after processing this batch is:  0.003953948616981506\n",
      "\n",
      "The classification loss after processing this batch is:  0.2811320126056671\n",
      "The representation loss after processing this batch is:  0.003758534789085388\n",
      "\n",
      "The classification loss after processing this batch is:  0.1675722748041153\n",
      "The representation loss after processing this batch is:  0.0037881135940551758\n",
      "\n",
      "The classification loss after processing this batch is:  0.26603612303733826\n",
      "The representation loss after processing this batch is:  0.002957269549369812\n",
      "\n",
      "The classification loss after processing this batch is:  0.37085309624671936\n",
      "The representation loss after processing this batch is:  0.003488793969154358\n",
      "\n",
      "The classification loss after processing this batch is:  0.19935297966003418\n",
      "The representation loss after processing this batch is:  0.003608427941799164\n",
      "\n",
      "The classification loss after processing this batch is:  0.3591494560241699\n",
      "The representation loss after processing this batch is:  0.003058549016714096\n",
      "\n",
      "The classification loss after processing this batch is:  0.2766648232936859\n",
      "The representation loss after processing this batch is:  0.003450527787208557\n",
      "\n",
      "The classification loss after processing this batch is:  0.22368472814559937\n",
      "The representation loss after processing this batch is:  0.0032115131616592407\n",
      "\n",
      "The classification loss after processing this batch is:  0.2188650518655777\n",
      "The representation loss after processing this batch is:  0.0034943819046020508\n",
      "\n",
      "The classification loss after processing this batch is:  0.3316434919834137\n",
      "The representation loss after processing this batch is:  0.003863222897052765\n",
      "\n",
      "The classification loss after processing this batch is:  0.24028517305850983\n",
      "The representation loss after processing this batch is:  0.0036510825157165527\n",
      "\n",
      "The classification loss after processing this batch is:  0.4675317108631134\n",
      "The representation loss after processing this batch is:  0.0035029202699661255\n",
      "\n",
      "The classification loss after processing this batch is:  0.34401607513427734\n",
      "The representation loss after processing this batch is:  0.00379393994808197\n",
      "\n",
      "The classification loss after processing this batch is:  0.3366491496562958\n",
      "The representation loss after processing this batch is:  0.0035756826400756836\n",
      "\n",
      "The classification loss after processing this batch is:  0.22958023846149445\n",
      "The representation loss after processing this batch is:  0.0031373314559459686\n",
      "\n",
      "The classification loss after processing this batch is:  0.33195051550865173\n",
      "The representation loss after processing this batch is:  0.003604017198085785\n",
      "\n",
      "The classification loss after processing this batch is:  0.25316599011421204\n",
      "The representation loss after processing this batch is:  0.003267720341682434\n",
      "\n",
      "The classification loss after processing this batch is:  0.3720830976963043\n",
      "The representation loss after processing this batch is:  0.0036129839718341827\n",
      "\n",
      "The classification loss after processing this batch is:  0.36470699310302734\n",
      "The representation loss after processing this batch is:  0.0037892088294029236\n",
      "\n",
      "The classification loss after processing this batch is:  0.36208656430244446\n",
      "The representation loss after processing this batch is:  0.004400212317705154\n",
      "\n",
      "The classification loss after processing this batch is:  0.33402252197265625\n",
      "The representation loss after processing this batch is:  0.003584064543247223\n",
      "\n",
      "The classification loss after processing this batch is:  0.2730094790458679\n",
      "The representation loss after processing this batch is:  0.003476962447166443\n",
      "\n",
      "The classification loss after processing this batch is:  0.36314645409584045\n",
      "The representation loss after processing this batch is:  0.0038639232516288757\n",
      "\n",
      "The classification loss after processing this batch is:  0.2720567584037781\n",
      "The representation loss after processing this batch is:  0.0036586374044418335\n",
      "\n",
      "The classification loss after processing this batch is:  0.306466668844223\n",
      "The representation loss after processing this batch is:  0.003488108515739441\n",
      "\n",
      "The classification loss after processing this batch is:  0.25887781381607056\n",
      "The representation loss after processing this batch is:  0.0037639960646629333\n",
      "\n",
      "The classification loss after processing this batch is:  0.26825568079948425\n",
      "The representation loss after processing this batch is:  0.003921248018741608\n",
      "\n",
      "The classification loss after processing this batch is:  0.22872203588485718\n",
      "The representation loss after processing this batch is:  0.003892701119184494\n",
      "\n",
      "The classification loss after processing this batch is:  0.3357428312301636\n",
      "The representation loss after processing this batch is:  0.0034485720098018646\n",
      "\n",
      "The classification loss after processing this batch is:  0.5129921436309814\n",
      "The representation loss after processing this batch is:  0.003466986119747162\n",
      "\n",
      "The classification loss after processing this batch is:  0.281965434551239\n",
      "The representation loss after processing this batch is:  0.003972090780735016\n",
      "\n",
      "The classification loss after processing this batch is:  0.41633349657058716\n",
      "The representation loss after processing this batch is:  0.0038752481341362\n",
      "\n",
      "The classification loss after processing this batch is:  0.46071818470954895\n",
      "The representation loss after processing this batch is:  0.003443405032157898\n",
      "\n",
      "The classification loss after processing this batch is:  0.37326350808143616\n",
      "The representation loss after processing this batch is:  0.003981180489063263\n",
      "\n",
      "The classification loss after processing this batch is:  0.23685242235660553\n",
      "The representation loss after processing this batch is:  0.0036005526781082153\n",
      "\n",
      "The classification loss after processing this batch is:  0.44330692291259766\n",
      "The representation loss after processing this batch is:  0.0037209242582321167\n",
      "\n",
      "The classification loss after processing this batch is:  0.4287368655204773\n",
      "The representation loss after processing this batch is:  0.0041854605078697205\n",
      "\n",
      "The classification loss after processing this batch is:  0.3134818375110626\n",
      "The representation loss after processing this batch is:  0.0037214569747447968\n",
      "\n",
      "The classification loss after processing this batch is:  0.17172349989414215\n",
      "The representation loss after processing this batch is:  0.0037719905376434326\n",
      "\n",
      "The classification loss after processing this batch is:  0.2828720808029175\n",
      "The representation loss after processing this batch is:  0.0039897337555885315\n",
      "\n",
      "The classification loss after processing this batch is:  0.3381451666355133\n",
      "The representation loss after processing this batch is:  0.003989353775978088\n",
      "\n",
      "The classification loss after processing this batch is:  0.3409966826438904\n",
      "The representation loss after processing this batch is:  0.0033758021891117096\n",
      "\n",
      "The classification loss after processing this batch is:  0.4093970060348511\n",
      "The representation loss after processing this batch is:  0.003651689738035202\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.3115603029727936\n",
      "The representation loss after processing this batch is:  0.0031547583639621735\n",
      "\n",
      "The classification loss after processing this batch is:  0.32119935750961304\n",
      "The representation loss after processing this batch is:  0.004065379500389099\n",
      "\n",
      "The classification loss after processing this batch is:  0.3901374638080597\n",
      "The representation loss after processing this batch is:  0.004291728138923645\n",
      "\n",
      "The classification loss after processing this batch is:  0.3113712966442108\n",
      "The representation loss after processing this batch is:  0.003864191472530365\n",
      "\n",
      "The classification loss after processing this batch is:  0.28458866477012634\n",
      "The representation loss after processing this batch is:  0.004064671695232391\n",
      "\n",
      "The classification loss after processing this batch is:  0.5648477077484131\n",
      "The representation loss after processing this batch is:  0.00379953533411026\n",
      "\n",
      "The classification loss after processing this batch is:  0.41552239656448364\n",
      "The representation loss after processing this batch is:  0.004477113485336304\n",
      "\n",
      "The classification loss after processing this batch is:  0.26583191752433777\n",
      "The representation loss after processing this batch is:  0.0034690722823143005\n",
      "\n",
      "The classification loss after processing this batch is:  0.22170935571193695\n",
      "The representation loss after processing this batch is:  0.003502842038869858\n",
      "\n",
      "The classification loss after processing this batch is:  0.23139485716819763\n",
      "The representation loss after processing this batch is:  0.002943068742752075\n",
      "\n",
      "The classification loss after processing this batch is:  0.2496170997619629\n",
      "The representation loss after processing this batch is:  0.004070475697517395\n",
      "\n",
      "The classification loss after processing this batch is:  0.2863418459892273\n",
      "The representation loss after processing this batch is:  0.0032293200492858887\n",
      "\n",
      "The classification loss after processing this batch is:  0.47445905208587646\n",
      "The representation loss after processing this batch is:  0.003255710005760193\n",
      "\n",
      "The classification loss after processing this batch is:  0.4332883059978485\n",
      "The representation loss after processing this batch is:  0.004065021872520447\n",
      "\n",
      "The classification loss after processing this batch is:  0.34186628460884094\n",
      "The representation loss after processing this batch is:  0.0031118541955947876\n",
      "\n",
      "The classification loss after processing this batch is:  0.2760181427001953\n",
      "The representation loss after processing this batch is:  0.0031736530363559723\n",
      "\n",
      "The classification loss after processing this batch is:  0.2698732912540436\n",
      "The representation loss after processing this batch is:  0.0032747089862823486\n",
      "\n",
      "The classification loss after processing this batch is:  0.25025227665901184\n",
      "The representation loss after processing this batch is:  0.0038139820098876953\n",
      "\n",
      "The classification loss after processing this batch is:  0.4236627519130707\n",
      "The representation loss after processing this batch is:  0.003614146262407303\n",
      "\n",
      "The classification loss after processing this batch is:  0.37813103199005127\n",
      "The representation loss after processing this batch is:  0.0034268461167812347\n",
      "\n",
      "The classification loss after processing this batch is:  0.4086694121360779\n",
      "The representation loss after processing this batch is:  0.003538556396961212\n",
      "\n",
      "The classification loss after processing this batch is:  0.31859827041625977\n",
      "The representation loss after processing this batch is:  0.0034966692328453064\n",
      "\n",
      "The classification loss after processing this batch is:  0.1536080539226532\n",
      "The representation loss after processing this batch is:  0.004145495593547821\n",
      "\n",
      "The classification loss after processing this batch is:  0.33521461486816406\n",
      "The representation loss after processing this batch is:  0.003376740962266922\n",
      "\n",
      "The classification loss after processing this batch is:  0.29339638352394104\n",
      "The representation loss after processing this batch is:  0.003869391977787018\n",
      "\n",
      "The classification loss after processing this batch is:  0.34119006991386414\n",
      "The representation loss after processing this batch is:  0.003911115229129791\n",
      "\n",
      "The classification loss after processing this batch is:  0.3453920781612396\n",
      "The representation loss after processing this batch is:  0.0032440871000289917\n",
      "\n",
      "The classification loss after processing this batch is:  0.41101595759391785\n",
      "The representation loss after processing this batch is:  0.003182418644428253\n",
      "\n",
      "The classification loss after processing this batch is:  0.3667263686656952\n",
      "The representation loss after processing this batch is:  0.0033719688653945923\n",
      "\n",
      "The classification loss after processing this batch is:  0.36357465386390686\n",
      "The representation loss after processing this batch is:  0.003520473837852478\n",
      "\n",
      "The classification loss after processing this batch is:  0.484551340341568\n",
      "The representation loss after processing this batch is:  0.0032172948122024536\n",
      "\n",
      "The classification loss after processing this batch is:  0.47121721506118774\n",
      "The representation loss after processing this batch is:  0.0031846314668655396\n",
      "\n",
      "The classification loss after processing this batch is:  0.3898942768573761\n",
      "The representation loss after processing this batch is:  0.0036127865314483643\n",
      "\n",
      "The classification loss after processing this batch is:  0.1863883137702942\n",
      "The representation loss after processing this batch is:  0.003452390432357788\n",
      "\n",
      "The classification loss after processing this batch is:  0.1486559808254242\n",
      "The representation loss after processing this batch is:  0.003881596028804779\n",
      "\n",
      "The classification loss after processing this batch is:  0.2699423134326935\n",
      "The representation loss after processing this batch is:  0.004031747579574585\n",
      "\n",
      "The classification loss after processing this batch is:  0.19940172135829926\n",
      "The representation loss after processing this batch is:  0.005092844367027283\n",
      "\n",
      "The classification loss after processing this batch is:  0.3698540925979614\n",
      "The representation loss after processing this batch is:  0.0035544633865356445\n",
      "\n",
      "The classification loss after processing this batch is:  0.2043156623840332\n",
      "The representation loss after processing this batch is:  0.0040195658802986145\n",
      "\n",
      "The classification loss after processing this batch is:  0.3966485857963562\n",
      "The representation loss after processing this batch is:  0.0036769136786460876\n",
      "\n",
      "The classification loss after processing this batch is:  0.16888752579689026\n",
      "The representation loss after processing this batch is:  0.003992877900600433\n",
      "\n",
      "The classification loss after processing this batch is:  0.32898321747779846\n",
      "The representation loss after processing this batch is:  0.0039050765335559845\n",
      "\n",
      "The classification loss after processing this batch is:  0.2705457806587219\n",
      "The representation loss after processing this batch is:  0.0037223398685455322\n",
      "\n",
      "The classification loss after processing this batch is:  0.31218284368515015\n",
      "The representation loss after processing this batch is:  0.004479251801967621\n",
      "\n",
      "The classification loss after processing this batch is:  0.2949259877204895\n",
      "The representation loss after processing this batch is:  0.0034397542476654053\n",
      "\n",
      "The classification loss after processing this batch is:  0.22986720502376556\n",
      "The representation loss after processing this batch is:  0.002922985702753067\n",
      "\n",
      "The classification loss after processing this batch is:  0.27127978205680847\n",
      "The representation loss after processing this batch is:  0.003215499222278595\n",
      "\n",
      "The classification loss after processing this batch is:  0.31843698024749756\n",
      "The representation loss after processing this batch is:  0.0035320892930030823\n",
      "\n",
      "The classification loss after processing this batch is:  0.34114551544189453\n",
      "The representation loss after processing this batch is:  0.0032126307487487793\n",
      "\n",
      "The classification loss after processing this batch is:  0.20599451661109924\n",
      "The representation loss after processing this batch is:  0.0034753233194351196\n",
      "\n",
      "The classification loss after processing this batch is:  0.1785573959350586\n",
      "The representation loss after processing this batch is:  0.003865055739879608\n",
      "\n",
      "The classification loss after processing this batch is:  0.16883672773838043\n",
      "The representation loss after processing this batch is:  0.003452412784099579\n",
      "\n",
      "The classification loss after processing this batch is:  0.19095346331596375\n",
      "The representation loss after processing this batch is:  0.003503181040287018\n",
      "\n",
      "The classification loss after processing this batch is:  0.20232130587100983\n",
      "The representation loss after processing this batch is:  0.003584466874599457\n",
      "\n",
      "The classification loss after processing this batch is:  0.3302358090877533\n",
      "The representation loss after processing this batch is:  0.003485061228275299\n",
      "\n",
      "The classification loss after processing this batch is:  0.19352252781391144\n",
      "The representation loss after processing this batch is:  0.0036903992295265198\n",
      "\n",
      "The classification loss after processing this batch is:  0.1556890457868576\n",
      "The representation loss after processing this batch is:  0.003659270703792572\n",
      "\n",
      "The classification loss after processing this batch is:  0.26615074276924133\n",
      "The representation loss after processing this batch is:  0.0038508400321006775\n",
      "\n",
      "The classification loss after processing this batch is:  0.28003165125846863\n",
      "The representation loss after processing this batch is:  0.0036079958081245422\n",
      "\n",
      "The classification loss after processing this batch is:  0.25055113434791565\n",
      "The representation loss after processing this batch is:  0.003691256046295166\n",
      "\n",
      "The classification loss after processing this batch is:  0.23015382885932922\n",
      "The representation loss after processing this batch is:  0.0038111284375190735\n",
      "\n",
      "The classification loss after processing this batch is:  0.18668915331363678\n",
      "The representation loss after processing this batch is:  0.0034835264086723328\n",
      "\n",
      "The classification loss after processing this batch is:  0.16595901548862457\n",
      "The representation loss after processing this batch is:  0.0033900514245033264\n",
      "\n",
      "The classification loss after processing this batch is:  0.31037041544914246\n",
      "The representation loss after processing this batch is:  0.0036344751715660095\n",
      "\n",
      "The classification loss after processing this batch is:  0.31103086471557617\n",
      "The representation loss after processing this batch is:  0.003612115979194641\n",
      "\n",
      "The classification loss after processing this batch is:  0.2391103059053421\n",
      "The representation loss after processing this batch is:  0.0037457793951034546\n",
      "\n",
      "The classification loss after processing this batch is:  0.37205302715301514\n",
      "The representation loss after processing this batch is:  0.00334911048412323\n",
      "\n",
      "The classification loss after processing this batch is:  0.23260833323001862\n",
      "The representation loss after processing this batch is:  0.0038167983293533325\n",
      "\n",
      "The classification loss after processing this batch is:  0.31272417306900024\n",
      "The representation loss after processing this batch is:  0.003070160746574402\n",
      "\n",
      "The classification loss after processing this batch is:  0.4011273980140686\n",
      "The representation loss after processing this batch is:  0.004092548042535782\n",
      "\n",
      "The classification loss after processing this batch is:  0.2415553778409958\n",
      "The representation loss after processing this batch is:  0.0037547126412391663\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.37953951954841614\n",
      "The representation loss after processing this batch is:  0.003478020429611206\n",
      "\n",
      "The classification loss after processing this batch is:  0.31251904368400574\n",
      "The representation loss after processing this batch is:  0.0031726211309432983\n",
      "\n",
      "The classification loss after processing this batch is:  0.2984688878059387\n",
      "The representation loss after processing this batch is:  0.0035357624292373657\n",
      "\n",
      "The classification loss after processing this batch is:  0.2942071259021759\n",
      "The representation loss after processing this batch is:  0.0032544583082199097\n",
      "\n",
      "The classification loss after processing this batch is:  0.28249022364616394\n",
      "The representation loss after processing this batch is:  0.00394158810377121\n",
      "\n",
      "The classification loss after processing this batch is:  0.2885337769985199\n",
      "The representation loss after processing this batch is:  0.003226138651371002\n",
      "\n",
      "The classification loss after processing this batch is:  0.27980655431747437\n",
      "The representation loss after processing this batch is:  0.0035403594374656677\n",
      "\n",
      "The classification loss after processing this batch is:  0.33852821588516235\n",
      "The representation loss after processing this batch is:  0.003973834216594696\n",
      "\n",
      "The classification loss after processing this batch is:  0.2437952160835266\n",
      "The representation loss after processing this batch is:  0.003700457513332367\n",
      "\n",
      "The classification loss after processing this batch is:  0.21937434375286102\n",
      "The representation loss after processing this batch is:  0.0033834055066108704\n",
      "\n",
      "The classification loss after processing this batch is:  0.24372373521327972\n",
      "The representation loss after processing this batch is:  0.0034335143864154816\n",
      "\n",
      "The classification loss after processing this batch is:  0.3151872456073761\n",
      "The representation loss after processing this batch is:  0.0029488354921340942\n",
      "\n",
      "The classification loss after processing this batch is:  0.19726307690143585\n",
      "The representation loss after processing this batch is:  0.0036879777908325195\n",
      "\n",
      "The classification loss after processing this batch is:  0.29105669260025024\n",
      "The representation loss after processing this batch is:  0.004072152078151703\n",
      "\n",
      "The classification loss after processing this batch is:  0.28901413083076477\n",
      "The representation loss after processing this batch is:  0.00322839617729187\n",
      "\n",
      "The classification loss after processing this batch is:  0.19548708200454712\n",
      "The representation loss after processing this batch is:  0.003994636237621307\n",
      "\n",
      "The classification loss after processing this batch is:  0.20701640844345093\n",
      "The representation loss after processing this batch is:  0.003985121846199036\n",
      "\n",
      "The classification loss after processing this batch is:  0.2695164382457733\n",
      "The representation loss after processing this batch is:  0.003832802176475525\n",
      "\n",
      "The classification loss after processing this batch is:  0.22972112894058228\n",
      "The representation loss after processing this batch is:  0.0037822797894477844\n",
      "\n",
      "The classification loss after processing this batch is:  0.26490047574043274\n",
      "The representation loss after processing this batch is:  0.0038833990693092346\n",
      "\n",
      "The classification loss after processing this batch is:  0.3251759111881256\n",
      "The representation loss after processing this batch is:  0.0036323554813861847\n",
      "\n",
      "The classification loss after processing this batch is:  0.23611371219158173\n",
      "The representation loss after processing this batch is:  0.00346287339925766\n",
      "\n",
      "The classification loss after processing this batch is:  0.3123897314071655\n",
      "The representation loss after processing this batch is:  0.0029523707926273346\n",
      "\n",
      "The classification loss after processing this batch is:  0.2660149931907654\n",
      "The representation loss after processing this batch is:  0.004043072462081909\n",
      "\n",
      "The classification loss after processing this batch is:  0.14478467404842377\n",
      "The representation loss after processing this batch is:  0.0038298219442367554\n",
      "\n",
      "The classification loss after processing this batch is:  0.20273561775684357\n",
      "The representation loss after processing this batch is:  0.003553323447704315\n",
      "\n",
      "The classification loss after processing this batch is:  0.2623905837535858\n",
      "The representation loss after processing this batch is:  0.0034220069646835327\n",
      "\n",
      "The classification loss after processing this batch is:  0.27179715037345886\n",
      "The representation loss after processing this batch is:  0.0034097284078598022\n",
      "\n",
      "The classification loss after processing this batch is:  0.23317664861679077\n",
      "The representation loss after processing this batch is:  0.0034995153546333313\n",
      "\n",
      "The classification loss after processing this batch is:  0.3053782284259796\n",
      "The representation loss after processing this batch is:  0.003614138811826706\n",
      "\n",
      "The classification loss after processing this batch is:  0.28761017322540283\n",
      "The representation loss after processing this batch is:  0.004198633134365082\n",
      "\n",
      "The classification loss after processing this batch is:  0.2547209858894348\n",
      "The representation loss after processing this batch is:  0.0036397092044353485\n",
      "\n",
      "The classification loss after processing this batch is:  0.36323052644729614\n",
      "The representation loss after processing this batch is:  0.003722742199897766\n",
      "\n",
      "The classification loss after processing this batch is:  0.290230393409729\n",
      "The representation loss after processing this batch is:  0.003497343510389328\n",
      "\n",
      "The classification loss after processing this batch is:  0.27713334560394287\n",
      "The representation loss after processing this batch is:  0.003646083176136017\n",
      "\n",
      "The classification loss after processing this batch is:  0.20239302515983582\n",
      "The representation loss after processing this batch is:  0.0042181238532066345\n",
      "\n",
      "The classification loss after processing this batch is:  0.17664340138435364\n",
      "The representation loss after processing this batch is:  0.0034846439957618713\n",
      "\n",
      "The classification loss after processing this batch is:  0.3908338248729706\n",
      "The representation loss after processing this batch is:  0.0032677985727787018\n",
      "\n",
      "The classification loss after processing this batch is:  0.3383968472480774\n",
      "The representation loss after processing this batch is:  0.00304354727268219\n",
      "\n",
      "The classification loss after processing this batch is:  0.34694868326187134\n",
      "The representation loss after processing this batch is:  0.0035488083958625793\n",
      "\n",
      "The classification loss after processing this batch is:  0.3513709306716919\n",
      "The representation loss after processing this batch is:  0.003572992980480194\n",
      "\n",
      "The classification loss after processing this batch is:  0.3182838559150696\n",
      "The representation loss after processing this batch is:  0.003717474639415741\n",
      "\n",
      "The classification loss after processing this batch is:  0.3188357651233673\n",
      "The representation loss after processing this batch is:  0.0032169371843338013\n",
      "\n",
      "The classification loss after processing this batch is:  0.3689132630825043\n",
      "The representation loss after processing this batch is:  0.003592953085899353\n",
      "\n",
      "The classification loss after processing this batch is:  0.3613217771053314\n",
      "The representation loss after processing this batch is:  0.0033132806420326233\n",
      "\n",
      "The classification loss after processing this batch is:  0.3770633637905121\n",
      "The representation loss after processing this batch is:  0.003470364958047867\n",
      "\n",
      "The classification loss after processing this batch is:  0.239472895860672\n",
      "The representation loss after processing this batch is:  0.003827296197414398\n",
      "\n",
      "The classification loss after processing this batch is:  0.17024390399456024\n",
      "The representation loss after processing this batch is:  0.003912895917892456\n",
      "\n",
      "The classification loss after processing this batch is:  0.23334963619709015\n",
      "The representation loss after processing this batch is:  0.00350923091173172\n",
      "\n",
      "The classification loss after processing this batch is:  0.28180772066116333\n",
      "The representation loss after processing this batch is:  0.003276132047176361\n",
      "\n",
      "The classification loss after processing this batch is:  0.2209451049566269\n",
      "The representation loss after processing this batch is:  0.003137793391942978\n",
      "\n",
      "The classification loss after processing this batch is:  0.2703399360179901\n",
      "The representation loss after processing this batch is:  0.0037335120141506195\n",
      "\n",
      "The classification loss after processing this batch is:  0.2568325400352478\n",
      "The representation loss after processing this batch is:  0.003251798450946808\n",
      "\n",
      "The classification loss after processing this batch is:  0.26443228125572205\n",
      "The representation loss after processing this batch is:  0.003388933837413788\n",
      "\n",
      "The classification loss after processing this batch is:  0.2505253553390503\n",
      "The representation loss after processing this batch is:  0.004112258553504944\n",
      "\n",
      "The classification loss after processing this batch is:  0.2166859209537506\n",
      "The representation loss after processing this batch is:  0.0032378509640693665\n",
      "\n",
      "The classification loss after processing this batch is:  0.24045056104660034\n",
      "The representation loss after processing this batch is:  0.003400459885597229\n",
      "\n",
      "The classification loss after processing this batch is:  0.2955654263496399\n",
      "The representation loss after processing this batch is:  0.003620244562625885\n",
      "\n",
      "The classification loss after processing this batch is:  0.3038153052330017\n",
      "The representation loss after processing this batch is:  0.0038906000554561615\n",
      "\n",
      "The classification loss after processing this batch is:  0.24434661865234375\n",
      "The representation loss after processing this batch is:  0.004204761236906052\n",
      "\n",
      "The classification loss after processing this batch is:  0.1861751675605774\n",
      "The representation loss after processing this batch is:  0.003667399287223816\n",
      "\n",
      "The classification loss after processing this batch is:  0.1781996339559555\n",
      "The representation loss after processing this batch is:  0.0034784525632858276\n",
      "\n",
      "The classification loss after processing this batch is:  0.30299457907676697\n",
      "The representation loss after processing this batch is:  0.0033682584762573242\n",
      "\n",
      "The classification loss after processing this batch is:  0.39120376110076904\n",
      "The representation loss after processing this batch is:  0.0030316151678562164\n",
      "\n",
      "The classification loss after processing this batch is:  0.2870100438594818\n",
      "The representation loss after processing this batch is:  0.0029409825801849365\n",
      "\n",
      "The classification loss after processing this batch is:  0.16501766443252563\n",
      "The representation loss after processing this batch is:  0.0032869651913642883\n",
      "\n",
      "The classification loss after processing this batch is:  0.30752047896385193\n",
      "The representation loss after processing this batch is:  0.002948649227619171\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1330871731042862\n",
      "The representation loss after processing this batch is:  0.003923185169696808\n",
      "\n",
      "The classification loss after processing this batch is:  0.25568142533302307\n",
      "The representation loss after processing this batch is:  0.0032043978571891785\n",
      "\n",
      "The classification loss after processing this batch is:  0.21741387248039246\n",
      "The representation loss after processing this batch is:  0.0037779435515403748\n",
      "\n",
      "The classification loss after processing this batch is:  0.15511268377304077\n",
      "The representation loss after processing this batch is:  0.003093905746936798\n",
      "\n",
      "The classification loss after processing this batch is:  0.18178482353687286\n",
      "The representation loss after processing this batch is:  0.00354168564081192\n",
      "\n",
      "The classification loss after processing this batch is:  0.1862984299659729\n",
      "The representation loss after processing this batch is:  0.0036728978157043457\n",
      "\n",
      "The classification loss after processing this batch is:  0.17117582261562347\n",
      "The representation loss after processing this batch is:  0.003353819251060486\n",
      "\n",
      "The classification loss after processing this batch is:  0.37265098094940186\n",
      "The representation loss after processing this batch is:  0.0032903142273426056\n",
      "\n",
      "The classification loss after processing this batch is:  0.39902782440185547\n",
      "The representation loss after processing this batch is:  0.003309205174446106\n",
      "\n",
      "The classification loss after processing this batch is:  0.30859375\n",
      "The representation loss after processing this batch is:  0.0035325735807418823\n",
      "\n",
      "The classification loss after processing this batch is:  0.3647244870662689\n",
      "The representation loss after processing this batch is:  0.003478921949863434\n",
      "\n",
      "The classification loss after processing this batch is:  0.27628734707832336\n",
      "The representation loss after processing this batch is:  0.0035634413361549377\n",
      "\n",
      "The classification loss after processing this batch is:  0.24369409680366516\n",
      "The representation loss after processing this batch is:  0.003624439239501953\n",
      "\n",
      "The classification loss after processing this batch is:  0.34303441643714905\n",
      "The representation loss after processing this batch is:  0.003882564604282379\n",
      "\n",
      "The classification loss after processing this batch is:  0.22993870079517365\n",
      "The representation loss after processing this batch is:  0.003820069134235382\n",
      "\n",
      "The classification loss after processing this batch is:  0.2988656163215637\n",
      "The representation loss after processing this batch is:  0.0033642612397670746\n",
      "\n",
      "The classification loss after processing this batch is:  0.2604891061782837\n",
      "The representation loss after processing this batch is:  0.003811940550804138\n",
      "\n",
      "The classification loss after processing this batch is:  0.29472842812538147\n",
      "The representation loss after processing this batch is:  0.003359265625476837\n",
      "\n",
      "The classification loss after processing this batch is:  0.2738209366798401\n",
      "The representation loss after processing this batch is:  0.0035820528864860535\n",
      "\n",
      "The classification loss after processing this batch is:  0.239919513463974\n",
      "The representation loss after processing this batch is:  0.004028983414173126\n",
      "\n",
      "The classification loss after processing this batch is:  0.32202258706092834\n",
      "The representation loss after processing this batch is:  0.0031915903091430664\n",
      "\n",
      "The classification loss after processing this batch is:  0.19924670457839966\n",
      "The representation loss after processing this batch is:  0.003962747752666473\n",
      "\n",
      "The classification loss after processing this batch is:  0.1837579607963562\n",
      "The representation loss after processing this batch is:  0.003398735076189041\n",
      "\n",
      "The classification loss after processing this batch is:  0.28034770488739014\n",
      "The representation loss after processing this batch is:  0.0032939985394477844\n",
      "\n",
      "The classification loss after processing this batch is:  0.3489746153354645\n",
      "The representation loss after processing this batch is:  0.0034950822591781616\n",
      "\n",
      "The classification loss after processing this batch is:  0.17742344737052917\n",
      "The representation loss after processing this batch is:  0.0033166632056236267\n",
      "\n",
      "The classification loss after processing this batch is:  0.22142232954502106\n",
      "The representation loss after processing this batch is:  0.003191981464624405\n",
      "\n",
      "The classification loss after processing this batch is:  0.3204464912414551\n",
      "The representation loss after processing this batch is:  0.0033662430942058563\n",
      "\n",
      "The classification loss after processing this batch is:  0.28975480794906616\n",
      "The representation loss after processing this batch is:  0.0032037943601608276\n",
      "\n",
      "The classification loss after processing this batch is:  0.2557680904865265\n",
      "The representation loss after processing this batch is:  0.0038271769881248474\n",
      "\n",
      "The classification loss after processing this batch is:  0.4256759583950043\n",
      "The representation loss after processing this batch is:  0.003014843910932541\n",
      "\n",
      "The classification loss after processing this batch is:  0.20717008411884308\n",
      "The representation loss after processing this batch is:  0.003734402358531952\n",
      "\n",
      "The classification loss after processing this batch is:  0.15904445946216583\n",
      "The representation loss after processing this batch is:  0.0030128657817840576\n",
      "\n",
      "The classification loss after processing this batch is:  0.18952162563800812\n",
      "The representation loss after processing this batch is:  0.003474511206150055\n",
      "\n",
      "The classification loss after processing this batch is:  0.2590354382991791\n",
      "The representation loss after processing this batch is:  0.0038810819387435913\n",
      "\n",
      "The classification loss after processing this batch is:  0.2520846128463745\n",
      "The representation loss after processing this batch is:  0.003729715943336487\n",
      "\n",
      "The classification loss after processing this batch is:  0.21279197931289673\n",
      "The representation loss after processing this batch is:  0.0037854164838790894\n",
      "\n",
      "The classification loss after processing this batch is:  0.25841954350471497\n",
      "The representation loss after processing this batch is:  0.0032748952507972717\n",
      "\n",
      "The classification loss after processing this batch is:  0.2655646502971649\n",
      "The representation loss after processing this batch is:  0.0033892355859279633\n",
      "\n",
      "The classification loss after processing this batch is:  0.2651047110557556\n",
      "The representation loss after processing this batch is:  0.0034264810383319855\n",
      "\n",
      "The classification loss after processing this batch is:  0.29451993107795715\n",
      "The representation loss after processing this batch is:  0.0031892843544483185\n",
      "\n",
      "The classification loss after processing this batch is:  0.37945613265037537\n",
      "The representation loss after processing this batch is:  0.00350889191031456\n",
      "\n",
      "The classification loss after processing this batch is:  0.3399427831172943\n",
      "The representation loss after processing this batch is:  0.0037887468934059143\n",
      "\n",
      "The classification loss after processing this batch is:  0.3910031020641327\n",
      "The representation loss after processing this batch is:  0.003111865371465683\n",
      "\n",
      "The classification loss after processing this batch is:  0.3227478265762329\n",
      "The representation loss after processing this batch is:  0.003439083695411682\n",
      "\n",
      "The classification loss after processing this batch is:  0.34839266538619995\n",
      "The representation loss after processing this batch is:  0.00349532812833786\n",
      "\n",
      "The classification loss after processing this batch is:  0.37420687079429626\n",
      "The representation loss after processing this batch is:  0.003285326063632965\n",
      "\n",
      "The classification loss after processing this batch is:  0.15234944224357605\n",
      "The representation loss after processing this batch is:  0.003327183425426483\n",
      "\n",
      "The classification loss after processing this batch is:  0.2837643325328827\n",
      "The representation loss after processing this batch is:  0.004111986607313156\n",
      "\n",
      "The classification loss after processing this batch is:  0.25089603662490845\n",
      "The representation loss after processing this batch is:  0.003675214946269989\n",
      "\n",
      "The classification loss after processing this batch is:  0.19424621760845184\n",
      "The representation loss after processing this batch is:  0.003864668309688568\n",
      "\n",
      "The classification loss after processing this batch is:  0.25832444429397583\n",
      "The representation loss after processing this batch is:  0.002954520285129547\n",
      "\n",
      "The classification loss after processing this batch is:  0.24795843660831451\n",
      "The representation loss after processing this batch is:  0.0034038759768009186\n",
      "\n",
      "The classification loss after processing this batch is:  0.2595251500606537\n",
      "The representation loss after processing this batch is:  0.0032637938857078552\n",
      "\n",
      "The classification loss after processing this batch is:  0.34637022018432617\n",
      "The representation loss after processing this batch is:  0.0029280930757522583\n",
      "\n",
      "The classification loss after processing this batch is:  0.33966976404190063\n",
      "The representation loss after processing this batch is:  0.0036102086305618286\n",
      "\n",
      "The classification loss after processing this batch is:  0.41025224328041077\n",
      "The representation loss after processing this batch is:  0.0034069865942001343\n",
      "\n",
      "The classification loss after processing this batch is:  0.30517563223838806\n",
      "The representation loss after processing this batch is:  0.003948889672756195\n",
      "\n",
      "The classification loss after processing this batch is:  0.33444079756736755\n",
      "The representation loss after processing this batch is:  0.0032320767641067505\n",
      "\n",
      "The classification loss after processing this batch is:  0.28950780630111694\n",
      "The representation loss after processing this batch is:  0.003247573971748352\n",
      "\n",
      "The classification loss after processing this batch is:  0.3386618196964264\n",
      "The representation loss after processing this batch is:  0.004277404397726059\n",
      "\n",
      "The classification loss after processing this batch is:  0.43663084506988525\n",
      "The representation loss after processing this batch is:  0.0038132071495056152\n",
      "\n",
      "The classification loss after processing this batch is:  0.14915138483047485\n",
      "The representation loss after processing this batch is:  0.003225613385438919\n",
      "\n",
      "The classification loss after processing this batch is:  0.14983227849006653\n",
      "The representation loss after processing this batch is:  0.003601856529712677\n",
      "\n",
      "The classification loss after processing this batch is:  0.37755629420280457\n",
      "The representation loss after processing this batch is:  0.003768526017665863\n",
      "\n",
      "The classification loss after processing this batch is:  0.18236973881721497\n",
      "The representation loss after processing this batch is:  0.0036000236868858337\n",
      "\n",
      "The classification loss after processing this batch is:  0.23589791357517242\n",
      "The representation loss after processing this batch is:  0.0030820369720458984\n",
      "\n",
      "The classification loss after processing this batch is:  0.2814764380455017\n",
      "The representation loss after processing this batch is:  0.0032832548022270203\n",
      "\n",
      "The classification loss after processing this batch is:  0.2982923090457916\n",
      "The representation loss after processing this batch is:  0.003468703478574753\n",
      "\n",
      "The classification loss after processing this batch is:  0.4662199020385742\n",
      "The representation loss after processing this batch is:  0.004080429673194885\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.4042713940143585\n",
      "The representation loss after processing this batch is:  0.003754459321498871\n",
      "\n",
      "The classification loss after processing this batch is:  0.36358413100242615\n",
      "The representation loss after processing this batch is:  0.004328019917011261\n",
      "\n",
      "The classification loss after processing this batch is:  0.20321711897850037\n",
      "The representation loss after processing this batch is:  0.0031280703842639923\n",
      "\n",
      "The classification loss after processing this batch is:  0.3542409837245941\n",
      "The representation loss after processing this batch is:  0.0029387101531028748\n",
      "\n",
      "The classification loss after processing this batch is:  0.18262876570224762\n",
      "The representation loss after processing this batch is:  0.003205418586730957\n",
      "\n",
      "The classification loss after processing this batch is:  0.15932942926883698\n",
      "The representation loss after processing this batch is:  0.0031743422150611877\n",
      "\n",
      "The classification loss after processing this batch is:  0.2320834994316101\n",
      "The representation loss after processing this batch is:  0.0032995939254760742\n",
      "\n",
      "The classification loss after processing this batch is:  0.14366261661052704\n",
      "The representation loss after processing this batch is:  0.003155134618282318\n",
      "\n",
      "The classification loss after processing this batch is:  0.22488822042942047\n",
      "The representation loss after processing this batch is:  0.0034446045756340027\n",
      "\n",
      "The classification loss after processing this batch is:  0.15817467868328094\n",
      "The representation loss after processing this batch is:  0.0033694058656692505\n",
      "\n",
      "The classification loss after processing this batch is:  0.1838073432445526\n",
      "The representation loss after processing this batch is:  0.003355804830789566\n",
      "\n",
      "The classification loss after processing this batch is:  0.23045669496059418\n",
      "The representation loss after processing this batch is:  0.003421638160943985\n",
      "\n",
      "The classification loss after processing this batch is:  0.3208497166633606\n",
      "The representation loss after processing this batch is:  0.003914646804332733\n",
      "\n",
      "The classification loss after processing this batch is:  0.3409353792667389\n",
      "The representation loss after processing this batch is:  0.0029699504375457764\n",
      "\n",
      "The classification loss after processing this batch is:  0.23995234072208405\n",
      "The representation loss after processing this batch is:  0.003657042980194092\n",
      "\n",
      "The classification loss after processing this batch is:  0.3089199662208557\n",
      "The representation loss after processing this batch is:  0.0034344494342803955\n",
      "\n",
      "The classification loss after processing this batch is:  0.1929170936346054\n",
      "The representation loss after processing this batch is:  0.003342844545841217\n",
      "\n",
      "The classification loss after processing this batch is:  0.30674049258232117\n",
      "The representation loss after processing this batch is:  0.0035270825028419495\n",
      "\n",
      "The classification loss after processing this batch is:  0.4880371689796448\n",
      "The representation loss after processing this batch is:  0.0034469962120056152\n",
      "\n",
      "The classification loss after processing this batch is:  0.3360888361930847\n",
      "The representation loss after processing this batch is:  0.0032011307775974274\n",
      "\n",
      "The classification loss after processing this batch is:  0.45013198256492615\n",
      "The representation loss after processing this batch is:  0.0032975897192955017\n",
      "\n",
      "The classification loss after processing this batch is:  0.31539857387542725\n",
      "The representation loss after processing this batch is:  0.003327794373035431\n",
      "\n",
      "The classification loss after processing this batch is:  0.3315509259700775\n",
      "The representation loss after processing this batch is:  0.0034274719655513763\n",
      "\n",
      "The classification loss after processing this batch is:  0.2647988200187683\n",
      "The representation loss after processing this batch is:  0.003389514982700348\n",
      "\n",
      "The classification loss after processing this batch is:  0.20286349952220917\n",
      "The representation loss after processing this batch is:  0.0031126514077186584\n",
      "\n",
      "The classification loss after processing this batch is:  0.21096518635749817\n",
      "The representation loss after processing this batch is:  0.0034102946519851685\n",
      "\n",
      "The classification loss after processing this batch is:  0.170327827334404\n",
      "The representation loss after processing this batch is:  0.003552548587322235\n",
      "\n",
      "The classification loss after processing this batch is:  0.15526561439037323\n",
      "The representation loss after processing this batch is:  0.0033948495984077454\n",
      "\n",
      "The classification loss after processing this batch is:  0.283998042345047\n",
      "The representation loss after processing this batch is:  0.0032663121819496155\n",
      "\n",
      "The classification loss after processing this batch is:  0.19372870028018951\n",
      "The representation loss after processing this batch is:  0.003646939992904663\n",
      "\n",
      "The classification loss after processing this batch is:  0.40783676505088806\n",
      "The representation loss after processing this batch is:  0.003611009567975998\n",
      "\n",
      "The classification loss after processing this batch is:  0.27453771233558655\n",
      "The representation loss after processing this batch is:  0.0033465251326560974\n",
      "\n",
      "The classification loss after processing this batch is:  0.2682782709598541\n",
      "The representation loss after processing this batch is:  0.0032113753259181976\n",
      "\n",
      "The classification loss after processing this batch is:  0.4558604955673218\n",
      "The representation loss after processing this batch is:  0.00322907418012619\n",
      "\n",
      "The classification loss after processing this batch is:  0.31468665599823\n",
      "The representation loss after processing this batch is:  0.0031217262148857117\n",
      "\n",
      "The classification loss after processing this batch is:  0.16990476846694946\n",
      "The representation loss after processing this batch is:  0.0033237971365451813\n",
      "\n",
      "The classification loss after processing this batch is:  0.1523008644580841\n",
      "The representation loss after processing this batch is:  0.0039671361446380615\n",
      "\n",
      "The classification loss after processing this batch is:  0.18499211966991425\n",
      "The representation loss after processing this batch is:  0.0034148022532463074\n",
      "\n",
      "The classification loss after processing this batch is:  0.18625853955745697\n",
      "The representation loss after processing this batch is:  0.00376979261636734\n",
      "\n",
      "The classification loss after processing this batch is:  0.22106832265853882\n",
      "The representation loss after processing this batch is:  0.00279814749956131\n",
      "\n",
      "The classification loss after processing this batch is:  0.4443763196468353\n",
      "The representation loss after processing this batch is:  0.0030233152210712433\n",
      "\n",
      "The classification loss after processing this batch is:  0.43675878643989563\n",
      "The representation loss after processing this batch is:  0.003283865749835968\n",
      "\n",
      "The classification loss after processing this batch is:  0.22776482999324799\n",
      "The representation loss after processing this batch is:  0.0034860074520111084\n",
      "\n",
      "The classification loss after processing this batch is:  0.3514482378959656\n",
      "The representation loss after processing this batch is:  0.0036271288990974426\n",
      "\n",
      "The classification loss after processing this batch is:  0.16261106729507446\n",
      "The representation loss after processing this batch is:  0.003138519823551178\n",
      "\n",
      "The classification loss after processing this batch is:  0.21927191317081451\n",
      "The representation loss after processing this batch is:  0.003429785370826721\n",
      "\n",
      "The classification loss after processing this batch is:  0.3814135193824768\n",
      "The representation loss after processing this batch is:  0.003116253763437271\n",
      "\n",
      "The classification loss after processing this batch is:  0.2412918657064438\n",
      "The representation loss after processing this batch is:  0.004151444882154465\n",
      "\n",
      "The classification loss after processing this batch is:  0.24428656697273254\n",
      "The representation loss after processing this batch is:  0.004673510789871216\n",
      "\n",
      "The classification loss after processing this batch is:  0.2039954513311386\n",
      "The representation loss after processing this batch is:  0.0037271976470947266\n",
      "\n",
      "The classification loss after processing this batch is:  0.31767329573631287\n",
      "The representation loss after processing this batch is:  0.003634244203567505\n",
      "\n",
      "The classification loss after processing this batch is:  0.3269089460372925\n",
      "The representation loss after processing this batch is:  0.004134766757488251\n",
      "\n",
      "The classification loss after processing this batch is:  0.2929677367210388\n",
      "The representation loss after processing this batch is:  0.0036997422575950623\n",
      "\n",
      "The classification loss after processing this batch is:  0.27416518330574036\n",
      "The representation loss after processing this batch is:  0.0036029890179634094\n",
      "\n",
      "The classification loss after processing this batch is:  0.3429103195667267\n",
      "The representation loss after processing this batch is:  0.0030228346586227417\n",
      "\n",
      "The classification loss after processing this batch is:  0.3094330132007599\n",
      "The representation loss after processing this batch is:  0.003200314939022064\n",
      "\n",
      "The classification loss after processing this batch is:  0.26161277294158936\n",
      "The representation loss after processing this batch is:  0.0036249831318855286\n",
      "\n",
      "The classification loss after processing this batch is:  0.18488097190856934\n",
      "The representation loss after processing this batch is:  0.003717869520187378\n",
      "\n",
      "The classification loss after processing this batch is:  0.12560246884822845\n",
      "The representation loss after processing this batch is:  0.003550425171852112\n",
      "\n",
      "The classification loss after processing this batch is:  0.2723517119884491\n",
      "The representation loss after processing this batch is:  0.0034578368067741394\n",
      "\n",
      "The classification loss after processing this batch is:  0.21758933365345\n",
      "The representation loss after processing this batch is:  0.003766007721424103\n",
      "\n",
      "The classification loss after processing this batch is:  0.3888702988624573\n",
      "The representation loss after processing this batch is:  0.0029582083225250244\n",
      "\n",
      "The classification loss after processing this batch is:  0.14984560012817383\n",
      "The representation loss after processing this batch is:  0.003917142748832703\n",
      "\n",
      "The classification loss after processing this batch is:  0.21636508405208588\n",
      "The representation loss after processing this batch is:  0.003613673150539398\n",
      "\n",
      "The classification loss after processing this batch is:  0.3024434447288513\n",
      "The representation loss after processing this batch is:  0.0038691461086273193\n",
      "\n",
      "The classification loss after processing this batch is:  0.2540225684642792\n",
      "The representation loss after processing this batch is:  0.003560580313205719\n",
      "\n",
      "The classification loss after processing this batch is:  0.2999981641769409\n",
      "The representation loss after processing this batch is:  0.00364656001329422\n",
      "\n",
      "The classification loss after processing this batch is:  0.15771985054016113\n",
      "The representation loss after processing this batch is:  0.0034735724329948425\n",
      "\n",
      "The classification loss after processing this batch is:  0.1639811247587204\n",
      "The representation loss after processing this batch is:  0.0033071674406528473\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.16923853754997253\n",
      "The representation loss after processing this batch is:  0.0034313462674617767\n",
      "\n",
      "The classification loss after processing this batch is:  0.2785544991493225\n",
      "The representation loss after processing this batch is:  0.003944478929042816\n",
      "\n",
      "The classification loss after processing this batch is:  0.2977491617202759\n",
      "The representation loss after processing this batch is:  0.0033882521092891693\n",
      "\n",
      "The classification loss after processing this batch is:  0.2915535271167755\n",
      "The representation loss after processing this batch is:  0.003085888922214508\n",
      "\n",
      "The classification loss after processing this batch is:  0.3418387174606323\n",
      "The representation loss after processing this batch is:  0.0030561089515686035\n",
      "\n",
      "The classification loss after processing this batch is:  0.41577911376953125\n",
      "The representation loss after processing this batch is:  0.0033413395285606384\n",
      "\n",
      "The classification loss after processing this batch is:  0.26809826493263245\n",
      "The representation loss after processing this batch is:  0.0036818236112594604\n",
      "\n",
      "The classification loss after processing this batch is:  0.38782933354377747\n",
      "The representation loss after processing this batch is:  0.0035065077245235443\n",
      "\n",
      "The classification loss after processing this batch is:  0.23660778999328613\n",
      "The representation loss after processing this batch is:  0.003477618098258972\n",
      "\n",
      "The classification loss after processing this batch is:  0.1601509004831314\n",
      "The representation loss after processing this batch is:  0.003367029130458832\n",
      "\n",
      "The classification loss after processing this batch is:  0.152542844414711\n",
      "The representation loss after processing this batch is:  0.0031683743000030518\n",
      "\n",
      "The classification loss after processing this batch is:  0.1598382443189621\n",
      "The representation loss after processing this batch is:  0.003486931324005127\n",
      "\n",
      "The classification loss after processing this batch is:  0.3650813400745392\n",
      "The representation loss after processing this batch is:  0.0037601590156555176\n",
      "\n",
      "The classification loss after processing this batch is:  0.1986408233642578\n",
      "The representation loss after processing this batch is:  0.0032185912132263184\n",
      "\n",
      "The classification loss after processing this batch is:  0.24772948026657104\n",
      "The representation loss after processing this batch is:  0.003814905881881714\n",
      "\n",
      "The classification loss after processing this batch is:  0.2409793585538864\n",
      "The representation loss after processing this batch is:  0.004015512764453888\n",
      "\n",
      "The classification loss after processing this batch is:  0.25085994601249695\n",
      "The representation loss after processing this batch is:  0.003449857234954834\n",
      "\n",
      "The classification loss after processing this batch is:  0.20767582952976227\n",
      "The representation loss after processing this batch is:  0.003251902759075165\n",
      "\n",
      "The classification loss after processing this batch is:  0.2400098741054535\n",
      "The representation loss after processing this batch is:  0.0030808448791503906\n",
      "\n",
      "The classification loss after processing this batch is:  0.30627766251564026\n",
      "The representation loss after processing this batch is:  0.0030919015407562256\n",
      "\n",
      "The classification loss after processing this batch is:  0.3129655718803406\n",
      "The representation loss after processing this batch is:  0.0036463215947151184\n",
      "\n",
      "The classification loss after processing this batch is:  0.17304280400276184\n",
      "The representation loss after processing this batch is:  0.0031883008778095245\n",
      "\n",
      "The classification loss after processing this batch is:  0.38469797372817993\n",
      "The representation loss after processing this batch is:  0.002722848206758499\n",
      "\n",
      "The classification loss after processing this batch is:  0.26255175471305847\n",
      "The representation loss after processing this batch is:  0.00318063423037529\n",
      "\n",
      "The classification loss after processing this batch is:  0.23262377083301544\n",
      "The representation loss after processing this batch is:  0.002997610718011856\n",
      "\n",
      "The classification loss after processing this batch is:  0.21536840498447418\n",
      "The representation loss after processing this batch is:  0.0034895017743110657\n",
      "\n",
      "The classification loss after processing this batch is:  0.19405892491340637\n",
      "The representation loss after processing this batch is:  0.0032411888241767883\n",
      "\n",
      "The classification loss after processing this batch is:  0.1645369529724121\n",
      "The representation loss after processing this batch is:  0.0034261271357536316\n",
      "\n",
      "The classification loss after processing this batch is:  0.174378901720047\n",
      "The representation loss after processing this batch is:  0.0035622194409370422\n",
      "\n",
      "The classification loss after processing this batch is:  0.29685765504837036\n",
      "The representation loss after processing this batch is:  0.0035525672137737274\n",
      "\n",
      "The classification loss after processing this batch is:  0.34944412112236023\n",
      "The representation loss after processing this batch is:  0.0035699158906936646\n",
      "\n",
      "The classification loss after processing this batch is:  0.29036659002304077\n",
      "The representation loss after processing this batch is:  0.0035324841737747192\n",
      "\n",
      "The classification loss after processing this batch is:  0.2980622947216034\n",
      "The representation loss after processing this batch is:  0.0034691616892814636\n",
      "\n",
      "The classification loss after processing this batch is:  0.26201727986335754\n",
      "The representation loss after processing this batch is:  0.003922298550605774\n",
      "\n",
      "The classification loss after processing this batch is:  0.3783330023288727\n",
      "The representation loss after processing this batch is:  0.0029486864805221558\n",
      "\n",
      "The classification loss after processing this batch is:  0.2538679242134094\n",
      "The representation loss after processing this batch is:  0.003105461597442627\n",
      "\n",
      "The classification loss after processing this batch is:  0.11383913457393646\n",
      "The representation loss after processing this batch is:  0.0033991485834121704\n",
      "\n",
      "The classification loss after processing this batch is:  0.2300996333360672\n",
      "The representation loss after processing this batch is:  0.0032323673367500305\n",
      "\n",
      "The classification loss after processing this batch is:  0.4780735671520233\n",
      "The representation loss after processing this batch is:  0.003365829586982727\n",
      "\n",
      "The classification loss after processing this batch is:  0.48064565658569336\n",
      "The representation loss after processing this batch is:  0.0032645314931869507\n",
      "\n",
      "The classification loss after processing this batch is:  0.45088714361190796\n",
      "The representation loss after processing this batch is:  0.0032987557351589203\n",
      "\n",
      "The classification loss after processing this batch is:  0.31069061160087585\n",
      "The representation loss after processing this batch is:  0.0032477229833602905\n",
      "\n",
      "The classification loss after processing this batch is:  0.23089417815208435\n",
      "The representation loss after processing this batch is:  0.0032243579626083374\n",
      "\n",
      "The classification loss after processing this batch is:  0.2046165019273758\n",
      "The representation loss after processing this batch is:  0.0033334866166114807\n",
      "\n",
      "The classification loss after processing this batch is:  0.21615852415561676\n",
      "The representation loss after processing this batch is:  0.003874000161886215\n",
      "\n",
      "The classification loss after processing this batch is:  0.3071666359901428\n",
      "The representation loss after processing this batch is:  0.003809131681919098\n",
      "\n",
      "The classification loss after processing this batch is:  0.25177526473999023\n",
      "The representation loss after processing this batch is:  0.0037054643034934998\n",
      "\n",
      "The classification loss after processing this batch is:  0.28597766160964966\n",
      "The representation loss after processing this batch is:  0.004264131188392639\n",
      "\n",
      "The classification loss after processing this batch is:  0.25657516717910767\n",
      "The representation loss after processing this batch is:  0.0033537372946739197\n",
      "\n",
      "The classification loss after processing this batch is:  0.230322927236557\n",
      "The representation loss after processing this batch is:  0.0031872615218162537\n",
      "\n",
      "The classification loss after processing this batch is:  0.2736970782279968\n",
      "The representation loss after processing this batch is:  0.004031874239444733\n",
      "\n",
      "The classification loss after processing this batch is:  0.3215456008911133\n",
      "The representation loss after processing this batch is:  0.0033121630549430847\n",
      "\n",
      "The classification loss after processing this batch is:  0.24999380111694336\n",
      "The representation loss after processing this batch is:  0.0030172280967235565\n",
      "\n",
      "The classification loss after processing this batch is:  0.45310693979263306\n",
      "The representation loss after processing this batch is:  0.003851722925901413\n",
      "\n",
      "The classification loss after processing this batch is:  0.4871276319026947\n",
      "The representation loss after processing this batch is:  0.0035296007990837097\n",
      "\n",
      "The classification loss after processing this batch is:  0.3036850094795227\n",
      "The representation loss after processing this batch is:  0.0036588460206985474\n",
      "\n",
      "The classification loss after processing this batch is:  0.29141750931739807\n",
      "The representation loss after processing this batch is:  0.00365622341632843\n",
      "\n",
      "The classification loss after processing this batch is:  0.22986173629760742\n",
      "The representation loss after processing this batch is:  0.003812551498413086\n",
      "\n",
      "The classification loss after processing this batch is:  0.1473073959350586\n",
      "The representation loss after processing this batch is:  0.0031515806913375854\n",
      "\n",
      "The classification loss after processing this batch is:  0.3676419258117676\n",
      "The representation loss after processing this batch is:  0.0031655803322792053\n",
      "\n",
      "The classification loss after processing this batch is:  0.2750687897205353\n",
      "The representation loss after processing this batch is:  0.0038846805691719055\n",
      "\n",
      "The classification loss after processing this batch is:  0.21529299020767212\n",
      "The representation loss after processing this batch is:  0.0038753673434257507\n",
      "\n",
      "The classification loss after processing this batch is:  0.3607066869735718\n",
      "The representation loss after processing this batch is:  0.0031466111540794373\n",
      "\n",
      "The classification loss after processing this batch is:  0.14260171353816986\n",
      "The representation loss after processing this batch is:  0.0030499808490276337\n",
      "\n",
      "The classification loss after processing this batch is:  0.1843985617160797\n",
      "The representation loss after processing this batch is:  0.003455840051174164\n",
      "\n",
      "The classification loss after processing this batch is:  0.22987309098243713\n",
      "The representation loss after processing this batch is:  0.003010861575603485\n",
      "\n",
      "The classification loss after processing this batch is:  0.329108864068985\n",
      "The representation loss after processing this batch is:  0.0031500495970249176\n",
      "\n",
      "The classification loss after processing this batch is:  0.3279171586036682\n",
      "The representation loss after processing this batch is:  0.0033355355262756348\n",
      "\n",
      "The classification loss after processing this batch is:  0.20661643147468567\n",
      "The representation loss after processing this batch is:  0.0034420043230056763\n",
      "\n",
      "The classification loss after processing this batch is:  0.21607576310634613\n",
      "The representation loss after processing this batch is:  0.0034580230712890625\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.12768305838108063\n",
      "The representation loss after processing this batch is:  0.003159821033477783\n",
      "\n",
      "The classification loss after processing this batch is:  0.16675134003162384\n",
      "The representation loss after processing this batch is:  0.003153979778289795\n",
      "\n",
      "The classification loss after processing this batch is:  0.17696210741996765\n",
      "The representation loss after processing this batch is:  0.003261275589466095\n",
      "\n",
      "The classification loss after processing this batch is:  0.15011145174503326\n",
      "The representation loss after processing this batch is:  0.003326892852783203\n",
      "\n",
      "The classification loss after processing this batch is:  0.2320438027381897\n",
      "The representation loss after processing this batch is:  0.002829458564519882\n",
      "\n",
      "The classification loss after processing this batch is:  0.22980280220508575\n",
      "The representation loss after processing this batch is:  0.003177538514137268\n",
      "\n",
      "The classification loss after processing this batch is:  0.29901596903800964\n",
      "The representation loss after processing this batch is:  0.0037664473056793213\n",
      "\n",
      "The classification loss after processing this batch is:  0.12832827866077423\n",
      "The representation loss after processing this batch is:  0.002598132938146591\n",
      "\n",
      "The classification loss after processing this batch is:  0.1714257150888443\n",
      "The representation loss after processing this batch is:  0.0032705888152122498\n",
      "\n",
      "The classification loss after processing this batch is:  0.19030806422233582\n",
      "The representation loss after processing this batch is:  0.0038890689611434937\n",
      "\n",
      "The classification loss after processing this batch is:  0.2920721769332886\n",
      "The representation loss after processing this batch is:  0.0031591802835464478\n",
      "\n",
      "The classification loss after processing this batch is:  0.16379033029079437\n",
      "The representation loss after processing this batch is:  0.0036064311861991882\n",
      "\n",
      "The classification loss after processing this batch is:  0.44393137097358704\n",
      "The representation loss after processing this batch is:  0.0038425251841545105\n",
      "\n",
      "The classification loss after processing this batch is:  0.3645224869251251\n",
      "The representation loss after processing this batch is:  0.003644615411758423\n",
      "\n",
      "The classification loss after processing this batch is:  0.3501035273075104\n",
      "The representation loss after processing this batch is:  0.003203481435775757\n",
      "\n",
      "The classification loss after processing this batch is:  0.2175264060497284\n",
      "The representation loss after processing this batch is:  0.0032445937395095825\n",
      "\n",
      "The classification loss after processing this batch is:  0.1855718493461609\n",
      "The representation loss after processing this batch is:  0.0033195391297340393\n",
      "\n",
      "The classification loss after processing this batch is:  0.23923549056053162\n",
      "The representation loss after processing this batch is:  0.0034518688917160034\n",
      "\n",
      "The classification loss after processing this batch is:  0.26908934116363525\n",
      "The representation loss after processing this batch is:  0.003338463604450226\n",
      "\n",
      "The classification loss after processing this batch is:  0.1754431426525116\n",
      "The representation loss after processing this batch is:  0.003231443464756012\n",
      "\n",
      "The classification loss after processing this batch is:  0.1029169112443924\n",
      "The representation loss after processing this batch is:  0.0030562058091163635\n",
      "\n",
      "The classification loss after processing this batch is:  0.30797943472862244\n",
      "The representation loss after processing this batch is:  0.0034212395548820496\n",
      "\n",
      "The classification loss after processing this batch is:  0.31501343846321106\n",
      "The representation loss after processing this batch is:  0.0032235458493232727\n",
      "\n",
      "The classification loss after processing this batch is:  0.29550275206565857\n",
      "The representation loss after processing this batch is:  0.003239758312702179\n",
      "\n",
      "The classification loss after processing this batch is:  0.3504243493080139\n",
      "The representation loss after processing this batch is:  0.003138534724712372\n",
      "\n",
      "The classification loss after processing this batch is:  0.368950754404068\n",
      "The representation loss after processing this batch is:  0.0036572515964508057\n",
      "\n",
      "The classification loss after processing this batch is:  0.5272242426872253\n",
      "The representation loss after processing this batch is:  0.0032730549573898315\n",
      "\n",
      "The classification loss after processing this batch is:  0.31903907656669617\n",
      "The representation loss after processing this batch is:  0.0032199695706367493\n",
      "\n",
      "The classification loss after processing this batch is:  0.2044287621974945\n",
      "The representation loss after processing this batch is:  0.0033898651599884033\n",
      "\n",
      "The classification loss after processing this batch is:  0.3245323896408081\n",
      "The representation loss after processing this batch is:  0.0034153014421463013\n",
      "\n",
      "The classification loss after processing this batch is:  0.2226955145597458\n",
      "The representation loss after processing this batch is:  0.003313504159450531\n",
      "\n",
      "The classification loss after processing this batch is:  0.22956307232379913\n",
      "The representation loss after processing this batch is:  0.0033190324902534485\n",
      "\n",
      "The classification loss after processing this batch is:  0.18042872846126556\n",
      "The representation loss after processing this batch is:  0.0034156590700149536\n",
      "\n",
      "The classification loss after processing this batch is:  0.17059847712516785\n",
      "The representation loss after processing this batch is:  0.003010265529155731\n",
      "\n",
      "The classification loss after processing this batch is:  0.12891189754009247\n",
      "The representation loss after processing this batch is:  0.003709934651851654\n",
      "\n",
      "The classification loss after processing this batch is:  0.28804972767829895\n",
      "The representation loss after processing this batch is:  0.0031854063272476196\n",
      "\n",
      "The classification loss after processing this batch is:  0.3376786410808563\n",
      "The representation loss after processing this batch is:  0.003028467297554016\n",
      "\n",
      "The classification loss after processing this batch is:  0.173289954662323\n",
      "The representation loss after processing this batch is:  0.003525085747241974\n",
      "\n",
      "The classification loss after processing this batch is:  0.2112363874912262\n",
      "The representation loss after processing this batch is:  0.003112807869911194\n",
      "\n",
      "The classification loss after processing this batch is:  0.22476600110530853\n",
      "The representation loss after processing this batch is:  0.003410547971725464\n",
      "\n",
      "The classification loss after processing this batch is:  0.1121089830994606\n",
      "The representation loss after processing this batch is:  0.0032673776149749756\n",
      "\n",
      "The classification loss after processing this batch is:  0.365421861410141\n",
      "The representation loss after processing this batch is:  0.003095574676990509\n",
      "\n",
      "The classification loss after processing this batch is:  0.21843571960926056\n",
      "The representation loss after processing this batch is:  0.0030798688530921936\n",
      "\n",
      "The classification loss after processing this batch is:  0.32913145422935486\n",
      "The representation loss after processing this batch is:  0.00345713272690773\n",
      "\n",
      "The classification loss after processing this batch is:  0.29461997747421265\n",
      "The representation loss after processing this batch is:  0.0034185945987701416\n",
      "\n",
      "The classification loss after processing this batch is:  0.35017916560173035\n",
      "The representation loss after processing this batch is:  0.003257911652326584\n",
      "\n",
      "The classification loss after processing this batch is:  0.11018189787864685\n",
      "The representation loss after processing this batch is:  0.003244873136281967\n",
      "\n",
      "The classification loss after processing this batch is:  0.14232918620109558\n",
      "The representation loss after processing this batch is:  0.0031921863555908203\n",
      "\n",
      "The classification loss after processing this batch is:  0.2594960033893585\n",
      "The representation loss after processing this batch is:  0.0031739845871925354\n",
      "\n",
      "The classification loss after processing this batch is:  0.15794596076011658\n",
      "The representation loss after processing this batch is:  0.0034880265593528748\n",
      "\n",
      "The classification loss after processing this batch is:  0.3257083594799042\n",
      "The representation loss after processing this batch is:  0.0036824941635131836\n",
      "\n",
      "The classification loss after processing this batch is:  0.17664165794849396\n",
      "The representation loss after processing this batch is:  0.003525383770465851\n",
      "\n",
      "The classification loss after processing this batch is:  0.25861284136772156\n",
      "The representation loss after processing this batch is:  0.003618840128183365\n",
      "\n",
      "The classification loss after processing this batch is:  0.2960672974586487\n",
      "The representation loss after processing this batch is:  0.0032341554760932922\n",
      "\n",
      "The classification loss after processing this batch is:  0.1949939727783203\n",
      "The representation loss after processing this batch is:  0.0035204514861106873\n",
      "\n",
      "The classification loss after processing this batch is:  0.18439935147762299\n",
      "The representation loss after processing this batch is:  0.003742590546607971\n",
      "\n",
      "The classification loss after processing this batch is:  0.3095594644546509\n",
      "The representation loss after processing this batch is:  0.003450930118560791\n",
      "\n",
      "The classification loss after processing this batch is:  0.23932763934135437\n",
      "The representation loss after processing this batch is:  0.0037132203578948975\n",
      "\n",
      "The classification loss after processing this batch is:  0.34589341282844543\n",
      "The representation loss after processing this batch is:  0.003744371235370636\n",
      "\n",
      "The classification loss after processing this batch is:  0.3592066466808319\n",
      "The representation loss after processing this batch is:  0.0035041794180870056\n",
      "\n",
      "The classification loss after processing this batch is:  0.3435170352458954\n",
      "The representation loss after processing this batch is:  0.0032173320651054382\n",
      "\n",
      "The classification loss after processing this batch is:  0.18413019180297852\n",
      "The representation loss after processing this batch is:  0.0035215988755226135\n",
      "\n",
      "The classification loss after processing this batch is:  0.1623421460390091\n",
      "The representation loss after processing this batch is:  0.003314882516860962\n",
      "\n",
      "The classification loss after processing this batch is:  0.1591254323720932\n",
      "The representation loss after processing this batch is:  0.003526933491230011\n",
      "\n",
      "The classification loss after processing this batch is:  0.16821768879890442\n",
      "The representation loss after processing this batch is:  0.003940403461456299\n",
      "\n",
      "The classification loss after processing this batch is:  0.27117207646369934\n",
      "The representation loss after processing this batch is:  0.002873554825782776\n",
      "\n",
      "The classification loss after processing this batch is:  0.2253216803073883\n",
      "The representation loss after processing this batch is:  0.0035309866070747375\n",
      "\n",
      "The classification loss after processing this batch is:  0.2528873085975647\n",
      "The representation loss after processing this batch is:  0.0035924166440963745\n",
      "\n",
      "The classification loss after processing this batch is:  0.17918625473976135\n",
      "The representation loss after processing this batch is:  0.0031470060348510742\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.25065886974334717\n",
      "The representation loss after processing this batch is:  0.0030169636011123657\n",
      "\n",
      "The classification loss after processing this batch is:  0.20621098577976227\n",
      "The representation loss after processing this batch is:  0.0033199340105056763\n",
      "\n",
      "The classification loss after processing this batch is:  0.24069984257221222\n",
      "The representation loss after processing this batch is:  0.003264985978603363\n",
      "\n",
      "The classification loss after processing this batch is:  0.28472474217414856\n",
      "The representation loss after processing this batch is:  0.0033317282795906067\n",
      "\n",
      "The classification loss after processing this batch is:  0.23759451508522034\n",
      "The representation loss after processing this batch is:  0.0033056288957595825\n",
      "\n",
      "The classification loss after processing this batch is:  0.20892399549484253\n",
      "The representation loss after processing this batch is:  0.003364957869052887\n",
      "\n",
      "The classification loss after processing this batch is:  0.29645881056785583\n",
      "The representation loss after processing this batch is:  0.0038424208760261536\n",
      "\n",
      "The classification loss after processing this batch is:  0.13666775822639465\n",
      "The representation loss after processing this batch is:  0.003473319113254547\n",
      "\n",
      "The classification loss after processing this batch is:  0.15981429815292358\n",
      "The representation loss after processing this batch is:  0.003093935549259186\n",
      "\n",
      "The classification loss after processing this batch is:  0.21167443692684174\n",
      "The representation loss after processing this batch is:  0.0031448006629943848\n",
      "\n",
      "The classification loss after processing this batch is:  0.18415307998657227\n",
      "The representation loss after processing this batch is:  0.003614947199821472\n",
      "\n",
      "The classification loss after processing this batch is:  0.2959306538105011\n",
      "The representation loss after processing this batch is:  0.002955060452222824\n",
      "\n",
      "The classification loss after processing this batch is:  0.30354681611061096\n",
      "The representation loss after processing this batch is:  0.003182545304298401\n",
      "\n",
      "The classification loss after processing this batch is:  0.25023096799850464\n",
      "The representation loss after processing this batch is:  0.0038951411843299866\n",
      "\n",
      "The classification loss after processing this batch is:  0.18164797127246857\n",
      "The representation loss after processing this batch is:  0.00368286669254303\n",
      "\n",
      "The classification loss after processing this batch is:  0.17688100039958954\n",
      "The representation loss after processing this batch is:  0.0035855919122695923\n",
      "\n",
      "The classification loss after processing this batch is:  0.4089680314064026\n",
      "The representation loss after processing this batch is:  0.0033889710903167725\n",
      "\n",
      "The classification loss after processing this batch is:  0.1422000527381897\n",
      "The representation loss after processing this batch is:  0.0035167112946510315\n",
      "\n",
      "The classification loss after processing this batch is:  0.22043552994728088\n",
      "The representation loss after processing this batch is:  0.0037227272987365723\n",
      "\n",
      "The classification loss after processing this batch is:  0.2969115674495697\n",
      "The representation loss after processing this batch is:  0.00302906334400177\n",
      "\n",
      "The classification loss after processing this batch is:  0.3981967866420746\n",
      "The representation loss after processing this batch is:  0.0034411922097206116\n",
      "\n",
      "The classification loss after processing this batch is:  0.20220880210399628\n",
      "The representation loss after processing this batch is:  0.0034186094999313354\n",
      "\n",
      "The classification loss after processing this batch is:  0.26836761832237244\n",
      "The representation loss after processing this batch is:  0.0031810030341148376\n",
      "\n",
      "The classification loss after processing this batch is:  0.1899978369474411\n",
      "The representation loss after processing this batch is:  0.002988263964653015\n",
      "\n",
      "The classification loss after processing this batch is:  0.12358318269252777\n",
      "The representation loss after processing this batch is:  0.0036033615469932556\n",
      "\n",
      "The classification loss after processing this batch is:  0.2695242762565613\n",
      "The representation loss after processing this batch is:  0.003911629319190979\n",
      "\n",
      "The classification loss after processing this batch is:  0.2021767497062683\n",
      "The representation loss after processing this batch is:  0.004138737916946411\n",
      "\n",
      "The classification loss after processing this batch is:  0.12976036965847015\n",
      "The representation loss after processing this batch is:  0.003465622663497925\n",
      "\n",
      "The classification loss after processing this batch is:  0.19464001059532166\n",
      "The representation loss after processing this batch is:  0.0030310899019241333\n",
      "\n",
      "The classification loss after processing this batch is:  0.2823922038078308\n",
      "The representation loss after processing this batch is:  0.0030206218361854553\n",
      "\n",
      "The classification loss after processing this batch is:  0.2840871512889862\n",
      "The representation loss after processing this batch is:  0.003121212124824524\n",
      "\n",
      "The classification loss after processing this batch is:  0.20162202417850494\n",
      "The representation loss after processing this batch is:  0.0028606057167053223\n",
      "\n",
      "The classification loss after processing this batch is:  0.2976689338684082\n",
      "The representation loss after processing this batch is:  0.0029516443610191345\n",
      "\n",
      "The classification loss after processing this batch is:  0.29194337129592896\n",
      "The representation loss after processing this batch is:  0.0029709674417972565\n",
      "\n",
      "The classification loss after processing this batch is:  0.31641659140586853\n",
      "The representation loss after processing this batch is:  0.0034432262182235718\n",
      "\n",
      "The classification loss after processing this batch is:  0.28949230909347534\n",
      "The representation loss after processing this batch is:  0.0028872378170490265\n",
      "\n",
      "The classification loss after processing this batch is:  0.30616867542266846\n",
      "The representation loss after processing this batch is:  0.0038082674145698547\n",
      "\n",
      "The classification loss after processing this batch is:  0.42621171474456787\n",
      "The representation loss after processing this batch is:  0.0032579973340034485\n",
      "\n",
      "The classification loss after processing this batch is:  0.17669972777366638\n",
      "The representation loss after processing this batch is:  0.0034875422716140747\n",
      "\n",
      "The classification loss after processing this batch is:  0.15567633509635925\n",
      "The representation loss after processing this batch is:  0.0035488158464431763\n",
      "\n",
      "The classification loss after processing this batch is:  0.15747365355491638\n",
      "The representation loss after processing this batch is:  0.002956211566925049\n",
      "\n",
      "The classification loss after processing this batch is:  0.18701383471488953\n",
      "The representation loss after processing this batch is:  0.0028208941221237183\n",
      "\n",
      "The classification loss after processing this batch is:  0.3131019175052643\n",
      "The representation loss after processing this batch is:  0.003152705729007721\n",
      "\n",
      "The classification loss after processing this batch is:  0.24364081025123596\n",
      "The representation loss after processing this batch is:  0.003789246082305908\n",
      "\n",
      "The classification loss after processing this batch is:  0.1300661861896515\n",
      "The representation loss after processing this batch is:  0.00278482586145401\n",
      "\n",
      "The classification loss after processing this batch is:  0.10294780135154724\n",
      "The representation loss after processing this batch is:  0.003406606614589691\n",
      "\n",
      "The classification loss after processing this batch is:  0.1413969099521637\n",
      "The representation loss after processing this batch is:  0.0036193355917930603\n",
      "\n",
      "The classification loss after processing this batch is:  0.2341662347316742\n",
      "The representation loss after processing this batch is:  0.004134558141231537\n",
      "\n",
      "The classification loss after processing this batch is:  0.2068309485912323\n",
      "The representation loss after processing this batch is:  0.003649480640888214\n",
      "\n",
      "The classification loss after processing this batch is:  0.1272314339876175\n",
      "The representation loss after processing this batch is:  0.003332272171974182\n",
      "\n",
      "The classification loss after processing this batch is:  0.12678304314613342\n",
      "The representation loss after processing this batch is:  0.004114896059036255\n",
      "\n",
      "The classification loss after processing this batch is:  0.1692470908164978\n",
      "The representation loss after processing this batch is:  0.00382889062166214\n",
      "\n",
      "The classification loss after processing this batch is:  0.1718655526638031\n",
      "The representation loss after processing this batch is:  0.003987796604633331\n",
      "\n",
      "The classification loss after processing this batch is:  0.09732697159051895\n",
      "The representation loss after processing this batch is:  0.004302062094211578\n",
      "\n",
      "The classification loss after processing this batch is:  0.15203653275966644\n",
      "The representation loss after processing this batch is:  0.0035250112414360046\n",
      "\n",
      "The classification loss after processing this batch is:  0.2650115191936493\n",
      "The representation loss after processing this batch is:  0.003595896065235138\n",
      "\n",
      "The classification loss after processing this batch is:  0.10701777786016464\n",
      "The representation loss after processing this batch is:  0.0038984641432762146\n",
      "\n",
      "The classification loss after processing this batch is:  0.06439714878797531\n",
      "The representation loss after processing this batch is:  0.0037946701049804688\n",
      "\n",
      "The classification loss after processing this batch is:  0.13950853049755096\n",
      "The representation loss after processing this batch is:  0.0035775527358055115\n",
      "\n",
      "The classification loss after processing this batch is:  0.12031998485326767\n",
      "The representation loss after processing this batch is:  0.003619462251663208\n",
      "\n",
      "The classification loss after processing this batch is:  0.08945313841104507\n",
      "The representation loss after processing this batch is:  0.00354013592004776\n",
      "\n",
      "The classification loss after processing this batch is:  0.09640534222126007\n",
      "The representation loss after processing this batch is:  0.004321657121181488\n",
      "\n",
      "The classification loss after processing this batch is:  0.08864288777112961\n",
      "The representation loss after processing this batch is:  0.004440091550350189\n",
      "\n",
      "The classification loss after processing this batch is:  0.39333251118659973\n",
      "The representation loss after processing this batch is:  0.0042553916573524475\n",
      "\n",
      "The classification loss after processing this batch is:  0.39574024081230164\n",
      "The representation loss after processing this batch is:  0.0041164010763168335\n",
      "\n",
      "The classification loss after processing this batch is:  0.3415793776512146\n",
      "The representation loss after processing this batch is:  0.004431560635566711\n",
      "\n",
      "The classification loss after processing this batch is:  0.10255804657936096\n",
      "The representation loss after processing this batch is:  0.003246314823627472\n",
      "\n",
      "The classification loss after processing this batch is:  0.09185362607240677\n",
      "The representation loss after processing this batch is:  0.0040292888879776\n",
      "\n",
      "The classification loss after processing this batch is:  0.10168289393186569\n",
      "The representation loss after processing this batch is:  0.0030197203159332275\n",
      "\n",
      "The classification loss after processing this batch is:  0.18219654262065887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.002857610583305359\n",
      "\n",
      "The classification loss after processing this batch is:  0.42071011662483215\n",
      "The representation loss after processing this batch is:  0.00351908802986145\n",
      "\n",
      "The classification loss after processing this batch is:  0.1785309761762619\n",
      "The representation loss after processing this batch is:  0.0033687129616737366\n",
      "\n",
      "The classification loss after processing this batch is:  0.12530213594436646\n",
      "The representation loss after processing this batch is:  0.0039057657122612\n",
      "\n",
      "The classification loss after processing this batch is:  0.16751892864704132\n",
      "The representation loss after processing this batch is:  0.0036965012550354004\n",
      "\n",
      "The classification loss after processing this batch is:  0.12262283265590668\n",
      "The representation loss after processing this batch is:  0.004505537450313568\n",
      "\n",
      "The classification loss after processing this batch is:  0.2434910386800766\n",
      "The representation loss after processing this batch is:  0.00312090665102005\n",
      "\n",
      "The classification loss after processing this batch is:  0.10824043303728104\n",
      "The representation loss after processing this batch is:  0.0032731443643569946\n",
      "\n",
      "The classification loss after processing this batch is:  0.21859312057495117\n",
      "The representation loss after processing this batch is:  0.0032184049487113953\n",
      "\n",
      "The classification loss after processing this batch is:  0.16025464236736298\n",
      "The representation loss after processing this batch is:  0.0036638565361499786\n",
      "\n",
      "The classification loss after processing this batch is:  0.23194469511508942\n",
      "The representation loss after processing this batch is:  0.003332238644361496\n",
      "\n",
      "The classification loss after processing this batch is:  0.16102036833763123\n",
      "The representation loss after processing this batch is:  0.003691047430038452\n",
      "\n",
      "The classification loss after processing this batch is:  0.19024518132209778\n",
      "The representation loss after processing this batch is:  0.0039871856570243835\n",
      "\n",
      "The classification loss after processing this batch is:  0.20287317037582397\n",
      "The representation loss after processing this batch is:  0.003045089542865753\n",
      "\n",
      "The classification loss after processing this batch is:  0.2793818712234497\n",
      "The representation loss after processing this batch is:  0.002970688045024872\n",
      "\n",
      "The classification loss after processing this batch is:  0.22913868725299835\n",
      "The representation loss after processing this batch is:  0.0031563378870487213\n",
      "\n",
      "The classification loss after processing this batch is:  0.355814665555954\n",
      "The representation loss after processing this batch is:  0.0028824880719184875\n",
      "\n",
      "The classification loss after processing this batch is:  0.22584247589111328\n",
      "The representation loss after processing this batch is:  0.002986382693052292\n",
      "\n",
      "The classification loss after processing this batch is:  0.29338884353637695\n",
      "The representation loss after processing this batch is:  0.003996022045612335\n",
      "\n",
      "The classification loss after processing this batch is:  0.17128057777881622\n",
      "The representation loss after processing this batch is:  0.003304898738861084\n",
      "\n",
      "The classification loss after processing this batch is:  0.40857696533203125\n",
      "The representation loss after processing this batch is:  0.003152124583721161\n",
      "\n",
      "The classification loss after processing this batch is:  0.2344309240579605\n",
      "The representation loss after processing this batch is:  0.0027277618646621704\n",
      "\n",
      "The classification loss after processing this batch is:  0.22119924426078796\n",
      "The representation loss after processing this batch is:  0.0032295696437358856\n",
      "\n",
      "The classification loss after processing this batch is:  0.3416915535926819\n",
      "The representation loss after processing this batch is:  0.0034290775656700134\n",
      "\n",
      "The classification loss after processing this batch is:  0.3284812867641449\n",
      "The representation loss after processing this batch is:  0.0031785964965820312\n",
      "\n",
      "The classification loss after processing this batch is:  0.16416746377944946\n",
      "The representation loss after processing this batch is:  0.003489270806312561\n",
      "\n",
      "The classification loss after processing this batch is:  0.36874160170555115\n",
      "The representation loss after processing this batch is:  0.004020072519779205\n",
      "\n",
      "The classification loss after processing this batch is:  0.2899352014064789\n",
      "The representation loss after processing this batch is:  0.003540661185979843\n",
      "\n",
      "The classification loss after processing this batch is:  0.389460951089859\n",
      "The representation loss after processing this batch is:  0.0031572096049785614\n",
      "\n",
      "The classification loss after processing this batch is:  0.1975845992565155\n",
      "The representation loss after processing this batch is:  0.0028558410704135895\n",
      "\n",
      "The classification loss after processing this batch is:  0.1682567000389099\n",
      "The representation loss after processing this batch is:  0.003164149820804596\n",
      "\n",
      "The classification loss after processing this batch is:  0.20202279090881348\n",
      "The representation loss after processing this batch is:  0.0030923858284950256\n",
      "\n",
      "The classification loss after processing this batch is:  0.284110963344574\n",
      "The representation loss after processing this batch is:  0.002893451601266861\n",
      "\n",
      "The classification loss after processing this batch is:  0.18960125744342804\n",
      "The representation loss after processing this batch is:  0.003280937671661377\n",
      "\n",
      "The classification loss after processing this batch is:  0.1013578251004219\n",
      "The representation loss after processing this batch is:  0.0032052695751190186\n",
      "\n",
      "The classification loss after processing this batch is:  0.11548711359500885\n",
      "The representation loss after processing this batch is:  0.0033310428261756897\n",
      "\n",
      "The classification loss after processing this batch is:  0.15697254240512848\n",
      "The representation loss after processing this batch is:  0.0030273422598838806\n",
      "\n",
      "The classification loss after processing this batch is:  0.18823875486850739\n",
      "The representation loss after processing this batch is:  0.0032109469175338745\n",
      "\n",
      "The classification loss after processing this batch is:  0.2501615881919861\n",
      "The representation loss after processing this batch is:  0.0034972429275512695\n",
      "\n",
      "The classification loss after processing this batch is:  0.21012718975543976\n",
      "The representation loss after processing this batch is:  0.0034561417996883392\n",
      "\n",
      "The classification loss after processing this batch is:  0.1885986626148224\n",
      "The representation loss after processing this batch is:  0.003214024007320404\n",
      "\n",
      "The classification loss after processing this batch is:  0.1292237788438797\n",
      "The representation loss after processing this batch is:  0.0029959306120872498\n",
      "\n",
      "The classification loss after processing this batch is:  0.1770247519016266\n",
      "The representation loss after processing this batch is:  0.0034440867602825165\n",
      "\n",
      "The classification loss after processing this batch is:  0.17381754517555237\n",
      "The representation loss after processing this batch is:  0.003148876130580902\n",
      "\n",
      "The classification loss after processing this batch is:  0.12304867058992386\n",
      "The representation loss after processing this batch is:  0.003317728638648987\n",
      "\n",
      "The classification loss after processing this batch is:  0.21322068572044373\n",
      "The representation loss after processing this batch is:  0.0032359883189201355\n",
      "\n",
      "The classification loss after processing this batch is:  0.3821469843387604\n",
      "The representation loss after processing this batch is:  0.003684885799884796\n",
      "\n",
      "The classification loss after processing this batch is:  0.22389112412929535\n",
      "The representation loss after processing this batch is:  0.003415539860725403\n",
      "\n",
      "The classification loss after processing this batch is:  0.22927354276180267\n",
      "The representation loss after processing this batch is:  0.0031401552259922028\n",
      "\n",
      "The classification loss after processing this batch is:  0.2121817022562027\n",
      "The representation loss after processing this batch is:  0.003080606460571289\n",
      "\n",
      "The classification loss after processing this batch is:  0.17369037866592407\n",
      "The representation loss after processing this batch is:  0.003086354583501816\n",
      "\n",
      "The classification loss after processing this batch is:  0.20375683903694153\n",
      "The representation loss after processing this batch is:  0.002909548580646515\n",
      "\n",
      "The classification loss after processing this batch is:  0.3285551071166992\n",
      "The representation loss after processing this batch is:  0.0036342069506645203\n",
      "\n",
      "The classification loss after processing this batch is:  0.1461285501718521\n",
      "The representation loss after processing this batch is:  0.0033754631876945496\n",
      "\n",
      "The classification loss after processing this batch is:  0.23346295952796936\n",
      "The representation loss after processing this batch is:  0.0030824318528175354\n",
      "\n",
      "The classification loss after processing this batch is:  0.21373802423477173\n",
      "The representation loss after processing this batch is:  0.0034332275390625\n",
      "\n",
      "The classification loss after processing this batch is:  0.25750622153282166\n",
      "The representation loss after processing this batch is:  0.0029195137321949005\n",
      "\n",
      "The classification loss after processing this batch is:  0.25033435225486755\n",
      "The representation loss after processing this batch is:  0.003318987786769867\n",
      "\n",
      "The classification loss after processing this batch is:  0.1851705014705658\n",
      "The representation loss after processing this batch is:  0.0033134333789348602\n",
      "\n",
      "The classification loss after processing this batch is:  0.15622571110725403\n",
      "The representation loss after processing this batch is:  0.003318004310131073\n",
      "\n",
      "The classification loss after processing this batch is:  0.21670001745224\n",
      "The representation loss after processing this batch is:  0.003552742302417755\n",
      "\n",
      "The classification loss after processing this batch is:  0.22785119712352753\n",
      "The representation loss after processing this batch is:  0.0032439976930618286\n",
      "\n",
      "The classification loss after processing this batch is:  0.2631247043609619\n",
      "The representation loss after processing this batch is:  0.0027331560850143433\n",
      "\n",
      "The classification loss after processing this batch is:  0.18640023469924927\n",
      "The representation loss after processing this batch is:  0.003999523818492889\n",
      "\n",
      "The classification loss after processing this batch is:  0.2989226281642914\n",
      "The representation loss after processing this batch is:  0.003333941102027893\n",
      "\n",
      "The classification loss after processing this batch is:  0.13677196204662323\n",
      "The representation loss after processing this batch is:  0.003012724220752716\n",
      "\n",
      "The classification loss after processing this batch is:  0.13500705361366272\n",
      "The representation loss after processing this batch is:  0.0029173754155635834\n",
      "\n",
      "The classification loss after processing this batch is:  0.2403291016817093\n",
      "The representation loss after processing this batch is:  0.0031785666942596436\n",
      "\n",
      "The classification loss after processing this batch is:  0.2740362286567688\n",
      "The representation loss after processing this batch is:  0.0030120983719825745\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.18253715336322784\n",
      "The representation loss after processing this batch is:  0.0030911974608898163\n",
      "\n",
      "The classification loss after processing this batch is:  0.21221381425857544\n",
      "The representation loss after processing this batch is:  0.0031372234225273132\n",
      "\n",
      "The classification loss after processing this batch is:  0.1528402715921402\n",
      "The representation loss after processing this batch is:  0.0034325681626796722\n",
      "\n",
      "The classification loss after processing this batch is:  0.27263686060905457\n",
      "The representation loss after processing this batch is:  0.003795325756072998\n",
      "\n",
      "The classification loss after processing this batch is:  0.21084553003311157\n",
      "The representation loss after processing this batch is:  0.002928752452135086\n",
      "\n",
      "The classification loss after processing this batch is:  0.13399797677993774\n",
      "The representation loss after processing this batch is:  0.0035325810313224792\n",
      "\n",
      "The classification loss after processing this batch is:  0.3515418767929077\n",
      "The representation loss after processing this batch is:  0.0030232444405555725\n",
      "\n",
      "The classification loss after processing this batch is:  0.21195635199546814\n",
      "The representation loss after processing this batch is:  0.003008700907230377\n",
      "\n",
      "The classification loss after processing this batch is:  0.2513841986656189\n",
      "The representation loss after processing this batch is:  0.003503933548927307\n",
      "\n",
      "The classification loss after processing this batch is:  0.19391751289367676\n",
      "The representation loss after processing this batch is:  0.00265609472990036\n",
      "\n",
      "The classification loss after processing this batch is:  0.16560621559619904\n",
      "The representation loss after processing this batch is:  0.0031831935048103333\n",
      "\n",
      "The classification loss after processing this batch is:  0.22969545423984528\n",
      "The representation loss after processing this batch is:  0.0030231699347496033\n",
      "\n",
      "The classification loss after processing this batch is:  0.25234121084213257\n",
      "The representation loss after processing this batch is:  0.0028231963515281677\n",
      "\n",
      "The classification loss after processing this batch is:  0.16419854760169983\n",
      "The representation loss after processing this batch is:  0.002881992608308792\n",
      "\n",
      "The classification loss after processing this batch is:  0.40512415766716003\n",
      "The representation loss after processing this batch is:  0.002841152250766754\n",
      "\n",
      "The classification loss after processing this batch is:  0.22410763800144196\n",
      "The representation loss after processing this batch is:  0.0028771013021469116\n",
      "\n",
      "The classification loss after processing this batch is:  0.1506907194852829\n",
      "The representation loss after processing this batch is:  0.0036321282386779785\n",
      "\n",
      "The classification loss after processing this batch is:  0.24613605439662933\n",
      "The representation loss after processing this batch is:  0.0030567310750484467\n",
      "\n",
      "The classification loss after processing this batch is:  0.179244726896286\n",
      "The representation loss after processing this batch is:  0.003139480948448181\n",
      "\n",
      "The classification loss after processing this batch is:  0.384920209646225\n",
      "The representation loss after processing this batch is:  0.0032901763916015625\n",
      "\n",
      "The classification loss after processing this batch is:  0.21823331713676453\n",
      "The representation loss after processing this batch is:  0.0031860172748565674\n",
      "\n",
      "The classification loss after processing this batch is:  0.21129252016544342\n",
      "The representation loss after processing this batch is:  0.002941001206636429\n",
      "\n",
      "The classification loss after processing this batch is:  0.4859031140804291\n",
      "The representation loss after processing this batch is:  0.0030926764011383057\n",
      "\n",
      "The classification loss after processing this batch is:  0.24722987413406372\n",
      "The representation loss after processing this batch is:  0.002921946346759796\n",
      "\n",
      "The classification loss after processing this batch is:  0.14508894085884094\n",
      "The representation loss after processing this batch is:  0.0034139007329940796\n",
      "\n",
      "The classification loss after processing this batch is:  0.2638431787490845\n",
      "The representation loss after processing this batch is:  0.002976059913635254\n",
      "\n",
      "The classification loss after processing this batch is:  0.24451173841953278\n",
      "The representation loss after processing this batch is:  0.0033120959997177124\n",
      "\n",
      "The classification loss after processing this batch is:  0.22852995991706848\n",
      "The representation loss after processing this batch is:  0.0034483596682548523\n",
      "\n",
      "The classification loss after processing this batch is:  0.13712409138679504\n",
      "The representation loss after processing this batch is:  0.0030634477734565735\n",
      "\n",
      "The classification loss after processing this batch is:  0.23129139840602875\n",
      "The representation loss after processing this batch is:  0.0033129826188087463\n",
      "\n",
      "The classification loss after processing this batch is:  0.2767340838909149\n",
      "The representation loss after processing this batch is:  0.0032152682542800903\n",
      "\n",
      "The classification loss after processing this batch is:  0.22454620897769928\n",
      "The representation loss after processing this batch is:  0.0034938454627990723\n",
      "\n",
      "The classification loss after processing this batch is:  0.28576165437698364\n",
      "The representation loss after processing this batch is:  0.0030892565846443176\n",
      "\n",
      "The classification loss after processing this batch is:  0.31726911664009094\n",
      "The representation loss after processing this batch is:  0.0035632550716400146\n",
      "\n",
      "The classification loss after processing this batch is:  0.33201634883880615\n",
      "The representation loss after processing this batch is:  0.003495529294013977\n",
      "\n",
      "The classification loss after processing this batch is:  0.18317969143390656\n",
      "The representation loss after processing this batch is:  0.003646343946456909\n",
      "\n",
      "The classification loss after processing this batch is:  0.1765572875738144\n",
      "The representation loss after processing this batch is:  0.0032592862844467163\n",
      "\n",
      "The classification loss after processing this batch is:  0.12464368343353271\n",
      "The representation loss after processing this batch is:  0.0030378177762031555\n",
      "\n",
      "The classification loss after processing this batch is:  0.215214341878891\n",
      "The representation loss after processing this batch is:  0.0027461498975753784\n",
      "\n",
      "The classification loss after processing this batch is:  0.2018599957227707\n",
      "The representation loss after processing this batch is:  0.0029606446623802185\n",
      "\n",
      "The classification loss after processing this batch is:  0.3465684652328491\n",
      "The representation loss after processing this batch is:  0.0032676085829734802\n",
      "\n",
      "The classification loss after processing this batch is:  0.3950638175010681\n",
      "The representation loss after processing this batch is:  0.0035262703895568848\n",
      "\n",
      "The classification loss after processing this batch is:  0.2172459065914154\n",
      "The representation loss after processing this batch is:  0.003270946443080902\n",
      "\n",
      "The classification loss after processing this batch is:  0.21335747838020325\n",
      "The representation loss after processing this batch is:  0.003391548991203308\n",
      "\n",
      "The classification loss after processing this batch is:  0.26127201318740845\n",
      "The representation loss after processing this batch is:  0.002821642905473709\n",
      "\n",
      "The classification loss after processing this batch is:  0.14580993354320526\n",
      "The representation loss after processing this batch is:  0.0034408122301101685\n",
      "\n",
      "The classification loss after processing this batch is:  0.14905261993408203\n",
      "The representation loss after processing this batch is:  0.00322607159614563\n",
      "\n",
      "The classification loss after processing this batch is:  0.2467639446258545\n",
      "The representation loss after processing this batch is:  0.0032496005296707153\n",
      "\n",
      "The classification loss after processing this batch is:  0.22739186882972717\n",
      "The representation loss after processing this batch is:  0.004164181649684906\n",
      "\n",
      "The classification loss after processing this batch is:  0.1418738067150116\n",
      "The representation loss after processing this batch is:  0.00330406054854393\n",
      "\n",
      "The classification loss after processing this batch is:  0.40152570605278015\n",
      "The representation loss after processing this batch is:  0.004370465874671936\n",
      "\n",
      "The classification loss after processing this batch is:  0.37071070075035095\n",
      "The representation loss after processing this batch is:  0.0029628612101078033\n",
      "\n",
      "The classification loss after processing this batch is:  0.3616042733192444\n",
      "The representation loss after processing this batch is:  0.0032909736037254333\n",
      "\n",
      "The classification loss after processing this batch is:  0.34184345602989197\n",
      "The representation loss after processing this batch is:  0.002992376685142517\n",
      "\n",
      "The classification loss after processing this batch is:  0.24162651598453522\n",
      "The representation loss after processing this batch is:  0.003229580819606781\n",
      "\n",
      "The classification loss after processing this batch is:  0.12623262405395508\n",
      "The representation loss after processing this batch is:  0.0034686513245105743\n",
      "\n",
      "The classification loss after processing this batch is:  0.286737322807312\n",
      "The representation loss after processing this batch is:  0.0029689520597457886\n",
      "\n",
      "The classification loss after processing this batch is:  0.532642662525177\n",
      "The representation loss after processing this batch is:  0.004271902143955231\n",
      "\n",
      "The classification loss after processing this batch is:  0.32498618960380554\n",
      "The representation loss after processing this batch is:  0.003561750054359436\n",
      "\n",
      "The classification loss after processing this batch is:  0.20174512267112732\n",
      "The representation loss after processing this batch is:  0.003513708710670471\n",
      "\n",
      "The classification loss after processing this batch is:  0.20367352664470673\n",
      "The representation loss after processing this batch is:  0.003273099660873413\n",
      "\n",
      "The classification loss after processing this batch is:  0.17890171706676483\n",
      "The representation loss after processing this batch is:  0.003368556499481201\n",
      "\n",
      "The classification loss after processing this batch is:  0.19861730933189392\n",
      "The representation loss after processing this batch is:  0.003078348934650421\n",
      "\n",
      "The classification loss after processing this batch is:  0.1529301255941391\n",
      "The representation loss after processing this batch is:  0.0034127086400985718\n",
      "\n",
      "The classification loss after processing this batch is:  0.2649590075016022\n",
      "The representation loss after processing this batch is:  0.00322694331407547\n",
      "\n",
      "The classification loss after processing this batch is:  0.19450153410434723\n",
      "The representation loss after processing this batch is:  0.0032339096069335938\n",
      "\n",
      "The classification loss after processing this batch is:  0.328064888715744\n",
      "The representation loss after processing this batch is:  0.0034905076026916504\n",
      "\n",
      "The classification loss after processing this batch is:  0.19096247851848602\n",
      "The representation loss after processing this batch is:  0.002789679914712906\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.24923385679721832\n",
      "The representation loss after processing this batch is:  0.0027799084782600403\n",
      "\n",
      "The classification loss after processing this batch is:  0.2291872352361679\n",
      "The representation loss after processing this batch is:  0.0032225437462329865\n",
      "\n",
      "The classification loss after processing this batch is:  0.2623627483844757\n",
      "The representation loss after processing this batch is:  0.0033668875694274902\n",
      "\n",
      "The classification loss after processing this batch is:  0.18736214935779572\n",
      "The representation loss after processing this batch is:  0.0029078423976898193\n",
      "\n",
      "The classification loss after processing this batch is:  0.32810264825820923\n",
      "The representation loss after processing this batch is:  0.003180369734764099\n",
      "\n",
      "The classification loss after processing this batch is:  0.32637038826942444\n",
      "The representation loss after processing this batch is:  0.003285035490989685\n",
      "\n",
      "The classification loss after processing this batch is:  0.2527715563774109\n",
      "The representation loss after processing this batch is:  0.0027626492083072662\n",
      "\n",
      "The classification loss after processing this batch is:  0.2728949189186096\n",
      "The representation loss after processing this batch is:  0.003257744014263153\n",
      "\n",
      "The classification loss after processing this batch is:  0.276782363653183\n",
      "The representation loss after processing this batch is:  0.003258161246776581\n",
      "\n",
      "The classification loss after processing this batch is:  0.33714333176612854\n",
      "The representation loss after processing this batch is:  0.0031515248119831085\n",
      "\n",
      "The classification loss after processing this batch is:  0.32618439197540283\n",
      "The representation loss after processing this batch is:  0.003740765154361725\n",
      "\n",
      "The classification loss after processing this batch is:  0.23029452562332153\n",
      "The representation loss after processing this batch is:  0.0035647526383399963\n",
      "\n",
      "The classification loss after processing this batch is:  0.20916585624217987\n",
      "The representation loss after processing this batch is:  0.003265105187892914\n",
      "\n",
      "The classification loss after processing this batch is:  0.41148999333381653\n",
      "The representation loss after processing this batch is:  0.0034223422408103943\n",
      "\n",
      "The classification loss after processing this batch is:  0.3676672875881195\n",
      "The representation loss after processing this batch is:  0.003176238387823105\n",
      "\n",
      "The classification loss after processing this batch is:  0.35374584794044495\n",
      "The representation loss after processing this batch is:  0.003468882292509079\n",
      "\n",
      "The classification loss after processing this batch is:  0.46794793009757996\n",
      "The representation loss after processing this batch is:  0.0027754828333854675\n",
      "\n",
      "The classification loss after processing this batch is:  0.35587188601493835\n",
      "The representation loss after processing this batch is:  0.0031054429709911346\n",
      "\n",
      "The classification loss after processing this batch is:  0.1750165820121765\n",
      "The representation loss after processing this batch is:  0.003150947391986847\n",
      "\n",
      "The classification loss after processing this batch is:  0.18828259408473969\n",
      "The representation loss after processing this batch is:  0.00315074622631073\n",
      "\n",
      "The classification loss after processing this batch is:  0.16490311920642853\n",
      "The representation loss after processing this batch is:  0.0034895092248916626\n",
      "\n",
      "The classification loss after processing this batch is:  0.214183047413826\n",
      "The representation loss after processing this batch is:  0.0042942240834236145\n",
      "\n",
      "The classification loss after processing this batch is:  0.12724928557872772\n",
      "The representation loss after processing this batch is:  0.0034158527851104736\n",
      "\n",
      "The classification loss after processing this batch is:  0.3208337724208832\n",
      "The representation loss after processing this batch is:  0.004250526428222656\n",
      "\n",
      "The classification loss after processing this batch is:  0.1986224353313446\n",
      "The representation loss after processing this batch is:  0.0031092315912246704\n",
      "\n",
      "The classification loss after processing this batch is:  0.18549762666225433\n",
      "The representation loss after processing this batch is:  0.003447752445936203\n",
      "\n",
      "The classification loss after processing this batch is:  0.33364608883857727\n",
      "The representation loss after processing this batch is:  0.0026328489184379578\n",
      "\n",
      "The classification loss after processing this batch is:  0.19880260527133942\n",
      "The representation loss after processing this batch is:  0.0034088194370269775\n",
      "\n",
      "The classification loss after processing this batch is:  0.34855830669403076\n",
      "The representation loss after processing this batch is:  0.003686465322971344\n",
      "\n",
      "The classification loss after processing this batch is:  0.3202057182788849\n",
      "The representation loss after processing this batch is:  0.004191972315311432\n",
      "\n",
      "The classification loss after processing this batch is:  0.22644709050655365\n",
      "The representation loss after processing this batch is:  0.003512240946292877\n",
      "\n",
      "The classification loss after processing this batch is:  0.2245311141014099\n",
      "The representation loss after processing this batch is:  0.0028192847967147827\n",
      "\n",
      "The classification loss after processing this batch is:  0.20154398679733276\n",
      "The representation loss after processing this batch is:  0.002933993935585022\n",
      "\n",
      "The classification loss after processing this batch is:  0.14218156039714813\n",
      "The representation loss after processing this batch is:  0.0029734820127487183\n",
      "\n",
      "The classification loss after processing this batch is:  0.12321904301643372\n",
      "The representation loss after processing this batch is:  0.0034150704741477966\n",
      "\n",
      "The classification loss after processing this batch is:  0.16190646588802338\n",
      "The representation loss after processing this batch is:  0.003210652619600296\n",
      "\n",
      "The classification loss after processing this batch is:  0.19902385771274567\n",
      "The representation loss after processing this batch is:  0.00269433856010437\n",
      "\n",
      "The classification loss after processing this batch is:  0.2149483859539032\n",
      "The representation loss after processing this batch is:  0.0030516013503074646\n",
      "\n",
      "The classification loss after processing this batch is:  0.266418993473053\n",
      "The representation loss after processing this batch is:  0.003355361521244049\n",
      "\n",
      "The classification loss after processing this batch is:  0.4699816405773163\n",
      "The representation loss after processing this batch is:  0.0034456998109817505\n",
      "\n",
      "The classification loss after processing this batch is:  0.389139860868454\n",
      "The representation loss after processing this batch is:  0.003229781985282898\n",
      "\n",
      "The classification loss after processing this batch is:  0.14242564141750336\n",
      "The representation loss after processing this batch is:  0.002957254648208618\n",
      "\n",
      "The classification loss after processing this batch is:  0.16316814720630646\n",
      "The representation loss after processing this batch is:  0.003368128091096878\n",
      "\n",
      "The classification loss after processing this batch is:  0.1999458372592926\n",
      "The representation loss after processing this batch is:  0.0029751211404800415\n",
      "\n",
      "The classification loss after processing this batch is:  0.16631953418254852\n",
      "The representation loss after processing this batch is:  0.002977907657623291\n",
      "\n",
      "The classification loss after processing this batch is:  0.1276492178440094\n",
      "The representation loss after processing this batch is:  0.0035495907068252563\n",
      "\n",
      "The classification loss after processing this batch is:  0.16092048585414886\n",
      "The representation loss after processing this batch is:  0.0035080984234809875\n",
      "\n",
      "The classification loss after processing this batch is:  0.2541140019893646\n",
      "The representation loss after processing this batch is:  0.0029388628900051117\n",
      "\n",
      "The classification loss after processing this batch is:  0.31774118542671204\n",
      "The representation loss after processing this batch is:  0.003277372568845749\n",
      "\n",
      "The classification loss after processing this batch is:  0.1304732710123062\n",
      "The representation loss after processing this batch is:  0.003722056746482849\n",
      "\n",
      "The classification loss after processing this batch is:  0.15208883583545685\n",
      "The representation loss after processing this batch is:  0.0030718520283699036\n",
      "\n",
      "The classification loss after processing this batch is:  0.13049913942813873\n",
      "The representation loss after processing this batch is:  0.0029778964817523956\n",
      "\n",
      "The classification loss after processing this batch is:  0.3068724572658539\n",
      "The representation loss after processing this batch is:  0.003285970538854599\n",
      "\n",
      "The classification loss after processing this batch is:  0.1821388304233551\n",
      "The representation loss after processing this batch is:  0.0032143518328666687\n",
      "\n",
      "The classification loss after processing this batch is:  0.11022678017616272\n",
      "The representation loss after processing this batch is:  0.0036689043045043945\n",
      "\n",
      "The classification loss after processing this batch is:  0.3209553360939026\n",
      "The representation loss after processing this batch is:  0.00342433899641037\n",
      "\n",
      "The classification loss after processing this batch is:  0.213693767786026\n",
      "The representation loss after processing this batch is:  0.0031295716762542725\n",
      "\n",
      "The classification loss after processing this batch is:  0.1593758910894394\n",
      "The representation loss after processing this batch is:  0.0029442869126796722\n",
      "\n",
      "The classification loss after processing this batch is:  0.23316170275211334\n",
      "The representation loss after processing this batch is:  0.0029662437736988068\n",
      "\n",
      "The classification loss after processing this batch is:  0.17773093283176422\n",
      "The representation loss after processing this batch is:  0.0029851049184799194\n",
      "\n",
      "The classification loss after processing this batch is:  0.2145124226808548\n",
      "The representation loss after processing this batch is:  0.0028751417994499207\n",
      "\n",
      "The classification loss after processing this batch is:  0.27146193385124207\n",
      "The representation loss after processing this batch is:  0.0029537752270698547\n",
      "\n",
      "The classification loss after processing this batch is:  0.3167293965816498\n",
      "The representation loss after processing this batch is:  0.0032477974891662598\n",
      "\n",
      "The classification loss after processing this batch is:  0.22136224806308746\n",
      "The representation loss after processing this batch is:  0.003071986138820648\n",
      "\n",
      "The classification loss after processing this batch is:  0.2773188054561615\n",
      "The representation loss after processing this batch is:  0.0031062066555023193\n",
      "\n",
      "The classification loss after processing this batch is:  0.20545421540737152\n",
      "The representation loss after processing this batch is:  0.003196772187948227\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2578827738761902\n",
      "The representation loss after processing this batch is:  0.0032782703638076782\n",
      "\n",
      "The classification loss after processing this batch is:  0.1881525069475174\n",
      "The representation loss after processing this batch is:  0.003421477973461151\n",
      "\n",
      "The classification loss after processing this batch is:  0.2800236940383911\n",
      "The representation loss after processing this batch is:  0.0034897886216640472\n",
      "\n",
      "The classification loss after processing this batch is:  0.17703333497047424\n",
      "The representation loss after processing this batch is:  0.00301186740398407\n",
      "\n",
      "The classification loss after processing this batch is:  0.23419030010700226\n",
      "The representation loss after processing this batch is:  0.0029488354921340942\n",
      "\n",
      "The classification loss after processing this batch is:  0.1768646538257599\n",
      "The representation loss after processing this batch is:  0.0032019615173339844\n",
      "\n",
      "The classification loss after processing this batch is:  0.27051225304603577\n",
      "The representation loss after processing this batch is:  0.003112558275461197\n",
      "\n",
      "The classification loss after processing this batch is:  0.19129109382629395\n",
      "The representation loss after processing this batch is:  0.0025439299643039703\n",
      "\n",
      "The classification loss after processing this batch is:  0.24568405747413635\n",
      "The representation loss after processing this batch is:  0.0031534358859062195\n",
      "\n",
      "The classification loss after processing this batch is:  0.2687479853630066\n",
      "The representation loss after processing this batch is:  0.0028238967061042786\n",
      "\n",
      "The classification loss after processing this batch is:  0.26655927300453186\n",
      "The representation loss after processing this batch is:  0.003017626702785492\n",
      "\n",
      "The classification loss after processing this batch is:  0.31348201632499695\n",
      "The representation loss after processing this batch is:  0.002922654151916504\n",
      "\n",
      "The classification loss after processing this batch is:  0.3359828591346741\n",
      "The representation loss after processing this batch is:  0.003160376101732254\n",
      "\n",
      "The classification loss after processing this batch is:  0.420564204454422\n",
      "The representation loss after processing this batch is:  0.0031333714723587036\n",
      "\n",
      "The classification loss after processing this batch is:  0.33818313479423523\n",
      "The representation loss after processing this batch is:  0.0028274841606616974\n",
      "\n",
      "The classification loss after processing this batch is:  0.1557949334383011\n",
      "The representation loss after processing this batch is:  0.0031504444777965546\n",
      "\n",
      "The classification loss after processing this batch is:  0.2140883505344391\n",
      "The representation loss after processing this batch is:  0.003120891749858856\n",
      "\n",
      "The classification loss after processing this batch is:  0.15422266721725464\n",
      "The representation loss after processing this batch is:  0.003376379609107971\n",
      "\n",
      "The classification loss after processing this batch is:  0.23527806997299194\n",
      "The representation loss after processing this batch is:  0.0035553649067878723\n",
      "\n",
      "The classification loss after processing this batch is:  0.3309014141559601\n",
      "The representation loss after processing this batch is:  0.0032913386821746826\n",
      "\n",
      "The classification loss after processing this batch is:  0.4299226701259613\n",
      "The representation loss after processing this batch is:  0.003306068480014801\n",
      "\n",
      "The classification loss after processing this batch is:  0.42398586869239807\n",
      "The representation loss after processing this batch is:  0.002732403576374054\n",
      "\n",
      "The classification loss after processing this batch is:  0.34025269746780396\n",
      "The representation loss after processing this batch is:  0.0032903552055358887\n",
      "\n",
      "The classification loss after processing this batch is:  0.1369650959968567\n",
      "The representation loss after processing this batch is:  0.0029645003378391266\n",
      "\n",
      "The classification loss after processing this batch is:  0.1799224317073822\n",
      "The representation loss after processing this batch is:  0.0033037737011909485\n",
      "\n",
      "The classification loss after processing this batch is:  0.29411786794662476\n",
      "The representation loss after processing this batch is:  0.0028631240129470825\n",
      "\n",
      "The classification loss after processing this batch is:  0.17500871419906616\n",
      "The representation loss after processing this batch is:  0.0030113235116004944\n",
      "\n",
      "The classification loss after processing this batch is:  0.15460027754306793\n",
      "The representation loss after processing this batch is:  0.003260999917984009\n",
      "\n",
      "The classification loss after processing this batch is:  0.172124445438385\n",
      "The representation loss after processing this batch is:  0.003064475953578949\n",
      "\n",
      "The classification loss after processing this batch is:  0.09689483046531677\n",
      "The representation loss after processing this batch is:  0.003208354115486145\n",
      "\n",
      "The classification loss after processing this batch is:  0.23322482407093048\n",
      "The representation loss after processing this batch is:  0.003586292266845703\n",
      "\n",
      "The classification loss after processing this batch is:  0.1829574555158615\n",
      "The representation loss after processing this batch is:  0.003370296210050583\n",
      "\n",
      "The classification loss after processing this batch is:  0.27873319387435913\n",
      "The representation loss after processing this batch is:  0.0030503198504447937\n",
      "\n",
      "The classification loss after processing this batch is:  0.23670481145381927\n",
      "The representation loss after processing this batch is:  0.0031504780054092407\n",
      "\n",
      "The classification loss after processing this batch is:  0.24319426715373993\n",
      "The representation loss after processing this batch is:  0.0034125149250030518\n",
      "\n",
      "The classification loss after processing this batch is:  0.29453083872795105\n",
      "The representation loss after processing this batch is:  0.00347021222114563\n",
      "\n",
      "The classification loss after processing this batch is:  0.2157139778137207\n",
      "The representation loss after processing this batch is:  0.0033893734216690063\n",
      "\n",
      "The classification loss after processing this batch is:  0.21651510894298553\n",
      "The representation loss after processing this batch is:  0.003519617021083832\n",
      "\n",
      "The classification loss after processing this batch is:  0.22563807666301727\n",
      "The representation loss after processing this batch is:  0.0037383288145065308\n",
      "\n",
      "The classification loss after processing this batch is:  0.2544611096382141\n",
      "The representation loss after processing this batch is:  0.0034531280398368835\n",
      "\n",
      "The classification loss after processing this batch is:  0.2499067634344101\n",
      "The representation loss after processing this batch is:  0.0029623620212078094\n",
      "\n",
      "The classification loss after processing this batch is:  0.33177757263183594\n",
      "The representation loss after processing this batch is:  0.0028785914182662964\n",
      "\n",
      "The classification loss after processing this batch is:  0.36403411626815796\n",
      "The representation loss after processing this batch is:  0.0031923726201057434\n",
      "\n",
      "The classification loss after processing this batch is:  0.16287054121494293\n",
      "The representation loss after processing this batch is:  0.0030246898531913757\n",
      "\n",
      "The classification loss after processing this batch is:  0.23032896220684052\n",
      "The representation loss after processing this batch is:  0.003253035247325897\n",
      "\n",
      "The classification loss after processing this batch is:  0.23917068541049957\n",
      "The representation loss after processing this batch is:  0.0035211220383644104\n",
      "\n",
      "The classification loss after processing this batch is:  0.3185056149959564\n",
      "The representation loss after processing this batch is:  0.003166966140270233\n",
      "\n",
      "The classification loss after processing this batch is:  0.3493421673774719\n",
      "The representation loss after processing this batch is:  0.0039015114307403564\n",
      "\n",
      "The classification loss after processing this batch is:  0.29144611954689026\n",
      "The representation loss after processing this batch is:  0.0036230310797691345\n",
      "\n",
      "The classification loss after processing this batch is:  0.36494889855384827\n",
      "The representation loss after processing this batch is:  0.0037861987948417664\n",
      "\n",
      "The classification loss after processing this batch is:  0.28465864062309265\n",
      "The representation loss after processing this batch is:  0.0037043914198875427\n",
      "\n",
      "The classification loss after processing this batch is:  0.2166723608970642\n",
      "The representation loss after processing this batch is:  0.003176569938659668\n",
      "\n",
      "The classification loss after processing this batch is:  0.24451598525047302\n",
      "The representation loss after processing this batch is:  0.004402346909046173\n",
      "\n",
      "The classification loss after processing this batch is:  0.17405255138874054\n",
      "The representation loss after processing this batch is:  0.003273792564868927\n",
      "\n",
      "The classification loss after processing this batch is:  0.24792170524597168\n",
      "The representation loss after processing this batch is:  0.0036253705620765686\n",
      "\n",
      "The classification loss after processing this batch is:  0.22705084085464478\n",
      "The representation loss after processing this batch is:  0.003448501229286194\n",
      "\n",
      "The classification loss after processing this batch is:  0.19345299899578094\n",
      "The representation loss after processing this batch is:  0.0028876513242721558\n",
      "\n",
      "The classification loss after processing this batch is:  0.1717895120382309\n",
      "The representation loss after processing this batch is:  0.002966649830341339\n",
      "\n",
      "The classification loss after processing this batch is:  0.2313094288110733\n",
      "The representation loss after processing this batch is:  0.00338880717754364\n",
      "\n",
      "The classification loss after processing this batch is:  0.202782541513443\n",
      "The representation loss after processing this batch is:  0.0029906556010246277\n",
      "\n",
      "The classification loss after processing this batch is:  0.16419006884098053\n",
      "The representation loss after processing this batch is:  0.002938278019428253\n",
      "\n",
      "The classification loss after processing this batch is:  0.2133793979883194\n",
      "The representation loss after processing this batch is:  0.0028828680515289307\n",
      "\n",
      "The classification loss after processing this batch is:  0.15116214752197266\n",
      "The representation loss after processing this batch is:  0.0027871504426002502\n",
      "\n",
      "The classification loss after processing this batch is:  0.19527040421962738\n",
      "The representation loss after processing this batch is:  0.0026760175824165344\n",
      "\n",
      "The classification loss after processing this batch is:  0.1684999018907547\n",
      "The representation loss after processing this batch is:  0.002885967493057251\n",
      "\n",
      "The classification loss after processing this batch is:  0.6671934127807617\n",
      "The representation loss after processing this batch is:  0.0031314678490161896\n",
      "\n",
      "The classification loss after processing this batch is:  0.2343619465827942\n",
      "The representation loss after processing this batch is:  0.0030195415019989014\n",
      "\n",
      "The classification loss after processing this batch is:  0.319245308637619\n",
      "The representation loss after processing this batch is:  0.003085937350988388\n",
      "\n",
      "The classification loss after processing this batch is:  0.369562029838562\n",
      "The representation loss after processing this batch is:  0.002904452383518219\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.23664237558841705\n",
      "The representation loss after processing this batch is:  0.0030487775802612305\n",
      "\n",
      "The classification loss after processing this batch is:  0.3472481369972229\n",
      "The representation loss after processing this batch is:  0.003479529172182083\n",
      "\n",
      "The classification loss after processing this batch is:  0.19652798771858215\n",
      "The representation loss after processing this batch is:  0.003322076052427292\n",
      "\n",
      "The classification loss after processing this batch is:  0.374152809381485\n",
      "The representation loss after processing this batch is:  0.002806350588798523\n",
      "\n",
      "The classification loss after processing this batch is:  0.14051327109336853\n",
      "The representation loss after processing this batch is:  0.002898968756198883\n",
      "\n",
      "The classification loss after processing this batch is:  0.186934694647789\n",
      "The representation loss after processing this batch is:  0.0031208842992782593\n",
      "\n",
      "The classification loss after processing this batch is:  0.13022388517856598\n",
      "The representation loss after processing this batch is:  0.0036455094814300537\n",
      "\n",
      "The classification loss after processing this batch is:  0.09741706401109695\n",
      "The representation loss after processing this batch is:  0.0034956932067871094\n",
      "\n",
      "The classification loss after processing this batch is:  0.18496765196323395\n",
      "The representation loss after processing this batch is:  0.0030795857310295105\n",
      "\n",
      "The classification loss after processing this batch is:  0.11212322115898132\n",
      "The representation loss after processing this batch is:  0.002890847623348236\n",
      "\n",
      "The classification loss after processing this batch is:  0.19630330801010132\n",
      "The representation loss after processing this batch is:  0.0031268447637557983\n",
      "\n",
      "The classification loss after processing this batch is:  0.17175303399562836\n",
      "The representation loss after processing this batch is:  0.0036836937069892883\n",
      "\n",
      "The classification loss after processing this batch is:  0.19017080962657928\n",
      "The representation loss after processing this batch is:  0.002880305051803589\n",
      "\n",
      "The classification loss after processing this batch is:  0.2177441120147705\n",
      "The representation loss after processing this batch is:  0.0028552934527397156\n",
      "\n",
      "The classification loss after processing this batch is:  0.1843702495098114\n",
      "The representation loss after processing this batch is:  0.0035353675484657288\n",
      "\n",
      "The classification loss after processing this batch is:  0.23354549705982208\n",
      "The representation loss after processing this batch is:  0.0031082704663276672\n",
      "\n",
      "The classification loss after processing this batch is:  0.24039389193058014\n",
      "The representation loss after processing this batch is:  0.003355585038661957\n",
      "\n",
      "The classification loss after processing this batch is:  0.2998940646648407\n",
      "The representation loss after processing this batch is:  0.003541909158229828\n",
      "\n",
      "The classification loss after processing this batch is:  0.20945586264133453\n",
      "The representation loss after processing this batch is:  0.0030289292335510254\n",
      "\n",
      "The classification loss after processing this batch is:  0.17010901868343353\n",
      "The representation loss after processing this batch is:  0.003139108419418335\n",
      "\n",
      "The classification loss after processing this batch is:  0.2892821133136749\n",
      "The representation loss after processing this batch is:  0.0032495856285095215\n",
      "\n",
      "The classification loss after processing this batch is:  0.28508859872817993\n",
      "The representation loss after processing this batch is:  0.003164149820804596\n",
      "\n",
      "The classification loss after processing this batch is:  0.25404852628707886\n",
      "The representation loss after processing this batch is:  0.002986796200275421\n",
      "\n",
      "The classification loss after processing this batch is:  0.19367775321006775\n",
      "The representation loss after processing this batch is:  0.0030135884881019592\n",
      "\n",
      "The classification loss after processing this batch is:  0.21249939501285553\n",
      "The representation loss after processing this batch is:  0.003442734479904175\n",
      "\n",
      "The classification loss after processing this batch is:  0.2380436509847641\n",
      "The representation loss after processing this batch is:  0.0030429884791374207\n",
      "\n",
      "The classification loss after processing this batch is:  0.2504850924015045\n",
      "The representation loss after processing this batch is:  0.0033212751150131226\n",
      "\n",
      "The classification loss after processing this batch is:  0.2298910766839981\n",
      "The representation loss after processing this batch is:  0.0033337250351905823\n",
      "\n",
      "The classification loss after processing this batch is:  0.20160728693008423\n",
      "The representation loss after processing this batch is:  0.003948040306568146\n",
      "\n",
      "The classification loss after processing this batch is:  0.26626497507095337\n",
      "The representation loss after processing this batch is:  0.0035709142684936523\n",
      "\n",
      "The classification loss after processing this batch is:  0.31104081869125366\n",
      "The representation loss after processing this batch is:  0.003000877797603607\n",
      "\n",
      "The classification loss after processing this batch is:  0.18544240295886993\n",
      "The representation loss after processing this batch is:  0.004259958863258362\n",
      "\n",
      "The classification loss after processing this batch is:  0.23251816630363464\n",
      "The representation loss after processing this batch is:  0.00303630530834198\n",
      "\n",
      "The classification loss after processing this batch is:  0.19705286622047424\n",
      "The representation loss after processing this batch is:  0.0027061626315116882\n",
      "\n",
      "The classification loss after processing this batch is:  0.2739453911781311\n",
      "The representation loss after processing this batch is:  0.0030869171023368835\n",
      "\n",
      "The classification loss after processing this batch is:  0.1416599601507187\n",
      "The representation loss after processing this batch is:  0.00334351509809494\n",
      "\n",
      "The classification loss after processing this batch is:  0.20547667145729065\n",
      "The representation loss after processing this batch is:  0.003566361963748932\n",
      "\n",
      "The classification loss after processing this batch is:  0.1551394760608673\n",
      "The representation loss after processing this batch is:  0.0034393221139907837\n",
      "\n",
      "The classification loss after processing this batch is:  0.16752223670482635\n",
      "The representation loss after processing this batch is:  0.002783454954624176\n",
      "\n",
      "The classification loss after processing this batch is:  0.14282220602035522\n",
      "The representation loss after processing this batch is:  0.0031686723232269287\n",
      "\n",
      "The classification loss after processing this batch is:  0.3112246096134186\n",
      "The representation loss after processing this batch is:  0.003469124436378479\n",
      "\n",
      "The classification loss after processing this batch is:  0.24555128812789917\n",
      "The representation loss after processing this batch is:  0.0034233108162879944\n",
      "\n",
      "The classification loss after processing this batch is:  0.23750744760036469\n",
      "The representation loss after processing this batch is:  0.0034106485545635223\n",
      "\n",
      "The classification loss after processing this batch is:  0.1832456886768341\n",
      "The representation loss after processing this batch is:  0.003770187497138977\n",
      "\n",
      "The classification loss after processing this batch is:  0.15956184267997742\n",
      "The representation loss after processing this batch is:  0.003261081874370575\n",
      "\n",
      "The classification loss after processing this batch is:  0.1895870566368103\n",
      "The representation loss after processing this batch is:  0.0030980184674263\n",
      "\n",
      "The classification loss after processing this batch is:  0.18871597945690155\n",
      "The representation loss after processing this batch is:  0.0031630918383598328\n",
      "\n",
      "The classification loss after processing this batch is:  0.18465128540992737\n",
      "The representation loss after processing this batch is:  0.0029793307185173035\n",
      "\n",
      "The classification loss after processing this batch is:  0.12796908617019653\n",
      "The representation loss after processing this batch is:  0.0032688602805137634\n",
      "\n",
      "The classification loss after processing this batch is:  0.10766296833753586\n",
      "The representation loss after processing this batch is:  0.0028615519404411316\n",
      "\n",
      "The classification loss after processing this batch is:  0.19762468338012695\n",
      "The representation loss after processing this batch is:  0.003154158592224121\n",
      "\n",
      "The classification loss after processing this batch is:  0.12842370569705963\n",
      "The representation loss after processing this batch is:  0.0035897716879844666\n",
      "\n",
      "The classification loss after processing this batch is:  0.27568939328193665\n",
      "The representation loss after processing this batch is:  0.0034610554575920105\n",
      "\n",
      "The classification loss after processing this batch is:  0.23078323900699615\n",
      "The representation loss after processing this batch is:  0.00261552631855011\n",
      "\n",
      "The classification loss after processing this batch is:  0.2511100769042969\n",
      "The representation loss after processing this batch is:  0.0030587948858737946\n",
      "\n",
      "The classification loss after processing this batch is:  0.10715986788272858\n",
      "The representation loss after processing this batch is:  0.003573767840862274\n",
      "\n",
      "The classification loss after processing this batch is:  0.3135105073451996\n",
      "The representation loss after processing this batch is:  0.003015603870153427\n",
      "\n",
      "The classification loss after processing this batch is:  0.22291383147239685\n",
      "The representation loss after processing this batch is:  0.0031715035438537598\n",
      "\n",
      "The classification loss after processing this batch is:  0.18965914845466614\n",
      "The representation loss after processing this batch is:  0.003228425979614258\n",
      "\n",
      "The classification loss after processing this batch is:  0.22910580039024353\n",
      "The representation loss after processing this batch is:  0.003285624086856842\n",
      "\n",
      "The classification loss after processing this batch is:  0.22191420197486877\n",
      "The representation loss after processing this batch is:  0.0036010369658470154\n",
      "\n",
      "The classification loss after processing this batch is:  0.1531660109758377\n",
      "The representation loss after processing this batch is:  0.003028787672519684\n",
      "\n",
      "The classification loss after processing this batch is:  0.14362914860248566\n",
      "The representation loss after processing this batch is:  0.0029819607734680176\n",
      "\n",
      "The classification loss after processing this batch is:  0.147572323679924\n",
      "The representation loss after processing this batch is:  0.002947106957435608\n",
      "\n",
      "The classification loss after processing this batch is:  0.2836645245552063\n",
      "The representation loss after processing this batch is:  0.003032393753528595\n",
      "\n",
      "The classification loss after processing this batch is:  0.22370894253253937\n",
      "The representation loss after processing this batch is:  0.002949278801679611\n",
      "\n",
      "The classification loss after processing this batch is:  0.24887295067310333\n",
      "The representation loss after processing this batch is:  0.004326298832893372\n",
      "\n",
      "The classification loss after processing this batch is:  0.2555750012397766\n",
      "The representation loss after processing this batch is:  0.003149125725030899\n",
      "\n",
      "The classification loss after processing this batch is:  0.2600667476654053\n",
      "The representation loss after processing this batch is:  0.003343924880027771\n",
      "\n",
      "The classification loss after processing this batch is:  0.2566582262516022\n",
      "The representation loss after processing this batch is:  0.00289212167263031\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.40422284603118896\n",
      "The representation loss after processing this batch is:  0.002939648926258087\n",
      "\n",
      "The classification loss after processing this batch is:  0.27108579874038696\n",
      "The representation loss after processing this batch is:  0.0027598589658737183\n",
      "\n",
      "The classification loss after processing this batch is:  0.2465454488992691\n",
      "The representation loss after processing this batch is:  0.002842959016561508\n",
      "\n",
      "The classification loss after processing this batch is:  0.1778241991996765\n",
      "The representation loss after processing this batch is:  0.0028696656227111816\n",
      "\n",
      "The classification loss after processing this batch is:  0.15894915163516998\n",
      "The representation loss after processing this batch is:  0.0027523115277290344\n",
      "\n",
      "The classification loss after processing this batch is:  0.13278332352638245\n",
      "The representation loss after processing this batch is:  0.0028929859399795532\n",
      "\n",
      "The classification loss after processing this batch is:  0.22867025434970856\n",
      "The representation loss after processing this batch is:  0.0035165175795555115\n",
      "\n",
      "The classification loss after processing this batch is:  0.21815866231918335\n",
      "The representation loss after processing this batch is:  0.003117278218269348\n",
      "\n",
      "The classification loss after processing this batch is:  0.15603677928447723\n",
      "The representation loss after processing this batch is:  0.003091186285018921\n",
      "\n",
      "The classification loss after processing this batch is:  0.2620611786842346\n",
      "The representation loss after processing this batch is:  0.00306113064289093\n",
      "\n",
      "The classification loss after processing this batch is:  0.21001647412776947\n",
      "The representation loss after processing this batch is:  0.0032256320118904114\n",
      "\n",
      "The classification loss after processing this batch is:  0.25309598445892334\n",
      "The representation loss after processing this batch is:  0.00285499170422554\n",
      "\n",
      "The classification loss after processing this batch is:  0.24121583998203278\n",
      "The representation loss after processing this batch is:  0.0030808188021183014\n",
      "\n",
      "The classification loss after processing this batch is:  0.34161490201950073\n",
      "The representation loss after processing this batch is:  0.0027306340634822845\n",
      "\n",
      "The classification loss after processing this batch is:  0.23448744416236877\n",
      "The representation loss after processing this batch is:  0.003076065331697464\n",
      "\n",
      "The classification loss after processing this batch is:  0.1524171531200409\n",
      "The representation loss after processing this batch is:  0.0034973174333572388\n",
      "\n",
      "The classification loss after processing this batch is:  0.21987612545490265\n",
      "The representation loss after processing this batch is:  0.0029501020908355713\n",
      "\n",
      "The classification loss after processing this batch is:  0.12191019207239151\n",
      "The representation loss after processing this batch is:  0.0030418485403060913\n",
      "\n",
      "The classification loss after processing this batch is:  0.13497145473957062\n",
      "The representation loss after processing this batch is:  0.003031328320503235\n",
      "\n",
      "The classification loss after processing this batch is:  0.18923963606357574\n",
      "The representation loss after processing this batch is:  0.003228306770324707\n",
      "\n",
      "The classification loss after processing this batch is:  0.2296043038368225\n",
      "The representation loss after processing this batch is:  0.0027550160884857178\n",
      "\n",
      "The classification loss after processing this batch is:  0.23862342536449432\n",
      "The representation loss after processing this batch is:  0.003269985318183899\n",
      "\n",
      "The classification loss after processing this batch is:  0.15074266493320465\n",
      "The representation loss after processing this batch is:  0.0036056041717529297\n",
      "\n",
      "The classification loss after processing this batch is:  0.19346633553504944\n",
      "The representation loss after processing this batch is:  0.00357259064912796\n",
      "\n",
      "The classification loss after processing this batch is:  0.13005763292312622\n",
      "The representation loss after processing this batch is:  0.003263436257839203\n",
      "\n",
      "The classification loss after processing this batch is:  0.28677913546562195\n",
      "The representation loss after processing this batch is:  0.003189563751220703\n",
      "\n",
      "The classification loss after processing this batch is:  0.1089956983923912\n",
      "The representation loss after processing this batch is:  0.0027445703744888306\n",
      "\n",
      "The classification loss after processing this batch is:  0.11000353842973709\n",
      "The representation loss after processing this batch is:  0.003525562584400177\n",
      "\n",
      "The classification loss after processing this batch is:  0.19573044776916504\n",
      "The representation loss after processing this batch is:  0.004244521260261536\n",
      "\n",
      "The classification loss after processing this batch is:  0.17955712974071503\n",
      "The representation loss after processing this batch is:  0.0031205415725708008\n",
      "\n",
      "The classification loss after processing this batch is:  0.16935749351978302\n",
      "The representation loss after processing this batch is:  0.003590881824493408\n",
      "\n",
      "The classification loss after processing this batch is:  0.1274046152830124\n",
      "The representation loss after processing this batch is:  0.003043070435523987\n",
      "\n",
      "The classification loss after processing this batch is:  0.22026672959327698\n",
      "The representation loss after processing this batch is:  0.003446616232395172\n",
      "\n",
      "The classification loss after processing this batch is:  0.2962961494922638\n",
      "The representation loss after processing this batch is:  0.003343641757965088\n",
      "\n",
      "The classification loss after processing this batch is:  0.27920591831207275\n",
      "The representation loss after processing this batch is:  0.0029480457305908203\n",
      "\n",
      "The classification loss after processing this batch is:  0.2754788100719452\n",
      "The representation loss after processing this batch is:  0.003508657217025757\n",
      "\n",
      "The classification loss after processing this batch is:  0.14326106011867523\n",
      "The representation loss after processing this batch is:  0.003297850489616394\n",
      "\n",
      "The classification loss after processing this batch is:  0.17807430028915405\n",
      "The representation loss after processing this batch is:  0.0028393901884555817\n",
      "\n",
      "The classification loss after processing this batch is:  0.33753249049186707\n",
      "The representation loss after processing this batch is:  0.003144174814224243\n",
      "\n",
      "The classification loss after processing this batch is:  0.38950517773628235\n",
      "The representation loss after processing this batch is:  0.003805391490459442\n",
      "\n",
      "The classification loss after processing this batch is:  0.3144165873527527\n",
      "The representation loss after processing this batch is:  0.003634270280599594\n",
      "\n",
      "The classification loss after processing this batch is:  0.3809518814086914\n",
      "The representation loss after processing this batch is:  0.0031993314623832703\n",
      "\n",
      "The classification loss after processing this batch is:  0.1797606199979782\n",
      "The representation loss after processing this batch is:  0.002821989357471466\n",
      "\n",
      "The classification loss after processing this batch is:  0.2782897353172302\n",
      "The representation loss after processing this batch is:  0.0028583481907844543\n",
      "\n",
      "The classification loss after processing this batch is:  0.19438369572162628\n",
      "The representation loss after processing this batch is:  0.0030138418078422546\n",
      "\n",
      "The classification loss after processing this batch is:  0.20204824209213257\n",
      "The representation loss after processing this batch is:  0.003096379339694977\n",
      "\n",
      "The classification loss after processing this batch is:  0.19964124262332916\n",
      "The representation loss after processing this batch is:  0.0031910240650177\n",
      "\n",
      "The classification loss after processing this batch is:  0.20265576243400574\n",
      "The representation loss after processing this batch is:  0.0028917118906974792\n",
      "\n",
      "The classification loss after processing this batch is:  0.23457485437393188\n",
      "The representation loss after processing this batch is:  0.003112170845270157\n",
      "\n",
      "The classification loss after processing this batch is:  0.18794727325439453\n",
      "The representation loss after processing this batch is:  0.003087475895881653\n",
      "\n",
      "The classification loss after processing this batch is:  0.2830371558666229\n",
      "The representation loss after processing this batch is:  0.002941317856311798\n",
      "\n",
      "The classification loss after processing this batch is:  0.10008727014064789\n",
      "The representation loss after processing this batch is:  0.0035618990659713745\n",
      "\n",
      "The classification loss after processing this batch is:  0.15170174837112427\n",
      "The representation loss after processing this batch is:  0.0033718720078468323\n",
      "\n",
      "The classification loss after processing this batch is:  0.20929385721683502\n",
      "The representation loss after processing this batch is:  0.003268234431743622\n",
      "\n",
      "The classification loss after processing this batch is:  0.2214500904083252\n",
      "The representation loss after processing this batch is:  0.0033365488052368164\n",
      "\n",
      "The classification loss after processing this batch is:  0.12067459523677826\n",
      "The representation loss after processing this batch is:  0.004129834473133087\n",
      "\n",
      "The classification loss after processing this batch is:  0.1299363225698471\n",
      "The representation loss after processing this batch is:  0.0030298084020614624\n",
      "\n",
      "The classification loss after processing this batch is:  0.27040231227874756\n",
      "The representation loss after processing this batch is:  0.0037635639309883118\n",
      "\n",
      "The classification loss after processing this batch is:  0.27818870544433594\n",
      "The representation loss after processing this batch is:  0.003121696412563324\n",
      "\n",
      "The classification loss after processing this batch is:  0.21126604080200195\n",
      "The representation loss after processing this batch is:  0.00339333713054657\n",
      "\n",
      "The classification loss after processing this batch is:  0.17697380483150482\n",
      "The representation loss after processing this batch is:  0.003039758652448654\n",
      "\n",
      "The classification loss after processing this batch is:  0.15941499173641205\n",
      "The representation loss after processing this batch is:  0.0031192004680633545\n",
      "\n",
      "The classification loss after processing this batch is:  0.15483912825584412\n",
      "The representation loss after processing this batch is:  0.002985849976539612\n",
      "\n",
      "The classification loss after processing this batch is:  0.22179946303367615\n",
      "The representation loss after processing this batch is:  0.0029640719294548035\n",
      "\n",
      "The classification loss after processing this batch is:  0.26931363344192505\n",
      "The representation loss after processing this batch is:  0.0031638965010643005\n",
      "\n",
      "The classification loss after processing this batch is:  0.21413637697696686\n",
      "The representation loss after processing this batch is:  0.0034303441643714905\n",
      "\n",
      "The classification loss after processing this batch is:  0.15805085003376007\n",
      "The representation loss after processing this batch is:  0.0029724016785621643\n",
      "\n",
      "The classification loss after processing this batch is:  0.27699577808380127\n",
      "The representation loss after processing this batch is:  0.0032092370092868805\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.31987258791923523\n",
      "The representation loss after processing this batch is:  0.0033117756247520447\n",
      "\n",
      "The classification loss after processing this batch is:  0.14514295756816864\n",
      "The representation loss after processing this batch is:  0.0034453123807907104\n",
      "\n",
      "The classification loss after processing this batch is:  0.15551236271858215\n",
      "The representation loss after processing this batch is:  0.0027899928390979767\n",
      "\n",
      "The classification loss after processing this batch is:  0.30885398387908936\n",
      "The representation loss after processing this batch is:  0.003108486533164978\n",
      "\n",
      "The classification loss after processing this batch is:  0.29157397150993347\n",
      "The representation loss after processing this batch is:  0.0028705596923828125\n",
      "\n",
      "The classification loss after processing this batch is:  0.17156963050365448\n",
      "The representation loss after processing this batch is:  0.0031721219420433044\n",
      "\n",
      "The classification loss after processing this batch is:  0.32030487060546875\n",
      "The representation loss after processing this batch is:  0.0026054605841636658\n",
      "\n",
      "The classification loss after processing this batch is:  0.25113895535469055\n",
      "The representation loss after processing this batch is:  0.0034119561314582825\n",
      "\n",
      "The classification loss after processing this batch is:  0.31036561727523804\n",
      "The representation loss after processing this batch is:  0.0035309717059135437\n",
      "\n",
      "The classification loss after processing this batch is:  0.2382509857416153\n",
      "The representation loss after processing this batch is:  0.003407202661037445\n",
      "\n",
      "The classification loss after processing this batch is:  0.2611140310764313\n",
      "The representation loss after processing this batch is:  0.00289134681224823\n",
      "\n",
      "The classification loss after processing this batch is:  0.16514435410499573\n",
      "The representation loss after processing this batch is:  0.004509970545768738\n",
      "\n",
      "The classification loss after processing this batch is:  0.2197452187538147\n",
      "The representation loss after processing this batch is:  0.002852305769920349\n",
      "\n",
      "The classification loss after processing this batch is:  0.1790561079978943\n",
      "The representation loss after processing this batch is:  0.002944067120552063\n",
      "\n",
      "The classification loss after processing this batch is:  0.21100281178951263\n",
      "The representation loss after processing this batch is:  0.00280202180147171\n",
      "\n",
      "The classification loss after processing this batch is:  0.18598954379558563\n",
      "The representation loss after processing this batch is:  0.003120221197605133\n",
      "\n",
      "The classification loss after processing this batch is:  0.20456399023532867\n",
      "The representation loss after processing this batch is:  0.0030521824955940247\n",
      "\n",
      "The classification loss after processing this batch is:  0.2953735888004303\n",
      "The representation loss after processing this batch is:  0.0029648244380950928\n",
      "\n",
      "The classification loss after processing this batch is:  0.13779357075691223\n",
      "The representation loss after processing this batch is:  0.003336302936077118\n",
      "\n",
      "The classification loss after processing this batch is:  0.14292435348033905\n",
      "The representation loss after processing this batch is:  0.0037666335701942444\n",
      "\n",
      "The classification loss after processing this batch is:  0.19706827402114868\n",
      "The representation loss after processing this batch is:  0.003453552722930908\n",
      "\n",
      "The classification loss after processing this batch is:  0.10703635960817337\n",
      "The representation loss after processing this batch is:  0.003048934042453766\n",
      "\n",
      "The classification loss after processing this batch is:  0.17829804122447968\n",
      "The representation loss after processing this batch is:  0.003055483102798462\n",
      "\n",
      "The classification loss after processing this batch is:  0.1167808249592781\n",
      "The representation loss after processing this batch is:  0.00344955176115036\n",
      "\n",
      "The classification loss after processing this batch is:  0.17321254312992096\n",
      "The representation loss after processing this batch is:  0.0030572712421417236\n",
      "\n",
      "The classification loss after processing this batch is:  0.21833227574825287\n",
      "The representation loss after processing this batch is:  0.0031914785504341125\n",
      "\n",
      "The classification loss after processing this batch is:  0.26649120450019836\n",
      "The representation loss after processing this batch is:  0.003993220627307892\n",
      "\n",
      "The classification loss after processing this batch is:  0.21784238517284393\n",
      "The representation loss after processing this batch is:  0.0035751312971115112\n",
      "\n",
      "The classification loss after processing this batch is:  0.169120654463768\n",
      "The representation loss after processing this batch is:  0.002833135426044464\n",
      "\n",
      "The classification loss after processing this batch is:  0.20446939766407013\n",
      "The representation loss after processing this batch is:  0.0035308972001075745\n",
      "\n",
      "The classification loss after processing this batch is:  0.13411836326122284\n",
      "The representation loss after processing this batch is:  0.0029784664511680603\n",
      "\n",
      "The classification loss after processing this batch is:  0.11818375438451767\n",
      "The representation loss after processing this batch is:  0.0035352930426597595\n",
      "\n",
      "The classification loss after processing this batch is:  0.13603970408439636\n",
      "The representation loss after processing this batch is:  0.002994254231452942\n",
      "\n",
      "The classification loss after processing this batch is:  0.12729690968990326\n",
      "The representation loss after processing this batch is:  0.003329925239086151\n",
      "\n",
      "The classification loss after processing this batch is:  0.18238306045532227\n",
      "The representation loss after processing this batch is:  0.0032013878226280212\n",
      "\n",
      "The classification loss after processing this batch is:  0.24870003759860992\n",
      "The representation loss after processing this batch is:  0.003152672201395035\n",
      "\n",
      "The classification loss after processing this batch is:  0.23921257257461548\n",
      "The representation loss after processing this batch is:  0.002811841666698456\n",
      "\n",
      "The classification loss after processing this batch is:  0.1613721251487732\n",
      "The representation loss after processing this batch is:  0.0034806355834007263\n",
      "\n",
      "The classification loss after processing this batch is:  0.1759686917066574\n",
      "The representation loss after processing this batch is:  0.0034821704030036926\n",
      "\n",
      "The classification loss after processing this batch is:  0.2227996438741684\n",
      "The representation loss after processing this batch is:  0.00322023406624794\n",
      "\n",
      "The classification loss after processing this batch is:  0.1797180026769638\n",
      "The representation loss after processing this batch is:  0.0033282488584518433\n",
      "\n",
      "The classification loss after processing this batch is:  0.5169007182121277\n",
      "The representation loss after processing this batch is:  0.0035334378480911255\n",
      "\n",
      "The classification loss after processing this batch is:  0.21351860463619232\n",
      "The representation loss after processing this batch is:  0.003654979169368744\n",
      "\n",
      "The classification loss after processing this batch is:  0.2899669110774994\n",
      "The representation loss after processing this batch is:  0.00407186895608902\n",
      "\n",
      "The classification loss after processing this batch is:  0.18425379693508148\n",
      "The representation loss after processing this batch is:  0.002872645854949951\n",
      "\n",
      "The classification loss after processing this batch is:  0.17827679216861725\n",
      "The representation loss after processing this batch is:  0.0031331777572631836\n",
      "\n",
      "The classification loss after processing this batch is:  0.1946781426668167\n",
      "The representation loss after processing this batch is:  0.002912871539592743\n",
      "\n",
      "The classification loss after processing this batch is:  0.20579048991203308\n",
      "The representation loss after processing this batch is:  0.0032638870179653168\n",
      "\n",
      "The classification loss after processing this batch is:  0.31726282835006714\n",
      "The representation loss after processing this batch is:  0.003396444022655487\n",
      "\n",
      "The classification loss after processing this batch is:  0.2981104850769043\n",
      "The representation loss after processing this batch is:  0.004412926733493805\n",
      "\n",
      "The classification loss after processing this batch is:  0.25399860739707947\n",
      "The representation loss after processing this batch is:  0.003908529877662659\n",
      "\n",
      "The classification loss after processing this batch is:  0.21434219181537628\n",
      "The representation loss after processing this batch is:  0.003358595073223114\n",
      "\n",
      "The classification loss after processing this batch is:  0.11008412390947342\n",
      "The representation loss after processing this batch is:  0.00323428213596344\n",
      "\n",
      "The classification loss after processing this batch is:  0.18895788490772247\n",
      "The representation loss after processing this batch is:  0.0032031796872615814\n",
      "\n",
      "The classification loss after processing this batch is:  0.16460742056369781\n",
      "The representation loss after processing this batch is:  0.002974439412355423\n",
      "\n",
      "The classification loss after processing this batch is:  0.1506699025630951\n",
      "The representation loss after processing this batch is:  0.0034408271312713623\n",
      "\n",
      "The classification loss after processing this batch is:  0.2332344651222229\n",
      "The representation loss after processing this batch is:  0.0030073747038841248\n",
      "\n",
      "The classification loss after processing this batch is:  0.31520846486091614\n",
      "The representation loss after processing this batch is:  0.003053009510040283\n",
      "\n",
      "The classification loss after processing this batch is:  0.21102610230445862\n",
      "The representation loss after processing this batch is:  0.0027022138237953186\n",
      "\n",
      "The classification loss after processing this batch is:  0.21334430575370789\n",
      "The representation loss after processing this batch is:  0.0030550621449947357\n",
      "\n",
      "The classification loss after processing this batch is:  0.19433090090751648\n",
      "The representation loss after processing this batch is:  0.003067195415496826\n",
      "\n",
      "The classification loss after processing this batch is:  0.1630280613899231\n",
      "The representation loss after processing this batch is:  0.0033168867230415344\n",
      "\n",
      "The classification loss after processing this batch is:  0.2203325778245926\n",
      "The representation loss after processing this batch is:  0.003254152834415436\n",
      "\n",
      "The classification loss after processing this batch is:  0.10020168870687485\n",
      "The representation loss after processing this batch is:  0.003296859562397003\n",
      "\n",
      "The classification loss after processing this batch is:  0.19585560262203217\n",
      "The representation loss after processing this batch is:  0.0027062371373176575\n",
      "\n",
      "The classification loss after processing this batch is:  0.2901937663555145\n",
      "The representation loss after processing this batch is:  0.0031320974230766296\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.13537754118442535\n",
      "The representation loss after processing this batch is:  0.0033988356590270996\n",
      "\n",
      "The classification loss after processing this batch is:  0.27477753162384033\n",
      "The representation loss after processing this batch is:  0.0027478113770484924\n",
      "\n",
      "The classification loss after processing this batch is:  0.2013201266527176\n",
      "The representation loss after processing this batch is:  0.002877764403820038\n",
      "\n",
      "The classification loss after processing this batch is:  0.17616017162799835\n",
      "The representation loss after processing this batch is:  0.002683579921722412\n",
      "\n",
      "The classification loss after processing this batch is:  0.15143680572509766\n",
      "The representation loss after processing this batch is:  0.0028814375400543213\n",
      "\n",
      "The classification loss after processing this batch is:  0.25422072410583496\n",
      "The representation loss after processing this batch is:  0.003225095570087433\n",
      "\n",
      "The classification loss after processing this batch is:  0.13303688168525696\n",
      "The representation loss after processing this batch is:  0.003362700343132019\n",
      "\n",
      "The classification loss after processing this batch is:  0.42239561676979065\n",
      "The representation loss after processing this batch is:  0.0030848607420921326\n",
      "\n",
      "The classification loss after processing this batch is:  0.24681095778942108\n",
      "The representation loss after processing this batch is:  0.0032870396971702576\n",
      "\n",
      "The classification loss after processing this batch is:  0.26625028252601624\n",
      "The representation loss after processing this batch is:  0.0029953867197036743\n",
      "\n",
      "The classification loss after processing this batch is:  0.14928671717643738\n",
      "The representation loss after processing this batch is:  0.002691507339477539\n",
      "\n",
      "The classification loss after processing this batch is:  0.24541647732257843\n",
      "The representation loss after processing this batch is:  0.003250688314437866\n",
      "\n",
      "The classification loss after processing this batch is:  0.14305457472801208\n",
      "The representation loss after processing this batch is:  0.0029043927788734436\n",
      "\n",
      "The classification loss after processing this batch is:  0.23846057057380676\n",
      "The representation loss after processing this batch is:  0.003087960183620453\n",
      "\n",
      "The classification loss after processing this batch is:  0.299005389213562\n",
      "The representation loss after processing this batch is:  0.0035336390137672424\n",
      "\n",
      "The classification loss after processing this batch is:  0.2391868531703949\n",
      "The representation loss after processing this batch is:  0.0038874857127666473\n",
      "\n",
      "The classification loss after processing this batch is:  0.26043957471847534\n",
      "The representation loss after processing this batch is:  0.0031487978994846344\n",
      "\n",
      "The classification loss after processing this batch is:  0.18691059947013855\n",
      "The representation loss after processing this batch is:  0.0030038096010684967\n",
      "\n",
      "The classification loss after processing this batch is:  0.28663673996925354\n",
      "The representation loss after processing this batch is:  0.003446429967880249\n",
      "\n",
      "The classification loss after processing this batch is:  0.2106916755437851\n",
      "The representation loss after processing this batch is:  0.003271065652370453\n",
      "\n",
      "The classification loss after processing this batch is:  0.24674725532531738\n",
      "The representation loss after processing this batch is:  0.003019191324710846\n",
      "\n",
      "The classification loss after processing this batch is:  0.18233469128608704\n",
      "The representation loss after processing this batch is:  0.0031731724739074707\n",
      "\n",
      "The classification loss after processing this batch is:  0.18704725801944733\n",
      "The representation loss after processing this batch is:  0.003240421414375305\n",
      "\n",
      "The classification loss after processing this batch is:  0.1239117681980133\n",
      "The representation loss after processing this batch is:  0.0030731521546840668\n",
      "\n",
      "The classification loss after processing this batch is:  0.2631332278251648\n",
      "The representation loss after processing this batch is:  0.0032502785325050354\n",
      "\n",
      "The classification loss after processing this batch is:  0.38477447628974915\n",
      "The representation loss after processing this batch is:  0.0030905306339263916\n",
      "\n",
      "The classification loss after processing this batch is:  0.18081596493721008\n",
      "The representation loss after processing this batch is:  0.0034140944480895996\n",
      "\n",
      "The classification loss after processing this batch is:  0.27854645252227783\n",
      "The representation loss after processing this batch is:  0.0038280561566352844\n",
      "\n",
      "The classification loss after processing this batch is:  0.3246980905532837\n",
      "The representation loss after processing this batch is:  0.003011271357536316\n",
      "\n",
      "The classification loss after processing this batch is:  0.26862138509750366\n",
      "The representation loss after processing this batch is:  0.003439001739025116\n",
      "\n",
      "The classification loss after processing this batch is:  0.15465694665908813\n",
      "The representation loss after processing this batch is:  0.0030896738171577454\n",
      "\n",
      "The classification loss after processing this batch is:  0.31339800357818604\n",
      "The representation loss after processing this batch is:  0.0032865777611732483\n",
      "\n",
      "The classification loss after processing this batch is:  0.2888600528240204\n",
      "The representation loss after processing this batch is:  0.0036397576332092285\n",
      "\n",
      "The classification loss after processing this batch is:  0.22990649938583374\n",
      "The representation loss after processing this batch is:  0.0031033754348754883\n",
      "\n",
      "The classification loss after processing this batch is:  0.10729165375232697\n",
      "The representation loss after processing this batch is:  0.003505803644657135\n",
      "\n",
      "The classification loss after processing this batch is:  0.2018299102783203\n",
      "The representation loss after processing this batch is:  0.003220692276954651\n",
      "\n",
      "The classification loss after processing this batch is:  0.21370866894721985\n",
      "The representation loss after processing this batch is:  0.003309398889541626\n",
      "\n",
      "The classification loss after processing this batch is:  0.24640800058841705\n",
      "The representation loss after processing this batch is:  0.0029589980840682983\n",
      "\n",
      "The classification loss after processing this batch is:  0.3103746771812439\n",
      "The representation loss after processing this batch is:  0.0032279789447784424\n",
      "\n",
      "The classification loss after processing this batch is:  0.23441804945468903\n",
      "The representation loss after processing this batch is:  0.0028269998729228973\n",
      "\n",
      "The classification loss after processing this batch is:  0.21904069185256958\n",
      "The representation loss after processing this batch is:  0.003729313611984253\n",
      "\n",
      "The classification loss after processing this batch is:  0.27924972772598267\n",
      "The representation loss after processing this batch is:  0.003737788647413254\n",
      "\n",
      "The classification loss after processing this batch is:  0.2237250655889511\n",
      "The representation loss after processing this batch is:  0.0034845247864723206\n",
      "\n",
      "The classification loss after processing this batch is:  0.20834451913833618\n",
      "The representation loss after processing this batch is:  0.0036671310663223267\n",
      "\n",
      "The classification loss after processing this batch is:  0.3867872953414917\n",
      "The representation loss after processing this batch is:  0.0033699795603752136\n",
      "\n",
      "The classification loss after processing this batch is:  0.33708909153938293\n",
      "The representation loss after processing this batch is:  0.003821060061454773\n",
      "\n",
      "The classification loss after processing this batch is:  0.19026921689510345\n",
      "The representation loss after processing this batch is:  0.0030461400747299194\n",
      "\n",
      "The classification loss after processing this batch is:  0.14083169400691986\n",
      "The representation loss after processing this batch is:  0.00314895436167717\n",
      "\n",
      "The classification loss after processing this batch is:  0.18124650418758392\n",
      "The representation loss after processing this batch is:  0.002796471118927002\n",
      "\n",
      "The classification loss after processing this batch is:  0.17258189618587494\n",
      "The representation loss after processing this batch is:  0.003488786518573761\n",
      "\n",
      "The classification loss after processing this batch is:  0.18672040104866028\n",
      "The representation loss after processing this batch is:  0.0029800646007061005\n",
      "\n",
      "The classification loss after processing this batch is:  0.3489234745502472\n",
      "The representation loss after processing this batch is:  0.0028610005974769592\n",
      "\n",
      "The classification loss after processing this batch is:  0.3182482421398163\n",
      "The representation loss after processing this batch is:  0.0036803409457206726\n",
      "\n",
      "The classification loss after processing this batch is:  0.2436470240354538\n",
      "The representation loss after processing this batch is:  0.002770945429801941\n",
      "\n",
      "The classification loss after processing this batch is:  0.20866253972053528\n",
      "The representation loss after processing this batch is:  0.0027448907494544983\n",
      "\n",
      "The classification loss after processing this batch is:  0.19026266038417816\n",
      "The representation loss after processing this batch is:  0.002652820199728012\n",
      "\n",
      "The classification loss after processing this batch is:  0.18873979151248932\n",
      "The representation loss after processing this batch is:  0.003209516406059265\n",
      "\n",
      "The classification loss after processing this batch is:  0.33846887946128845\n",
      "The representation loss after processing this batch is:  0.0030867643654346466\n",
      "\n",
      "The classification loss after processing this batch is:  0.30785658955574036\n",
      "The representation loss after processing this batch is:  0.0030359625816345215\n",
      "\n",
      "The classification loss after processing this batch is:  0.35656216740608215\n",
      "The representation loss after processing this batch is:  0.0030830204486846924\n",
      "\n",
      "The classification loss after processing this batch is:  0.2254769653081894\n",
      "The representation loss after processing this batch is:  0.003094121813774109\n",
      "\n",
      "The classification loss after processing this batch is:  0.09107062965631485\n",
      "The representation loss after processing this batch is:  0.003563106060028076\n",
      "\n",
      "The classification loss after processing this batch is:  0.249915212392807\n",
      "The representation loss after processing this batch is:  0.0030721165239810944\n",
      "\n",
      "The classification loss after processing this batch is:  0.2078327089548111\n",
      "The representation loss after processing this batch is:  0.0032551586627960205\n",
      "\n",
      "The classification loss after processing this batch is:  0.25489336252212524\n",
      "The representation loss after processing this batch is:  0.0036976635456085205\n",
      "\n",
      "The classification loss after processing this batch is:  0.26010826230049133\n",
      "The representation loss after processing this batch is:  0.0029672011733055115\n",
      "\n",
      "The classification loss after processing this batch is:  0.2894251048564911\n",
      "The representation loss after processing this batch is:  0.0030340105295181274\n",
      "\n",
      "The classification loss after processing this batch is:  0.24871765077114105\n",
      "The representation loss after processing this batch is:  0.002829939126968384\n",
      "\n",
      "The classification loss after processing this batch is:  0.2875693142414093\n",
      "The representation loss after processing this batch is:  0.003147874027490616\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.38245758414268494\n",
      "The representation loss after processing this batch is:  0.0030201002955436707\n",
      "\n",
      "The classification loss after processing this batch is:  0.3737991452217102\n",
      "The representation loss after processing this batch is:  0.002953067421913147\n",
      "\n",
      "The classification loss after processing this batch is:  0.28923365473747253\n",
      "The representation loss after processing this batch is:  0.003101915121078491\n",
      "\n",
      "The classification loss after processing this batch is:  0.11678720265626907\n",
      "The representation loss after processing this batch is:  0.0032279491424560547\n",
      "\n",
      "The classification loss after processing this batch is:  0.08253779262304306\n",
      "The representation loss after processing this batch is:  0.003210201859474182\n",
      "\n",
      "The classification loss after processing this batch is:  0.1959267109632492\n",
      "The representation loss after processing this batch is:  0.0031797215342521667\n",
      "\n",
      "The classification loss after processing this batch is:  0.1229458898305893\n",
      "The representation loss after processing this batch is:  0.004655875265598297\n",
      "\n",
      "The classification loss after processing this batch is:  0.28016000986099243\n",
      "The representation loss after processing this batch is:  0.0032442212104797363\n",
      "\n",
      "The classification loss after processing this batch is:  0.13934437930583954\n",
      "The representation loss after processing this batch is:  0.0033568143844604492\n",
      "\n",
      "The classification loss after processing this batch is:  0.30033665895462036\n",
      "The representation loss after processing this batch is:  0.003203287720680237\n",
      "\n",
      "The classification loss after processing this batch is:  0.10857153683900833\n",
      "The representation loss after processing this batch is:  0.003556452691555023\n",
      "\n",
      "The classification loss after processing this batch is:  0.24039551615715027\n",
      "The representation loss after processing this batch is:  0.0032461732625961304\n",
      "\n",
      "The classification loss after processing this batch is:  0.19978736340999603\n",
      "The representation loss after processing this batch is:  0.0033353567123413086\n",
      "\n",
      "The classification loss after processing this batch is:  0.24010762572288513\n",
      "The representation loss after processing this batch is:  0.0033494681119918823\n",
      "\n",
      "The classification loss after processing this batch is:  0.1967751681804657\n",
      "The representation loss after processing this batch is:  0.0028886422514915466\n",
      "\n",
      "The classification loss after processing this batch is:  0.1442364752292633\n",
      "The representation loss after processing this batch is:  0.0027738921344280243\n",
      "\n",
      "The classification loss after processing this batch is:  0.2038251906633377\n",
      "The representation loss after processing this batch is:  0.002882234752178192\n",
      "\n",
      "The classification loss after processing this batch is:  0.23574768006801605\n",
      "The representation loss after processing this batch is:  0.00300714373588562\n",
      "\n",
      "The classification loss after processing this batch is:  0.2583081126213074\n",
      "The representation loss after processing this batch is:  0.003046557307243347\n",
      "\n",
      "The classification loss after processing this batch is:  0.1810007393360138\n",
      "The representation loss after processing this batch is:  0.0031383559107780457\n",
      "\n",
      "The classification loss after processing this batch is:  0.12651893496513367\n",
      "The representation loss after processing this batch is:  0.0033555924892425537\n",
      "\n",
      "The classification loss after processing this batch is:  0.106925368309021\n",
      "The representation loss after processing this batch is:  0.0029662102460861206\n",
      "\n",
      "The classification loss after processing this batch is:  0.11713090538978577\n",
      "The representation loss after processing this batch is:  0.0033381134271621704\n",
      "\n",
      "The classification loss after processing this batch is:  0.11354576051235199\n",
      "The representation loss after processing this batch is:  0.0033071115612983704\n",
      "\n",
      "The classification loss after processing this batch is:  0.2099117636680603\n",
      "The representation loss after processing this batch is:  0.0032316073775291443\n",
      "\n",
      "The classification loss after processing this batch is:  0.13843539357185364\n",
      "The representation loss after processing this batch is:  0.003186941146850586\n",
      "\n",
      "The classification loss after processing this batch is:  0.08789060264825821\n",
      "The representation loss after processing this batch is:  0.0032467544078826904\n",
      "\n",
      "The classification loss after processing this batch is:  0.19595269858837128\n",
      "The representation loss after processing this batch is:  0.0037135928869247437\n",
      "\n",
      "The classification loss after processing this batch is:  0.17441177368164062\n",
      "The representation loss after processing this batch is:  0.0032988935708999634\n",
      "\n",
      "The classification loss after processing this batch is:  0.13430480659008026\n",
      "The representation loss after processing this batch is:  0.003172982484102249\n",
      "\n",
      "The classification loss after processing this batch is:  0.14583304524421692\n",
      "The representation loss after processing this batch is:  0.003214046359062195\n",
      "\n",
      "The classification loss after processing this batch is:  0.12047391384840012\n",
      "The representation loss after processing this batch is:  0.0029753446578979492\n",
      "\n",
      "The classification loss after processing this batch is:  0.10268600285053253\n",
      "The representation loss after processing this batch is:  0.0030564814805984497\n",
      "\n",
      "The classification loss after processing this batch is:  0.2431434690952301\n",
      "The representation loss after processing this batch is:  0.0031330958008766174\n",
      "\n",
      "The classification loss after processing this batch is:  0.2434510886669159\n",
      "The representation loss after processing this batch is:  0.0033037737011909485\n",
      "\n",
      "The classification loss after processing this batch is:  0.17496460676193237\n",
      "The representation loss after processing this batch is:  0.003275178372859955\n",
      "\n",
      "The classification loss after processing this batch is:  0.2920834720134735\n",
      "The representation loss after processing this batch is:  0.0030092336237430573\n",
      "\n",
      "The classification loss after processing this batch is:  0.14430071413516998\n",
      "The representation loss after processing this batch is:  0.003154933452606201\n",
      "\n",
      "The classification loss after processing this batch is:  0.2199101746082306\n",
      "The representation loss after processing this batch is:  0.0027568861842155457\n",
      "\n",
      "The classification loss after processing this batch is:  0.2899180054664612\n",
      "The representation loss after processing this batch is:  0.003506682813167572\n",
      "\n",
      "The classification loss after processing this batch is:  0.16987618803977966\n",
      "The representation loss after processing this batch is:  0.0032100677490234375\n",
      "\n",
      "The classification loss after processing this batch is:  0.2874066233634949\n",
      "The representation loss after processing this batch is:  0.0030472800135612488\n",
      "\n",
      "The classification loss after processing this batch is:  0.2262624055147171\n",
      "The representation loss after processing this batch is:  0.002989955246448517\n",
      "\n",
      "The classification loss after processing this batch is:  0.21083997189998627\n",
      "The representation loss after processing this batch is:  0.003022797405719757\n",
      "\n",
      "The classification loss after processing this batch is:  0.23356583714485168\n",
      "The representation loss after processing this batch is:  0.0029938220977783203\n",
      "\n",
      "The classification loss after processing this batch is:  0.2014680653810501\n",
      "The representation loss after processing this batch is:  0.0033826828002929688\n",
      "\n",
      "The classification loss after processing this batch is:  0.21896976232528687\n",
      "The representation loss after processing this batch is:  0.002877611666917801\n",
      "\n",
      "The classification loss after processing this batch is:  0.19492462277412415\n",
      "The representation loss after processing this batch is:  0.003183133900165558\n",
      "\n",
      "The classification loss after processing this batch is:  0.26514214277267456\n",
      "The representation loss after processing this batch is:  0.003296762704849243\n",
      "\n",
      "The classification loss after processing this batch is:  0.1913929283618927\n",
      "The representation loss after processing this batch is:  0.0030444934964179993\n",
      "\n",
      "The classification loss after processing this batch is:  0.1553780734539032\n",
      "The representation loss after processing this batch is:  0.0031007975339889526\n",
      "\n",
      "The classification loss after processing this batch is:  0.15807102620601654\n",
      "The representation loss after processing this batch is:  0.0028553158044815063\n",
      "\n",
      "The classification loss after processing this batch is:  0.26796355843544006\n",
      "The representation loss after processing this batch is:  0.002620857208967209\n",
      "\n",
      "The classification loss after processing this batch is:  0.12770770490169525\n",
      "The representation loss after processing this batch is:  0.003264009952545166\n",
      "\n",
      "The classification loss after processing this batch is:  0.21267248690128326\n",
      "The representation loss after processing this batch is:  0.003465794026851654\n",
      "\n",
      "The classification loss after processing this batch is:  0.21546770632266998\n",
      "The representation loss after processing this batch is:  0.002801664173603058\n",
      "\n",
      "The classification loss after processing this batch is:  0.13997571170330048\n",
      "The representation loss after processing this batch is:  0.003551959991455078\n",
      "\n",
      "The classification loss after processing this batch is:  0.1269361525774002\n",
      "The representation loss after processing this batch is:  0.003272026777267456\n",
      "\n",
      "The classification loss after processing this batch is:  0.2012428343296051\n",
      "The representation loss after processing this batch is:  0.0032503455877304077\n",
      "\n",
      "The classification loss after processing this batch is:  0.16488154232501984\n",
      "The representation loss after processing this batch is:  0.0034647732973098755\n",
      "\n",
      "The classification loss after processing this batch is:  0.19420471787452698\n",
      "The representation loss after processing this batch is:  0.0032444894313812256\n",
      "\n",
      "The classification loss after processing this batch is:  0.2499828040599823\n",
      "The representation loss after processing this batch is:  0.002953905612230301\n",
      "\n",
      "The classification loss after processing this batch is:  0.17801329493522644\n",
      "The representation loss after processing this batch is:  0.0031117647886276245\n",
      "\n",
      "The classification loss after processing this batch is:  0.2586861550807953\n",
      "The representation loss after processing this batch is:  0.0025190450251102448\n",
      "\n",
      "The classification loss after processing this batch is:  0.2062995582818985\n",
      "The representation loss after processing this batch is:  0.003423832356929779\n",
      "\n",
      "The classification loss after processing this batch is:  0.10245607793331146\n",
      "The representation loss after processing this batch is:  0.0032560303807258606\n",
      "\n",
      "The classification loss after processing this batch is:  0.14340637624263763\n",
      "The representation loss after processing this batch is:  0.002978213131427765\n",
      "\n",
      "The classification loss after processing this batch is:  0.21187235414981842\n",
      "The representation loss after processing this batch is:  0.003086291253566742\n",
      "\n",
      "The classification loss after processing this batch is:  0.2116984724998474\n",
      "The representation loss after processing this batch is:  0.003103204071521759\n",
      "\n",
      "The classification loss after processing this batch is:  0.17133833467960358\n",
      "The representation loss after processing this batch is:  0.0032805204391479492\n",
      "\n",
      "The classification loss after processing this batch is:  0.23835109174251556\n",
      "The representation loss after processing this batch is:  0.003219086676836014\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.21425527334213257\n",
      "The representation loss after processing this batch is:  0.0038223788142204285\n",
      "\n",
      "The classification loss after processing this batch is:  0.2019064724445343\n",
      "The representation loss after processing this batch is:  0.0032845772802829742\n",
      "\n",
      "The classification loss after processing this batch is:  0.2780681848526001\n",
      "The representation loss after processing this batch is:  0.003015577793121338\n",
      "\n",
      "The classification loss after processing this batch is:  0.21057789027690887\n",
      "The representation loss after processing this batch is:  0.0030549094080924988\n",
      "\n",
      "The classification loss after processing this batch is:  0.1942245215177536\n",
      "The representation loss after processing this batch is:  0.0031957998871803284\n",
      "\n",
      "The classification loss after processing this batch is:  0.1297444850206375\n",
      "The representation loss after processing this batch is:  0.0038712844252586365\n",
      "\n",
      "The classification loss after processing this batch is:  0.11372800916433334\n",
      "The representation loss after processing this batch is:  0.003202572464942932\n",
      "\n",
      "The classification loss after processing this batch is:  0.3018541634082794\n",
      "The representation loss after processing this batch is:  0.002767033874988556\n",
      "\n",
      "The classification loss after processing this batch is:  0.24675804376602173\n",
      "The representation loss after processing this batch is:  0.0027930736541748047\n",
      "\n",
      "The classification loss after processing this batch is:  0.25345325469970703\n",
      "The representation loss after processing this batch is:  0.002931542694568634\n",
      "\n",
      "The classification loss after processing this batch is:  0.2589549422264099\n",
      "The representation loss after processing this batch is:  0.003161601722240448\n",
      "\n",
      "The classification loss after processing this batch is:  0.23719091713428497\n",
      "The representation loss after processing this batch is:  0.0031262189149856567\n",
      "\n",
      "The classification loss after processing this batch is:  0.24825352430343628\n",
      "The representation loss after processing this batch is:  0.002932816743850708\n",
      "\n",
      "The classification loss after processing this batch is:  0.2779111862182617\n",
      "The representation loss after processing this batch is:  0.0032527074217796326\n",
      "\n",
      "The classification loss after processing this batch is:  0.27362850308418274\n",
      "The representation loss after processing this batch is:  0.0029383674263954163\n",
      "\n",
      "The classification loss after processing this batch is:  0.289387047290802\n",
      "The representation loss after processing this batch is:  0.0031927861273288727\n",
      "\n",
      "The classification loss after processing this batch is:  0.1729000061750412\n",
      "The representation loss after processing this batch is:  0.0035108253359794617\n",
      "\n",
      "The classification loss after processing this batch is:  0.10869456827640533\n",
      "The representation loss after processing this batch is:  0.0034872516989707947\n",
      "\n",
      "The classification loss after processing this batch is:  0.1910468488931656\n",
      "The representation loss after processing this batch is:  0.003069087862968445\n",
      "\n",
      "The classification loss after processing this batch is:  0.22016003727912903\n",
      "The representation loss after processing this batch is:  0.0027750730514526367\n",
      "\n",
      "The classification loss after processing this batch is:  0.14146973192691803\n",
      "The representation loss after processing this batch is:  0.0027588382363319397\n",
      "\n",
      "The classification loss after processing this batch is:  0.18075376749038696\n",
      "The representation loss after processing this batch is:  0.0031962990760803223\n",
      "\n",
      "The classification loss after processing this batch is:  0.2026439607143402\n",
      "The representation loss after processing this batch is:  0.002888783812522888\n",
      "\n",
      "The classification loss after processing this batch is:  0.1943618506193161\n",
      "The representation loss after processing this batch is:  0.0030159279704093933\n",
      "\n",
      "The classification loss after processing this batch is:  0.16613608598709106\n",
      "The representation loss after processing this batch is:  0.0035087354481220245\n",
      "\n",
      "The classification loss after processing this batch is:  0.156094491481781\n",
      "The representation loss after processing this batch is:  0.0028976574540138245\n",
      "\n",
      "The classification loss after processing this batch is:  0.15621478855609894\n",
      "The representation loss after processing this batch is:  0.0032143443822860718\n",
      "\n",
      "The classification loss after processing this batch is:  0.22043949365615845\n",
      "The representation loss after processing this batch is:  0.0034760385751724243\n",
      "\n",
      "The classification loss after processing this batch is:  0.19411271810531616\n",
      "The representation loss after processing this batch is:  0.0033014900982379913\n",
      "\n",
      "The classification loss after processing this batch is:  0.19382937252521515\n",
      "The representation loss after processing this batch is:  0.003713790327310562\n",
      "\n",
      "The classification loss after processing this batch is:  0.11888895183801651\n",
      "The representation loss after processing this batch is:  0.0035743340849876404\n",
      "\n",
      "The classification loss after processing this batch is:  0.11528486758470535\n",
      "The representation loss after processing this batch is:  0.0031107962131500244\n",
      "\n",
      "The classification loss after processing this batch is:  0.23110269010066986\n",
      "The representation loss after processing this batch is:  0.0030873343348503113\n",
      "\n",
      "The classification loss after processing this batch is:  0.3106149733066559\n",
      "The representation loss after processing this batch is:  0.0026333890855312347\n",
      "\n",
      "The classification loss after processing this batch is:  0.19715924561023712\n",
      "The representation loss after processing this batch is:  0.0027479082345962524\n",
      "\n",
      "The classification loss after processing this batch is:  0.10375677049160004\n",
      "The representation loss after processing this batch is:  0.003157947212457657\n",
      "\n",
      "The classification loss after processing this batch is:  0.2420215606689453\n",
      "The representation loss after processing this batch is:  0.002520151436328888\n",
      "\n",
      "The classification loss after processing this batch is:  0.08003219217061996\n",
      "The representation loss after processing this batch is:  0.0034252703189849854\n",
      "\n",
      "The classification loss after processing this batch is:  0.2060236632823944\n",
      "The representation loss after processing this batch is:  0.002903170883655548\n",
      "\n",
      "The classification loss after processing this batch is:  0.17038597166538239\n",
      "The representation loss after processing this batch is:  0.0034496337175369263\n",
      "\n",
      "The classification loss after processing this batch is:  0.10643099248409271\n",
      "The representation loss after processing this batch is:  0.002712137997150421\n",
      "\n",
      "The classification loss after processing this batch is:  0.13310475647449493\n",
      "The representation loss after processing this batch is:  0.0033436641097068787\n",
      "\n",
      "The classification loss after processing this batch is:  0.12833505868911743\n",
      "The representation loss after processing this batch is:  0.0032519102096557617\n",
      "\n",
      "The classification loss after processing this batch is:  0.11440762132406235\n",
      "The representation loss after processing this batch is:  0.0031638219952583313\n",
      "\n",
      "The classification loss after processing this batch is:  0.29948094487190247\n",
      "The representation loss after processing this batch is:  0.003032032400369644\n",
      "\n",
      "The classification loss after processing this batch is:  0.30664852261543274\n",
      "The representation loss after processing this batch is:  0.0028680600225925446\n",
      "\n",
      "The classification loss after processing this batch is:  0.26156800985336304\n",
      "The representation loss after processing this batch is:  0.003010723739862442\n",
      "\n",
      "The classification loss after processing this batch is:  0.29319027066230774\n",
      "The representation loss after processing this batch is:  0.0029686875641345978\n",
      "\n",
      "The classification loss after processing this batch is:  0.19389842450618744\n",
      "The representation loss after processing this batch is:  0.0031123608350753784\n",
      "\n",
      "The classification loss after processing this batch is:  0.17776688933372498\n",
      "The representation loss after processing this batch is:  0.003220774233341217\n",
      "\n",
      "The classification loss after processing this batch is:  0.27600666880607605\n",
      "The representation loss after processing this batch is:  0.0030924230813980103\n",
      "\n",
      "The classification loss after processing this batch is:  0.16911226511001587\n",
      "The representation loss after processing this batch is:  0.0034655816853046417\n",
      "\n",
      "The classification loss after processing this batch is:  0.2553614377975464\n",
      "The representation loss after processing this batch is:  0.0031201131641864777\n",
      "\n",
      "The classification loss after processing this batch is:  0.18424615263938904\n",
      "The representation loss after processing this batch is:  0.0031678974628448486\n",
      "\n",
      "The classification loss after processing this batch is:  0.23641209304332733\n",
      "The representation loss after processing this batch is:  0.0028144381940364838\n",
      "\n",
      "The classification loss after processing this batch is:  0.19302740693092346\n",
      "The representation loss after processing this batch is:  0.00299280509352684\n",
      "\n",
      "The classification loss after processing this batch is:  0.17777423560619354\n",
      "The representation loss after processing this batch is:  0.0032020211219787598\n",
      "\n",
      "The classification loss after processing this batch is:  0.24468521773815155\n",
      "The representation loss after processing this batch is:  0.002875387668609619\n",
      "\n",
      "The classification loss after processing this batch is:  0.11574852466583252\n",
      "The representation loss after processing this batch is:  0.003570660948753357\n",
      "\n",
      "The classification loss after processing this batch is:  0.1254379004240036\n",
      "The representation loss after processing this batch is:  0.003103002905845642\n",
      "\n",
      "The classification loss after processing this batch is:  0.2097875028848648\n",
      "The representation loss after processing this batch is:  0.0029218345880508423\n",
      "\n",
      "The classification loss after processing this batch is:  0.2834388017654419\n",
      "The representation loss after processing this batch is:  0.0030469223856925964\n",
      "\n",
      "The classification loss after processing this batch is:  0.12233572453260422\n",
      "The representation loss after processing this batch is:  0.0029887333512306213\n",
      "\n",
      "The classification loss after processing this batch is:  0.1439722329378128\n",
      "The representation loss after processing this batch is:  0.002774365246295929\n",
      "\n",
      "The classification loss after processing this batch is:  0.23678509891033173\n",
      "The representation loss after processing this batch is:  0.0029697753489017487\n",
      "\n",
      "The classification loss after processing this batch is:  0.25354644656181335\n",
      "The representation loss after processing this batch is:  0.0028434693813323975\n",
      "\n",
      "The classification loss after processing this batch is:  0.1838575154542923\n",
      "The representation loss after processing this batch is:  0.0031947121024131775\n",
      "\n",
      "The classification loss after processing this batch is:  0.3402542769908905\n",
      "The representation loss after processing this batch is:  0.0028050877153873444\n",
      "\n",
      "The classification loss after processing this batch is:  0.1490972936153412\n",
      "The representation loss after processing this batch is:  0.003331877291202545\n",
      "\n",
      "The classification loss after processing this batch is:  0.09007194638252258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.002603307366371155\n",
      "\n",
      "The classification loss after processing this batch is:  0.11914269626140594\n",
      "The representation loss after processing this batch is:  0.003126673400402069\n",
      "\n",
      "The classification loss after processing this batch is:  0.20602144300937653\n",
      "The representation loss after processing this batch is:  0.0036182701587677\n",
      "\n",
      "The classification loss after processing this batch is:  0.21148023009300232\n",
      "The representation loss after processing this batch is:  0.00341903418302536\n",
      "\n",
      "The classification loss after processing this batch is:  0.154164656996727\n",
      "The representation loss after processing this batch is:  0.003755137324333191\n",
      "\n",
      "The classification loss after processing this batch is:  0.18703173100948334\n",
      "The representation loss after processing this batch is:  0.002979651093482971\n",
      "\n",
      "The classification loss after processing this batch is:  0.18458887934684753\n",
      "The representation loss after processing this batch is:  0.002978794276714325\n",
      "\n",
      "The classification loss after processing this batch is:  0.1999492198228836\n",
      "The representation loss after processing this batch is:  0.003077942878007889\n",
      "\n",
      "The classification loss after processing this batch is:  0.21422168612480164\n",
      "The representation loss after processing this batch is:  0.002952028065919876\n",
      "\n",
      "The classification loss after processing this batch is:  0.2781001925468445\n",
      "The representation loss after processing this batch is:  0.00304567813873291\n",
      "\n",
      "The classification loss after processing this batch is:  0.24689741432666779\n",
      "The representation loss after processing this batch is:  0.0033478066325187683\n",
      "\n",
      "The classification loss after processing this batch is:  0.31595370173454285\n",
      "The representation loss after processing this batch is:  0.0028515122830867767\n",
      "\n",
      "The classification loss after processing this batch is:  0.22621043026447296\n",
      "The representation loss after processing this batch is:  0.0030036866664886475\n",
      "\n",
      "The classification loss after processing this batch is:  0.23815713822841644\n",
      "The representation loss after processing this batch is:  0.0030966848134994507\n",
      "\n",
      "The classification loss after processing this batch is:  0.2834364175796509\n",
      "The representation loss after processing this batch is:  0.003001488745212555\n",
      "\n",
      "The classification loss after processing this batch is:  0.11744783818721771\n",
      "The representation loss after processing this batch is:  0.0030310899019241333\n",
      "\n",
      "The classification loss after processing this batch is:  0.2096693068742752\n",
      "The representation loss after processing this batch is:  0.003669966012239456\n",
      "\n",
      "The classification loss after processing this batch is:  0.17386646568775177\n",
      "The representation loss after processing this batch is:  0.0031684190034866333\n",
      "\n",
      "The classification loss after processing this batch is:  0.1573769450187683\n",
      "The representation loss after processing this batch is:  0.0033176392316818237\n",
      "\n",
      "The classification loss after processing this batch is:  0.15870466828346252\n",
      "The representation loss after processing this batch is:  0.0026247985661029816\n",
      "\n",
      "The classification loss after processing this batch is:  0.1828669011592865\n",
      "The representation loss after processing this batch is:  0.002856660634279251\n",
      "\n",
      "The classification loss after processing this batch is:  0.1855950653553009\n",
      "The representation loss after processing this batch is:  0.00296657532453537\n",
      "\n",
      "The classification loss after processing this batch is:  0.2451878935098648\n",
      "The representation loss after processing this batch is:  0.0027052760124206543\n",
      "\n",
      "The classification loss after processing this batch is:  0.25133082270622253\n",
      "The representation loss after processing this batch is:  0.00305996835231781\n",
      "\n",
      "The classification loss after processing this batch is:  0.2964663803577423\n",
      "The representation loss after processing this batch is:  0.0030351579189300537\n",
      "\n",
      "The classification loss after processing this batch is:  0.19188092648983002\n",
      "The representation loss after processing this batch is:  0.003506205976009369\n",
      "\n",
      "The classification loss after processing this batch is:  0.2295517921447754\n",
      "The representation loss after processing this batch is:  0.002859562635421753\n",
      "\n",
      "The classification loss after processing this batch is:  0.2029559463262558\n",
      "The representation loss after processing this batch is:  0.0030348896980285645\n",
      "\n",
      "The classification loss after processing this batch is:  0.28405845165252686\n",
      "The representation loss after processing this batch is:  0.0037258118391036987\n",
      "\n",
      "The classification loss after processing this batch is:  0.3533245623111725\n",
      "The representation loss after processing this batch is:  0.0033520907163619995\n",
      "\n",
      "The classification loss after processing this batch is:  0.10762068629264832\n",
      "The representation loss after processing this batch is:  0.002714984118938446\n",
      "\n",
      "The classification loss after processing this batch is:  0.11851216107606888\n",
      "The representation loss after processing this batch is:  0.00309598445892334\n",
      "\n",
      "The classification loss after processing this batch is:  0.3073672652244568\n",
      "The representation loss after processing this batch is:  0.0034492649137973785\n",
      "\n",
      "The classification loss after processing this batch is:  0.13686153292655945\n",
      "The representation loss after processing this batch is:  0.0032222121953964233\n",
      "\n",
      "The classification loss after processing this batch is:  0.174553781747818\n",
      "The representation loss after processing this batch is:  0.0028444677591323853\n",
      "\n",
      "The classification loss after processing this batch is:  0.210100457072258\n",
      "The representation loss after processing this batch is:  0.00290873646736145\n",
      "\n",
      "The classification loss after processing this batch is:  0.21060843765735626\n",
      "The representation loss after processing this batch is:  0.0031594596803188324\n",
      "\n",
      "The classification loss after processing this batch is:  0.36010226607322693\n",
      "The representation loss after processing this batch is:  0.0037384256720542908\n",
      "\n",
      "The classification loss after processing this batch is:  0.2774313986301422\n",
      "The representation loss after processing this batch is:  0.0034805014729499817\n",
      "\n",
      "The classification loss after processing this batch is:  0.2694099545478821\n",
      "The representation loss after processing this batch is:  0.003723137080669403\n",
      "\n",
      "The classification loss after processing this batch is:  0.1442846655845642\n",
      "The representation loss after processing this batch is:  0.0026533380150794983\n",
      "\n",
      "The classification loss after processing this batch is:  0.29433855414390564\n",
      "The representation loss after processing this batch is:  0.002778865396976471\n",
      "\n",
      "The classification loss after processing this batch is:  0.135050967335701\n",
      "The representation loss after processing this batch is:  0.0028511807322502136\n",
      "\n",
      "The classification loss after processing this batch is:  0.11759845167398453\n",
      "The representation loss after processing this batch is:  0.002808868885040283\n",
      "\n",
      "The classification loss after processing this batch is:  0.17260941863059998\n",
      "The representation loss after processing this batch is:  0.0028432831168174744\n",
      "\n",
      "The classification loss after processing this batch is:  0.11501267552375793\n",
      "The representation loss after processing this batch is:  0.0028162002563476562\n",
      "\n",
      "The classification loss after processing this batch is:  0.15629030764102936\n",
      "The representation loss after processing this batch is:  0.003103099763393402\n",
      "\n",
      "The classification loss after processing this batch is:  0.12135272473096848\n",
      "The representation loss after processing this batch is:  0.0032187625765800476\n",
      "\n",
      "The classification loss after processing this batch is:  0.14104010164737701\n",
      "The representation loss after processing this batch is:  0.0030002444982528687\n",
      "\n",
      "The classification loss after processing this batch is:  0.17143858969211578\n",
      "The representation loss after processing this batch is:  0.0029824450612068176\n",
      "\n",
      "The classification loss after processing this batch is:  0.25042542815208435\n",
      "The representation loss after processing this batch is:  0.0033267810940742493\n",
      "\n",
      "The classification loss after processing this batch is:  0.2467959225177765\n",
      "The representation loss after processing this batch is:  0.0026539526879787445\n",
      "\n",
      "The classification loss after processing this batch is:  0.19274196028709412\n",
      "The representation loss after processing this batch is:  0.003250010311603546\n",
      "\n",
      "The classification loss after processing this batch is:  0.26305288076400757\n",
      "The representation loss after processing this batch is:  0.0031313076615333557\n",
      "\n",
      "The classification loss after processing this batch is:  0.13969109952449799\n",
      "The representation loss after processing this batch is:  0.002911105751991272\n",
      "\n",
      "The classification loss after processing this batch is:  0.23713137209415436\n",
      "The representation loss after processing this batch is:  0.0030634328722953796\n",
      "\n",
      "The classification loss after processing this batch is:  0.3820686340332031\n",
      "The representation loss after processing this batch is:  0.0032733753323554993\n",
      "\n",
      "The classification loss after processing this batch is:  0.2638164162635803\n",
      "The representation loss after processing this batch is:  0.0029343515634536743\n",
      "\n",
      "The classification loss after processing this batch is:  0.36222508549690247\n",
      "The representation loss after processing this batch is:  0.002915896475315094\n",
      "\n",
      "The classification loss after processing this batch is:  0.26870423555374146\n",
      "The representation loss after processing this batch is:  0.0030478984117507935\n",
      "\n",
      "The classification loss after processing this batch is:  0.24907201528549194\n",
      "The representation loss after processing this batch is:  0.0029028356075286865\n",
      "\n",
      "The classification loss after processing this batch is:  0.19325301051139832\n",
      "The representation loss after processing this batch is:  0.0029660090804100037\n",
      "\n",
      "The classification loss after processing this batch is:  0.1483132392168045\n",
      "The representation loss after processing this batch is:  0.0028472095727920532\n",
      "\n",
      "The classification loss after processing this batch is:  0.1840481162071228\n",
      "The representation loss after processing this batch is:  0.0030206218361854553\n",
      "\n",
      "The classification loss after processing this batch is:  0.10548833757638931\n",
      "The representation loss after processing this batch is:  0.0032176226377487183\n",
      "\n",
      "The classification loss after processing this batch is:  0.10647054016590118\n",
      "The representation loss after processing this batch is:  0.0031111687421798706\n",
      "\n",
      "The classification loss after processing this batch is:  0.22088870406150818\n",
      "The representation loss after processing this batch is:  0.0030183568596839905\n",
      "\n",
      "The classification loss after processing this batch is:  0.13821932673454285\n",
      "The representation loss after processing this batch is:  0.003230869770050049\n",
      "\n",
      "The classification loss after processing this batch is:  0.32934436202049255\n",
      "The representation loss after processing this batch is:  0.003466695547103882\n",
      "\n",
      "The classification loss after processing this batch is:  0.19566570222377777\n",
      "The representation loss after processing this batch is:  0.0030184760689735413\n",
      "\n",
      "The classification loss after processing this batch is:  0.22352345287799835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.00300394743680954\n",
      "\n",
      "The classification loss after processing this batch is:  0.372875839471817\n",
      "The representation loss after processing this batch is:  0.0028322190046310425\n",
      "\n",
      "The classification loss after processing this batch is:  0.22424310445785522\n",
      "The representation loss after processing this batch is:  0.002744067460298538\n",
      "\n",
      "The classification loss after processing this batch is:  0.11003411561250687\n",
      "The representation loss after processing this batch is:  0.0028597749769687653\n",
      "\n",
      "The classification loss after processing this batch is:  0.12022001296281815\n",
      "The representation loss after processing this batch is:  0.0033898726105690002\n",
      "\n",
      "The classification loss after processing this batch is:  0.137755885720253\n",
      "The representation loss after processing this batch is:  0.003165632486343384\n",
      "\n",
      "The classification loss after processing this batch is:  0.14637158811092377\n",
      "The representation loss after processing this batch is:  0.003266282379627228\n",
      "\n",
      "The classification loss after processing this batch is:  0.15968330204486847\n",
      "The representation loss after processing this batch is:  0.0026641450822353363\n",
      "\n",
      "The classification loss after processing this batch is:  0.3613852858543396\n",
      "The representation loss after processing this batch is:  0.0026981867849826813\n",
      "\n",
      "The classification loss after processing this batch is:  0.32593056559562683\n",
      "The representation loss after processing this batch is:  0.0029232725501060486\n",
      "\n",
      "The classification loss after processing this batch is:  0.18772561848163605\n",
      "The representation loss after processing this batch is:  0.0033696219325065613\n",
      "\n",
      "The classification loss after processing this batch is:  0.28913843631744385\n",
      "The representation loss after processing this batch is:  0.0032731443643569946\n",
      "\n",
      "The classification loss after processing this batch is:  0.12700536847114563\n",
      "The representation loss after processing this batch is:  0.0028387904167175293\n",
      "\n",
      "The classification loss after processing this batch is:  0.17798417806625366\n",
      "The representation loss after processing this batch is:  0.002916976809501648\n",
      "\n",
      "The classification loss after processing this batch is:  0.3172202408313751\n",
      "The representation loss after processing this batch is:  0.002819843590259552\n",
      "\n",
      "The classification loss after processing this batch is:  0.17292265594005585\n",
      "The representation loss after processing this batch is:  0.003611501306295395\n",
      "\n",
      "The classification loss after processing this batch is:  0.2028634399175644\n",
      "The representation loss after processing this batch is:  0.0040154606103897095\n",
      "\n",
      "The classification loss after processing this batch is:  0.13150416314601898\n",
      "The representation loss after processing this batch is:  0.003379039466381073\n",
      "\n",
      "The classification loss after processing this batch is:  0.2423955351114273\n",
      "The representation loss after processing this batch is:  0.003444775938987732\n",
      "\n",
      "The classification loss after processing this batch is:  0.25207608938217163\n",
      "The representation loss after processing this batch is:  0.0035611316561698914\n",
      "\n",
      "The classification loss after processing this batch is:  0.22564005851745605\n",
      "The representation loss after processing this batch is:  0.0035177618265151978\n",
      "\n",
      "The classification loss after processing this batch is:  0.20791953802108765\n",
      "The representation loss after processing this batch is:  0.0034055039286613464\n",
      "\n",
      "The classification loss after processing this batch is:  0.2670418918132782\n",
      "The representation loss after processing this batch is:  0.00266062468290329\n",
      "\n",
      "The classification loss after processing this batch is:  0.2249317616224289\n",
      "The representation loss after processing this batch is:  0.002881251275539398\n",
      "\n",
      "The classification loss after processing this batch is:  0.19930019974708557\n",
      "The representation loss after processing this batch is:  0.003231227397918701\n",
      "\n",
      "The classification loss after processing this batch is:  0.1332240253686905\n",
      "The representation loss after processing this batch is:  0.0034481436014175415\n",
      "\n",
      "The classification loss after processing this batch is:  0.08203453570604324\n",
      "The representation loss after processing this batch is:  0.0033130645751953125\n",
      "\n",
      "The classification loss after processing this batch is:  0.20376275479793549\n",
      "The representation loss after processing this batch is:  0.003121905028820038\n",
      "\n",
      "The classification loss after processing this batch is:  0.16375106573104858\n",
      "The representation loss after processing this batch is:  0.0034621581435203552\n",
      "\n",
      "The classification loss after processing this batch is:  0.3381776213645935\n",
      "The representation loss after processing this batch is:  0.0026673078536987305\n",
      "\n",
      "The classification loss after processing this batch is:  0.1112888753414154\n",
      "The representation loss after processing this batch is:  0.0034964457154273987\n",
      "\n",
      "The classification loss after processing this batch is:  0.15768203139305115\n",
      "The representation loss after processing this batch is:  0.003238476812839508\n",
      "\n",
      "The classification loss after processing this batch is:  0.23511455953121185\n",
      "The representation loss after processing this batch is:  0.0033489391207695007\n",
      "\n",
      "The classification loss after processing this batch is:  0.20158615708351135\n",
      "The representation loss after processing this batch is:  0.003305107355117798\n",
      "\n",
      "The classification loss after processing this batch is:  0.228946253657341\n",
      "The representation loss after processing this batch is:  0.003305472433567047\n",
      "\n",
      "The classification loss after processing this batch is:  0.10028430074453354\n",
      "The representation loss after processing this batch is:  0.002988003194332123\n",
      "\n",
      "The classification loss after processing this batch is:  0.11325164884328842\n",
      "The representation loss after processing this batch is:  0.0029947198927402496\n",
      "\n",
      "The classification loss after processing this batch is:  0.1254976987838745\n",
      "The representation loss after processing this batch is:  0.003243621438741684\n",
      "\n",
      "The classification loss after processing this batch is:  0.23545585572719574\n",
      "The representation loss after processing this batch is:  0.0034703612327575684\n",
      "\n",
      "The classification loss after processing this batch is:  0.251407265663147\n",
      "The representation loss after processing this batch is:  0.0031029991805553436\n",
      "\n",
      "The classification loss after processing this batch is:  0.23037464916706085\n",
      "The representation loss after processing this batch is:  0.0028236135840415955\n",
      "\n",
      "The classification loss after processing this batch is:  0.27531343698501587\n",
      "The representation loss after processing this batch is:  0.002914082258939743\n",
      "\n",
      "The classification loss after processing this batch is:  0.33128127455711365\n",
      "The representation loss after processing this batch is:  0.002878047525882721\n",
      "\n",
      "The classification loss after processing this batch is:  0.1857127845287323\n",
      "The representation loss after processing this batch is:  0.0030750036239624023\n",
      "\n",
      "The classification loss after processing this batch is:  0.3230346441268921\n",
      "The representation loss after processing this batch is:  0.0031066909432411194\n",
      "\n",
      "The classification loss after processing this batch is:  0.18270525336265564\n",
      "The representation loss after processing this batch is:  0.0032191798090934753\n",
      "\n",
      "The classification loss after processing this batch is:  0.11333861947059631\n",
      "The representation loss after processing this batch is:  0.002974189817905426\n",
      "\n",
      "The classification loss after processing this batch is:  0.1081070527434349\n",
      "The representation loss after processing this batch is:  0.0028278231620788574\n",
      "\n",
      "The classification loss after processing this batch is:  0.12197563052177429\n",
      "The representation loss after processing this batch is:  0.0030100569128990173\n",
      "\n",
      "The classification loss after processing this batch is:  0.32015547156333923\n",
      "The representation loss after processing this batch is:  0.003334447741508484\n",
      "\n",
      "The classification loss after processing this batch is:  0.13195356726646423\n",
      "The representation loss after processing this batch is:  0.002940431237220764\n",
      "\n",
      "The classification loss after processing this batch is:  0.18707101047039032\n",
      "The representation loss after processing this batch is:  0.003466181457042694\n",
      "\n",
      "The classification loss after processing this batch is:  0.19293050467967987\n",
      "The representation loss after processing this batch is:  0.003659769892692566\n",
      "\n",
      "The classification loss after processing this batch is:  0.20622247457504272\n",
      "The representation loss after processing this batch is:  0.003088526427745819\n",
      "\n",
      "The classification loss after processing this batch is:  0.15579074621200562\n",
      "The representation loss after processing this batch is:  0.0029858052730560303\n",
      "\n",
      "The classification loss after processing this batch is:  0.21525786817073822\n",
      "The representation loss after processing this batch is:  0.002716831862926483\n",
      "\n",
      "The classification loss after processing this batch is:  0.23713883757591248\n",
      "The representation loss after processing this batch is:  0.002801802009344101\n",
      "\n",
      "The classification loss after processing this batch is:  0.2550030052661896\n",
      "The representation loss after processing this batch is:  0.0034892186522483826\n",
      "\n",
      "The classification loss after processing this batch is:  0.12919121980667114\n",
      "The representation loss after processing this batch is:  0.0029141828417778015\n",
      "\n",
      "The classification loss after processing this batch is:  0.34390032291412354\n",
      "The representation loss after processing this batch is:  0.002447623759508133\n",
      "\n",
      "The classification loss after processing this batch is:  0.18495884537696838\n",
      "The representation loss after processing this batch is:  0.002843014895915985\n",
      "\n",
      "The classification loss after processing this batch is:  0.1674838662147522\n",
      "The representation loss after processing this batch is:  0.0026804618537425995\n",
      "\n",
      "The classification loss after processing this batch is:  0.16896438598632812\n",
      "The representation loss after processing this batch is:  0.0032299458980560303\n",
      "\n",
      "The classification loss after processing this batch is:  0.14492304623126984\n",
      "The representation loss after processing this batch is:  0.0029547959566116333\n",
      "\n",
      "The classification loss after processing this batch is:  0.12833918631076813\n",
      "The representation loss after processing this batch is:  0.002919994294643402\n",
      "\n",
      "The classification loss after processing this batch is:  0.13791635632514954\n",
      "The representation loss after processing this batch is:  0.0032564401626586914\n",
      "\n",
      "The classification loss after processing this batch is:  0.2321743369102478\n",
      "The representation loss after processing this batch is:  0.003200933337211609\n",
      "\n",
      "The classification loss after processing this batch is:  0.2611772119998932\n",
      "The representation loss after processing this batch is:  0.003094300627708435\n",
      "\n",
      "The classification loss after processing this batch is:  0.2363361418247223\n",
      "The representation loss after processing this batch is:  0.0032050833106040955\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.20443248748779297\n",
      "The representation loss after processing this batch is:  0.0030704662203788757\n",
      "\n",
      "The classification loss after processing this batch is:  0.20266875624656677\n",
      "The representation loss after processing this batch is:  0.0035775601863861084\n",
      "\n",
      "The classification loss after processing this batch is:  0.3047768175601959\n",
      "The representation loss after processing this batch is:  0.00274016335606575\n",
      "\n",
      "The classification loss after processing this batch is:  0.20730261504650116\n",
      "The representation loss after processing this batch is:  0.0027657300233840942\n",
      "\n",
      "The classification loss after processing this batch is:  0.06796108186244965\n",
      "The representation loss after processing this batch is:  0.00309772789478302\n",
      "\n",
      "The classification loss after processing this batch is:  0.1752428412437439\n",
      "The representation loss after processing this batch is:  0.00277598574757576\n",
      "\n",
      "The classification loss after processing this batch is:  0.3859221637248993\n",
      "The representation loss after processing this batch is:  0.0030188746750354767\n",
      "\n",
      "The classification loss after processing this batch is:  0.41585928201675415\n",
      "The representation loss after processing this batch is:  0.0030922293663024902\n",
      "\n",
      "The classification loss after processing this batch is:  0.3704628348350525\n",
      "The representation loss after processing this batch is:  0.0029041431844234467\n",
      "\n",
      "The classification loss after processing this batch is:  0.2567113935947418\n",
      "The representation loss after processing this batch is:  0.002808552235364914\n",
      "\n",
      "The classification loss after processing this batch is:  0.14403337240219116\n",
      "The representation loss after processing this batch is:  0.0029412247240543365\n",
      "\n",
      "The classification loss after processing this batch is:  0.17015355825424194\n",
      "The representation loss after processing this batch is:  0.002947211265563965\n",
      "\n",
      "The classification loss after processing this batch is:  0.16709694266319275\n",
      "The representation loss after processing this batch is:  0.0034327246248722076\n",
      "\n",
      "The classification loss after processing this batch is:  0.24434243142604828\n",
      "The representation loss after processing this batch is:  0.0033016428351402283\n",
      "\n",
      "The classification loss after processing this batch is:  0.20201273262500763\n",
      "The representation loss after processing this batch is:  0.003419749438762665\n",
      "\n",
      "The classification loss after processing this batch is:  0.22538794577121735\n",
      "The representation loss after processing this batch is:  0.003932841122150421\n",
      "\n",
      "The classification loss after processing this batch is:  0.1881445199251175\n",
      "The representation loss after processing this batch is:  0.0031118243932724\n",
      "\n",
      "The classification loss after processing this batch is:  0.18058954179286957\n",
      "The representation loss after processing this batch is:  0.0028852522373199463\n",
      "\n",
      "The classification loss after processing this batch is:  0.23129241168498993\n",
      "The representation loss after processing this batch is:  0.003559596836566925\n",
      "\n",
      "The classification loss after processing this batch is:  0.2502391040325165\n",
      "The representation loss after processing this batch is:  0.0027759894728660583\n",
      "\n",
      "The classification loss after processing this batch is:  0.19168470799922943\n",
      "The representation loss after processing this batch is:  0.0027147717773914337\n",
      "\n",
      "The classification loss after processing this batch is:  0.36890289187431335\n",
      "The representation loss after processing this batch is:  0.003531459718942642\n",
      "\n",
      "The classification loss after processing this batch is:  0.4090516269207001\n",
      "The representation loss after processing this batch is:  0.003161013126373291\n",
      "\n",
      "The classification loss after processing this batch is:  0.24049393832683563\n",
      "The representation loss after processing this batch is:  0.003300607204437256\n",
      "\n",
      "The classification loss after processing this batch is:  0.21930523216724396\n",
      "The representation loss after processing this batch is:  0.0032634884119033813\n",
      "\n",
      "The classification loss after processing this batch is:  0.15772151947021484\n",
      "The representation loss after processing this batch is:  0.003806851804256439\n",
      "\n",
      "The classification loss after processing this batch is:  0.09164292365312576\n",
      "The representation loss after processing this batch is:  0.0028965994715690613\n",
      "\n",
      "The classification loss after processing this batch is:  0.29624855518341064\n",
      "The representation loss after processing this batch is:  0.0028022825717926025\n",
      "\n",
      "The classification loss after processing this batch is:  0.2186448574066162\n",
      "The representation loss after processing this batch is:  0.0036531612277030945\n",
      "\n",
      "The classification loss after processing this batch is:  0.16236162185668945\n",
      "The representation loss after processing this batch is:  0.0035016611218452454\n",
      "\n",
      "The classification loss after processing this batch is:  0.2847200334072113\n",
      "The representation loss after processing this batch is:  0.0028160065412521362\n",
      "\n",
      "The classification loss after processing this batch is:  0.09049014747142792\n",
      "The representation loss after processing this batch is:  0.002827875316143036\n",
      "\n",
      "The classification loss after processing this batch is:  0.12798599898815155\n",
      "The representation loss after processing this batch is:  0.003176845610141754\n",
      "\n",
      "The classification loss after processing this batch is:  0.16688111424446106\n",
      "The representation loss after processing this batch is:  0.002749703824520111\n",
      "\n",
      "The classification loss after processing this batch is:  0.25557368993759155\n",
      "The representation loss after processing this batch is:  0.002977754920721054\n",
      "\n",
      "The classification loss after processing this batch is:  0.26461344957351685\n",
      "The representation loss after processing this batch is:  0.0030556991696357727\n",
      "\n",
      "The classification loss after processing this batch is:  0.1436627060174942\n",
      "The representation loss after processing this batch is:  0.0032082349061965942\n",
      "\n",
      "The classification loss after processing this batch is:  0.15309977531433105\n",
      "The representation loss after processing this batch is:  0.003166414797306061\n",
      "\n",
      "The classification loss after processing this batch is:  0.09100442379713058\n",
      "The representation loss after processing this batch is:  0.0028407201170921326\n",
      "\n",
      "The classification loss after processing this batch is:  0.11171653121709824\n",
      "The representation loss after processing this batch is:  0.002925761044025421\n",
      "\n",
      "The classification loss after processing this batch is:  0.1477026492357254\n",
      "The representation loss after processing this batch is:  0.003033094108104706\n",
      "\n",
      "The classification loss after processing this batch is:  0.102935791015625\n",
      "The representation loss after processing this batch is:  0.0030973106622695923\n",
      "\n",
      "The classification loss after processing this batch is:  0.17016111314296722\n",
      "The representation loss after processing this batch is:  0.002536393702030182\n",
      "\n",
      "The classification loss after processing this batch is:  0.18916447460651398\n",
      "The representation loss after processing this batch is:  0.0028587281703948975\n",
      "\n",
      "The classification loss after processing this batch is:  0.23861703276634216\n",
      "The representation loss after processing this batch is:  0.003282777965068817\n",
      "\n",
      "The classification loss after processing this batch is:  0.08499860018491745\n",
      "The representation loss after processing this batch is:  0.0024569332599639893\n",
      "\n",
      "The classification loss after processing this batch is:  0.1102476418018341\n",
      "The representation loss after processing this batch is:  0.0029549747705459595\n",
      "\n",
      "The classification loss after processing this batch is:  0.1508954018354416\n",
      "The representation loss after processing this batch is:  0.0034764260053634644\n",
      "\n",
      "The classification loss after processing this batch is:  0.22395910322666168\n",
      "The representation loss after processing this batch is:  0.00289226695895195\n",
      "\n",
      "The classification loss after processing this batch is:  0.11151449382305145\n",
      "The representation loss after processing this batch is:  0.003459557890892029\n",
      "\n",
      "The classification loss after processing this batch is:  0.32571685314178467\n",
      "The representation loss after processing this batch is:  0.00356457382440567\n",
      "\n",
      "The classification loss after processing this batch is:  0.2692373991012573\n",
      "The representation loss after processing this batch is:  0.0032049529254436493\n",
      "\n",
      "The classification loss after processing this batch is:  0.2709403932094574\n",
      "The representation loss after processing this batch is:  0.0030964910984039307\n",
      "\n",
      "The classification loss after processing this batch is:  0.16010287404060364\n",
      "The representation loss after processing this batch is:  0.0031151026487350464\n",
      "\n",
      "The classification loss after processing this batch is:  0.14299026131629944\n",
      "The representation loss after processing this batch is:  0.0029425621032714844\n",
      "\n",
      "The classification loss after processing this batch is:  0.1876128762960434\n",
      "The representation loss after processing this batch is:  0.0030802786350250244\n",
      "\n",
      "The classification loss after processing this batch is:  0.2344910353422165\n",
      "The representation loss after processing this batch is:  0.0030779168009757996\n",
      "\n",
      "The classification loss after processing this batch is:  0.1309332251548767\n",
      "The representation loss after processing this batch is:  0.0029291436076164246\n",
      "\n",
      "The classification loss after processing this batch is:  0.06852038204669952\n",
      "The representation loss after processing this batch is:  0.0027287155389785767\n",
      "\n",
      "The classification loss after processing this batch is:  0.25629422068595886\n",
      "The representation loss after processing this batch is:  0.0032144561409950256\n",
      "\n",
      "The classification loss after processing this batch is:  0.27618029713630676\n",
      "The representation loss after processing this batch is:  0.002837788313627243\n",
      "\n",
      "The classification loss after processing this batch is:  0.2106369435787201\n",
      "The representation loss after processing this batch is:  0.0027253180742263794\n",
      "\n",
      "The classification loss after processing this batch is:  0.3062460720539093\n",
      "The representation loss after processing this batch is:  0.002809852361679077\n",
      "\n",
      "The classification loss after processing this batch is:  0.32117870450019836\n",
      "The representation loss after processing this batch is:  0.0032832324504852295\n",
      "\n",
      "The classification loss after processing this batch is:  0.4372411072254181\n",
      "The representation loss after processing this batch is:  0.0028175637125968933\n",
      "\n",
      "The classification loss after processing this batch is:  0.24822218716144562\n",
      "The representation loss after processing this batch is:  0.002946704626083374\n",
      "\n",
      "The classification loss after processing this batch is:  0.15687443315982819\n",
      "The representation loss after processing this batch is:  0.0030606985092163086\n",
      "\n",
      "The classification loss after processing this batch is:  0.2505973279476166\n",
      "The representation loss after processing this batch is:  0.003278769552707672\n",
      "\n",
      "The classification loss after processing this batch is:  0.16422811150550842\n",
      "The representation loss after processing this batch is:  0.003047935664653778\n",
      "\n",
      "The classification loss after processing this batch is:  0.14210687577724457\n",
      "The representation loss after processing this batch is:  0.0031044557690620422\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.138570174574852\n",
      "The representation loss after processing this batch is:  0.0031022056937217712\n",
      "\n",
      "The classification loss after processing this batch is:  0.1098315566778183\n",
      "The representation loss after processing this batch is:  0.0028268471360206604\n",
      "\n",
      "The classification loss after processing this batch is:  0.07564757764339447\n",
      "The representation loss after processing this batch is:  0.003482051193714142\n",
      "\n",
      "The classification loss after processing this batch is:  0.2111610621213913\n",
      "The representation loss after processing this batch is:  0.002917114645242691\n",
      "\n",
      "The classification loss after processing this batch is:  0.2578680217266083\n",
      "The representation loss after processing this batch is:  0.002904452383518219\n",
      "\n",
      "The classification loss after processing this batch is:  0.12744887173175812\n",
      "The representation loss after processing this batch is:  0.003105156123638153\n",
      "\n",
      "The classification loss after processing this batch is:  0.16286568343639374\n",
      "The representation loss after processing this batch is:  0.0026959776878356934\n",
      "\n",
      "The classification loss after processing this batch is:  0.18357780575752258\n",
      "The representation loss after processing this batch is:  0.0030598193407058716\n",
      "\n",
      "The classification loss after processing this batch is:  0.08122850209474564\n",
      "The representation loss after processing this batch is:  0.0029596760869026184\n",
      "\n",
      "The classification loss after processing this batch is:  0.315098375082016\n",
      "The representation loss after processing this batch is:  0.002952471375465393\n",
      "\n",
      "The classification loss after processing this batch is:  0.16597825288772583\n",
      "The representation loss after processing this batch is:  0.0027876943349838257\n",
      "\n",
      "The classification loss after processing this batch is:  0.30206096172332764\n",
      "The representation loss after processing this batch is:  0.003081105649471283\n",
      "\n",
      "The classification loss after processing this batch is:  0.21762295067310333\n",
      "The representation loss after processing this batch is:  0.0032275021076202393\n",
      "\n",
      "The classification loss after processing this batch is:  0.2693701386451721\n",
      "The representation loss after processing this batch is:  0.002876628190279007\n",
      "\n",
      "The classification loss after processing this batch is:  0.07864923030138016\n",
      "The representation loss after processing this batch is:  0.003137752413749695\n",
      "\n",
      "The classification loss after processing this batch is:  0.10054343193769455\n",
      "The representation loss after processing this batch is:  0.002808414399623871\n",
      "\n",
      "The classification loss after processing this batch is:  0.21056729555130005\n",
      "The representation loss after processing this batch is:  0.002869885414838791\n",
      "\n",
      "The classification loss after processing this batch is:  0.10967525094747543\n",
      "The representation loss after processing this batch is:  0.0032884329557418823\n",
      "\n",
      "The classification loss after processing this batch is:  0.24906907975673676\n",
      "The representation loss after processing this batch is:  0.003219880163669586\n",
      "\n",
      "The classification loss after processing this batch is:  0.13212454319000244\n",
      "The representation loss after processing this batch is:  0.003196246922016144\n",
      "\n",
      "The classification loss after processing this batch is:  0.18053892254829407\n",
      "The representation loss after processing this batch is:  0.003444187343120575\n",
      "\n",
      "The classification loss after processing this batch is:  0.2187715321779251\n",
      "The representation loss after processing this batch is:  0.0028262436389923096\n",
      "\n",
      "The classification loss after processing this batch is:  0.14357605576515198\n",
      "The representation loss after processing this batch is:  0.003300286829471588\n",
      "\n",
      "The classification loss after processing this batch is:  0.15432891249656677\n",
      "The representation loss after processing this batch is:  0.003400459885597229\n",
      "\n",
      "The classification loss after processing this batch is:  0.2727203667163849\n",
      "The representation loss after processing this batch is:  0.0031975731253623962\n",
      "\n",
      "The classification loss after processing this batch is:  0.18838396668434143\n",
      "The representation loss after processing this batch is:  0.00319787859916687\n",
      "\n",
      "The classification loss after processing this batch is:  0.2851909399032593\n",
      "The representation loss after processing this batch is:  0.0033040717244148254\n",
      "\n",
      "The classification loss after processing this batch is:  0.2739552855491638\n",
      "The representation loss after processing this batch is:  0.0031148865818977356\n",
      "\n",
      "The classification loss after processing this batch is:  0.23680900037288666\n",
      "The representation loss after processing this batch is:  0.0028741806745529175\n",
      "\n",
      "The classification loss after processing this batch is:  0.15118806064128876\n",
      "The representation loss after processing this batch is:  0.0031474456191062927\n",
      "\n",
      "The classification loss after processing this batch is:  0.11984850466251373\n",
      "The representation loss after processing this batch is:  0.0029102563858032227\n",
      "\n",
      "The classification loss after processing this batch is:  0.1173422709107399\n",
      "The representation loss after processing this batch is:  0.0031107068061828613\n",
      "\n",
      "The classification loss after processing this batch is:  0.11172854155302048\n",
      "The representation loss after processing this batch is:  0.003490656614303589\n",
      "\n",
      "The classification loss after processing this batch is:  0.19012083113193512\n",
      "The representation loss after processing this batch is:  0.0024788230657577515\n",
      "\n",
      "The classification loss after processing this batch is:  0.1693224310874939\n",
      "The representation loss after processing this batch is:  0.0031334608793258667\n",
      "\n",
      "The classification loss after processing this batch is:  0.17990459501743317\n",
      "The representation loss after processing this batch is:  0.0035292208194732666\n",
      "\n",
      "The classification loss after processing this batch is:  0.13674093782901764\n",
      "The representation loss after processing this batch is:  0.0029546022415161133\n",
      "\n",
      "The classification loss after processing this batch is:  0.22002333402633667\n",
      "The representation loss after processing this batch is:  0.002673819661140442\n",
      "\n",
      "The classification loss after processing this batch is:  0.15562622249126434\n",
      "The representation loss after processing this batch is:  0.0029048100113868713\n",
      "\n",
      "The classification loss after processing this batch is:  0.20050926506519318\n",
      "The representation loss after processing this batch is:  0.0029668211936950684\n",
      "\n",
      "The classification loss after processing this batch is:  0.23168770968914032\n",
      "The representation loss after processing this batch is:  0.0029489323496818542\n",
      "\n",
      "The classification loss after processing this batch is:  0.18501584231853485\n",
      "The representation loss after processing this batch is:  0.0030211135745048523\n",
      "\n",
      "The classification loss after processing this batch is:  0.15240556001663208\n",
      "The representation loss after processing this batch is:  0.0031598731875419617\n",
      "\n",
      "The classification loss after processing this batch is:  0.24510832130908966\n",
      "The representation loss after processing this batch is:  0.0033749639987945557\n",
      "\n",
      "The classification loss after processing this batch is:  0.10157044231891632\n",
      "The representation loss after processing this batch is:  0.002993166446685791\n",
      "\n",
      "The classification loss after processing this batch is:  0.12739792466163635\n",
      "The representation loss after processing this batch is:  0.002895079553127289\n",
      "\n",
      "The classification loss after processing this batch is:  0.1676066368818283\n",
      "The representation loss after processing this batch is:  0.002874918282032013\n",
      "\n",
      "The classification loss after processing this batch is:  0.1312084048986435\n",
      "The representation loss after processing this batch is:  0.0034841299057006836\n",
      "\n",
      "The classification loss after processing this batch is:  0.21662171185016632\n",
      "The representation loss after processing this batch is:  0.0026091746985912323\n",
      "\n",
      "The classification loss after processing this batch is:  0.25465020537376404\n",
      "The representation loss after processing this batch is:  0.002951420843601227\n",
      "\n",
      "The classification loss after processing this batch is:  0.17456701397895813\n",
      "The representation loss after processing this batch is:  0.0034937113523483276\n",
      "\n",
      "The classification loss after processing this batch is:  0.13996145129203796\n",
      "The representation loss after processing this batch is:  0.00356852263212204\n",
      "\n",
      "The classification loss after processing this batch is:  0.12889762222766876\n",
      "The representation loss after processing this batch is:  0.0030063018202781677\n",
      "\n",
      "The classification loss after processing this batch is:  0.3391295373439789\n",
      "The representation loss after processing this batch is:  0.0032087452709674835\n",
      "\n",
      "The classification loss after processing this batch is:  0.09312070906162262\n",
      "The representation loss after processing this batch is:  0.0031461119651794434\n",
      "\n",
      "The classification loss after processing this batch is:  0.17916177213191986\n",
      "The representation loss after processing this batch is:  0.0031698942184448242\n",
      "\n",
      "The classification loss after processing this batch is:  0.23953653872013092\n",
      "The representation loss after processing this batch is:  0.0028027407824993134\n",
      "\n",
      "The classification loss after processing this batch is:  0.38077932596206665\n",
      "The representation loss after processing this batch is:  0.0030559226870536804\n",
      "\n",
      "The classification loss after processing this batch is:  0.15567727386951447\n",
      "The representation loss after processing this batch is:  0.0030992552638053894\n",
      "\n",
      "The classification loss after processing this batch is:  0.20454111695289612\n",
      "The representation loss after processing this batch is:  0.002986796200275421\n",
      "\n",
      "The classification loss after processing this batch is:  0.12984664738178253\n",
      "The representation loss after processing this batch is:  0.0028847455978393555\n",
      "\n",
      "The classification loss after processing this batch is:  0.0775194987654686\n",
      "The representation loss after processing this batch is:  0.003229305148124695\n",
      "\n",
      "The classification loss after processing this batch is:  0.1987745761871338\n",
      "The representation loss after processing this batch is:  0.003544725477695465\n",
      "\n",
      "The classification loss after processing this batch is:  0.13981539011001587\n",
      "The representation loss after processing this batch is:  0.003865770995616913\n",
      "\n",
      "The classification loss after processing this batch is:  0.10240001976490021\n",
      "The representation loss after processing this batch is:  0.0032527409493923187\n",
      "\n",
      "The classification loss after processing this batch is:  0.12298626452684402\n",
      "The representation loss after processing this batch is:  0.002687707543373108\n",
      "\n",
      "The classification loss after processing this batch is:  0.21945995092391968\n",
      "The representation loss after processing this batch is:  0.0027522780001163483\n",
      "\n",
      "The classification loss after processing this batch is:  0.22139449417591095\n",
      "The representation loss after processing this batch is:  0.002909339964389801\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.13545452058315277\n",
      "The representation loss after processing this batch is:  0.0025949254631996155\n",
      "\n",
      "The classification loss after processing this batch is:  0.211440309882164\n",
      "The representation loss after processing this batch is:  0.0029337555170059204\n",
      "\n",
      "The classification loss after processing this batch is:  0.2383878082036972\n",
      "The representation loss after processing this batch is:  0.0026813186705112457\n",
      "\n",
      "The classification loss after processing this batch is:  0.24613304436206818\n",
      "The representation loss after processing this batch is:  0.0030143633484840393\n",
      "\n",
      "The classification loss after processing this batch is:  0.2347269058227539\n",
      "The representation loss after processing this batch is:  0.0027673542499542236\n",
      "\n",
      "The classification loss after processing this batch is:  0.23486825823783875\n",
      "The representation loss after processing this batch is:  0.003305785357952118\n",
      "\n",
      "The classification loss after processing this batch is:  0.35626888275146484\n",
      "The representation loss after processing this batch is:  0.003245413303375244\n",
      "\n",
      "The classification loss after processing this batch is:  0.1500271111726761\n",
      "The representation loss after processing this batch is:  0.003078736364841461\n",
      "\n",
      "The classification loss after processing this batch is:  0.1249745711684227\n",
      "The representation loss after processing this batch is:  0.0032955557107925415\n",
      "\n",
      "The classification loss after processing this batch is:  0.100956030189991\n",
      "The representation loss after processing this batch is:  0.0026726722717285156\n",
      "\n",
      "The classification loss after processing this batch is:  0.1315888911485672\n",
      "The representation loss after processing this batch is:  0.0028130635619163513\n",
      "\n",
      "The classification loss after processing this batch is:  0.270320326089859\n",
      "The representation loss after processing this batch is:  0.002963770180940628\n",
      "\n",
      "The classification loss after processing this batch is:  0.19156479835510254\n",
      "The representation loss after processing this batch is:  0.0035000890493392944\n",
      "\n",
      "The classification loss after processing this batch is:  0.1019144207239151\n",
      "The representation loss after processing this batch is:  0.0025858357548713684\n",
      "\n",
      "The classification loss after processing this batch is:  0.07583504170179367\n",
      "The representation loss after processing this batch is:  0.003341861069202423\n",
      "\n",
      "The classification loss after processing this batch is:  0.09740681946277618\n",
      "The representation loss after processing this batch is:  0.00335703045129776\n",
      "\n",
      "The classification loss after processing this batch is:  0.15409435331821442\n",
      "The representation loss after processing this batch is:  0.003906525671482086\n",
      "\n",
      "The classification loss after processing this batch is:  0.16028611361980438\n",
      "The representation loss after processing this batch is:  0.0033705681562423706\n",
      "\n",
      "The classification loss after processing this batch is:  0.10079748183488846\n",
      "The representation loss after processing this batch is:  0.0031473785638809204\n",
      "\n",
      "The classification loss after processing this batch is:  0.07653147727251053\n",
      "The representation loss after processing this batch is:  0.0035737305879592896\n",
      "\n",
      "The classification loss after processing this batch is:  0.12358841300010681\n",
      "The representation loss after processing this batch is:  0.003504432737827301\n",
      "\n",
      "The classification loss after processing this batch is:  0.13120941817760468\n",
      "The representation loss after processing this batch is:  0.0037003904581069946\n",
      "\n",
      "The classification loss after processing this batch is:  0.0626475065946579\n",
      "The representation loss after processing this batch is:  0.004134699702262878\n",
      "\n",
      "The classification loss after processing this batch is:  0.09420368820428848\n",
      "The representation loss after processing this batch is:  0.003227710723876953\n",
      "\n",
      "The classification loss after processing this batch is:  0.23668482899665833\n",
      "The representation loss after processing this batch is:  0.003234565258026123\n",
      "\n",
      "The classification loss after processing this batch is:  0.07879658043384552\n",
      "The representation loss after processing this batch is:  0.003682367503643036\n",
      "\n",
      "The classification loss after processing this batch is:  0.04355787858366966\n",
      "The representation loss after processing this batch is:  0.003512457013130188\n",
      "\n",
      "The classification loss after processing this batch is:  0.08855222910642624\n",
      "The representation loss after processing this batch is:  0.003327317535877228\n",
      "\n",
      "The classification loss after processing this batch is:  0.08361338824033737\n",
      "The representation loss after processing this batch is:  0.0035640373826026917\n",
      "\n",
      "The classification loss after processing this batch is:  0.06193436682224274\n",
      "The representation loss after processing this batch is:  0.0032545626163482666\n",
      "\n",
      "The classification loss after processing this batch is:  0.060047414153814316\n",
      "The representation loss after processing this batch is:  0.003868497908115387\n",
      "\n",
      "The classification loss after processing this batch is:  0.04930059611797333\n",
      "The representation loss after processing this batch is:  0.003935806453227997\n",
      "\n",
      "The classification loss after processing this batch is:  0.34381815791130066\n",
      "The representation loss after processing this batch is:  0.003925032913684845\n",
      "\n",
      "The classification loss after processing this batch is:  0.3397357761859894\n",
      "The representation loss after processing this batch is:  0.003925323486328125\n",
      "\n",
      "The classification loss after processing this batch is:  0.2978460192680359\n",
      "The representation loss after processing this batch is:  0.003826253116130829\n",
      "\n",
      "The classification loss after processing this batch is:  0.07274440675973892\n",
      "The representation loss after processing this batch is:  0.002992101013660431\n",
      "\n",
      "The classification loss after processing this batch is:  0.057120032608509064\n",
      "The representation loss after processing this batch is:  0.003841690719127655\n",
      "\n",
      "The classification loss after processing this batch is:  0.054314397275447845\n",
      "The representation loss after processing this batch is:  0.0026077479124069214\n",
      "\n",
      "The classification loss after processing this batch is:  0.15179748833179474\n",
      "The representation loss after processing this batch is:  0.0026098117232322693\n",
      "\n",
      "The classification loss after processing this batch is:  0.35077518224716187\n",
      "The representation loss after processing this batch is:  0.003340497612953186\n",
      "\n",
      "The classification loss after processing this batch is:  0.1369238793849945\n",
      "The representation loss after processing this batch is:  0.0029574111104011536\n",
      "\n",
      "The classification loss after processing this batch is:  0.1048414334654808\n",
      "The representation loss after processing this batch is:  0.003596976399421692\n",
      "\n",
      "The classification loss after processing this batch is:  0.11488249152898788\n",
      "The representation loss after processing this batch is:  0.0035445764660835266\n",
      "\n",
      "The classification loss after processing this batch is:  0.09176433831453323\n",
      "The representation loss after processing this batch is:  0.004199914634227753\n",
      "\n",
      "The classification loss after processing this batch is:  0.18272212147712708\n",
      "The representation loss after processing this batch is:  0.002925306558609009\n",
      "\n",
      "The classification loss after processing this batch is:  0.07669883221387863\n",
      "The representation loss after processing this batch is:  0.0030323266983032227\n",
      "\n",
      "The classification loss after processing this batch is:  0.15634068846702576\n",
      "The representation loss after processing this batch is:  0.0030824169516563416\n",
      "\n",
      "The classification loss after processing this batch is:  0.120792455971241\n",
      "The representation loss after processing this batch is:  0.0031902864575386047\n",
      "\n",
      "The classification loss after processing this batch is:  0.21417805552482605\n",
      "The representation loss after processing this batch is:  0.003021031618118286\n",
      "\n",
      "The classification loss after processing this batch is:  0.12249290198087692\n",
      "The representation loss after processing this batch is:  0.0033425018191337585\n",
      "\n",
      "The classification loss after processing this batch is:  0.1410086750984192\n",
      "The representation loss after processing this batch is:  0.003461278975009918\n",
      "\n",
      "The classification loss after processing this batch is:  0.1751452386379242\n",
      "The representation loss after processing this batch is:  0.002794302999973297\n",
      "\n",
      "The classification loss after processing this batch is:  0.21894732117652893\n",
      "The representation loss after processing this batch is:  0.0027449168264865875\n",
      "\n",
      "The classification loss after processing this batch is:  0.16129866242408752\n",
      "The representation loss after processing this batch is:  0.0029709599912166595\n",
      "\n",
      "The classification loss after processing this batch is:  0.2566986382007599\n",
      "The representation loss after processing this batch is:  0.0028338395059108734\n",
      "\n",
      "The classification loss after processing this batch is:  0.1714968979358673\n",
      "The representation loss after processing this batch is:  0.0028727762401103973\n",
      "\n",
      "The classification loss after processing this batch is:  0.217830628156662\n",
      "The representation loss after processing this batch is:  0.0035365596413612366\n",
      "\n",
      "The classification loss after processing this batch is:  0.12071866542100906\n",
      "The representation loss after processing this batch is:  0.003052450716495514\n",
      "\n",
      "The classification loss after processing this batch is:  0.3425961434841156\n",
      "The representation loss after processing this batch is:  0.0028817765414714813\n",
      "\n",
      "The classification loss after processing this batch is:  0.17436771094799042\n",
      "The representation loss after processing this batch is:  0.0025786086916923523\n",
      "\n",
      "The classification loss after processing this batch is:  0.16896004974842072\n",
      "The representation loss after processing this batch is:  0.002961777150630951\n",
      "\n",
      "The classification loss after processing this batch is:  0.2818630039691925\n",
      "The representation loss after processing this batch is:  0.003026556223630905\n",
      "\n",
      "The classification loss after processing this batch is:  0.24700793623924255\n",
      "The representation loss after processing this batch is:  0.002942979335784912\n",
      "\n",
      "The classification loss after processing this batch is:  0.11659380793571472\n",
      "The representation loss after processing this batch is:  0.003184698522090912\n",
      "\n",
      "The classification loss after processing this batch is:  0.31896162033081055\n",
      "The representation loss after processing this batch is:  0.003970786929130554\n",
      "\n",
      "The classification loss after processing this batch is:  0.21308909356594086\n",
      "The representation loss after processing this batch is:  0.0032372884452342987\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.35330137610435486\n",
      "The representation loss after processing this batch is:  0.002874411642551422\n",
      "\n",
      "The classification loss after processing this batch is:  0.14552466571331024\n",
      "The representation loss after processing this batch is:  0.002673868089914322\n",
      "\n",
      "The classification loss after processing this batch is:  0.13191699981689453\n",
      "The representation loss after processing this batch is:  0.0028965845704078674\n",
      "\n",
      "The classification loss after processing this batch is:  0.14223365485668182\n",
      "The representation loss after processing this batch is:  0.0028172284364700317\n",
      "\n",
      "The classification loss after processing this batch is:  0.21469077467918396\n",
      "The representation loss after processing this batch is:  0.002738896757364273\n",
      "\n",
      "The classification loss after processing this batch is:  0.1507931649684906\n",
      "The representation loss after processing this batch is:  0.0030331164598464966\n",
      "\n",
      "The classification loss after processing this batch is:  0.08415685594081879\n",
      "The representation loss after processing this batch is:  0.0028807222843170166\n",
      "\n",
      "The classification loss after processing this batch is:  0.07057128101587296\n",
      "The representation loss after processing this batch is:  0.002916857600212097\n",
      "\n",
      "The classification loss after processing this batch is:  0.1067124605178833\n",
      "The representation loss after processing this batch is:  0.00263088196516037\n",
      "\n",
      "The classification loss after processing this batch is:  0.13660889863967896\n",
      "The representation loss after processing this batch is:  0.0029977522790431976\n",
      "\n",
      "The classification loss after processing this batch is:  0.20491951704025269\n",
      "The representation loss after processing this batch is:  0.0032346211373806\n",
      "\n",
      "The classification loss after processing this batch is:  0.1572876125574112\n",
      "The representation loss after processing this batch is:  0.003118414431810379\n",
      "\n",
      "The classification loss after processing this batch is:  0.1487649530172348\n",
      "The representation loss after processing this batch is:  0.0028903745114803314\n",
      "\n",
      "The classification loss after processing this batch is:  0.08936616778373718\n",
      "The representation loss after processing this batch is:  0.0028969794511795044\n",
      "\n",
      "The classification loss after processing this batch is:  0.12337958067655563\n",
      "The representation loss after processing this batch is:  0.0031036585569381714\n",
      "\n",
      "The classification loss after processing this batch is:  0.12588182091712952\n",
      "The representation loss after processing this batch is:  0.0028847455978393555\n",
      "\n",
      "The classification loss after processing this batch is:  0.08289563655853271\n",
      "The representation loss after processing this batch is:  0.0030449852347373962\n",
      "\n",
      "The classification loss after processing this batch is:  0.16039510071277618\n",
      "The representation loss after processing this batch is:  0.003071792423725128\n",
      "\n",
      "The classification loss after processing this batch is:  0.2815427780151367\n",
      "The representation loss after processing this batch is:  0.003276146948337555\n",
      "\n",
      "The classification loss after processing this batch is:  0.17971257865428925\n",
      "The representation loss after processing this batch is:  0.0031018853187561035\n",
      "\n",
      "The classification loss after processing this batch is:  0.17833760380744934\n",
      "The representation loss after processing this batch is:  0.002804584801197052\n",
      "\n",
      "The classification loss after processing this batch is:  0.18476656079292297\n",
      "The representation loss after processing this batch is:  0.0028654485940933228\n",
      "\n",
      "The classification loss after processing this batch is:  0.13527263700962067\n",
      "The representation loss after processing this batch is:  0.0028223544359207153\n",
      "\n",
      "The classification loss after processing this batch is:  0.14643971621990204\n",
      "The representation loss after processing this batch is:  0.002629674971103668\n",
      "\n",
      "The classification loss after processing this batch is:  0.27478039264678955\n",
      "The representation loss after processing this batch is:  0.0033051669597625732\n",
      "\n",
      "The classification loss after processing this batch is:  0.1129126027226448\n",
      "The representation loss after processing this batch is:  0.003013189882040024\n",
      "\n",
      "The classification loss after processing this batch is:  0.20003481209278107\n",
      "The representation loss after processing this batch is:  0.0028545930981636047\n",
      "\n",
      "The classification loss after processing this batch is:  0.15988852083683014\n",
      "The representation loss after processing this batch is:  0.003112107515335083\n",
      "\n",
      "The classification loss after processing this batch is:  0.17859452962875366\n",
      "The representation loss after processing this batch is:  0.0027995966374874115\n",
      "\n",
      "The classification loss after processing this batch is:  0.19160890579223633\n",
      "The representation loss after processing this batch is:  0.0031266696751117706\n",
      "\n",
      "The classification loss after processing this batch is:  0.12026515603065491\n",
      "The representation loss after processing this batch is:  0.00301414355635643\n",
      "\n",
      "The classification loss after processing this batch is:  0.12782886624336243\n",
      "The representation loss after processing this batch is:  0.0031958073377609253\n",
      "\n",
      "The classification loss after processing this batch is:  0.16945242881774902\n",
      "The representation loss after processing this batch is:  0.0033186674118041992\n",
      "\n",
      "The classification loss after processing this batch is:  0.18813927471637726\n",
      "The representation loss after processing this batch is:  0.003007955849170685\n",
      "\n",
      "The classification loss after processing this batch is:  0.19489242136478424\n",
      "The representation loss after processing this batch is:  0.00249655544757843\n",
      "\n",
      "The classification loss after processing this batch is:  0.14513714611530304\n",
      "The representation loss after processing this batch is:  0.003569953143596649\n",
      "\n",
      "The classification loss after processing this batch is:  0.2270154356956482\n",
      "The representation loss after processing this batch is:  0.0031628161668777466\n",
      "\n",
      "The classification loss after processing this batch is:  0.09840475767850876\n",
      "The representation loss after processing this batch is:  0.0027708783745765686\n",
      "\n",
      "The classification loss after processing this batch is:  0.10075170546770096\n",
      "The representation loss after processing this batch is:  0.002633761614561081\n",
      "\n",
      "The classification loss after processing this batch is:  0.19148406386375427\n",
      "The representation loss after processing this batch is:  0.0028973817825317383\n",
      "\n",
      "The classification loss after processing this batch is:  0.2303137183189392\n",
      "The representation loss after processing this batch is:  0.0026722922921180725\n",
      "\n",
      "The classification loss after processing this batch is:  0.12250108271837234\n",
      "The representation loss after processing this batch is:  0.0027984455227851868\n",
      "\n",
      "The classification loss after processing this batch is:  0.15201567113399506\n",
      "The representation loss after processing this batch is:  0.0028087347745895386\n",
      "\n",
      "The classification loss after processing this batch is:  0.10619863122701645\n",
      "The representation loss after processing this batch is:  0.0030217990279197693\n",
      "\n",
      "The classification loss after processing this batch is:  0.1879478543996811\n",
      "The representation loss after processing this batch is:  0.003324747085571289\n",
      "\n",
      "The classification loss after processing this batch is:  0.17168623208999634\n",
      "The representation loss after processing this batch is:  0.0026849843561649323\n",
      "\n",
      "The classification loss after processing this batch is:  0.09726244956254959\n",
      "The representation loss after processing this batch is:  0.003196828067302704\n",
      "\n",
      "The classification loss after processing this batch is:  0.2601608633995056\n",
      "The representation loss after processing this batch is:  0.0027903057634830475\n",
      "\n",
      "The classification loss after processing this batch is:  0.17445042729377747\n",
      "The representation loss after processing this batch is:  0.002778850495815277\n",
      "\n",
      "The classification loss after processing this batch is:  0.18656057119369507\n",
      "The representation loss after processing this batch is:  0.003036417067050934\n",
      "\n",
      "The classification loss after processing this batch is:  0.13327866792678833\n",
      "The representation loss after processing this batch is:  0.00255565345287323\n",
      "\n",
      "The classification loss after processing this batch is:  0.12195523083209991\n",
      "The representation loss after processing this batch is:  0.003016740083694458\n",
      "\n",
      "The classification loss after processing this batch is:  0.1794341504573822\n",
      "The representation loss after processing this batch is:  0.0026495903730392456\n",
      "\n",
      "The classification loss after processing this batch is:  0.22011767327785492\n",
      "The representation loss after processing this batch is:  0.002579905092716217\n",
      "\n",
      "The classification loss after processing this batch is:  0.13238780200481415\n",
      "The representation loss after processing this batch is:  0.0027653947472572327\n",
      "\n",
      "The classification loss after processing this batch is:  0.3464871048927307\n",
      "The representation loss after processing this batch is:  0.00267014279961586\n",
      "\n",
      "The classification loss after processing this batch is:  0.17404718697071075\n",
      "The representation loss after processing this batch is:  0.002724241465330124\n",
      "\n",
      "The classification loss after processing this batch is:  0.10540031641721725\n",
      "The representation loss after processing this batch is:  0.0033462122082710266\n",
      "\n",
      "The classification loss after processing this batch is:  0.1800525188446045\n",
      "The representation loss after processing this batch is:  0.002770237624645233\n",
      "\n",
      "The classification loss after processing this batch is:  0.1147928535938263\n",
      "The representation loss after processing this batch is:  0.0030452460050582886\n",
      "\n",
      "The classification loss after processing this batch is:  0.34164753556251526\n",
      "The representation loss after processing this batch is:  0.003063701093196869\n",
      "\n",
      "The classification loss after processing this batch is:  0.1704856902360916\n",
      "The representation loss after processing this batch is:  0.0029854923486709595\n",
      "\n",
      "The classification loss after processing this batch is:  0.16651365160942078\n",
      "The representation loss after processing this batch is:  0.0026748254895210266\n",
      "\n",
      "The classification loss after processing this batch is:  0.4067029356956482\n",
      "The representation loss after processing this batch is:  0.002672843635082245\n",
      "\n",
      "The classification loss after processing this batch is:  0.19576428830623627\n",
      "The representation loss after processing this batch is:  0.002887822687625885\n",
      "\n",
      "The classification loss after processing this batch is:  0.10788624733686447\n",
      "The representation loss after processing this batch is:  0.003067798912525177\n",
      "\n",
      "The classification loss after processing this batch is:  0.19450895488262177\n",
      "The representation loss after processing this batch is:  0.002745121717453003\n",
      "\n",
      "The classification loss after processing this batch is:  0.18908223509788513\n",
      "The representation loss after processing this batch is:  0.0030576586723327637\n",
      "\n",
      "The classification loss after processing this batch is:  0.18878303468227386\n",
      "The representation loss after processing this batch is:  0.0031815022230148315\n",
      "\n",
      "The classification loss after processing this batch is:  0.10135864466428757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.0026766955852508545\n",
      "\n",
      "The classification loss after processing this batch is:  0.1666446179151535\n",
      "The representation loss after processing this batch is:  0.002899467945098877\n",
      "\n",
      "The classification loss after processing this batch is:  0.2195308953523636\n",
      "The representation loss after processing this batch is:  0.0029075518250465393\n",
      "\n",
      "The classification loss after processing this batch is:  0.18356582522392273\n",
      "The representation loss after processing this batch is:  0.0032515302300453186\n",
      "\n",
      "The classification loss after processing this batch is:  0.23582573235034943\n",
      "The representation loss after processing this batch is:  0.002826165407896042\n",
      "\n",
      "The classification loss after processing this batch is:  0.2825860381126404\n",
      "The representation loss after processing this batch is:  0.003438815474510193\n",
      "\n",
      "The classification loss after processing this batch is:  0.2457025796175003\n",
      "The representation loss after processing this batch is:  0.0032075345516204834\n",
      "\n",
      "The classification loss after processing this batch is:  0.1281517595052719\n",
      "The representation loss after processing this batch is:  0.0034104958176612854\n",
      "\n",
      "The classification loss after processing this batch is:  0.14624382555484772\n",
      "The representation loss after processing this batch is:  0.0029311776161193848\n",
      "\n",
      "The classification loss after processing this batch is:  0.09050261974334717\n",
      "The representation loss after processing this batch is:  0.0028411895036697388\n",
      "\n",
      "The classification loss after processing this batch is:  0.17513863742351532\n",
      "The representation loss after processing this batch is:  0.002752862870693207\n",
      "\n",
      "The classification loss after processing this batch is:  0.18023797869682312\n",
      "The representation loss after processing this batch is:  0.002834402024745941\n",
      "\n",
      "The classification loss after processing this batch is:  0.29469165205955505\n",
      "The representation loss after processing this batch is:  0.0030679255723953247\n",
      "\n",
      "The classification loss after processing this batch is:  0.326532244682312\n",
      "The representation loss after processing this batch is:  0.0033200308680534363\n",
      "\n",
      "The classification loss after processing this batch is:  0.15249115228652954\n",
      "The representation loss after processing this batch is:  0.003063291311264038\n",
      "\n",
      "The classification loss after processing this batch is:  0.16727273166179657\n",
      "The representation loss after processing this batch is:  0.003098323941230774\n",
      "\n",
      "The classification loss after processing this batch is:  0.22459235787391663\n",
      "The representation loss after processing this batch is:  0.0027872025966644287\n",
      "\n",
      "The classification loss after processing this batch is:  0.10526220500469208\n",
      "The representation loss after processing this batch is:  0.0031949803233146667\n",
      "\n",
      "The classification loss after processing this batch is:  0.11420920491218567\n",
      "The representation loss after processing this batch is:  0.003103308379650116\n",
      "\n",
      "The classification loss after processing this batch is:  0.1917424201965332\n",
      "The representation loss after processing this batch is:  0.002991229295730591\n",
      "\n",
      "The classification loss after processing this batch is:  0.17410239577293396\n",
      "The representation loss after processing this batch is:  0.0038404464721679688\n",
      "\n",
      "The classification loss after processing this batch is:  0.11003569513559341\n",
      "The representation loss after processing this batch is:  0.003050025552511215\n",
      "\n",
      "The classification loss after processing this batch is:  0.3310326933860779\n",
      "The representation loss after processing this batch is:  0.0041902512311935425\n",
      "\n",
      "The classification loss after processing this batch is:  0.33439889550209045\n",
      "The representation loss after processing this batch is:  0.002831004559993744\n",
      "\n",
      "The classification loss after processing this batch is:  0.2448877990245819\n",
      "The representation loss after processing this batch is:  0.003124617040157318\n",
      "\n",
      "The classification loss after processing this batch is:  0.2847285568714142\n",
      "The representation loss after processing this batch is:  0.0028577446937561035\n",
      "\n",
      "The classification loss after processing this batch is:  0.20289434492588043\n",
      "The representation loss after processing this batch is:  0.0029442980885505676\n",
      "\n",
      "The classification loss after processing this batch is:  0.08603273332118988\n",
      "The representation loss after processing this batch is:  0.003140389919281006\n",
      "\n",
      "The classification loss after processing this batch is:  0.21648147702217102\n",
      "The representation loss after processing this batch is:  0.002826109528541565\n",
      "\n",
      "The classification loss after processing this batch is:  0.46882036328315735\n",
      "The representation loss after processing this batch is:  0.003923937678337097\n",
      "\n",
      "The classification loss after processing this batch is:  0.257327139377594\n",
      "The representation loss after processing this batch is:  0.0034194588661193848\n",
      "\n",
      "The classification loss after processing this batch is:  0.13663515448570251\n",
      "The representation loss after processing this batch is:  0.0032227560877799988\n",
      "\n",
      "The classification loss after processing this batch is:  0.14415620267391205\n",
      "The representation loss after processing this batch is:  0.0030121058225631714\n",
      "\n",
      "The classification loss after processing this batch is:  0.1191280409693718\n",
      "The representation loss after processing this batch is:  0.0032157376408576965\n",
      "\n",
      "The classification loss after processing this batch is:  0.14662550389766693\n",
      "The representation loss after processing this batch is:  0.0031333565711975098\n",
      "\n",
      "The classification loss after processing this batch is:  0.13007713854312897\n",
      "The representation loss after processing this batch is:  0.0032204240560531616\n",
      "\n",
      "The classification loss after processing this batch is:  0.20287488400936127\n",
      "The representation loss after processing this batch is:  0.0030639134347438812\n",
      "\n",
      "The classification loss after processing this batch is:  0.16692905128002167\n",
      "The representation loss after processing this batch is:  0.002944841980934143\n",
      "\n",
      "The classification loss after processing this batch is:  0.2790590822696686\n",
      "The representation loss after processing this batch is:  0.0033865422010421753\n",
      "\n",
      "The classification loss after processing this batch is:  0.1453198492527008\n",
      "The representation loss after processing this batch is:  0.002700548619031906\n",
      "\n",
      "The classification loss after processing this batch is:  0.18628175556659698\n",
      "The representation loss after processing this batch is:  0.0026634447276592255\n",
      "\n",
      "The classification loss after processing this batch is:  0.20605874061584473\n",
      "The representation loss after processing this batch is:  0.0030304715037345886\n",
      "\n",
      "The classification loss after processing this batch is:  0.20090129971504211\n",
      "The representation loss after processing this batch is:  0.0029940269887447357\n",
      "\n",
      "The classification loss after processing this batch is:  0.1518573760986328\n",
      "The representation loss after processing this batch is:  0.0027702897787094116\n",
      "\n",
      "The classification loss after processing this batch is:  0.27572184801101685\n",
      "The representation loss after processing this batch is:  0.002934493124485016\n",
      "\n",
      "The classification loss after processing this batch is:  0.25987234711647034\n",
      "The representation loss after processing this batch is:  0.0029742568731307983\n",
      "\n",
      "The classification loss after processing this batch is:  0.20101428031921387\n",
      "The representation loss after processing this batch is:  0.002682402729988098\n",
      "\n",
      "The classification loss after processing this batch is:  0.2081945240497589\n",
      "The representation loss after processing this batch is:  0.0029883235692977905\n",
      "\n",
      "The classification loss after processing this batch is:  0.23581990599632263\n",
      "The representation loss after processing this batch is:  0.002972126007080078\n",
      "\n",
      "The classification loss after processing this batch is:  0.27935537695884705\n",
      "The representation loss after processing this batch is:  0.00291486456990242\n",
      "\n",
      "The classification loss after processing this batch is:  0.2481444776058197\n",
      "The representation loss after processing this batch is:  0.003625251352787018\n",
      "\n",
      "The classification loss after processing this batch is:  0.20623779296875\n",
      "The representation loss after processing this batch is:  0.003321804106235504\n",
      "\n",
      "The classification loss after processing this batch is:  0.1526164561510086\n",
      "The representation loss after processing this batch is:  0.0032134205102920532\n",
      "\n",
      "The classification loss after processing this batch is:  0.3409770429134369\n",
      "The representation loss after processing this batch is:  0.0032116547226905823\n",
      "\n",
      "The classification loss after processing this batch is:  0.31748315691947937\n",
      "The representation loss after processing this batch is:  0.002904985100030899\n",
      "\n",
      "The classification loss after processing this batch is:  0.3237360715866089\n",
      "The representation loss after processing this batch is:  0.003178231418132782\n",
      "\n",
      "The classification loss after processing this batch is:  0.3971150517463684\n",
      "The representation loss after processing this batch is:  0.0026243478059768677\n",
      "\n",
      "The classification loss after processing this batch is:  0.30209192633628845\n",
      "The representation loss after processing this batch is:  0.002793639898300171\n",
      "\n",
      "The classification loss after processing this batch is:  0.1367253214120865\n",
      "The representation loss after processing this batch is:  0.002772584557533264\n",
      "\n",
      "The classification loss after processing this batch is:  0.14127680659294128\n",
      "The representation loss after processing this batch is:  0.002786673605442047\n",
      "\n",
      "The classification loss after processing this batch is:  0.12751856446266174\n",
      "The representation loss after processing this batch is:  0.0032551735639572144\n",
      "\n",
      "The classification loss after processing this batch is:  0.16669604182243347\n",
      "The representation loss after processing this batch is:  0.003771558403968811\n",
      "\n",
      "The classification loss after processing this batch is:  0.08651016652584076\n",
      "The representation loss after processing this batch is:  0.0031254813075065613\n",
      "\n",
      "The classification loss after processing this batch is:  0.2704857885837555\n",
      "The representation loss after processing this batch is:  0.003909081220626831\n",
      "\n",
      "The classification loss after processing this batch is:  0.1761595755815506\n",
      "The representation loss after processing this batch is:  0.002910558134317398\n",
      "\n",
      "The classification loss after processing this batch is:  0.1357232928276062\n",
      "The representation loss after processing this batch is:  0.003076404333114624\n",
      "\n",
      "The classification loss after processing this batch is:  0.2734469175338745\n",
      "The representation loss after processing this batch is:  0.0024748966097831726\n",
      "\n",
      "The classification loss after processing this batch is:  0.13532941043376923\n",
      "The representation loss after processing this batch is:  0.003229055553674698\n",
      "\n",
      "The classification loss after processing this batch is:  0.2768292725086212\n",
      "The representation loss after processing this batch is:  0.0034957081079483032\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2709047198295593\n",
      "The representation loss after processing this batch is:  0.003837898373603821\n",
      "\n",
      "The classification loss after processing this batch is:  0.18480592966079712\n",
      "The representation loss after processing this batch is:  0.0034183859825134277\n",
      "\n",
      "The classification loss after processing this batch is:  0.18224003911018372\n",
      "The representation loss after processing this batch is:  0.002681620419025421\n",
      "\n",
      "The classification loss after processing this batch is:  0.1568872481584549\n",
      "The representation loss after processing this batch is:  0.0028608813881874084\n",
      "\n",
      "The classification loss after processing this batch is:  0.09335605055093765\n",
      "The representation loss after processing this batch is:  0.002642296254634857\n",
      "\n",
      "The classification loss after processing this batch is:  0.10183979570865631\n",
      "The representation loss after processing this batch is:  0.0033046603202819824\n",
      "\n",
      "The classification loss after processing this batch is:  0.12409398704767227\n",
      "The representation loss after processing this batch is:  0.002936840057373047\n",
      "\n",
      "The classification loss after processing this batch is:  0.16142994165420532\n",
      "The representation loss after processing this batch is:  0.0025310255587100983\n",
      "\n",
      "The classification loss after processing this batch is:  0.18541322648525238\n",
      "The representation loss after processing this batch is:  0.002741865813732147\n",
      "\n",
      "The classification loss after processing this batch is:  0.22187159955501556\n",
      "The representation loss after processing this batch is:  0.003160439431667328\n",
      "\n",
      "The classification loss after processing this batch is:  0.40842095017433167\n",
      "The representation loss after processing this batch is:  0.0031476765871047974\n",
      "\n",
      "The classification loss after processing this batch is:  0.32717037200927734\n",
      "The representation loss after processing this batch is:  0.0029493048787117004\n",
      "\n",
      "The classification loss after processing this batch is:  0.11599645763635635\n",
      "The representation loss after processing this batch is:  0.002756454050540924\n",
      "\n",
      "The classification loss after processing this batch is:  0.11449093371629715\n",
      "The representation loss after processing this batch is:  0.003184705972671509\n",
      "\n",
      "The classification loss after processing this batch is:  0.1398584544658661\n",
      "The representation loss after processing this batch is:  0.0026983246207237244\n",
      "\n",
      "The classification loss after processing this batch is:  0.116852305829525\n",
      "The representation loss after processing this batch is:  0.0027071014046669006\n",
      "\n",
      "The classification loss after processing this batch is:  0.08447598665952682\n",
      "The representation loss after processing this batch is:  0.003346480429172516\n",
      "\n",
      "The classification loss after processing this batch is:  0.11059391498565674\n",
      "The representation loss after processing this batch is:  0.0033733248710632324\n",
      "\n",
      "The classification loss after processing this batch is:  0.18794821202754974\n",
      "The representation loss after processing this batch is:  0.0027081966400146484\n",
      "\n",
      "The classification loss after processing this batch is:  0.25296124815940857\n",
      "The representation loss after processing this batch is:  0.0029900968074798584\n",
      "\n",
      "The classification loss after processing this batch is:  0.1032741591334343\n",
      "The representation loss after processing this batch is:  0.003221772611141205\n",
      "\n",
      "The classification loss after processing this batch is:  0.11263083666563034\n",
      "The representation loss after processing this batch is:  0.0029449239373207092\n",
      "\n",
      "The classification loss after processing this batch is:  0.09347796440124512\n",
      "The representation loss after processing this batch is:  0.0027494430541992188\n",
      "\n",
      "The classification loss after processing this batch is:  0.27495771646499634\n",
      "The representation loss after processing this batch is:  0.00297672301530838\n",
      "\n",
      "The classification loss after processing this batch is:  0.15862588584423065\n",
      "The representation loss after processing this batch is:  0.002925470471382141\n",
      "\n",
      "The classification loss after processing this batch is:  0.07628722488880157\n",
      "The representation loss after processing this batch is:  0.003476254642009735\n",
      "\n",
      "The classification loss after processing this batch is:  0.23053404688835144\n",
      "The representation loss after processing this batch is:  0.003120318055152893\n",
      "\n",
      "The classification loss after processing this batch is:  0.1703694611787796\n",
      "The representation loss after processing this batch is:  0.002809472382068634\n",
      "\n",
      "The classification loss after processing this batch is:  0.11547506600618362\n",
      "The representation loss after processing this batch is:  0.0027223899960517883\n",
      "\n",
      "The classification loss after processing this batch is:  0.1763736754655838\n",
      "The representation loss after processing this batch is:  0.002623286098241806\n",
      "\n",
      "The classification loss after processing this batch is:  0.1261862963438034\n",
      "The representation loss after processing this batch is:  0.0028056949377059937\n",
      "\n",
      "The classification loss after processing this batch is:  0.15899556875228882\n",
      "The representation loss after processing this batch is:  0.00272572785615921\n",
      "\n",
      "The classification loss after processing this batch is:  0.2039865106344223\n",
      "The representation loss after processing this batch is:  0.002773366868495941\n",
      "\n",
      "The classification loss after processing this batch is:  0.263793408870697\n",
      "The representation loss after processing this batch is:  0.0029778704047203064\n",
      "\n",
      "The classification loss after processing this batch is:  0.17807722091674805\n",
      "The representation loss after processing this batch is:  0.0028154924511909485\n",
      "\n",
      "The classification loss after processing this batch is:  0.19328291714191437\n",
      "The representation loss after processing this batch is:  0.0028577595949172974\n",
      "\n",
      "The classification loss after processing this batch is:  0.15115322172641754\n",
      "The representation loss after processing this batch is:  0.0028991252183914185\n",
      "\n",
      "The classification loss after processing this batch is:  0.2188137024641037\n",
      "The representation loss after processing this batch is:  0.0029324665665626526\n",
      "\n",
      "The classification loss after processing this batch is:  0.13116998970508575\n",
      "The representation loss after processing this batch is:  0.0031467676162719727\n",
      "\n",
      "The classification loss after processing this batch is:  0.22147493064403534\n",
      "The representation loss after processing this batch is:  0.003176555037498474\n",
      "\n",
      "The classification loss after processing this batch is:  0.12996438145637512\n",
      "The representation loss after processing this batch is:  0.0027950629591941833\n",
      "\n",
      "The classification loss after processing this batch is:  0.19350020587444305\n",
      "The representation loss after processing this batch is:  0.0027660876512527466\n",
      "\n",
      "The classification loss after processing this batch is:  0.1406286358833313\n",
      "The representation loss after processing this batch is:  0.0029722899198532104\n",
      "\n",
      "The classification loss after processing this batch is:  0.2106635421514511\n",
      "The representation loss after processing this batch is:  0.002843298017978668\n",
      "\n",
      "The classification loss after processing this batch is:  0.15368518233299255\n",
      "The representation loss after processing this batch is:  0.0024539269506931305\n",
      "\n",
      "The classification loss after processing this batch is:  0.19138804078102112\n",
      "The representation loss after processing this batch is:  0.0028955787420272827\n",
      "\n",
      "The classification loss after processing this batch is:  0.2224929928779602\n",
      "The representation loss after processing this batch is:  0.002599656581878662\n",
      "\n",
      "The classification loss after processing this batch is:  0.19432754814624786\n",
      "The representation loss after processing this batch is:  0.0027007125318050385\n",
      "\n",
      "The classification loss after processing this batch is:  0.25899359583854675\n",
      "The representation loss after processing this batch is:  0.002741783857345581\n",
      "\n",
      "The classification loss after processing this batch is:  0.2701823115348816\n",
      "The representation loss after processing this batch is:  0.0028372816741466522\n",
      "\n",
      "The classification loss after processing this batch is:  0.338954359292984\n",
      "The representation loss after processing this batch is:  0.0028233081102371216\n",
      "\n",
      "The classification loss after processing this batch is:  0.27525508403778076\n",
      "The representation loss after processing this batch is:  0.0027167685329914093\n",
      "\n",
      "The classification loss after processing this batch is:  0.11355684697628021\n",
      "The representation loss after processing this batch is:  0.003051541745662689\n",
      "\n",
      "The classification loss after processing this batch is:  0.1827380210161209\n",
      "The representation loss after processing this batch is:  0.002871580421924591\n",
      "\n",
      "The classification loss after processing this batch is:  0.12347518652677536\n",
      "The representation loss after processing this batch is:  0.0030029043555259705\n",
      "\n",
      "The classification loss after processing this batch is:  0.1774960458278656\n",
      "The representation loss after processing this batch is:  0.003338746726512909\n",
      "\n",
      "The classification loss after processing this batch is:  0.2724347412586212\n",
      "The representation loss after processing this batch is:  0.0031865984201431274\n",
      "\n",
      "The classification loss after processing this batch is:  0.35162585973739624\n",
      "The representation loss after processing this batch is:  0.00310564786195755\n",
      "\n",
      "The classification loss after processing this batch is:  0.365620881319046\n",
      "The representation loss after processing this batch is:  0.00252416729927063\n",
      "\n",
      "The classification loss after processing this batch is:  0.27531465888023376\n",
      "The representation loss after processing this batch is:  0.003005675971508026\n",
      "\n",
      "The classification loss after processing this batch is:  0.11372745782136917\n",
      "The representation loss after processing this batch is:  0.0026797428727149963\n",
      "\n",
      "The classification loss after processing this batch is:  0.13719059526920319\n",
      "The representation loss after processing this batch is:  0.0030402690172195435\n",
      "\n",
      "The classification loss after processing this batch is:  0.26338091492652893\n",
      "The representation loss after processing this batch is:  0.002731107175350189\n",
      "\n",
      "The classification loss after processing this batch is:  0.1304081231355667\n",
      "The representation loss after processing this batch is:  0.0028267502784729004\n",
      "\n",
      "The classification loss after processing this batch is:  0.13302204012870789\n",
      "The representation loss after processing this batch is:  0.0030963048338890076\n",
      "\n",
      "The classification loss after processing this batch is:  0.13017581403255463\n",
      "The representation loss after processing this batch is:  0.002940818667411804\n",
      "\n",
      "The classification loss after processing this batch is:  0.060695353895425797\n",
      "The representation loss after processing this batch is:  0.0028585195541381836\n",
      "\n",
      "The classification loss after processing this batch is:  0.17216351628303528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.003389008343219757\n",
      "\n",
      "The classification loss after processing this batch is:  0.1518455147743225\n",
      "The representation loss after processing this batch is:  0.003224886953830719\n",
      "\n",
      "The classification loss after processing this batch is:  0.2228921353816986\n",
      "The representation loss after processing this batch is:  0.0027664564549922943\n",
      "\n",
      "The classification loss after processing this batch is:  0.19479216635227203\n",
      "The representation loss after processing this batch is:  0.0028714053332805634\n",
      "\n",
      "The classification loss after processing this batch is:  0.1880238801240921\n",
      "The representation loss after processing this batch is:  0.0032285600900650024\n",
      "\n",
      "The classification loss after processing this batch is:  0.23253662884235382\n",
      "The representation loss after processing this batch is:  0.003229007124900818\n",
      "\n",
      "The classification loss after processing this batch is:  0.16486181318759918\n",
      "The representation loss after processing this batch is:  0.003061097115278244\n",
      "\n",
      "The classification loss after processing this batch is:  0.17219850420951843\n",
      "The representation loss after processing this batch is:  0.0033750683069229126\n",
      "\n",
      "The classification loss after processing this batch is:  0.18241658806800842\n",
      "The representation loss after processing this batch is:  0.003468729555606842\n",
      "\n",
      "The classification loss after processing this batch is:  0.19224604964256287\n",
      "The representation loss after processing this batch is:  0.0031454935669898987\n",
      "\n",
      "The classification loss after processing this batch is:  0.20851613581180573\n",
      "The representation loss after processing this batch is:  0.0028830617666244507\n",
      "\n",
      "The classification loss after processing this batch is:  0.29805248975753784\n",
      "The representation loss after processing this batch is:  0.0026153363287448883\n",
      "\n",
      "The classification loss after processing this batch is:  0.2932632565498352\n",
      "The representation loss after processing this batch is:  0.0030352547764778137\n",
      "\n",
      "The classification loss after processing this batch is:  0.13430288434028625\n",
      "The representation loss after processing this batch is:  0.0026996172964572906\n",
      "\n",
      "The classification loss after processing this batch is:  0.19306491315364838\n",
      "The representation loss after processing this batch is:  0.003007587045431137\n",
      "\n",
      "The classification loss after processing this batch is:  0.18876507878303528\n",
      "The representation loss after processing this batch is:  0.0031405165791511536\n",
      "\n",
      "The classification loss after processing this batch is:  0.258055716753006\n",
      "The representation loss after processing this batch is:  0.0029129832983016968\n",
      "\n",
      "The classification loss after processing this batch is:  0.28844955563545227\n",
      "The representation loss after processing this batch is:  0.003505915403366089\n",
      "\n",
      "The classification loss after processing this batch is:  0.2424664944410324\n",
      "The representation loss after processing this batch is:  0.0032277852296829224\n",
      "\n",
      "The classification loss after processing this batch is:  0.32213687896728516\n",
      "The representation loss after processing this batch is:  0.0033940747380256653\n",
      "\n",
      "The classification loss after processing this batch is:  0.22639591991901398\n",
      "The representation loss after processing this batch is:  0.003372669219970703\n",
      "\n",
      "The classification loss after processing this batch is:  0.17961403727531433\n",
      "The representation loss after processing this batch is:  0.002951323986053467\n",
      "\n",
      "The classification loss after processing this batch is:  0.20419548451900482\n",
      "The representation loss after processing this batch is:  0.003661110997200012\n",
      "\n",
      "The classification loss after processing this batch is:  0.1298636943101883\n",
      "The representation loss after processing this batch is:  0.00309763103723526\n",
      "\n",
      "The classification loss after processing this batch is:  0.21136505901813507\n",
      "The representation loss after processing this batch is:  0.0033319368958473206\n",
      "\n",
      "The classification loss after processing this batch is:  0.18256576359272003\n",
      "The representation loss after processing this batch is:  0.0032084956765174866\n",
      "\n",
      "The classification loss after processing this batch is:  0.15619762241840363\n",
      "The representation loss after processing this batch is:  0.0025872811675071716\n",
      "\n",
      "The classification loss after processing this batch is:  0.1427145004272461\n",
      "The representation loss after processing this batch is:  0.002853967249393463\n",
      "\n",
      "The classification loss after processing this batch is:  0.20129720866680145\n",
      "The representation loss after processing this batch is:  0.003112412989139557\n",
      "\n",
      "The classification loss after processing this batch is:  0.1762159764766693\n",
      "The representation loss after processing this batch is:  0.002718571573495865\n",
      "\n",
      "The classification loss after processing this batch is:  0.14527186751365662\n",
      "The representation loss after processing this batch is:  0.002856910228729248\n",
      "\n",
      "The classification loss after processing this batch is:  0.1673387587070465\n",
      "The representation loss after processing this batch is:  0.0025650858879089355\n",
      "\n",
      "The classification loss after processing this batch is:  0.10537692904472351\n",
      "The representation loss after processing this batch is:  0.00268004834651947\n",
      "\n",
      "The classification loss after processing this batch is:  0.15249855816364288\n",
      "The representation loss after processing this batch is:  0.0024858377873897552\n",
      "\n",
      "The classification loss after processing this batch is:  0.13738085329532623\n",
      "The representation loss after processing this batch is:  0.0025025159120559692\n",
      "\n",
      "The classification loss after processing this batch is:  0.571365237236023\n",
      "The representation loss after processing this batch is:  0.0030135661363601685\n",
      "\n",
      "The classification loss after processing this batch is:  0.1609526425600052\n",
      "The representation loss after processing this batch is:  0.002912066876888275\n",
      "\n",
      "The classification loss after processing this batch is:  0.24466973543167114\n",
      "The representation loss after processing this batch is:  0.002752896398305893\n",
      "\n",
      "The classification loss after processing this batch is:  0.3333032727241516\n",
      "The representation loss after processing this batch is:  0.002741582691669464\n",
      "\n",
      "The classification loss after processing this batch is:  0.16652072966098785\n",
      "The representation loss after processing this batch is:  0.002708546817302704\n",
      "\n",
      "The classification loss after processing this batch is:  0.2798844575881958\n",
      "The representation loss after processing this batch is:  0.0032804906368255615\n",
      "\n",
      "The classification loss after processing this batch is:  0.15639927983283997\n",
      "The representation loss after processing this batch is:  0.00298256054520607\n",
      "\n",
      "The classification loss after processing this batch is:  0.32427990436553955\n",
      "The representation loss after processing this batch is:  0.0025125890970230103\n",
      "\n",
      "The classification loss after processing this batch is:  0.09443528950214386\n",
      "The representation loss after processing this batch is:  0.002747185528278351\n",
      "\n",
      "The classification loss after processing this batch is:  0.14420096576213837\n",
      "The representation loss after processing this batch is:  0.0029219016432762146\n",
      "\n",
      "The classification loss after processing this batch is:  0.09221290796995163\n",
      "The representation loss after processing this batch is:  0.0032649189233779907\n",
      "\n",
      "The classification loss after processing this batch is:  0.06360103189945221\n",
      "The representation loss after processing this batch is:  0.0032551512122154236\n",
      "\n",
      "The classification loss after processing this batch is:  0.13426455855369568\n",
      "The representation loss after processing this batch is:  0.0029819607734680176\n",
      "\n",
      "The classification loss after processing this batch is:  0.07803218811750412\n",
      "The representation loss after processing this batch is:  0.0026662275195121765\n",
      "\n",
      "The classification loss after processing this batch is:  0.16548778116703033\n",
      "The representation loss after processing this batch is:  0.0029580071568489075\n",
      "\n",
      "The classification loss after processing this batch is:  0.12966664135456085\n",
      "The representation loss after processing this batch is:  0.003714747726917267\n",
      "\n",
      "The classification loss after processing this batch is:  0.15117499232292175\n",
      "The representation loss after processing this batch is:  0.002672046422958374\n",
      "\n",
      "The classification loss after processing this batch is:  0.157270148396492\n",
      "The representation loss after processing this batch is:  0.002654869109392166\n",
      "\n",
      "The classification loss after processing this batch is:  0.11908076703548431\n",
      "The representation loss after processing this batch is:  0.003058716654777527\n",
      "\n",
      "The classification loss after processing this batch is:  0.20043189823627472\n",
      "The representation loss after processing this batch is:  0.002879265695810318\n",
      "\n",
      "The classification loss after processing this batch is:  0.1868589222431183\n",
      "The representation loss after processing this batch is:  0.003141827881336212\n",
      "\n",
      "The classification loss after processing this batch is:  0.2547766864299774\n",
      "The representation loss after processing this batch is:  0.0033029839396476746\n",
      "\n",
      "The classification loss after processing this batch is:  0.15105025470256805\n",
      "The representation loss after processing this batch is:  0.0028111152350902557\n",
      "\n",
      "The classification loss after processing this batch is:  0.13253460824489594\n",
      "The representation loss after processing this batch is:  0.0029565095901489258\n",
      "\n",
      "The classification loss after processing this batch is:  0.23594076931476593\n",
      "The representation loss after processing this batch is:  0.002907074987888336\n",
      "\n",
      "The classification loss after processing this batch is:  0.24679210782051086\n",
      "The representation loss after processing this batch is:  0.0030083954334259033\n",
      "\n",
      "The classification loss after processing this batch is:  0.2061479538679123\n",
      "The representation loss after processing this batch is:  0.00269944965839386\n",
      "\n",
      "The classification loss after processing this batch is:  0.1256527602672577\n",
      "The representation loss after processing this batch is:  0.00296107679605484\n",
      "\n",
      "The classification loss after processing this batch is:  0.16556502878665924\n",
      "The representation loss after processing this batch is:  0.0032290518283843994\n",
      "\n",
      "The classification loss after processing this batch is:  0.18405380845069885\n",
      "The representation loss after processing this batch is:  0.00279100239276886\n",
      "\n",
      "The classification loss after processing this batch is:  0.19865018129348755\n",
      "The representation loss after processing this batch is:  0.0030751116573810577\n",
      "\n",
      "The classification loss after processing this batch is:  0.19431546330451965\n",
      "The representation loss after processing this batch is:  0.0033061355352401733\n",
      "\n",
      "The classification loss after processing this batch is:  0.14447999000549316\n",
      "The representation loss after processing this batch is:  0.0035067908465862274\n",
      "\n",
      "The classification loss after processing this batch is:  0.2101752609014511\n",
      "The representation loss after processing this batch is:  0.003218039870262146\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.24579808115959167\n",
      "The representation loss after processing this batch is:  0.002852201461791992\n",
      "\n",
      "The classification loss after processing this batch is:  0.14348196983337402\n",
      "The representation loss after processing this batch is:  0.003890007734298706\n",
      "\n",
      "The classification loss after processing this batch is:  0.19056768715381622\n",
      "The representation loss after processing this batch is:  0.002776205539703369\n",
      "\n",
      "The classification loss after processing this batch is:  0.15687057375907898\n",
      "The representation loss after processing this batch is:  0.0025682374835014343\n",
      "\n",
      "The classification loss after processing this batch is:  0.2174134999513626\n",
      "The representation loss after processing this batch is:  0.002861037850379944\n",
      "\n",
      "The classification loss after processing this batch is:  0.10874073952436447\n",
      "The representation loss after processing this batch is:  0.0029838979244232178\n",
      "\n",
      "The classification loss after processing this batch is:  0.17773064970970154\n",
      "The representation loss after processing this batch is:  0.0032712966203689575\n",
      "\n",
      "The classification loss after processing this batch is:  0.12960301339626312\n",
      "The representation loss after processing this batch is:  0.0031119510531425476\n",
      "\n",
      "The classification loss after processing this batch is:  0.13932426273822784\n",
      "The representation loss after processing this batch is:  0.0025340914726257324\n",
      "\n",
      "The classification loss after processing this batch is:  0.11688336730003357\n",
      "The representation loss after processing this batch is:  0.0030148103833198547\n",
      "\n",
      "The classification loss after processing this batch is:  0.24040056765079498\n",
      "The representation loss after processing this batch is:  0.003188006579875946\n",
      "\n",
      "The classification loss after processing this batch is:  0.21108748018741608\n",
      "The representation loss after processing this batch is:  0.0033211931586265564\n",
      "\n",
      "The classification loss after processing this batch is:  0.20203256607055664\n",
      "The representation loss after processing this batch is:  0.003295082598924637\n",
      "\n",
      "The classification loss after processing this batch is:  0.15221063792705536\n",
      "The representation loss after processing this batch is:  0.003464244306087494\n",
      "\n",
      "The classification loss after processing this batch is:  0.12743067741394043\n",
      "The representation loss after processing this batch is:  0.0029341354966163635\n",
      "\n",
      "The classification loss after processing this batch is:  0.14653994143009186\n",
      "The representation loss after processing this batch is:  0.002918921411037445\n",
      "\n",
      "The classification loss after processing this batch is:  0.1456584632396698\n",
      "The representation loss after processing this batch is:  0.0028973445296287537\n",
      "\n",
      "The classification loss after processing this batch is:  0.15473869442939758\n",
      "The representation loss after processing this batch is:  0.002794042229652405\n",
      "\n",
      "The classification loss after processing this batch is:  0.0887729600071907\n",
      "The representation loss after processing this batch is:  0.0029259026050567627\n",
      "\n",
      "The classification loss after processing this batch is:  0.07774472236633301\n",
      "The representation loss after processing this batch is:  0.002738639712333679\n",
      "\n",
      "The classification loss after processing this batch is:  0.14466024935245514\n",
      "The representation loss after processing this batch is:  0.0028603151440620422\n",
      "\n",
      "The classification loss after processing this batch is:  0.0801520124077797\n",
      "The representation loss after processing this batch is:  0.003224089741706848\n",
      "\n",
      "The classification loss after processing this batch is:  0.22016115486621857\n",
      "The representation loss after processing this batch is:  0.00309782475233078\n",
      "\n",
      "The classification loss after processing this batch is:  0.16481170058250427\n",
      "The representation loss after processing this batch is:  0.0025376901030540466\n",
      "\n",
      "The classification loss after processing this batch is:  0.20465867221355438\n",
      "The representation loss after processing this batch is:  0.002963908016681671\n",
      "\n",
      "The classification loss after processing this batch is:  0.07269775867462158\n",
      "The representation loss after processing this batch is:  0.0033255964517593384\n",
      "\n",
      "The classification loss after processing this batch is:  0.250257670879364\n",
      "The representation loss after processing this batch is:  0.0028961971402168274\n",
      "\n",
      "The classification loss after processing this batch is:  0.17657241225242615\n",
      "The representation loss after processing this batch is:  0.002996966242790222\n",
      "\n",
      "The classification loss after processing this batch is:  0.1608140915632248\n",
      "The representation loss after processing this batch is:  0.00289309024810791\n",
      "\n",
      "The classification loss after processing this batch is:  0.17141999304294586\n",
      "The representation loss after processing this batch is:  0.0031616315245628357\n",
      "\n",
      "The classification loss after processing this batch is:  0.15455862879753113\n",
      "The representation loss after processing this batch is:  0.0033506937325000763\n",
      "\n",
      "The classification loss after processing this batch is:  0.11862536519765854\n",
      "The representation loss after processing this batch is:  0.002833925187587738\n",
      "\n",
      "The classification loss after processing this batch is:  0.11473533511161804\n",
      "The representation loss after processing this batch is:  0.0029485151171684265\n",
      "\n",
      "The classification loss after processing this batch is:  0.12164171040058136\n",
      "The representation loss after processing this batch is:  0.002762705087661743\n",
      "\n",
      "The classification loss after processing this batch is:  0.24341371655464172\n",
      "The representation loss after processing this batch is:  0.0029325783252716064\n",
      "\n",
      "The classification loss after processing this batch is:  0.17511485517024994\n",
      "The representation loss after processing this batch is:  0.002727515995502472\n",
      "\n",
      "The classification loss after processing this batch is:  0.20368750393390656\n",
      "The representation loss after processing this batch is:  0.004002705216407776\n",
      "\n",
      "The classification loss after processing this batch is:  0.22343268990516663\n",
      "The representation loss after processing this batch is:  0.002899564802646637\n",
      "\n",
      "The classification loss after processing this batch is:  0.20500926673412323\n",
      "The representation loss after processing this batch is:  0.0031365230679512024\n",
      "\n",
      "The classification loss after processing this batch is:  0.2261095941066742\n",
      "The representation loss after processing this batch is:  0.0027989596128463745\n",
      "\n",
      "The classification loss after processing this batch is:  0.34477102756500244\n",
      "The representation loss after processing this batch is:  0.002672094851732254\n",
      "\n",
      "The classification loss after processing this batch is:  0.22670523822307587\n",
      "The representation loss after processing this batch is:  0.0024721771478652954\n",
      "\n",
      "The classification loss after processing this batch is:  0.17837108671665192\n",
      "The representation loss after processing this batch is:  0.0025882497429847717\n",
      "\n",
      "The classification loss after processing this batch is:  0.14617151021957397\n",
      "The representation loss after processing this batch is:  0.002711847424507141\n",
      "\n",
      "The classification loss after processing this batch is:  0.10911092907190323\n",
      "The representation loss after processing this batch is:  0.0026628226041793823\n",
      "\n",
      "The classification loss after processing this batch is:  0.09409962594509125\n",
      "The representation loss after processing this batch is:  0.0025590360164642334\n",
      "\n",
      "The classification loss after processing this batch is:  0.17165857553482056\n",
      "The representation loss after processing this batch is:  0.003357522189617157\n",
      "\n",
      "The classification loss after processing this batch is:  0.1763571798801422\n",
      "The representation loss after processing this batch is:  0.002852514386177063\n",
      "\n",
      "The classification loss after processing this batch is:  0.12271516025066376\n",
      "The representation loss after processing this batch is:  0.0028282254934310913\n",
      "\n",
      "The classification loss after processing this batch is:  0.22900480031967163\n",
      "The representation loss after processing this batch is:  0.002807021141052246\n",
      "\n",
      "The classification loss after processing this batch is:  0.18160328269004822\n",
      "The representation loss after processing this batch is:  0.0030031800270080566\n",
      "\n",
      "The classification loss after processing this batch is:  0.19729703664779663\n",
      "The representation loss after processing this batch is:  0.002673853188753128\n",
      "\n",
      "The classification loss after processing this batch is:  0.19551660120487213\n",
      "The representation loss after processing this batch is:  0.002767316997051239\n",
      "\n",
      "The classification loss after processing this batch is:  0.27727699279785156\n",
      "The representation loss after processing this batch is:  0.0025227144360542297\n",
      "\n",
      "The classification loss after processing this batch is:  0.20188423991203308\n",
      "The representation loss after processing this batch is:  0.0029442496597766876\n",
      "\n",
      "The classification loss after processing this batch is:  0.12633463740348816\n",
      "The representation loss after processing this batch is:  0.0033239126205444336\n",
      "\n",
      "The classification loss after processing this batch is:  0.17631219327449799\n",
      "The representation loss after processing this batch is:  0.0027828961610794067\n",
      "\n",
      "The classification loss after processing this batch is:  0.08576932549476624\n",
      "The representation loss after processing this batch is:  0.0027719587087631226\n",
      "\n",
      "The classification loss after processing this batch is:  0.10260572284460068\n",
      "The representation loss after processing this batch is:  0.002898871898651123\n",
      "\n",
      "The classification loss after processing this batch is:  0.15146568417549133\n",
      "The representation loss after processing this batch is:  0.0031050443649291992\n",
      "\n",
      "The classification loss after processing this batch is:  0.19725793600082397\n",
      "The representation loss after processing this batch is:  0.002613566815853119\n",
      "\n",
      "The classification loss after processing this batch is:  0.19015829265117645\n",
      "The representation loss after processing this batch is:  0.003065630793571472\n",
      "\n",
      "The classification loss after processing this batch is:  0.11497493088245392\n",
      "The representation loss after processing this batch is:  0.0034870728850364685\n",
      "\n",
      "The classification loss after processing this batch is:  0.15909187495708466\n",
      "The representation loss after processing this batch is:  0.003240928053855896\n",
      "\n",
      "The classification loss after processing this batch is:  0.10453832894563675\n",
      "The representation loss after processing this batch is:  0.0030838027596473694\n",
      "\n",
      "The classification loss after processing this batch is:  0.26588118076324463\n",
      "The representation loss after processing this batch is:  0.002911575138568878\n",
      "\n",
      "The classification loss after processing this batch is:  0.07866670191287994\n",
      "The representation loss after processing this batch is:  0.002575881779193878\n",
      "\n",
      "The classification loss after processing this batch is:  0.08078859001398087\n",
      "The representation loss after processing this batch is:  0.0033035725355148315\n",
      "\n",
      "The classification loss after processing this batch is:  0.152941033244133\n",
      "The representation loss after processing this batch is:  0.003870345652103424\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.15564113855361938\n",
      "The representation loss after processing this batch is:  0.0029561594128608704\n",
      "\n",
      "The classification loss after processing this batch is:  0.13167300820350647\n",
      "The representation loss after processing this batch is:  0.0033212900161743164\n",
      "\n",
      "The classification loss after processing this batch is:  0.09860362857580185\n",
      "The representation loss after processing this batch is:  0.002756137400865555\n",
      "\n",
      "The classification loss after processing this batch is:  0.1923477202653885\n",
      "The representation loss after processing this batch is:  0.0032396316528320312\n",
      "\n",
      "The classification loss after processing this batch is:  0.2575036883354187\n",
      "The representation loss after processing this batch is:  0.0033250898122787476\n",
      "\n",
      "The classification loss after processing this batch is:  0.2272932380437851\n",
      "The representation loss after processing this batch is:  0.0027898289263248444\n",
      "\n",
      "The classification loss after processing this batch is:  0.211286261677742\n",
      "The representation loss after processing this batch is:  0.003344208002090454\n",
      "\n",
      "The classification loss after processing this batch is:  0.10927483439445496\n",
      "The representation loss after processing this batch is:  0.003081768751144409\n",
      "\n",
      "The classification loss after processing this batch is:  0.13769842684268951\n",
      "The representation loss after processing this batch is:  0.0026066116988658905\n",
      "\n",
      "The classification loss after processing this batch is:  0.27337586879730225\n",
      "The representation loss after processing this batch is:  0.002960771322250366\n",
      "\n",
      "The classification loss after processing this batch is:  0.31979623436927795\n",
      "The representation loss after processing this batch is:  0.0034724175930023193\n",
      "\n",
      "The classification loss after processing this batch is:  0.27137327194213867\n",
      "The representation loss after processing this batch is:  0.003448076546192169\n",
      "\n",
      "The classification loss after processing this batch is:  0.319595068693161\n",
      "The representation loss after processing this batch is:  0.00307580828666687\n",
      "\n",
      "The classification loss after processing this batch is:  0.12800879776477814\n",
      "The representation loss after processing this batch is:  0.0026196837425231934\n",
      "\n",
      "The classification loss after processing this batch is:  0.2115938514471054\n",
      "The representation loss after processing this batch is:  0.0027585551142692566\n",
      "\n",
      "The classification loss after processing this batch is:  0.1479726880788803\n",
      "The representation loss after processing this batch is:  0.002853572368621826\n",
      "\n",
      "The classification loss after processing this batch is:  0.15172599256038666\n",
      "The representation loss after processing this batch is:  0.0028774291276931763\n",
      "\n",
      "The classification loss after processing this batch is:  0.15427282452583313\n",
      "The representation loss after processing this batch is:  0.0028543174266815186\n",
      "\n",
      "The classification loss after processing this batch is:  0.1851794570684433\n",
      "The representation loss after processing this batch is:  0.002749986946582794\n",
      "\n",
      "The classification loss after processing this batch is:  0.19035959243774414\n",
      "The representation loss after processing this batch is:  0.002871274948120117\n",
      "\n",
      "The classification loss after processing this batch is:  0.1455346792936325\n",
      "The representation loss after processing this batch is:  0.002814546227455139\n",
      "\n",
      "The classification loss after processing this batch is:  0.22034047544002533\n",
      "The representation loss after processing this batch is:  0.0027633309364318848\n",
      "\n",
      "The classification loss after processing this batch is:  0.07303263992071152\n",
      "The representation loss after processing this batch is:  0.0031949877738952637\n",
      "\n",
      "The classification loss after processing this batch is:  0.13003651797771454\n",
      "The representation loss after processing this batch is:  0.003158971667289734\n",
      "\n",
      "The classification loss after processing this batch is:  0.20123355090618134\n",
      "The representation loss after processing this batch is:  0.002986609935760498\n",
      "\n",
      "The classification loss after processing this batch is:  0.19018977880477905\n",
      "The representation loss after processing this batch is:  0.00315026193857193\n",
      "\n",
      "The classification loss after processing this batch is:  0.08503639698028564\n",
      "The representation loss after processing this batch is:  0.003720015287399292\n",
      "\n",
      "The classification loss after processing this batch is:  0.10231499373912811\n",
      "The representation loss after processing this batch is:  0.002825230360031128\n",
      "\n",
      "The classification loss after processing this batch is:  0.23688377439975739\n",
      "The representation loss after processing this batch is:  0.003488011658191681\n",
      "\n",
      "The classification loss after processing this batch is:  0.2259441465139389\n",
      "The representation loss after processing this batch is:  0.002776842564344406\n",
      "\n",
      "The classification loss after processing this batch is:  0.1859278678894043\n",
      "The representation loss after processing this batch is:  0.0031567439436912537\n",
      "\n",
      "The classification loss after processing this batch is:  0.14530397951602936\n",
      "The representation loss after processing this batch is:  0.0029281899333000183\n",
      "\n",
      "The classification loss after processing this batch is:  0.11625335365533829\n",
      "The representation loss after processing this batch is:  0.002966858446598053\n",
      "\n",
      "The classification loss after processing this batch is:  0.13179084658622742\n",
      "The representation loss after processing this batch is:  0.002747412770986557\n",
      "\n",
      "The classification loss after processing this batch is:  0.17959830164909363\n",
      "The representation loss after processing this batch is:  0.00273885577917099\n",
      "\n",
      "The classification loss after processing this batch is:  0.23247963190078735\n",
      "The representation loss after processing this batch is:  0.002752453088760376\n",
      "\n",
      "The classification loss after processing this batch is:  0.16519810259342194\n",
      "The representation loss after processing this batch is:  0.003191225230693817\n",
      "\n",
      "The classification loss after processing this batch is:  0.1151723712682724\n",
      "The representation loss after processing this batch is:  0.0027486085891723633\n",
      "\n",
      "The classification loss after processing this batch is:  0.20515362918376923\n",
      "The representation loss after processing this batch is:  0.0030651018023490906\n",
      "\n",
      "The classification loss after processing this batch is:  0.262788861989975\n",
      "The representation loss after processing this batch is:  0.0029892995953559875\n",
      "\n",
      "The classification loss after processing this batch is:  0.10853030532598495\n",
      "The representation loss after processing this batch is:  0.0030457451939582825\n",
      "\n",
      "The classification loss after processing this batch is:  0.11215800791978836\n",
      "The representation loss after processing this batch is:  0.002612188458442688\n",
      "\n",
      "The classification loss after processing this batch is:  0.25187522172927856\n",
      "The representation loss after processing this batch is:  0.0029460489749908447\n",
      "\n",
      "The classification loss after processing this batch is:  0.2395164966583252\n",
      "The representation loss after processing this batch is:  0.0026607513427734375\n",
      "\n",
      "The classification loss after processing this batch is:  0.13278597593307495\n",
      "The representation loss after processing this batch is:  0.0028354376554489136\n",
      "\n",
      "The classification loss after processing this batch is:  0.22979240119457245\n",
      "The representation loss after processing this batch is:  0.0024338141083717346\n",
      "\n",
      "The classification loss after processing this batch is:  0.19798196852207184\n",
      "The representation loss after processing this batch is:  0.0030957311391830444\n",
      "\n",
      "The classification loss after processing this batch is:  0.24960486590862274\n",
      "The representation loss after processing this batch is:  0.0033708587288856506\n",
      "\n",
      "The classification loss after processing this batch is:  0.19262294471263885\n",
      "The representation loss after processing this batch is:  0.0032584667205810547\n",
      "\n",
      "The classification loss after processing this batch is:  0.21118076145648956\n",
      "The representation loss after processing this batch is:  0.0027432143688201904\n",
      "\n",
      "The classification loss after processing this batch is:  0.13339655101299286\n",
      "The representation loss after processing this batch is:  0.004178233444690704\n",
      "\n",
      "The classification loss after processing this batch is:  0.16161581873893738\n",
      "The representation loss after processing this batch is:  0.002750866115093231\n",
      "\n",
      "The classification loss after processing this batch is:  0.1355542540550232\n",
      "The representation loss after processing this batch is:  0.002636842429637909\n",
      "\n",
      "The classification loss after processing this batch is:  0.15807446837425232\n",
      "The representation loss after processing this batch is:  0.0027159005403518677\n",
      "\n",
      "The classification loss after processing this batch is:  0.1487048715353012\n",
      "The representation loss after processing this batch is:  0.002813391387462616\n",
      "\n",
      "The classification loss after processing this batch is:  0.17042504251003265\n",
      "The representation loss after processing this batch is:  0.0028444379568099976\n",
      "\n",
      "The classification loss after processing this batch is:  0.24956560134887695\n",
      "The representation loss after processing this batch is:  0.0027669966220855713\n",
      "\n",
      "The classification loss after processing this batch is:  0.10092134773731232\n",
      "The representation loss after processing this batch is:  0.003121688961982727\n",
      "\n",
      "The classification loss after processing this batch is:  0.10647069662809372\n",
      "The representation loss after processing this batch is:  0.003457196056842804\n",
      "\n",
      "The classification loss after processing this batch is:  0.17226238548755646\n",
      "The representation loss after processing this batch is:  0.0031727924942970276\n",
      "\n",
      "The classification loss after processing this batch is:  0.0726730078458786\n",
      "The representation loss after processing this batch is:  0.0027358680963516235\n",
      "\n",
      "The classification loss after processing this batch is:  0.13600078225135803\n",
      "The representation loss after processing this batch is:  0.002893194556236267\n",
      "\n",
      "The classification loss after processing this batch is:  0.07766047865152359\n",
      "The representation loss after processing this batch is:  0.00300714373588562\n",
      "\n",
      "The classification loss after processing this batch is:  0.14951761066913605\n",
      "The representation loss after processing this batch is:  0.0029086321592330933\n",
      "\n",
      "The classification loss after processing this batch is:  0.1837795525789261\n",
      "The representation loss after processing this batch is:  0.0030374079942703247\n",
      "\n",
      "The classification loss after processing this batch is:  0.21823181211948395\n",
      "The representation loss after processing this batch is:  0.0037857070565223694\n",
      "\n",
      "The classification loss after processing this batch is:  0.18765224516391754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.0033471956849098206\n",
      "\n",
      "The classification loss after processing this batch is:  0.12479957938194275\n",
      "The representation loss after processing this batch is:  0.0028701871633529663\n",
      "\n",
      "The classification loss after processing this batch is:  0.15429721772670746\n",
      "The representation loss after processing this batch is:  0.003312245011329651\n",
      "\n",
      "The classification loss after processing this batch is:  0.1035694032907486\n",
      "The representation loss after processing this batch is:  0.0028378814458847046\n",
      "\n",
      "The classification loss after processing this batch is:  0.09062525629997253\n",
      "The representation loss after processing this batch is:  0.003343932330608368\n",
      "\n",
      "The classification loss after processing this batch is:  0.10025563836097717\n",
      "The representation loss after processing this batch is:  0.002850547432899475\n",
      "\n",
      "The classification loss after processing this batch is:  0.09396020323038101\n",
      "The representation loss after processing this batch is:  0.0030676648020744324\n",
      "\n",
      "The classification loss after processing this batch is:  0.1392752081155777\n",
      "The representation loss after processing this batch is:  0.00305040180683136\n",
      "\n",
      "The classification loss after processing this batch is:  0.20853808522224426\n",
      "The representation loss after processing this batch is:  0.0031644925475120544\n",
      "\n",
      "The classification loss after processing this batch is:  0.2070767730474472\n",
      "The representation loss after processing this batch is:  0.002640940248966217\n",
      "\n",
      "The classification loss after processing this batch is:  0.1478472203016281\n",
      "The representation loss after processing this batch is:  0.0034261420369148254\n",
      "\n",
      "The classification loss after processing this batch is:  0.13973625004291534\n",
      "The representation loss after processing this batch is:  0.003161512315273285\n",
      "\n",
      "The classification loss after processing this batch is:  0.17228570580482483\n",
      "The representation loss after processing this batch is:  0.0030395537614822388\n",
      "\n",
      "The classification loss after processing this batch is:  0.14021660387516022\n",
      "The representation loss after processing this batch is:  0.0031723827123641968\n",
      "\n",
      "The classification loss after processing this batch is:  0.44301262497901917\n",
      "The representation loss after processing this batch is:  0.0034380629658699036\n",
      "\n",
      "The classification loss after processing this batch is:  0.172880619764328\n",
      "The representation loss after processing this batch is:  0.003364972770214081\n",
      "\n",
      "The classification loss after processing this batch is:  0.25384747982025146\n",
      "The representation loss after processing this batch is:  0.0037663429975509644\n",
      "\n",
      "The classification loss after processing this batch is:  0.14285795390605927\n",
      "The representation loss after processing this batch is:  0.002711758017539978\n",
      "\n",
      "The classification loss after processing this batch is:  0.14363861083984375\n",
      "The representation loss after processing this batch is:  0.0028582438826560974\n",
      "\n",
      "The classification loss after processing this batch is:  0.17006142437458038\n",
      "The representation loss after processing this batch is:  0.002686336636543274\n",
      "\n",
      "The classification loss after processing this batch is:  0.16357456147670746\n",
      "The representation loss after processing this batch is:  0.0030273832380771637\n",
      "\n",
      "The classification loss after processing this batch is:  0.2827123701572418\n",
      "The representation loss after processing this batch is:  0.0031427666544914246\n",
      "\n",
      "The classification loss after processing this batch is:  0.21929877996444702\n",
      "The representation loss after processing this batch is:  0.0039047449827194214\n",
      "\n",
      "The classification loss after processing this batch is:  0.22765745222568512\n",
      "The representation loss after processing this batch is:  0.003632873296737671\n",
      "\n",
      "The classification loss after processing this batch is:  0.18134737014770508\n",
      "The representation loss after processing this batch is:  0.003062695264816284\n",
      "\n",
      "The classification loss after processing this batch is:  0.08298991620540619\n",
      "The representation loss after processing this batch is:  0.003076814115047455\n",
      "\n",
      "The classification loss after processing this batch is:  0.15146397054195404\n",
      "The representation loss after processing this batch is:  0.002856433391571045\n",
      "\n",
      "The classification loss after processing this batch is:  0.1328725665807724\n",
      "The representation loss after processing this batch is:  0.0027756765484809875\n",
      "\n",
      "The classification loss after processing this batch is:  0.12400897592306137\n",
      "The representation loss after processing this batch is:  0.003095567226409912\n",
      "\n",
      "The classification loss after processing this batch is:  0.19264431297779083\n",
      "The representation loss after processing this batch is:  0.0027270540595054626\n",
      "\n",
      "The classification loss after processing this batch is:  0.2794550955295563\n",
      "The representation loss after processing this batch is:  0.002790190279483795\n",
      "\n",
      "The classification loss after processing this batch is:  0.17369960248470306\n",
      "The representation loss after processing this batch is:  0.002490125596523285\n",
      "\n",
      "The classification loss after processing this batch is:  0.15393348038196564\n",
      "The representation loss after processing this batch is:  0.0028320997953414917\n",
      "\n",
      "The classification loss after processing this batch is:  0.16703087091445923\n",
      "The representation loss after processing this batch is:  0.0028634145855903625\n",
      "\n",
      "The classification loss after processing this batch is:  0.13069888949394226\n",
      "The representation loss after processing this batch is:  0.003253661096096039\n",
      "\n",
      "The classification loss after processing this batch is:  0.18411779403686523\n",
      "The representation loss after processing this batch is:  0.0029912441968917847\n",
      "\n",
      "The classification loss after processing this batch is:  0.07592182606458664\n",
      "The representation loss after processing this batch is:  0.00301419198513031\n",
      "\n",
      "The classification loss after processing this batch is:  0.1730525940656662\n",
      "The representation loss after processing this batch is:  0.002615213394165039\n",
      "\n",
      "The classification loss after processing this batch is:  0.2475299835205078\n",
      "The representation loss after processing this batch is:  0.002928018569946289\n",
      "\n",
      "The classification loss after processing this batch is:  0.09902521967887878\n",
      "The representation loss after processing this batch is:  0.0030972063541412354\n",
      "\n",
      "The classification loss after processing this batch is:  0.22449363768100739\n",
      "The representation loss after processing this batch is:  0.0024661757051944733\n",
      "\n",
      "The classification loss after processing this batch is:  0.1643296629190445\n",
      "The representation loss after processing this batch is:  0.0025643855333328247\n",
      "\n",
      "The classification loss after processing this batch is:  0.15041443705558777\n",
      "The representation loss after processing this batch is:  0.0026821643114089966\n",
      "\n",
      "The classification loss after processing this batch is:  0.11427322775125504\n",
      "The representation loss after processing this batch is:  0.0026753321290016174\n",
      "\n",
      "The classification loss after processing this batch is:  0.20150652527809143\n",
      "The representation loss after processing this batch is:  0.002931036055088043\n",
      "\n",
      "The classification loss after processing this batch is:  0.09648311883211136\n",
      "The representation loss after processing this batch is:  0.0031623467803001404\n",
      "\n",
      "The classification loss after processing this batch is:  0.4093446135520935\n",
      "The representation loss after processing this batch is:  0.0029290467500686646\n",
      "\n",
      "The classification loss after processing this batch is:  0.19534602761268616\n",
      "The representation loss after processing this batch is:  0.0029430240392684937\n",
      "\n",
      "The classification loss after processing this batch is:  0.22229214012622833\n",
      "The representation loss after processing this batch is:  0.002850770950317383\n",
      "\n",
      "The classification loss after processing this batch is:  0.11887885630130768\n",
      "The representation loss after processing this batch is:  0.002575136721134186\n",
      "\n",
      "The classification loss after processing this batch is:  0.19243739545345306\n",
      "The representation loss after processing this batch is:  0.0031540244817733765\n",
      "\n",
      "The classification loss after processing this batch is:  0.10239846259355545\n",
      "The representation loss after processing this batch is:  0.002721734344959259\n",
      "\n",
      "The classification loss after processing this batch is:  0.18964949250221252\n",
      "The representation loss after processing this batch is:  0.0029376447200775146\n",
      "\n",
      "The classification loss after processing this batch is:  0.2724083364009857\n",
      "The representation loss after processing this batch is:  0.003183320164680481\n",
      "\n",
      "The classification loss after processing this batch is:  0.19632914662361145\n",
      "The representation loss after processing this batch is:  0.003520064055919647\n",
      "\n",
      "The classification loss after processing this batch is:  0.22455435991287231\n",
      "The representation loss after processing this batch is:  0.002902969717979431\n",
      "\n",
      "The classification loss after processing this batch is:  0.13860173523426056\n",
      "The representation loss after processing this batch is:  0.002704143524169922\n",
      "\n",
      "The classification loss after processing this batch is:  0.24474507570266724\n",
      "The representation loss after processing this batch is:  0.0031433701515197754\n",
      "\n",
      "The classification loss after processing this batch is:  0.1757650375366211\n",
      "The representation loss after processing this batch is:  0.0030685290694236755\n",
      "\n",
      "The classification loss after processing this batch is:  0.22073443233966827\n",
      "The representation loss after processing this batch is:  0.00289154052734375\n",
      "\n",
      "The classification loss after processing this batch is:  0.14471717178821564\n",
      "The representation loss after processing this batch is:  0.0030039995908737183\n",
      "\n",
      "The classification loss after processing this batch is:  0.14988365769386292\n",
      "The representation loss after processing this batch is:  0.0030643045902252197\n",
      "\n",
      "The classification loss after processing this batch is:  0.0909426361322403\n",
      "The representation loss after processing this batch is:  0.0027270354330539703\n",
      "\n",
      "The classification loss after processing this batch is:  0.2246970385313034\n",
      "The representation loss after processing this batch is:  0.0029272176325321198\n",
      "\n",
      "The classification loss after processing this batch is:  0.32347574830055237\n",
      "The representation loss after processing this batch is:  0.0029041022062301636\n",
      "\n",
      "The classification loss after processing this batch is:  0.14422963559627533\n",
      "The representation loss after processing this batch is:  0.003155432641506195\n",
      "\n",
      "The classification loss after processing this batch is:  0.2253020852804184\n",
      "The representation loss after processing this batch is:  0.003795318305492401\n",
      "\n",
      "The classification loss after processing this batch is:  0.2539576292037964\n",
      "The representation loss after processing this batch is:  0.0027644485235214233\n",
      "\n",
      "The classification loss after processing this batch is:  0.23281683027744293\n",
      "The representation loss after processing this batch is:  0.0032723620533943176\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1082308292388916\n",
      "The representation loss after processing this batch is:  0.0027805864810943604\n",
      "\n",
      "The classification loss after processing this batch is:  0.2389642596244812\n",
      "The representation loss after processing this batch is:  0.003124825656414032\n",
      "\n",
      "The classification loss after processing this batch is:  0.22851009666919708\n",
      "The representation loss after processing this batch is:  0.003227606415748596\n",
      "\n",
      "The classification loss after processing this batch is:  0.17979417741298676\n",
      "The representation loss after processing this batch is:  0.002873852849006653\n",
      "\n",
      "The classification loss after processing this batch is:  0.07661435753107071\n",
      "The representation loss after processing this batch is:  0.003121897578239441\n",
      "\n",
      "The classification loss after processing this batch is:  0.14523956179618835\n",
      "The representation loss after processing this batch is:  0.003112219274044037\n",
      "\n",
      "The classification loss after processing this batch is:  0.1615498661994934\n",
      "The representation loss after processing this batch is:  0.003158465027809143\n",
      "\n",
      "The classification loss after processing this batch is:  0.19112186133861542\n",
      "The representation loss after processing this batch is:  0.0026764795184135437\n",
      "\n",
      "The classification loss after processing this batch is:  0.25235065817832947\n",
      "The representation loss after processing this batch is:  0.0030579566955566406\n",
      "\n",
      "The classification loss after processing this batch is:  0.2009456902742386\n",
      "The representation loss after processing this batch is:  0.0027619190514087677\n",
      "\n",
      "The classification loss after processing this batch is:  0.17424039542675018\n",
      "The representation loss after processing this batch is:  0.00334823876619339\n",
      "\n",
      "The classification loss after processing this batch is:  0.2310452163219452\n",
      "The representation loss after processing this batch is:  0.0034427866339683533\n",
      "\n",
      "The classification loss after processing this batch is:  0.1755886673927307\n",
      "The representation loss after processing this batch is:  0.0033277124166488647\n",
      "\n",
      "The classification loss after processing this batch is:  0.17256273329257965\n",
      "The representation loss after processing this batch is:  0.0033322125673294067\n",
      "\n",
      "The classification loss after processing this batch is:  0.3093148469924927\n",
      "The representation loss after processing this batch is:  0.0031183362007141113\n",
      "\n",
      "The classification loss after processing this batch is:  0.28624165058135986\n",
      "The representation loss after processing this batch is:  0.0035422444343566895\n",
      "\n",
      "The classification loss after processing this batch is:  0.13944225013256073\n",
      "The representation loss after processing this batch is:  0.0029186084866523743\n",
      "\n",
      "The classification loss after processing this batch is:  0.10885809361934662\n",
      "The representation loss after processing this batch is:  0.0029179900884628296\n",
      "\n",
      "The classification loss after processing this batch is:  0.14153365790843964\n",
      "The representation loss after processing this batch is:  0.002710886299610138\n",
      "\n",
      "The classification loss after processing this batch is:  0.1388983577489853\n",
      "The representation loss after processing this batch is:  0.003184176981449127\n",
      "\n",
      "The classification loss after processing this batch is:  0.14682576060295105\n",
      "The representation loss after processing this batch is:  0.00277923047542572\n",
      "\n",
      "The classification loss after processing this batch is:  0.2943119704723358\n",
      "The representation loss after processing this batch is:  0.0026671364903450012\n",
      "\n",
      "The classification loss after processing this batch is:  0.26116234064102173\n",
      "The representation loss after processing this batch is:  0.0036286190152168274\n",
      "\n",
      "The classification loss after processing this batch is:  0.19065900146961212\n",
      "The representation loss after processing this batch is:  0.0025879554450511932\n",
      "\n",
      "The classification loss after processing this batch is:  0.17458155751228333\n",
      "The representation loss after processing this batch is:  0.0026010386645793915\n",
      "\n",
      "The classification loss after processing this batch is:  0.15234938263893127\n",
      "The representation loss after processing this batch is:  0.002490740269422531\n",
      "\n",
      "The classification loss after processing this batch is:  0.1673416942358017\n",
      "The representation loss after processing this batch is:  0.0027758702635765076\n",
      "\n",
      "The classification loss after processing this batch is:  0.2895239293575287\n",
      "The representation loss after processing this batch is:  0.002840731292963028\n",
      "\n",
      "The classification loss after processing this batch is:  0.2639321982860565\n",
      "The representation loss after processing this batch is:  0.002909727394580841\n",
      "\n",
      "The classification loss after processing this batch is:  0.33290863037109375\n",
      "The representation loss after processing this batch is:  0.0028322413563728333\n",
      "\n",
      "The classification loss after processing this batch is:  0.17586740851402283\n",
      "The representation loss after processing this batch is:  0.003016069531440735\n",
      "\n",
      "The classification loss after processing this batch is:  0.07061341404914856\n",
      "The representation loss after processing this batch is:  0.003382064402103424\n",
      "\n",
      "The classification loss after processing this batch is:  0.20801857113838196\n",
      "The representation loss after processing this batch is:  0.0029029808938503265\n",
      "\n",
      "The classification loss after processing this batch is:  0.1680362969636917\n",
      "The representation loss after processing this batch is:  0.002892501652240753\n",
      "\n",
      "The classification loss after processing this batch is:  0.22558142244815826\n",
      "The representation loss after processing this batch is:  0.003427758812904358\n",
      "\n",
      "The classification loss after processing this batch is:  0.21803337335586548\n",
      "The representation loss after processing this batch is:  0.0027985163033008575\n",
      "\n",
      "The classification loss after processing this batch is:  0.22417278587818146\n",
      "The representation loss after processing this batch is:  0.0028948336839675903\n",
      "\n",
      "The classification loss after processing this batch is:  0.20273055136203766\n",
      "The representation loss after processing this batch is:  0.002651594579219818\n",
      "\n",
      "The classification loss after processing this batch is:  0.2370266318321228\n",
      "The representation loss after processing this batch is:  0.002749975770711899\n",
      "\n",
      "The classification loss after processing this batch is:  0.32505980134010315\n",
      "The representation loss after processing this batch is:  0.002880483865737915\n",
      "\n",
      "The classification loss after processing this batch is:  0.31664901971817017\n",
      "The representation loss after processing this batch is:  0.00299062579870224\n",
      "\n",
      "The classification loss after processing this batch is:  0.22458000481128693\n",
      "The representation loss after processing this batch is:  0.0028780847787857056\n",
      "\n",
      "The classification loss after processing this batch is:  0.08403466641902924\n",
      "The representation loss after processing this batch is:  0.0030425935983657837\n",
      "\n",
      "The classification loss after processing this batch is:  0.05768679827451706\n",
      "The representation loss after processing this batch is:  0.0029531940817832947\n",
      "\n",
      "The classification loss after processing this batch is:  0.1596805304288864\n",
      "The representation loss after processing this batch is:  0.002910122275352478\n",
      "\n",
      "The classification loss after processing this batch is:  0.09276900440454483\n",
      "The representation loss after processing this batch is:  0.00429004430770874\n",
      "\n",
      "The classification loss after processing this batch is:  0.22715336084365845\n",
      "The representation loss after processing this batch is:  0.003041408956050873\n",
      "\n",
      "The classification loss after processing this batch is:  0.11704324930906296\n",
      "The representation loss after processing this batch is:  0.003225170075893402\n",
      "\n",
      "The classification loss after processing this batch is:  0.2501487731933594\n",
      "The representation loss after processing this batch is:  0.0029845088720321655\n",
      "\n",
      "The classification loss after processing this batch is:  0.08497507125139236\n",
      "The representation loss after processing this batch is:  0.0034037157893180847\n",
      "\n",
      "The classification loss after processing this batch is:  0.2010347992181778\n",
      "The representation loss after processing this batch is:  0.0030151866376399994\n",
      "\n",
      "The classification loss after processing this batch is:  0.16366714239120483\n",
      "The representation loss after processing this batch is:  0.0032686814665794373\n",
      "\n",
      "The classification loss after processing this batch is:  0.2090698927640915\n",
      "The representation loss after processing this batch is:  0.0030420497059822083\n",
      "\n",
      "The classification loss after processing this batch is:  0.1560392826795578\n",
      "The representation loss after processing this batch is:  0.002760060131549835\n",
      "\n",
      "The classification loss after processing this batch is:  0.11061925441026688\n",
      "The representation loss after processing this batch is:  0.0025856606662273407\n",
      "\n",
      "The classification loss after processing this batch is:  0.1730790138244629\n",
      "The representation loss after processing this batch is:  0.002875104546546936\n",
      "\n",
      "The classification loss after processing this batch is:  0.1947677880525589\n",
      "The representation loss after processing this batch is:  0.002747856080532074\n",
      "\n",
      "The classification loss after processing this batch is:  0.22313188016414642\n",
      "The representation loss after processing this batch is:  0.002892330288887024\n",
      "\n",
      "The classification loss after processing this batch is:  0.16955558955669403\n",
      "The representation loss after processing this batch is:  0.0030205026268959045\n",
      "\n",
      "The classification loss after processing this batch is:  0.1050490140914917\n",
      "The representation loss after processing this batch is:  0.003049015998840332\n",
      "\n",
      "The classification loss after processing this batch is:  0.0767235979437828\n",
      "The representation loss after processing this batch is:  0.002879895269870758\n",
      "\n",
      "The classification loss after processing this batch is:  0.0852215439081192\n",
      "The representation loss after processing this batch is:  0.0031760558485984802\n",
      "\n",
      "The classification loss after processing this batch is:  0.07577688992023468\n",
      "The representation loss after processing this batch is:  0.0029902979731559753\n",
      "\n",
      "The classification loss after processing this batch is:  0.16081936657428741\n",
      "The representation loss after processing this batch is:  0.0030051767826080322\n",
      "\n",
      "The classification loss after processing this batch is:  0.1116081178188324\n",
      "The representation loss after processing this batch is:  0.0030217766761779785\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.062000956386327744\n",
      "The representation loss after processing this batch is:  0.0030037686228752136\n",
      "\n",
      "The classification loss after processing this batch is:  0.1667979210615158\n",
      "The representation loss after processing this batch is:  0.003481462597846985\n",
      "\n",
      "The classification loss after processing this batch is:  0.13191701471805573\n",
      "The representation loss after processing this batch is:  0.003046862781047821\n",
      "\n",
      "The classification loss after processing this batch is:  0.08410106599330902\n",
      "The representation loss after processing this batch is:  0.0028728358447551727\n",
      "\n",
      "The classification loss after processing this batch is:  0.10976474732160568\n",
      "The representation loss after processing this batch is:  0.00309918075799942\n",
      "\n",
      "The classification loss after processing this batch is:  0.08662291616201401\n",
      "The representation loss after processing this batch is:  0.002773575484752655\n",
      "\n",
      "The classification loss after processing this batch is:  0.07478640973567963\n",
      "The representation loss after processing this batch is:  0.0029870569705963135\n",
      "\n",
      "The classification loss after processing this batch is:  0.20656387507915497\n",
      "The representation loss after processing this batch is:  0.002939566969871521\n",
      "\n",
      "The classification loss after processing this batch is:  0.2142220437526703\n",
      "The representation loss after processing this batch is:  0.003146640956401825\n",
      "\n",
      "The classification loss after processing this batch is:  0.13219720125198364\n",
      "The representation loss after processing this batch is:  0.0030362308025360107\n",
      "\n",
      "The classification loss after processing this batch is:  0.24939663708209991\n",
      "The representation loss after processing this batch is:  0.002791237086057663\n",
      "\n",
      "The classification loss after processing this batch is:  0.10807804763317108\n",
      "The representation loss after processing this batch is:  0.00284615159034729\n",
      "\n",
      "The classification loss after processing this batch is:  0.18327811360359192\n",
      "The representation loss after processing this batch is:  0.0026257336139678955\n",
      "\n",
      "The classification loss after processing this batch is:  0.22177067399024963\n",
      "The representation loss after processing this batch is:  0.00321168452501297\n",
      "\n",
      "The classification loss after processing this batch is:  0.13188472390174866\n",
      "The representation loss after processing this batch is:  0.00308120995759964\n",
      "\n",
      "The classification loss after processing this batch is:  0.2403409332036972\n",
      "The representation loss after processing this batch is:  0.0028640925884246826\n",
      "\n",
      "The classification loss after processing this batch is:  0.18073035776615143\n",
      "The representation loss after processing this batch is:  0.002836748957633972\n",
      "\n",
      "The classification loss after processing this batch is:  0.17555387318134308\n",
      "The representation loss after processing this batch is:  0.0029228180646896362\n",
      "\n",
      "The classification loss after processing this batch is:  0.19805052876472473\n",
      "The representation loss after processing this batch is:  0.00284721702337265\n",
      "\n",
      "The classification loss after processing this batch is:  0.16369791328907013\n",
      "The representation loss after processing this batch is:  0.003127463161945343\n",
      "\n",
      "The classification loss after processing this batch is:  0.17160670459270477\n",
      "The representation loss after processing this batch is:  0.002639342099428177\n",
      "\n",
      "The classification loss after processing this batch is:  0.14458821713924408\n",
      "The representation loss after processing this batch is:  0.0030224397778511047\n",
      "\n",
      "The classification loss after processing this batch is:  0.2274976372718811\n",
      "The representation loss after processing this batch is:  0.0029304400086402893\n",
      "\n",
      "The classification loss after processing this batch is:  0.16273531317710876\n",
      "The representation loss after processing this batch is:  0.0026417970657348633\n",
      "\n",
      "The classification loss after processing this batch is:  0.11909456551074982\n",
      "The representation loss after processing this batch is:  0.0029959529638290405\n",
      "\n",
      "The classification loss after processing this batch is:  0.1202460303902626\n",
      "The representation loss after processing this batch is:  0.002655111253261566\n",
      "\n",
      "The classification loss after processing this batch is:  0.2431221604347229\n",
      "The representation loss after processing this batch is:  0.002486087381839752\n",
      "\n",
      "The classification loss after processing this batch is:  0.10963524132966995\n",
      "The representation loss after processing this batch is:  0.0031433627009391785\n",
      "\n",
      "The classification loss after processing this batch is:  0.16194753348827362\n",
      "The representation loss after processing this batch is:  0.0032086893916130066\n",
      "\n",
      "The classification loss after processing this batch is:  0.18104301393032074\n",
      "The representation loss after processing this batch is:  0.002636924386024475\n",
      "\n",
      "The classification loss after processing this batch is:  0.11120753735303879\n",
      "The representation loss after processing this batch is:  0.003267839550971985\n",
      "\n",
      "The classification loss after processing this batch is:  0.08573951572179794\n",
      "The representation loss after processing this batch is:  0.0030279606580734253\n",
      "\n",
      "The classification loss after processing this batch is:  0.14199669659137726\n",
      "The representation loss after processing this batch is:  0.0030931830406188965\n",
      "\n",
      "The classification loss after processing this batch is:  0.13496902585029602\n",
      "The representation loss after processing this batch is:  0.0032477453351020813\n",
      "\n",
      "The classification loss after processing this batch is:  0.1583503782749176\n",
      "The representation loss after processing this batch is:  0.0029789507389068604\n",
      "\n",
      "The classification loss after processing this batch is:  0.21945632994174957\n",
      "The representation loss after processing this batch is:  0.002788592129945755\n",
      "\n",
      "The classification loss after processing this batch is:  0.1464187055826187\n",
      "The representation loss after processing this batch is:  0.0029394924640655518\n",
      "\n",
      "The classification loss after processing this batch is:  0.23294299840927124\n",
      "The representation loss after processing this batch is:  0.0023955591022968292\n",
      "\n",
      "The classification loss after processing this batch is:  0.17768512666225433\n",
      "The representation loss after processing this batch is:  0.0032481253147125244\n",
      "\n",
      "The classification loss after processing this batch is:  0.08144770562648773\n",
      "The representation loss after processing this batch is:  0.003071144223213196\n",
      "\n",
      "The classification loss after processing this batch is:  0.11116917431354523\n",
      "The representation loss after processing this batch is:  0.002826739102602005\n",
      "\n",
      "The classification loss after processing this batch is:  0.1727483570575714\n",
      "The representation loss after processing this batch is:  0.0028606653213500977\n",
      "\n",
      "The classification loss after processing this batch is:  0.1724330484867096\n",
      "The representation loss after processing this batch is:  0.0029239654541015625\n",
      "\n",
      "The classification loss after processing this batch is:  0.1359645575284958\n",
      "The representation loss after processing this batch is:  0.0030335187911987305\n",
      "\n",
      "The classification loss after processing this batch is:  0.2054152935743332\n",
      "The representation loss after processing this batch is:  0.0029724054038524628\n",
      "\n",
      "The classification loss after processing this batch is:  0.17584581673145294\n",
      "The representation loss after processing this batch is:  0.00366828590631485\n",
      "\n",
      "The classification loss after processing this batch is:  0.1745668351650238\n",
      "The representation loss after processing this batch is:  0.0031144097447395325\n",
      "\n",
      "The classification loss after processing this batch is:  0.23239071667194366\n",
      "The representation loss after processing this batch is:  0.0028048455715179443\n",
      "\n",
      "The classification loss after processing this batch is:  0.18041566014289856\n",
      "The representation loss after processing this batch is:  0.002760283648967743\n",
      "\n",
      "The classification loss after processing this batch is:  0.15712231397628784\n",
      "The representation loss after processing this batch is:  0.002940036356449127\n",
      "\n",
      "The classification loss after processing this batch is:  0.10488998144865036\n",
      "The representation loss after processing this batch is:  0.003414466977119446\n",
      "\n",
      "The classification loss after processing this batch is:  0.092703677713871\n",
      "The representation loss after processing this batch is:  0.0030089691281318665\n",
      "\n",
      "The classification loss after processing this batch is:  0.24700713157653809\n",
      "The representation loss after processing this batch is:  0.00252397358417511\n",
      "\n",
      "The classification loss after processing this batch is:  0.19924074411392212\n",
      "The representation loss after processing this batch is:  0.0026367977261543274\n",
      "\n",
      "The classification loss after processing this batch is:  0.20197150111198425\n",
      "The representation loss after processing this batch is:  0.0027648434042930603\n",
      "\n",
      "The classification loss after processing this batch is:  0.21128146350383759\n",
      "The representation loss after processing this batch is:  0.0030273348093032837\n",
      "\n",
      "The classification loss after processing this batch is:  0.18300670385360718\n",
      "The representation loss after processing this batch is:  0.003000400960445404\n",
      "\n",
      "The classification loss after processing this batch is:  0.2104824334383011\n",
      "The representation loss after processing this batch is:  0.002826020121574402\n",
      "\n",
      "The classification loss after processing this batch is:  0.22919420897960663\n",
      "The representation loss after processing this batch is:  0.0030472055077552795\n",
      "\n",
      "The classification loss after processing this batch is:  0.2361365705728531\n",
      "The representation loss after processing this batch is:  0.002843402326107025\n",
      "\n",
      "The classification loss after processing this batch is:  0.24049800634384155\n",
      "The representation loss after processing this batch is:  0.0030675120651721954\n",
      "\n",
      "The classification loss after processing this batch is:  0.12884968519210815\n",
      "The representation loss after processing this batch is:  0.003286898136138916\n",
      "\n",
      "The classification loss after processing this batch is:  0.08623974025249481\n",
      "The representation loss after processing this batch is:  0.003314174711704254\n",
      "\n",
      "The classification loss after processing this batch is:  0.16116686165332794\n",
      "The representation loss after processing this batch is:  0.0029131658375263214\n",
      "\n",
      "The classification loss after processing this batch is:  0.18091708421707153\n",
      "The representation loss after processing this batch is:  0.0026765242218971252\n",
      "\n",
      "The classification loss after processing this batch is:  0.10050830245018005\n",
      "The representation loss after processing this batch is:  0.0026937276124954224\n",
      "\n",
      "The classification loss after processing this batch is:  0.13735917210578918\n",
      "The representation loss after processing this batch is:  0.002928696572780609\n",
      "\n",
      "The classification loss after processing this batch is:  0.1647917777299881\n",
      "The representation loss after processing this batch is:  0.002738848328590393\n",
      "\n",
      "The classification loss after processing this batch is:  0.14909198880195618\n",
      "The representation loss after processing this batch is:  0.0029436498880386353\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.12872152030467987\n",
      "The representation loss after processing this batch is:  0.003176748752593994\n",
      "\n",
      "The classification loss after processing this batch is:  0.13231238722801208\n",
      "The representation loss after processing this batch is:  0.002649247646331787\n",
      "\n",
      "The classification loss after processing this batch is:  0.12729951739311218\n",
      "The representation loss after processing this batch is:  0.002954859286546707\n",
      "\n",
      "The classification loss after processing this batch is:  0.18641187250614166\n",
      "The representation loss after processing this batch is:  0.003381602466106415\n",
      "\n",
      "The classification loss after processing this batch is:  0.14205637574195862\n",
      "The representation loss after processing this batch is:  0.0029999203979969025\n",
      "\n",
      "The classification loss after processing this batch is:  0.1793341338634491\n",
      "The representation loss after processing this batch is:  0.003444913774728775\n",
      "\n",
      "The classification loss after processing this batch is:  0.08341009169816971\n",
      "The representation loss after processing this batch is:  0.0033447295427322388\n",
      "\n",
      "The classification loss after processing this batch is:  0.09117839485406876\n",
      "The representation loss after processing this batch is:  0.0030836090445518494\n",
      "\n",
      "The classification loss after processing this batch is:  0.205789253115654\n",
      "The representation loss after processing this batch is:  0.002857007086277008\n",
      "\n",
      "The classification loss after processing this batch is:  0.2564970552921295\n",
      "The representation loss after processing this batch is:  0.0026295073330402374\n",
      "\n",
      "The classification loss after processing this batch is:  0.14706608653068542\n",
      "The representation loss after processing this batch is:  0.0026030614972114563\n",
      "\n",
      "The classification loss after processing this batch is:  0.07587133347988129\n",
      "The representation loss after processing this batch is:  0.0028873756527900696\n",
      "\n",
      "The classification loss after processing this batch is:  0.20584604144096375\n",
      "The representation loss after processing this batch is:  0.002398677170276642\n",
      "\n",
      "The classification loss after processing this batch is:  0.0618932768702507\n",
      "The representation loss after processing this batch is:  0.0030604898929595947\n",
      "\n",
      "The classification loss after processing this batch is:  0.18721802532672882\n",
      "The representation loss after processing this batch is:  0.002809479832649231\n",
      "\n",
      "The classification loss after processing this batch is:  0.15210333466529846\n",
      "The representation loss after processing this batch is:  0.0031345337629318237\n",
      "\n",
      "The classification loss after processing this batch is:  0.0751739889383316\n",
      "The representation loss after processing this batch is:  0.0024984627962112427\n",
      "\n",
      "The classification loss after processing this batch is:  0.12048553675413132\n",
      "The representation loss after processing this batch is:  0.0030804499983787537\n",
      "\n",
      "The classification loss after processing this batch is:  0.11799953132867813\n",
      "The representation loss after processing this batch is:  0.002965584397315979\n",
      "\n",
      "The classification loss after processing this batch is:  0.08894968777894974\n",
      "The representation loss after processing this batch is:  0.0028262436389923096\n",
      "\n",
      "The classification loss after processing this batch is:  0.2802583873271942\n",
      "The representation loss after processing this batch is:  0.0028411932289600372\n",
      "\n",
      "The classification loss after processing this batch is:  0.2544696033000946\n",
      "The representation loss after processing this batch is:  0.0026213563978672028\n",
      "\n",
      "The classification loss after processing this batch is:  0.22870442271232605\n",
      "The representation loss after processing this batch is:  0.002911612391471863\n",
      "\n",
      "The classification loss after processing this batch is:  0.25957566499710083\n",
      "The representation loss after processing this batch is:  0.0027385465800762177\n",
      "\n",
      "The classification loss after processing this batch is:  0.16627849638462067\n",
      "The representation loss after processing this batch is:  0.0030629336833953857\n",
      "\n",
      "The classification loss after processing this batch is:  0.1514560729265213\n",
      "The representation loss after processing this batch is:  0.003070913255214691\n",
      "\n",
      "The classification loss after processing this batch is:  0.23474232852458954\n",
      "The representation loss after processing this batch is:  0.0028300508856773376\n",
      "\n",
      "The classification loss after processing this batch is:  0.1420004516839981\n",
      "The representation loss after processing this batch is:  0.0030865035951137543\n",
      "\n",
      "The classification loss after processing this batch is:  0.23849782347679138\n",
      "The representation loss after processing this batch is:  0.0029548071324825287\n",
      "\n",
      "The classification loss after processing this batch is:  0.164932519197464\n",
      "The representation loss after processing this batch is:  0.0028848275542259216\n",
      "\n",
      "The classification loss after processing this batch is:  0.19661611318588257\n",
      "The representation loss after processing this batch is:  0.0026095621287822723\n",
      "\n",
      "The classification loss after processing this batch is:  0.14388595521450043\n",
      "The representation loss after processing this batch is:  0.0027855709195137024\n",
      "\n",
      "The classification loss after processing this batch is:  0.13759253919124603\n",
      "The representation loss after processing this batch is:  0.0029179081320762634\n",
      "\n",
      "The classification loss after processing this batch is:  0.19833646714687347\n",
      "The representation loss after processing this batch is:  0.002686150372028351\n",
      "\n",
      "The classification loss after processing this batch is:  0.08598650246858597\n",
      "The representation loss after processing this batch is:  0.003238178789615631\n",
      "\n",
      "The classification loss after processing this batch is:  0.09441424906253815\n",
      "The representation loss after processing this batch is:  0.0028978735208511353\n",
      "\n",
      "The classification loss after processing this batch is:  0.18609043955802917\n",
      "The representation loss after processing this batch is:  0.0027559325098991394\n",
      "\n",
      "The classification loss after processing this batch is:  0.2506543695926666\n",
      "The representation loss after processing this batch is:  0.002870403230190277\n",
      "\n",
      "The classification loss after processing this batch is:  0.09247071295976639\n",
      "The representation loss after processing this batch is:  0.0027089864015579224\n",
      "\n",
      "The classification loss after processing this batch is:  0.10945267230272293\n",
      "The representation loss after processing this batch is:  0.0025047436356544495\n",
      "\n",
      "The classification loss after processing this batch is:  0.1962207704782486\n",
      "The representation loss after processing this batch is:  0.0027557983994483948\n",
      "\n",
      "The classification loss after processing this batch is:  0.2470073401927948\n",
      "The representation loss after processing this batch is:  0.002590373158454895\n",
      "\n",
      "The classification loss after processing this batch is:  0.15651318430900574\n",
      "The representation loss after processing this batch is:  0.0028908438980579376\n",
      "\n",
      "The classification loss after processing this batch is:  0.29248473048210144\n",
      "The representation loss after processing this batch is:  0.0025929249823093414\n",
      "\n",
      "The classification loss after processing this batch is:  0.12711971998214722\n",
      "The representation loss after processing this batch is:  0.0031125321984291077\n",
      "\n",
      "The classification loss after processing this batch is:  0.061340175569057465\n",
      "The representation loss after processing this batch is:  0.002432018518447876\n",
      "\n",
      "The classification loss after processing this batch is:  0.08227387815713882\n",
      "The representation loss after processing this batch is:  0.002774856984615326\n",
      "\n",
      "The classification loss after processing this batch is:  0.1805231124162674\n",
      "The representation loss after processing this batch is:  0.0033090561628341675\n",
      "\n",
      "The classification loss after processing this batch is:  0.18995729088783264\n",
      "The representation loss after processing this batch is:  0.003364741802215576\n",
      "\n",
      "The classification loss after processing this batch is:  0.13321635127067566\n",
      "The representation loss after processing this batch is:  0.003871537744998932\n",
      "\n",
      "The classification loss after processing this batch is:  0.15026436746120453\n",
      "The representation loss after processing this batch is:  0.002853900194168091\n",
      "\n",
      "The classification loss after processing this batch is:  0.14409559965133667\n",
      "The representation loss after processing this batch is:  0.002789340913295746\n",
      "\n",
      "The classification loss after processing this batch is:  0.16698017716407776\n",
      "The representation loss after processing this batch is:  0.002833586186170578\n",
      "\n",
      "The classification loss after processing this batch is:  0.1740279197692871\n",
      "The representation loss after processing this batch is:  0.0026985742151737213\n",
      "\n",
      "The classification loss after processing this batch is:  0.21711359918117523\n",
      "The representation loss after processing this batch is:  0.0027556605637073517\n",
      "\n",
      "The classification loss after processing this batch is:  0.20137841999530792\n",
      "The representation loss after processing this batch is:  0.003025650978088379\n",
      "\n",
      "The classification loss after processing this batch is:  0.28572553396224976\n",
      "The representation loss after processing this batch is:  0.0027142278850078583\n",
      "\n",
      "The classification loss after processing this batch is:  0.17922474443912506\n",
      "The representation loss after processing this batch is:  0.002686966210603714\n",
      "\n",
      "The classification loss after processing this batch is:  0.19408521056175232\n",
      "The representation loss after processing this batch is:  0.0028836876153945923\n",
      "\n",
      "The classification loss after processing this batch is:  0.24180206656455994\n",
      "The representation loss after processing this batch is:  0.002788819372653961\n",
      "\n",
      "The classification loss after processing this batch is:  0.09505273401737213\n",
      "The representation loss after processing this batch is:  0.0028067752718925476\n",
      "\n",
      "The classification loss after processing this batch is:  0.16802765429019928\n",
      "The representation loss after processing this batch is:  0.003493998199701309\n",
      "\n",
      "The classification loss after processing this batch is:  0.13523200154304504\n",
      "The representation loss after processing this batch is:  0.0029824748635292053\n",
      "\n",
      "The classification loss after processing this batch is:  0.14329293370246887\n",
      "The representation loss after processing this batch is:  0.0030430927872657776\n",
      "\n",
      "The classification loss after processing this batch is:  0.11825963854789734\n",
      "The representation loss after processing this batch is:  0.0024430416524410248\n",
      "\n",
      "The classification loss after processing this batch is:  0.15186840295791626\n",
      "The representation loss after processing this batch is:  0.0026305243372917175\n",
      "\n",
      "The classification loss after processing this batch is:  0.1410636454820633\n",
      "The representation loss after processing this batch is:  0.0028000175952911377\n",
      "\n",
      "The classification loss after processing this batch is:  0.2034854292869568\n",
      "The representation loss after processing this batch is:  0.0026469752192497253\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.19102860987186432\n",
      "The representation loss after processing this batch is:  0.002920977771282196\n",
      "\n",
      "The classification loss after processing this batch is:  0.24375773966312408\n",
      "The representation loss after processing this batch is:  0.0027518942952156067\n",
      "\n",
      "The classification loss after processing this batch is:  0.14240394532680511\n",
      "The representation loss after processing this batch is:  0.0031055063009262085\n",
      "\n",
      "The classification loss after processing this batch is:  0.17872454226016998\n",
      "The representation loss after processing this batch is:  0.002664674073457718\n",
      "\n",
      "The classification loss after processing this batch is:  0.15715180337429047\n",
      "The representation loss after processing this batch is:  0.002864852547645569\n",
      "\n",
      "The classification loss after processing this batch is:  0.25922688841819763\n",
      "The representation loss after processing this batch is:  0.0034204162657260895\n",
      "\n",
      "The classification loss after processing this batch is:  0.3022443652153015\n",
      "The representation loss after processing this batch is:  0.0030578970909118652\n",
      "\n",
      "The classification loss after processing this batch is:  0.07858577370643616\n",
      "The representation loss after processing this batch is:  0.0025369077920913696\n",
      "\n",
      "The classification loss after processing this batch is:  0.09020034223794937\n",
      "The representation loss after processing this batch is:  0.00300665944814682\n",
      "\n",
      "The classification loss after processing this batch is:  0.26109936833381653\n",
      "The representation loss after processing this batch is:  0.003133770078420639\n",
      "\n",
      "The classification loss after processing this batch is:  0.1182783916592598\n",
      "The representation loss after processing this batch is:  0.0030703023076057434\n",
      "\n",
      "The classification loss after processing this batch is:  0.12670724093914032\n",
      "The representation loss after processing this batch is:  0.0027965381741523743\n",
      "\n",
      "The classification loss after processing this batch is:  0.17065931856632233\n",
      "The representation loss after processing this batch is:  0.0028441399335861206\n",
      "\n",
      "The classification loss after processing this batch is:  0.16642214357852936\n",
      "The representation loss after processing this batch is:  0.0030574537813663483\n",
      "\n",
      "The classification loss after processing this batch is:  0.29007408022880554\n",
      "The representation loss after processing this batch is:  0.0036232098937034607\n",
      "\n",
      "The classification loss after processing this batch is:  0.2130919098854065\n",
      "The representation loss after processing this batch is:  0.003288090229034424\n",
      "\n",
      "The classification loss after processing this batch is:  0.2231452465057373\n",
      "The representation loss after processing this batch is:  0.0034480243921279907\n",
      "\n",
      "The classification loss after processing this batch is:  0.11723650246858597\n",
      "The representation loss after processing this batch is:  0.002444915473461151\n",
      "\n",
      "The classification loss after processing this batch is:  0.2553006708621979\n",
      "The representation loss after processing this batch is:  0.0027819648385047913\n",
      "\n",
      "The classification loss after processing this batch is:  0.09962791949510574\n",
      "The representation loss after processing this batch is:  0.002671748399734497\n",
      "\n",
      "The classification loss after processing this batch is:  0.09725162386894226\n",
      "The representation loss after processing this batch is:  0.002802155911922455\n",
      "\n",
      "The classification loss after processing this batch is:  0.13829869031906128\n",
      "The representation loss after processing this batch is:  0.002781219780445099\n",
      "\n",
      "The classification loss after processing this batch is:  0.09312019497156143\n",
      "The representation loss after processing this batch is:  0.002734728157520294\n",
      "\n",
      "The classification loss after processing this batch is:  0.11843010038137436\n",
      "The representation loss after processing this batch is:  0.002956181764602661\n",
      "\n",
      "The classification loss after processing this batch is:  0.09268149733543396\n",
      "The representation loss after processing this batch is:  0.002991221845149994\n",
      "\n",
      "The classification loss after processing this batch is:  0.11868008971214294\n",
      "The representation loss after processing this batch is:  0.0029438920319080353\n",
      "\n",
      "The classification loss after processing this batch is:  0.1506429761648178\n",
      "The representation loss after processing this batch is:  0.002835683524608612\n",
      "\n",
      "The classification loss after processing this batch is:  0.21131397783756256\n",
      "The representation loss after processing this batch is:  0.0031971484422683716\n",
      "\n",
      "The classification loss after processing this batch is:  0.20286421477794647\n",
      "The representation loss after processing this batch is:  0.0025582946836948395\n",
      "\n",
      "The classification loss after processing this batch is:  0.17129351198673248\n",
      "The representation loss after processing this batch is:  0.0031987950205802917\n",
      "\n",
      "The classification loss after processing this batch is:  0.22652466595172882\n",
      "The representation loss after processing this batch is:  0.0029018446803092957\n",
      "\n",
      "The classification loss after processing this batch is:  0.10217438638210297\n",
      "The representation loss after processing this batch is:  0.0026855766773223877\n",
      "\n",
      "The classification loss after processing this batch is:  0.191331148147583\n",
      "The representation loss after processing this batch is:  0.0029091238975524902\n",
      "\n",
      "The classification loss after processing this batch is:  0.3181059956550598\n",
      "The representation loss after processing this batch is:  0.0030138418078422546\n",
      "\n",
      "The classification loss after processing this batch is:  0.2021423876285553\n",
      "The representation loss after processing this batch is:  0.0027313455939292908\n",
      "\n",
      "The classification loss after processing this batch is:  0.2860548794269562\n",
      "The representation loss after processing this batch is:  0.0028200410306453705\n",
      "\n",
      "The classification loss after processing this batch is:  0.2226661890745163\n",
      "The representation loss after processing this batch is:  0.0028227418661117554\n",
      "\n",
      "The classification loss after processing this batch is:  0.2029123604297638\n",
      "The representation loss after processing this batch is:  0.002681497484445572\n",
      "\n",
      "The classification loss after processing this batch is:  0.15912602841854095\n",
      "The representation loss after processing this batch is:  0.0028225407004356384\n",
      "\n",
      "The classification loss after processing this batch is:  0.11991184204816818\n",
      "The representation loss after processing this batch is:  0.0027388334274291992\n",
      "\n",
      "The classification loss after processing this batch is:  0.1577892005443573\n",
      "The representation loss after processing this batch is:  0.0028439313173294067\n",
      "\n",
      "The classification loss after processing this batch is:  0.07610376179218292\n",
      "The representation loss after processing this batch is:  0.0029464587569236755\n",
      "\n",
      "The classification loss after processing this batch is:  0.07411147654056549\n",
      "The representation loss after processing this batch is:  0.002972930669784546\n",
      "\n",
      "The classification loss after processing this batch is:  0.1575053632259369\n",
      "The representation loss after processing this batch is:  0.0029977187514305115\n",
      "\n",
      "The classification loss after processing this batch is:  0.09622026979923248\n",
      "The representation loss after processing this batch is:  0.0030311867594718933\n",
      "\n",
      "The classification loss after processing this batch is:  0.27122703194618225\n",
      "The representation loss after processing this batch is:  0.0035316944122314453\n",
      "\n",
      "The classification loss after processing this batch is:  0.1606077402830124\n",
      "The representation loss after processing this batch is:  0.0027833208441734314\n",
      "\n",
      "The classification loss after processing this batch is:  0.19474974274635315\n",
      "The representation loss after processing this batch is:  0.0028625428676605225\n",
      "\n",
      "The classification loss after processing this batch is:  0.3464657962322235\n",
      "The representation loss after processing this batch is:  0.0027088336646556854\n",
      "\n",
      "The classification loss after processing this batch is:  0.188961923122406\n",
      "The representation loss after processing this batch is:  0.002735007554292679\n",
      "\n",
      "The classification loss after processing this batch is:  0.07819656282663345\n",
      "The representation loss after processing this batch is:  0.0027206167578697205\n",
      "\n",
      "The classification loss after processing this batch is:  0.09865832328796387\n",
      "The representation loss after processing this batch is:  0.003183498978614807\n",
      "\n",
      "The classification loss after processing this batch is:  0.10907915234565735\n",
      "The representation loss after processing this batch is:  0.003083959221839905\n",
      "\n",
      "The classification loss after processing this batch is:  0.12037989497184753\n",
      "The representation loss after processing this batch is:  0.0030108392238616943\n",
      "\n",
      "The classification loss after processing this batch is:  0.13079792261123657\n",
      "The representation loss after processing this batch is:  0.0025159120559692383\n",
      "\n",
      "The classification loss after processing this batch is:  0.29732003808021545\n",
      "The representation loss after processing this batch is:  0.002445608377456665\n",
      "\n",
      "The classification loss after processing this batch is:  0.2598777413368225\n",
      "The representation loss after processing this batch is:  0.0028042644262313843\n",
      "\n",
      "The classification loss after processing this batch is:  0.17584986984729767\n",
      "The representation loss after processing this batch is:  0.003120698034763336\n",
      "\n",
      "The classification loss after processing this batch is:  0.25593647360801697\n",
      "The representation loss after processing this batch is:  0.0031153634190559387\n",
      "\n",
      "The classification loss after processing this batch is:  0.1068638265132904\n",
      "The representation loss after processing this batch is:  0.002713620662689209\n",
      "\n",
      "The classification loss after processing this batch is:  0.15988832712173462\n",
      "The representation loss after processing this batch is:  0.0027256980538368225\n",
      "\n",
      "The classification loss after processing this batch is:  0.28164130449295044\n",
      "The representation loss after processing this batch is:  0.0026879534125328064\n",
      "\n",
      "The classification loss after processing this batch is:  0.13915543258190155\n",
      "The representation loss after processing this batch is:  0.0033876150846481323\n",
      "\n",
      "The classification loss after processing this batch is:  0.1709739863872528\n",
      "The representation loss after processing this batch is:  0.0037321969866752625\n",
      "\n",
      "The classification loss after processing this batch is:  0.10755438357591629\n",
      "The representation loss after processing this batch is:  0.0031675249338150024\n",
      "\n",
      "The classification loss after processing this batch is:  0.19950366020202637\n",
      "The representation loss after processing this batch is:  0.003411509096622467\n",
      "\n",
      "The classification loss after processing this batch is:  0.21091489493846893\n",
      "The representation loss after processing this batch is:  0.003298819065093994\n",
      "\n",
      "The classification loss after processing this batch is:  0.173965722322464\n",
      "The representation loss after processing this batch is:  0.0032832324504852295\n",
      "\n",
      "The classification loss after processing this batch is:  0.16679029166698456\n",
      "The representation loss after processing this batch is:  0.0032314807176589966\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.22832991182804108\n",
      "The representation loss after processing this batch is:  0.002476729452610016\n",
      "\n",
      "The classification loss after processing this batch is:  0.16760531067848206\n",
      "The representation loss after processing this batch is:  0.0027115345001220703\n",
      "\n",
      "The classification loss after processing this batch is:  0.1703367978334427\n",
      "The representation loss after processing this batch is:  0.002965502440929413\n",
      "\n",
      "The classification loss after processing this batch is:  0.10507076233625412\n",
      "The representation loss after processing this batch is:  0.003189101815223694\n",
      "\n",
      "The classification loss after processing this batch is:  0.05922210216522217\n",
      "The representation loss after processing this batch is:  0.0031442493200302124\n",
      "\n",
      "The classification loss after processing this batch is:  0.16930337250232697\n",
      "The representation loss after processing this batch is:  0.0029783397912979126\n",
      "\n",
      "The classification loss after processing this batch is:  0.13254287838935852\n",
      "The representation loss after processing this batch is:  0.0031315982341766357\n",
      "\n",
      "The classification loss after processing this batch is:  0.303109735250473\n",
      "The representation loss after processing this batch is:  0.0025209151208400726\n",
      "\n",
      "The classification loss after processing this batch is:  0.07751527428627014\n",
      "The representation loss after processing this batch is:  0.0032191649079322815\n",
      "\n",
      "The classification loss after processing this batch is:  0.1274079829454422\n",
      "The representation loss after processing this batch is:  0.0030007734894752502\n",
      "\n",
      "The classification loss after processing this batch is:  0.19899982213974\n",
      "The representation loss after processing this batch is:  0.0030336305499076843\n",
      "\n",
      "The classification loss after processing this batch is:  0.16876162588596344\n",
      "The representation loss after processing this batch is:  0.0030520930886268616\n",
      "\n",
      "The classification loss after processing this batch is:  0.18567213416099548\n",
      "The representation loss after processing this batch is:  0.0031249523162841797\n",
      "\n",
      "The classification loss after processing this batch is:  0.07813452929258347\n",
      "The representation loss after processing this batch is:  0.002822786569595337\n",
      "\n",
      "The classification loss after processing this batch is:  0.08974171429872513\n",
      "The representation loss after processing this batch is:  0.002901047468185425\n",
      "\n",
      "The classification loss after processing this batch is:  0.09340104460716248\n",
      "The representation loss after processing this batch is:  0.0031064599752426147\n",
      "\n",
      "The classification loss after processing this batch is:  0.1976829171180725\n",
      "The representation loss after processing this batch is:  0.0034249350428581238\n",
      "\n",
      "The classification loss after processing this batch is:  0.22978417575359344\n",
      "The representation loss after processing this batch is:  0.0029907673597335815\n",
      "\n",
      "The classification loss after processing this batch is:  0.1862807422876358\n",
      "The representation loss after processing this batch is:  0.0026201196014881134\n",
      "\n",
      "The classification loss after processing this batch is:  0.21999095380306244\n",
      "The representation loss after processing this batch is:  0.0028054527938365936\n",
      "\n",
      "The classification loss after processing this batch is:  0.2777327001094818\n",
      "The representation loss after processing this batch is:  0.002684619277715683\n",
      "\n",
      "The classification loss after processing this batch is:  0.15257610380649567\n",
      "The representation loss after processing this batch is:  0.0028338059782981873\n",
      "\n",
      "The classification loss after processing this batch is:  0.272330641746521\n",
      "The representation loss after processing this batch is:  0.0030032768845558167\n",
      "\n",
      "The classification loss after processing this batch is:  0.14700983464717865\n",
      "The representation loss after processing this batch is:  0.003035038709640503\n",
      "\n",
      "The classification loss after processing this batch is:  0.09225741028785706\n",
      "The representation loss after processing this batch is:  0.002797059714794159\n",
      "\n",
      "The classification loss after processing this batch is:  0.08221431821584702\n",
      "The representation loss after processing this batch is:  0.0027556493878364563\n",
      "\n",
      "The classification loss after processing this batch is:  0.10153152793645859\n",
      "The representation loss after processing this batch is:  0.0028509125113487244\n",
      "\n",
      "The classification loss after processing this batch is:  0.2996205985546112\n",
      "The representation loss after processing this batch is:  0.0030589625239372253\n",
      "\n",
      "The classification loss after processing this batch is:  0.10717353224754333\n",
      "The representation loss after processing this batch is:  0.002817966043949127\n",
      "\n",
      "The classification loss after processing this batch is:  0.1675945222377777\n",
      "The representation loss after processing this batch is:  0.003328844904899597\n",
      "\n",
      "The classification loss after processing this batch is:  0.1691444367170334\n",
      "The representation loss after processing this batch is:  0.0032754987478256226\n",
      "\n",
      "The classification loss after processing this batch is:  0.1710519641637802\n",
      "The representation loss after processing this batch is:  0.0029541626572608948\n",
      "\n",
      "The classification loss after processing this batch is:  0.11393090337514877\n",
      "The representation loss after processing this batch is:  0.002881377935409546\n",
      "\n",
      "The classification loss after processing this batch is:  0.19785593450069427\n",
      "The representation loss after processing this batch is:  0.002658449113368988\n",
      "\n",
      "The classification loss after processing this batch is:  0.21128331124782562\n",
      "The representation loss after processing this batch is:  0.0026973001658916473\n",
      "\n",
      "The classification loss after processing this batch is:  0.21692663431167603\n",
      "The representation loss after processing this batch is:  0.0032956749200820923\n",
      "\n",
      "The classification loss after processing this batch is:  0.10374736785888672\n",
      "The representation loss after processing this batch is:  0.0027870461344718933\n",
      "\n",
      "The classification loss after processing this batch is:  0.3112626373767853\n",
      "The representation loss after processing this batch is:  0.002343982458114624\n",
      "\n",
      "The classification loss after processing this batch is:  0.1323855221271515\n",
      "The representation loss after processing this batch is:  0.0026570409536361694\n",
      "\n",
      "The classification loss after processing this batch is:  0.13686661422252655\n",
      "The representation loss after processing this batch is:  0.00246429443359375\n",
      "\n",
      "The classification loss after processing this batch is:  0.14697284996509552\n",
      "The representation loss after processing this batch is:  0.0030753016471862793\n",
      "\n",
      "The classification loss after processing this batch is:  0.11449141055345535\n",
      "The representation loss after processing this batch is:  0.002790413796901703\n",
      "\n",
      "The classification loss after processing this batch is:  0.11378245055675507\n",
      "The representation loss after processing this batch is:  0.0027371197938919067\n",
      "\n",
      "The classification loss after processing this batch is:  0.1190192773938179\n",
      "The representation loss after processing this batch is:  0.0030380934476852417\n",
      "\n",
      "The classification loss after processing this batch is:  0.19645525515079498\n",
      "The representation loss after processing this batch is:  0.0029686912894248962\n",
      "\n",
      "The classification loss after processing this batch is:  0.2235773503780365\n",
      "The representation loss after processing this batch is:  0.002915605902671814\n",
      "\n",
      "The classification loss after processing this batch is:  0.20979076623916626\n",
      "The representation loss after processing this batch is:  0.002966277301311493\n",
      "\n",
      "The classification loss after processing this batch is:  0.15274371206760406\n",
      "The representation loss after processing this batch is:  0.0029226653277873993\n",
      "\n",
      "The classification loss after processing this batch is:  0.1634928435087204\n",
      "The representation loss after processing this batch is:  0.0035659894347190857\n",
      "\n",
      "The classification loss after processing this batch is:  0.2446540892124176\n",
      "The representation loss after processing this batch is:  0.002589806914329529\n",
      "\n",
      "The classification loss after processing this batch is:  0.17616994678974152\n",
      "The representation loss after processing this batch is:  0.00262334942817688\n",
      "\n",
      "The classification loss after processing this batch is:  0.044934287667274475\n",
      "The representation loss after processing this batch is:  0.0029453113675117493\n",
      "\n",
      "The classification loss after processing this batch is:  0.14698508381843567\n",
      "The representation loss after processing this batch is:  0.00257737934589386\n",
      "\n",
      "The classification loss after processing this batch is:  0.32947877049446106\n",
      "The representation loss after processing this batch is:  0.002864796668291092\n",
      "\n",
      "The classification loss after processing this batch is:  0.3665088713169098\n",
      "The representation loss after processing this batch is:  0.002976261079311371\n",
      "\n",
      "The classification loss after processing this batch is:  0.3162580132484436\n",
      "The representation loss after processing this batch is:  0.0026603825390338898\n",
      "\n",
      "The classification loss after processing this batch is:  0.21214771270751953\n",
      "The representation loss after processing this batch is:  0.0026658624410629272\n",
      "\n",
      "The classification loss after processing this batch is:  0.09947545826435089\n",
      "The representation loss after processing this batch is:  0.0027014650404453278\n",
      "\n",
      "The classification loss after processing this batch is:  0.14419886469841003\n",
      "The representation loss after processing this batch is:  0.0026717409491539\n",
      "\n",
      "The classification loss after processing this batch is:  0.14342001080513\n",
      "The representation loss after processing this batch is:  0.0030985474586486816\n",
      "\n",
      "The classification loss after processing this batch is:  0.22011658549308777\n",
      "The representation loss after processing this batch is:  0.00306662917137146\n",
      "\n",
      "The classification loss after processing this batch is:  0.18468904495239258\n",
      "The representation loss after processing this batch is:  0.00307522714138031\n",
      "\n",
      "The classification loss after processing this batch is:  0.18974685668945312\n",
      "The representation loss after processing this batch is:  0.00362609326839447\n",
      "\n",
      "The classification loss after processing this batch is:  0.1428002417087555\n",
      "The representation loss after processing this batch is:  0.002791106700897217\n",
      "\n",
      "The classification loss after processing this batch is:  0.14792071282863617\n",
      "The representation loss after processing this batch is:  0.0027276575565338135\n",
      "\n",
      "The classification loss after processing this batch is:  0.21131595969200134\n",
      "The representation loss after processing this batch is:  0.003247298300266266\n",
      "\n",
      "The classification loss after processing this batch is:  0.2024794965982437\n",
      "The representation loss after processing this batch is:  0.0027014166116714478\n",
      "\n",
      "The classification loss after processing this batch is:  0.14680485427379608\n",
      "The representation loss after processing this batch is:  0.0026061274111270905\n",
      "\n",
      "The classification loss after processing this batch is:  0.3148152530193329\n",
      "The representation loss after processing this batch is:  0.0033409446477890015\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.3512369692325592\n",
      "The representation loss after processing this batch is:  0.002942018210887909\n",
      "\n",
      "The classification loss after processing this batch is:  0.21570277214050293\n",
      "The representation loss after processing this batch is:  0.0030893534421920776\n",
      "\n",
      "The classification loss after processing this batch is:  0.18360449373722076\n",
      "The representation loss after processing this batch is:  0.0029335469007492065\n",
      "\n",
      "The classification loss after processing this batch is:  0.12837105989456177\n",
      "The representation loss after processing this batch is:  0.0035768821835517883\n",
      "\n",
      "The classification loss after processing this batch is:  0.06362713873386383\n",
      "The representation loss after processing this batch is:  0.0028999000787734985\n",
      "\n",
      "The classification loss after processing this batch is:  0.2508062422275543\n",
      "The representation loss after processing this batch is:  0.0027069374918937683\n",
      "\n",
      "The classification loss after processing this batch is:  0.19930441677570343\n",
      "The representation loss after processing this batch is:  0.003363199532032013\n",
      "\n",
      "The classification loss after processing this batch is:  0.14438946545124054\n",
      "The representation loss after processing this batch is:  0.0032647252082824707\n",
      "\n",
      "The classification loss after processing this batch is:  0.2700570225715637\n",
      "The representation loss after processing this batch is:  0.002679765224456787\n",
      "\n",
      "The classification loss after processing this batch is:  0.06826142221689224\n",
      "The representation loss after processing this batch is:  0.0027361512184143066\n",
      "\n",
      "The classification loss after processing this batch is:  0.09287616610527039\n",
      "The representation loss after processing this batch is:  0.003187716007232666\n",
      "\n",
      "The classification loss after processing this batch is:  0.13130523264408112\n",
      "The representation loss after processing this batch is:  0.002579204738140106\n",
      "\n",
      "The classification loss after processing this batch is:  0.19880150258541107\n",
      "The representation loss after processing this batch is:  0.0028156302869319916\n",
      "\n",
      "The classification loss after processing this batch is:  0.21778589487075806\n",
      "The representation loss after processing this batch is:  0.0029892325401306152\n",
      "\n",
      "The classification loss after processing this batch is:  0.12511740624904633\n",
      "The representation loss after processing this batch is:  0.0029211267828941345\n",
      "\n",
      "The classification loss after processing this batch is:  0.12452720105648041\n",
      "The representation loss after processing this batch is:  0.0028586536645889282\n",
      "\n",
      "The classification loss after processing this batch is:  0.07274015992879868\n",
      "The representation loss after processing this batch is:  0.0026793256402015686\n",
      "\n",
      "The classification loss after processing this batch is:  0.07650043815374374\n",
      "The representation loss after processing this batch is:  0.0027308836579322815\n",
      "\n",
      "The classification loss after processing this batch is:  0.1190272644162178\n",
      "The representation loss after processing this batch is:  0.002939850091934204\n",
      "\n",
      "The classification loss after processing this batch is:  0.077728770673275\n",
      "The representation loss after processing this batch is:  0.0030023008584976196\n",
      "\n",
      "The classification loss after processing this batch is:  0.13927620649337769\n",
      "The representation loss after processing this batch is:  0.002460010349750519\n",
      "\n",
      "The classification loss after processing this batch is:  0.18158796429634094\n",
      "The representation loss after processing this batch is:  0.0027710571885108948\n",
      "\n",
      "The classification loss after processing this batch is:  0.22049392759799957\n",
      "The representation loss after processing this batch is:  0.002919808030128479\n",
      "\n",
      "The classification loss after processing this batch is:  0.06584066152572632\n",
      "The representation loss after processing this batch is:  0.0022421441972255707\n",
      "\n",
      "The classification loss after processing this batch is:  0.08839168399572372\n",
      "The representation loss after processing this batch is:  0.0028312429785728455\n",
      "\n",
      "The classification loss after processing this batch is:  0.135670468211174\n",
      "The representation loss after processing this batch is:  0.003121785819530487\n",
      "\n",
      "The classification loss after processing this batch is:  0.18462421000003815\n",
      "The representation loss after processing this batch is:  0.0028217583894729614\n",
      "\n",
      "The classification loss after processing this batch is:  0.08595729619264603\n",
      "The representation loss after processing this batch is:  0.0032508373260498047\n",
      "\n",
      "The classification loss after processing this batch is:  0.2555634677410126\n",
      "The representation loss after processing this batch is:  0.0033080726861953735\n",
      "\n",
      "The classification loss after processing this batch is:  0.21512781083583832\n",
      "The representation loss after processing this batch is:  0.002968389540910721\n",
      "\n",
      "The classification loss after processing this batch is:  0.22791141271591187\n",
      "The representation loss after processing this batch is:  0.0028900951147079468\n",
      "\n",
      "The classification loss after processing this batch is:  0.13659292459487915\n",
      "The representation loss after processing this batch is:  0.0029640421271324158\n",
      "\n",
      "The classification loss after processing this batch is:  0.11721246689558029\n",
      "The representation loss after processing this batch is:  0.002739928662776947\n",
      "\n",
      "The classification loss after processing this batch is:  0.15437395870685577\n",
      "The representation loss after processing this batch is:  0.0029215440154075623\n",
      "\n",
      "The classification loss after processing this batch is:  0.20027144253253937\n",
      "The representation loss after processing this batch is:  0.0030439719557762146\n",
      "\n",
      "The classification loss after processing this batch is:  0.10927427560091019\n",
      "The representation loss after processing this batch is:  0.002824842929840088\n",
      "\n",
      "The classification loss after processing this batch is:  0.04964054748415947\n",
      "The representation loss after processing this batch is:  0.0025333017110824585\n",
      "\n",
      "The classification loss after processing this batch is:  0.24024072289466858\n",
      "The representation loss after processing this batch is:  0.003117769956588745\n",
      "\n",
      "The classification loss after processing this batch is:  0.2525361478328705\n",
      "The representation loss after processing this batch is:  0.002688072621822357\n",
      "\n",
      "The classification loss after processing this batch is:  0.15753622353076935\n",
      "The representation loss after processing this batch is:  0.0025750473141670227\n",
      "\n",
      "The classification loss after processing this batch is:  0.2790869474411011\n",
      "The representation loss after processing this batch is:  0.002627044916152954\n",
      "\n",
      "The classification loss after processing this batch is:  0.28946736454963684\n",
      "The representation loss after processing this batch is:  0.0030418038368225098\n",
      "\n",
      "The classification loss after processing this batch is:  0.3755183219909668\n",
      "The representation loss after processing this batch is:  0.002617187798023224\n",
      "\n",
      "The classification loss after processing this batch is:  0.19354969263076782\n",
      "The representation loss after processing this batch is:  0.002828143537044525\n",
      "\n",
      "The classification loss after processing this batch is:  0.12551453709602356\n",
      "The representation loss after processing this batch is:  0.0028514936566352844\n",
      "\n",
      "The classification loss after processing this batch is:  0.20476965606212616\n",
      "The representation loss after processing this batch is:  0.0031277239322662354\n",
      "\n",
      "The classification loss after processing this batch is:  0.13821610808372498\n",
      "The representation loss after processing this batch is:  0.0028510689735412598\n",
      "\n",
      "The classification loss after processing this batch is:  0.10579191893339157\n",
      "The representation loss after processing this batch is:  0.0029558688402175903\n",
      "\n",
      "The classification loss after processing this batch is:  0.11923527717590332\n",
      "The representation loss after processing this batch is:  0.0027608126401901245\n",
      "\n",
      "The classification loss after processing this batch is:  0.07964636385440826\n",
      "The representation loss after processing this batch is:  0.002624295651912689\n",
      "\n",
      "The classification loss after processing this batch is:  0.05519700050354004\n",
      "The representation loss after processing this batch is:  0.003324657678604126\n",
      "\n",
      "The classification loss after processing this batch is:  0.18205779790878296\n",
      "The representation loss after processing this batch is:  0.0028607770800590515\n",
      "\n",
      "The classification loss after processing this batch is:  0.2157129943370819\n",
      "The representation loss after processing this batch is:  0.0027289241552352905\n",
      "\n",
      "The classification loss after processing this batch is:  0.10063014924526215\n",
      "The representation loss after processing this batch is:  0.003083847463130951\n",
      "\n",
      "The classification loss after processing this batch is:  0.1318744570016861\n",
      "The representation loss after processing this batch is:  0.0026854872703552246\n",
      "\n",
      "The classification loss after processing this batch is:  0.15724386274814606\n",
      "The representation loss after processing this batch is:  0.002847328782081604\n",
      "\n",
      "The classification loss after processing this batch is:  0.058976467698812485\n",
      "The representation loss after processing this batch is:  0.0027900710701942444\n",
      "\n",
      "The classification loss after processing this batch is:  0.2728593945503235\n",
      "The representation loss after processing this batch is:  0.002806447446346283\n",
      "\n",
      "The classification loss after processing this batch is:  0.13622881472110748\n",
      "The representation loss after processing this batch is:  0.002586156129837036\n",
      "\n",
      "The classification loss after processing this batch is:  0.28665924072265625\n",
      "The representation loss after processing this batch is:  0.0027896687388420105\n",
      "\n",
      "The classification loss after processing this batch is:  0.17208942770957947\n",
      "The representation loss after processing this batch is:  0.002979271113872528\n",
      "\n",
      "The classification loss after processing this batch is:  0.214595228433609\n",
      "The representation loss after processing this batch is:  0.0027569644153118134\n",
      "\n",
      "The classification loss after processing this batch is:  0.061822596937417984\n",
      "The representation loss after processing this batch is:  0.0029510706663131714\n",
      "\n",
      "The classification loss after processing this batch is:  0.07501482218503952\n",
      "The representation loss after processing this batch is:  0.0027089640498161316\n",
      "\n",
      "The classification loss after processing this batch is:  0.18344774842262268\n",
      "The representation loss after processing this batch is:  0.0027356408536434174\n",
      "\n",
      "The classification loss after processing this batch is:  0.08062585443258286\n",
      "The representation loss after processing this batch is:  0.0032003596425056458\n",
      "\n",
      "The classification loss after processing this batch is:  0.20615622401237488\n",
      "The representation loss after processing this batch is:  0.0030121803283691406\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.12127920985221863\n",
      "The representation loss after processing this batch is:  0.002995632588863373\n",
      "\n",
      "The classification loss after processing this batch is:  0.14068110287189484\n",
      "The representation loss after processing this batch is:  0.0032581984996795654\n",
      "\n",
      "The classification loss after processing this batch is:  0.18822231888771057\n",
      "The representation loss after processing this batch is:  0.002697199583053589\n",
      "\n",
      "The classification loss after processing this batch is:  0.11195716261863708\n",
      "The representation loss after processing this batch is:  0.003145165741443634\n",
      "\n",
      "The classification loss after processing this batch is:  0.13773204386234283\n",
      "The representation loss after processing this batch is:  0.003115743398666382\n",
      "\n",
      "The classification loss after processing this batch is:  0.24486348032951355\n",
      "The representation loss after processing this batch is:  0.0029786452651023865\n",
      "\n",
      "The classification loss after processing this batch is:  0.1651897430419922\n",
      "The representation loss after processing this batch is:  0.003046669065952301\n",
      "\n",
      "The classification loss after processing this batch is:  0.24846993386745453\n",
      "The representation loss after processing this batch is:  0.0028521940112113953\n",
      "\n",
      "The classification loss after processing this batch is:  0.24128369987010956\n",
      "The representation loss after processing this batch is:  0.002883009612560272\n",
      "\n",
      "The classification loss after processing this batch is:  0.19194450974464417\n",
      "The representation loss after processing this batch is:  0.0026388019323349\n",
      "\n",
      "The classification loss after processing this batch is:  0.12755367159843445\n",
      "The representation loss after processing this batch is:  0.0029504746198654175\n",
      "\n",
      "The classification loss after processing this batch is:  0.09463651478290558\n",
      "The representation loss after processing this batch is:  0.002712756395339966\n",
      "\n",
      "The classification loss after processing this batch is:  0.10252115875482559\n",
      "The representation loss after processing this batch is:  0.0028092116117477417\n",
      "\n",
      "The classification loss after processing this batch is:  0.08715645223855972\n",
      "The representation loss after processing this batch is:  0.003299117088317871\n",
      "\n",
      "The classification loss after processing this batch is:  0.14946381747722626\n",
      "The representation loss after processing this batch is:  0.002351224422454834\n",
      "\n",
      "The classification loss after processing this batch is:  0.14300374686717987\n",
      "The representation loss after processing this batch is:  0.002869337797164917\n",
      "\n",
      "The classification loss after processing this batch is:  0.151649609208107\n",
      "The representation loss after processing this batch is:  0.003243684768676758\n",
      "\n",
      "The classification loss after processing this batch is:  0.11262893676757812\n",
      "The representation loss after processing this batch is:  0.0028113648295402527\n",
      "\n",
      "The classification loss after processing this batch is:  0.19077090919017792\n",
      "The representation loss after processing this batch is:  0.002526693046092987\n",
      "\n",
      "The classification loss after processing this batch is:  0.11883910745382309\n",
      "The representation loss after processing this batch is:  0.002690531313419342\n",
      "\n",
      "The classification loss after processing this batch is:  0.1837848275899887\n",
      "The representation loss after processing this batch is:  0.0028133168816566467\n",
      "\n",
      "The classification loss after processing this batch is:  0.18892648816108704\n",
      "The representation loss after processing this batch is:  0.0027834922075271606\n",
      "\n",
      "The classification loss after processing this batch is:  0.15270744264125824\n",
      "The representation loss after processing this batch is:  0.0029840096831321716\n",
      "\n",
      "The classification loss after processing this batch is:  0.1139085665345192\n",
      "The representation loss after processing this batch is:  0.0031386390328407288\n",
      "\n",
      "The classification loss after processing this batch is:  0.22044043242931366\n",
      "The representation loss after processing this batch is:  0.0032159462571144104\n",
      "\n",
      "The classification loss after processing this batch is:  0.08571473509073257\n",
      "The representation loss after processing this batch is:  0.002734571695327759\n",
      "\n",
      "The classification loss after processing this batch is:  0.10255888849496841\n",
      "The representation loss after processing this batch is:  0.002692773938179016\n",
      "\n",
      "The classification loss after processing this batch is:  0.14793545007705688\n",
      "The representation loss after processing this batch is:  0.0027938932180404663\n",
      "\n",
      "The classification loss after processing this batch is:  0.09878065437078476\n",
      "The representation loss after processing this batch is:  0.0032149702310562134\n",
      "\n",
      "The classification loss after processing this batch is:  0.17215080559253693\n",
      "The representation loss after processing this batch is:  0.0024495162069797516\n",
      "\n",
      "The classification loss after processing this batch is:  0.22722932696342468\n",
      "The representation loss after processing this batch is:  0.0028348416090011597\n",
      "\n",
      "The classification loss after processing this batch is:  0.1383899301290512\n",
      "The representation loss after processing this batch is:  0.0031591057777404785\n",
      "\n",
      "The classification loss after processing this batch is:  0.11914733052253723\n",
      "The representation loss after processing this batch is:  0.0034335628151893616\n",
      "\n",
      "The classification loss after processing this batch is:  0.10593175143003464\n",
      "The representation loss after processing this batch is:  0.002682827413082123\n",
      "\n",
      "The classification loss after processing this batch is:  0.29365211725234985\n",
      "The representation loss after processing this batch is:  0.0030516982078552246\n",
      "\n",
      "The classification loss after processing this batch is:  0.068691186606884\n",
      "The representation loss after processing this batch is:  0.0029254108667373657\n",
      "\n",
      "The classification loss after processing this batch is:  0.14374645054340363\n",
      "The representation loss after processing this batch is:  0.002891130745410919\n",
      "\n",
      "The classification loss after processing this batch is:  0.20583756268024445\n",
      "The representation loss after processing this batch is:  0.0026733726263046265\n",
      "\n",
      "The classification loss after processing this batch is:  0.35630160570144653\n",
      "The representation loss after processing this batch is:  0.0028825998306274414\n",
      "\n",
      "The classification loss after processing this batch is:  0.12232692539691925\n",
      "The representation loss after processing this batch is:  0.0028406530618667603\n",
      "\n",
      "The classification loss after processing this batch is:  0.1658574938774109\n",
      "The representation loss after processing this batch is:  0.002780802547931671\n",
      "\n",
      "The classification loss after processing this batch is:  0.1034906730055809\n",
      "The representation loss after processing this batch is:  0.002884902060031891\n",
      "\n",
      "The classification loss after processing this batch is:  0.05379965156316757\n",
      "The representation loss after processing this batch is:  0.002943947911262512\n",
      "\n",
      "The classification loss after processing this batch is:  0.16723284125328064\n",
      "The representation loss after processing this batch is:  0.0033450573682785034\n",
      "\n",
      "The classification loss after processing this batch is:  0.11517561227083206\n",
      "The representation loss after processing this batch is:  0.003632575273513794\n",
      "\n",
      "The classification loss after processing this batch is:  0.08047914505004883\n",
      "The representation loss after processing this batch is:  0.003145851194858551\n",
      "\n",
      "The classification loss after processing this batch is:  0.09311249107122421\n",
      "The representation loss after processing this batch is:  0.0025659948587417603\n",
      "\n",
      "The classification loss after processing this batch is:  0.18963392078876495\n",
      "The representation loss after processing this batch is:  0.0025908276438713074\n",
      "\n",
      "The classification loss after processing this batch is:  0.17647455632686615\n",
      "The representation loss after processing this batch is:  0.0027644336223602295\n",
      "\n",
      "The classification loss after processing this batch is:  0.10244395583868027\n",
      "The representation loss after processing this batch is:  0.002503536641597748\n",
      "\n",
      "The classification loss after processing this batch is:  0.15498247742652893\n",
      "The representation loss after processing this batch is:  0.002814166247844696\n",
      "\n",
      "The classification loss after processing this batch is:  0.20891138911247253\n",
      "The representation loss after processing this batch is:  0.0025011152029037476\n",
      "\n",
      "The classification loss after processing this batch is:  0.2092752456665039\n",
      "The representation loss after processing this batch is:  0.002819664776325226\n",
      "\n",
      "The classification loss after processing this batch is:  0.20884431898593903\n",
      "The representation loss after processing this batch is:  0.0026163682341575623\n",
      "\n",
      "The classification loss after processing this batch is:  0.1870880126953125\n",
      "The representation loss after processing this batch is:  0.0030272528529167175\n",
      "\n",
      "The classification loss after processing this batch is:  0.29074302315711975\n",
      "The representation loss after processing this batch is:  0.0030890144407749176\n",
      "\n",
      "The classification loss after processing this batch is:  0.12478099018335342\n",
      "The representation loss after processing this batch is:  0.0028744637966156006\n",
      "\n",
      "The classification loss after processing this batch is:  0.10525984317064285\n",
      "The representation loss after processing this batch is:  0.0032399892807006836\n",
      "\n",
      "The classification loss after processing this batch is:  0.07285691797733307\n",
      "The representation loss after processing this batch is:  0.0026617422699928284\n",
      "\n",
      "The classification loss after processing this batch is:  0.10422693192958832\n",
      "The representation loss after processing this batch is:  0.0027081742882728577\n",
      "\n",
      "The classification loss after processing this batch is:  0.2437119483947754\n",
      "The representation loss after processing this batch is:  0.002848796546459198\n",
      "\n",
      "The classification loss after processing this batch is:  0.16343379020690918\n",
      "The representation loss after processing this batch is:  0.0032430216670036316\n",
      "\n",
      "The classification loss after processing this batch is:  0.07859588414430618\n",
      "The representation loss after processing this batch is:  0.002619914710521698\n",
      "\n",
      "The classification loss after processing this batch is:  0.05803794786334038\n",
      "The representation loss after processing this batch is:  0.0032531023025512695\n",
      "\n",
      "The classification loss after processing this batch is:  0.06861843168735504\n",
      "The representation loss after processing this batch is:  0.003312140703201294\n",
      "\n",
      "The classification loss after processing this batch is:  0.10673826187849045\n",
      "The representation loss after processing this batch is:  0.003795325756072998\n",
      "\n",
      "The classification loss after processing this batch is:  0.12883952260017395\n",
      "The representation loss after processing this batch is:  0.0033103302121162415\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08139777183532715\n",
      "The representation loss after processing this batch is:  0.003071241080760956\n",
      "\n",
      "The classification loss after processing this batch is:  0.05489024147391319\n",
      "The representation loss after processing this batch is:  0.0031970739364624023\n",
      "\n",
      "The classification loss after processing this batch is:  0.08971217274665833\n",
      "The representation loss after processing this batch is:  0.003418572247028351\n",
      "\n",
      "The classification loss after processing this batch is:  0.10771739482879639\n",
      "The representation loss after processing this batch is:  0.003768928349018097\n",
      "\n",
      "The classification loss after processing this batch is:  0.04392990097403526\n",
      "The representation loss after processing this batch is:  0.003980852663516998\n",
      "\n",
      "The classification loss after processing this batch is:  0.06934328377246857\n",
      "The representation loss after processing this batch is:  0.0032124891877174377\n",
      "\n",
      "The classification loss after processing this batch is:  0.19855038821697235\n",
      "The representation loss after processing this batch is:  0.003134317696094513\n",
      "\n",
      "The classification loss after processing this batch is:  0.05881505832076073\n",
      "The representation loss after processing this batch is:  0.003467075526714325\n",
      "\n",
      "The classification loss after processing this batch is:  0.03154309466481209\n",
      "The representation loss after processing this batch is:  0.0031934306025505066\n",
      "\n",
      "The classification loss after processing this batch is:  0.059843357652425766\n",
      "The representation loss after processing this batch is:  0.003245837986469269\n",
      "\n",
      "The classification loss after processing this batch is:  0.05779902637004852\n",
      "The representation loss after processing this batch is:  0.003619566559791565\n",
      "\n",
      "The classification loss after processing this batch is:  0.0513886995613575\n",
      "The representation loss after processing this batch is:  0.003106512129306793\n",
      "\n",
      "The classification loss after processing this batch is:  0.04352732375264168\n",
      "The representation loss after processing this batch is:  0.0036525577306747437\n",
      "\n",
      "The classification loss after processing this batch is:  0.03495899960398674\n",
      "The representation loss after processing this batch is:  0.0037101581692695618\n",
      "\n",
      "The classification loss after processing this batch is:  0.31182703375816345\n",
      "The representation loss after processing this batch is:  0.0037450119853019714\n",
      "\n",
      "The classification loss after processing this batch is:  0.3018498420715332\n",
      "The representation loss after processing this batch is:  0.0037143677473068237\n",
      "\n",
      "The classification loss after processing this batch is:  0.25448909401893616\n",
      "The representation loss after processing this batch is:  0.0037110745906829834\n",
      "\n",
      "The classification loss after processing this batch is:  0.05643384903669357\n",
      "The representation loss after processing this batch is:  0.002792924642562866\n",
      "\n",
      "The classification loss after processing this batch is:  0.03899795189499855\n",
      "The representation loss after processing this batch is:  0.0037634819746017456\n",
      "\n",
      "The classification loss after processing this batch is:  0.034903548657894135\n",
      "The representation loss after processing this batch is:  0.002514094114303589\n",
      "\n",
      "The classification loss after processing this batch is:  0.1365559846162796\n",
      "The representation loss after processing this batch is:  0.0026275068521499634\n",
      "\n",
      "The classification loss after processing this batch is:  0.3200090527534485\n",
      "The representation loss after processing this batch is:  0.0030942484736442566\n",
      "\n",
      "The classification loss after processing this batch is:  0.1162290945649147\n",
      "The representation loss after processing this batch is:  0.002814769744873047\n",
      "\n",
      "The classification loss after processing this batch is:  0.08654581755399704\n",
      "The representation loss after processing this batch is:  0.003271743655204773\n",
      "\n",
      "The classification loss after processing this batch is:  0.08518772572278976\n",
      "The representation loss after processing this batch is:  0.003316834568977356\n",
      "\n",
      "The classification loss after processing this batch is:  0.0751626119017601\n",
      "The representation loss after processing this batch is:  0.003939397633075714\n",
      "\n",
      "The classification loss after processing this batch is:  0.14573881030082703\n",
      "The representation loss after processing this batch is:  0.0027017518877983093\n",
      "\n",
      "The classification loss after processing this batch is:  0.06558356434106827\n",
      "The representation loss after processing this batch is:  0.0027975961565971375\n",
      "\n",
      "The classification loss after processing this batch is:  0.12512223422527313\n",
      "The representation loss after processing this batch is:  0.002895619720220566\n",
      "\n",
      "The classification loss after processing this batch is:  0.10106398910284042\n",
      "The representation loss after processing this batch is:  0.0029218383133411407\n",
      "\n",
      "The classification loss after processing this batch is:  0.2033044695854187\n",
      "The representation loss after processing this batch is:  0.0028713569045066833\n",
      "\n",
      "The classification loss after processing this batch is:  0.09747395664453506\n",
      "The representation loss after processing this batch is:  0.0031741708517074585\n",
      "\n",
      "The classification loss after processing this batch is:  0.11182845383882523\n",
      "The representation loss after processing this batch is:  0.003290124237537384\n",
      "\n",
      "The classification loss after processing this batch is:  0.16148491203784943\n",
      "The representation loss after processing this batch is:  0.002698764204978943\n",
      "\n",
      "The classification loss after processing this batch is:  0.17232519388198853\n",
      "The representation loss after processing this batch is:  0.0026100650429725647\n",
      "\n",
      "The classification loss after processing this batch is:  0.12351473420858383\n",
      "The representation loss after processing this batch is:  0.002819962799549103\n",
      "\n",
      "The classification loss after processing this batch is:  0.19876666367053986\n",
      "The representation loss after processing this batch is:  0.0027845799922943115\n",
      "\n",
      "The classification loss after processing this batch is:  0.15027494728565216\n",
      "The representation loss after processing this batch is:  0.0028050243854522705\n",
      "\n",
      "The classification loss after processing this batch is:  0.17406108975410461\n",
      "The representation loss after processing this batch is:  0.0033222585916519165\n",
      "\n",
      "The classification loss after processing this batch is:  0.09994373470544815\n",
      "The representation loss after processing this batch is:  0.002856999635696411\n",
      "\n",
      "The classification loss after processing this batch is:  0.2944388687610626\n",
      "The representation loss after processing this batch is:  0.00268593430519104\n",
      "\n",
      "The classification loss after processing this batch is:  0.13132990896701813\n",
      "The representation loss after processing this batch is:  0.002564951777458191\n",
      "\n",
      "The classification loss after processing this batch is:  0.13483601808547974\n",
      "The representation loss after processing this batch is:  0.002789843827486038\n",
      "\n",
      "The classification loss after processing this batch is:  0.24495629966259003\n",
      "The representation loss after processing this batch is:  0.0029654130339622498\n",
      "\n",
      "The classification loss after processing this batch is:  0.19397395849227905\n",
      "The representation loss after processing this batch is:  0.0029456689953804016\n",
      "\n",
      "The classification loss after processing this batch is:  0.09705860167741776\n",
      "The representation loss after processing this batch is:  0.0030049942433834076\n",
      "\n",
      "The classification loss after processing this batch is:  0.28939518332481384\n",
      "The representation loss after processing this batch is:  0.0038050636649131775\n",
      "\n",
      "The classification loss after processing this batch is:  0.16958604753017426\n",
      "The representation loss after processing this batch is:  0.0030079297721385956\n",
      "\n",
      "The classification loss after processing this batch is:  0.3285106420516968\n",
      "The representation loss after processing this batch is:  0.002813488245010376\n",
      "\n",
      "The classification loss after processing this batch is:  0.11846508085727692\n",
      "The representation loss after processing this batch is:  0.0025305673480033875\n",
      "\n",
      "The classification loss after processing this batch is:  0.10032080858945847\n",
      "The representation loss after processing this batch is:  0.002734266221523285\n",
      "\n",
      "The classification loss after processing this batch is:  0.10844495892524719\n",
      "The representation loss after processing this batch is:  0.0026342645287513733\n",
      "\n",
      "The classification loss after processing this batch is:  0.17375174164772034\n",
      "The representation loss after processing this batch is:  0.002647608518600464\n",
      "\n",
      "The classification loss after processing this batch is:  0.13058309257030487\n",
      "The representation loss after processing this batch is:  0.0028477609157562256\n",
      "\n",
      "The classification loss after processing this batch is:  0.074815534055233\n",
      "The representation loss after processing this batch is:  0.0028216466307640076\n",
      "\n",
      "The classification loss after processing this batch is:  0.047038089483976364\n",
      "The representation loss after processing this batch is:  0.0027291476726531982\n",
      "\n",
      "The classification loss after processing this batch is:  0.07773931324481964\n",
      "The representation loss after processing this batch is:  0.0025681741535663605\n",
      "\n",
      "The classification loss after processing this batch is:  0.11091966927051544\n",
      "The representation loss after processing this batch is:  0.0027807429432868958\n",
      "\n",
      "The classification loss after processing this batch is:  0.17807792127132416\n",
      "The representation loss after processing this batch is:  0.003046579658985138\n",
      "\n",
      "The classification loss after processing this batch is:  0.12618407607078552\n",
      "The representation loss after processing this batch is:  0.003032602369785309\n",
      "\n",
      "The classification loss after processing this batch is:  0.12487413734197617\n",
      "The representation loss after processing this batch is:  0.0027032531797885895\n",
      "\n",
      "The classification loss after processing this batch is:  0.06778775900602341\n",
      "The representation loss after processing this batch is:  0.002754978835582733\n",
      "\n",
      "The classification loss after processing this batch is:  0.1010299101471901\n",
      "The representation loss after processing this batch is:  0.0028835535049438477\n",
      "\n",
      "The classification loss after processing this batch is:  0.1098097488284111\n",
      "The representation loss after processing this batch is:  0.0027343183755874634\n",
      "\n",
      "The classification loss after processing this batch is:  0.06339284032583237\n",
      "The representation loss after processing this batch is:  0.0027613043785095215\n",
      "\n",
      "The classification loss after processing this batch is:  0.12894360721111298\n",
      "The representation loss after processing this batch is:  0.002889476716518402\n",
      "\n",
      "The classification loss after processing this batch is:  0.2325136661529541\n",
      "The representation loss after processing this batch is:  0.003152593970298767\n",
      "\n",
      "The classification loss after processing this batch is:  0.14446887373924255\n",
      "The representation loss after processing this batch is:  0.0030151978135108948\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1516004502773285\n",
      "The representation loss after processing this batch is:  0.0025240927934646606\n",
      "\n",
      "The classification loss after processing this batch is:  0.1638144552707672\n",
      "The representation loss after processing this batch is:  0.002729669213294983\n",
      "\n",
      "The classification loss after processing this batch is:  0.10948168486356735\n",
      "The representation loss after processing this batch is:  0.00259200856089592\n",
      "\n",
      "The classification loss after processing this batch is:  0.11654064804315567\n",
      "The representation loss after processing this batch is:  0.0025558583438396454\n",
      "\n",
      "The classification loss after processing this batch is:  0.24016380310058594\n",
      "The representation loss after processing this batch is:  0.0033125951886177063\n",
      "\n",
      "The classification loss after processing this batch is:  0.08645831048488617\n",
      "The representation loss after processing this batch is:  0.002796359360218048\n",
      "\n",
      "The classification loss after processing this batch is:  0.16687066853046417\n",
      "The representation loss after processing this batch is:  0.002676844596862793\n",
      "\n",
      "The classification loss after processing this batch is:  0.11991668492555618\n",
      "The representation loss after processing this batch is:  0.0028316043317317963\n",
      "\n",
      "The classification loss after processing this batch is:  0.14633069932460785\n",
      "The representation loss after processing this batch is:  0.0026684291660785675\n",
      "\n",
      "The classification loss after processing this batch is:  0.17107293009757996\n",
      "The representation loss after processing this batch is:  0.003003876656293869\n",
      "\n",
      "The classification loss after processing this batch is:  0.08949575573205948\n",
      "The representation loss after processing this batch is:  0.002831745892763138\n",
      "\n",
      "The classification loss after processing this batch is:  0.11571869254112244\n",
      "The representation loss after processing this batch is:  0.0030945539474487305\n",
      "\n",
      "The classification loss after processing this batch is:  0.13930436968803406\n",
      "The representation loss after processing this batch is:  0.0032144933938980103\n",
      "\n",
      "The classification loss after processing this batch is:  0.1655253767967224\n",
      "The representation loss after processing this batch is:  0.0027859732508659363\n",
      "\n",
      "The classification loss after processing this batch is:  0.15475249290466309\n",
      "The representation loss after processing this batch is:  0.0024087056517601013\n",
      "\n",
      "The classification loss after processing this batch is:  0.11886058747768402\n",
      "The representation loss after processing this batch is:  0.003162577748298645\n",
      "\n",
      "The classification loss after processing this batch is:  0.19486449658870697\n",
      "The representation loss after processing this batch is:  0.002960205078125\n",
      "\n",
      "The classification loss after processing this batch is:  0.08261088281869888\n",
      "The representation loss after processing this batch is:  0.0025894641876220703\n",
      "\n",
      "The classification loss after processing this batch is:  0.07930055260658264\n",
      "The representation loss after processing this batch is:  0.0025776512920856476\n",
      "\n",
      "The classification loss after processing this batch is:  0.17459501326084137\n",
      "The representation loss after processing this batch is:  0.0027069970965385437\n",
      "\n",
      "The classification loss after processing this batch is:  0.19603951275348663\n",
      "The representation loss after processing this batch is:  0.002544395625591278\n",
      "\n",
      "The classification loss after processing this batch is:  0.09525243192911148\n",
      "The representation loss after processing this batch is:  0.002688288688659668\n",
      "\n",
      "The classification loss after processing this batch is:  0.11393426358699799\n",
      "The representation loss after processing this batch is:  0.0025646984577178955\n",
      "\n",
      "The classification loss after processing this batch is:  0.07982538640499115\n",
      "The representation loss after processing this batch is:  0.002668611705303192\n",
      "\n",
      "The classification loss after processing this batch is:  0.14306434988975525\n",
      "The representation loss after processing this batch is:  0.0029506757855415344\n",
      "\n",
      "The classification loss after processing this batch is:  0.1556449830532074\n",
      "The representation loss after processing this batch is:  0.0024962611496448517\n",
      "\n",
      "The classification loss after processing this batch is:  0.08216597139835358\n",
      "The representation loss after processing this batch is:  0.002958148717880249\n",
      "\n",
      "The classification loss after processing this batch is:  0.21158376336097717\n",
      "The representation loss after processing this batch is:  0.0025937817990779877\n",
      "\n",
      "The classification loss after processing this batch is:  0.1500987857580185\n",
      "The representation loss after processing this batch is:  0.0026127323508262634\n",
      "\n",
      "The classification loss after processing this batch is:  0.15265817940235138\n",
      "The representation loss after processing this batch is:  0.0028246864676475525\n",
      "\n",
      "The classification loss after processing this batch is:  0.10639216750860214\n",
      "The representation loss after processing this batch is:  0.0024582073092460632\n",
      "\n",
      "The classification loss after processing this batch is:  0.09565284103155136\n",
      "The representation loss after processing this batch is:  0.002867750823497772\n",
      "\n",
      "The classification loss after processing this batch is:  0.15597301721572876\n",
      "The representation loss after processing this batch is:  0.002622012048959732\n",
      "\n",
      "The classification loss after processing this batch is:  0.19686470925807953\n",
      "The representation loss after processing this batch is:  0.0024550259113311768\n",
      "\n",
      "The classification loss after processing this batch is:  0.11243513226509094\n",
      "The representation loss after processing this batch is:  0.002635277807712555\n",
      "\n",
      "The classification loss after processing this batch is:  0.3075707256793976\n",
      "The representation loss after processing this batch is:  0.0026650652289390564\n",
      "\n",
      "The classification loss after processing this batch is:  0.14388206601142883\n",
      "The representation loss after processing this batch is:  0.0026034973561763763\n",
      "\n",
      "The classification loss after processing this batch is:  0.08255727589130402\n",
      "The representation loss after processing this batch is:  0.0032617375254631042\n",
      "\n",
      "The classification loss after processing this batch is:  0.14441119134426117\n",
      "The representation loss after processing this batch is:  0.002544999122619629\n",
      "\n",
      "The classification loss after processing this batch is:  0.09318706393241882\n",
      "The representation loss after processing this batch is:  0.0029373615980148315\n",
      "\n",
      "The classification loss after processing this batch is:  0.2978270947933197\n",
      "The representation loss after processing this batch is:  0.002994723618030548\n",
      "\n",
      "The classification loss after processing this batch is:  0.1521115005016327\n",
      "The representation loss after processing this batch is:  0.0026924535632133484\n",
      "\n",
      "The classification loss after processing this batch is:  0.1475818008184433\n",
      "The representation loss after processing this batch is:  0.002443656325340271\n",
      "\n",
      "The classification loss after processing this batch is:  0.34439602494239807\n",
      "The representation loss after processing this batch is:  0.002461470663547516\n",
      "\n",
      "The classification loss after processing this batch is:  0.16398382186889648\n",
      "The representation loss after processing this batch is:  0.0028891637921333313\n",
      "\n",
      "The classification loss after processing this batch is:  0.09174537658691406\n",
      "The representation loss after processing this batch is:  0.0027918070554733276\n",
      "\n",
      "The classification loss after processing this batch is:  0.16190600395202637\n",
      "The representation loss after processing this batch is:  0.002489086240530014\n",
      "\n",
      "The classification loss after processing this batch is:  0.1570514738559723\n",
      "The representation loss after processing this batch is:  0.0028347447514533997\n",
      "\n",
      "The classification loss after processing this batch is:  0.1733957976102829\n",
      "The representation loss after processing this batch is:  0.0030744075775146484\n",
      "\n",
      "The classification loss after processing this batch is:  0.08015481382608414\n",
      "The representation loss after processing this batch is:  0.00266149640083313\n",
      "\n",
      "The classification loss after processing this batch is:  0.13832098245620728\n",
      "The representation loss after processing this batch is:  0.0027724355459213257\n",
      "\n",
      "The classification loss after processing this batch is:  0.18671353161334991\n",
      "The representation loss after processing this batch is:  0.002719566226005554\n",
      "\n",
      "The classification loss after processing this batch is:  0.1727553755044937\n",
      "The representation loss after processing this batch is:  0.0029638484120368958\n",
      "\n",
      "The classification loss after processing this batch is:  0.20775248110294342\n",
      "The representation loss after processing this batch is:  0.0026426762342453003\n",
      "\n",
      "The classification loss after processing this batch is:  0.24910856783390045\n",
      "The representation loss after processing this batch is:  0.0032993555068969727\n",
      "\n",
      "The classification loss after processing this batch is:  0.1971338838338852\n",
      "The representation loss after processing this batch is:  0.0030988603830337524\n",
      "\n",
      "The classification loss after processing this batch is:  0.09750260412693024\n",
      "The representation loss after processing this batch is:  0.0031286701560020447\n",
      "\n",
      "The classification loss after processing this batch is:  0.113304004073143\n",
      "The representation loss after processing this batch is:  0.002741388976573944\n",
      "\n",
      "The classification loss after processing this batch is:  0.0700455904006958\n",
      "The representation loss after processing this batch is:  0.002675820142030716\n",
      "\n",
      "The classification loss after processing this batch is:  0.14476095139980316\n",
      "The representation loss after processing this batch is:  0.002673529088497162\n",
      "\n",
      "The classification loss after processing this batch is:  0.17123514413833618\n",
      "The representation loss after processing this batch is:  0.0027083903551101685\n",
      "\n",
      "The classification loss after processing this batch is:  0.25746169686317444\n",
      "The representation loss after processing this batch is:  0.0029495209455490112\n",
      "\n",
      "The classification loss after processing this batch is:  0.28787267208099365\n",
      "The representation loss after processing this batch is:  0.0030256733298301697\n",
      "\n",
      "The classification loss after processing this batch is:  0.11102123558521271\n",
      "The representation loss after processing this batch is:  0.002888806164264679\n",
      "\n",
      "The classification loss after processing this batch is:  0.13648316264152527\n",
      "The representation loss after processing this batch is:  0.0029283687472343445\n",
      "\n",
      "The classification loss after processing this batch is:  0.1919599175453186\n",
      "The representation loss after processing this batch is:  0.0026626475155353546\n",
      "\n",
      "The classification loss after processing this batch is:  0.0763218030333519\n",
      "The representation loss after processing this batch is:  0.003021717071533203\n",
      "\n",
      "The classification loss after processing this batch is:  0.08432456851005554\n",
      "The representation loss after processing this batch is:  0.0029305294156074524\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.16554775834083557\n",
      "The representation loss after processing this batch is:  0.002603389322757721\n",
      "\n",
      "The classification loss after processing this batch is:  0.1394905298948288\n",
      "The representation loss after processing this batch is:  0.0035687237977981567\n",
      "\n",
      "The classification loss after processing this batch is:  0.10222610831260681\n",
      "The representation loss after processing this batch is:  0.0028082728385925293\n",
      "\n",
      "The classification loss after processing this batch is:  0.27470919489860535\n",
      "The representation loss after processing this batch is:  0.003985852003097534\n",
      "\n",
      "The classification loss after processing this batch is:  0.3018718361854553\n",
      "The representation loss after processing this batch is:  0.0026165060698986053\n",
      "\n",
      "The classification loss after processing this batch is:  0.1814262419939041\n",
      "The representation loss after processing this batch is:  0.0029197633266448975\n",
      "\n",
      "The classification loss after processing this batch is:  0.2704390287399292\n",
      "The representation loss after processing this batch is:  0.002685166895389557\n",
      "\n",
      "The classification loss after processing this batch is:  0.17207567393779755\n",
      "The representation loss after processing this batch is:  0.0028111524879932404\n",
      "\n",
      "The classification loss after processing this batch is:  0.06608398258686066\n",
      "The representation loss after processing this batch is:  0.002897486090660095\n",
      "\n",
      "The classification loss after processing this batch is:  0.17879930138587952\n",
      "The representation loss after processing this batch is:  0.002617359161376953\n",
      "\n",
      "The classification loss after processing this batch is:  0.40902242064476013\n",
      "The representation loss after processing this batch is:  0.003610163927078247\n",
      "\n",
      "The classification loss after processing this batch is:  0.2242346704006195\n",
      "The representation loss after processing this batch is:  0.0032760612666606903\n",
      "\n",
      "The classification loss after processing this batch is:  0.1037338599562645\n",
      "The representation loss after processing this batch is:  0.0029217973351478577\n",
      "\n",
      "The classification loss after processing this batch is:  0.10808269679546356\n",
      "The representation loss after processing this batch is:  0.002894200384616852\n",
      "\n",
      "The classification loss after processing this batch is:  0.09103023260831833\n",
      "The representation loss after processing this batch is:  0.003009296953678131\n",
      "\n",
      "The classification loss after processing this batch is:  0.11484677344560623\n",
      "The representation loss after processing this batch is:  0.00325736403465271\n",
      "\n",
      "The classification loss after processing this batch is:  0.11628443747758865\n",
      "The representation loss after processing this batch is:  0.0030724182724952698\n",
      "\n",
      "The classification loss after processing this batch is:  0.17805150151252747\n",
      "The representation loss after processing this batch is:  0.0028663426637649536\n",
      "\n",
      "The classification loss after processing this batch is:  0.14742662012577057\n",
      "The representation loss after processing this batch is:  0.00267985463142395\n",
      "\n",
      "The classification loss after processing this batch is:  0.2533097565174103\n",
      "The representation loss after processing this batch is:  0.003134720027446747\n",
      "\n",
      "The classification loss after processing this batch is:  0.12586627900600433\n",
      "The representation loss after processing this batch is:  0.002503741532564163\n",
      "\n",
      "The classification loss after processing this batch is:  0.16061560809612274\n",
      "The representation loss after processing this batch is:  0.0025031715631484985\n",
      "\n",
      "The classification loss after processing this batch is:  0.19282597303390503\n",
      "The representation loss after processing this batch is:  0.0026857852935791016\n",
      "\n",
      "The classification loss after processing this batch is:  0.16844876110553741\n",
      "The representation loss after processing this batch is:  0.0027531422674655914\n",
      "\n",
      "The classification loss after processing this batch is:  0.13528794050216675\n",
      "The representation loss after processing this batch is:  0.0026283785700798035\n",
      "\n",
      "The classification loss after processing this batch is:  0.2392929345369339\n",
      "The representation loss after processing this batch is:  0.002696588635444641\n",
      "\n",
      "The classification loss after processing this batch is:  0.2233034074306488\n",
      "The representation loss after processing this batch is:  0.0028685256838798523\n",
      "\n",
      "The classification loss after processing this batch is:  0.16795215010643005\n",
      "The representation loss after processing this batch is:  0.002653326839208603\n",
      "\n",
      "The classification loss after processing this batch is:  0.17123906314373016\n",
      "The representation loss after processing this batch is:  0.002893775701522827\n",
      "\n",
      "The classification loss after processing this batch is:  0.2129773199558258\n",
      "The representation loss after processing this batch is:  0.0027046501636505127\n",
      "\n",
      "The classification loss after processing this batch is:  0.2388715147972107\n",
      "The representation loss after processing this batch is:  0.0027769654989242554\n",
      "\n",
      "The classification loss after processing this batch is:  0.19919779896736145\n",
      "The representation loss after processing this batch is:  0.003526940941810608\n",
      "\n",
      "The classification loss after processing this batch is:  0.18325497210025787\n",
      "The representation loss after processing this batch is:  0.0031556710600852966\n",
      "\n",
      "The classification loss after processing this batch is:  0.1234249696135521\n",
      "The representation loss after processing this batch is:  0.003199934959411621\n",
      "\n",
      "The classification loss after processing this batch is:  0.29680633544921875\n",
      "The representation loss after processing this batch is:  0.0030974149703979492\n",
      "\n",
      "The classification loss after processing this batch is:  0.2818632423877716\n",
      "The representation loss after processing this batch is:  0.002590510994195938\n",
      "\n",
      "The classification loss after processing this batch is:  0.2929239869117737\n",
      "The representation loss after processing this batch is:  0.003003302961587906\n",
      "\n",
      "The classification loss after processing this batch is:  0.35198548436164856\n",
      "The representation loss after processing this batch is:  0.0025887787342071533\n",
      "\n",
      "The classification loss after processing this batch is:  0.2772057354450226\n",
      "The representation loss after processing this batch is:  0.002573363482952118\n",
      "\n",
      "The classification loss after processing this batch is:  0.1096777692437172\n",
      "The representation loss after processing this batch is:  0.0026360899209976196\n",
      "\n",
      "The classification loss after processing this batch is:  0.1191997081041336\n",
      "The representation loss after processing this batch is:  0.002562478184700012\n",
      "\n",
      "The classification loss after processing this batch is:  0.09041882306337357\n",
      "The representation loss after processing this batch is:  0.003077961504459381\n",
      "\n",
      "The classification loss after processing this batch is:  0.13640587031841278\n",
      "The representation loss after processing this batch is:  0.003490746021270752\n",
      "\n",
      "The classification loss after processing this batch is:  0.06510457396507263\n",
      "The representation loss after processing this batch is:  0.002986215054988861\n",
      "\n",
      "The classification loss after processing this batch is:  0.2457735687494278\n",
      "The representation loss after processing this batch is:  0.0038262754678726196\n",
      "\n",
      "The classification loss after processing this batch is:  0.15972815454006195\n",
      "The representation loss after processing this batch is:  0.002772718667984009\n",
      "\n",
      "The classification loss after processing this batch is:  0.10187966376543045\n",
      "The representation loss after processing this batch is:  0.0029324591159820557\n",
      "\n",
      "The classification loss after processing this batch is:  0.2162187546491623\n",
      "The representation loss after processing this batch is:  0.002362661063671112\n",
      "\n",
      "The classification loss after processing this batch is:  0.09627847373485565\n",
      "The representation loss after processing this batch is:  0.0031743086874485016\n",
      "\n",
      "The classification loss after processing this batch is:  0.20572112500667572\n",
      "The representation loss after processing this batch is:  0.003453761339187622\n",
      "\n",
      "The classification loss after processing this batch is:  0.22009262442588806\n",
      "The representation loss after processing this batch is:  0.0036341100931167603\n",
      "\n",
      "The classification loss after processing this batch is:  0.14803162217140198\n",
      "The representation loss after processing this batch is:  0.0034527331590652466\n",
      "\n",
      "The classification loss after processing this batch is:  0.1587112694978714\n",
      "The representation loss after processing this batch is:  0.0024848952889442444\n",
      "\n",
      "The classification loss after processing this batch is:  0.11738698929548264\n",
      "The representation loss after processing this batch is:  0.0026110708713531494\n",
      "\n",
      "The classification loss after processing this batch is:  0.06391053646802902\n",
      "The representation loss after processing this batch is:  0.0025266334414482117\n",
      "\n",
      "The classification loss after processing this batch is:  0.08943295478820801\n",
      "The representation loss after processing this batch is:  0.003233112394809723\n",
      "\n",
      "The classification loss after processing this batch is:  0.10431662946939468\n",
      "The representation loss after processing this batch is:  0.002738784998655319\n",
      "\n",
      "The classification loss after processing this batch is:  0.13026630878448486\n",
      "The representation loss after processing this batch is:  0.00243927538394928\n",
      "\n",
      "The classification loss after processing this batch is:  0.15175357460975647\n",
      "The representation loss after processing this batch is:  0.002591341733932495\n",
      "\n",
      "The classification loss after processing this batch is:  0.1796513944864273\n",
      "The representation loss after processing this batch is:  0.002903886139392853\n",
      "\n",
      "The classification loss after processing this batch is:  0.36472922563552856\n",
      "The representation loss after processing this batch is:  0.0031340643763542175\n",
      "\n",
      "The classification loss after processing this batch is:  0.28810781240463257\n",
      "The representation loss after processing this batch is:  0.0028520971536636353\n",
      "\n",
      "The classification loss after processing this batch is:  0.0956818014383316\n",
      "The representation loss after processing this batch is:  0.002588026225566864\n",
      "\n",
      "The classification loss after processing this batch is:  0.08417387306690216\n",
      "The representation loss after processing this batch is:  0.0030902400612831116\n",
      "\n",
      "The classification loss after processing this batch is:  0.10267679393291473\n",
      "The representation loss after processing this batch is:  0.002530716359615326\n",
      "\n",
      "The classification loss after processing this batch is:  0.08565175533294678\n",
      "The representation loss after processing this batch is:  0.0025885701179504395\n",
      "\n",
      "The classification loss after processing this batch is:  0.05897647514939308\n",
      "The representation loss after processing this batch is:  0.0031661540269851685\n",
      "\n",
      "The classification loss after processing this batch is:  0.08564626425504684\n",
      "The representation loss after processing this batch is:  0.003285318613052368\n",
      "\n",
      "The classification loss after processing this batch is:  0.14599372446537018\n",
      "The representation loss after processing this batch is:  0.00254223495721817\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.2133139967918396\n",
      "The representation loss after processing this batch is:  0.0028274431824684143\n",
      "\n",
      "The classification loss after processing this batch is:  0.09361732751131058\n",
      "The representation loss after processing this batch is:  0.002963319420814514\n",
      "\n",
      "The classification loss after processing this batch is:  0.0945657417178154\n",
      "The representation loss after processing this batch is:  0.0028227344155311584\n",
      "\n",
      "The classification loss after processing this batch is:  0.07154535502195358\n",
      "The representation loss after processing this batch is:  0.00260094553232193\n",
      "\n",
      "The classification loss after processing this batch is:  0.26113995909690857\n",
      "The representation loss after processing this batch is:  0.002732597291469574\n",
      "\n",
      "The classification loss after processing this batch is:  0.1424117088317871\n",
      "The representation loss after processing this batch is:  0.0028251856565475464\n",
      "\n",
      "The classification loss after processing this batch is:  0.061005041003227234\n",
      "The representation loss after processing this batch is:  0.0030984580516815186\n",
      "\n",
      "The classification loss after processing this batch is:  0.17593161761760712\n",
      "The representation loss after processing this batch is:  0.0028919652104377747\n",
      "\n",
      "The classification loss after processing this batch is:  0.14504291117191315\n",
      "The representation loss after processing this batch is:  0.0024968162178993225\n",
      "\n",
      "The classification loss after processing this batch is:  0.08835700899362564\n",
      "The representation loss after processing this batch is:  0.002601124346256256\n",
      "\n",
      "The classification loss after processing this batch is:  0.1359187513589859\n",
      "The representation loss after processing this batch is:  0.0024155043065547943\n",
      "\n",
      "The classification loss after processing this batch is:  0.10043813288211823\n",
      "The representation loss after processing this batch is:  0.002626478672027588\n",
      "\n",
      "The classification loss after processing this batch is:  0.12359842658042908\n",
      "The representation loss after processing this batch is:  0.002739228308200836\n",
      "\n",
      "The classification loss after processing this batch is:  0.17475567758083344\n",
      "The representation loss after processing this batch is:  0.002581201493740082\n",
      "\n",
      "The classification loss after processing this batch is:  0.2320149689912796\n",
      "The representation loss after processing this batch is:  0.002877175807952881\n",
      "\n",
      "The classification loss after processing this batch is:  0.15708138048648834\n",
      "The representation loss after processing this batch is:  0.002618566155433655\n",
      "\n",
      "The classification loss after processing this batch is:  0.15068592131137848\n",
      "The representation loss after processing this batch is:  0.0026859864592552185\n",
      "\n",
      "The classification loss after processing this batch is:  0.12117782980203629\n",
      "The representation loss after processing this batch is:  0.0027535706758499146\n",
      "\n",
      "The classification loss after processing this batch is:  0.184193953871727\n",
      "The representation loss after processing this batch is:  0.002674490213394165\n",
      "\n",
      "The classification loss after processing this batch is:  0.0960870161652565\n",
      "The representation loss after processing this batch is:  0.0029517337679862976\n",
      "\n",
      "The classification loss after processing this batch is:  0.18237616121768951\n",
      "The representation loss after processing this batch is:  0.0029150135815143585\n",
      "\n",
      "The classification loss after processing this batch is:  0.10692931711673737\n",
      "The representation loss after processing this batch is:  0.0026076138019561768\n",
      "\n",
      "The classification loss after processing this batch is:  0.16845978796482086\n",
      "The representation loss after processing this batch is:  0.00264083594083786\n",
      "\n",
      "The classification loss after processing this batch is:  0.1099807396531105\n",
      "The representation loss after processing this batch is:  0.0029026567935943604\n",
      "\n",
      "The classification loss after processing this batch is:  0.16599124670028687\n",
      "The representation loss after processing this batch is:  0.0024801380932331085\n",
      "\n",
      "The classification loss after processing this batch is:  0.13332615792751312\n",
      "The representation loss after processing this batch is:  0.0023596882820129395\n",
      "\n",
      "The classification loss after processing this batch is:  0.14912204444408417\n",
      "The representation loss after processing this batch is:  0.002742767333984375\n",
      "\n",
      "The classification loss after processing this batch is:  0.18632255494594574\n",
      "The representation loss after processing this batch is:  0.002499207854270935\n",
      "\n",
      "The classification loss after processing this batch is:  0.16039393842220306\n",
      "The representation loss after processing this batch is:  0.002532064914703369\n",
      "\n",
      "The classification loss after processing this batch is:  0.2364284247159958\n",
      "The representation loss after processing this batch is:  0.0025435499846935272\n",
      "\n",
      "The classification loss after processing this batch is:  0.22067411243915558\n",
      "The representation loss after processing this batch is:  0.0024776533246040344\n",
      "\n",
      "The classification loss after processing this batch is:  0.30484867095947266\n",
      "The representation loss after processing this batch is:  0.00257197767496109\n",
      "\n",
      "The classification loss after processing this batch is:  0.2255527228116989\n",
      "The representation loss after processing this batch is:  0.0025111548602581024\n",
      "\n",
      "The classification loss after processing this batch is:  0.09707119315862656\n",
      "The representation loss after processing this batch is:  0.0029255151748657227\n",
      "\n",
      "The classification loss after processing this batch is:  0.17002280056476593\n",
      "The representation loss after processing this batch is:  0.0028904974460601807\n",
      "\n",
      "The classification loss after processing this batch is:  0.10016615688800812\n",
      "The representation loss after processing this batch is:  0.002791576087474823\n",
      "\n",
      "The classification loss after processing this batch is:  0.1430172175168991\n",
      "The representation loss after processing this batch is:  0.003184005618095398\n",
      "\n",
      "The classification loss after processing this batch is:  0.2306993007659912\n",
      "The representation loss after processing this batch is:  0.0032082125544548035\n",
      "\n",
      "The classification loss after processing this batch is:  0.2934717535972595\n",
      "The representation loss after processing this batch is:  0.0030592456459999084\n",
      "\n",
      "The classification loss after processing this batch is:  0.3083318769931793\n",
      "The representation loss after processing this batch is:  0.002467341721057892\n",
      "\n",
      "The classification loss after processing this batch is:  0.23224356770515442\n",
      "The representation loss after processing this batch is:  0.0027509182691574097\n",
      "\n",
      "The classification loss after processing this batch is:  0.09648091346025467\n",
      "The representation loss after processing this batch is:  0.002589091658592224\n",
      "\n",
      "The classification loss after processing this batch is:  0.11389680951833725\n",
      "The representation loss after processing this batch is:  0.002842620015144348\n",
      "\n",
      "The classification loss after processing this batch is:  0.2440701574087143\n",
      "The representation loss after processing this batch is:  0.002697072923183441\n",
      "\n",
      "The classification loss after processing this batch is:  0.10509206354618073\n",
      "The representation loss after processing this batch is:  0.00266188383102417\n",
      "\n",
      "The classification loss after processing this batch is:  0.11122849583625793\n",
      "The representation loss after processing this batch is:  0.002875126898288727\n",
      "\n",
      "The classification loss after processing this batch is:  0.10490043461322784\n",
      "The representation loss after processing this batch is:  0.00277864933013916\n",
      "\n",
      "The classification loss after processing this batch is:  0.04334021359682083\n",
      "The representation loss after processing this batch is:  0.002772986888885498\n",
      "\n",
      "The classification loss after processing this batch is:  0.14185209572315216\n",
      "The representation loss after processing this batch is:  0.003181304782629013\n",
      "\n",
      "The classification loss after processing this batch is:  0.1265150010585785\n",
      "The representation loss after processing this batch is:  0.003233291208744049\n",
      "\n",
      "The classification loss after processing this batch is:  0.17909957468509674\n",
      "The representation loss after processing this batch is:  0.002641569823026657\n",
      "\n",
      "The classification loss after processing this batch is:  0.16667312383651733\n",
      "The representation loss after processing this batch is:  0.0025959908962249756\n",
      "\n",
      "The classification loss after processing this batch is:  0.15644827485084534\n",
      "The representation loss after processing this batch is:  0.002924121916294098\n",
      "\n",
      "The classification loss after processing this batch is:  0.19643589854240417\n",
      "The representation loss after processing this batch is:  0.002955220639705658\n",
      "\n",
      "The classification loss after processing this batch is:  0.13241522014141083\n",
      "The representation loss after processing this batch is:  0.0027924254536628723\n",
      "\n",
      "The classification loss after processing this batch is:  0.14469251036643982\n",
      "The representation loss after processing this batch is:  0.0031765177845954895\n",
      "\n",
      "The classification loss after processing this batch is:  0.14122724533081055\n",
      "The representation loss after processing this batch is:  0.003169044852256775\n",
      "\n",
      "The classification loss after processing this batch is:  0.15884250402450562\n",
      "The representation loss after processing this batch is:  0.002904258668422699\n",
      "\n",
      "The classification loss after processing this batch is:  0.1869673728942871\n",
      "The representation loss after processing this batch is:  0.0027653202414512634\n",
      "\n",
      "The classification loss after processing this batch is:  0.2642727196216583\n",
      "The representation loss after processing this batch is:  0.0024602822959423065\n",
      "\n",
      "The classification loss after processing this batch is:  0.24730919301509857\n",
      "The representation loss after processing this batch is:  0.0029649659991264343\n",
      "\n",
      "The classification loss after processing this batch is:  0.12108088284730911\n",
      "The representation loss after processing this batch is:  0.0025273002684116364\n",
      "\n",
      "The classification loss after processing this batch is:  0.1771395057439804\n",
      "The representation loss after processing this batch is:  0.0029380246996879578\n",
      "\n",
      "The classification loss after processing this batch is:  0.16298618912696838\n",
      "The representation loss after processing this batch is:  0.002788446843624115\n",
      "\n",
      "The classification loss after processing this batch is:  0.2179482877254486\n",
      "The representation loss after processing this batch is:  0.0027920566499233246\n",
      "\n",
      "The classification loss after processing this batch is:  0.24659699201583862\n",
      "The representation loss after processing this batch is:  0.0032301396131515503\n",
      "\n",
      "The classification loss after processing this batch is:  0.21385131776332855\n",
      "The representation loss after processing this batch is:  0.002960696816444397\n",
      "\n",
      "The classification loss after processing this batch is:  0.2952632009983063\n",
      "The representation loss after processing this batch is:  0.0031682029366493225\n",
      "\n",
      "The classification loss after processing this batch is:  0.19384190440177917\n",
      "The representation loss after processing this batch is:  0.003215506672859192\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.16136957705020905\n",
      "The representation loss after processing this batch is:  0.0027546361088752747\n",
      "\n",
      "The classification loss after processing this batch is:  0.16804103553295135\n",
      "The representation loss after processing this batch is:  0.0031955018639564514\n",
      "\n",
      "The classification loss after processing this batch is:  0.09974474459886551\n",
      "The representation loss after processing this batch is:  0.0029324591159820557\n",
      "\n",
      "The classification loss after processing this batch is:  0.19515559077262878\n",
      "The representation loss after processing this batch is:  0.0030285418033599854\n",
      "\n",
      "The classification loss after processing this batch is:  0.1616213172674179\n",
      "The representation loss after processing this batch is:  0.002831757068634033\n",
      "\n",
      "The classification loss after processing this batch is:  0.12415584921836853\n",
      "The representation loss after processing this batch is:  0.0024826563894748688\n",
      "\n",
      "The classification loss after processing this batch is:  0.12899000942707062\n",
      "The representation loss after processing this batch is:  0.0028060302138328552\n",
      "\n",
      "The classification loss after processing this batch is:  0.17979121208190918\n",
      "The representation loss after processing this batch is:  0.0030040666460990906\n",
      "\n",
      "The classification loss after processing this batch is:  0.15748733282089233\n",
      "The representation loss after processing this batch is:  0.002548113465309143\n",
      "\n",
      "The classification loss after processing this batch is:  0.14325660467147827\n",
      "The representation loss after processing this batch is:  0.0026641562581062317\n",
      "\n",
      "The classification loss after processing this batch is:  0.1407569944858551\n",
      "The representation loss after processing this batch is:  0.002527013421058655\n",
      "\n",
      "The classification loss after processing this batch is:  0.08415839821100235\n",
      "The representation loss after processing this batch is:  0.0026507750153541565\n",
      "\n",
      "The classification loss after processing this batch is:  0.14219777286052704\n",
      "The representation loss after processing this batch is:  0.002375226467847824\n",
      "\n",
      "The classification loss after processing this batch is:  0.1231587752699852\n",
      "The representation loss after processing this batch is:  0.0023008547723293304\n",
      "\n",
      "The classification loss after processing this batch is:  0.5117335319519043\n",
      "The representation loss after processing this batch is:  0.002852797508239746\n",
      "\n",
      "The classification loss after processing this batch is:  0.12521310150623322\n",
      "The representation loss after processing this batch is:  0.0027789250016212463\n",
      "\n",
      "The classification loss after processing this batch is:  0.20867423713207245\n",
      "The representation loss after processing this batch is:  0.0025782957673072815\n",
      "\n",
      "The classification loss after processing this batch is:  0.3058452904224396\n",
      "The representation loss after processing this batch is:  0.00279216468334198\n",
      "\n",
      "The classification loss after processing this batch is:  0.12020888179540634\n",
      "The representation loss after processing this batch is:  0.002580709755420685\n",
      "\n",
      "The classification loss after processing this batch is:  0.2507127523422241\n",
      "The representation loss after processing this batch is:  0.0030375495553016663\n",
      "\n",
      "The classification loss after processing this batch is:  0.1357397735118866\n",
      "The representation loss after processing this batch is:  0.002969697117805481\n",
      "\n",
      "The classification loss after processing this batch is:  0.2995817959308624\n",
      "The representation loss after processing this batch is:  0.002370215952396393\n",
      "\n",
      "The classification loss after processing this batch is:  0.0761132538318634\n",
      "The representation loss after processing this batch is:  0.0027453675866127014\n",
      "\n",
      "The classification loss after processing this batch is:  0.11749842762947083\n",
      "The representation loss after processing this batch is:  0.002856411039829254\n",
      "\n",
      "The classification loss after processing this batch is:  0.0659908577799797\n",
      "The representation loss after processing this batch is:  0.0030495449900627136\n",
      "\n",
      "The classification loss after processing this batch is:  0.04738171771168709\n",
      "The representation loss after processing this batch is:  0.0029857978224754333\n",
      "\n",
      "The classification loss after processing this batch is:  0.1038757860660553\n",
      "The representation loss after processing this batch is:  0.0028027519583702087\n",
      "\n",
      "The classification loss after processing this batch is:  0.0628582239151001\n",
      "The representation loss after processing this batch is:  0.002384491264820099\n",
      "\n",
      "The classification loss after processing this batch is:  0.13379745185375214\n",
      "The representation loss after processing this batch is:  0.00293644517660141\n",
      "\n",
      "The classification loss after processing this batch is:  0.10679999738931656\n",
      "The representation loss after processing this batch is:  0.003616616129875183\n",
      "\n",
      "The classification loss after processing this batch is:  0.13715387880802155\n",
      "The representation loss after processing this batch is:  0.002606816589832306\n",
      "\n",
      "The classification loss after processing this batch is:  0.1306711882352829\n",
      "The representation loss after processing this batch is:  0.0025386065244674683\n",
      "\n",
      "The classification loss after processing this batch is:  0.09036194533109665\n",
      "The representation loss after processing this batch is:  0.002694040536880493\n",
      "\n",
      "The classification loss after processing this batch is:  0.17683540284633636\n",
      "The representation loss after processing this batch is:  0.0027155019342899323\n",
      "\n",
      "The classification loss after processing this batch is:  0.16056828200817108\n",
      "The representation loss after processing this batch is:  0.003034546971321106\n",
      "\n",
      "The classification loss after processing this batch is:  0.22794367372989655\n",
      "The representation loss after processing this batch is:  0.0032029375433921814\n",
      "\n",
      "The classification loss after processing this batch is:  0.12473026663064957\n",
      "The representation loss after processing this batch is:  0.002619832754135132\n",
      "\n",
      "The classification loss after processing this batch is:  0.10663523524999619\n",
      "The representation loss after processing this batch is:  0.0028015263378620148\n",
      "\n",
      "The classification loss after processing this batch is:  0.21347282826900482\n",
      "The representation loss after processing this batch is:  0.0027817264199256897\n",
      "\n",
      "The classification loss after processing this batch is:  0.2225370705127716\n",
      "The representation loss after processing this batch is:  0.002871572971343994\n",
      "\n",
      "The classification loss after processing this batch is:  0.17449264228343964\n",
      "The representation loss after processing this batch is:  0.0026424750685691833\n",
      "\n",
      "The classification loss after processing this batch is:  0.08520588278770447\n",
      "The representation loss after processing this batch is:  0.0028805136680603027\n",
      "\n",
      "The classification loss after processing this batch is:  0.13434505462646484\n",
      "The representation loss after processing this batch is:  0.0030259713530540466\n",
      "\n",
      "The classification loss after processing this batch is:  0.15028968453407288\n",
      "The representation loss after processing this batch is:  0.0026431716978549957\n",
      "\n",
      "The classification loss after processing this batch is:  0.16543057560920715\n",
      "The representation loss after processing this batch is:  0.0029567107558250427\n",
      "\n",
      "The classification loss after processing this batch is:  0.16528990864753723\n",
      "The representation loss after processing this batch is:  0.0033492855727672577\n",
      "\n",
      "The classification loss after processing this batch is:  0.10871150344610214\n",
      "The representation loss after processing this batch is:  0.003317583352327347\n",
      "\n",
      "The classification loss after processing this batch is:  0.1753658652305603\n",
      "The representation loss after processing this batch is:  0.003132954239845276\n",
      "\n",
      "The classification loss after processing this batch is:  0.19718672335147858\n",
      "The representation loss after processing this batch is:  0.0027716532349586487\n",
      "\n",
      "The classification loss after processing this batch is:  0.11810138821601868\n",
      "The representation loss after processing this batch is:  0.003600001335144043\n",
      "\n",
      "The classification loss after processing this batch is:  0.17587032914161682\n",
      "The representation loss after processing this batch is:  0.0025917068123817444\n",
      "\n",
      "The classification loss after processing this batch is:  0.11728815734386444\n",
      "The representation loss after processing this batch is:  0.0024925842881202698\n",
      "\n",
      "The classification loss after processing this batch is:  0.18912458419799805\n",
      "The representation loss after processing this batch is:  0.0027196556329727173\n",
      "\n",
      "The classification loss after processing this batch is:  0.0864892527461052\n",
      "The representation loss after processing this batch is:  0.002672143280506134\n",
      "\n",
      "The classification loss after processing this batch is:  0.15044638514518738\n",
      "The representation loss after processing this batch is:  0.0031109005212783813\n",
      "\n",
      "The classification loss after processing this batch is:  0.12004486471414566\n",
      "The representation loss after processing this batch is:  0.003134794533252716\n",
      "\n",
      "The classification loss after processing this batch is:  0.12040311843156815\n",
      "The representation loss after processing this batch is:  0.0024702250957489014\n",
      "\n",
      "The classification loss after processing this batch is:  0.10818304866552353\n",
      "The representation loss after processing this batch is:  0.002929970622062683\n",
      "\n",
      "The classification loss after processing this batch is:  0.1844937950372696\n",
      "The representation loss after processing this batch is:  0.0030367448925971985\n",
      "\n",
      "The classification loss after processing this batch is:  0.18651527166366577\n",
      "The representation loss after processing this batch is:  0.003161795437335968\n",
      "\n",
      "The classification loss after processing this batch is:  0.18587414920330048\n",
      "The representation loss after processing this batch is:  0.0031108520925045013\n",
      "\n",
      "The classification loss after processing this batch is:  0.13713334500789642\n",
      "The representation loss after processing this batch is:  0.0032739415764808655\n",
      "\n",
      "The classification loss after processing this batch is:  0.10607416927814484\n",
      "The representation loss after processing this batch is:  0.0027430132031440735\n",
      "\n",
      "The classification loss after processing this batch is:  0.11713012307882309\n",
      "The representation loss after processing this batch is:  0.002957761287689209\n",
      "\n",
      "The classification loss after processing this batch is:  0.11098403483629227\n",
      "The representation loss after processing this batch is:  0.002956591546535492\n",
      "\n",
      "The classification loss after processing this batch is:  0.12927350401878357\n",
      "The representation loss after processing this batch is:  0.002626948058605194\n",
      "\n",
      "The classification loss after processing this batch is:  0.06393000483512878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.002717740833759308\n",
      "\n",
      "The classification loss after processing this batch is:  0.06734710186719894\n",
      "The representation loss after processing this batch is:  0.002601921558380127\n",
      "\n",
      "The classification loss after processing this batch is:  0.11074811965227127\n",
      "The representation loss after processing this batch is:  0.0028477609157562256\n",
      "\n",
      "The classification loss after processing this batch is:  0.058478984981775284\n",
      "The representation loss after processing this batch is:  0.002945415675640106\n",
      "\n",
      "The classification loss after processing this batch is:  0.1972220093011856\n",
      "The representation loss after processing this batch is:  0.002765186131000519\n",
      "\n",
      "The classification loss after processing this batch is:  0.13840684294700623\n",
      "The representation loss after processing this batch is:  0.002411443740129471\n",
      "\n",
      "The classification loss after processing this batch is:  0.16533923149108887\n",
      "The representation loss after processing this batch is:  0.0028295665979385376\n",
      "\n",
      "The classification loss after processing this batch is:  0.05570737272500992\n",
      "The representation loss after processing this batch is:  0.00307387113571167\n",
      "\n",
      "The classification loss after processing this batch is:  0.21081694960594177\n",
      "The representation loss after processing this batch is:  0.0027674585580825806\n",
      "\n",
      "The classification loss after processing this batch is:  0.1442197859287262\n",
      "The representation loss after processing this batch is:  0.0027339160442352295\n",
      "\n",
      "The classification loss after processing this batch is:  0.13283327221870422\n",
      "The representation loss after processing this batch is:  0.0026673004031181335\n",
      "\n",
      "The classification loss after processing this batch is:  0.13488124310970306\n",
      "The representation loss after processing this batch is:  0.0029632598161697388\n",
      "\n",
      "The classification loss after processing this batch is:  0.1216503232717514\n",
      "The representation loss after processing this batch is:  0.003115866333246231\n",
      "\n",
      "The classification loss after processing this batch is:  0.09965946525335312\n",
      "The representation loss after processing this batch is:  0.002677828073501587\n",
      "\n",
      "The classification loss after processing this batch is:  0.0930049866437912\n",
      "The representation loss after processing this batch is:  0.0028462782502174377\n",
      "\n",
      "The classification loss after processing this batch is:  0.10354265570640564\n",
      "The representation loss after processing this batch is:  0.0026452243328094482\n",
      "\n",
      "The classification loss after processing this batch is:  0.21606948971748352\n",
      "The representation loss after processing this batch is:  0.0028412118554115295\n",
      "\n",
      "The classification loss after processing this batch is:  0.147336944937706\n",
      "The representation loss after processing this batch is:  0.0024795159697532654\n",
      "\n",
      "The classification loss after processing this batch is:  0.1777440756559372\n",
      "The representation loss after processing this batch is:  0.003542274236679077\n",
      "\n",
      "The classification loss after processing this batch is:  0.2021341621875763\n",
      "The representation loss after processing this batch is:  0.0028099119663238525\n",
      "\n",
      "The classification loss after processing this batch is:  0.17855902016162872\n",
      "The representation loss after processing this batch is:  0.0028981342911720276\n",
      "\n",
      "The classification loss after processing this batch is:  0.19940198957920074\n",
      "The representation loss after processing this batch is:  0.0027060583233833313\n",
      "\n",
      "The classification loss after processing this batch is:  0.31545642018318176\n",
      "The representation loss after processing this batch is:  0.0025269240140914917\n",
      "\n",
      "The classification loss after processing this batch is:  0.2133861482143402\n",
      "The representation loss after processing this batch is:  0.0023567751049995422\n",
      "\n",
      "The classification loss after processing this batch is:  0.14951176941394806\n",
      "The representation loss after processing this batch is:  0.002394411712884903\n",
      "\n",
      "The classification loss after processing this batch is:  0.12551921606063843\n",
      "The representation loss after processing this batch is:  0.002543322741985321\n",
      "\n",
      "The classification loss after processing this batch is:  0.09138739854097366\n",
      "The representation loss after processing this batch is:  0.002610728144645691\n",
      "\n",
      "The classification loss after processing this batch is:  0.07603432983160019\n",
      "The representation loss after processing this batch is:  0.0025329813361167908\n",
      "\n",
      "The classification loss after processing this batch is:  0.12742958962917328\n",
      "The representation loss after processing this batch is:  0.0032452717423439026\n",
      "\n",
      "The classification loss after processing this batch is:  0.15718215703964233\n",
      "The representation loss after processing this batch is:  0.002717047929763794\n",
      "\n",
      "The classification loss after processing this batch is:  0.09774021804332733\n",
      "The representation loss after processing this batch is:  0.002702660858631134\n",
      "\n",
      "The classification loss after processing this batch is:  0.21705792844295502\n",
      "The representation loss after processing this batch is:  0.002774495631456375\n",
      "\n",
      "The classification loss after processing this batch is:  0.15193279087543488\n",
      "The representation loss after processing this batch is:  0.0027872323989868164\n",
      "\n",
      "The classification loss after processing this batch is:  0.1631307303905487\n",
      "The representation loss after processing this batch is:  0.0026271305978298187\n",
      "\n",
      "The classification loss after processing this batch is:  0.15970350801944733\n",
      "The representation loss after processing this batch is:  0.0025568008422851562\n",
      "\n",
      "The classification loss after processing this batch is:  0.2348078042268753\n",
      "The representation loss after processing this batch is:  0.002402752637863159\n",
      "\n",
      "The classification loss after processing this batch is:  0.1687396615743637\n",
      "The representation loss after processing this batch is:  0.0027317851781845093\n",
      "\n",
      "The classification loss after processing this batch is:  0.11043627560138702\n",
      "The representation loss after processing this batch is:  0.003143422305583954\n",
      "\n",
      "The classification loss after processing this batch is:  0.16262651979923248\n",
      "The representation loss after processing this batch is:  0.0025849640369415283\n",
      "\n",
      "The classification loss after processing this batch is:  0.06785540282726288\n",
      "The representation loss after processing this batch is:  0.002570033073425293\n",
      "\n",
      "The classification loss after processing this batch is:  0.07420892268419266\n",
      "The representation loss after processing this batch is:  0.002703718841075897\n",
      "\n",
      "The classification loss after processing this batch is:  0.13473083078861237\n",
      "The representation loss after processing this batch is:  0.002985626459121704\n",
      "\n",
      "The classification loss after processing this batch is:  0.1822485327720642\n",
      "The representation loss after processing this batch is:  0.002476505935192108\n",
      "\n",
      "The classification loss after processing this batch is:  0.1695156991481781\n",
      "The representation loss after processing this batch is:  0.0028994902968406677\n",
      "\n",
      "The classification loss after processing this batch is:  0.09311935305595398\n",
      "The representation loss after processing this batch is:  0.0033623352646827698\n",
      "\n",
      "The classification loss after processing this batch is:  0.12653708457946777\n",
      "The representation loss after processing this batch is:  0.003016941249370575\n",
      "\n",
      "The classification loss after processing this batch is:  0.08533895015716553\n",
      "The representation loss after processing this batch is:  0.0029143840074539185\n",
      "\n",
      "The classification loss after processing this batch is:  0.23214587569236755\n",
      "The representation loss after processing this batch is:  0.0026963502168655396\n",
      "\n",
      "The classification loss after processing this batch is:  0.0673162117600441\n",
      "The representation loss after processing this batch is:  0.0023657530546188354\n",
      "\n",
      "The classification loss after processing this batch is:  0.06767794489860535\n",
      "The representation loss after processing this batch is:  0.0030684322118759155\n",
      "\n",
      "The classification loss after processing this batch is:  0.13816212117671967\n",
      "The representation loss after processing this batch is:  0.0035561025142669678\n",
      "\n",
      "The classification loss after processing this batch is:  0.14298288524150848\n",
      "The representation loss after processing this batch is:  0.0027869120240211487\n",
      "\n",
      "The classification loss after processing this batch is:  0.10962089151144028\n",
      "The representation loss after processing this batch is:  0.0031532645225524902\n",
      "\n",
      "The classification loss after processing this batch is:  0.07319138944149017\n",
      "The representation loss after processing this batch is:  0.0026150867342948914\n",
      "\n",
      "The classification loss after processing this batch is:  0.1595889776945114\n",
      "The representation loss after processing this batch is:  0.0031485632061958313\n",
      "\n",
      "The classification loss after processing this batch is:  0.2018888145685196\n",
      "The representation loss after processing this batch is:  0.0030978694558143616\n",
      "\n",
      "The classification loss after processing this batch is:  0.20344534516334534\n",
      "The representation loss after processing this batch is:  0.002607487142086029\n",
      "\n",
      "The classification loss after processing this batch is:  0.1824970543384552\n",
      "The representation loss after processing this batch is:  0.0031234174966812134\n",
      "\n",
      "The classification loss after processing this batch is:  0.08918724954128265\n",
      "The representation loss after processing this batch is:  0.002883896231651306\n",
      "\n",
      "The classification loss after processing this batch is:  0.11476495116949081\n",
      "The representation loss after processing this batch is:  0.002481885254383087\n",
      "\n",
      "The classification loss after processing this batch is:  0.22961346805095673\n",
      "The representation loss after processing this batch is:  0.002849481999874115\n",
      "\n",
      "The classification loss after processing this batch is:  0.2688632607460022\n",
      "The representation loss after processing this batch is:  0.0030810311436653137\n",
      "\n",
      "The classification loss after processing this batch is:  0.24334698915481567\n",
      "The representation loss after processing this batch is:  0.0032393187284469604\n",
      "\n",
      "The classification loss after processing this batch is:  0.2860071361064911\n",
      "The representation loss after processing this batch is:  0.00293780118227005\n",
      "\n",
      "The classification loss after processing this batch is:  0.09921625256538391\n",
      "The representation loss after processing this batch is:  0.0024411529302597046\n",
      "\n",
      "The classification loss after processing this batch is:  0.17916879057884216\n",
      "The representation loss after processing this batch is:  0.0025926604866981506\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.11996500939130783\n",
      "The representation loss after processing this batch is:  0.002696022391319275\n",
      "\n",
      "The classification loss after processing this batch is:  0.12140016257762909\n",
      "The representation loss after processing this batch is:  0.002602122724056244\n",
      "\n",
      "The classification loss after processing this batch is:  0.12363196909427643\n",
      "The representation loss after processing this batch is:  0.0026721134781837463\n",
      "\n",
      "The classification loss after processing this batch is:  0.18934999406337738\n",
      "The representation loss after processing this batch is:  0.002690643072128296\n",
      "\n",
      "The classification loss after processing this batch is:  0.16297391057014465\n",
      "The representation loss after processing this batch is:  0.0025967657566070557\n",
      "\n",
      "The classification loss after processing this batch is:  0.11557920277118683\n",
      "The representation loss after processing this batch is:  0.0026264488697052\n",
      "\n",
      "The classification loss after processing this batch is:  0.1875450611114502\n",
      "The representation loss after processing this batch is:  0.002698957920074463\n",
      "\n",
      "The classification loss after processing this batch is:  0.05638603866100311\n",
      "The representation loss after processing this batch is:  0.002988569438457489\n",
      "\n",
      "The classification loss after processing this batch is:  0.12580512464046478\n",
      "The representation loss after processing this batch is:  0.0029938071966171265\n",
      "\n",
      "The classification loss after processing this batch is:  0.1816590279340744\n",
      "The representation loss after processing this batch is:  0.0027793794870376587\n",
      "\n",
      "The classification loss after processing this batch is:  0.16779379546642303\n",
      "The representation loss after processing this batch is:  0.0030177682638168335\n",
      "\n",
      "The classification loss after processing this batch is:  0.063515305519104\n",
      "The representation loss after processing this batch is:  0.0034147948026657104\n",
      "\n",
      "The classification loss after processing this batch is:  0.08910871297121048\n",
      "The representation loss after processing this batch is:  0.0027620159089565277\n",
      "\n",
      "The classification loss after processing this batch is:  0.19748029112815857\n",
      "The representation loss after processing this batch is:  0.0033876076340675354\n",
      "\n",
      "The classification loss after processing this batch is:  0.19654257595539093\n",
      "The representation loss after processing this batch is:  0.0026023536920547485\n",
      "\n",
      "The classification loss after processing this batch is:  0.16610018908977509\n",
      "The representation loss after processing this batch is:  0.0030028298497200012\n",
      "\n",
      "The classification loss after processing this batch is:  0.12781593203544617\n",
      "The representation loss after processing this batch is:  0.0027834363281726837\n",
      "\n",
      "The classification loss after processing this batch is:  0.08905936777591705\n",
      "The representation loss after processing this batch is:  0.002929195761680603\n",
      "\n",
      "The classification loss after processing this batch is:  0.12514016032218933\n",
      "The representation loss after processing this batch is:  0.002603486180305481\n",
      "\n",
      "The classification loss after processing this batch is:  0.14914584159851074\n",
      "The representation loss after processing this batch is:  0.0026634037494659424\n",
      "\n",
      "The classification loss after processing this batch is:  0.2002638280391693\n",
      "The representation loss after processing this batch is:  0.0026442036032676697\n",
      "\n",
      "The classification loss after processing this batch is:  0.13331076502799988\n",
      "The representation loss after processing this batch is:  0.0029973983764648438\n",
      "\n",
      "The classification loss after processing this batch is:  0.09310109168291092\n",
      "The representation loss after processing this batch is:  0.0026835575699806213\n",
      "\n",
      "The classification loss after processing this batch is:  0.17438361048698425\n",
      "The representation loss after processing this batch is:  0.002937406301498413\n",
      "\n",
      "The classification loss after processing this batch is:  0.23418760299682617\n",
      "The representation loss after processing this batch is:  0.0027865618467330933\n",
      "\n",
      "The classification loss after processing this batch is:  0.09362280368804932\n",
      "The representation loss after processing this batch is:  0.0028987377882003784\n",
      "\n",
      "The classification loss after processing this batch is:  0.09563741087913513\n",
      "The representation loss after processing this batch is:  0.0024505816400051117\n",
      "\n",
      "The classification loss after processing this batch is:  0.22767218947410583\n",
      "The representation loss after processing this batch is:  0.0027287527918815613\n",
      "\n",
      "The classification loss after processing this batch is:  0.21527554094791412\n",
      "The representation loss after processing this batch is:  0.0026267021894454956\n",
      "\n",
      "The classification loss after processing this batch is:  0.10461614280939102\n",
      "The representation loss after processing this batch is:  0.002708643674850464\n",
      "\n",
      "The classification loss after processing this batch is:  0.1912466436624527\n",
      "The representation loss after processing this batch is:  0.0023697763681411743\n",
      "\n",
      "The classification loss after processing this batch is:  0.1919466108083725\n",
      "The representation loss after processing this batch is:  0.0028784647583961487\n",
      "\n",
      "The classification loss after processing this batch is:  0.21859104931354523\n",
      "The representation loss after processing this batch is:  0.003099672496318817\n",
      "\n",
      "The classification loss after processing this batch is:  0.16075433790683746\n",
      "The representation loss after processing this batch is:  0.0030151158571243286\n",
      "\n",
      "The classification loss after processing this batch is:  0.18748219311237335\n",
      "The representation loss after processing this batch is:  0.0026503652334213257\n",
      "\n",
      "The classification loss after processing this batch is:  0.129380002617836\n",
      "The representation loss after processing this batch is:  0.0036946386098861694\n",
      "\n",
      "The classification loss after processing this batch is:  0.138257697224617\n",
      "The representation loss after processing this batch is:  0.0026742666959762573\n",
      "\n",
      "The classification loss after processing this batch is:  0.1153404489159584\n",
      "The representation loss after processing this batch is:  0.0025140419602394104\n",
      "\n",
      "The classification loss after processing this batch is:  0.11813012510538101\n",
      "The representation loss after processing this batch is:  0.0025019198656082153\n",
      "\n",
      "The classification loss after processing this batch is:  0.1256384700536728\n",
      "The representation loss after processing this batch is:  0.0026307106018066406\n",
      "\n",
      "The classification loss after processing this batch is:  0.14867720007896423\n",
      "The representation loss after processing this batch is:  0.0027320757508277893\n",
      "\n",
      "The classification loss after processing this batch is:  0.21415267884731293\n",
      "The representation loss after processing this batch is:  0.002644035965204239\n",
      "\n",
      "The classification loss after processing this batch is:  0.08094601333141327\n",
      "The representation loss after processing this batch is:  0.002908967435359955\n",
      "\n",
      "The classification loss after processing this batch is:  0.08173181861639023\n",
      "The representation loss after processing this batch is:  0.003306083381175995\n",
      "\n",
      "The classification loss after processing this batch is:  0.14743860065937042\n",
      "The representation loss after processing this batch is:  0.003055669367313385\n",
      "\n",
      "The classification loss after processing this batch is:  0.051795925945043564\n",
      "The representation loss after processing this batch is:  0.002613469958305359\n",
      "\n",
      "The classification loss after processing this batch is:  0.11387582868337631\n",
      "The representation loss after processing this batch is:  0.002799801528453827\n",
      "\n",
      "The classification loss after processing this batch is:  0.05845058336853981\n",
      "The representation loss after processing this batch is:  0.002819076180458069\n",
      "\n",
      "The classification loss after processing this batch is:  0.13016003370285034\n",
      "The representation loss after processing this batch is:  0.002724260091781616\n",
      "\n",
      "The classification loss after processing this batch is:  0.1679612547159195\n",
      "The representation loss after processing this batch is:  0.002896256744861603\n",
      "\n",
      "The classification loss after processing this batch is:  0.18415461480617523\n",
      "The representation loss after processing this batch is:  0.0035001561045646667\n",
      "\n",
      "The classification loss after processing this batch is:  0.15944518148899078\n",
      "The representation loss after processing this batch is:  0.003331385552883148\n",
      "\n",
      "The classification loss after processing this batch is:  0.10231330990791321\n",
      "The representation loss after processing this batch is:  0.002862483263015747\n",
      "\n",
      "The classification loss after processing this batch is:  0.12494922429323196\n",
      "The representation loss after processing this batch is:  0.003181915730237961\n",
      "\n",
      "The classification loss after processing this batch is:  0.09560125321149826\n",
      "The representation loss after processing this batch is:  0.002680562436580658\n",
      "\n",
      "The classification loss after processing this batch is:  0.07445774972438812\n",
      "The representation loss after processing this batch is:  0.003148108720779419\n",
      "\n",
      "The classification loss after processing this batch is:  0.08453236520290375\n",
      "The representation loss after processing this batch is:  0.00268419086933136\n",
      "\n",
      "The classification loss after processing this batch is:  0.07223670929670334\n",
      "The representation loss after processing this batch is:  0.0029230639338493347\n",
      "\n",
      "The classification loss after processing this batch is:  0.11880488693714142\n",
      "The representation loss after processing this batch is:  0.0029126331210136414\n",
      "\n",
      "The classification loss after processing this batch is:  0.17199628055095673\n",
      "The representation loss after processing this batch is:  0.0030321143567562103\n",
      "\n",
      "The classification loss after processing this batch is:  0.1810232251882553\n",
      "The representation loss after processing this batch is:  0.0026782825589179993\n",
      "\n",
      "The classification loss after processing this batch is:  0.1370725929737091\n",
      "The representation loss after processing this batch is:  0.0033548474311828613\n",
      "\n",
      "The classification loss after processing this batch is:  0.11905274540185928\n",
      "The representation loss after processing this batch is:  0.0029923096299171448\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14818337559700012\n",
      "The representation loss after processing this batch is:  0.002984825521707535\n",
      "\n",
      "The classification loss after processing this batch is:  0.10942146927118301\n",
      "The representation loss after processing this batch is:  0.003015086054801941\n",
      "\n",
      "The classification loss after processing this batch is:  0.3933645188808441\n",
      "The representation loss after processing this batch is:  0.0033285915851593018\n",
      "\n",
      "The classification loss after processing this batch is:  0.16238142549991608\n",
      "The representation loss after processing this batch is:  0.0031184405088424683\n",
      "\n",
      "The classification loss after processing this batch is:  0.22896817326545715\n",
      "The representation loss after processing this batch is:  0.003553256392478943\n",
      "\n",
      "The classification loss after processing this batch is:  0.11062566190958023\n",
      "The representation loss after processing this batch is:  0.0025995224714279175\n",
      "\n",
      "The classification loss after processing this batch is:  0.12407603859901428\n",
      "The representation loss after processing this batch is:  0.0025695860385894775\n",
      "\n",
      "The classification loss after processing this batch is:  0.1455708146095276\n",
      "The representation loss after processing this batch is:  0.00264565646648407\n",
      "\n",
      "The classification loss after processing this batch is:  0.13592609763145447\n",
      "The representation loss after processing this batch is:  0.002949818968772888\n",
      "\n",
      "The classification loss after processing this batch is:  0.23742498457431793\n",
      "The representation loss after processing this batch is:  0.0028606802225112915\n",
      "\n",
      "The classification loss after processing this batch is:  0.17440538108348846\n",
      "The representation loss after processing this batch is:  0.003563523292541504\n",
      "\n",
      "The classification loss after processing this batch is:  0.20846493542194366\n",
      "The representation loss after processing this batch is:  0.003325328230857849\n",
      "\n",
      "The classification loss after processing this batch is:  0.15655885636806488\n",
      "The representation loss after processing this batch is:  0.002909652888774872\n",
      "\n",
      "The classification loss after processing this batch is:  0.06356591731309891\n",
      "The representation loss after processing this batch is:  0.0029403716325759888\n",
      "\n",
      "The classification loss after processing this batch is:  0.12247630953788757\n",
      "The representation loss after processing this batch is:  0.0026134029030799866\n",
      "\n",
      "The classification loss after processing this batch is:  0.110439732670784\n",
      "The representation loss after processing this batch is:  0.0026587583124637604\n",
      "\n",
      "The classification loss after processing this batch is:  0.10453905165195465\n",
      "The representation loss after processing this batch is:  0.0029591843485832214\n",
      "\n",
      "The classification loss after processing this batch is:  0.16959956288337708\n",
      "The representation loss after processing this batch is:  0.0025270432233810425\n",
      "\n",
      "The classification loss after processing this batch is:  0.25215944647789\n",
      "The representation loss after processing this batch is:  0.0026553571224212646\n",
      "\n",
      "The classification loss after processing this batch is:  0.15260647237300873\n",
      "The representation loss after processing this batch is:  0.0023234598338603973\n",
      "\n",
      "The classification loss after processing this batch is:  0.12175321578979492\n",
      "The representation loss after processing this batch is:  0.002607405185699463\n",
      "\n",
      "The classification loss after processing this batch is:  0.1360481083393097\n",
      "The representation loss after processing this batch is:  0.0027870088815689087\n",
      "\n",
      "The classification loss after processing this batch is:  0.10548437386751175\n",
      "The representation loss after processing this batch is:  0.0030957013368606567\n",
      "\n",
      "The classification loss after processing this batch is:  0.15131911635398865\n",
      "The representation loss after processing this batch is:  0.0029674023389816284\n",
      "\n",
      "The classification loss after processing this batch is:  0.06176867336034775\n",
      "The representation loss after processing this batch is:  0.002931647002696991\n",
      "\n",
      "The classification loss after processing this batch is:  0.15066200494766235\n",
      "The representation loss after processing this batch is:  0.0026010945439338684\n",
      "\n",
      "The classification loss after processing this batch is:  0.22206908464431763\n",
      "The representation loss after processing this batch is:  0.002797544002532959\n",
      "\n",
      "The classification loss after processing this batch is:  0.07797909528017044\n",
      "The representation loss after processing this batch is:  0.0028057843446731567\n",
      "\n",
      "The classification loss after processing this batch is:  0.18990951776504517\n",
      "The representation loss after processing this batch is:  0.0023676566779613495\n",
      "\n",
      "The classification loss after processing this batch is:  0.13829027116298676\n",
      "The representation loss after processing this batch is:  0.0023930221796035767\n",
      "\n",
      "The classification loss after processing this batch is:  0.12917478382587433\n",
      "The representation loss after processing this batch is:  0.002669915556907654\n",
      "\n",
      "The classification loss after processing this batch is:  0.08668216317892075\n",
      "The representation loss after processing this batch is:  0.0025875791907310486\n",
      "\n",
      "The classification loss after processing this batch is:  0.16833217442035675\n",
      "The representation loss after processing this batch is:  0.002654463052749634\n",
      "\n",
      "The classification loss after processing this batch is:  0.08292751014232635\n",
      "The representation loss after processing this batch is:  0.0029750876128673553\n",
      "\n",
      "The classification loss after processing this batch is:  0.3667857348918915\n",
      "The representation loss after processing this batch is:  0.002862483263015747\n",
      "\n",
      "The classification loss after processing this batch is:  0.177132710814476\n",
      "The representation loss after processing this batch is:  0.0028319060802459717\n",
      "\n",
      "The classification loss after processing this batch is:  0.19665591418743134\n",
      "The representation loss after processing this batch is:  0.002748332917690277\n",
      "\n",
      "The classification loss after processing this batch is:  0.1007501408457756\n",
      "The representation loss after processing this batch is:  0.002454429864883423\n",
      "\n",
      "The classification loss after processing this batch is:  0.16278375685214996\n",
      "The representation loss after processing this batch is:  0.0028110668063163757\n",
      "\n",
      "The classification loss after processing this batch is:  0.07600539177656174\n",
      "The representation loss after processing this batch is:  0.00264735147356987\n",
      "\n",
      "The classification loss after processing this batch is:  0.15706634521484375\n",
      "The representation loss after processing this batch is:  0.002752382308244705\n",
      "\n",
      "The classification loss after processing this batch is:  0.23202762007713318\n",
      "The representation loss after processing this batch is:  0.002950504422187805\n",
      "\n",
      "The classification loss after processing this batch is:  0.1689901202917099\n",
      "The representation loss after processing this batch is:  0.0033624395728111267\n",
      "\n",
      "The classification loss after processing this batch is:  0.19584257900714874\n",
      "The representation loss after processing this batch is:  0.0028673969209194183\n",
      "\n",
      "The classification loss after processing this batch is:  0.11755228787660599\n",
      "The representation loss after processing this batch is:  0.002543248236179352\n",
      "\n",
      "The classification loss after processing this batch is:  0.2278480976819992\n",
      "The representation loss after processing this batch is:  0.002940066158771515\n",
      "\n",
      "The classification loss after processing this batch is:  0.15987475216388702\n",
      "The representation loss after processing this batch is:  0.0029820874333381653\n",
      "\n",
      "The classification loss after processing this batch is:  0.2045293152332306\n",
      "The representation loss after processing this batch is:  0.0027507618069648743\n",
      "\n",
      "The classification loss after processing this batch is:  0.1285448968410492\n",
      "The representation loss after processing this batch is:  0.002804800868034363\n",
      "\n",
      "The classification loss after processing this batch is:  0.12300802767276764\n",
      "The representation loss after processing this batch is:  0.0030150413513183594\n",
      "\n",
      "The classification loss after processing this batch is:  0.06741632521152496\n",
      "The representation loss after processing this batch is:  0.0024817362427711487\n",
      "\n",
      "The classification loss after processing this batch is:  0.20418156683444977\n",
      "The representation loss after processing this batch is:  0.0026376955211162567\n",
      "\n",
      "The classification loss after processing this batch is:  0.27002161741256714\n",
      "The representation loss after processing this batch is:  0.002791251987218857\n",
      "\n",
      "The classification loss after processing this batch is:  0.11862894892692566\n",
      "The representation loss after processing this batch is:  0.0030689090490341187\n",
      "\n",
      "The classification loss after processing this batch is:  0.18321776390075684\n",
      "The representation loss after processing this batch is:  0.0035858526825904846\n",
      "\n",
      "The classification loss after processing this batch is:  0.21735143661499023\n",
      "The representation loss after processing this batch is:  0.0027191229164600372\n",
      "\n",
      "The classification loss after processing this batch is:  0.20783402025699615\n",
      "The representation loss after processing this batch is:  0.0032472535967826843\n",
      "\n",
      "The classification loss after processing this batch is:  0.08071757107973099\n",
      "The representation loss after processing this batch is:  0.002507288008928299\n",
      "\n",
      "The classification loss after processing this batch is:  0.18833965063095093\n",
      "The representation loss after processing this batch is:  0.002871580421924591\n",
      "\n",
      "The classification loss after processing this batch is:  0.18630704283714294\n",
      "The representation loss after processing this batch is:  0.0030761808156967163\n",
      "\n",
      "The classification loss after processing this batch is:  0.146921306848526\n",
      "The representation loss after processing this batch is:  0.002778582274913788\n",
      "\n",
      "The classification loss after processing this batch is:  0.059865571558475494\n",
      "The representation loss after processing this batch is:  0.002819962799549103\n",
      "\n",
      "The classification loss after processing this batch is:  0.11268015950918198\n",
      "The representation loss after processing this batch is:  0.0029822885990142822\n",
      "\n",
      "The classification loss after processing this batch is:  0.12343170493841171\n",
      "The representation loss after processing this batch is:  0.0030053332448005676\n",
      "\n",
      "The classification loss after processing this batch is:  0.1516043245792389\n",
      "The representation loss after processing this batch is:  0.002533216029405594\n",
      "\n",
      "The classification loss after processing this batch is:  0.21644817292690277\n",
      "The representation loss after processing this batch is:  0.002850659191608429\n",
      "\n",
      "The classification loss after processing this batch is:  0.17925260961055756\n",
      "The representation loss after processing this batch is:  0.002739179879426956\n",
      "\n",
      "The classification loss after processing this batch is:  0.14326432347297668\n",
      "The representation loss after processing this batch is:  0.0030668899416923523\n",
      "\n",
      "The classification loss after processing this batch is:  0.19711105525493622\n",
      "The representation loss after processing this batch is:  0.003176391124725342\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.15189461410045624\n",
      "The representation loss after processing this batch is:  0.0033101364970207214\n",
      "\n",
      "The classification loss after processing this batch is:  0.1359388381242752\n",
      "The representation loss after processing this batch is:  0.0032459571957588196\n",
      "\n",
      "The classification loss after processing this batch is:  0.2676163911819458\n",
      "The representation loss after processing this batch is:  0.0029839128255844116\n",
      "\n",
      "The classification loss after processing this batch is:  0.23506473004817963\n",
      "The representation loss after processing this batch is:  0.003360077738761902\n",
      "\n",
      "The classification loss after processing this batch is:  0.1146756261587143\n",
      "The representation loss after processing this batch is:  0.0028388649225234985\n",
      "\n",
      "The classification loss after processing this batch is:  0.08699463307857513\n",
      "The representation loss after processing this batch is:  0.0027675367891788483\n",
      "\n",
      "The classification loss after processing this batch is:  0.11751902848482132\n",
      "The representation loss after processing this batch is:  0.002516619861125946\n",
      "\n",
      "The classification loss after processing this batch is:  0.11682204902172089\n",
      "The representation loss after processing this batch is:  0.0028447210788726807\n",
      "\n",
      "The classification loss after processing this batch is:  0.12899424135684967\n",
      "The representation loss after processing this batch is:  0.002678915858268738\n",
      "\n",
      "The classification loss after processing this batch is:  0.2561333477497101\n",
      "The representation loss after processing this batch is:  0.0026236698031425476\n",
      "\n",
      "The classification loss after processing this batch is:  0.2265453338623047\n",
      "The representation loss after processing this batch is:  0.0033345893025398254\n",
      "\n",
      "The classification loss after processing this batch is:  0.17137214541435242\n",
      "The representation loss after processing this batch is:  0.0023704692721366882\n",
      "\n",
      "The classification loss after processing this batch is:  0.15667031705379486\n",
      "The representation loss after processing this batch is:  0.002478271722793579\n",
      "\n",
      "The classification loss after processing this batch is:  0.13451078534126282\n",
      "The representation loss after processing this batch is:  0.002367611974477768\n",
      "\n",
      "The classification loss after processing this batch is:  0.14974665641784668\n",
      "The representation loss after processing this batch is:  0.002548638731241226\n",
      "\n",
      "The classification loss after processing this batch is:  0.25624731183052063\n",
      "The representation loss after processing this batch is:  0.0026440657675266266\n",
      "\n",
      "The classification loss after processing this batch is:  0.22697977721691132\n",
      "The representation loss after processing this batch is:  0.0027154386043548584\n",
      "\n",
      "The classification loss after processing this batch is:  0.32560452818870544\n",
      "The representation loss after processing this batch is:  0.002679497003555298\n",
      "\n",
      "The classification loss after processing this batch is:  0.15436069667339325\n",
      "The representation loss after processing this batch is:  0.0028847679495811462\n",
      "\n",
      "The classification loss after processing this batch is:  0.05804365873336792\n",
      "The representation loss after processing this batch is:  0.0031820982694625854\n",
      "\n",
      "The classification loss after processing this batch is:  0.17940858006477356\n",
      "The representation loss after processing this batch is:  0.002827771008014679\n",
      "\n",
      "The classification loss after processing this batch is:  0.14006195962429047\n",
      "The representation loss after processing this batch is:  0.0026362761855125427\n",
      "\n",
      "The classification loss after processing this batch is:  0.2095995843410492\n",
      "The representation loss after processing this batch is:  0.0032690316438674927\n",
      "\n",
      "The classification loss after processing this batch is:  0.192597895860672\n",
      "The representation loss after processing this batch is:  0.0027425140142440796\n",
      "\n",
      "The classification loss after processing this batch is:  0.19206885993480682\n",
      "The representation loss after processing this batch is:  0.0027009248733520508\n",
      "\n",
      "The classification loss after processing this batch is:  0.16038250923156738\n",
      "The representation loss after processing this batch is:  0.0024638772010803223\n",
      "\n",
      "The classification loss after processing this batch is:  0.205847829580307\n",
      "The representation loss after processing this batch is:  0.002555210143327713\n",
      "\n",
      "The classification loss after processing this batch is:  0.2843068540096283\n",
      "The representation loss after processing this batch is:  0.0027647092938423157\n",
      "\n",
      "The classification loss after processing this batch is:  0.27151167392730713\n",
      "The representation loss after processing this batch is:  0.003039821982383728\n",
      "\n",
      "The classification loss after processing this batch is:  0.1807253360748291\n",
      "The representation loss after processing this batch is:  0.00274716317653656\n",
      "\n",
      "The classification loss after processing this batch is:  0.06393759697675705\n",
      "The representation loss after processing this batch is:  0.0030551329255104065\n",
      "\n",
      "The classification loss after processing this batch is:  0.04472999647259712\n",
      "The representation loss after processing this batch is:  0.0028492361307144165\n",
      "\n",
      "The classification loss after processing this batch is:  0.14424188435077667\n",
      "The representation loss after processing this batch is:  0.002671748399734497\n",
      "\n",
      "The classification loss after processing this batch is:  0.08685848116874695\n",
      "The representation loss after processing this batch is:  0.004327863454818726\n",
      "\n",
      "The classification loss after processing this batch is:  0.19478873908519745\n",
      "The representation loss after processing this batch is:  0.0027842745184898376\n",
      "\n",
      "The classification loss after processing this batch is:  0.10113632678985596\n",
      "The representation loss after processing this batch is:  0.0030326172709465027\n",
      "\n",
      "The classification loss after processing this batch is:  0.21521078050136566\n",
      "The representation loss after processing this batch is:  0.002775423228740692\n",
      "\n",
      "The classification loss after processing this batch is:  0.07004598528146744\n",
      "The representation loss after processing this batch is:  0.0032318681478500366\n",
      "\n",
      "The classification loss after processing this batch is:  0.16516949236392975\n",
      "The representation loss after processing this batch is:  0.002818875014781952\n",
      "\n",
      "The classification loss after processing this batch is:  0.1467597335577011\n",
      "The representation loss after processing this batch is:  0.003192223608493805\n",
      "\n",
      "The classification loss after processing this batch is:  0.1895795315504074\n",
      "The representation loss after processing this batch is:  0.0029792189598083496\n",
      "\n",
      "The classification loss after processing this batch is:  0.13212566077709198\n",
      "The representation loss after processing this batch is:  0.002645328640937805\n",
      "\n",
      "The classification loss after processing this batch is:  0.08580708503723145\n",
      "The representation loss after processing this batch is:  0.002514079213142395\n",
      "\n",
      "The classification loss after processing this batch is:  0.15723416209220886\n",
      "The representation loss after processing this batch is:  0.002870984375476837\n",
      "\n",
      "The classification loss after processing this batch is:  0.1626943051815033\n",
      "The representation loss after processing this batch is:  0.0025593936443328857\n",
      "\n",
      "The classification loss after processing this batch is:  0.19062824547290802\n",
      "The representation loss after processing this batch is:  0.00274764746427536\n",
      "\n",
      "The classification loss after processing this batch is:  0.16744208335876465\n",
      "The representation loss after processing this batch is:  0.002869322896003723\n",
      "\n",
      "The classification loss after processing this batch is:  0.0951143279671669\n",
      "The representation loss after processing this batch is:  0.002831876277923584\n",
      "\n",
      "The classification loss after processing this batch is:  0.05690832808613777\n",
      "The representation loss after processing this batch is:  0.002725847065448761\n",
      "\n",
      "The classification loss after processing this batch is:  0.061706721782684326\n",
      "The representation loss after processing this batch is:  0.00305388867855072\n",
      "\n",
      "The classification loss after processing this batch is:  0.05313704162836075\n",
      "The representation loss after processing this batch is:  0.0028690770268440247\n",
      "\n",
      "The classification loss after processing this batch is:  0.1338237076997757\n",
      "The representation loss after processing this batch is:  0.0028565451502799988\n",
      "\n",
      "The classification loss after processing this batch is:  0.09129635989665985\n",
      "The representation loss after processing this batch is:  0.0028838887810707092\n",
      "\n",
      "The classification loss after processing this batch is:  0.04745404049754143\n",
      "The representation loss after processing this batch is:  0.0028579160571098328\n",
      "\n",
      "The classification loss after processing this batch is:  0.14504937827587128\n",
      "The representation loss after processing this batch is:  0.0033069849014282227\n",
      "\n",
      "The classification loss after processing this batch is:  0.09887972474098206\n",
      "The representation loss after processing this batch is:  0.002936035394668579\n",
      "\n",
      "The classification loss after processing this batch is:  0.05792824178934097\n",
      "The representation loss after processing this batch is:  0.0026745647192001343\n",
      "\n",
      "The classification loss after processing this batch is:  0.09039674699306488\n",
      "The representation loss after processing this batch is:  0.002848193049430847\n",
      "\n",
      "The classification loss after processing this batch is:  0.06621064245700836\n",
      "The representation loss after processing this batch is:  0.002597600221633911\n",
      "\n",
      "The classification loss after processing this batch is:  0.053396862000226974\n",
      "The representation loss after processing this batch is:  0.0029227733612060547\n",
      "\n",
      "The classification loss after processing this batch is:  0.17709602415561676\n",
      "The representation loss after processing this batch is:  0.002765953540802002\n",
      "\n",
      "The classification loss after processing this batch is:  0.19033993780612946\n",
      "The representation loss after processing this batch is:  0.00290650874376297\n",
      "\n",
      "The classification loss after processing this batch is:  0.10173260420560837\n",
      "The representation loss after processing this batch is:  0.002880483865737915\n",
      "\n",
      "The classification loss after processing this batch is:  0.21984876692295074\n",
      "The representation loss after processing this batch is:  0.0027343779802322388\n",
      "\n",
      "The classification loss after processing this batch is:  0.0899905264377594\n",
      "The representation loss after processing this batch is:  0.00259612500667572\n",
      "\n",
      "The classification loss after processing this batch is:  0.16727003455162048\n",
      "The representation loss after processing this batch is:  0.0024638697504997253\n",
      "\n",
      "The classification loss after processing this batch is:  0.18302936851978302\n",
      "The representation loss after processing this batch is:  0.0029723793268203735\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1026553139090538\n",
      "The representation loss after processing this batch is:  0.002904728055000305\n",
      "\n",
      "The classification loss after processing this batch is:  0.21502746641635895\n",
      "The representation loss after processing this batch is:  0.0027371644973754883\n",
      "\n",
      "The classification loss after processing this batch is:  0.15113568305969238\n",
      "The representation loss after processing this batch is:  0.0027003586292266846\n",
      "\n",
      "The classification loss after processing this batch is:  0.16059939563274384\n",
      "The representation loss after processing this batch is:  0.002819925546646118\n",
      "\n",
      "The classification loss after processing this batch is:  0.16914300620555878\n",
      "The representation loss after processing this batch is:  0.0027697384357452393\n",
      "\n",
      "The classification loss after processing this batch is:  0.13349922001361847\n",
      "The representation loss after processing this batch is:  0.003039442002773285\n",
      "\n",
      "The classification loss after processing this batch is:  0.14619164168834686\n",
      "The representation loss after processing this batch is:  0.0024064183235168457\n",
      "\n",
      "The classification loss after processing this batch is:  0.11068716645240784\n",
      "The representation loss after processing this batch is:  0.002859950065612793\n",
      "\n",
      "The classification loss after processing this batch is:  0.20595026016235352\n",
      "The representation loss after processing this batch is:  0.002687610685825348\n",
      "\n",
      "The classification loss after processing this batch is:  0.15340961515903473\n",
      "The representation loss after processing this batch is:  0.002539604902267456\n",
      "\n",
      "The classification loss after processing this batch is:  0.08845774829387665\n",
      "The representation loss after processing this batch is:  0.002898372709751129\n",
      "\n",
      "The classification loss after processing this batch is:  0.10269021987915039\n",
      "The representation loss after processing this batch is:  0.002579614520072937\n",
      "\n",
      "The classification loss after processing this batch is:  0.21037977933883667\n",
      "The representation loss after processing this batch is:  0.002347860485315323\n",
      "\n",
      "The classification loss after processing this batch is:  0.09343407303094864\n",
      "The representation loss after processing this batch is:  0.003005295991897583\n",
      "\n",
      "The classification loss after processing this batch is:  0.13134552538394928\n",
      "The representation loss after processing this batch is:  0.0027358531951904297\n",
      "\n",
      "The classification loss after processing this batch is:  0.15888553857803345\n",
      "The representation loss after processing this batch is:  0.0025761425495147705\n",
      "\n",
      "The classification loss after processing this batch is:  0.09004562348127365\n",
      "The representation loss after processing this batch is:  0.003001466393470764\n",
      "\n",
      "The classification loss after processing this batch is:  0.06392049044370651\n",
      "The representation loss after processing this batch is:  0.0029333606362342834\n",
      "\n",
      "The classification loss after processing this batch is:  0.11835666000843048\n",
      "The representation loss after processing this batch is:  0.002880990505218506\n",
      "\n",
      "The classification loss after processing this batch is:  0.12215086817741394\n",
      "The representation loss after processing this batch is:  0.002984117716550827\n",
      "\n",
      "The classification loss after processing this batch is:  0.14457982778549194\n",
      "The representation loss after processing this batch is:  0.0027480758726596832\n",
      "\n",
      "The classification loss after processing this batch is:  0.20571231842041016\n",
      "The representation loss after processing this batch is:  0.0026573501527309418\n",
      "\n",
      "The classification loss after processing this batch is:  0.12157678604125977\n",
      "The representation loss after processing this batch is:  0.0028640367090702057\n",
      "\n",
      "The classification loss after processing this batch is:  0.2082427442073822\n",
      "The representation loss after processing this batch is:  0.0023450851440429688\n",
      "\n",
      "The classification loss after processing this batch is:  0.1822485774755478\n",
      "The representation loss after processing this batch is:  0.0030256807804107666\n",
      "\n",
      "The classification loss after processing this batch is:  0.06904980540275574\n",
      "The representation loss after processing this batch is:  0.002904556691646576\n",
      "\n",
      "The classification loss after processing this batch is:  0.08576086908578873\n",
      "The representation loss after processing this batch is:  0.002692919224500656\n",
      "\n",
      "The classification loss after processing this batch is:  0.13730958104133606\n",
      "The representation loss after processing this batch is:  0.0026846379041671753\n",
      "\n",
      "The classification loss after processing this batch is:  0.15210381150245667\n",
      "The representation loss after processing this batch is:  0.0028030648827552795\n",
      "\n",
      "The classification loss after processing this batch is:  0.11984232068061829\n",
      "The representation loss after processing this batch is:  0.002902500331401825\n",
      "\n",
      "The classification loss after processing this batch is:  0.18845485150814056\n",
      "The representation loss after processing this batch is:  0.0027934908866882324\n",
      "\n",
      "The classification loss after processing this batch is:  0.15033544600009918\n",
      "The representation loss after processing this batch is:  0.0034760013222694397\n",
      "\n",
      "The classification loss after processing this batch is:  0.15452784299850464\n",
      "The representation loss after processing this batch is:  0.0031011775135993958\n",
      "\n",
      "The classification loss after processing this batch is:  0.19885896146297455\n",
      "The representation loss after processing this batch is:  0.002743236720561981\n",
      "\n",
      "The classification loss after processing this batch is:  0.15386272966861725\n",
      "The representation loss after processing this batch is:  0.002582333981990814\n",
      "\n",
      "The classification loss after processing this batch is:  0.13754430413246155\n",
      "The representation loss after processing this batch is:  0.0026984848082065582\n",
      "\n",
      "The classification loss after processing this batch is:  0.08731861412525177\n",
      "The representation loss after processing this batch is:  0.0032117068767547607\n",
      "\n",
      "The classification loss after processing this batch is:  0.06818563491106033\n",
      "The representation loss after processing this batch is:  0.002866990864276886\n",
      "\n",
      "The classification loss after processing this batch is:  0.2064247727394104\n",
      "The representation loss after processing this batch is:  0.002484116703271866\n",
      "\n",
      "The classification loss after processing this batch is:  0.17214229702949524\n",
      "The representation loss after processing this batch is:  0.0025518909096717834\n",
      "\n",
      "The classification loss after processing this batch is:  0.16685143113136292\n",
      "The representation loss after processing this batch is:  0.0026932284235954285\n",
      "\n",
      "The classification loss after processing this batch is:  0.17339210212230682\n",
      "The representation loss after processing this batch is:  0.0028322115540504456\n",
      "\n",
      "The classification loss after processing this batch is:  0.15045662224292755\n",
      "The representation loss after processing this batch is:  0.002720203250646591\n",
      "\n",
      "The classification loss after processing this batch is:  0.1835479587316513\n",
      "The representation loss after processing this batch is:  0.002656280994415283\n",
      "\n",
      "The classification loss after processing this batch is:  0.1996649205684662\n",
      "The representation loss after processing this batch is:  0.0028179772198200226\n",
      "\n",
      "The classification loss after processing this batch is:  0.21619684994220734\n",
      "The representation loss after processing this batch is:  0.0027650073170661926\n",
      "\n",
      "The classification loss after processing this batch is:  0.21921157836914062\n",
      "The representation loss after processing this batch is:  0.0026343315839767456\n",
      "\n",
      "The classification loss after processing this batch is:  0.11140125244855881\n",
      "The representation loss after processing this batch is:  0.003108099102973938\n",
      "\n",
      "The classification loss after processing this batch is:  0.06982865184545517\n",
      "The representation loss after processing this batch is:  0.003091573715209961\n",
      "\n",
      "The classification loss after processing this batch is:  0.14076551795005798\n",
      "The representation loss after processing this batch is:  0.0028647780418395996\n",
      "\n",
      "The classification loss after processing this batch is:  0.15449635684490204\n",
      "The representation loss after processing this batch is:  0.0025596991181373596\n",
      "\n",
      "The classification loss after processing this batch is:  0.07244793325662613\n",
      "The representation loss after processing this batch is:  0.002672053873538971\n",
      "\n",
      "The classification loss after processing this batch is:  0.10932590812444687\n",
      "The representation loss after processing this batch is:  0.002675894647836685\n",
      "\n",
      "The classification loss after processing this batch is:  0.12927286326885223\n",
      "The representation loss after processing this batch is:  0.00257013738155365\n",
      "\n",
      "The classification loss after processing this batch is:  0.12125467509031296\n",
      "The representation loss after processing this batch is:  0.0028463229537010193\n",
      "\n",
      "The classification loss after processing this batch is:  0.10576431453227997\n",
      "The representation loss after processing this batch is:  0.0029304809868335724\n",
      "\n",
      "The classification loss after processing this batch is:  0.1166391670703888\n",
      "The representation loss after processing this batch is:  0.002496950328350067\n",
      "\n",
      "The classification loss after processing this batch is:  0.10142364352941513\n",
      "The representation loss after processing this batch is:  0.002799566835165024\n",
      "\n",
      "The classification loss after processing this batch is:  0.15313686430454254\n",
      "The representation loss after processing this batch is:  0.0032097473740577698\n",
      "\n",
      "The classification loss after processing this batch is:  0.12169750779867172\n",
      "The representation loss after processing this batch is:  0.002763736993074417\n",
      "\n",
      "The classification loss after processing this batch is:  0.1708192080259323\n",
      "The representation loss after processing this batch is:  0.003059498965740204\n",
      "\n",
      "The classification loss after processing this batch is:  0.05816460773348808\n",
      "The representation loss after processing this batch is:  0.00312776118516922\n",
      "\n",
      "The classification loss after processing this batch is:  0.07407117635011673\n",
      "The representation loss after processing this batch is:  0.002894163131713867\n",
      "\n",
      "The classification loss after processing this batch is:  0.188326895236969\n",
      "The representation loss after processing this batch is:  0.0026329979300498962\n",
      "\n",
      "The classification loss after processing this batch is:  0.22463633120059967\n",
      "The representation loss after processing this batch is:  0.0025733038783073425\n",
      "\n",
      "The classification loss after processing this batch is:  0.11234768480062485\n",
      "The representation loss after processing this batch is:  0.002515070140361786\n",
      "\n",
      "The classification loss after processing this batch is:  0.05763396993279457\n",
      "The representation loss after processing this batch is:  0.0026410818099975586\n",
      "\n",
      "The classification loss after processing this batch is:  0.16285446286201477\n",
      "The representation loss after processing this batch is:  0.0022520460188388824\n",
      "\n",
      "The classification loss after processing this batch is:  0.04752494767308235\n",
      "The representation loss after processing this batch is:  0.002889186143875122\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.16392192244529724\n",
      "The representation loss after processing this batch is:  0.002661287784576416\n",
      "\n",
      "The classification loss after processing this batch is:  0.1341347098350525\n",
      "The representation loss after processing this batch is:  0.002922661602497101\n",
      "\n",
      "The classification loss after processing this batch is:  0.06651487201452255\n",
      "The representation loss after processing this batch is:  0.0023878440260887146\n",
      "\n",
      "The classification loss after processing this batch is:  0.1054908037185669\n",
      "The representation loss after processing this batch is:  0.002939872443675995\n",
      "\n",
      "The classification loss after processing this batch is:  0.10118276625871658\n",
      "The representation loss after processing this batch is:  0.0028454959392547607\n",
      "\n",
      "The classification loss after processing this batch is:  0.06860318034887314\n",
      "The representation loss after processing this batch is:  0.0025597363710403442\n",
      "\n",
      "The classification loss after processing this batch is:  0.25421765446662903\n",
      "The representation loss after processing this batch is:  0.0026184357702732086\n",
      "\n",
      "The classification loss after processing this batch is:  0.22886864840984344\n",
      "The representation loss after processing this batch is:  0.00254681333899498\n",
      "\n",
      "The classification loss after processing this batch is:  0.22050334513187408\n",
      "The representation loss after processing this batch is:  0.0027111098170280457\n",
      "\n",
      "The classification loss after processing this batch is:  0.23490428924560547\n",
      "The representation loss after processing this batch is:  0.002516515552997589\n",
      "\n",
      "The classification loss after processing this batch is:  0.14511817693710327\n",
      "The representation loss after processing this batch is:  0.0029127970337867737\n",
      "\n",
      "The classification loss after processing this batch is:  0.12137596309185028\n",
      "The representation loss after processing this batch is:  0.0029193833470344543\n",
      "\n",
      "The classification loss after processing this batch is:  0.20901863276958466\n",
      "The representation loss after processing this batch is:  0.002654843032360077\n",
      "\n",
      "The classification loss after processing this batch is:  0.12708589434623718\n",
      "The representation loss after processing this batch is:  0.002949479967355728\n",
      "\n",
      "The classification loss after processing this batch is:  0.21030081808567047\n",
      "The representation loss after processing this batch is:  0.0028014853596687317\n",
      "\n",
      "The classification loss after processing this batch is:  0.14442653954029083\n",
      "The representation loss after processing this batch is:  0.002684086561203003\n",
      "\n",
      "The classification loss after processing this batch is:  0.1735897958278656\n",
      "The representation loss after processing this batch is:  0.002499908208847046\n",
      "\n",
      "The classification loss after processing this batch is:  0.11536291241645813\n",
      "The representation loss after processing this batch is:  0.0026611946523189545\n",
      "\n",
      "The classification loss after processing this batch is:  0.11441577225923538\n",
      "The representation loss after processing this batch is:  0.002816811203956604\n",
      "\n",
      "The classification loss after processing this batch is:  0.17191815376281738\n",
      "The representation loss after processing this batch is:  0.0025078505277633667\n",
      "\n",
      "The classification loss after processing this batch is:  0.0648232251405716\n",
      "The representation loss after processing this batch is:  0.0029220134019851685\n",
      "\n",
      "The classification loss after processing this batch is:  0.07867161929607391\n",
      "The representation loss after processing this batch is:  0.0027927905321121216\n",
      "\n",
      "The classification loss after processing this batch is:  0.15331211686134338\n",
      "The representation loss after processing this batch is:  0.002529323101043701\n",
      "\n",
      "The classification loss after processing this batch is:  0.22628377377986908\n",
      "The representation loss after processing this batch is:  0.002708032727241516\n",
      "\n",
      "The classification loss after processing this batch is:  0.07876349240541458\n",
      "The representation loss after processing this batch is:  0.0025911331176757812\n",
      "\n",
      "The classification loss after processing this batch is:  0.09061013162136078\n",
      "The representation loss after processing this batch is:  0.00237327441573143\n",
      "\n",
      "The classification loss after processing this batch is:  0.1698078215122223\n",
      "The representation loss after processing this batch is:  0.002710990607738495\n",
      "\n",
      "The classification loss after processing this batch is:  0.23854780197143555\n",
      "The representation loss after processing this batch is:  0.002456098794937134\n",
      "\n",
      "The classification loss after processing this batch is:  0.13118143379688263\n",
      "The representation loss after processing this batch is:  0.0026523396372795105\n",
      "\n",
      "The classification loss after processing this batch is:  0.25199949741363525\n",
      "The representation loss after processing this batch is:  0.002446945756673813\n",
      "\n",
      "The classification loss after processing this batch is:  0.1113128736615181\n",
      "The representation loss after processing this batch is:  0.0031007900834083557\n",
      "\n",
      "The classification loss after processing this batch is:  0.04281575605273247\n",
      "The representation loss after processing this batch is:  0.002407453954219818\n",
      "\n",
      "The classification loss after processing this batch is:  0.05961746349930763\n",
      "The representation loss after processing this batch is:  0.0026703476905822754\n",
      "\n",
      "The classification loss after processing this batch is:  0.169343501329422\n",
      "The representation loss after processing this batch is:  0.003175780177116394\n",
      "\n",
      "The classification loss after processing this batch is:  0.1670742630958557\n",
      "The representation loss after processing this batch is:  0.0031417757272720337\n",
      "\n",
      "The classification loss after processing this batch is:  0.11397404223680496\n",
      "The representation loss after processing this batch is:  0.0036801472306251526\n",
      "\n",
      "The classification loss after processing this batch is:  0.12532934546470642\n",
      "The representation loss after processing this batch is:  0.0027654841542243958\n",
      "\n",
      "The classification loss after processing this batch is:  0.12373827397823334\n",
      "The representation loss after processing this batch is:  0.0026084035634994507\n",
      "\n",
      "The classification loss after processing this batch is:  0.14786949753761292\n",
      "The representation loss after processing this batch is:  0.002623245120048523\n",
      "\n",
      "The classification loss after processing this batch is:  0.1435641646385193\n",
      "The representation loss after processing this batch is:  0.0024139881134033203\n",
      "\n",
      "The classification loss after processing this batch is:  0.18556353449821472\n",
      "The representation loss after processing this batch is:  0.0025556646287441254\n",
      "\n",
      "The classification loss after processing this batch is:  0.1670236438512802\n",
      "The representation loss after processing this batch is:  0.002871870994567871\n",
      "\n",
      "The classification loss after processing this batch is:  0.2795686423778534\n",
      "The representation loss after processing this batch is:  0.002590540796518326\n",
      "\n",
      "The classification loss after processing this batch is:  0.15218287706375122\n",
      "The representation loss after processing this batch is:  0.0025698915123939514\n",
      "\n",
      "The classification loss after processing this batch is:  0.164142906665802\n",
      "The representation loss after processing this batch is:  0.002770073711872101\n",
      "\n",
      "The classification loss after processing this batch is:  0.19857975840568542\n",
      "The representation loss after processing this batch is:  0.002600371837615967\n",
      "\n",
      "The classification loss after processing this batch is:  0.07337576895952225\n",
      "The representation loss after processing this batch is:  0.002605743706226349\n",
      "\n",
      "The classification loss after processing this batch is:  0.1467038244009018\n",
      "The representation loss after processing this batch is:  0.003505285829305649\n",
      "\n",
      "The classification loss after processing this batch is:  0.107236847281456\n",
      "The representation loss after processing this batch is:  0.0028837695717811584\n",
      "\n",
      "The classification loss after processing this batch is:  0.13496781885623932\n",
      "The representation loss after processing this batch is:  0.002862699329853058\n",
      "\n",
      "The classification loss after processing this batch is:  0.0938071757555008\n",
      "The representation loss after processing this batch is:  0.0023601464927196503\n",
      "\n",
      "The classification loss after processing this batch is:  0.13162264227867126\n",
      "The representation loss after processing this batch is:  0.0024913251399993896\n",
      "\n",
      "The classification loss after processing this batch is:  0.12071346491575241\n",
      "The representation loss after processing this batch is:  0.002675272524356842\n",
      "\n",
      "The classification loss after processing this batch is:  0.1731555014848709\n",
      "The representation loss after processing this batch is:  0.002482302486896515\n",
      "\n",
      "The classification loss after processing this batch is:  0.16264677047729492\n",
      "The representation loss after processing this batch is:  0.0028367415070533752\n",
      "\n",
      "The classification loss after processing this batch is:  0.22725282609462738\n",
      "The representation loss after processing this batch is:  0.002633325755596161\n",
      "\n",
      "The classification loss after processing this batch is:  0.12142494320869446\n",
      "The representation loss after processing this batch is:  0.0029264166951179504\n",
      "\n",
      "The classification loss after processing this batch is:  0.147465318441391\n",
      "The representation loss after processing this batch is:  0.0024946704506874084\n",
      "\n",
      "The classification loss after processing this batch is:  0.1318821907043457\n",
      "The representation loss after processing this batch is:  0.002687700092792511\n",
      "\n",
      "The classification loss after processing this batch is:  0.24128909409046173\n",
      "The representation loss after processing this batch is:  0.0032658912241458893\n",
      "\n",
      "The classification loss after processing this batch is:  0.28398922085762024\n",
      "The representation loss after processing this batch is:  0.002814248204231262\n",
      "\n",
      "The classification loss after processing this batch is:  0.05908530578017235\n",
      "The representation loss after processing this batch is:  0.0023711100220680237\n",
      "\n",
      "The classification loss after processing this batch is:  0.06735289841890335\n",
      "The representation loss after processing this batch is:  0.0029462724924087524\n",
      "\n",
      "The classification loss after processing this batch is:  0.24930353462696075\n",
      "The representation loss after processing this batch is:  0.0028611496090888977\n",
      "\n",
      "The classification loss after processing this batch is:  0.10200928151607513\n",
      "The representation loss after processing this batch is:  0.0030805617570877075\n",
      "\n",
      "The classification loss after processing this batch is:  0.0956922098994255\n",
      "The representation loss after processing this batch is:  0.0026378333568573\n",
      "\n",
      "The classification loss after processing this batch is:  0.14950449764728546\n",
      "The representation loss after processing this batch is:  0.0026025772094726562\n",
      "\n",
      "The classification loss after processing this batch is:  0.12942424416542053\n",
      "The representation loss after processing this batch is:  0.002946276217699051\n",
      "\n",
      "The classification loss after processing this batch is:  0.25684982538223267\n",
      "The representation loss after processing this batch is:  0.0034566596150398254\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.17739258706569672\n",
      "The representation loss after processing this batch is:  0.003089509904384613\n",
      "\n",
      "The classification loss after processing this batch is:  0.19947390258312225\n",
      "The representation loss after processing this batch is:  0.00321333110332489\n",
      "\n",
      "The classification loss after processing this batch is:  0.10143362730741501\n",
      "The representation loss after processing this batch is:  0.002401493489742279\n",
      "\n",
      "The classification loss after processing this batch is:  0.22225786745548248\n",
      "The representation loss after processing this batch is:  0.002624835819005966\n",
      "\n",
      "The classification loss after processing this batch is:  0.06827303767204285\n",
      "The representation loss after processing this batch is:  0.0025780871510505676\n",
      "\n",
      "The classification loss after processing this batch is:  0.08045120537281036\n",
      "The representation loss after processing this batch is:  0.0028085336089134216\n",
      "\n",
      "The classification loss after processing this batch is:  0.11749763786792755\n",
      "The representation loss after processing this batch is:  0.002525314688682556\n",
      "\n",
      "The classification loss after processing this batch is:  0.07637068629264832\n",
      "The representation loss after processing this batch is:  0.002487465739250183\n",
      "\n",
      "The classification loss after processing this batch is:  0.1010526642203331\n",
      "The representation loss after processing this batch is:  0.002745404839515686\n",
      "\n",
      "The classification loss after processing this batch is:  0.07693223655223846\n",
      "The representation loss after processing this batch is:  0.0028535425662994385\n",
      "\n",
      "The classification loss after processing this batch is:  0.09922616183757782\n",
      "The representation loss after processing this batch is:  0.002818915992975235\n",
      "\n",
      "The classification loss after processing this batch is:  0.1420644372701645\n",
      "The representation loss after processing this batch is:  0.002759389579296112\n",
      "\n",
      "The classification loss after processing this batch is:  0.18801085650920868\n",
      "The representation loss after processing this batch is:  0.0029302164912223816\n",
      "\n",
      "The classification loss after processing this batch is:  0.19255667924880981\n",
      "The representation loss after processing this batch is:  0.002409841865301132\n",
      "\n",
      "The classification loss after processing this batch is:  0.17096994817256927\n",
      "The representation loss after processing this batch is:  0.0032295510172843933\n",
      "\n",
      "The classification loss after processing this batch is:  0.20712445676326752\n",
      "The representation loss after processing this batch is:  0.002739720046520233\n",
      "\n",
      "The classification loss after processing this batch is:  0.07761314511299133\n",
      "The representation loss after processing this batch is:  0.002683691680431366\n",
      "\n",
      "The classification loss after processing this batch is:  0.17172808945178986\n",
      "The representation loss after processing this batch is:  0.0026662424206733704\n",
      "\n",
      "The classification loss after processing this batch is:  0.2839007079601288\n",
      "The representation loss after processing this batch is:  0.0028416961431503296\n",
      "\n",
      "The classification loss after processing this batch is:  0.16064077615737915\n",
      "The representation loss after processing this batch is:  0.002436921000480652\n",
      "\n",
      "The classification loss after processing this batch is:  0.2381686270236969\n",
      "The representation loss after processing this batch is:  0.002577774226665497\n",
      "\n",
      "The classification loss after processing this batch is:  0.18832992017269135\n",
      "The representation loss after processing this batch is:  0.0026228055357933044\n",
      "\n",
      "The classification loss after processing this batch is:  0.17444801330566406\n",
      "The representation loss after processing this batch is:  0.002595122903585434\n",
      "\n",
      "The classification loss after processing this batch is:  0.14294691383838654\n",
      "The representation loss after processing this batch is:  0.0027478858828544617\n",
      "\n",
      "The classification loss after processing this batch is:  0.10197032988071442\n",
      "The representation loss after processing this batch is:  0.0026306062936782837\n",
      "\n",
      "The classification loss after processing this batch is:  0.1360590010881424\n",
      "The representation loss after processing this batch is:  0.002730324864387512\n",
      "\n",
      "The classification loss after processing this batch is:  0.062214408069849014\n",
      "The representation loss after processing this batch is:  0.0028375163674354553\n",
      "\n",
      "The classification loss after processing this batch is:  0.05548058822751045\n",
      "The representation loss after processing this batch is:  0.0026949122548103333\n",
      "\n",
      "The classification loss after processing this batch is:  0.12286494672298431\n",
      "The representation loss after processing this batch is:  0.002887450158596039\n",
      "\n",
      "The classification loss after processing this batch is:  0.07095815986394882\n",
      "The representation loss after processing this batch is:  0.0029077231884002686\n",
      "\n",
      "The classification loss after processing this batch is:  0.2507144808769226\n",
      "The representation loss after processing this batch is:  0.0033580362796783447\n",
      "\n",
      "The classification loss after processing this batch is:  0.1435263305902481\n",
      "The representation loss after processing this batch is:  0.002570606768131256\n",
      "\n",
      "The classification loss after processing this batch is:  0.18512441217899323\n",
      "The representation loss after processing this batch is:  0.0027397572994232178\n",
      "\n",
      "The classification loss after processing this batch is:  0.32804661989212036\n",
      "The representation loss after processing this batch is:  0.0025930888950824738\n",
      "\n",
      "The classification loss after processing this batch is:  0.17373152077198029\n",
      "The representation loss after processing this batch is:  0.002618663012981415\n",
      "\n",
      "The classification loss after processing this batch is:  0.059199269860982895\n",
      "The representation loss after processing this batch is:  0.00263417512178421\n",
      "\n",
      "The classification loss after processing this batch is:  0.08624140173196793\n",
      "The representation loss after processing this batch is:  0.0029067546129226685\n",
      "\n",
      "The classification loss after processing this batch is:  0.08669638633728027\n",
      "The representation loss after processing this batch is:  0.0029224976897239685\n",
      "\n",
      "The classification loss after processing this batch is:  0.10424607247114182\n",
      "The representation loss after processing this batch is:  0.0028793513774871826\n",
      "\n",
      "The classification loss after processing this batch is:  0.11378300189971924\n",
      "The representation loss after processing this batch is:  0.002426471561193466\n",
      "\n",
      "The classification loss after processing this batch is:  0.2505626082420349\n",
      "The representation loss after processing this batch is:  0.0023102201521396637\n",
      "\n",
      "The classification loss after processing this batch is:  0.2183740735054016\n",
      "The representation loss after processing this batch is:  0.0026180297136306763\n",
      "\n",
      "The classification loss after processing this batch is:  0.1622910052537918\n",
      "The representation loss after processing this batch is:  0.0030048787593841553\n",
      "\n",
      "The classification loss after processing this batch is:  0.2384939193725586\n",
      "The representation loss after processing this batch is:  0.002943478524684906\n",
      "\n",
      "The classification loss after processing this batch is:  0.08966194093227386\n",
      "The representation loss after processing this batch is:  0.0026945099234580994\n",
      "\n",
      "The classification loss after processing this batch is:  0.14514636993408203\n",
      "The representation loss after processing this batch is:  0.002608969807624817\n",
      "\n",
      "The classification loss after processing this batch is:  0.23792418837547302\n",
      "The representation loss after processing this batch is:  0.0025249384343624115\n",
      "\n",
      "The classification loss after processing this batch is:  0.11626606434583664\n",
      "The representation loss after processing this batch is:  0.0031982362270355225\n",
      "\n",
      "The classification loss after processing this batch is:  0.15105333924293518\n",
      "The representation loss after processing this batch is:  0.00357992947101593\n",
      "\n",
      "The classification loss after processing this batch is:  0.08902288228273392\n",
      "The representation loss after processing this batch is:  0.0030063316226005554\n",
      "\n",
      "The classification loss after processing this batch is:  0.1736176759004593\n",
      "The representation loss after processing this batch is:  0.0034006163477897644\n",
      "\n",
      "The classification loss after processing this batch is:  0.1901918202638626\n",
      "The representation loss after processing this batch is:  0.0031284689903259277\n",
      "\n",
      "The classification loss after processing this batch is:  0.13678652048110962\n",
      "The representation loss after processing this batch is:  0.0029986798763275146\n",
      "\n",
      "The classification loss after processing this batch is:  0.15224625170230865\n",
      "The representation loss after processing this batch is:  0.0031543150544166565\n",
      "\n",
      "The classification loss after processing this batch is:  0.20964008569717407\n",
      "The representation loss after processing this batch is:  0.0023160502314567566\n",
      "\n",
      "The classification loss after processing this batch is:  0.1388138383626938\n",
      "The representation loss after processing this batch is:  0.0026459842920303345\n",
      "\n",
      "The classification loss after processing this batch is:  0.16103287041187286\n",
      "The representation loss after processing this batch is:  0.002789013087749481\n",
      "\n",
      "The classification loss after processing this batch is:  0.08834108710289001\n",
      "The representation loss after processing this batch is:  0.0030486509203910828\n",
      "\n",
      "The classification loss after processing this batch is:  0.04342297464609146\n",
      "The representation loss after processing this batch is:  0.003017902374267578\n",
      "\n",
      "The classification loss after processing this batch is:  0.142100989818573\n",
      "The representation loss after processing this batch is:  0.002868831157684326\n",
      "\n",
      "The classification loss after processing this batch is:  0.10109622031450272\n",
      "The representation loss after processing this batch is:  0.002964101731777191\n",
      "\n",
      "The classification loss after processing this batch is:  0.28348174691200256\n",
      "The representation loss after processing this batch is:  0.00245574489235878\n",
      "\n",
      "The classification loss after processing this batch is:  0.06127787381410599\n",
      "The representation loss after processing this batch is:  0.002984650433063507\n",
      "\n",
      "The classification loss after processing this batch is:  0.11291024833917618\n",
      "The representation loss after processing this batch is:  0.002643182873725891\n",
      "\n",
      "The classification loss after processing this batch is:  0.16868339478969574\n",
      "The representation loss after processing this batch is:  0.002850376069545746\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.13688591122627258\n",
      "The representation loss after processing this batch is:  0.002808481454849243\n",
      "\n",
      "The classification loss after processing this batch is:  0.16656433045864105\n",
      "The representation loss after processing this batch is:  0.0029630884528160095\n",
      "\n",
      "The classification loss after processing this batch is:  0.07330869138240814\n",
      "The representation loss after processing this batch is:  0.0026108548045158386\n",
      "\n",
      "The classification loss after processing this batch is:  0.06583358347415924\n",
      "The representation loss after processing this batch is:  0.0026840977370738983\n",
      "\n",
      "The classification loss after processing this batch is:  0.08120886981487274\n",
      "The representation loss after processing this batch is:  0.0028874725103378296\n",
      "\n",
      "The classification loss after processing this batch is:  0.18282486498355865\n",
      "The representation loss after processing this batch is:  0.003318190574645996\n",
      "\n",
      "The classification loss after processing this batch is:  0.21823236346244812\n",
      "The representation loss after processing this batch is:  0.0027920007705688477\n",
      "\n",
      "The classification loss after processing this batch is:  0.15804719924926758\n",
      "The representation loss after processing this batch is:  0.0023811720311641693\n",
      "\n",
      "The classification loss after processing this batch is:  0.19009317457675934\n",
      "The representation loss after processing this batch is:  0.0026030391454696655\n",
      "\n",
      "The classification loss after processing this batch is:  0.2547872066497803\n",
      "The representation loss after processing this batch is:  0.0025013014674186707\n",
      "\n",
      "The classification loss after processing this batch is:  0.13692811131477356\n",
      "The representation loss after processing this batch is:  0.002719290554523468\n",
      "\n",
      "The classification loss after processing this batch is:  0.24665269255638123\n",
      "The representation loss after processing this batch is:  0.002802237868309021\n",
      "\n",
      "The classification loss after processing this batch is:  0.1282598078250885\n",
      "The representation loss after processing this batch is:  0.002946913242340088\n",
      "\n",
      "The classification loss after processing this batch is:  0.08285097032785416\n",
      "The representation loss after processing this batch is:  0.0026290789246559143\n",
      "\n",
      "The classification loss after processing this batch is:  0.07027149945497513\n",
      "The representation loss after processing this batch is:  0.0025650933384895325\n",
      "\n",
      "The classification loss after processing this batch is:  0.09186051040887833\n",
      "The representation loss after processing this batch is:  0.002709686756134033\n",
      "\n",
      "The classification loss after processing this batch is:  0.2911924421787262\n",
      "The representation loss after processing this batch is:  0.002911604940891266\n",
      "\n",
      "The classification loss after processing this batch is:  0.10002676397562027\n",
      "The representation loss after processing this batch is:  0.0026907995343208313\n",
      "\n",
      "The classification loss after processing this batch is:  0.1513497680425644\n",
      "The representation loss after processing this batch is:  0.0031243935227394104\n",
      "\n",
      "The classification loss after processing this batch is:  0.15083585679531097\n",
      "The representation loss after processing this batch is:  0.0031125620007514954\n",
      "\n",
      "The classification loss after processing this batch is:  0.1414821445941925\n",
      "The representation loss after processing this batch is:  0.0028464719653129578\n",
      "\n",
      "The classification loss after processing this batch is:  0.08932416886091232\n",
      "The representation loss after processing this batch is:  0.0028000399470329285\n",
      "\n",
      "The classification loss after processing this batch is:  0.184935063123703\n",
      "The representation loss after processing this batch is:  0.00251103937625885\n",
      "\n",
      "The classification loss after processing this batch is:  0.2013411819934845\n",
      "The representation loss after processing this batch is:  0.0025653354823589325\n",
      "\n",
      "The classification loss after processing this batch is:  0.18769219517707825\n",
      "The representation loss after processing this batch is:  0.0031311139464378357\n",
      "\n",
      "The classification loss after processing this batch is:  0.08933378756046295\n",
      "The representation loss after processing this batch is:  0.002745348960161209\n",
      "\n",
      "The classification loss after processing this batch is:  0.30866777896881104\n",
      "The representation loss after processing this batch is:  0.002323724329471588\n",
      "\n",
      "The classification loss after processing this batch is:  0.1036258265376091\n",
      "The representation loss after processing this batch is:  0.002496480941772461\n",
      "\n",
      "The classification loss after processing this batch is:  0.11020640283823013\n",
      "The representation loss after processing this batch is:  0.002369474619626999\n",
      "\n",
      "The classification loss after processing this batch is:  0.1329600065946579\n",
      "The representation loss after processing this batch is:  0.003005102276802063\n",
      "\n",
      "The classification loss after processing this batch is:  0.0953090488910675\n",
      "The representation loss after processing this batch is:  0.0026910826563835144\n",
      "\n",
      "The classification loss after processing this batch is:  0.10296568274497986\n",
      "The representation loss after processing this batch is:  0.0026020631194114685\n",
      "\n",
      "The classification loss after processing this batch is:  0.0989503338932991\n",
      "The representation loss after processing this batch is:  0.0029322952032089233\n",
      "\n",
      "The classification loss after processing this batch is:  0.1830245405435562\n",
      "The representation loss after processing this batch is:  0.002847440540790558\n",
      "\n",
      "The classification loss after processing this batch is:  0.21459917724132538\n",
      "The representation loss after processing this batch is:  0.00270070880651474\n",
      "\n",
      "The classification loss after processing this batch is:  0.18952417373657227\n",
      "The representation loss after processing this batch is:  0.0027412623167037964\n",
      "\n",
      "The classification loss after processing this batch is:  0.13010524213314056\n",
      "The representation loss after processing this batch is:  0.002813126891851425\n",
      "\n",
      "The classification loss after processing this batch is:  0.14090000092983246\n",
      "The representation loss after processing this batch is:  0.003402240574359894\n",
      "\n",
      "The classification loss after processing this batch is:  0.19515392184257507\n",
      "The representation loss after processing this batch is:  0.0023901760578155518\n",
      "\n",
      "The classification loss after processing this batch is:  0.15616288781166077\n",
      "The representation loss after processing this batch is:  0.002567403018474579\n",
      "\n",
      "The classification loss after processing this batch is:  0.032362017780542374\n",
      "The representation loss after processing this batch is:  0.002820223569869995\n",
      "\n",
      "The classification loss after processing this batch is:  0.13175798952579498\n",
      "The representation loss after processing this batch is:  0.002426460385322571\n",
      "\n",
      "The classification loss after processing this batch is:  0.29223236441612244\n",
      "The representation loss after processing this batch is:  0.002764139324426651\n",
      "\n",
      "The classification loss after processing this batch is:  0.3252474367618561\n",
      "The representation loss after processing this batch is:  0.0028380826115608215\n",
      "\n",
      "The classification loss after processing this batch is:  0.27387258410453796\n",
      "The representation loss after processing this batch is:  0.002579323947429657\n",
      "\n",
      "The classification loss after processing this batch is:  0.18087591230869293\n",
      "The representation loss after processing this batch is:  0.002487458288669586\n",
      "\n",
      "The classification loss after processing this batch is:  0.07235191017389297\n",
      "The representation loss after processing this batch is:  0.0026516765356063843\n",
      "\n",
      "The classification loss after processing this batch is:  0.1267416775226593\n",
      "The representation loss after processing this batch is:  0.002440124750137329\n",
      "\n",
      "The classification loss after processing this batch is:  0.11646581441164017\n",
      "The representation loss after processing this batch is:  0.0029472187161445618\n",
      "\n",
      "The classification loss after processing this batch is:  0.19234159588813782\n",
      "The representation loss after processing this batch is:  0.0029964670538902283\n",
      "\n",
      "The classification loss after processing this batch is:  0.17133696377277374\n",
      "The representation loss after processing this batch is:  0.002874121069908142\n",
      "\n",
      "The classification loss after processing this batch is:  0.16654615104198456\n",
      "The representation loss after processing this batch is:  0.0032993778586387634\n",
      "\n",
      "The classification loss after processing this batch is:  0.11788150668144226\n",
      "The representation loss after processing this batch is:  0.0026191696524620056\n",
      "\n",
      "The classification loss after processing this batch is:  0.12860658764839172\n",
      "The representation loss after processing this batch is:  0.0026475712656974792\n",
      "\n",
      "The classification loss after processing this batch is:  0.19340987503528595\n",
      "The representation loss after processing this batch is:  0.0031087175011634827\n",
      "\n",
      "The classification loss after processing this batch is:  0.1807686984539032\n",
      "The representation loss after processing this batch is:  0.0026080161333084106\n",
      "\n",
      "The classification loss after processing this batch is:  0.13113920390605927\n",
      "The representation loss after processing this batch is:  0.0024162717163562775\n",
      "\n",
      "The classification loss after processing this batch is:  0.2755632698535919\n",
      "The representation loss after processing this batch is:  0.0032446086406707764\n",
      "\n",
      "The classification loss after processing this batch is:  0.3129902184009552\n",
      "The representation loss after processing this batch is:  0.0028821565210819244\n",
      "\n",
      "The classification loss after processing this batch is:  0.18421316146850586\n",
      "The representation loss after processing this batch is:  0.002947889268398285\n",
      "\n",
      "The classification loss after processing this batch is:  0.15666140615940094\n",
      "The representation loss after processing this batch is:  0.0027440711855888367\n",
      "\n",
      "The classification loss after processing this batch is:  0.10678032785654068\n",
      "The representation loss after processing this batch is:  0.003300905227661133\n",
      "\n",
      "The classification loss after processing this batch is:  0.04979870840907097\n",
      "The representation loss after processing this batch is:  0.0029131174087524414\n",
      "\n",
      "The classification loss after processing this batch is:  0.22429171204566956\n",
      "The representation loss after processing this batch is:  0.0026385411620140076\n",
      "\n",
      "The classification loss after processing this batch is:  0.18431156873703003\n",
      "The representation loss after processing this batch is:  0.0032398998737335205\n",
      "\n",
      "The classification loss after processing this batch is:  0.12310338765382767\n",
      "The representation loss after processing this batch is:  0.0031428486108779907\n",
      "\n",
      "The classification loss after processing this batch is:  0.25373631715774536\n",
      "The representation loss after processing this batch is:  0.0025640055537223816\n",
      "\n",
      "The classification loss after processing this batch is:  0.058443546295166016\n",
      "The representation loss after processing this batch is:  0.0026349425315856934\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.07391247153282166\n",
      "The representation loss after processing this batch is:  0.0030905231833457947\n",
      "\n",
      "The classification loss after processing this batch is:  0.10614635795354843\n",
      "The representation loss after processing this batch is:  0.002492383122444153\n",
      "\n",
      "The classification loss after processing this batch is:  0.154202401638031\n",
      "The representation loss after processing this batch is:  0.0026257820427417755\n",
      "\n",
      "The classification loss after processing this batch is:  0.18660172820091248\n",
      "The representation loss after processing this batch is:  0.002963908016681671\n",
      "\n",
      "The classification loss after processing this batch is:  0.1180296465754509\n",
      "The representation loss after processing this batch is:  0.0027721822261810303\n",
      "\n",
      "The classification loss after processing this batch is:  0.11134118586778641\n",
      "The representation loss after processing this batch is:  0.0026967301964759827\n",
      "\n",
      "The classification loss after processing this batch is:  0.05976201966404915\n",
      "The representation loss after processing this batch is:  0.002732783555984497\n",
      "\n",
      "The classification loss after processing this batch is:  0.06038195267319679\n",
      "The representation loss after processing this batch is:  0.002607375383377075\n",
      "\n",
      "The classification loss after processing this batch is:  0.10295278578996658\n",
      "The representation loss after processing this batch is:  0.00279342383146286\n",
      "\n",
      "The classification loss after processing this batch is:  0.06214229390025139\n",
      "The representation loss after processing this batch is:  0.0028411448001861572\n",
      "\n",
      "The classification loss after processing this batch is:  0.11709901690483093\n",
      "The representation loss after processing this batch is:  0.0024190954864025116\n",
      "\n",
      "The classification loss after processing this batch is:  0.1833370178937912\n",
      "The representation loss after processing this batch is:  0.002664923667907715\n",
      "\n",
      "The classification loss after processing this batch is:  0.2061614990234375\n",
      "The representation loss after processing this batch is:  0.002840660512447357\n",
      "\n",
      "The classification loss after processing this batch is:  0.05134899541735649\n",
      "The representation loss after processing this batch is:  0.00217481330037117\n",
      "\n",
      "The classification loss after processing this batch is:  0.08214637637138367\n",
      "The representation loss after processing this batch is:  0.0026496797800064087\n",
      "\n",
      "The classification loss after processing this batch is:  0.12418298423290253\n",
      "The representation loss after processing this batch is:  0.0029495730996131897\n",
      "\n",
      "The classification loss after processing this batch is:  0.1703496128320694\n",
      "The representation loss after processing this batch is:  0.0026799626648426056\n",
      "\n",
      "The classification loss after processing this batch is:  0.07117487490177155\n",
      "The representation loss after processing this batch is:  0.003193289041519165\n",
      "\n",
      "The classification loss after processing this batch is:  0.21139417588710785\n",
      "The representation loss after processing this batch is:  0.003244347870349884\n",
      "\n",
      "The classification loss after processing this batch is:  0.18855775892734528\n",
      "The representation loss after processing this batch is:  0.00276300311088562\n",
      "\n",
      "The classification loss after processing this batch is:  0.21090398728847504\n",
      "The representation loss after processing this batch is:  0.0027412883937358856\n",
      "\n",
      "The classification loss after processing this batch is:  0.13024812936782837\n",
      "The representation loss after processing this batch is:  0.0027713775634765625\n",
      "\n",
      "The classification loss after processing this batch is:  0.09982635825872421\n",
      "The representation loss after processing this batch is:  0.002605341374874115\n",
      "\n",
      "The classification loss after processing this batch is:  0.12707366049289703\n",
      "The representation loss after processing this batch is:  0.0028070881962776184\n",
      "\n",
      "The classification loss after processing this batch is:  0.17588292062282562\n",
      "The representation loss after processing this batch is:  0.0028734803199768066\n",
      "\n",
      "The classification loss after processing this batch is:  0.09222245961427689\n",
      "The representation loss after processing this batch is:  0.0026339590549468994\n",
      "\n",
      "The classification loss after processing this batch is:  0.03795822709798813\n",
      "The representation loss after processing this batch is:  0.0023789703845977783\n",
      "\n",
      "The classification loss after processing this batch is:  0.2255268096923828\n",
      "The representation loss after processing this batch is:  0.0028757229447364807\n",
      "\n",
      "The classification loss after processing this batch is:  0.2286011129617691\n",
      "The representation loss after processing this batch is:  0.0025410503149032593\n",
      "\n",
      "The classification loss after processing this batch is:  0.12450528889894485\n",
      "The representation loss after processing this batch is:  0.002474769949913025\n",
      "\n",
      "The classification loss after processing this batch is:  0.26527759432792664\n",
      "The representation loss after processing this batch is:  0.002514198422431946\n",
      "\n",
      "The classification loss after processing this batch is:  0.2672024965286255\n",
      "The representation loss after processing this batch is:  0.0028338655829429626\n",
      "\n",
      "The classification loss after processing this batch is:  0.34219983220100403\n",
      "The representation loss after processing this batch is:  0.002583622932434082\n",
      "\n",
      "The classification loss after processing this batch is:  0.17185112833976746\n",
      "The representation loss after processing this batch is:  0.0026949644088745117\n",
      "\n",
      "The classification loss after processing this batch is:  0.10591401904821396\n",
      "The representation loss after processing this batch is:  0.00263398140668869\n",
      "\n",
      "The classification loss after processing this batch is:  0.17834225296974182\n",
      "The representation loss after processing this batch is:  0.002823278307914734\n",
      "\n",
      "The classification loss after processing this batch is:  0.11137530952692032\n",
      "The representation loss after processing this batch is:  0.0027116909623146057\n",
      "\n",
      "The classification loss after processing this batch is:  0.08116225153207779\n",
      "The representation loss after processing this batch is:  0.002809680998325348\n",
      "\n",
      "The classification loss after processing this batch is:  0.09730204939842224\n",
      "The representation loss after processing this batch is:  0.0025878511369228363\n",
      "\n",
      "The classification loss after processing this batch is:  0.06595495343208313\n",
      "The representation loss after processing this batch is:  0.0025174468755722046\n",
      "\n",
      "The classification loss after processing this batch is:  0.04281673580408096\n",
      "The representation loss after processing this batch is:  0.0031399503350257874\n",
      "\n",
      "The classification loss after processing this batch is:  0.15421204268932343\n",
      "The representation loss after processing this batch is:  0.002772293984889984\n",
      "\n",
      "The classification loss after processing this batch is:  0.1877450942993164\n",
      "The representation loss after processing this batch is:  0.0025122761726379395\n",
      "\n",
      "The classification loss after processing this batch is:  0.08357533812522888\n",
      "The representation loss after processing this batch is:  0.002947673201560974\n",
      "\n",
      "The classification loss after processing this batch is:  0.1064327210187912\n",
      "The representation loss after processing this batch is:  0.0025282278656959534\n",
      "\n",
      "The classification loss after processing this batch is:  0.1301700323820114\n",
      "The representation loss after processing this batch is:  0.002624407410621643\n",
      "\n",
      "The classification loss after processing this batch is:  0.0444268062710762\n",
      "The representation loss after processing this batch is:  0.002634786069393158\n",
      "\n",
      "The classification loss after processing this batch is:  0.23866812884807587\n",
      "The representation loss after processing this batch is:  0.002613566815853119\n",
      "\n",
      "The classification loss after processing this batch is:  0.11119910329580307\n",
      "The representation loss after processing this batch is:  0.002441391348838806\n",
      "\n",
      "The classification loss after processing this batch is:  0.2663758099079132\n",
      "The representation loss after processing this batch is:  0.002615649253129959\n",
      "\n",
      "The classification loss after processing this batch is:  0.1515035331249237\n",
      "The representation loss after processing this batch is:  0.0027788281440734863\n",
      "\n",
      "The classification loss after processing this batch is:  0.1771966964006424\n",
      "The representation loss after processing this batch is:  0.002639811486005783\n",
      "\n",
      "The classification loss after processing this batch is:  0.046072881668806076\n",
      "The representation loss after processing this batch is:  0.002864450216293335\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.05852150171995163\n",
      "The representation loss after processing this batch is:  0.0025170743465423584\n",
      "\n",
      "The classification loss after processing this batch is:  0.16568459570407867\n",
      "The representation loss after processing this batch is:  0.0025676488876342773\n",
      "\n",
      "The classification loss after processing this batch is:  0.06942501664161682\n",
      "The representation loss after processing this batch is:  0.00302731990814209\n",
      "\n",
      "The classification loss after processing this batch is:  0.15938276052474976\n",
      "The representation loss after processing this batch is:  0.002827078104019165\n",
      "\n",
      "The classification loss after processing this batch is:  0.10942713916301727\n",
      "The representation loss after processing this batch is:  0.0029281824827194214\n",
      "\n",
      "The classification loss after processing this batch is:  0.1069084033370018\n",
      "The representation loss after processing this batch is:  0.0031078755855560303\n",
      "\n",
      "The classification loss after processing this batch is:  0.16877469420433044\n",
      "The representation loss after processing this batch is:  0.002641931176185608\n",
      "\n",
      "The classification loss after processing this batch is:  0.09053980559110641\n",
      "The representation loss after processing this batch is:  0.0029960796236991882\n",
      "\n",
      "The classification loss after processing this batch is:  0.13287030160427094\n",
      "The representation loss after processing this batch is:  0.0029869452118873596\n",
      "\n",
      "The classification loss after processing this batch is:  0.22842217981815338\n",
      "The representation loss after processing this batch is:  0.0028793811798095703\n",
      "\n",
      "The classification loss after processing this batch is:  0.15783637762069702\n",
      "The representation loss after processing this batch is:  0.002986133098602295\n",
      "\n",
      "The classification loss after processing this batch is:  0.23063825070858002\n",
      "The representation loss after processing this batch is:  0.002563297748565674\n",
      "\n",
      "The classification loss after processing this batch is:  0.2138592153787613\n",
      "The representation loss after processing this batch is:  0.0027414634823799133\n",
      "\n",
      "The classification loss after processing this batch is:  0.16593049466609955\n",
      "The representation loss after processing this batch is:  0.002501972019672394\n",
      "\n",
      "The classification loss after processing this batch is:  0.10575338453054428\n",
      "The representation loss after processing this batch is:  0.002769380807876587\n",
      "\n",
      "The classification loss after processing this batch is:  0.07650384306907654\n",
      "The representation loss after processing this batch is:  0.0026050880551338196\n",
      "\n",
      "The classification loss after processing this batch is:  0.09753932803869247\n",
      "The representation loss after processing this batch is:  0.0026542171835899353\n",
      "\n",
      "The classification loss after processing this batch is:  0.07117734849452972\n",
      "The representation loss after processing this batch is:  0.002980366349220276\n",
      "\n",
      "The classification loss after processing this batch is:  0.12103449553251266\n",
      "The representation loss after processing this batch is:  0.002272002398967743\n",
      "\n",
      "The classification loss after processing this batch is:  0.124398373067379\n",
      "The representation loss after processing this batch is:  0.0026809945702552795\n",
      "\n",
      "The classification loss after processing this batch is:  0.12761788070201874\n",
      "The representation loss after processing this batch is:  0.0029879510402679443\n",
      "\n",
      "The classification loss after processing this batch is:  0.09830127656459808\n",
      "The representation loss after processing this batch is:  0.0026652663946151733\n",
      "\n",
      "The classification loss after processing this batch is:  0.16644133627414703\n",
      "The representation loss after processing this batch is:  0.0023948997259140015\n",
      "\n",
      "The classification loss after processing this batch is:  0.0899767205119133\n",
      "The representation loss after processing this batch is:  0.002561122179031372\n",
      "\n",
      "The classification loss after processing this batch is:  0.16630207002162933\n",
      "The representation loss after processing this batch is:  0.0027252286672592163\n",
      "\n",
      "The classification loss after processing this batch is:  0.1604226976633072\n",
      "The representation loss after processing this batch is:  0.0026513636112213135\n",
      "\n",
      "The classification loss after processing this batch is:  0.1283419281244278\n",
      "The representation loss after processing this batch is:  0.0028911828994750977\n",
      "\n",
      "The classification loss after processing this batch is:  0.09042476862668991\n",
      "The representation loss after processing this batch is:  0.003001771867275238\n",
      "\n",
      "The classification loss after processing this batch is:  0.2059343308210373\n",
      "The representation loss after processing this batch is:  0.0028529614210128784\n",
      "\n",
      "The classification loss after processing this batch is:  0.0748995766043663\n",
      "The representation loss after processing this batch is:  0.0026920735836029053\n",
      "\n",
      "The classification loss after processing this batch is:  0.0820927619934082\n",
      "The representation loss after processing this batch is:  0.0026249662041664124\n",
      "\n",
      "The classification loss after processing this batch is:  0.13522611558437347\n",
      "The representation loss after processing this batch is:  0.0026431381702423096\n",
      "\n",
      "The classification loss after processing this batch is:  0.07257979363203049\n",
      "The representation loss after processing this batch is:  0.0030210986733436584\n",
      "\n",
      "The classification loss after processing this batch is:  0.1526811271905899\n",
      "The representation loss after processing this batch is:  0.0024078376591205597\n",
      "\n",
      "The classification loss after processing this batch is:  0.19117705523967743\n",
      "The representation loss after processing this batch is:  0.0028170496225357056\n",
      "\n",
      "The classification loss after processing this batch is:  0.10549912601709366\n",
      "The representation loss after processing this batch is:  0.0029816702008247375\n",
      "\n",
      "The classification loss after processing this batch is:  0.10037099570035934\n",
      "The representation loss after processing this batch is:  0.003240622580051422\n",
      "\n",
      "The classification loss after processing this batch is:  0.09358089417219162\n",
      "The representation loss after processing this batch is:  0.0025966763496398926\n",
      "\n",
      "The classification loss after processing this batch is:  0.25774049758911133\n",
      "The representation loss after processing this batch is:  0.002919241786003113\n",
      "\n",
      "The classification loss after processing this batch is:  0.05826738104224205\n",
      "The representation loss after processing this batch is:  0.002746284008026123\n",
      "\n",
      "The classification loss after processing this batch is:  0.11096780747175217\n",
      "The representation loss after processing this batch is:  0.002843111753463745\n",
      "\n",
      "The classification loss after processing this batch is:  0.18498878180980682\n",
      "The representation loss after processing this batch is:  0.002582237124443054\n",
      "\n",
      "The classification loss after processing this batch is:  0.3420705497264862\n",
      "The representation loss after processing this batch is:  0.0027995631098747253\n",
      "\n",
      "The classification loss after processing this batch is:  0.10242261737585068\n",
      "The representation loss after processing this batch is:  0.002602219581604004\n",
      "\n",
      "The classification loss after processing this batch is:  0.1365639716386795\n",
      "The representation loss after processing this batch is:  0.0027065500617027283\n",
      "\n",
      "The classification loss after processing this batch is:  0.09246497601270676\n",
      "The representation loss after processing this batch is:  0.0027385205030441284\n",
      "\n",
      "The classification loss after processing this batch is:  0.044458094984292984\n",
      "The representation loss after processing this batch is:  0.002752557396888733\n",
      "\n",
      "The classification loss after processing this batch is:  0.15219657123088837\n",
      "The representation loss after processing this batch is:  0.0032060444355010986\n",
      "\n",
      "The classification loss after processing this batch is:  0.10060571879148483\n",
      "The representation loss after processing this batch is:  0.003476247191429138\n",
      "\n",
      "The classification loss after processing this batch is:  0.06629180908203125\n",
      "The representation loss after processing this batch is:  0.0029172301292419434\n",
      "\n",
      "The classification loss after processing this batch is:  0.0823376327753067\n",
      "The representation loss after processing this batch is:  0.0023543238639831543\n",
      "\n",
      "The classification loss after processing this batch is:  0.17466838657855988\n",
      "The representation loss after processing this batch is:  0.0024480782449245453\n",
      "\n",
      "The classification loss after processing this batch is:  0.14662818610668182\n",
      "The representation loss after processing this batch is:  0.002729453146457672\n",
      "\n",
      "The classification loss after processing this batch is:  0.08734893053770065\n",
      "The representation loss after processing this batch is:  0.002438679337501526\n",
      "\n",
      "The classification loss after processing this batch is:  0.11658604443073273\n",
      "The representation loss after processing this batch is:  0.002762317657470703\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.19328604638576508\n",
      "The representation loss after processing this batch is:  0.00240490585565567\n",
      "\n",
      "The classification loss after processing this batch is:  0.17834778130054474\n",
      "The representation loss after processing this batch is:  0.0026947930455207825\n",
      "\n",
      "The classification loss after processing this batch is:  0.19781328737735748\n",
      "The representation loss after processing this batch is:  0.002512909471988678\n",
      "\n",
      "The classification loss after processing this batch is:  0.15483751893043518\n",
      "The representation loss after processing this batch is:  0.0028958171606063843\n",
      "\n",
      "The classification loss after processing this batch is:  0.23886850476264954\n",
      "The representation loss after processing this batch is:  0.0028191134333610535\n",
      "\n",
      "The classification loss after processing this batch is:  0.10567399859428406\n",
      "The representation loss after processing this batch is:  0.0025921761989593506\n",
      "\n",
      "The classification loss after processing this batch is:  0.08959320187568665\n",
      "The representation loss after processing this batch is:  0.00301467627286911\n",
      "\n",
      "The classification loss after processing this batch is:  0.06014537066221237\n",
      "The representation loss after processing this batch is:  0.002646893262863159\n",
      "\n",
      "The classification loss after processing this batch is:  0.08815634995698929\n",
      "The representation loss after processing this batch is:  0.0026299357414245605\n",
      "\n",
      "The classification loss after processing this batch is:  0.227294921875\n",
      "The representation loss after processing this batch is:  0.002759363502264023\n",
      "\n",
      "The classification loss after processing this batch is:  0.1499255746603012\n",
      "The representation loss after processing this batch is:  0.00316755473613739\n",
      "\n",
      "The classification loss after processing this batch is:  0.060267407447099686\n",
      "The representation loss after processing this batch is:  0.0025312677025794983\n",
      "\n",
      "The classification loss after processing this batch is:  0.04466896876692772\n",
      "The representation loss after processing this batch is:  0.0030418336391448975\n",
      "\n",
      "The classification loss after processing this batch is:  0.053279466927051544\n",
      "The representation loss after processing this batch is:  0.003249041736125946\n",
      "\n",
      "The classification loss after processing this batch is:  0.08282143622636795\n",
      "The representation loss after processing this batch is:  0.0036268383264541626\n",
      "\n",
      "The classification loss after processing this batch is:  0.09873264282941818\n",
      "The representation loss after processing this batch is:  0.003093443810939789\n",
      "\n",
      "The classification loss after processing this batch is:  0.06760319322347641\n",
      "The representation loss after processing this batch is:  0.0029742494225502014\n",
      "\n",
      "The classification loss after processing this batch is:  0.04078960418701172\n",
      "The representation loss after processing this batch is:  0.0029600709676742554\n",
      "\n",
      "The classification loss after processing this batch is:  0.06566707044839859\n",
      "The representation loss after processing this batch is:  0.0033183246850967407\n",
      "\n",
      "The classification loss after processing this batch is:  0.0926264300942421\n",
      "The representation loss after processing this batch is:  0.0036435648798942566\n",
      "\n",
      "The classification loss after processing this batch is:  0.027541279792785645\n",
      "The representation loss after processing this batch is:  0.00373966246843338\n",
      "\n",
      "The classification loss after processing this batch is:  0.05295554921030998\n",
      "The representation loss after processing this batch is:  0.0031971558928489685\n",
      "\n",
      "The classification loss after processing this batch is:  0.16948910057544708\n",
      "The representation loss after processing this batch is:  0.0029767602682113647\n",
      "\n",
      "The classification loss after processing this batch is:  0.04722129553556442\n",
      "The representation loss after processing this batch is:  0.003297865390777588\n",
      "\n",
      "The classification loss after processing this batch is:  0.023535745218396187\n",
      "The representation loss after processing this batch is:  0.0030569061636924744\n",
      "\n",
      "The classification loss after processing this batch is:  0.040254492312669754\n",
      "The representation loss after processing this batch is:  0.0032006055116653442\n",
      "\n",
      "The classification loss after processing this batch is:  0.03996701538562775\n",
      "The representation loss after processing this batch is:  0.003548465669155121\n",
      "\n",
      "The classification loss after processing this batch is:  0.0447639599442482\n",
      "The representation loss after processing this batch is:  0.003011070191860199\n",
      "\n",
      "The classification loss after processing this batch is:  0.03532388061285019\n",
      "The representation loss after processing this batch is:  0.00341004878282547\n",
      "\n",
      "The classification loss after processing this batch is:  0.025634558871388435\n",
      "The representation loss after processing this batch is:  0.003704354166984558\n",
      "\n",
      "The classification loss after processing this batch is:  0.2722497284412384\n",
      "The representation loss after processing this batch is:  0.003638923168182373\n",
      "\n",
      "The classification loss after processing this batch is:  0.2937091886997223\n",
      "The representation loss after processing this batch is:  0.0035125017166137695\n",
      "\n",
      "The classification loss after processing this batch is:  0.2300674021244049\n",
      "The representation loss after processing this batch is:  0.0036555975675582886\n",
      "\n",
      "The classification loss after processing this batch is:  0.04883219674229622\n",
      "The representation loss after processing this batch is:  0.0026883333921432495\n",
      "\n",
      "The classification loss after processing this batch is:  0.02973197214305401\n",
      "The representation loss after processing this batch is:  0.00336601585149765\n",
      "\n",
      "The classification loss after processing this batch is:  0.02408592216670513\n",
      "The representation loss after processing this batch is:  0.0022741034626960754\n",
      "\n",
      "The classification loss after processing this batch is:  0.127083882689476\n",
      "The representation loss after processing this batch is:  0.0025675371289253235\n",
      "\n",
      "The classification loss after processing this batch is:  0.32688385248184204\n",
      "The representation loss after processing this batch is:  0.0029562562704086304\n",
      "\n",
      "The classification loss after processing this batch is:  0.0972512885928154\n",
      "The representation loss after processing this batch is:  0.0026674941182136536\n",
      "\n",
      "The classification loss after processing this batch is:  0.07319364696741104\n",
      "The representation loss after processing this batch is:  0.003154970705509186\n",
      "\n",
      "The classification loss after processing this batch is:  0.06454641371965408\n",
      "The representation loss after processing this batch is:  0.003150753676891327\n",
      "\n",
      "The classification loss after processing this batch is:  0.06305096298456192\n",
      "The representation loss after processing this batch is:  0.0036729946732521057\n",
      "\n",
      "The classification loss after processing this batch is:  0.11596573889255524\n",
      "The representation loss after processing this batch is:  0.0025321394205093384\n",
      "\n",
      "The classification loss after processing this batch is:  0.05780046433210373\n",
      "The representation loss after processing this batch is:  0.002662956714630127\n",
      "\n",
      "The classification loss after processing this batch is:  0.10989212244749069\n",
      "The representation loss after processing this batch is:  0.0026967711746692657\n",
      "\n",
      "The classification loss after processing this batch is:  0.09778952598571777\n",
      "The representation loss after processing this batch is:  0.00268414244055748\n",
      "\n",
      "The classification loss after processing this batch is:  0.18865276873111725\n",
      "The representation loss after processing this batch is:  0.002781420946121216\n",
      "\n",
      "The classification loss after processing this batch is:  0.08612189441919327\n",
      "The representation loss after processing this batch is:  0.003037087619304657\n",
      "\n",
      "The classification loss after processing this batch is:  0.09130553901195526\n",
      "The representation loss after processing this batch is:  0.0031601935625076294\n",
      "\n",
      "The classification loss after processing this batch is:  0.16109295189380646\n",
      "The representation loss after processing this batch is:  0.0026405304670333862\n",
      "\n",
      "The classification loss after processing this batch is:  0.1514265090227127\n",
      "The representation loss after processing this batch is:  0.0024832338094711304\n",
      "\n",
      "The classification loss after processing this batch is:  0.09653104096651077\n",
      "The representation loss after processing this batch is:  0.002727493643760681\n",
      "\n",
      "The classification loss after processing this batch is:  0.17555637657642365\n",
      "The representation loss after processing this batch is:  0.0025660619139671326\n",
      "\n",
      "The classification loss after processing this batch is:  0.123426154255867\n",
      "The representation loss after processing this batch is:  0.002719912678003311\n",
      "\n",
      "The classification loss after processing this batch is:  0.14299549162387848\n",
      "The representation loss after processing this batch is:  0.0031454265117645264\n",
      "\n",
      "The classification loss after processing this batch is:  0.08642447739839554\n",
      "The representation loss after processing this batch is:  0.002729974687099457\n",
      "\n",
      "The classification loss after processing this batch is:  0.2532908022403717\n",
      "The representation loss after processing this batch is:  0.0026381537318229675\n",
      "\n",
      "The classification loss after processing this batch is:  0.11079848557710648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.0024698153138160706\n",
      "\n",
      "The classification loss after processing this batch is:  0.11886367946863174\n",
      "The representation loss after processing this batch is:  0.002756252884864807\n",
      "\n",
      "The classification loss after processing this batch is:  0.22467222809791565\n",
      "The representation loss after processing this batch is:  0.002879541367292404\n",
      "\n",
      "The classification loss after processing this batch is:  0.15270286798477173\n",
      "The representation loss after processing this batch is:  0.0028147846460342407\n",
      "\n",
      "The classification loss after processing this batch is:  0.08385791629552841\n",
      "The representation loss after processing this batch is:  0.002876643091440201\n",
      "\n",
      "The classification loss after processing this batch is:  0.2601419687271118\n",
      "The representation loss after processing this batch is:  0.003530532121658325\n",
      "\n",
      "The classification loss after processing this batch is:  0.14488887786865234\n",
      "The representation loss after processing this batch is:  0.0028875917196273804\n",
      "\n",
      "The classification loss after processing this batch is:  0.31457504630088806\n",
      "The representation loss after processing this batch is:  0.002661377191543579\n",
      "\n",
      "The classification loss after processing this batch is:  0.10095588117837906\n",
      "The representation loss after processing this batch is:  0.002402655780315399\n",
      "\n",
      "The classification loss after processing this batch is:  0.08305918425321579\n",
      "The representation loss after processing this batch is:  0.002628602087497711\n",
      "\n",
      "The classification loss after processing this batch is:  0.09238763898611069\n",
      "The representation loss after processing this batch is:  0.0024623945355415344\n",
      "\n",
      "The classification loss after processing this batch is:  0.1396864503622055\n",
      "The representation loss after processing this batch is:  0.0025007277727127075\n",
      "\n",
      "The classification loss after processing this batch is:  0.10636036843061447\n",
      "The representation loss after processing this batch is:  0.0027725398540496826\n",
      "\n",
      "The classification loss after processing this batch is:  0.06450662016868591\n",
      "The representation loss after processing this batch is:  0.002741582691669464\n",
      "\n",
      "The classification loss after processing this batch is:  0.04027955234050751\n",
      "The representation loss after processing this batch is:  0.002627357840538025\n",
      "\n",
      "The classification loss after processing this batch is:  0.06414411962032318\n",
      "The representation loss after processing this batch is:  0.002567138522863388\n",
      "\n",
      "The classification loss after processing this batch is:  0.09352637827396393\n",
      "The representation loss after processing this batch is:  0.002564951777458191\n",
      "\n",
      "The classification loss after processing this batch is:  0.1706772744655609\n",
      "The representation loss after processing this batch is:  0.002953171730041504\n",
      "\n",
      "The classification loss after processing this batch is:  0.1040157824754715\n",
      "The representation loss after processing this batch is:  0.0029487498104572296\n",
      "\n",
      "The classification loss after processing this batch is:  0.11528671532869339\n",
      "The representation loss after processing this batch is:  0.0026185810565948486\n",
      "\n",
      "The classification loss after processing this batch is:  0.05447773635387421\n",
      "The representation loss after processing this batch is:  0.0025546252727508545\n",
      "\n",
      "The classification loss after processing this batch is:  0.08273351937532425\n",
      "The representation loss after processing this batch is:  0.002730082720518112\n",
      "\n",
      "The classification loss after processing this batch is:  0.09706339985132217\n",
      "The representation loss after processing this batch is:  0.0025741159915924072\n",
      "\n",
      "The classification loss after processing this batch is:  0.0541241355240345\n",
      "The representation loss after processing this batch is:  0.0026894211769104004\n",
      "\n",
      "The classification loss after processing this batch is:  0.1043025404214859\n",
      "The representation loss after processing this batch is:  0.002688668668270111\n",
      "\n",
      "The classification loss after processing this batch is:  0.20028091967105865\n",
      "The representation loss after processing this batch is:  0.0030668824911117554\n",
      "\n",
      "The classification loss after processing this batch is:  0.13534198701381683\n",
      "The representation loss after processing this batch is:  0.0028782710433006287\n",
      "\n",
      "The classification loss after processing this batch is:  0.1301652491092682\n",
      "The representation loss after processing this batch is:  0.002381104975938797\n",
      "\n",
      "The classification loss after processing this batch is:  0.15400081872940063\n",
      "The representation loss after processing this batch is:  0.002607010304927826\n",
      "\n",
      "The classification loss after processing this batch is:  0.0999395102262497\n",
      "The representation loss after processing this batch is:  0.002439882606267929\n",
      "\n",
      "The classification loss after processing this batch is:  0.09528624266386032\n",
      "The representation loss after processing this batch is:  0.002521321177482605\n",
      "\n",
      "The classification loss after processing this batch is:  0.21790853142738342\n",
      "The representation loss after processing this batch is:  0.003142125904560089\n",
      "\n",
      "The classification loss after processing this batch is:  0.07194434106349945\n",
      "The representation loss after processing this batch is:  0.0027568601071834564\n",
      "\n",
      "The classification loss after processing this batch is:  0.1537523865699768\n",
      "The representation loss after processing this batch is:  0.0025755614042282104\n",
      "\n",
      "The classification loss after processing this batch is:  0.09371377527713776\n",
      "The representation loss after processing this batch is:  0.002642575651407242\n",
      "\n",
      "The classification loss after processing this batch is:  0.12711632251739502\n",
      "The representation loss after processing this batch is:  0.002485748380422592\n",
      "\n",
      "The classification loss after processing this batch is:  0.15040220320224762\n",
      "The representation loss after processing this batch is:  0.002769049257040024\n",
      "\n",
      "The classification loss after processing this batch is:  0.07619552314281464\n",
      "The representation loss after processing this batch is:  0.0027173012495040894\n",
      "\n",
      "The classification loss after processing this batch is:  0.11403186619281769\n",
      "The representation loss after processing this batch is:  0.003020346164703369\n",
      "\n",
      "The classification loss after processing this batch is:  0.12686511874198914\n",
      "The representation loss after processing this batch is:  0.0030463114380836487\n",
      "\n",
      "The classification loss after processing this batch is:  0.14478202164173126\n",
      "The representation loss after processing this batch is:  0.002682402729988098\n",
      "\n",
      "The classification loss after processing this batch is:  0.13585689663887024\n",
      "The representation loss after processing this batch is:  0.002398356795310974\n",
      "\n",
      "The classification loss after processing this batch is:  0.10701217502355576\n",
      "The representation loss after processing this batch is:  0.0030236095190048218\n",
      "\n",
      "The classification loss after processing this batch is:  0.17722028493881226\n",
      "The representation loss after processing this batch is:  0.0028774216771125793\n",
      "\n",
      "The classification loss after processing this batch is:  0.07511986047029495\n",
      "The representation loss after processing this batch is:  0.00239717960357666\n",
      "\n",
      "The classification loss after processing this batch is:  0.07079216837882996\n",
      "The representation loss after processing this batch is:  0.0024605803191661835\n",
      "\n",
      "The classification loss after processing this batch is:  0.16158077120780945\n",
      "The representation loss after processing this batch is:  0.002692192792892456\n",
      "\n",
      "The classification loss after processing this batch is:  0.16538909077644348\n",
      "The representation loss after processing this batch is:  0.0024350732564926147\n",
      "\n",
      "The classification loss after processing this batch is:  0.08322551101446152\n",
      "The representation loss after processing this batch is:  0.002566128969192505\n",
      "\n",
      "The classification loss after processing this batch is:  0.09378443658351898\n",
      "The representation loss after processing this batch is:  0.0024391040205955505\n",
      "\n",
      "The classification loss after processing this batch is:  0.05758674442768097\n",
      "The representation loss after processing this batch is:  0.0025229230523109436\n",
      "\n",
      "The classification loss after processing this batch is:  0.10670822113752365\n",
      "The representation loss after processing this batch is:  0.0027513355016708374\n",
      "\n",
      "The classification loss after processing this batch is:  0.13540934026241302\n",
      "The representation loss after processing this batch is:  0.002270050346851349\n",
      "\n",
      "The classification loss after processing this batch is:  0.07449056953191757\n",
      "The representation loss after processing this batch is:  0.0028176382184028625\n",
      "\n",
      "The classification loss after processing this batch is:  0.18196915090084076\n",
      "The representation loss after processing this batch is:  0.002549104392528534\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14156658947467804\n",
      "The representation loss after processing this batch is:  0.002504222095012665\n",
      "\n",
      "The classification loss after processing this batch is:  0.12287921458482742\n",
      "The representation loss after processing this batch is:  0.0026963576674461365\n",
      "\n",
      "The classification loss after processing this batch is:  0.08348876982927322\n",
      "The representation loss after processing this batch is:  0.0023107677698135376\n",
      "\n",
      "The classification loss after processing this batch is:  0.07520385086536407\n",
      "The representation loss after processing this batch is:  0.0027287304401397705\n",
      "\n",
      "The classification loss after processing this batch is:  0.13749001920223236\n",
      "The representation loss after processing this batch is:  0.00252523273229599\n",
      "\n",
      "The classification loss after processing this batch is:  0.1760486513376236\n",
      "The representation loss after processing this batch is:  0.002357199788093567\n",
      "\n",
      "The classification loss after processing this batch is:  0.09375523030757904\n",
      "The representation loss after processing this batch is:  0.002475135028362274\n",
      "\n",
      "The classification loss after processing this batch is:  0.2780390679836273\n",
      "The representation loss after processing this batch is:  0.0024779364466667175\n",
      "\n",
      "The classification loss after processing this batch is:  0.12433301657438278\n",
      "The representation loss after processing this batch is:  0.002454284578561783\n",
      "\n",
      "The classification loss after processing this batch is:  0.07232486456632614\n",
      "The representation loss after processing this batch is:  0.003163382411003113\n",
      "\n",
      "The classification loss after processing this batch is:  0.12511393427848816\n",
      "The representation loss after processing this batch is:  0.0023898929357528687\n",
      "\n",
      "The classification loss after processing this batch is:  0.07150904834270477\n",
      "The representation loss after processing this batch is:  0.0027153566479682922\n",
      "\n",
      "The classification loss after processing this batch is:  0.2761591672897339\n",
      "The representation loss after processing this batch is:  0.002915419638156891\n",
      "\n",
      "The classification loss after processing this batch is:  0.135501429438591\n",
      "The representation loss after processing this batch is:  0.0024746879935264587\n",
      "\n",
      "The classification loss after processing this batch is:  0.11913442611694336\n",
      "The representation loss after processing this batch is:  0.0023041218519210815\n",
      "\n",
      "The classification loss after processing this batch is:  0.3033025860786438\n",
      "The representation loss after processing this batch is:  0.0023097768425941467\n",
      "\n",
      "The classification loss after processing this batch is:  0.14603303372859955\n",
      "The representation loss after processing this batch is:  0.002715863287448883\n",
      "\n",
      "The classification loss after processing this batch is:  0.07993320375680923\n",
      "The representation loss after processing this batch is:  0.002618260681629181\n",
      "\n",
      "The classification loss after processing this batch is:  0.13129915297031403\n",
      "The representation loss after processing this batch is:  0.0023623332381248474\n",
      "\n",
      "The classification loss after processing this batch is:  0.13734979927539825\n",
      "The representation loss after processing this batch is:  0.0027084872126579285\n",
      "\n",
      "The classification loss after processing this batch is:  0.168184295296669\n",
      "The representation loss after processing this batch is:  0.002925865352153778\n",
      "\n",
      "The classification loss after processing this batch is:  0.06282711029052734\n",
      "The representation loss after processing this batch is:  0.0025768280029296875\n",
      "\n",
      "The classification loss after processing this batch is:  0.11590846627950668\n",
      "The representation loss after processing this batch is:  0.002615131437778473\n",
      "\n",
      "The classification loss after processing this batch is:  0.1636459082365036\n",
      "The representation loss after processing this batch is:  0.002603679895401001\n",
      "\n",
      "The classification loss after processing this batch is:  0.16283611953258514\n",
      "The representation loss after processing this batch is:  0.00292138010263443\n",
      "\n",
      "The classification loss after processing this batch is:  0.18993492424488068\n",
      "The representation loss after processing this batch is:  0.0025207772850990295\n",
      "\n",
      "The classification loss after processing this batch is:  0.21324892342090607\n",
      "The representation loss after processing this batch is:  0.003169804811477661\n",
      "\n",
      "The classification loss after processing this batch is:  0.15825419127941132\n",
      "The representation loss after processing this batch is:  0.00300704687833786\n",
      "\n",
      "The classification loss after processing this batch is:  0.08231233060359955\n",
      "The representation loss after processing this batch is:  0.002831973135471344\n",
      "\n",
      "The classification loss after processing this batch is:  0.09836447238922119\n",
      "The representation loss after processing this batch is:  0.0026065558195114136\n",
      "\n",
      "The classification loss after processing this batch is:  0.05941611900925636\n",
      "The representation loss after processing this batch is:  0.0025460124015808105\n",
      "\n",
      "The classification loss after processing this batch is:  0.12547951936721802\n",
      "The representation loss after processing this batch is:  0.002536207437515259\n",
      "\n",
      "The classification loss after processing this batch is:  0.1654445081949234\n",
      "The representation loss after processing this batch is:  0.0026305541396141052\n",
      "\n",
      "The classification loss after processing this batch is:  0.22734645009040833\n",
      "The representation loss after processing this batch is:  0.0027631819248199463\n",
      "\n",
      "The classification loss after processing this batch is:  0.26784709095954895\n",
      "The representation loss after processing this batch is:  0.0028418004512786865\n",
      "\n",
      "The classification loss after processing this batch is:  0.09074322879314423\n",
      "The representation loss after processing this batch is:  0.002803504467010498\n",
      "\n",
      "The classification loss after processing this batch is:  0.11547866463661194\n",
      "The representation loss after processing this batch is:  0.002855531871318817\n",
      "\n",
      "The classification loss after processing this batch is:  0.17303848266601562\n",
      "The representation loss after processing this batch is:  0.0025387778878211975\n",
      "\n",
      "The classification loss after processing this batch is:  0.059089526534080505\n",
      "The representation loss after processing this batch is:  0.002946123480796814\n",
      "\n",
      "The classification loss after processing this batch is:  0.07212670892477036\n",
      "The representation loss after processing this batch is:  0.0028501227498054504\n",
      "\n",
      "The classification loss after processing this batch is:  0.1512596756219864\n",
      "The representation loss after processing this batch is:  0.002417363226413727\n",
      "\n",
      "The classification loss after processing this batch is:  0.11835797876119614\n",
      "The representation loss after processing this batch is:  0.0034408867359161377\n",
      "\n",
      "The classification loss after processing this batch is:  0.0963614284992218\n",
      "The representation loss after processing this batch is:  0.0026922449469566345\n",
      "\n",
      "The classification loss after processing this batch is:  0.2452705353498459\n",
      "The representation loss after processing this batch is:  0.0038818493485450745\n",
      "\n",
      "The classification loss after processing this batch is:  0.28193333745002747\n",
      "The representation loss after processing this batch is:  0.002399913966655731\n",
      "\n",
      "The classification loss after processing this batch is:  0.1452881246805191\n",
      "The representation loss after processing this batch is:  0.002718806266784668\n",
      "\n",
      "The classification loss after processing this batch is:  0.240072563290596\n",
      "The representation loss after processing this batch is:  0.002573668956756592\n",
      "\n",
      "The classification loss after processing this batch is:  0.15030156075954437\n",
      "The representation loss after processing this batch is:  0.002693425863981247\n",
      "\n",
      "The classification loss after processing this batch is:  0.05545731261372566\n",
      "The representation loss after processing this batch is:  0.002706911414861679\n",
      "\n",
      "The classification loss after processing this batch is:  0.14961664378643036\n",
      "The representation loss after processing this batch is:  0.0024900510907173157\n",
      "\n",
      "The classification loss after processing this batch is:  0.3616950213909149\n",
      "The representation loss after processing this batch is:  0.0034837424755096436\n",
      "\n",
      "The classification loss after processing this batch is:  0.19133931398391724\n",
      "The representation loss after processing this batch is:  0.003167722374200821\n",
      "\n",
      "The classification loss after processing this batch is:  0.07710602879524231\n",
      "The representation loss after processing this batch is:  0.0027999356389045715\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08247461169958115\n",
      "The representation loss after processing this batch is:  0.0028322935104370117\n",
      "\n",
      "The classification loss after processing this batch is:  0.06538267433643341\n",
      "The representation loss after processing this batch is:  0.002969317138195038\n",
      "\n",
      "The classification loss after processing this batch is:  0.0982220321893692\n",
      "The representation loss after processing this batch is:  0.003188185393810272\n",
      "\n",
      "The classification loss after processing this batch is:  0.10683798044919968\n",
      "The representation loss after processing this batch is:  0.002842061221599579\n",
      "\n",
      "The classification loss after processing this batch is:  0.15322443842887878\n",
      "The representation loss after processing this batch is:  0.0028059594333171844\n",
      "\n",
      "The classification loss after processing this batch is:  0.12736912071704865\n",
      "The representation loss after processing this batch is:  0.002517193555831909\n",
      "\n",
      "The classification loss after processing this batch is:  0.21665678918361664\n",
      "The representation loss after processing this batch is:  0.0029957666993141174\n",
      "\n",
      "The classification loss after processing this batch is:  0.10251176357269287\n",
      "The representation loss after processing this batch is:  0.002424221485853195\n",
      "\n",
      "The classification loss after processing this batch is:  0.1439683437347412\n",
      "The representation loss after processing this batch is:  0.002268340438604355\n",
      "\n",
      "The classification loss after processing this batch is:  0.17357482016086578\n",
      "The representation loss after processing this batch is:  0.0026210248470306396\n",
      "\n",
      "The classification loss after processing this batch is:  0.1469719409942627\n",
      "The representation loss after processing this batch is:  0.0025926679372787476\n",
      "\n",
      "The classification loss after processing this batch is:  0.11451148986816406\n",
      "The representation loss after processing this batch is:  0.0025453120470046997\n",
      "\n",
      "The classification loss after processing this batch is:  0.2115667313337326\n",
      "The representation loss after processing this batch is:  0.002574741840362549\n",
      "\n",
      "The classification loss after processing this batch is:  0.19590768218040466\n",
      "The representation loss after processing this batch is:  0.002841949462890625\n",
      "\n",
      "The classification loss after processing this batch is:  0.14343604445457458\n",
      "The representation loss after processing this batch is:  0.0025266706943511963\n",
      "\n",
      "The classification loss after processing this batch is:  0.1450493335723877\n",
      "The representation loss after processing this batch is:  0.002733662724494934\n",
      "\n",
      "The classification loss after processing this batch is:  0.19862040877342224\n",
      "The representation loss after processing this batch is:  0.0025978833436965942\n",
      "\n",
      "The classification loss after processing this batch is:  0.20264269411563873\n",
      "The representation loss after processing this batch is:  0.0026957690715789795\n",
      "\n",
      "The classification loss after processing this batch is:  0.17739734053611755\n",
      "The representation loss after processing this batch is:  0.003261759877204895\n",
      "\n",
      "The classification loss after processing this batch is:  0.1612837165594101\n",
      "The representation loss after processing this batch is:  0.003041081130504608\n",
      "\n",
      "The classification loss after processing this batch is:  0.1022973358631134\n",
      "The representation loss after processing this batch is:  0.0031337887048721313\n",
      "\n",
      "The classification loss after processing this batch is:  0.2583741545677185\n",
      "The representation loss after processing this batch is:  0.0029377341270446777\n",
      "\n",
      "The classification loss after processing this batch is:  0.25208982825279236\n",
      "The representation loss after processing this batch is:  0.002527926117181778\n",
      "\n",
      "The classification loss after processing this batch is:  0.26471301913261414\n",
      "The representation loss after processing this batch is:  0.0029337406158447266\n",
      "\n",
      "The classification loss after processing this batch is:  0.32473084330558777\n",
      "The representation loss after processing this batch is:  0.002449043095111847\n",
      "\n",
      "The classification loss after processing this batch is:  0.24779489636421204\n",
      "The representation loss after processing this batch is:  0.0024633854627609253\n",
      "\n",
      "The classification loss after processing this batch is:  0.10276307165622711\n",
      "The representation loss after processing this batch is:  0.0025146007537841797\n",
      "\n",
      "The classification loss after processing this batch is:  0.0985303595662117\n",
      "The representation loss after processing this batch is:  0.00252494215965271\n",
      "\n",
      "The classification loss after processing this batch is:  0.06924065947532654\n",
      "The representation loss after processing this batch is:  0.00295373797416687\n",
      "\n",
      "The classification loss after processing this batch is:  0.11792375147342682\n",
      "The representation loss after processing this batch is:  0.003286227583885193\n",
      "\n",
      "The classification loss after processing this batch is:  0.050191666930913925\n",
      "The representation loss after processing this batch is:  0.002874933183193207\n",
      "\n",
      "The classification loss after processing this batch is:  0.23499630391597748\n",
      "The representation loss after processing this batch is:  0.00365380197763443\n",
      "\n",
      "The classification loss after processing this batch is:  0.1532433182001114\n",
      "The representation loss after processing this batch is:  0.002625536173582077\n",
      "\n",
      "The classification loss after processing this batch is:  0.08814331889152527\n",
      "The representation loss after processing this batch is:  0.002823825925588608\n",
      "\n",
      "The classification loss after processing this batch is:  0.18220514059066772\n",
      "The representation loss after processing this batch is:  0.002358507364988327\n",
      "\n",
      "The classification loss after processing this batch is:  0.08055807650089264\n",
      "The representation loss after processing this batch is:  0.003079015761613846\n",
      "\n",
      "The classification loss after processing this batch is:  0.16402767598628998\n",
      "The representation loss after processing this batch is:  0.003274105489253998\n",
      "\n",
      "The classification loss after processing this batch is:  0.1930338591337204\n",
      "The representation loss after processing this batch is:  0.0034980475902557373\n",
      "\n",
      "The classification loss after processing this batch is:  0.12946449220180511\n",
      "The representation loss after processing this batch is:  0.0032400935888290405\n",
      "\n",
      "The classification loss after processing this batch is:  0.14696192741394043\n",
      "The representation loss after processing this batch is:  0.002308189868927002\n",
      "\n",
      "The classification loss after processing this batch is:  0.09736048430204391\n",
      "The representation loss after processing this batch is:  0.002473093569278717\n",
      "\n",
      "The classification loss after processing this batch is:  0.04246598109602928\n",
      "The representation loss after processing this batch is:  0.0026078149676322937\n",
      "\n",
      "The classification loss after processing this batch is:  0.0830288752913475\n",
      "The representation loss after processing this batch is:  0.002943269908428192\n",
      "\n",
      "The classification loss after processing this batch is:  0.08587697148323059\n",
      "The representation loss after processing this batch is:  0.002537161111831665\n",
      "\n",
      "The classification loss after processing this batch is:  0.11796602606773376\n",
      "The representation loss after processing this batch is:  0.002330102026462555\n",
      "\n",
      "The classification loss after processing this batch is:  0.13516981899738312\n",
      "The representation loss after processing this batch is:  0.002612963318824768\n",
      "\n",
      "The classification loss after processing this batch is:  0.1423562467098236\n",
      "The representation loss after processing this batch is:  0.00271742045879364\n",
      "\n",
      "The classification loss after processing this batch is:  0.3509744107723236\n",
      "The representation loss after processing this batch is:  0.003155633807182312\n",
      "\n",
      "The classification loss after processing this batch is:  0.2585858404636383\n",
      "The representation loss after processing this batch is:  0.0028547868132591248\n",
      "\n",
      "The classification loss after processing this batch is:  0.08624892681837082\n",
      "The representation loss after processing this batch is:  0.002550654113292694\n",
      "\n",
      "The classification loss after processing this batch is:  0.07120105624198914\n",
      "The representation loss after processing this batch is:  0.0029464587569236755\n",
      "\n",
      "The classification loss after processing this batch is:  0.08595708012580872\n",
      "The representation loss after processing this batch is:  0.002457551658153534\n",
      "\n",
      "The classification loss after processing this batch is:  0.0675894170999527\n",
      "The representation loss after processing this batch is:  0.002522401511669159\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.04267760366201401\n",
      "The representation loss after processing this batch is:  0.0029735714197158813\n",
      "\n",
      "The classification loss after processing this batch is:  0.06640785187482834\n",
      "The representation loss after processing this batch is:  0.0031590908765792847\n",
      "\n",
      "The classification loss after processing this batch is:  0.12403019517660141\n",
      "The representation loss after processing this batch is:  0.0024160444736480713\n",
      "\n",
      "The classification loss after processing this batch is:  0.1781480610370636\n",
      "The representation loss after processing this batch is:  0.002757050096988678\n",
      "\n",
      "The classification loss after processing this batch is:  0.09142600744962692\n",
      "The representation loss after processing this batch is:  0.0028149187564849854\n",
      "\n",
      "The classification loss after processing this batch is:  0.07932625710964203\n",
      "The representation loss after processing this batch is:  0.0026850849390029907\n",
      "\n",
      "The classification loss after processing this batch is:  0.05464412271976471\n",
      "The representation loss after processing this batch is:  0.0024253129959106445\n",
      "\n",
      "The classification loss after processing this batch is:  0.25346460938453674\n",
      "The representation loss after processing this batch is:  0.0026854462921619415\n",
      "\n",
      "The classification loss after processing this batch is:  0.1378239244222641\n",
      "The representation loss after processing this batch is:  0.002776533365249634\n",
      "\n",
      "The classification loss after processing this batch is:  0.05966082587838173\n",
      "The representation loss after processing this batch is:  0.0028704479336738586\n",
      "\n",
      "The classification loss after processing this batch is:  0.15398845076560974\n",
      "The representation loss after processing this batch is:  0.0028036609292030334\n",
      "\n",
      "The classification loss after processing this batch is:  0.12900979816913605\n",
      "The representation loss after processing this batch is:  0.0023839473724365234\n",
      "\n",
      "The classification loss after processing this batch is:  0.08287343382835388\n",
      "The representation loss after processing this batch is:  0.0024747028946876526\n",
      "\n",
      "The classification loss after processing this batch is:  0.12078847736120224\n",
      "The representation loss after processing this batch is:  0.002331431955099106\n",
      "\n",
      "The classification loss after processing this batch is:  0.08650410920381546\n",
      "The representation loss after processing this batch is:  0.0025390684604644775\n",
      "\n",
      "The classification loss after processing this batch is:  0.09525056928396225\n",
      "The representation loss after processing this batch is:  0.0025529414415359497\n",
      "\n",
      "The classification loss after processing this batch is:  0.14138174057006836\n",
      "The representation loss after processing this batch is:  0.0024469122290611267\n",
      "\n",
      "The classification loss after processing this batch is:  0.2106642723083496\n",
      "The representation loss after processing this batch is:  0.002745300531387329\n",
      "\n",
      "The classification loss after processing this batch is:  0.1462537944316864\n",
      "The representation loss after processing this batch is:  0.0024406462907791138\n",
      "\n",
      "The classification loss after processing this batch is:  0.12745387852191925\n",
      "The representation loss after processing this batch is:  0.002473682165145874\n",
      "\n",
      "The classification loss after processing this batch is:  0.10109976679086685\n",
      "The representation loss after processing this batch is:  0.002555985003709793\n",
      "\n",
      "The classification loss after processing this batch is:  0.1543809473514557\n",
      "The representation loss after processing this batch is:  0.002505846321582794\n",
      "\n",
      "The classification loss after processing this batch is:  0.0749252587556839\n",
      "The representation loss after processing this batch is:  0.0027653947472572327\n",
      "\n",
      "The classification loss after processing this batch is:  0.15390561521053314\n",
      "The representation loss after processing this batch is:  0.0026827752590179443\n",
      "\n",
      "The classification loss after processing this batch is:  0.0826120376586914\n",
      "The representation loss after processing this batch is:  0.002457365393638611\n",
      "\n",
      "The classification loss after processing this batch is:  0.1462850421667099\n",
      "The representation loss after processing this batch is:  0.002618156373500824\n",
      "\n",
      "The classification loss after processing this batch is:  0.08786772191524506\n",
      "The representation loss after processing this batch is:  0.002786204218864441\n",
      "\n",
      "The classification loss after processing this batch is:  0.1371000111103058\n",
      "The representation loss after processing this batch is:  0.00237872451543808\n",
      "\n",
      "The classification loss after processing this batch is:  0.10951633006334305\n",
      "The representation loss after processing this batch is:  0.002273775637149811\n",
      "\n",
      "The classification loss after processing this batch is:  0.11582675576210022\n",
      "The representation loss after processing this batch is:  0.0026797428727149963\n",
      "\n",
      "The classification loss after processing this batch is:  0.15998044610023499\n",
      "The representation loss after processing this batch is:  0.0024483278393745422\n",
      "\n",
      "The classification loss after processing this batch is:  0.1338874250650406\n",
      "The representation loss after processing this batch is:  0.0023978017270565033\n",
      "\n",
      "The classification loss after processing this batch is:  0.2046576291322708\n",
      "The representation loss after processing this batch is:  0.0023761019110679626\n",
      "\n",
      "The classification loss after processing this batch is:  0.18901701271533966\n",
      "The representation loss after processing this batch is:  0.0023342370986938477\n",
      "\n",
      "The classification loss after processing this batch is:  0.26638665795326233\n",
      "The representation loss after processing this batch is:  0.0023877806961536407\n",
      "\n",
      "The classification loss after processing this batch is:  0.19679376482963562\n",
      "The representation loss after processing this batch is:  0.00247114896774292\n",
      "\n",
      "The classification loss after processing this batch is:  0.08907733857631683\n",
      "The representation loss after processing this batch is:  0.002733048051595688\n",
      "\n",
      "The classification loss after processing this batch is:  0.16888555884361267\n",
      "The representation loss after processing this batch is:  0.0028755590319633484\n",
      "\n",
      "The classification loss after processing this batch is:  0.0876258835196495\n",
      "The representation loss after processing this batch is:  0.0026379600167274475\n",
      "\n",
      "The classification loss after processing this batch is:  0.1304631382226944\n",
      "The representation loss after processing this batch is:  0.002979416400194168\n",
      "\n",
      "The classification loss after processing this batch is:  0.19881638884544373\n",
      "The representation loss after processing this batch is:  0.003178142011165619\n",
      "\n",
      "The classification loss after processing this batch is:  0.25071632862091064\n",
      "The representation loss after processing this batch is:  0.0030165091156959534\n",
      "\n",
      "The classification loss after processing this batch is:  0.2574184834957123\n",
      "The representation loss after processing this batch is:  0.002446778118610382\n",
      "\n",
      "The classification loss after processing this batch is:  0.19014355540275574\n",
      "The representation loss after processing this batch is:  0.0025717243552207947\n",
      "\n",
      "The classification loss after processing this batch is:  0.07833708822727203\n",
      "The representation loss after processing this batch is:  0.002507038414478302\n",
      "\n",
      "The classification loss after processing this batch is:  0.10489191859960556\n",
      "The representation loss after processing this batch is:  0.00275314599275589\n",
      "\n",
      "The classification loss after processing this batch is:  0.2200070172548294\n",
      "The representation loss after processing this batch is:  0.0024506226181983948\n",
      "\n",
      "The classification loss after processing this batch is:  0.09404012560844421\n",
      "The representation loss after processing this batch is:  0.0025686919689178467\n",
      "\n",
      "The classification loss after processing this batch is:  0.09717901796102524\n",
      "The representation loss after processing this batch is:  0.002533428370952606\n",
      "\n",
      "The classification loss after processing this batch is:  0.08558324724435806\n",
      "The representation loss after processing this batch is:  0.002713799476623535\n",
      "\n",
      "The classification loss after processing this batch is:  0.032834749668836594\n",
      "The representation loss after processing this batch is:  0.00262615829706192\n",
      "\n",
      "The classification loss after processing this batch is:  0.11624635010957718\n",
      "The representation loss after processing this batch is:  0.002945229411125183\n",
      "\n",
      "The classification loss after processing this batch is:  0.109018974006176\n",
      "The representation loss after processing this batch is:  0.0032913312315940857\n",
      "\n",
      "The classification loss after processing this batch is:  0.1494484394788742\n",
      "The representation loss after processing this batch is:  0.002605162560939789\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1406615674495697\n",
      "The representation loss after processing this batch is:  0.0023960769176483154\n",
      "\n",
      "The classification loss after processing this batch is:  0.12412254512310028\n",
      "The representation loss after processing this batch is:  0.0028540492057800293\n",
      "\n",
      "The classification loss after processing this batch is:  0.16899077594280243\n",
      "The representation loss after processing this batch is:  0.0026353970170021057\n",
      "\n",
      "The classification loss after processing this batch is:  0.11639455705881119\n",
      "The representation loss after processing this batch is:  0.0026792213320732117\n",
      "\n",
      "The classification loss after processing this batch is:  0.12993621826171875\n",
      "The representation loss after processing this batch is:  0.003183715045452118\n",
      "\n",
      "The classification loss after processing this batch is:  0.1040048897266388\n",
      "The representation loss after processing this batch is:  0.002970270812511444\n",
      "\n",
      "The classification loss after processing this batch is:  0.13481217622756958\n",
      "The representation loss after processing this batch is:  0.0027718394994735718\n",
      "\n",
      "The classification loss after processing this batch is:  0.18212822079658508\n",
      "The representation loss after processing this batch is:  0.0025538429617881775\n",
      "\n",
      "The classification loss after processing this batch is:  0.2388543039560318\n",
      "The representation loss after processing this batch is:  0.0024608224630355835\n",
      "\n",
      "The classification loss after processing this batch is:  0.2066705971956253\n",
      "The representation loss after processing this batch is:  0.0028403252363204956\n",
      "\n",
      "The classification loss after processing this batch is:  0.09770696610212326\n",
      "The representation loss after processing this batch is:  0.0024548880755901337\n",
      "\n",
      "The classification loss after processing this batch is:  0.1589331328868866\n",
      "The representation loss after processing this batch is:  0.0028149038553237915\n",
      "\n",
      "The classification loss after processing this batch is:  0.14150740206241608\n",
      "The representation loss after processing this batch is:  0.002606108784675598\n",
      "\n",
      "The classification loss after processing this batch is:  0.18441742658615112\n",
      "The representation loss after processing this batch is:  0.0026728659868240356\n",
      "\n",
      "The classification loss after processing this batch is:  0.20736797153949738\n",
      "The representation loss after processing this batch is:  0.0029963329434394836\n",
      "\n",
      "The classification loss after processing this batch is:  0.19776304066181183\n",
      "The representation loss after processing this batch is:  0.0027638375759124756\n",
      "\n",
      "The classification loss after processing this batch is:  0.2748821973800659\n",
      "The representation loss after processing this batch is:  0.0031123086810112\n",
      "\n",
      "The classification loss after processing this batch is:  0.15136384963989258\n",
      "The representation loss after processing this batch is:  0.0030701011419296265\n",
      "\n",
      "The classification loss after processing this batch is:  0.1402844786643982\n",
      "The representation loss after processing this batch is:  0.0026781857013702393\n",
      "\n",
      "The classification loss after processing this batch is:  0.14291957020759583\n",
      "The representation loss after processing this batch is:  0.00305870920419693\n",
      "\n",
      "The classification loss after processing this batch is:  0.07685890048742294\n",
      "The representation loss after processing this batch is:  0.0028416141867637634\n",
      "\n",
      "The classification loss after processing this batch is:  0.17586824297904968\n",
      "The representation loss after processing this batch is:  0.0028828606009483337\n",
      "\n",
      "The classification loss after processing this batch is:  0.13708201050758362\n",
      "The representation loss after processing this batch is:  0.0025377273559570312\n",
      "\n",
      "The classification loss after processing this batch is:  0.10484929382801056\n",
      "The representation loss after processing this batch is:  0.0025196000933647156\n",
      "\n",
      "The classification loss after processing this batch is:  0.11435966938734055\n",
      "The representation loss after processing this batch is:  0.0027133822441101074\n",
      "\n",
      "The classification loss after processing this batch is:  0.15724582970142365\n",
      "The representation loss after processing this batch is:  0.0030425190925598145\n",
      "\n",
      "The classification loss after processing this batch is:  0.14184890687465668\n",
      "The representation loss after processing this batch is:  0.002520747482776642\n",
      "\n",
      "The classification loss after processing this batch is:  0.1373797506093979\n",
      "The representation loss after processing this batch is:  0.0026765987277030945\n",
      "\n",
      "The classification loss after processing this batch is:  0.12338501960039139\n",
      "The representation loss after processing this batch is:  0.0024942830204963684\n",
      "\n",
      "The classification loss after processing this batch is:  0.06613076478242874\n",
      "The representation loss after processing this batch is:  0.0025074556469917297\n",
      "\n",
      "The classification loss after processing this batch is:  0.12760433554649353\n",
      "The representation loss after processing this batch is:  0.0022234246134757996\n",
      "\n",
      "The classification loss after processing this batch is:  0.1052747294306755\n",
      "The representation loss after processing this batch is:  0.0022406242787837982\n",
      "\n",
      "The classification loss after processing this batch is:  0.4617103636264801\n",
      "The representation loss after processing this batch is:  0.002740178257226944\n",
      "\n",
      "The classification loss after processing this batch is:  0.10142868012189865\n",
      "The representation loss after processing this batch is:  0.002631537616252899\n",
      "\n",
      "The classification loss after processing this batch is:  0.17322202026844025\n",
      "The representation loss after processing this batch is:  0.0024909116327762604\n",
      "\n",
      "The classification loss after processing this batch is:  0.2831370532512665\n",
      "The representation loss after processing this batch is:  0.002743177115917206\n",
      "\n",
      "The classification loss after processing this batch is:  0.09499292820692062\n",
      "The representation loss after processing this batch is:  0.00243397057056427\n",
      "\n",
      "The classification loss after processing this batch is:  0.2136841118335724\n",
      "The representation loss after processing this batch is:  0.0028908178210258484\n",
      "\n",
      "The classification loss after processing this batch is:  0.12692543864250183\n",
      "The representation loss after processing this batch is:  0.0029008127748966217\n",
      "\n",
      "The classification loss after processing this batch is:  0.2697286605834961\n",
      "The representation loss after processing this batch is:  0.002337794750928879\n",
      "\n",
      "The classification loss after processing this batch is:  0.060055628418922424\n",
      "The representation loss after processing this batch is:  0.0026043951511383057\n",
      "\n",
      "The classification loss after processing this batch is:  0.10841336101293564\n",
      "The representation loss after processing this batch is:  0.0027639269828796387\n",
      "\n",
      "The classification loss after processing this batch is:  0.04241383448243141\n",
      "The representation loss after processing this batch is:  0.0029235780239105225\n",
      "\n",
      "The classification loss after processing this batch is:  0.036889806389808655\n",
      "The representation loss after processing this batch is:  0.0028202682733535767\n",
      "\n",
      "The classification loss after processing this batch is:  0.08554323017597198\n",
      "The representation loss after processing this batch is:  0.002656802535057068\n",
      "\n",
      "The classification loss after processing this batch is:  0.051373474299907684\n",
      "The representation loss after processing this batch is:  0.00230378657579422\n",
      "\n",
      "The classification loss after processing this batch is:  0.10979916900396347\n",
      "The representation loss after processing this batch is:  0.0028516724705696106\n",
      "\n",
      "The classification loss after processing this batch is:  0.10159104317426682\n",
      "The representation loss after processing this batch is:  0.003386296331882477\n",
      "\n",
      "The classification loss after processing this batch is:  0.11825136095285416\n",
      "The representation loss after processing this batch is:  0.0024773702025413513\n",
      "\n",
      "The classification loss after processing this batch is:  0.10830872505903244\n",
      "The representation loss after processing this batch is:  0.0024787113070487976\n",
      "\n",
      "The classification loss after processing this batch is:  0.06689997017383575\n",
      "The representation loss after processing this batch is:  0.002612292766571045\n",
      "\n",
      "The classification loss after processing this batch is:  0.1602810174226761\n",
      "The representation loss after processing this batch is:  0.0026023760437965393\n",
      "\n",
      "The classification loss after processing this batch is:  0.1439020186662674\n",
      "The representation loss after processing this batch is:  0.002972416579723358\n",
      "\n",
      "The classification loss after processing this batch is:  0.20440451800823212\n",
      "The representation loss after processing this batch is:  0.0030817463994026184\n",
      "\n",
      "The classification loss after processing this batch is:  0.10828138142824173\n",
      "The representation loss after processing this batch is:  0.0025487616658210754\n",
      "\n",
      "The classification loss after processing this batch is:  0.08979237824678421\n",
      "The representation loss after processing this batch is:  0.002661924809217453\n",
      "\n",
      "The classification loss after processing this batch is:  0.21171382069587708\n",
      "The representation loss after processing this batch is:  0.0026664063334465027\n",
      "\n",
      "The classification loss after processing this batch is:  0.1859188973903656\n",
      "The representation loss after processing this batch is:  0.0027722418308258057\n",
      "\n",
      "The classification loss after processing this batch is:  0.1621990203857422\n",
      "The representation loss after processing this batch is:  0.0025169774889945984\n",
      "\n",
      "The classification loss after processing this batch is:  0.061611074954271317\n",
      "The representation loss after processing this batch is:  0.002727903425693512\n",
      "\n",
      "The classification loss after processing this batch is:  0.11555101722478867\n",
      "The representation loss after processing this batch is:  0.0027936920523643494\n",
      "\n",
      "The classification loss after processing this batch is:  0.12988929450511932\n",
      "The representation loss after processing this batch is:  0.0025578662753105164\n",
      "\n",
      "The classification loss after processing this batch is:  0.1450931280851364\n",
      "The representation loss after processing this batch is:  0.0027984678745269775\n",
      "\n",
      "The classification loss after processing this batch is:  0.14767010509967804\n",
      "The representation loss after processing this batch is:  0.0034130997955799103\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08621744811534882\n",
      "The representation loss after processing this batch is:  0.003140978515148163\n",
      "\n",
      "The classification loss after processing this batch is:  0.15683265030384064\n",
      "The representation loss after processing this batch is:  0.00296860933303833\n",
      "\n",
      "The classification loss after processing this batch is:  0.18574737012386322\n",
      "The representation loss after processing this batch is:  0.0026143789291381836\n",
      "\n",
      "The classification loss after processing this batch is:  0.0960383415222168\n",
      "The representation loss after processing this batch is:  0.0032538995146751404\n",
      "\n",
      "The classification loss after processing this batch is:  0.15424953401088715\n",
      "The representation loss after processing this batch is:  0.002427928149700165\n",
      "\n",
      "The classification loss after processing this batch is:  0.08924395591020584\n",
      "The representation loss after processing this batch is:  0.002268850803375244\n",
      "\n",
      "The classification loss after processing this batch is:  0.16206972301006317\n",
      "The representation loss after processing this batch is:  0.002470828592777252\n",
      "\n",
      "The classification loss after processing this batch is:  0.07962352782487869\n",
      "The representation loss after processing this batch is:  0.0025381147861480713\n",
      "\n",
      "The classification loss after processing this batch is:  0.13652491569519043\n",
      "The representation loss after processing this batch is:  0.0030344873666763306\n",
      "\n",
      "The classification loss after processing this batch is:  0.11517176032066345\n",
      "The representation loss after processing this batch is:  0.002956993877887726\n",
      "\n",
      "The classification loss after processing this batch is:  0.1085410863161087\n",
      "The representation loss after processing this batch is:  0.0024711862206459045\n",
      "\n",
      "The classification loss after processing this batch is:  0.10209041088819504\n",
      "The representation loss after processing this batch is:  0.0028220415115356445\n",
      "\n",
      "The classification loss after processing this batch is:  0.15990851819515228\n",
      "The representation loss after processing this batch is:  0.002980828285217285\n",
      "\n",
      "The classification loss after processing this batch is:  0.17213186621665955\n",
      "The representation loss after processing this batch is:  0.0030530691146850586\n",
      "\n",
      "The classification loss after processing this batch is:  0.15874579548835754\n",
      "The representation loss after processing this batch is:  0.002929624170064926\n",
      "\n",
      "The classification loss after processing this batch is:  0.1214093416929245\n",
      "The representation loss after processing this batch is:  0.0030123665928840637\n",
      "\n",
      "The classification loss after processing this batch is:  0.08946814388036728\n",
      "The representation loss after processing this batch is:  0.0025769323110580444\n",
      "\n",
      "The classification loss after processing this batch is:  0.09961406886577606\n",
      "The representation loss after processing this batch is:  0.002945907413959503\n",
      "\n",
      "The classification loss after processing this batch is:  0.0811140164732933\n",
      "The representation loss after processing this batch is:  0.002846546471118927\n",
      "\n",
      "The classification loss after processing this batch is:  0.1073654443025589\n",
      "The representation loss after processing this batch is:  0.002574928104877472\n",
      "\n",
      "The classification loss after processing this batch is:  0.055296286940574646\n",
      "The representation loss after processing this batch is:  0.0025266706943511963\n",
      "\n",
      "The classification loss after processing this batch is:  0.05993270501494408\n",
      "The representation loss after processing this batch is:  0.0025198981165885925\n",
      "\n",
      "The classification loss after processing this batch is:  0.09623983502388\n",
      "The representation loss after processing this batch is:  0.0028137117624282837\n",
      "\n",
      "The classification loss after processing this batch is:  0.04256703704595566\n",
      "The representation loss after processing this batch is:  0.0027921348810195923\n",
      "\n",
      "The classification loss after processing this batch is:  0.17153896391391754\n",
      "The representation loss after processing this batch is:  0.0025873705744743347\n",
      "\n",
      "The classification loss after processing this batch is:  0.1152728870511055\n",
      "The representation loss after processing this batch is:  0.0022866912186145782\n",
      "\n",
      "The classification loss after processing this batch is:  0.1358797699213028\n",
      "The representation loss after processing this batch is:  0.0027435049414634705\n",
      "\n",
      "The classification loss after processing this batch is:  0.04619792476296425\n",
      "The representation loss after processing this batch is:  0.002951115369796753\n",
      "\n",
      "The classification loss after processing this batch is:  0.18476326763629913\n",
      "The representation loss after processing this batch is:  0.002673991024494171\n",
      "\n",
      "The classification loss after processing this batch is:  0.13301540911197662\n",
      "The representation loss after processing this batch is:  0.002575904130935669\n",
      "\n",
      "The classification loss after processing this batch is:  0.11843306571245193\n",
      "The representation loss after processing this batch is:  0.002455577254295349\n",
      "\n",
      "The classification loss after processing this batch is:  0.11419603228569031\n",
      "The representation loss after processing this batch is:  0.002777509391307831\n",
      "\n",
      "The classification loss after processing this batch is:  0.09997240453958511\n",
      "The representation loss after processing this batch is:  0.00286010280251503\n",
      "\n",
      "The classification loss after processing this batch is:  0.08135434985160828\n",
      "The representation loss after processing this batch is:  0.0026051178574562073\n",
      "\n",
      "The classification loss after processing this batch is:  0.07999090105295181\n",
      "The representation loss after processing this batch is:  0.002756759524345398\n",
      "\n",
      "The classification loss after processing this batch is:  0.08137187361717224\n",
      "The representation loss after processing this batch is:  0.0025112107396125793\n",
      "\n",
      "The classification loss after processing this batch is:  0.1986015886068344\n",
      "The representation loss after processing this batch is:  0.002721816301345825\n",
      "\n",
      "The classification loss after processing this batch is:  0.1328168511390686\n",
      "The representation loss after processing this batch is:  0.0023871175944805145\n",
      "\n",
      "The classification loss after processing this batch is:  0.16478493809700012\n",
      "The representation loss after processing this batch is:  0.0032836198806762695\n",
      "\n",
      "The classification loss after processing this batch is:  0.19300991296768188\n",
      "The representation loss after processing this batch is:  0.0028004273772239685\n",
      "\n",
      "The classification loss after processing this batch is:  0.1764984428882599\n",
      "The representation loss after processing this batch is:  0.0027917027473449707\n",
      "\n",
      "The classification loss after processing this batch is:  0.17834065854549408\n",
      "The representation loss after processing this batch is:  0.002681933343410492\n",
      "\n",
      "The classification loss after processing this batch is:  0.2802552580833435\n",
      "The representation loss after processing this batch is:  0.002470124512910843\n",
      "\n",
      "The classification loss after processing this batch is:  0.19641761481761932\n",
      "The representation loss after processing this batch is:  0.002376154065132141\n",
      "\n",
      "The classification loss after processing this batch is:  0.13271155953407288\n",
      "The representation loss after processing this batch is:  0.002329666167497635\n",
      "\n",
      "The classification loss after processing this batch is:  0.10803292691707611\n",
      "The representation loss after processing this batch is:  0.0024359747767448425\n",
      "\n",
      "The classification loss after processing this batch is:  0.07752177119255066\n",
      "The representation loss after processing this batch is:  0.0025313422083854675\n",
      "\n",
      "The classification loss after processing this batch is:  0.060246214270591736\n",
      "The representation loss after processing this batch is:  0.0024839267134666443\n",
      "\n",
      "The classification loss after processing this batch is:  0.10140474885702133\n",
      "The representation loss after processing this batch is:  0.003039933741092682\n",
      "\n",
      "The classification loss after processing this batch is:  0.1549258679151535\n",
      "The representation loss after processing this batch is:  0.002626940608024597\n",
      "\n",
      "The classification loss after processing this batch is:  0.08534020930528641\n",
      "The representation loss after processing this batch is:  0.002587229013442993\n",
      "\n",
      "The classification loss after processing this batch is:  0.2173403799533844\n",
      "The representation loss after processing this batch is:  0.0027448199689388275\n",
      "\n",
      "The classification loss after processing this batch is:  0.12583161890506744\n",
      "The representation loss after processing this batch is:  0.0026715025305747986\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14338022470474243\n",
      "The representation loss after processing this batch is:  0.002592802047729492\n",
      "\n",
      "The classification loss after processing this batch is:  0.14409217238426208\n",
      "The representation loss after processing this batch is:  0.0024946480989456177\n",
      "\n",
      "The classification loss after processing this batch is:  0.20139871537685394\n",
      "The representation loss after processing this batch is:  0.0022961944341659546\n",
      "\n",
      "The classification loss after processing this batch is:  0.14214687049388885\n",
      "The representation loss after processing this batch is:  0.0025068819522857666\n",
      "\n",
      "The classification loss after processing this batch is:  0.10789856314659119\n",
      "The representation loss after processing this batch is:  0.0029441416263580322\n",
      "\n",
      "The classification loss after processing this batch is:  0.14542798697948456\n",
      "The representation loss after processing this batch is:  0.0024222955107688904\n",
      "\n",
      "The classification loss after processing this batch is:  0.058803804218769073\n",
      "The representation loss after processing this batch is:  0.002460986375808716\n",
      "\n",
      "The classification loss after processing this batch is:  0.060922518372535706\n",
      "The representation loss after processing this batch is:  0.0024982839822769165\n",
      "\n",
      "The classification loss after processing this batch is:  0.13079477846622467\n",
      "The representation loss after processing this batch is:  0.0029476284980773926\n",
      "\n",
      "The classification loss after processing this batch is:  0.17277781665325165\n",
      "The representation loss after processing this batch is:  0.0024987757205963135\n",
      "\n",
      "The classification loss after processing this batch is:  0.1514049619436264\n",
      "The representation loss after processing this batch is:  0.0026902705430984497\n",
      "\n",
      "The classification loss after processing this batch is:  0.08216553181409836\n",
      "The representation loss after processing this batch is:  0.0032673701643943787\n",
      "\n",
      "The classification loss after processing this batch is:  0.11376164853572845\n",
      "The representation loss after processing this batch is:  0.0029362663626670837\n",
      "\n",
      "The classification loss after processing this batch is:  0.07826285809278488\n",
      "The representation loss after processing this batch is:  0.002732604742050171\n",
      "\n",
      "The classification loss after processing this batch is:  0.20391838252544403\n",
      "The representation loss after processing this batch is:  0.002627052366733551\n",
      "\n",
      "The classification loss after processing this batch is:  0.06164275109767914\n",
      "The representation loss after processing this batch is:  0.0022591501474380493\n",
      "\n",
      "The classification loss after processing this batch is:  0.055038053542375565\n",
      "The representation loss after processing this batch is:  0.002924405038356781\n",
      "\n",
      "The classification loss after processing this batch is:  0.13018180429935455\n",
      "The representation loss after processing this batch is:  0.003376990556716919\n",
      "\n",
      "The classification loss after processing this batch is:  0.12689751386642456\n",
      "The representation loss after processing this batch is:  0.002675265073776245\n",
      "\n",
      "The classification loss after processing this batch is:  0.09412489831447601\n",
      "The representation loss after processing this batch is:  0.0030298233032226562\n",
      "\n",
      "The classification loss after processing this batch is:  0.06031280755996704\n",
      "The representation loss after processing this batch is:  0.002566233277320862\n",
      "\n",
      "The classification loss after processing this batch is:  0.13584327697753906\n",
      "The representation loss after processing this batch is:  0.0029980987310409546\n",
      "\n",
      "The classification loss after processing this batch is:  0.17178064584732056\n",
      "The representation loss after processing this batch is:  0.0028529688715934753\n",
      "\n",
      "The classification loss after processing this batch is:  0.19386254251003265\n",
      "The representation loss after processing this batch is:  0.0025109462440013885\n",
      "\n",
      "The classification loss after processing this batch is:  0.15985244512557983\n",
      "The representation loss after processing this batch is:  0.002952471375465393\n",
      "\n",
      "The classification loss after processing this batch is:  0.0729561522603035\n",
      "The representation loss after processing this batch is:  0.0027505382895469666\n",
      "\n",
      "The classification loss after processing this batch is:  0.09670118242502213\n",
      "The representation loss after processing this batch is:  0.0025059543550014496\n",
      "\n",
      "The classification loss after processing this batch is:  0.20039592683315277\n",
      "The representation loss after processing this batch is:  0.002788938581943512\n",
      "\n",
      "The classification loss after processing this batch is:  0.22665713727474213\n",
      "The representation loss after processing this batch is:  0.0030067265033721924\n",
      "\n",
      "The classification loss after processing this batch is:  0.22261032462120056\n",
      "The representation loss after processing this batch is:  0.0032887831330299377\n",
      "\n",
      "The classification loss after processing this batch is:  0.2728016674518585\n",
      "The representation loss after processing this batch is:  0.0027595162391662598\n",
      "\n",
      "The classification loss after processing this batch is:  0.0792708694934845\n",
      "The representation loss after processing this batch is:  0.002426654100418091\n",
      "\n",
      "The classification loss after processing this batch is:  0.16345208883285522\n",
      "The representation loss after processing this batch is:  0.0026032179594039917\n",
      "\n",
      "The classification loss after processing this batch is:  0.10121740400791168\n",
      "The representation loss after processing this batch is:  0.0025185570120811462\n",
      "\n",
      "The classification loss after processing this batch is:  0.10058844089508057\n",
      "The representation loss after processing this batch is:  0.002423010766506195\n",
      "\n",
      "The classification loss after processing this batch is:  0.10209083557128906\n",
      "The representation loss after processing this batch is:  0.0026070550084114075\n",
      "\n",
      "The classification loss after processing this batch is:  0.17393770813941956\n",
      "The representation loss after processing this batch is:  0.0026685893535614014\n",
      "\n",
      "The classification loss after processing this batch is:  0.14123958349227905\n",
      "The representation loss after processing this batch is:  0.002475261688232422\n",
      "\n",
      "The classification loss after processing this batch is:  0.09582661092281342\n",
      "The representation loss after processing this batch is:  0.0025522634387016296\n",
      "\n",
      "The classification loss after processing this batch is:  0.17367476224899292\n",
      "The representation loss after processing this batch is:  0.002627432346343994\n",
      "\n",
      "The classification loss after processing this batch is:  0.04929583892226219\n",
      "The representation loss after processing this batch is:  0.0029548481106758118\n",
      "\n",
      "The classification loss after processing this batch is:  0.11774887889623642\n",
      "The representation loss after processing this batch is:  0.002950236201286316\n",
      "\n",
      "The classification loss after processing this batch is:  0.15885932743549347\n",
      "The representation loss after processing this batch is:  0.0027061104774475098\n",
      "\n",
      "The classification loss after processing this batch is:  0.15442189574241638\n",
      "The representation loss after processing this batch is:  0.002819553017616272\n",
      "\n",
      "The classification loss after processing this batch is:  0.05569081008434296\n",
      "The representation loss after processing this batch is:  0.0032020211219787598\n",
      "\n",
      "The classification loss after processing this batch is:  0.07754310220479965\n",
      "The representation loss after processing this batch is:  0.0025654956698417664\n",
      "\n",
      "The classification loss after processing this batch is:  0.17709562182426453\n",
      "The representation loss after processing this batch is:  0.003129720687866211\n",
      "\n",
      "The classification loss after processing this batch is:  0.17651277780532837\n",
      "The representation loss after processing this batch is:  0.0024463795125484467\n",
      "\n",
      "The classification loss after processing this batch is:  0.1470116227865219\n",
      "The representation loss after processing this batch is:  0.0025701597332954407\n",
      "\n",
      "The classification loss after processing this batch is:  0.11514291167259216\n",
      "The representation loss after processing this batch is:  0.0025839507579803467\n",
      "\n",
      "The classification loss after processing this batch is:  0.06989309191703796\n",
      "The representation loss after processing this batch is:  0.002759583294391632\n",
      "\n",
      "The classification loss after processing this batch is:  0.12207252532243729\n",
      "The representation loss after processing this batch is:  0.002457793802022934\n",
      "\n",
      "The classification loss after processing this batch is:  0.13518290221691132\n",
      "The representation loss after processing this batch is:  0.0026635751128196716\n",
      "\n",
      "The classification loss after processing this batch is:  0.16695721447467804\n",
      "The representation loss after processing this batch is:  0.00261494517326355\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10876219719648361\n",
      "The representation loss after processing this batch is:  0.0028594285249710083\n",
      "\n",
      "The classification loss after processing this batch is:  0.07038439065217972\n",
      "The representation loss after processing this batch is:  0.0024784430861473083\n",
      "\n",
      "The classification loss after processing this batch is:  0.1532084196805954\n",
      "The representation loss after processing this batch is:  0.002732645720243454\n",
      "\n",
      "The classification loss after processing this batch is:  0.21171243488788605\n",
      "The representation loss after processing this batch is:  0.0026503652334213257\n",
      "\n",
      "The classification loss after processing this batch is:  0.0709800198674202\n",
      "The representation loss after processing this batch is:  0.0028222426772117615\n",
      "\n",
      "The classification loss after processing this batch is:  0.08469417691230774\n",
      "The representation loss after processing this batch is:  0.0022807084023952484\n",
      "\n",
      "The classification loss after processing this batch is:  0.19789338111877441\n",
      "The representation loss after processing this batch is:  0.0026002898812294006\n",
      "\n",
      "The classification loss after processing this batch is:  0.197936549782753\n",
      "The representation loss after processing this batch is:  0.00254695862531662\n",
      "\n",
      "The classification loss after processing this batch is:  0.09756629914045334\n",
      "The representation loss after processing this batch is:  0.0025433003902435303\n",
      "\n",
      "The classification loss after processing this batch is:  0.1710345298051834\n",
      "The representation loss after processing this batch is:  0.0023486539721488953\n",
      "\n",
      "The classification loss after processing this batch is:  0.1805671751499176\n",
      "The representation loss after processing this batch is:  0.0027906373143196106\n",
      "\n",
      "The classification loss after processing this batch is:  0.19846086204051971\n",
      "The representation loss after processing this batch is:  0.002802513539791107\n",
      "\n",
      "The classification loss after processing this batch is:  0.14091971516609192\n",
      "The representation loss after processing this batch is:  0.0028846636414527893\n",
      "\n",
      "The classification loss after processing this batch is:  0.173782616853714\n",
      "The representation loss after processing this batch is:  0.0025020837783813477\n",
      "\n",
      "The classification loss after processing this batch is:  0.12112133949995041\n",
      "The representation loss after processing this batch is:  0.0034775957465171814\n",
      "\n",
      "The classification loss after processing this batch is:  0.11146675795316696\n",
      "The representation loss after processing this batch is:  0.002702385187149048\n",
      "\n",
      "The classification loss after processing this batch is:  0.09966643899679184\n",
      "The representation loss after processing this batch is:  0.0024245157837867737\n",
      "\n",
      "The classification loss after processing this batch is:  0.09951216727495193\n",
      "The representation loss after processing this batch is:  0.00238187238574028\n",
      "\n",
      "The classification loss after processing this batch is:  0.10886411368846893\n",
      "The representation loss after processing this batch is:  0.0026578158140182495\n",
      "\n",
      "The classification loss after processing this batch is:  0.1260654628276825\n",
      "The representation loss after processing this batch is:  0.0025818273425102234\n",
      "\n",
      "The classification loss after processing this batch is:  0.18985658884048462\n",
      "The representation loss after processing this batch is:  0.002559121698141098\n",
      "\n",
      "The classification loss after processing this batch is:  0.06618043035268784\n",
      "The representation loss after processing this batch is:  0.002813585102558136\n",
      "\n",
      "The classification loss after processing this batch is:  0.06527473777532578\n",
      "The representation loss after processing this batch is:  0.0031135007739067078\n",
      "\n",
      "The classification loss after processing this batch is:  0.12835335731506348\n",
      "The representation loss after processing this batch is:  0.002997659146785736\n",
      "\n",
      "The classification loss after processing this batch is:  0.04148636758327484\n",
      "The representation loss after processing this batch is:  0.002442695200443268\n",
      "\n",
      "The classification loss after processing this batch is:  0.09057431668043137\n",
      "The representation loss after processing this batch is:  0.0026356950402259827\n",
      "\n",
      "The classification loss after processing this batch is:  0.04377387464046478\n",
      "The representation loss after processing this batch is:  0.0027005448937416077\n",
      "\n",
      "The classification loss after processing this batch is:  0.11923445761203766\n",
      "The representation loss after processing this batch is:  0.0024995431303977966\n",
      "\n",
      "The classification loss after processing this batch is:  0.15789538621902466\n",
      "The representation loss after processing this batch is:  0.0028012841939926147\n",
      "\n",
      "The classification loss after processing this batch is:  0.16216398775577545\n",
      "The representation loss after processing this batch is:  0.0033839717507362366\n",
      "\n",
      "The classification loss after processing this batch is:  0.14113830029964447\n",
      "The representation loss after processing this batch is:  0.0031133145093917847\n",
      "\n",
      "The classification loss after processing this batch is:  0.08737390488386154\n",
      "The representation loss after processing this batch is:  0.002830781042575836\n",
      "\n",
      "The classification loss after processing this batch is:  0.11117623001337051\n",
      "The representation loss after processing this batch is:  0.002847183495759964\n",
      "\n",
      "The classification loss after processing this batch is:  0.09250474721193314\n",
      "The representation loss after processing this batch is:  0.002490684390068054\n",
      "\n",
      "The classification loss after processing this batch is:  0.06319918483495712\n",
      "The representation loss after processing this batch is:  0.0029724016785621643\n",
      "\n",
      "The classification loss after processing this batch is:  0.07339894771575928\n",
      "The representation loss after processing this batch is:  0.0026595517992973328\n",
      "\n",
      "The classification loss after processing this batch is:  0.054119691252708435\n",
      "The representation loss after processing this batch is:  0.002742685377597809\n",
      "\n",
      "The classification loss after processing this batch is:  0.10317998379468918\n",
      "The representation loss after processing this batch is:  0.002874232828617096\n",
      "\n",
      "The classification loss after processing this batch is:  0.1569153368473053\n",
      "The representation loss after processing this batch is:  0.0027005821466445923\n",
      "\n",
      "The classification loss after processing this batch is:  0.17860345542430878\n",
      "The representation loss after processing this batch is:  0.002740316092967987\n",
      "\n",
      "The classification loss after processing this batch is:  0.12718968093395233\n",
      "The representation loss after processing this batch is:  0.0031833797693252563\n",
      "\n",
      "The classification loss after processing this batch is:  0.1102205365896225\n",
      "The representation loss after processing this batch is:  0.002853021025657654\n",
      "\n",
      "The classification loss after processing this batch is:  0.13242703676223755\n",
      "The representation loss after processing this batch is:  0.0028012096881866455\n",
      "\n",
      "The classification loss after processing this batch is:  0.09296400845050812\n",
      "The representation loss after processing this batch is:  0.0028821229934692383\n",
      "\n",
      "The classification loss after processing this batch is:  0.34141334891319275\n",
      "The representation loss after processing this batch is:  0.003248848021030426\n",
      "\n",
      "The classification loss after processing this batch is:  0.15618854761123657\n",
      "The representation loss after processing this batch is:  0.0029589012265205383\n",
      "\n",
      "The classification loss after processing this batch is:  0.21074767410755157\n",
      "The representation loss after processing this batch is:  0.0033702030777931213\n",
      "\n",
      "The classification loss after processing this batch is:  0.0933774784207344\n",
      "The representation loss after processing this batch is:  0.0024651065468788147\n",
      "\n",
      "The classification loss after processing this batch is:  0.10779412090778351\n",
      "The representation loss after processing this batch is:  0.00247357040643692\n",
      "\n",
      "The classification loss after processing this batch is:  0.1422918140888214\n",
      "The representation loss after processing this batch is:  0.00250457227230072\n",
      "\n",
      "The classification loss after processing this batch is:  0.11570201814174652\n",
      "The representation loss after processing this batch is:  0.0028676576912403107\n",
      "\n",
      "The classification loss after processing this batch is:  0.2148347795009613\n",
      "The representation loss after processing this batch is:  0.002688273787498474\n",
      "\n",
      "The classification loss after processing this batch is:  0.14077623188495636\n",
      "The representation loss after processing this batch is:  0.003285624086856842\n",
      "\n",
      "The classification loss after processing this batch is:  0.1910078525543213\n",
      "The representation loss after processing this batch is:  0.0031292885541915894\n",
      "\n",
      "The classification loss after processing this batch is:  0.14022542536258698\n",
      "The representation loss after processing this batch is:  0.0029130131006240845\n",
      "\n",
      "The classification loss after processing this batch is:  0.05084587633609772\n",
      "The representation loss after processing this batch is:  0.0028539076447486877\n",
      "\n",
      "The classification loss after processing this batch is:  0.10650500655174255\n",
      "The representation loss after processing this batch is:  0.0024059489369392395\n",
      "\n",
      "The classification loss after processing this batch is:  0.10328510403633118\n",
      "The representation loss after processing this batch is:  0.0025436468422412872\n",
      "\n",
      "The classification loss after processing this batch is:  0.0871298685669899\n",
      "The representation loss after processing this batch is:  0.0027955621480941772\n",
      "\n",
      "The classification loss after processing this batch is:  0.1602383702993393\n",
      "The representation loss after processing this batch is:  0.0023867040872573853\n",
      "\n",
      "The classification loss after processing this batch is:  0.23850232362747192\n",
      "The representation loss after processing this batch is:  0.002467714250087738\n",
      "\n",
      "The classification loss after processing this batch is:  0.13475577533245087\n",
      "The representation loss after processing this batch is:  0.0022630468010902405\n",
      "\n",
      "The classification loss after processing this batch is:  0.10187966376543045\n",
      "The representation loss after processing this batch is:  0.002600833773612976\n",
      "\n",
      "The classification loss after processing this batch is:  0.12414181977510452\n",
      "The representation loss after processing this batch is:  0.0026823878288269043\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.0837085098028183\n",
      "The representation loss after processing this batch is:  0.0029133185744285583\n",
      "\n",
      "The classification loss after processing this batch is:  0.13067752122879028\n",
      "The representation loss after processing this batch is:  0.0029201284050941467\n",
      "\n",
      "The classification loss after processing this batch is:  0.05635111406445503\n",
      "The representation loss after processing this batch is:  0.0028357580304145813\n",
      "\n",
      "The classification loss after processing this batch is:  0.13059504330158234\n",
      "The representation loss after processing this batch is:  0.002443559467792511\n",
      "\n",
      "The classification loss after processing this batch is:  0.192244291305542\n",
      "The representation loss after processing this batch is:  0.002691354602575302\n",
      "\n",
      "The classification loss after processing this batch is:  0.06694521754980087\n",
      "The representation loss after processing this batch is:  0.002585485577583313\n",
      "\n",
      "The classification loss after processing this batch is:  0.1757524311542511\n",
      "The representation loss after processing this batch is:  0.002291899174451828\n",
      "\n",
      "The classification loss after processing this batch is:  0.11622757464647293\n",
      "The representation loss after processing this batch is:  0.0022425204515457153\n",
      "\n",
      "The classification loss after processing this batch is:  0.12148495018482208\n",
      "The representation loss after processing this batch is:  0.0025074854493141174\n",
      "\n",
      "The classification loss after processing this batch is:  0.07154476642608643\n",
      "The representation loss after processing this batch is:  0.002582564949989319\n",
      "\n",
      "The classification loss after processing this batch is:  0.14204123616218567\n",
      "The representation loss after processing this batch is:  0.002549789845943451\n",
      "\n",
      "The classification loss after processing this batch is:  0.07383938133716583\n",
      "The representation loss after processing this batch is:  0.0028046593070030212\n",
      "\n",
      "The classification loss after processing this batch is:  0.3378673791885376\n",
      "The representation loss after processing this batch is:  0.0028081461787223816\n",
      "\n",
      "The classification loss after processing this batch is:  0.15913669764995575\n",
      "The representation loss after processing this batch is:  0.0027625635266304016\n",
      "\n",
      "The classification loss after processing this batch is:  0.17214849591255188\n",
      "The representation loss after processing this batch is:  0.0025447458028793335\n",
      "\n",
      "The classification loss after processing this batch is:  0.08524139970541\n",
      "The representation loss after processing this batch is:  0.0023263581097126007\n",
      "\n",
      "The classification loss after processing this batch is:  0.1425810009241104\n",
      "The representation loss after processing this batch is:  0.002609632909297943\n",
      "\n",
      "The classification loss after processing this batch is:  0.060684241354465485\n",
      "The representation loss after processing this batch is:  0.0024601146578788757\n",
      "\n",
      "The classification loss after processing this batch is:  0.13976240158081055\n",
      "The representation loss after processing this batch is:  0.0025056637823581696\n",
      "\n",
      "The classification loss after processing this batch is:  0.20169299840927124\n",
      "The representation loss after processing this batch is:  0.0026725009083747864\n",
      "\n",
      "The classification loss after processing this batch is:  0.16242213547229767\n",
      "The representation loss after processing this batch is:  0.0031081587076187134\n",
      "\n",
      "The classification loss after processing this batch is:  0.18141821026802063\n",
      "The representation loss after processing this batch is:  0.002798996865749359\n",
      "\n",
      "The classification loss after processing this batch is:  0.10629180073738098\n",
      "The representation loss after processing this batch is:  0.002360798418521881\n",
      "\n",
      "The classification loss after processing this batch is:  0.21356144547462463\n",
      "The representation loss after processing this batch is:  0.002775140106678009\n",
      "\n",
      "The classification loss after processing this batch is:  0.14392095804214478\n",
      "The representation loss after processing this batch is:  0.0028038397431373596\n",
      "\n",
      "The classification loss after processing this batch is:  0.1934843212366104\n",
      "The representation loss after processing this batch is:  0.002685241401195526\n",
      "\n",
      "The classification loss after processing this batch is:  0.12325067818164825\n",
      "The representation loss after processing this batch is:  0.0027337446808815002\n",
      "\n",
      "The classification loss after processing this batch is:  0.10471207648515701\n",
      "The representation loss after processing this batch is:  0.0028993189334869385\n",
      "\n",
      "The classification loss after processing this batch is:  0.0578053742647171\n",
      "The representation loss after processing this batch is:  0.00234348326921463\n",
      "\n",
      "The classification loss after processing this batch is:  0.18487490713596344\n",
      "The representation loss after processing this batch is:  0.0024343617260456085\n",
      "\n",
      "The classification loss after processing this batch is:  0.24866323173046112\n",
      "The representation loss after processing this batch is:  0.0027703121304512024\n",
      "\n",
      "The classification loss after processing this batch is:  0.11255279928445816\n",
      "The representation loss after processing this batch is:  0.002922140061855316\n",
      "\n",
      "The classification loss after processing this batch is:  0.14927536249160767\n",
      "The representation loss after processing this batch is:  0.0034229010343551636\n",
      "\n",
      "The classification loss after processing this batch is:  0.18944451212882996\n",
      "The representation loss after processing this batch is:  0.002594463527202606\n",
      "\n",
      "The classification loss after processing this batch is:  0.16841033101081848\n",
      "The representation loss after processing this batch is:  0.0030291378498077393\n",
      "\n",
      "The classification loss after processing this batch is:  0.06412770599126816\n",
      "The representation loss after processing this batch is:  0.002371549606323242\n",
      "\n",
      "The classification loss after processing this batch is:  0.16110776364803314\n",
      "The representation loss after processing this batch is:  0.0026730671525001526\n",
      "\n",
      "The classification loss after processing this batch is:  0.16131331026554108\n",
      "The representation loss after processing this batch is:  0.002785317599773407\n",
      "\n",
      "The classification loss after processing this batch is:  0.11957462131977081\n",
      "The representation loss after processing this batch is:  0.0026606060564517975\n",
      "\n",
      "The classification loss after processing this batch is:  0.0450030080974102\n",
      "The representation loss after processing this batch is:  0.0027232468128204346\n",
      "\n",
      "The classification loss after processing this batch is:  0.09358528256416321\n",
      "The representation loss after processing this batch is:  0.0027751773595809937\n",
      "\n",
      "The classification loss after processing this batch is:  0.09435386210680008\n",
      "The representation loss after processing this batch is:  0.0028410106897354126\n",
      "\n",
      "The classification loss after processing this batch is:  0.13331541419029236\n",
      "The representation loss after processing this batch is:  0.0024630166590213776\n",
      "\n",
      "The classification loss after processing this batch is:  0.19285087287425995\n",
      "The representation loss after processing this batch is:  0.002649456262588501\n",
      "\n",
      "The classification loss after processing this batch is:  0.15989771485328674\n",
      "The representation loss after processing this batch is:  0.002544030547142029\n",
      "\n",
      "The classification loss after processing this batch is:  0.11754478514194489\n",
      "The representation loss after processing this batch is:  0.002806819975376129\n",
      "\n",
      "The classification loss after processing this batch is:  0.1781339794397354\n",
      "The representation loss after processing this batch is:  0.0029976218938827515\n",
      "\n",
      "The classification loss after processing this batch is:  0.133767768740654\n",
      "The representation loss after processing this batch is:  0.0032048299908638\n",
      "\n",
      "The classification loss after processing this batch is:  0.1160103976726532\n",
      "The representation loss after processing this batch is:  0.0031020045280456543\n",
      "\n",
      "The classification loss after processing this batch is:  0.22864915430545807\n",
      "The representation loss after processing this batch is:  0.0028423145413398743\n",
      "\n",
      "The classification loss after processing this batch is:  0.1990605890750885\n",
      "The representation loss after processing this batch is:  0.0032238438725471497\n",
      "\n",
      "The classification loss after processing this batch is:  0.09023783355951309\n",
      "The representation loss after processing this batch is:  0.0026405751705169678\n",
      "\n",
      "The classification loss after processing this batch is:  0.07490932196378708\n",
      "The representation loss after processing this batch is:  0.0026172585785388947\n",
      "\n",
      "The classification loss after processing this batch is:  0.10400982946157455\n",
      "The representation loss after processing this batch is:  0.00240325927734375\n",
      "\n",
      "The classification loss after processing this batch is:  0.10225261747837067\n",
      "The representation loss after processing this batch is:  0.002651400864124298\n",
      "\n",
      "The classification loss after processing this batch is:  0.11922015994787216\n",
      "The representation loss after processing this batch is:  0.0026137717068195343\n",
      "\n",
      "The classification loss after processing this batch is:  0.23145125806331635\n",
      "The representation loss after processing this batch is:  0.0023967809975147247\n",
      "\n",
      "The classification loss after processing this batch is:  0.20110133290290833\n",
      "The representation loss after processing this batch is:  0.003057412803173065\n",
      "\n",
      "The classification loss after processing this batch is:  0.16942091286182404\n",
      "The representation loss after processing this batch is:  0.0021964795887470245\n",
      "\n",
      "The classification loss after processing this batch is:  0.13935886323451996\n",
      "The representation loss after processing this batch is:  0.00228862464427948\n",
      "\n",
      "The classification loss after processing this batch is:  0.11893077939748764\n",
      "The representation loss after processing this batch is:  0.002353433519601822\n",
      "\n",
      "The classification loss after processing this batch is:  0.13667939603328705\n",
      "The representation loss after processing this batch is:  0.0023588761687278748\n",
      "\n",
      "The classification loss after processing this batch is:  0.22508661448955536\n",
      "The representation loss after processing this batch is:  0.002474825829267502\n",
      "\n",
      "The classification loss after processing this batch is:  0.19894473254680634\n",
      "The representation loss after processing this batch is:  0.0025180429220199585\n",
      "\n",
      "The classification loss after processing this batch is:  0.32214877009391785\n",
      "The representation loss after processing this batch is:  0.002542659640312195\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1410052478313446\n",
      "The representation loss after processing this batch is:  0.002706959843635559\n",
      "\n",
      "The classification loss after processing this batch is:  0.04806014522910118\n",
      "The representation loss after processing this batch is:  0.0030083060264587402\n",
      "\n",
      "The classification loss after processing this batch is:  0.16500553488731384\n",
      "The representation loss after processing this batch is:  0.0027014464139938354\n",
      "\n",
      "The classification loss after processing this batch is:  0.1168091744184494\n",
      "The representation loss after processing this batch is:  0.0026007741689682007\n",
      "\n",
      "The classification loss after processing this batch is:  0.18185819685459137\n",
      "The representation loss after processing this batch is:  0.0031185969710350037\n",
      "\n",
      "The classification loss after processing this batch is:  0.16883420944213867\n",
      "The representation loss after processing this batch is:  0.0026833415031433105\n",
      "\n",
      "The classification loss after processing this batch is:  0.17079049348831177\n",
      "The representation loss after processing this batch is:  0.0025552362203598022\n",
      "\n",
      "The classification loss after processing this batch is:  0.14053741097450256\n",
      "The representation loss after processing this batch is:  0.002483569085597992\n",
      "\n",
      "The classification loss after processing this batch is:  0.18220186233520508\n",
      "The representation loss after processing this batch is:  0.0023983269929885864\n",
      "\n",
      "The classification loss after processing this batch is:  0.2535075843334198\n",
      "The representation loss after processing this batch is:  0.0026713907718658447\n",
      "\n",
      "The classification loss after processing this batch is:  0.24892853200435638\n",
      "The representation loss after processing this batch is:  0.002953961491584778\n",
      "\n",
      "The classification loss after processing this batch is:  0.15030477941036224\n",
      "The representation loss after processing this batch is:  0.0025881603360176086\n",
      "\n",
      "The classification loss after processing this batch is:  0.053631916642189026\n",
      "The representation loss after processing this batch is:  0.0030288174748420715\n",
      "\n",
      "The classification loss after processing this batch is:  0.038656461983919144\n",
      "The representation loss after processing this batch is:  0.0026550590991973877\n",
      "\n",
      "The classification loss after processing this batch is:  0.12838008999824524\n",
      "The representation loss after processing this batch is:  0.002636440098285675\n",
      "\n",
      "The classification loss after processing this batch is:  0.082799531519413\n",
      "The representation loss after processing this batch is:  0.004102848470211029\n",
      "\n",
      "The classification loss after processing this batch is:  0.17389808595180511\n",
      "The representation loss after processing this batch is:  0.002556517720222473\n",
      "\n",
      "The classification loss after processing this batch is:  0.0872679129242897\n",
      "The representation loss after processing this batch is:  0.002867475152015686\n",
      "\n",
      "The classification loss after processing this batch is:  0.1990104615688324\n",
      "The representation loss after processing this batch is:  0.002552628517150879\n",
      "\n",
      "The classification loss after processing this batch is:  0.06408767402172089\n",
      "The representation loss after processing this batch is:  0.00304587185382843\n",
      "\n",
      "The classification loss after processing this batch is:  0.14713138341903687\n",
      "The representation loss after processing this batch is:  0.002668756991624832\n",
      "\n",
      "The classification loss after processing this batch is:  0.12403883039951324\n",
      "The representation loss after processing this batch is:  0.0031869113445281982\n",
      "\n",
      "The classification loss after processing this batch is:  0.18032483756542206\n",
      "The representation loss after processing this batch is:  0.002898581326007843\n",
      "\n",
      "The classification loss after processing this batch is:  0.11179016530513763\n",
      "The representation loss after processing this batch is:  0.0025556161999702454\n",
      "\n",
      "The classification loss after processing this batch is:  0.07786881178617477\n",
      "The representation loss after processing this batch is:  0.0022998452186584473\n",
      "\n",
      "The classification loss after processing this batch is:  0.1449326127767563\n",
      "The representation loss after processing this batch is:  0.002775624394416809\n",
      "\n",
      "The classification loss after processing this batch is:  0.1369488388299942\n",
      "The representation loss after processing this batch is:  0.0025052353739738464\n",
      "\n",
      "The classification loss after processing this batch is:  0.16219402849674225\n",
      "The representation loss after processing this batch is:  0.0025884732604026794\n",
      "\n",
      "The classification loss after processing this batch is:  0.16297517716884613\n",
      "The representation loss after processing this batch is:  0.0028591230511665344\n",
      "\n",
      "The classification loss after processing this batch is:  0.08560672402381897\n",
      "The representation loss after processing this batch is:  0.0027917250990867615\n",
      "\n",
      "The classification loss after processing this batch is:  0.04722902923822403\n",
      "The representation loss after processing this batch is:  0.00262238085269928\n",
      "\n",
      "The classification loss after processing this batch is:  0.053841184824705124\n",
      "The representation loss after processing this batch is:  0.002909347414970398\n",
      "\n",
      "The classification loss after processing this batch is:  0.038423966616392136\n",
      "The representation loss after processing this batch is:  0.002863667905330658\n",
      "\n",
      "The classification loss after processing this batch is:  0.11332140862941742\n",
      "The representation loss after processing this batch is:  0.0027497336268424988\n",
      "\n",
      "The classification loss after processing this batch is:  0.07398005574941635\n",
      "The representation loss after processing this batch is:  0.0028204843401908875\n",
      "\n",
      "The classification loss after processing this batch is:  0.038106951862573624\n",
      "The representation loss after processing this batch is:  0.0026729777455329895\n",
      "\n",
      "The classification loss after processing this batch is:  0.12847116589546204\n",
      "The representation loss after processing this batch is:  0.0032395347952842712\n",
      "\n",
      "The classification loss after processing this batch is:  0.08177914470434189\n",
      "The representation loss after processing this batch is:  0.002837657928466797\n",
      "\n",
      "The classification loss after processing this batch is:  0.049124181270599365\n",
      "The representation loss after processing this batch is:  0.0025650784373283386\n",
      "\n",
      "The classification loss after processing this batch is:  0.0723641887307167\n",
      "The representation loss after processing this batch is:  0.0026324838399887085\n",
      "\n",
      "The classification loss after processing this batch is:  0.056308209896087646\n",
      "The representation loss after processing this batch is:  0.002554871141910553\n",
      "\n",
      "The classification loss after processing this batch is:  0.0422898605465889\n",
      "The representation loss after processing this batch is:  0.0028409138321876526\n",
      "\n",
      "The classification loss after processing this batch is:  0.15725253522396088\n",
      "The representation loss after processing this batch is:  0.0027223899960517883\n",
      "\n",
      "The classification loss after processing this batch is:  0.16631142795085907\n",
      "The representation loss after processing this batch is:  0.0027983859181404114\n",
      "\n",
      "The classification loss after processing this batch is:  0.08108334243297577\n",
      "The representation loss after processing this batch is:  0.0027662068605422974\n",
      "\n",
      "The classification loss after processing this batch is:  0.18976019322872162\n",
      "The representation loss after processing this batch is:  0.0026566646993160248\n",
      "\n",
      "The classification loss after processing this batch is:  0.07728016376495361\n",
      "The representation loss after processing this batch is:  0.0025124624371528625\n",
      "\n",
      "The classification loss after processing this batch is:  0.15952390432357788\n",
      "The representation loss after processing this batch is:  0.002380959689617157\n",
      "\n",
      "The classification loss after processing this batch is:  0.16084523499011993\n",
      "The representation loss after processing this batch is:  0.00291229784488678\n",
      "\n",
      "The classification loss after processing this batch is:  0.09077228605747223\n",
      "The representation loss after processing this batch is:  0.0027543827891349792\n",
      "\n",
      "The classification loss after processing this batch is:  0.1922418624162674\n",
      "The representation loss after processing this batch is:  0.0026719272136688232\n",
      "\n",
      "The classification loss after processing this batch is:  0.14393524825572968\n",
      "The representation loss after processing this batch is:  0.0025214850902557373\n",
      "\n",
      "The classification loss after processing this batch is:  0.16017267107963562\n",
      "The representation loss after processing this batch is:  0.0026874542236328125\n",
      "\n",
      "The classification loss after processing this batch is:  0.14712944626808167\n",
      "The representation loss after processing this batch is:  0.0026382580399513245\n",
      "\n",
      "The classification loss after processing this batch is:  0.12527115643024445\n",
      "The representation loss after processing this batch is:  0.002794399857521057\n",
      "\n",
      "The classification loss after processing this batch is:  0.12999318540096283\n",
      "The representation loss after processing this batch is:  0.00234285369515419\n",
      "\n",
      "The classification loss after processing this batch is:  0.09942824393510818\n",
      "The representation loss after processing this batch is:  0.0028599873185157776\n",
      "\n",
      "The classification loss after processing this batch is:  0.19405235350131989\n",
      "The representation loss after processing this batch is:  0.002491287887096405\n",
      "\n",
      "The classification loss after processing this batch is:  0.14691594243049622\n",
      "The representation loss after processing this batch is:  0.002398282289505005\n",
      "\n",
      "The classification loss after processing this batch is:  0.06649868190288544\n",
      "The representation loss after processing this batch is:  0.002742290496826172\n",
      "\n",
      "The classification loss after processing this batch is:  0.09206893295049667\n",
      "The representation loss after processing this batch is:  0.0025145411491394043\n",
      "\n",
      "The classification loss after processing this batch is:  0.19385860860347748\n",
      "The representation loss after processing this batch is:  0.002123035490512848\n",
      "\n",
      "The classification loss after processing this batch is:  0.0825134739279747\n",
      "The representation loss after processing this batch is:  0.002819433808326721\n",
      "\n",
      "The classification loss after processing this batch is:  0.11337792873382568\n",
      "The representation loss after processing this batch is:  0.002553515136241913\n",
      "\n",
      "The classification loss after processing this batch is:  0.1361730545759201\n",
      "The representation loss after processing this batch is:  0.0023915916681289673\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08065011352300644\n",
      "The representation loss after processing this batch is:  0.002883411943912506\n",
      "\n",
      "The classification loss after processing this batch is:  0.050477661192417145\n",
      "The representation loss after processing this batch is:  0.0027373135089874268\n",
      "\n",
      "The classification loss after processing this batch is:  0.10215066373348236\n",
      "The representation loss after processing this batch is:  0.002843700349330902\n",
      "\n",
      "The classification loss after processing this batch is:  0.11357295513153076\n",
      "The representation loss after processing this batch is:  0.0027346163988113403\n",
      "\n",
      "The classification loss after processing this batch is:  0.1289971023797989\n",
      "The representation loss after processing this batch is:  0.0025909245014190674\n",
      "\n",
      "The classification loss after processing this batch is:  0.1928180754184723\n",
      "The representation loss after processing this batch is:  0.0025757811963558197\n",
      "\n",
      "The classification loss after processing this batch is:  0.11162686347961426\n",
      "The representation loss after processing this batch is:  0.002777140587568283\n",
      "\n",
      "The classification loss after processing this batch is:  0.18630674481391907\n",
      "The representation loss after processing this batch is:  0.0023159943521022797\n",
      "\n",
      "The classification loss after processing this batch is:  0.17615357041358948\n",
      "The representation loss after processing this batch is:  0.0029726549983024597\n",
      "\n",
      "The classification loss after processing this batch is:  0.062266986817121506\n",
      "The representation loss after processing this batch is:  0.0027815550565719604\n",
      "\n",
      "The classification loss after processing this batch is:  0.06746481359004974\n",
      "The representation loss after processing this batch is:  0.0026342160999774933\n",
      "\n",
      "The classification loss after processing this batch is:  0.11272130161523819\n",
      "The representation loss after processing this batch is:  0.002605833113193512\n",
      "\n",
      "The classification loss after processing this batch is:  0.1452445238828659\n",
      "The representation loss after processing this batch is:  0.0027193278074264526\n",
      "\n",
      "The classification loss after processing this batch is:  0.10654136538505554\n",
      "The representation loss after processing this batch is:  0.0027290508151054382\n",
      "\n",
      "The classification loss after processing this batch is:  0.17045950889587402\n",
      "The representation loss after processing this batch is:  0.002673756331205368\n",
      "\n",
      "The classification loss after processing this batch is:  0.1299959272146225\n",
      "The representation loss after processing this batch is:  0.0031942427158355713\n",
      "\n",
      "The classification loss after processing this batch is:  0.13644535839557648\n",
      "The representation loss after processing this batch is:  0.0030684396624565125\n",
      "\n",
      "The classification loss after processing this batch is:  0.17042423784732819\n",
      "The representation loss after processing this batch is:  0.002638988196849823\n",
      "\n",
      "The classification loss after processing this batch is:  0.12936492264270782\n",
      "The representation loss after processing this batch is:  0.0025523975491523743\n",
      "\n",
      "The classification loss after processing this batch is:  0.11851122975349426\n",
      "The representation loss after processing this batch is:  0.0025483444333076477\n",
      "\n",
      "The classification loss after processing this batch is:  0.0747838020324707\n",
      "The representation loss after processing this batch is:  0.003076910972595215\n",
      "\n",
      "The classification loss after processing this batch is:  0.05489286407828331\n",
      "The representation loss after processing this batch is:  0.0027122125029563904\n",
      "\n",
      "The classification loss after processing this batch is:  0.17743584513664246\n",
      "The representation loss after processing this batch is:  0.0023747235536575317\n",
      "\n",
      "The classification loss after processing this batch is:  0.14690028131008148\n",
      "The representation loss after processing this batch is:  0.0025047585368156433\n",
      "\n",
      "The classification loss after processing this batch is:  0.1406327337026596\n",
      "The representation loss after processing this batch is:  0.0026131272315979004\n",
      "\n",
      "The classification loss after processing this batch is:  0.14353087544441223\n",
      "The representation loss after processing this batch is:  0.0026806145906448364\n",
      "\n",
      "The classification loss after processing this batch is:  0.12193634361028671\n",
      "The representation loss after processing this batch is:  0.0026137307286262512\n",
      "\n",
      "The classification loss after processing this batch is:  0.15613265335559845\n",
      "The representation loss after processing this batch is:  0.002514369785785675\n",
      "\n",
      "The classification loss after processing this batch is:  0.17682713270187378\n",
      "The representation loss after processing this batch is:  0.0027268975973129272\n",
      "\n",
      "The classification loss after processing this batch is:  0.19868968427181244\n",
      "The representation loss after processing this batch is:  0.0026202797889709473\n",
      "\n",
      "The classification loss after processing this batch is:  0.20477430522441864\n",
      "The representation loss after processing this batch is:  0.0024554915726184845\n",
      "\n",
      "The classification loss after processing this batch is:  0.09579094499349594\n",
      "The representation loss after processing this batch is:  0.0029385313391685486\n",
      "\n",
      "The classification loss after processing this batch is:  0.0595705546438694\n",
      "The representation loss after processing this batch is:  0.0029467791318893433\n",
      "\n",
      "The classification loss after processing this batch is:  0.11705274134874344\n",
      "The representation loss after processing this batch is:  0.00283842533826828\n",
      "\n",
      "The classification loss after processing this batch is:  0.1305253654718399\n",
      "The representation loss after processing this batch is:  0.0024908557534217834\n",
      "\n",
      "The classification loss after processing this batch is:  0.05631021782755852\n",
      "The representation loss after processing this batch is:  0.002658247947692871\n",
      "\n",
      "The classification loss after processing this batch is:  0.07964649051427841\n",
      "The representation loss after processing this batch is:  0.0026172026991844177\n",
      "\n",
      "The classification loss after processing this batch is:  0.10749885439872742\n",
      "The representation loss after processing this batch is:  0.0024487748742103577\n",
      "\n",
      "The classification loss after processing this batch is:  0.10345198959112167\n",
      "The representation loss after processing this batch is:  0.002717547118663788\n",
      "\n",
      "The classification loss after processing this batch is:  0.08300129324197769\n",
      "The representation loss after processing this batch is:  0.0028680339455604553\n",
      "\n",
      "The classification loss after processing this batch is:  0.1052219420671463\n",
      "The representation loss after processing this batch is:  0.002415962517261505\n",
      "\n",
      "The classification loss after processing this batch is:  0.08584888279438019\n",
      "The representation loss after processing this batch is:  0.00266309455037117\n",
      "\n",
      "The classification loss after processing this batch is:  0.1332511603832245\n",
      "The representation loss after processing this batch is:  0.0031173229217529297\n",
      "\n",
      "The classification loss after processing this batch is:  0.1008085384964943\n",
      "The representation loss after processing this batch is:  0.002592310309410095\n",
      "\n",
      "The classification loss after processing this batch is:  0.15657983720302582\n",
      "The representation loss after processing this batch is:  0.002794593572616577\n",
      "\n",
      "The classification loss after processing this batch is:  0.03928161412477493\n",
      "The representation loss after processing this batch is:  0.002882435917854309\n",
      "\n",
      "The classification loss after processing this batch is:  0.06323491036891937\n",
      "The representation loss after processing this batch is:  0.0027126818895339966\n",
      "\n",
      "The classification loss after processing this batch is:  0.17291326820850372\n",
      "The representation loss after processing this batch is:  0.0024064108729362488\n",
      "\n",
      "The classification loss after processing this batch is:  0.18792861700057983\n",
      "The representation loss after processing this batch is:  0.0024971067905426025\n",
      "\n",
      "The classification loss after processing this batch is:  0.09150735288858414\n",
      "The representation loss after processing this batch is:  0.00241638720035553\n",
      "\n",
      "The classification loss after processing this batch is:  0.042850054800510406\n",
      "The representation loss after processing this batch is:  0.0024445056915283203\n",
      "\n",
      "The classification loss after processing this batch is:  0.13334162533283234\n",
      "The representation loss after processing this batch is:  0.0021911300718784332\n",
      "\n",
      "The classification loss after processing this batch is:  0.031822603195905685\n",
      "The representation loss after processing this batch is:  0.0027785897254943848\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1479799598455429\n",
      "The representation loss after processing this batch is:  0.002567760646343231\n",
      "\n",
      "The classification loss after processing this batch is:  0.12957894802093506\n",
      "The representation loss after processing this batch is:  0.002817578613758087\n",
      "\n",
      "The classification loss after processing this batch is:  0.06688977777957916\n",
      "The representation loss after processing this batch is:  0.002350248396396637\n",
      "\n",
      "The classification loss after processing this batch is:  0.0980900302529335\n",
      "The representation loss after processing this batch is:  0.002790093421936035\n",
      "\n",
      "The classification loss after processing this batch is:  0.08802063763141632\n",
      "The representation loss after processing this batch is:  0.002709507942199707\n",
      "\n",
      "The classification loss after processing this batch is:  0.05556295067071915\n",
      "The representation loss after processing this batch is:  0.002489529550075531\n",
      "\n",
      "The classification loss after processing this batch is:  0.234836608171463\n",
      "The representation loss after processing this batch is:  0.0025219321250915527\n",
      "\n",
      "The classification loss after processing this batch is:  0.21083399653434753\n",
      "The representation loss after processing this batch is:  0.0025035887956619263\n",
      "\n",
      "The classification loss after processing this batch is:  0.20362071692943573\n",
      "The representation loss after processing this batch is:  0.0026468075811862946\n",
      "\n",
      "The classification loss after processing this batch is:  0.2096509039402008\n",
      "The representation loss after processing this batch is:  0.0024383962154388428\n",
      "\n",
      "The classification loss after processing this batch is:  0.13414059579372406\n",
      "The representation loss after processing this batch is:  0.0027516186237335205\n",
      "\n",
      "The classification loss after processing this batch is:  0.09367290884256363\n",
      "The representation loss after processing this batch is:  0.002795472741127014\n",
      "\n",
      "The classification loss after processing this batch is:  0.18716080486774445\n",
      "The representation loss after processing this batch is:  0.00261872261762619\n",
      "\n",
      "The classification loss after processing this batch is:  0.11514916270971298\n",
      "The representation loss after processing this batch is:  0.002825804054737091\n",
      "\n",
      "The classification loss after processing this batch is:  0.17852894961833954\n",
      "The representation loss after processing this batch is:  0.0026780106127262115\n",
      "\n",
      "The classification loss after processing this batch is:  0.12368376553058624\n",
      "The representation loss after processing this batch is:  0.002652972936630249\n",
      "\n",
      "The classification loss after processing this batch is:  0.16156569123268127\n",
      "The representation loss after processing this batch is:  0.0024766437709331512\n",
      "\n",
      "The classification loss after processing this batch is:  0.09474703669548035\n",
      "The representation loss after processing this batch is:  0.002667810767889023\n",
      "\n",
      "The classification loss after processing this batch is:  0.09114299714565277\n",
      "The representation loss after processing this batch is:  0.0026193931698799133\n",
      "\n",
      "The classification loss after processing this batch is:  0.15700991451740265\n",
      "The representation loss after processing this batch is:  0.002328425645828247\n",
      "\n",
      "The classification loss after processing this batch is:  0.04977583885192871\n",
      "The representation loss after processing this batch is:  0.002814456820487976\n",
      "\n",
      "The classification loss after processing this batch is:  0.0650525614619255\n",
      "The representation loss after processing this batch is:  0.002732396125793457\n",
      "\n",
      "The classification loss after processing this batch is:  0.1249689906835556\n",
      "The representation loss after processing this batch is:  0.0025078505277633667\n",
      "\n",
      "The classification loss after processing this batch is:  0.20687103271484375\n",
      "The representation loss after processing this batch is:  0.0024441182613372803\n",
      "\n",
      "The classification loss after processing this batch is:  0.059953682124614716\n",
      "The representation loss after processing this batch is:  0.0024340227246284485\n",
      "\n",
      "The classification loss after processing this batch is:  0.08108890801668167\n",
      "The representation loss after processing this batch is:  0.0023650862276554108\n",
      "\n",
      "The classification loss after processing this batch is:  0.1581685096025467\n",
      "The representation loss after processing this batch is:  0.00258704274892807\n",
      "\n",
      "The classification loss after processing this batch is:  0.22206148505210876\n",
      "The representation loss after processing this batch is:  0.0024610385298728943\n",
      "\n",
      "The classification loss after processing this batch is:  0.1054559201002121\n",
      "The representation loss after processing this batch is:  0.0025156736373901367\n",
      "\n",
      "The classification loss after processing this batch is:  0.21808572113513947\n",
      "The representation loss after processing this batch is:  0.002338692545890808\n",
      "\n",
      "The classification loss after processing this batch is:  0.08618737757205963\n",
      "The representation loss after processing this batch is:  0.0029978081583976746\n",
      "\n",
      "The classification loss after processing this batch is:  0.03161453828215599\n",
      "The representation loss after processing this batch is:  0.0023001953959465027\n",
      "\n",
      "The classification loss after processing this batch is:  0.042512670159339905\n",
      "The representation loss after processing this batch is:  0.0026566684246063232\n",
      "\n",
      "The classification loss after processing this batch is:  0.16349078714847565\n",
      "The representation loss after processing this batch is:  0.002995207905769348\n",
      "\n",
      "The classification loss after processing this batch is:  0.14888662099838257\n",
      "The representation loss after processing this batch is:  0.003020770847797394\n",
      "\n",
      "The classification loss after processing this batch is:  0.097704216837883\n",
      "The representation loss after processing this batch is:  0.00352410227060318\n",
      "\n",
      "The classification loss after processing this batch is:  0.11126255989074707\n",
      "The representation loss after processing this batch is:  0.0026338770985603333\n",
      "\n",
      "The classification loss after processing this batch is:  0.11303789913654327\n",
      "The representation loss after processing this batch is:  0.0024943798780441284\n",
      "\n",
      "The classification loss after processing this batch is:  0.13765405118465424\n",
      "The representation loss after processing this batch is:  0.0024950355291366577\n",
      "\n",
      "The classification loss after processing this batch is:  0.1211862564086914\n",
      "The representation loss after processing this batch is:  0.002228483557701111\n",
      "\n",
      "The classification loss after processing this batch is:  0.16535551846027374\n",
      "The representation loss after processing this batch is:  0.002428881824016571\n",
      "\n",
      "The classification loss after processing this batch is:  0.15020109713077545\n",
      "The representation loss after processing this batch is:  0.0028214231133461\n",
      "\n",
      "The classification loss after processing this batch is:  0.2720434367656708\n",
      "The representation loss after processing this batch is:  0.0024778172373771667\n",
      "\n",
      "The classification loss after processing this batch is:  0.13897594809532166\n",
      "The representation loss after processing this batch is:  0.0024029389023780823\n",
      "\n",
      "The classification loss after processing this batch is:  0.14395229518413544\n",
      "The representation loss after processing this batch is:  0.0025760680437088013\n",
      "\n",
      "The classification loss after processing this batch is:  0.16951747238636017\n",
      "The representation loss after processing this batch is:  0.0024703890085220337\n",
      "\n",
      "The classification loss after processing this batch is:  0.058972589671611786\n",
      "The representation loss after processing this batch is:  0.0024406835436820984\n",
      "\n",
      "The classification loss after processing this batch is:  0.11739946156740189\n",
      "The representation loss after processing this batch is:  0.0033099502325057983\n",
      "\n",
      "The classification loss after processing this batch is:  0.09018636494874954\n",
      "The representation loss after processing this batch is:  0.0027553588151931763\n",
      "\n",
      "The classification loss after processing this batch is:  0.13410428166389465\n",
      "The representation loss after processing this batch is:  0.0026934482157230377\n",
      "\n",
      "The classification loss after processing this batch is:  0.07854726165533066\n",
      "The representation loss after processing this batch is:  0.0022422783076763153\n",
      "\n",
      "The classification loss after processing this batch is:  0.1132606565952301\n",
      "The representation loss after processing this batch is:  0.002424962818622589\n",
      "\n",
      "The classification loss after processing this batch is:  0.10730225592851639\n",
      "The representation loss after processing this batch is:  0.0025410205125808716\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.15309210121631622\n",
      "The representation loss after processing this batch is:  0.0023714229464530945\n",
      "\n",
      "The classification loss after processing this batch is:  0.1324099749326706\n",
      "The representation loss after processing this batch is:  0.002695217728614807\n",
      "\n",
      "The classification loss after processing this batch is:  0.21401315927505493\n",
      "The representation loss after processing this batch is:  0.002514660358428955\n",
      "\n",
      "The classification loss after processing this batch is:  0.10045567899942398\n",
      "The representation loss after processing this batch is:  0.0027787908911705017\n",
      "\n",
      "The classification loss after processing this batch is:  0.12063832581043243\n",
      "The representation loss after processing this batch is:  0.0023081786930561066\n",
      "\n",
      "The classification loss after processing this batch is:  0.10967447608709335\n",
      "The representation loss after processing this batch is:  0.0025815144181251526\n",
      "\n",
      "The classification loss after processing this batch is:  0.2273685485124588\n",
      "The representation loss after processing this batch is:  0.0031232833862304688\n",
      "\n",
      "The classification loss after processing this batch is:  0.26058468222618103\n",
      "The representation loss after processing this batch is:  0.002797551453113556\n",
      "\n",
      "The classification loss after processing this batch is:  0.04640110209584236\n",
      "The representation loss after processing this batch is:  0.0022796913981437683\n",
      "\n",
      "The classification loss after processing this batch is:  0.062082283198833466\n",
      "The representation loss after processing this batch is:  0.002866312861442566\n",
      "\n",
      "The classification loss after processing this batch is:  0.23098351061344147\n",
      "The representation loss after processing this batch is:  0.002773042768239975\n",
      "\n",
      "The classification loss after processing this batch is:  0.08649689704179764\n",
      "The representation loss after processing this batch is:  0.003009714186191559\n",
      "\n",
      "The classification loss after processing this batch is:  0.08254248648881912\n",
      "The representation loss after processing this batch is:  0.0025014206767082214\n",
      "\n",
      "The classification loss after processing this batch is:  0.12880443036556244\n",
      "The representation loss after processing this batch is:  0.0024674981832504272\n",
      "\n",
      "The classification loss after processing this batch is:  0.10452084243297577\n",
      "The representation loss after processing this batch is:  0.0028689950704574585\n",
      "\n",
      "The classification loss after processing this batch is:  0.22790376842021942\n",
      "The representation loss after processing this batch is:  0.003124929964542389\n",
      "\n",
      "The classification loss after processing this batch is:  0.1460711658000946\n",
      "The representation loss after processing this batch is:  0.003015585243701935\n",
      "\n",
      "The classification loss after processing this batch is:  0.16358080506324768\n",
      "The representation loss after processing this batch is:  0.0031919777393341064\n",
      "\n",
      "The classification loss after processing this batch is:  0.08651041239500046\n",
      "The representation loss after processing this batch is:  0.0022574737668037415\n",
      "\n",
      "The classification loss after processing this batch is:  0.200821653008461\n",
      "The representation loss after processing this batch is:  0.0024625398218631744\n",
      "\n",
      "The classification loss after processing this batch is:  0.05287747457623482\n",
      "The representation loss after processing this batch is:  0.0024380460381507874\n",
      "\n",
      "The classification loss after processing this batch is:  0.07004715502262115\n",
      "The representation loss after processing this batch is:  0.0027165487408638\n",
      "\n",
      "The classification loss after processing this batch is:  0.10652139782905579\n",
      "The representation loss after processing this batch is:  0.0024420469999313354\n",
      "\n",
      "The classification loss after processing this batch is:  0.06346382200717926\n",
      "The representation loss after processing this batch is:  0.0024168044328689575\n",
      "\n",
      "The classification loss after processing this batch is:  0.08481202274560928\n",
      "The representation loss after processing this batch is:  0.0027253031730651855\n",
      "\n",
      "The classification loss after processing this batch is:  0.059781212359666824\n",
      "The representation loss after processing this batch is:  0.0027811378240585327\n",
      "\n",
      "The classification loss after processing this batch is:  0.08594315499067307\n",
      "The representation loss after processing this batch is:  0.002657514065504074\n",
      "\n",
      "The classification loss after processing this batch is:  0.1216307058930397\n",
      "The representation loss after processing this batch is:  0.002696290612220764\n",
      "\n",
      "The classification loss after processing this batch is:  0.15310996770858765\n",
      "The representation loss after processing this batch is:  0.0027275830507278442\n",
      "\n",
      "The classification loss after processing this batch is:  0.180217444896698\n",
      "The representation loss after processing this batch is:  0.0023233629763126373\n",
      "\n",
      "The classification loss after processing this batch is:  0.1548219472169876\n",
      "The representation loss after processing this batch is:  0.0031974464654922485\n",
      "\n",
      "The classification loss after processing this batch is:  0.2008054405450821\n",
      "The representation loss after processing this batch is:  0.0027052797377109528\n",
      "\n",
      "The classification loss after processing this batch is:  0.059298522770404816\n",
      "The representation loss after processing this batch is:  0.0025457292795181274\n",
      "\n",
      "The classification loss after processing this batch is:  0.15891829133033752\n",
      "The representation loss after processing this batch is:  0.0025765225291252136\n",
      "\n",
      "The classification loss after processing this batch is:  0.2550297975540161\n",
      "The representation loss after processing this batch is:  0.0026678070425987244\n",
      "\n",
      "The classification loss after processing this batch is:  0.13452230393886566\n",
      "The representation loss after processing this batch is:  0.0022802427411079407\n",
      "\n",
      "The classification loss after processing this batch is:  0.19539646804332733\n",
      "The representation loss after processing this batch is:  0.0025361888110637665\n",
      "\n",
      "The classification loss after processing this batch is:  0.1686275452375412\n",
      "The representation loss after processing this batch is:  0.0024928152561187744\n",
      "\n",
      "The classification loss after processing this batch is:  0.15628725290298462\n",
      "The representation loss after processing this batch is:  0.0025933459401130676\n",
      "\n",
      "The classification loss after processing this batch is:  0.12904603779315948\n",
      "The representation loss after processing this batch is:  0.0026864036917686462\n",
      "\n",
      "The classification loss after processing this batch is:  0.0915437564253807\n",
      "The representation loss after processing this batch is:  0.0025707632303237915\n",
      "\n",
      "The classification loss after processing this batch is:  0.11044240742921829\n",
      "The representation loss after processing this batch is:  0.0026183202862739563\n",
      "\n",
      "The classification loss after processing this batch is:  0.05352902412414551\n",
      "The representation loss after processing this batch is:  0.0027133971452713013\n",
      "\n",
      "The classification loss after processing this batch is:  0.046606358140707016\n",
      "The representation loss after processing this batch is:  0.002466246485710144\n",
      "\n",
      "The classification loss after processing this batch is:  0.10864317417144775\n",
      "The representation loss after processing this batch is:  0.0029193684458732605\n",
      "\n",
      "The classification loss after processing this batch is:  0.05574241653084755\n",
      "The representation loss after processing this batch is:  0.002724260091781616\n",
      "\n",
      "The classification loss after processing this batch is:  0.22675465047359467\n",
      "The representation loss after processing this batch is:  0.0032836981117725372\n",
      "\n",
      "The classification loss after processing this batch is:  0.1344500184059143\n",
      "The representation loss after processing this batch is:  0.002454303205013275\n",
      "\n",
      "The classification loss after processing this batch is:  0.17804458737373352\n",
      "The representation loss after processing this batch is:  0.0028846412897109985\n",
      "\n",
      "The classification loss after processing this batch is:  0.32013043761253357\n",
      "The representation loss after processing this batch is:  0.0025078952312469482\n",
      "\n",
      "The classification loss after processing this batch is:  0.15421180427074432\n",
      "The representation loss after processing this batch is:  0.002577889710664749\n",
      "\n",
      "The classification loss after processing this batch is:  0.04714882746338844\n",
      "The representation loss after processing this batch is:  0.0025729089975357056\n",
      "\n",
      "The classification loss after processing this batch is:  0.07933519035577774\n",
      "The representation loss after processing this batch is:  0.00283137708902359\n",
      "\n",
      "The classification loss after processing this batch is:  0.07555899769067764\n",
      "The representation loss after processing this batch is:  0.002808190882205963\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08969561755657196\n",
      "The representation loss after processing this batch is:  0.0028002187609672546\n",
      "\n",
      "The classification loss after processing this batch is:  0.10234670341014862\n",
      "The representation loss after processing this batch is:  0.0023404136300086975\n",
      "\n",
      "The classification loss after processing this batch is:  0.2234661877155304\n",
      "The representation loss after processing this batch is:  0.0022250451147556305\n",
      "\n",
      "The classification loss after processing this batch is:  0.19352518022060394\n",
      "The representation loss after processing this batch is:  0.002461940050125122\n",
      "\n",
      "The classification loss after processing this batch is:  0.1482093781232834\n",
      "The representation loss after processing this batch is:  0.002884872257709503\n",
      "\n",
      "The classification loss after processing this batch is:  0.22949086129665375\n",
      "The representation loss after processing this batch is:  0.0028757303953170776\n",
      "\n",
      "The classification loss after processing this batch is:  0.085067018866539\n",
      "The representation loss after processing this batch is:  0.0026132985949516296\n",
      "\n",
      "The classification loss after processing this batch is:  0.12166837602853775\n",
      "The representation loss after processing this batch is:  0.0025686509907245636\n",
      "\n",
      "The classification loss after processing this batch is:  0.21143049001693726\n",
      "The representation loss after processing this batch is:  0.0024630241096019745\n",
      "\n",
      "The classification loss after processing this batch is:  0.10930560529232025\n",
      "The representation loss after processing this batch is:  0.00302162766456604\n",
      "\n",
      "The classification loss after processing this batch is:  0.14383439719676971\n",
      "The representation loss after processing this batch is:  0.003512248396873474\n",
      "\n",
      "The classification loss after processing this batch is:  0.07745251059532166\n",
      "The representation loss after processing this batch is:  0.0029072798788547516\n",
      "\n",
      "The classification loss after processing this batch is:  0.15654399991035461\n",
      "The representation loss after processing this batch is:  0.00332525372505188\n",
      "\n",
      "The classification loss after processing this batch is:  0.17494462430477142\n",
      "The representation loss after processing this batch is:  0.0030164942145347595\n",
      "\n",
      "The classification loss after processing this batch is:  0.11111675202846527\n",
      "The representation loss after processing this batch is:  0.002808593213558197\n",
      "\n",
      "The classification loss after processing this batch is:  0.14700819551944733\n",
      "The representation loss after processing this batch is:  0.003163553774356842\n",
      "\n",
      "The classification loss after processing this batch is:  0.20079723000526428\n",
      "The representation loss after processing this batch is:  0.0021942630410194397\n",
      "\n",
      "The classification loss after processing this batch is:  0.11941131204366684\n",
      "The representation loss after processing this batch is:  0.0025769174098968506\n",
      "\n",
      "The classification loss after processing this batch is:  0.1480044573545456\n",
      "The representation loss after processing this batch is:  0.0026377514004707336\n",
      "\n",
      "The classification loss after processing this batch is:  0.07767133414745331\n",
      "The representation loss after processing this batch is:  0.003069758415222168\n",
      "\n",
      "The classification loss after processing this batch is:  0.03075174055993557\n",
      "The representation loss after processing this batch is:  0.0028951242566108704\n",
      "\n",
      "The classification loss after processing this batch is:  0.11000668257474899\n",
      "The representation loss after processing this batch is:  0.002791456878185272\n",
      "\n",
      "The classification loss after processing this batch is:  0.07973934710025787\n",
      "The representation loss after processing this batch is:  0.002856619656085968\n",
      "\n",
      "The classification loss after processing this batch is:  0.2700236141681671\n",
      "The representation loss after processing this batch is:  0.0023541636765003204\n",
      "\n",
      "The classification loss after processing this batch is:  0.0535770058631897\n",
      "The representation loss after processing this batch is:  0.002749323844909668\n",
      "\n",
      "The classification loss after processing this batch is:  0.10860639065504074\n",
      "The representation loss after processing this batch is:  0.002472296357154846\n",
      "\n",
      "The classification loss after processing this batch is:  0.14978566765785217\n",
      "The representation loss after processing this batch is:  0.002747759222984314\n",
      "\n",
      "The classification loss after processing this batch is:  0.11671232432126999\n",
      "The representation loss after processing this batch is:  0.0026125237345695496\n",
      "\n",
      "The classification loss after processing this batch is:  0.14177890121936798\n",
      "The representation loss after processing this batch is:  0.002791173756122589\n",
      "\n",
      "The classification loss after processing this batch is:  0.06026051566004753\n",
      "The representation loss after processing this batch is:  0.0025669336318969727\n",
      "\n",
      "The classification loss after processing this batch is:  0.05540703609585762\n",
      "The representation loss after processing this batch is:  0.002517111599445343\n",
      "\n",
      "The classification loss after processing this batch is:  0.073455311357975\n",
      "The representation loss after processing this batch is:  0.0027001798152923584\n",
      "\n",
      "The classification loss after processing this batch is:  0.16991743445396423\n",
      "The representation loss after processing this batch is:  0.0032286271452903748\n",
      "\n",
      "The classification loss after processing this batch is:  0.21182869374752045\n",
      "The representation loss after processing this batch is:  0.0026052817702293396\n",
      "\n",
      "The classification loss after processing this batch is:  0.13594938814640045\n",
      "The representation loss after processing this batch is:  0.002245355397462845\n",
      "\n",
      "The classification loss after processing this batch is:  0.15857146680355072\n",
      "The representation loss after processing this batch is:  0.0025590285658836365\n",
      "\n",
      "The classification loss after processing this batch is:  0.2271248996257782\n",
      "The representation loss after processing this batch is:  0.002445310354232788\n",
      "\n",
      "The classification loss after processing this batch is:  0.11167679727077484\n",
      "The representation loss after processing this batch is:  0.002717643976211548\n",
      "\n",
      "The classification loss after processing this batch is:  0.21865424513816833\n",
      "The representation loss after processing this batch is:  0.0027075186371803284\n",
      "\n",
      "The classification loss after processing this batch is:  0.10755046457052231\n",
      "The representation loss after processing this batch is:  0.0027162358164787292\n",
      "\n",
      "The classification loss after processing this batch is:  0.07292471081018448\n",
      "The representation loss after processing this batch is:  0.002538040280342102\n",
      "\n",
      "The classification loss after processing this batch is:  0.06478885561227798\n",
      "The representation loss after processing this batch is:  0.002435721457004547\n",
      "\n",
      "The classification loss after processing this batch is:  0.08245433866977692\n",
      "The representation loss after processing this batch is:  0.002604953944683075\n",
      "\n",
      "The classification loss after processing this batch is:  0.27259305119514465\n",
      "The representation loss after processing this batch is:  0.0027315616607666016\n",
      "\n",
      "The classification loss after processing this batch is:  0.09324904531240463\n",
      "The representation loss after processing this batch is:  0.0025609731674194336\n",
      "\n",
      "The classification loss after processing this batch is:  0.1446978896856308\n",
      "The representation loss after processing this batch is:  0.002991899847984314\n",
      "\n",
      "The classification loss after processing this batch is:  0.13440202176570892\n",
      "The representation loss after processing this batch is:  0.0030353814363479614\n",
      "\n",
      "The classification loss after processing this batch is:  0.12037479132413864\n",
      "The representation loss after processing this batch is:  0.002727232873439789\n",
      "\n",
      "The classification loss after processing this batch is:  0.0784066766500473\n",
      "The representation loss after processing this batch is:  0.00268535315990448\n",
      "\n",
      "The classification loss after processing this batch is:  0.17249202728271484\n",
      "The representation loss after processing this batch is:  0.0024519190192222595\n",
      "\n",
      "The classification loss after processing this batch is:  0.18888896703720093\n",
      "The representation loss after processing this batch is:  0.002470012754201889\n",
      "\n",
      "The classification loss after processing this batch is:  0.17486810684204102\n",
      "The representation loss after processing this batch is:  0.002992764115333557\n",
      "\n",
      "The classification loss after processing this batch is:  0.07573850452899933\n",
      "The representation loss after processing this batch is:  0.0025864839553833008\n",
      "\n",
      "The classification loss after processing this batch is:  0.30893567204475403\n",
      "The representation loss after processing this batch is:  0.0022960901260375977\n",
      "\n",
      "The classification loss after processing this batch is:  0.08481709659099579\n",
      "The representation loss after processing this batch is:  0.0023600347340106964\n",
      "\n",
      "The classification loss after processing this batch is:  0.08993934094905853\n",
      "The representation loss after processing this batch is:  0.0023101046681404114\n",
      "\n",
      "The classification loss after processing this batch is:  0.12551410496234894\n",
      "The representation loss after processing this batch is:  0.0029244720935821533\n",
      "\n",
      "The classification loss after processing this batch is:  0.08773098140954971\n",
      "The representation loss after processing this batch is:  0.0025723129510879517\n",
      "\n",
      "The classification loss after processing this batch is:  0.09408655017614365\n",
      "The representation loss after processing this batch is:  0.00251074880361557\n",
      "\n",
      "The classification loss after processing this batch is:  0.08907989412546158\n",
      "The representation loss after processing this batch is:  0.002843335270881653\n",
      "\n",
      "The classification loss after processing this batch is:  0.1827119141817093\n",
      "The representation loss after processing this batch is:  0.00270288810133934\n",
      "\n",
      "The classification loss after processing this batch is:  0.19827105104923248\n",
      "The representation loss after processing this batch is:  0.0025651082396507263\n",
      "\n",
      "The classification loss after processing this batch is:  0.17280028760433197\n",
      "The representation loss after processing this batch is:  0.0025436729192733765\n",
      "\n",
      "The classification loss after processing this batch is:  0.1200251430273056\n",
      "The representation loss after processing this batch is:  0.002767525613307953\n",
      "\n",
      "The classification loss after processing this batch is:  0.12430892139673233\n",
      "The representation loss after processing this batch is:  0.0032697096467018127\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1632998287677765\n",
      "The representation loss after processing this batch is:  0.0022992826998233795\n",
      "\n",
      "The classification loss after processing this batch is:  0.140481099486351\n",
      "The representation loss after processing this batch is:  0.0024831555783748627\n",
      "\n",
      "The classification loss after processing this batch is:  0.02589181251823902\n",
      "The representation loss after processing this batch is:  0.002702571451663971\n",
      "\n",
      "The classification loss after processing this batch is:  0.11074052006006241\n",
      "The representation loss after processing this batch is:  0.0023804381489753723\n",
      "\n",
      "The classification loss after processing this batch is:  0.25642073154449463\n",
      "The representation loss after processing this batch is:  0.002685829997062683\n",
      "\n",
      "The classification loss after processing this batch is:  0.29812800884246826\n",
      "The representation loss after processing this batch is:  0.00271790474653244\n",
      "\n",
      "The classification loss after processing this batch is:  0.24287913739681244\n",
      "The representation loss after processing this batch is:  0.002472285181283951\n",
      "\n",
      "The classification loss after processing this batch is:  0.16656659543514252\n",
      "The representation loss after processing this batch is:  0.002299647778272629\n",
      "\n",
      "The classification loss after processing this batch is:  0.05362953618168831\n",
      "The representation loss after processing this batch is:  0.0025508366525173187\n",
      "\n",
      "The classification loss after processing this batch is:  0.11688811331987381\n",
      "The representation loss after processing this batch is:  0.0024298131465911865\n",
      "\n",
      "The classification loss after processing this batch is:  0.10776498168706894\n",
      "The representation loss after processing this batch is:  0.0029481276869773865\n",
      "\n",
      "The classification loss after processing this batch is:  0.17175334692001343\n",
      "The representation loss after processing this batch is:  0.0029056742787361145\n",
      "\n",
      "The classification loss after processing this batch is:  0.15675702691078186\n",
      "The representation loss after processing this batch is:  0.0028059855103492737\n",
      "\n",
      "The classification loss after processing this batch is:  0.15050378441810608\n",
      "The representation loss after processing this batch is:  0.0030731037259101868\n",
      "\n",
      "The classification loss after processing this batch is:  0.09898386895656586\n",
      "The representation loss after processing this batch is:  0.0025908201932907104\n",
      "\n",
      "The classification loss after processing this batch is:  0.11015171557664871\n",
      "The representation loss after processing this batch is:  0.00255642831325531\n",
      "\n",
      "The classification loss after processing this batch is:  0.17401936650276184\n",
      "The representation loss after processing this batch is:  0.0029144957661628723\n",
      "\n",
      "The classification loss after processing this batch is:  0.1673891842365265\n",
      "The representation loss after processing this batch is:  0.0026047229766845703\n",
      "\n",
      "The classification loss after processing this batch is:  0.11309158056974411\n",
      "The representation loss after processing this batch is:  0.0022681094706058502\n",
      "\n",
      "The classification loss after processing this batch is:  0.2509872317314148\n",
      "The representation loss after processing this batch is:  0.0032339468598365784\n",
      "\n",
      "The classification loss after processing this batch is:  0.31234264373779297\n",
      "The representation loss after processing this batch is:  0.0027894489467144012\n",
      "\n",
      "The classification loss after processing this batch is:  0.1716122329235077\n",
      "The representation loss after processing this batch is:  0.0029397234320640564\n",
      "\n",
      "The classification loss after processing this batch is:  0.1349145472049713\n",
      "The representation loss after processing this batch is:  0.002734176814556122\n",
      "\n",
      "The classification loss after processing this batch is:  0.09729795157909393\n",
      "The representation loss after processing this batch is:  0.00314350426197052\n",
      "\n",
      "The classification loss after processing this batch is:  0.043253589421510696\n",
      "The representation loss after processing this batch is:  0.002728976309299469\n",
      "\n",
      "The classification loss after processing this batch is:  0.19698843359947205\n",
      "The representation loss after processing this batch is:  0.002518177032470703\n",
      "\n",
      "The classification loss after processing this batch is:  0.17024794220924377\n",
      "The representation loss after processing this batch is:  0.0029305070638656616\n",
      "\n",
      "The classification loss after processing this batch is:  0.11210634559392929\n",
      "The representation loss after processing this batch is:  0.003087662160396576\n",
      "\n",
      "The classification loss after processing this batch is:  0.2392737865447998\n",
      "The representation loss after processing this batch is:  0.002551540732383728\n",
      "\n",
      "The classification loss after processing this batch is:  0.05525945499539375\n",
      "The representation loss after processing this batch is:  0.0026155859231948853\n",
      "\n",
      "The classification loss after processing this batch is:  0.061320189386606216\n",
      "The representation loss after processing this batch is:  0.0029065310955047607\n",
      "\n",
      "The classification loss after processing this batch is:  0.09390696883201599\n",
      "The representation loss after processing this batch is:  0.002499915659427643\n",
      "\n",
      "The classification loss after processing this batch is:  0.1291741579771042\n",
      "The representation loss after processing this batch is:  0.0025259293615818024\n",
      "\n",
      "The classification loss after processing this batch is:  0.15696555376052856\n",
      "The representation loss after processing this batch is:  0.0029279738664627075\n",
      "\n",
      "The classification loss after processing this batch is:  0.1152607649564743\n",
      "The representation loss after processing this batch is:  0.002658560872077942\n",
      "\n",
      "The classification loss after processing this batch is:  0.10401671379804611\n",
      "The representation loss after processing this batch is:  0.002640366554260254\n",
      "\n",
      "The classification loss after processing this batch is:  0.05470554530620575\n",
      "The representation loss after processing this batch is:  0.0026511922478675842\n",
      "\n",
      "The classification loss after processing this batch is:  0.052210088819265366\n",
      "The representation loss after processing this batch is:  0.0025291070342063904\n",
      "\n",
      "The classification loss after processing this batch is:  0.0880298838019371\n",
      "The representation loss after processing this batch is:  0.0027993693947792053\n",
      "\n",
      "The classification loss after processing this batch is:  0.052300404757261276\n",
      "The representation loss after processing this batch is:  0.002776600420475006\n",
      "\n",
      "The classification loss after processing this batch is:  0.10321889817714691\n",
      "The representation loss after processing this batch is:  0.002338852733373642\n",
      "\n",
      "The classification loss after processing this batch is:  0.16982623934745789\n",
      "The representation loss after processing this batch is:  0.002549789845943451\n",
      "\n",
      "The classification loss after processing this batch is:  0.19392751157283783\n",
      "The representation loss after processing this batch is:  0.002836279571056366\n",
      "\n",
      "The classification loss after processing this batch is:  0.04336824268102646\n",
      "The representation loss after processing this batch is:  0.002148076891899109\n",
      "\n",
      "The classification loss after processing this batch is:  0.07317009568214417\n",
      "The representation loss after processing this batch is:  0.0024562105536460876\n",
      "\n",
      "The classification loss after processing this batch is:  0.1133941262960434\n",
      "The representation loss after processing this batch is:  0.0029746517539024353\n",
      "\n",
      "The classification loss after processing this batch is:  0.16295842826366425\n",
      "The representation loss after processing this batch is:  0.0025847963988780975\n",
      "\n",
      "The classification loss after processing this batch is:  0.06506408751010895\n",
      "The representation loss after processing this batch is:  0.0029923319816589355\n",
      "\n",
      "The classification loss after processing this batch is:  0.1891981065273285\n",
      "The representation loss after processing this batch is:  0.0032297223806381226\n",
      "\n",
      "The classification loss after processing this batch is:  0.17530426383018494\n",
      "The representation loss after processing this batch is:  0.00260741263628006\n",
      "\n",
      "The classification loss after processing this batch is:  0.2057950645685196\n",
      "The representation loss after processing this batch is:  0.002690110355615616\n",
      "\n",
      "The classification loss after processing this batch is:  0.11826355010271072\n",
      "The representation loss after processing this batch is:  0.0026467740535736084\n",
      "\n",
      "The classification loss after processing this batch is:  0.07590583711862564\n",
      "The representation loss after processing this batch is:  0.0025731250643730164\n",
      "\n",
      "The classification loss after processing this batch is:  0.10633893311023712\n",
      "The representation loss after processing this batch is:  0.0026876553893089294\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1596808135509491\n",
      "The representation loss after processing this batch is:  0.0026653632521629333\n",
      "\n",
      "The classification loss after processing this batch is:  0.07811185717582703\n",
      "The representation loss after processing this batch is:  0.0025429129600524902\n",
      "\n",
      "The classification loss after processing this batch is:  0.03344420716166496\n",
      "The representation loss after processing this batch is:  0.002292647957801819\n",
      "\n",
      "The classification loss after processing this batch is:  0.21736760437488556\n",
      "The representation loss after processing this batch is:  0.0027747228741645813\n",
      "\n",
      "The classification loss after processing this batch is:  0.21229912340641022\n",
      "The representation loss after processing this batch is:  0.002505313605070114\n",
      "\n",
      "The classification loss after processing this batch is:  0.09713727980852127\n",
      "The representation loss after processing this batch is:  0.00236530601978302\n",
      "\n",
      "The classification loss after processing this batch is:  0.26184749603271484\n",
      "The representation loss after processing this batch is:  0.0024773478507995605\n",
      "\n",
      "The classification loss after processing this batch is:  0.23501577973365784\n",
      "The representation loss after processing this batch is:  0.00267588347196579\n",
      "\n",
      "The classification loss after processing this batch is:  0.30644190311431885\n",
      "The representation loss after processing this batch is:  0.002552211284637451\n",
      "\n",
      "The classification loss after processing this batch is:  0.15594039857387543\n",
      "The representation loss after processing this batch is:  0.0025345459580421448\n",
      "\n",
      "The classification loss after processing this batch is:  0.09098341315984726\n",
      "The representation loss after processing this batch is:  0.00244971364736557\n",
      "\n",
      "The classification loss after processing this batch is:  0.16200730204582214\n",
      "The representation loss after processing this batch is:  0.002673014998435974\n",
      "\n",
      "The classification loss after processing this batch is:  0.09187886118888855\n",
      "The representation loss after processing this batch is:  0.0026460587978363037\n",
      "\n",
      "The classification loss after processing this batch is:  0.07293098419904709\n",
      "The representation loss after processing this batch is:  0.0026789456605911255\n",
      "\n",
      "The classification loss after processing this batch is:  0.08478717505931854\n",
      "The representation loss after processing this batch is:  0.0024204999208450317\n",
      "\n",
      "The classification loss after processing this batch is:  0.05542035773396492\n",
      "The representation loss after processing this batch is:  0.0024032294750213623\n",
      "\n",
      "The classification loss after processing this batch is:  0.03439461067318916\n",
      "The representation loss after processing this batch is:  0.003044120967388153\n",
      "\n",
      "The classification loss after processing this batch is:  0.13734516501426697\n",
      "The representation loss after processing this batch is:  0.00269341841340065\n",
      "\n",
      "The classification loss after processing this batch is:  0.17254206538200378\n",
      "The representation loss after processing this batch is:  0.002428218722343445\n",
      "\n",
      "The classification loss after processing this batch is:  0.06801221519708633\n",
      "The representation loss after processing this batch is:  0.0027594268321990967\n",
      "\n",
      "The classification loss after processing this batch is:  0.09085562825202942\n",
      "The representation loss after processing this batch is:  0.002405136823654175\n",
      "\n",
      "The classification loss after processing this batch is:  0.1172456219792366\n",
      "The representation loss after processing this batch is:  0.0025523528456687927\n",
      "\n",
      "The classification loss after processing this batch is:  0.03550725057721138\n",
      "The representation loss after processing this batch is:  0.002521708607673645\n",
      "\n",
      "The classification loss after processing this batch is:  0.21013511717319489\n",
      "The representation loss after processing this batch is:  0.002578623592853546\n",
      "\n",
      "The classification loss after processing this batch is:  0.09367923438549042\n",
      "The representation loss after processing this batch is:  0.0023992955684661865\n",
      "\n",
      "The classification loss after processing this batch is:  0.2599424123764038\n",
      "The representation loss after processing this batch is:  0.0025389865040779114\n",
      "\n",
      "The classification loss after processing this batch is:  0.13731008768081665\n",
      "The representation loss after processing this batch is:  0.0026009082794189453\n",
      "\n",
      "The classification loss after processing this batch is:  0.15312053263187408\n",
      "The representation loss after processing this batch is:  0.002474777400493622\n",
      "\n",
      "The classification loss after processing this batch is:  0.03548561781644821\n",
      "The representation loss after processing this batch is:  0.0027710646390914917\n",
      "\n",
      "The classification loss after processing this batch is:  0.0487540178000927\n",
      "The representation loss after processing this batch is:  0.0023248717188835144\n",
      "\n",
      "The classification loss after processing this batch is:  0.16553521156311035\n",
      "The representation loss after processing this batch is:  0.0024097785353660583\n",
      "\n",
      "The classification loss after processing this batch is:  0.06534194201231003\n",
      "The representation loss after processing this batch is:  0.0028747394680976868\n",
      "\n",
      "The classification loss after processing this batch is:  0.13522712886333466\n",
      "The representation loss after processing this batch is:  0.002653852105140686\n",
      "\n",
      "The classification loss after processing this batch is:  0.09920573979616165\n",
      "The representation loss after processing this batch is:  0.00284779816865921\n",
      "\n",
      "The classification loss after processing this batch is:  0.0940886065363884\n",
      "The representation loss after processing this batch is:  0.002987802028656006\n",
      "\n",
      "The classification loss after processing this batch is:  0.1560465544462204\n",
      "The representation loss after processing this batch is:  0.0025428682565689087\n",
      "\n",
      "The classification loss after processing this batch is:  0.07445767521858215\n",
      "The representation loss after processing this batch is:  0.002785421907901764\n",
      "\n",
      "The classification loss after processing this batch is:  0.12475042045116425\n",
      "The representation loss after processing this batch is:  0.0028197169303894043\n",
      "\n",
      "The classification loss after processing this batch is:  0.21709121763706207\n",
      "The representation loss after processing this batch is:  0.0027444884181022644\n",
      "\n",
      "The classification loss after processing this batch is:  0.1576012223958969\n",
      "The representation loss after processing this batch is:  0.0028341859579086304\n",
      "\n",
      "The classification loss after processing this batch is:  0.21887697279453278\n",
      "The representation loss after processing this batch is:  0.0023725032806396484\n",
      "\n",
      "The classification loss after processing this batch is:  0.19976599514484406\n",
      "The representation loss after processing this batch is:  0.0026041045784950256\n",
      "\n",
      "The classification loss after processing this batch is:  0.1388290524482727\n",
      "The representation loss after processing this batch is:  0.002329118549823761\n",
      "\n",
      "The classification loss after processing this batch is:  0.0946572870016098\n",
      "The representation loss after processing this batch is:  0.0025732293725013733\n",
      "\n",
      "The classification loss after processing this batch is:  0.0662895143032074\n",
      "The representation loss after processing this batch is:  0.0024665966629981995\n",
      "\n",
      "The classification loss after processing this batch is:  0.09359642118215561\n",
      "The representation loss after processing this batch is:  0.0026106834411621094\n",
      "\n",
      "The classification loss after processing this batch is:  0.05910605937242508\n",
      "The representation loss after processing this batch is:  0.002776898443698883\n",
      "\n",
      "The classification loss after processing this batch is:  0.10600276291370392\n",
      "The representation loss after processing this batch is:  0.0021801069378852844\n",
      "\n",
      "The classification loss after processing this batch is:  0.108843132853508\n",
      "The representation loss after processing this batch is:  0.0025187060236930847\n",
      "\n",
      "The classification loss after processing this batch is:  0.10834455490112305\n",
      "The representation loss after processing this batch is:  0.0028343722224235535\n",
      "\n",
      "The classification loss after processing this batch is:  0.08693092316389084\n",
      "The representation loss after processing this batch is:  0.0025068894028663635\n",
      "\n",
      "The classification loss after processing this batch is:  0.14641278982162476\n",
      "The representation loss after processing this batch is:  0.0022486820816993713\n",
      "\n",
      "The classification loss after processing this batch is:  0.07608537375926971\n",
      "The representation loss after processing this batch is:  0.002576090395450592\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14815720915794373\n",
      "The representation loss after processing this batch is:  0.0025744810700416565\n",
      "\n",
      "The classification loss after processing this batch is:  0.1445775330066681\n",
      "The representation loss after processing this batch is:  0.0025300607085227966\n",
      "\n",
      "The classification loss after processing this batch is:  0.11268305033445358\n",
      "The representation loss after processing this batch is:  0.0027477964758872986\n",
      "\n",
      "The classification loss after processing this batch is:  0.07385174185037613\n",
      "The representation loss after processing this batch is:  0.0028693079948425293\n",
      "\n",
      "The classification loss after processing this batch is:  0.18996717035770416\n",
      "The representation loss after processing this batch is:  0.0026000812649726868\n",
      "\n",
      "The classification loss after processing this batch is:  0.06987491250038147\n",
      "The representation loss after processing this batch is:  0.0026320144534111023\n",
      "\n",
      "The classification loss after processing this batch is:  0.06779894977807999\n",
      "The representation loss after processing this batch is:  0.002592705190181732\n",
      "\n",
      "The classification loss after processing this batch is:  0.12775935232639313\n",
      "The representation loss after processing this batch is:  0.0025247111916542053\n",
      "\n",
      "The classification loss after processing this batch is:  0.058039452880620956\n",
      "The representation loss after processing this batch is:  0.0028573349118232727\n",
      "\n",
      "The classification loss after processing this batch is:  0.1319035440683365\n",
      "The representation loss after processing this batch is:  0.0023322366178035736\n",
      "\n",
      "The classification loss after processing this batch is:  0.1726079285144806\n",
      "The representation loss after processing this batch is:  0.002708207815885544\n",
      "\n",
      "The classification loss after processing this batch is:  0.09140367805957794\n",
      "The representation loss after processing this batch is:  0.0027964189648628235\n",
      "\n",
      "The classification loss after processing this batch is:  0.09361138939857483\n",
      "The representation loss after processing this batch is:  0.002977900207042694\n",
      "\n",
      "The classification loss after processing this batch is:  0.08353995531797409\n",
      "The representation loss after processing this batch is:  0.002599872648715973\n",
      "\n",
      "The classification loss after processing this batch is:  0.24566367268562317\n",
      "The representation loss after processing this batch is:  0.002764705568552017\n",
      "\n",
      "The classification loss after processing this batch is:  0.05232614278793335\n",
      "The representation loss after processing this batch is:  0.002627626061439514\n",
      "\n",
      "The classification loss after processing this batch is:  0.09200869500637054\n",
      "The representation loss after processing this batch is:  0.0027668848633766174\n",
      "\n",
      "The classification loss after processing this batch is:  0.1697876900434494\n",
      "The representation loss after processing this batch is:  0.002424541860818863\n",
      "\n",
      "The classification loss after processing this batch is:  0.3226853609085083\n",
      "The representation loss after processing this batch is:  0.00279197096824646\n",
      "\n",
      "The classification loss after processing this batch is:  0.09122496098279953\n",
      "The representation loss after processing this batch is:  0.0024966076016426086\n",
      "\n",
      "The classification loss after processing this batch is:  0.11532703787088394\n",
      "The representation loss after processing this batch is:  0.0026051178574562073\n",
      "\n",
      "The classification loss after processing this batch is:  0.08531166613101959\n",
      "The representation loss after processing this batch is:  0.0025648176670074463\n",
      "\n",
      "The classification loss after processing this batch is:  0.037474002689123154\n",
      "The representation loss after processing this batch is:  0.0026063919067382812\n",
      "\n",
      "The classification loss after processing this batch is:  0.13407066464424133\n",
      "The representation loss after processing this batch is:  0.00312698632478714\n",
      "\n",
      "The classification loss after processing this batch is:  0.0889054462313652\n",
      "The representation loss after processing this batch is:  0.0033578723669052124\n",
      "\n",
      "The classification loss after processing this batch is:  0.05907987058162689\n",
      "The representation loss after processing this batch is:  0.0027778558433055878\n",
      "\n",
      "The classification loss after processing this batch is:  0.07329758256673813\n",
      "The representation loss after processing this batch is:  0.002279534935951233\n",
      "\n",
      "The classification loss after processing this batch is:  0.16037620604038239\n",
      "The representation loss after processing this batch is:  0.002400040626525879\n",
      "\n",
      "The classification loss after processing this batch is:  0.1276538223028183\n",
      "The representation loss after processing this batch is:  0.002668514847755432\n",
      "\n",
      "The classification loss after processing this batch is:  0.08350927382707596\n",
      "The representation loss after processing this batch is:  0.0022973939776420593\n",
      "\n",
      "The classification loss after processing this batch is:  0.08626388013362885\n",
      "The representation loss after processing this batch is:  0.0027800947427749634\n",
      "\n",
      "The classification loss after processing this batch is:  0.19044652581214905\n",
      "The representation loss after processing this batch is:  0.0023882240056991577\n",
      "\n",
      "The classification loss after processing this batch is:  0.16055943071842194\n",
      "The representation loss after processing this batch is:  0.0026383697986602783\n",
      "\n",
      "The classification loss after processing this batch is:  0.19419759511947632\n",
      "The representation loss after processing this batch is:  0.002375498414039612\n",
      "\n",
      "The classification loss after processing this batch is:  0.1355145126581192\n",
      "The representation loss after processing this batch is:  0.002905517816543579\n",
      "\n",
      "The classification loss after processing this batch is:  0.1978638917207718\n",
      "The representation loss after processing this batch is:  0.0026386789977550507\n",
      "\n",
      "The classification loss after processing this batch is:  0.09700581431388855\n",
      "The representation loss after processing this batch is:  0.0025623664259910583\n",
      "\n",
      "The classification loss after processing this batch is:  0.0784442201256752\n",
      "The representation loss after processing this batch is:  0.002926461398601532\n",
      "\n",
      "The classification loss after processing this batch is:  0.05086148530244827\n",
      "The representation loss after processing this batch is:  0.002596057951450348\n",
      "\n",
      "The classification loss after processing this batch is:  0.0820954367518425\n",
      "The representation loss after processing this batch is:  0.002548016607761383\n",
      "\n",
      "The classification loss after processing this batch is:  0.21491530537605286\n",
      "The representation loss after processing this batch is:  0.00264127179980278\n",
      "\n",
      "The classification loss after processing this batch is:  0.13627971708774567\n",
      "The representation loss after processing this batch is:  0.0030159130692481995\n",
      "\n",
      "The classification loss after processing this batch is:  0.048777446150779724\n",
      "The representation loss after processing this batch is:  0.002409987151622772\n",
      "\n",
      "The classification loss after processing this batch is:  0.038391921669244766\n",
      "The representation loss after processing this batch is:  0.0029489025473594666\n",
      "\n",
      "The classification loss after processing this batch is:  0.042045958340168\n",
      "The representation loss after processing this batch is:  0.003093406558036804\n",
      "\n",
      "The classification loss after processing this batch is:  0.0690501481294632\n",
      "The representation loss after processing this batch is:  0.003396153450012207\n",
      "\n",
      "The classification loss after processing this batch is:  0.0852680429816246\n",
      "The representation loss after processing this batch is:  0.0029192492365837097\n",
      "\n",
      "The classification loss after processing this batch is:  0.05901049077510834\n",
      "The representation loss after processing this batch is:  0.002894662320613861\n",
      "\n",
      "The classification loss after processing this batch is:  0.02843429334461689\n",
      "The representation loss after processing this batch is:  0.002900645136833191\n",
      "\n",
      "The classification loss after processing this batch is:  0.05266601964831352\n",
      "The representation loss after processing this batch is:  0.0031800344586372375\n",
      "\n",
      "The classification loss after processing this batch is:  0.08516321331262589\n",
      "The representation loss after processing this batch is:  0.0035702213644981384\n",
      "\n",
      "The classification loss after processing this batch is:  0.01933266408741474\n",
      "The representation loss after processing this batch is:  0.0034973695874214172\n",
      "\n",
      "The classification loss after processing this batch is:  0.04419694468379021\n",
      "The representation loss after processing this batch is:  0.003071114420890808\n",
      "\n",
      "The classification loss after processing this batch is:  0.15734554827213287\n",
      "The representation loss after processing this batch is:  0.002871371805667877\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.03622560575604439\n",
      "The representation loss after processing this batch is:  0.003196515142917633\n",
      "\n",
      "The classification loss after processing this batch is:  0.01675039902329445\n",
      "The representation loss after processing this batch is:  0.002996668219566345\n",
      "\n",
      "The classification loss after processing this batch is:  0.02975323237478733\n",
      "The representation loss after processing this batch is:  0.0031088367104530334\n",
      "\n",
      "The classification loss after processing this batch is:  0.03171323984861374\n",
      "The representation loss after processing this batch is:  0.0032839179039001465\n",
      "\n",
      "The classification loss after processing this batch is:  0.03849203884601593\n",
      "The representation loss after processing this batch is:  0.002871863543987274\n",
      "\n",
      "The classification loss after processing this batch is:  0.02978912927210331\n",
      "The representation loss after processing this batch is:  0.0033731982111930847\n",
      "\n",
      "The classification loss after processing this batch is:  0.020388063043355942\n",
      "The representation loss after processing this batch is:  0.003592662513256073\n",
      "\n",
      "The classification loss after processing this batch is:  0.24810488522052765\n",
      "The representation loss after processing this batch is:  0.0035036951303482056\n",
      "\n",
      "The classification loss after processing this batch is:  0.2824549376964569\n",
      "The representation loss after processing this batch is:  0.00339391827583313\n",
      "\n",
      "The classification loss after processing this batch is:  0.22159786522388458\n",
      "The representation loss after processing this batch is:  0.003702700138092041\n",
      "\n",
      "The classification loss after processing this batch is:  0.041541825979948044\n",
      "The representation loss after processing this batch is:  0.0026906654238700867\n",
      "\n",
      "The classification loss after processing this batch is:  0.021929018199443817\n",
      "The representation loss after processing this batch is:  0.003268502652645111\n",
      "\n",
      "The classification loss after processing this batch is:  0.016232255846261978\n",
      "The representation loss after processing this batch is:  0.002260372042655945\n",
      "\n",
      "The classification loss after processing this batch is:  0.12922586500644684\n",
      "The representation loss after processing this batch is:  0.0024798735976219177\n",
      "\n",
      "The classification loss after processing this batch is:  0.32207974791526794\n",
      "The representation loss after processing this batch is:  0.0028662383556365967\n",
      "\n",
      "The classification loss after processing this batch is:  0.07805564999580383\n",
      "The representation loss after processing this batch is:  0.002601228654384613\n",
      "\n",
      "The classification loss after processing this batch is:  0.05319277569651604\n",
      "The representation loss after processing this batch is:  0.003131553530693054\n",
      "\n",
      "The classification loss after processing this batch is:  0.04663410037755966\n",
      "The representation loss after processing this batch is:  0.0029909908771514893\n",
      "\n",
      "The classification loss after processing this batch is:  0.051687709987163544\n",
      "The representation loss after processing this batch is:  0.0034300759434700012\n",
      "\n",
      "The classification loss after processing this batch is:  0.09762754291296005\n",
      "The representation loss after processing this batch is:  0.0024151429533958435\n",
      "\n",
      "The classification loss after processing this batch is:  0.049777839332818985\n",
      "The representation loss after processing this batch is:  0.002580977976322174\n",
      "\n",
      "The classification loss after processing this batch is:  0.10269619524478912\n",
      "The representation loss after processing this batch is:  0.002622779458761215\n",
      "\n",
      "The classification loss after processing this batch is:  0.0965929850935936\n",
      "The representation loss after processing this batch is:  0.002470221370458603\n",
      "\n",
      "The classification loss after processing this batch is:  0.1661904752254486\n",
      "The representation loss after processing this batch is:  0.002727396786212921\n",
      "\n",
      "The classification loss after processing this batch is:  0.08079502731561661\n",
      "The representation loss after processing this batch is:  0.0029051974415779114\n",
      "\n",
      "The classification loss after processing this batch is:  0.0772106721997261\n",
      "The representation loss after processing this batch is:  0.003102615475654602\n",
      "\n",
      "The classification loss after processing this batch is:  0.15151455998420715\n",
      "The representation loss after processing this batch is:  0.0024250634014606476\n",
      "\n",
      "The classification loss after processing this batch is:  0.1314539909362793\n",
      "The representation loss after processing this batch is:  0.0023886114358901978\n",
      "\n",
      "The classification loss after processing this batch is:  0.07816649973392487\n",
      "The representation loss after processing this batch is:  0.0026622898876667023\n",
      "\n",
      "The classification loss after processing this batch is:  0.1568675935268402\n",
      "The representation loss after processing this batch is:  0.002442695200443268\n",
      "\n",
      "The classification loss after processing this batch is:  0.10766705125570297\n",
      "The representation loss after processing this batch is:  0.0025650151073932648\n",
      "\n",
      "The classification loss after processing this batch is:  0.13327746093273163\n",
      "The representation loss after processing this batch is:  0.003135479986667633\n",
      "\n",
      "The classification loss after processing this batch is:  0.08277138322591782\n",
      "The representation loss after processing this batch is:  0.0025768429040908813\n",
      "\n",
      "The classification loss after processing this batch is:  0.2316949963569641\n",
      "The representation loss after processing this batch is:  0.0025823190808296204\n",
      "\n",
      "The classification loss after processing this batch is:  0.10663442313671112\n",
      "The representation loss after processing this batch is:  0.0023586973547935486\n",
      "\n",
      "The classification loss after processing this batch is:  0.10103379935026169\n",
      "The representation loss after processing this batch is:  0.0026904940605163574\n",
      "\n",
      "The classification loss after processing this batch is:  0.21589021384716034\n",
      "The representation loss after processing this batch is:  0.0027894824743270874\n",
      "\n",
      "The classification loss after processing this batch is:  0.13087451457977295\n",
      "The representation loss after processing this batch is:  0.0026734471321105957\n",
      "\n",
      "The classification loss after processing this batch is:  0.07687737047672272\n",
      "The representation loss after processing this batch is:  0.0027277059853076935\n",
      "\n",
      "The classification loss after processing this batch is:  0.23757193982601166\n",
      "The representation loss after processing this batch is:  0.0032361894845962524\n",
      "\n",
      "The classification loss after processing this batch is:  0.12559321522712708\n",
      "The representation loss after processing this batch is:  0.002810053527355194\n",
      "\n",
      "The classification loss after processing this batch is:  0.31577855348587036\n",
      "The representation loss after processing this batch is:  0.002552442252635956\n",
      "\n",
      "The classification loss after processing this batch is:  0.09347321093082428\n",
      "The representation loss after processing this batch is:  0.002280082553625107\n",
      "\n",
      "The classification loss after processing this batch is:  0.06830655038356781\n",
      "The representation loss after processing this batch is:  0.0025617703795433044\n",
      "\n",
      "The classification loss after processing this batch is:  0.08152488619089127\n",
      "The representation loss after processing this batch is:  0.0023696012794971466\n",
      "\n",
      "The classification loss after processing this batch is:  0.11824146658182144\n",
      "The representation loss after processing this batch is:  0.0023510269820690155\n",
      "\n",
      "The classification loss after processing this batch is:  0.08868202567100525\n",
      "The representation loss after processing this batch is:  0.0025721602141857147\n",
      "\n",
      "The classification loss after processing this batch is:  0.05166571959853172\n",
      "The representation loss after processing this batch is:  0.002609662711620331\n",
      "\n",
      "The classification loss after processing this batch is:  0.03664012253284454\n",
      "The representation loss after processing this batch is:  0.0026413574814796448\n",
      "\n",
      "The classification loss after processing this batch is:  0.05055290833115578\n",
      "The representation loss after processing this batch is:  0.002509135752916336\n",
      "\n",
      "The classification loss after processing this batch is:  0.08472646772861481\n",
      "The representation loss after processing this batch is:  0.0024989694356918335\n",
      "\n",
      "The classification loss after processing this batch is:  0.17344847321510315\n",
      "The representation loss after processing this batch is:  0.0028146877884864807\n",
      "\n",
      "The classification loss after processing this batch is:  0.08737622946500778\n",
      "The representation loss after processing this batch is:  0.002838198095560074\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10996580868959427\n",
      "The representation loss after processing this batch is:  0.0024974532425403595\n",
      "\n",
      "The classification loss after processing this batch is:  0.04461740329861641\n",
      "The representation loss after processing this batch is:  0.002460971474647522\n",
      "\n",
      "The classification loss after processing this batch is:  0.06845922023057938\n",
      "The representation loss after processing this batch is:  0.0026686862111091614\n",
      "\n",
      "The classification loss after processing this batch is:  0.09686996042728424\n",
      "The representation loss after processing this batch is:  0.0024164319038391113\n",
      "\n",
      "The classification loss after processing this batch is:  0.05250425264239311\n",
      "The representation loss after processing this batch is:  0.002632707357406616\n",
      "\n",
      "The classification loss after processing this batch is:  0.08427368849515915\n",
      "The representation loss after processing this batch is:  0.002551130950450897\n",
      "\n",
      "The classification loss after processing this batch is:  0.17562463879585266\n",
      "The representation loss after processing this batch is:  0.002977631986141205\n",
      "\n",
      "The classification loss after processing this batch is:  0.11751312762498856\n",
      "The representation loss after processing this batch is:  0.0027862265706062317\n",
      "\n",
      "The classification loss after processing this batch is:  0.1208115816116333\n",
      "The representation loss after processing this batch is:  0.0022197291254997253\n",
      "\n",
      "The classification loss after processing this batch is:  0.15324467420578003\n",
      "The representation loss after processing this batch is:  0.0025776997208595276\n",
      "\n",
      "The classification loss after processing this batch is:  0.08855487406253815\n",
      "The representation loss after processing this batch is:  0.0023349374532699585\n",
      "\n",
      "The classification loss after processing this batch is:  0.08200938254594803\n",
      "The representation loss after processing this batch is:  0.002536732703447342\n",
      "\n",
      "The classification loss after processing this batch is:  0.19943541288375854\n",
      "The representation loss after processing this batch is:  0.0029933899641036987\n",
      "\n",
      "The classification loss after processing this batch is:  0.060137923806905746\n",
      "The representation loss after processing this batch is:  0.002679966390132904\n",
      "\n",
      "The classification loss after processing this batch is:  0.1415775865316391\n",
      "The representation loss after processing this batch is:  0.0024189576506614685\n",
      "\n",
      "The classification loss after processing this batch is:  0.07107258588075638\n",
      "The representation loss after processing this batch is:  0.002489205449819565\n",
      "\n",
      "The classification loss after processing this batch is:  0.11294269561767578\n",
      "The representation loss after processing this batch is:  0.0023585036396980286\n",
      "\n",
      "The classification loss after processing this batch is:  0.13881772756576538\n",
      "The representation loss after processing this batch is:  0.002625502645969391\n",
      "\n",
      "The classification loss after processing this batch is:  0.0690162181854248\n",
      "The representation loss after processing this batch is:  0.0026208385825157166\n",
      "\n",
      "The classification loss after processing this batch is:  0.10783261805772781\n",
      "The representation loss after processing this batch is:  0.0029556825757026672\n",
      "\n",
      "The classification loss after processing this batch is:  0.11217869073152542\n",
      "The representation loss after processing this batch is:  0.0028174519538879395\n",
      "\n",
      "The classification loss after processing this batch is:  0.12730836868286133\n",
      "The representation loss after processing this batch is:  0.002645067870616913\n",
      "\n",
      "The classification loss after processing this batch is:  0.13553264737129211\n",
      "The representation loss after processing this batch is:  0.0023877695202827454\n",
      "\n",
      "The classification loss after processing this batch is:  0.09079258143901825\n",
      "The representation loss after processing this batch is:  0.00298917293548584\n",
      "\n",
      "The classification loss after processing this batch is:  0.16620445251464844\n",
      "The representation loss after processing this batch is:  0.0027645155787467957\n",
      "\n",
      "The classification loss after processing this batch is:  0.0778656005859375\n",
      "The representation loss after processing this batch is:  0.0023086480796337128\n",
      "\n",
      "The classification loss after processing this batch is:  0.061687059700489044\n",
      "The representation loss after processing this batch is:  0.0023453645408153534\n",
      "\n",
      "The classification loss after processing this batch is:  0.1483636498451233\n",
      "The representation loss after processing this batch is:  0.0025653913617134094\n",
      "\n",
      "The classification loss after processing this batch is:  0.12905016541481018\n",
      "The representation loss after processing this batch is:  0.0023634135723114014\n",
      "\n",
      "The classification loss after processing this batch is:  0.07546175271272659\n",
      "The representation loss after processing this batch is:  0.0023884400725364685\n",
      "\n",
      "The classification loss after processing this batch is:  0.08228164166212082\n",
      "The representation loss after processing this batch is:  0.0024073198437690735\n",
      "\n",
      "The classification loss after processing this batch is:  0.0495305098593235\n",
      "The representation loss after processing this batch is:  0.0024472996592521667\n",
      "\n",
      "The classification loss after processing this batch is:  0.08503389358520508\n",
      "The representation loss after processing this batch is:  0.002677537500858307\n",
      "\n",
      "The classification loss after processing this batch is:  0.11332826316356659\n",
      "The representation loss after processing this batch is:  0.002193830907344818\n",
      "\n",
      "The classification loss after processing this batch is:  0.06896872073411942\n",
      "The representation loss after processing this batch is:  0.0026198476552963257\n",
      "\n",
      "The classification loss after processing this batch is:  0.1649257391691208\n",
      "The representation loss after processing this batch is:  0.002507045865058899\n",
      "\n",
      "The classification loss after processing this batch is:  0.12796622514724731\n",
      "The representation loss after processing this batch is:  0.0024472735822200775\n",
      "\n",
      "The classification loss after processing this batch is:  0.10430949181318283\n",
      "The representation loss after processing this batch is:  0.0026806145906448364\n",
      "\n",
      "The classification loss after processing this batch is:  0.0718788430094719\n",
      "The representation loss after processing this batch is:  0.002238646149635315\n",
      "\n",
      "The classification loss after processing this batch is:  0.06596937030553818\n",
      "The representation loss after processing this batch is:  0.0026285797357559204\n",
      "\n",
      "The classification loss after processing this batch is:  0.12172628194093704\n",
      "The representation loss after processing this batch is:  0.002372298389673233\n",
      "\n",
      "The classification loss after processing this batch is:  0.17080028355121613\n",
      "The representation loss after processing this batch is:  0.0023537203669548035\n",
      "\n",
      "The classification loss after processing this batch is:  0.08710895478725433\n",
      "The representation loss after processing this batch is:  0.0023961663246154785\n",
      "\n",
      "The classification loss after processing this batch is:  0.2526315748691559\n",
      "The representation loss after processing this batch is:  0.0023815184831619263\n",
      "\n",
      "The classification loss after processing this batch is:  0.11012902855873108\n",
      "The representation loss after processing this batch is:  0.0023502185940742493\n",
      "\n",
      "The classification loss after processing this batch is:  0.06252111494541168\n",
      "The representation loss after processing this batch is:  0.003138333559036255\n",
      "\n",
      "The classification loss after processing this batch is:  0.11576366424560547\n",
      "The representation loss after processing this batch is:  0.0023426711559295654\n",
      "\n",
      "The classification loss after processing this batch is:  0.056704532355070114\n",
      "The representation loss after processing this batch is:  0.002580389380455017\n",
      "\n",
      "The classification loss after processing this batch is:  0.25264811515808105\n",
      "The representation loss after processing this batch is:  0.0028113946318626404\n",
      "\n",
      "The classification loss after processing this batch is:  0.12912294268608093\n",
      "The representation loss after processing this batch is:  0.002356022596359253\n",
      "\n",
      "The classification loss after processing this batch is:  0.116209015250206\n",
      "The representation loss after processing this batch is:  0.0022347718477249146\n",
      "\n",
      "The classification loss after processing this batch is:  0.28067484498023987\n",
      "The representation loss after processing this batch is:  0.0022488869726657867\n",
      "\n",
      "The classification loss after processing this batch is:  0.13213063776493073\n",
      "The representation loss after processing this batch is:  0.002590775489807129\n",
      "\n",
      "The classification loss after processing this batch is:  0.072587750852108\n",
      "The representation loss after processing this batch is:  0.0025477036833763123\n",
      "\n",
      "The classification loss after processing this batch is:  0.11588343232870102\n",
      "The representation loss after processing this batch is:  0.002337627112865448\n",
      "\n",
      "The classification loss after processing this batch is:  0.1235174834728241\n",
      "The representation loss after processing this batch is:  0.0025840476155281067\n",
      "\n",
      "The classification loss after processing this batch is:  0.16256073117256165\n",
      "The representation loss after processing this batch is:  0.0027923136949539185\n",
      "\n",
      "The classification loss after processing this batch is:  0.059736479073762894\n",
      "The representation loss after processing this batch is:  0.0025560185313224792\n",
      "\n",
      "The classification loss after processing this batch is:  0.10088048130273819\n",
      "The representation loss after processing this batch is:  0.0025523751974105835\n",
      "\n",
      "The classification loss after processing this batch is:  0.15057523548603058\n",
      "The representation loss after processing this batch is:  0.002409324049949646\n",
      "\n",
      "The classification loss after processing this batch is:  0.15213721990585327\n",
      "The representation loss after processing this batch is:  0.002766519784927368\n",
      "\n",
      "The classification loss after processing this batch is:  0.17885343730449677\n",
      "The representation loss after processing this batch is:  0.0024673044681549072\n",
      "\n",
      "The classification loss after processing this batch is:  0.19679374992847443\n",
      "The representation loss after processing this batch is:  0.0029352903366088867\n",
      "\n",
      "The classification loss after processing this batch is:  0.12852849066257477\n",
      "The representation loss after processing this batch is:  0.002984151244163513\n",
      "\n",
      "The classification loss after processing this batch is:  0.07184837013483047\n",
      "The representation loss after processing this batch is:  0.0026344135403633118\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.09023784846067429\n",
      "The representation loss after processing this batch is:  0.002530161291360855\n",
      "\n",
      "The classification loss after processing this batch is:  0.0457477942109108\n",
      "The representation loss after processing this batch is:  0.002450615167617798\n",
      "\n",
      "The classification loss after processing this batch is:  0.1157098263502121\n",
      "The representation loss after processing this batch is:  0.0025391504168510437\n",
      "\n",
      "The classification loss after processing this batch is:  0.16260124742984772\n",
      "The representation loss after processing this batch is:  0.002493031322956085\n",
      "\n",
      "The classification loss after processing this batch is:  0.2092248648405075\n",
      "The representation loss after processing this batch is:  0.0026954486966133118\n",
      "\n",
      "The classification loss after processing this batch is:  0.2513773739337921\n",
      "The representation loss after processing this batch is:  0.0027197301387786865\n",
      "\n",
      "The classification loss after processing this batch is:  0.08024117350578308\n",
      "The representation loss after processing this batch is:  0.0027474090456962585\n",
      "\n",
      "The classification loss after processing this batch is:  0.1044989824295044\n",
      "The representation loss after processing this batch is:  0.002791576087474823\n",
      "\n",
      "The classification loss after processing this batch is:  0.15261393785476685\n",
      "The representation loss after processing this batch is:  0.002411816269159317\n",
      "\n",
      "The classification loss after processing this batch is:  0.04849090799689293\n",
      "The representation loss after processing this batch is:  0.0028356239199638367\n",
      "\n",
      "The classification loss after processing this batch is:  0.06539754569530487\n",
      "The representation loss after processing this batch is:  0.00273701548576355\n",
      "\n",
      "The classification loss after processing this batch is:  0.14257535338401794\n",
      "The representation loss after processing this batch is:  0.0023203864693641663\n",
      "\n",
      "The classification loss after processing this batch is:  0.09757575392723083\n",
      "The representation loss after processing this batch is:  0.0033578798174858093\n",
      "\n",
      "The classification loss after processing this batch is:  0.09327692538499832\n",
      "The representation loss after processing this batch is:  0.0026334524154663086\n",
      "\n",
      "The classification loss after processing this batch is:  0.22209244966506958\n",
      "The representation loss after processing this batch is:  0.0035937801003456116\n",
      "\n",
      "The classification loss after processing this batch is:  0.27042967081069946\n",
      "The representation loss after processing this batch is:  0.0022167228162288666\n",
      "\n",
      "The classification loss after processing this batch is:  0.12503081560134888\n",
      "The representation loss after processing this batch is:  0.002566330134868622\n",
      "\n",
      "The classification loss after processing this batch is:  0.21632035076618195\n",
      "The representation loss after processing this batch is:  0.002459131181240082\n",
      "\n",
      "The classification loss after processing this batch is:  0.1427440196275711\n",
      "The representation loss after processing this batch is:  0.0025053396821022034\n",
      "\n",
      "The classification loss after processing this batch is:  0.04776836559176445\n",
      "The representation loss after processing this batch is:  0.0025347545742988586\n",
      "\n",
      "The classification loss after processing this batch is:  0.1379186511039734\n",
      "The representation loss after processing this batch is:  0.0023815706372261047\n",
      "\n",
      "The classification loss after processing this batch is:  0.3342098295688629\n",
      "The representation loss after processing this batch is:  0.0030861645936965942\n",
      "\n",
      "The classification loss after processing this batch is:  0.16994282603263855\n",
      "The representation loss after processing this batch is:  0.0029618963599205017\n",
      "\n",
      "The classification loss after processing this batch is:  0.06405878812074661\n",
      "The representation loss after processing this batch is:  0.002740427851676941\n",
      "\n",
      "The classification loss after processing this batch is:  0.067588210105896\n",
      "The representation loss after processing this batch is:  0.0027190595865249634\n",
      "\n",
      "The classification loss after processing this batch is:  0.05401543155312538\n",
      "The representation loss after processing this batch is:  0.002871684730052948\n",
      "\n",
      "The classification loss after processing this batch is:  0.09285197407007217\n",
      "The representation loss after processing this batch is:  0.002932921051979065\n",
      "\n",
      "The classification loss after processing this batch is:  0.09362151473760605\n",
      "The representation loss after processing this batch is:  0.002783358097076416\n",
      "\n",
      "The classification loss after processing this batch is:  0.12704606354236603\n",
      "The representation loss after processing this batch is:  0.0026898086071014404\n",
      "\n",
      "The classification loss after processing this batch is:  0.11491869390010834\n",
      "The representation loss after processing this batch is:  0.0025665760040283203\n",
      "\n",
      "The classification loss after processing this batch is:  0.19929583370685577\n",
      "The representation loss after processing this batch is:  0.0028907954692840576\n",
      "\n",
      "The classification loss after processing this batch is:  0.08954406529664993\n",
      "The representation loss after processing this batch is:  0.00231005996465683\n",
      "\n",
      "The classification loss after processing this batch is:  0.13460513949394226\n",
      "The representation loss after processing this batch is:  0.002142045646905899\n",
      "\n",
      "The classification loss after processing this batch is:  0.15308253467082977\n",
      "The representation loss after processing this batch is:  0.002505950629711151\n",
      "\n",
      "The classification loss after processing this batch is:  0.131611168384552\n",
      "The representation loss after processing this batch is:  0.0025043562054634094\n",
      "\n",
      "The classification loss after processing this batch is:  0.09770534187555313\n",
      "The representation loss after processing this batch is:  0.002406783401966095\n",
      "\n",
      "The classification loss after processing this batch is:  0.19748397171497345\n",
      "The representation loss after processing this batch is:  0.0024765804409980774\n",
      "\n",
      "The classification loss after processing this batch is:  0.16865110397338867\n",
      "The representation loss after processing this batch is:  0.002682916820049286\n",
      "\n",
      "The classification loss after processing this batch is:  0.13209722936153412\n",
      "The representation loss after processing this batch is:  0.0024131014943122864\n",
      "\n",
      "The classification loss after processing this batch is:  0.13535752892494202\n",
      "The representation loss after processing this batch is:  0.002604342997074127\n",
      "\n",
      "The classification loss after processing this batch is:  0.1882394701242447\n",
      "The representation loss after processing this batch is:  0.002460487186908722\n",
      "\n",
      "The classification loss after processing this batch is:  0.1875087171792984\n",
      "The representation loss after processing this batch is:  0.0026386938989162445\n",
      "\n",
      "The classification loss after processing this batch is:  0.17096662521362305\n",
      "The representation loss after processing this batch is:  0.002957656979560852\n",
      "\n",
      "The classification loss after processing this batch is:  0.14550113677978516\n",
      "The representation loss after processing this batch is:  0.002894580364227295\n",
      "\n",
      "The classification loss after processing this batch is:  0.08848168700933456\n",
      "The representation loss after processing this batch is:  0.003050893545150757\n",
      "\n",
      "The classification loss after processing this batch is:  0.24686290323734283\n",
      "The representation loss after processing this batch is:  0.002827964723110199\n",
      "\n",
      "The classification loss after processing this batch is:  0.2192760407924652\n",
      "The representation loss after processing this batch is:  0.002437114715576172\n",
      "\n",
      "The classification loss after processing this batch is:  0.26138439774513245\n",
      "The representation loss after processing this batch is:  0.0026958398520946503\n",
      "\n",
      "The classification loss after processing this batch is:  0.3076225519180298\n",
      "The representation loss after processing this batch is:  0.002376049757003784\n",
      "\n",
      "The classification loss after processing this batch is:  0.22766193747520447\n",
      "The representation loss after processing this batch is:  0.002328239381313324\n",
      "\n",
      "The classification loss after processing this batch is:  0.10686644166707993\n",
      "The representation loss after processing this batch is:  0.002377055585384369\n",
      "\n",
      "The classification loss after processing this batch is:  0.08448359370231628\n",
      "The representation loss after processing this batch is:  0.0023958906531333923\n",
      "\n",
      "The classification loss after processing this batch is:  0.05360253155231476\n",
      "The representation loss after processing this batch is:  0.002695433795452118\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10453996062278748\n",
      "The representation loss after processing this batch is:  0.0031995847821235657\n",
      "\n",
      "The classification loss after processing this batch is:  0.041525889188051224\n",
      "The representation loss after processing this batch is:  0.002793155610561371\n",
      "\n",
      "The classification loss after processing this batch is:  0.22421953082084656\n",
      "The representation loss after processing this batch is:  0.0035596266388893127\n",
      "\n",
      "The classification loss after processing this batch is:  0.14308887720108032\n",
      "The representation loss after processing this batch is:  0.0024877451360225677\n",
      "\n",
      "The classification loss after processing this batch is:  0.08479554206132889\n",
      "The representation loss after processing this batch is:  0.0026464536786079407\n",
      "\n",
      "The classification loss after processing this batch is:  0.16075532138347626\n",
      "The representation loss after processing this batch is:  0.002316497266292572\n",
      "\n",
      "The classification loss after processing this batch is:  0.0693734660744667\n",
      "The representation loss after processing this batch is:  0.0029664598405361176\n",
      "\n",
      "The classification loss after processing this batch is:  0.13920079171657562\n",
      "The representation loss after processing this batch is:  0.003116607666015625\n",
      "\n",
      "The classification loss after processing this batch is:  0.18014422059059143\n",
      "The representation loss after processing this batch is:  0.0032487064599990845\n",
      "\n",
      "The classification loss after processing this batch is:  0.1221410408616066\n",
      "The representation loss after processing this batch is:  0.0031179413199424744\n",
      "\n",
      "The classification loss after processing this batch is:  0.1373923420906067\n",
      "The representation loss after processing this batch is:  0.002231106162071228\n",
      "\n",
      "The classification loss after processing this batch is:  0.09127768129110336\n",
      "The representation loss after processing this batch is:  0.0024124085903167725\n",
      "\n",
      "The classification loss after processing this batch is:  0.030829310417175293\n",
      "The representation loss after processing this batch is:  0.0026542097330093384\n",
      "\n",
      "The classification loss after processing this batch is:  0.07443051040172577\n",
      "The representation loss after processing this batch is:  0.0028105080127716064\n",
      "\n",
      "The classification loss after processing this batch is:  0.07150015234947205\n",
      "The representation loss after processing this batch is:  0.0023533888161182404\n",
      "\n",
      "The classification loss after processing this batch is:  0.10902012139558792\n",
      "The representation loss after processing this batch is:  0.0023259148001670837\n",
      "\n",
      "The classification loss after processing this batch is:  0.11678989976644516\n",
      "The representation loss after processing this batch is:  0.002555437386035919\n",
      "\n",
      "The classification loss after processing this batch is:  0.11738165467977524\n",
      "The representation loss after processing this batch is:  0.0025429949164390564\n",
      "\n",
      "The classification loss after processing this batch is:  0.3353721797466278\n",
      "The representation loss after processing this batch is:  0.0031221210956573486\n",
      "\n",
      "The classification loss after processing this batch is:  0.24340786039829254\n",
      "The representation loss after processing this batch is:  0.0027642250061035156\n",
      "\n",
      "The classification loss after processing this batch is:  0.07664917409420013\n",
      "The representation loss after processing this batch is:  0.0024618208408355713\n",
      "\n",
      "The classification loss after processing this batch is:  0.06044203042984009\n",
      "The representation loss after processing this batch is:  0.0027896538376808167\n",
      "\n",
      "The classification loss after processing this batch is:  0.07499516755342484\n",
      "The representation loss after processing this batch is:  0.0024242252111434937\n",
      "\n",
      "The classification loss after processing this batch is:  0.05786998197436333\n",
      "The representation loss after processing this batch is:  0.0024961084127426147\n",
      "\n",
      "The classification loss after processing this batch is:  0.030227405950427055\n",
      "The representation loss after processing this batch is:  0.0027601197361946106\n",
      "\n",
      "The classification loss after processing this batch is:  0.05672115460038185\n",
      "The representation loss after processing this batch is:  0.003047548234462738\n",
      "\n",
      "The classification loss after processing this batch is:  0.11493686586618423\n",
      "The representation loss after processing this batch is:  0.002326570451259613\n",
      "\n",
      "The classification loss after processing this batch is:  0.1670885980129242\n",
      "The representation loss after processing this batch is:  0.0026636049151420593\n",
      "\n",
      "The classification loss after processing this batch is:  0.09754245728254318\n",
      "The representation loss after processing this batch is:  0.0027170032262802124\n",
      "\n",
      "The classification loss after processing this batch is:  0.07133585959672928\n",
      "The representation loss after processing this batch is:  0.0025625303387641907\n",
      "\n",
      "The classification loss after processing this batch is:  0.04477880522608757\n",
      "The representation loss after processing this batch is:  0.0023998022079467773\n",
      "\n",
      "The classification loss after processing this batch is:  0.25900134444236755\n",
      "The representation loss after processing this batch is:  0.0025561749935150146\n",
      "\n",
      "The classification loss after processing this batch is:  0.12459833920001984\n",
      "The representation loss after processing this batch is:  0.002736389636993408\n",
      "\n",
      "The classification loss after processing this batch is:  0.051864609122276306\n",
      "The representation loss after processing this batch is:  0.00277690589427948\n",
      "\n",
      "The classification loss after processing this batch is:  0.1269841492176056\n",
      "The representation loss after processing this batch is:  0.0026338398456573486\n",
      "\n",
      "The classification loss after processing this batch is:  0.11688407510519028\n",
      "The representation loss after processing this batch is:  0.0022574514150619507\n",
      "\n",
      "The classification loss after processing this batch is:  0.07232164591550827\n",
      "The representation loss after processing this batch is:  0.002343498170375824\n",
      "\n",
      "The classification loss after processing this batch is:  0.11108167469501495\n",
      "The representation loss after processing this batch is:  0.0022175535559654236\n",
      "\n",
      "The classification loss after processing this batch is:  0.0732114389538765\n",
      "The representation loss after processing this batch is:  0.0025285184383392334\n",
      "\n",
      "The classification loss after processing this batch is:  0.07852403819561005\n",
      "The representation loss after processing this batch is:  0.002399034798145294\n",
      "\n",
      "The classification loss after processing this batch is:  0.11576075106859207\n",
      "The representation loss after processing this batch is:  0.0023145899176597595\n",
      "\n",
      "The classification loss after processing this batch is:  0.1846597045660019\n",
      "The representation loss after processing this batch is:  0.002668507397174835\n",
      "\n",
      "The classification loss after processing this batch is:  0.13669328391551971\n",
      "The representation loss after processing this batch is:  0.002444066107273102\n",
      "\n",
      "The classification loss after processing this batch is:  0.11719176918268204\n",
      "The representation loss after processing this batch is:  0.0023953765630722046\n",
      "\n",
      "The classification loss after processing this batch is:  0.09161800891160965\n",
      "The representation loss after processing this batch is:  0.0025028809905052185\n",
      "\n",
      "The classification loss after processing this batch is:  0.14572304487228394\n",
      "The representation loss after processing this batch is:  0.0023590177297592163\n",
      "\n",
      "The classification loss after processing this batch is:  0.062028128653764725\n",
      "The representation loss after processing this batch is:  0.002720355987548828\n",
      "\n",
      "The classification loss after processing this batch is:  0.14159494638442993\n",
      "The representation loss after processing this batch is:  0.002547934651374817\n",
      "\n",
      "The classification loss after processing this batch is:  0.06584273278713226\n",
      "The representation loss after processing this batch is:  0.0024355128407478333\n",
      "\n",
      "The classification loss after processing this batch is:  0.12367008626461029\n",
      "The representation loss after processing this batch is:  0.0025613009929656982\n",
      "\n",
      "The classification loss after processing this batch is:  0.07767904549837112\n",
      "The representation loss after processing this batch is:  0.002644486725330353\n",
      "\n",
      "The classification loss after processing this batch is:  0.11358902603387833\n",
      "The representation loss after processing this batch is:  0.0022501759231090546\n",
      "\n",
      "The classification loss after processing this batch is:  0.1008996069431305\n",
      "The representation loss after processing this batch is:  0.0022623129189014435\n",
      "\n",
      "The classification loss after processing this batch is:  0.10010629147291183\n",
      "The representation loss after processing this batch is:  0.002664409577846527\n",
      "\n",
      "The classification loss after processing this batch is:  0.1363300383090973\n",
      "The representation loss after processing this batch is:  0.0023940205574035645\n",
      "\n",
      "The classification loss after processing this batch is:  0.1131787970662117\n",
      "The representation loss after processing this batch is:  0.0023317933082580566\n",
      "\n",
      "The classification loss after processing this batch is:  0.17559099197387695\n",
      "The representation loss after processing this batch is:  0.002262696623802185\n",
      "\n",
      "The classification loss after processing this batch is:  0.17226606607437134\n",
      "The representation loss after processing this batch is:  0.0022140592336654663\n",
      "\n",
      "The classification loss after processing this batch is:  0.23538893461227417\n",
      "The representation loss after processing this batch is:  0.0022786706686019897\n",
      "\n",
      "The classification loss after processing this batch is:  0.181674063205719\n",
      "The representation loss after processing this batch is:  0.0024312548339366913\n",
      "\n",
      "The classification loss after processing this batch is:  0.08248426765203476\n",
      "The representation loss after processing this batch is:  0.002699136734008789\n",
      "\n",
      "The classification loss after processing this batch is:  0.16149988770484924\n",
      "The representation loss after processing this batch is:  0.0027725771069526672\n",
      "\n",
      "The classification loss after processing this batch is:  0.08310095220804214\n",
      "The representation loss after processing this batch is:  0.0025262609124183655\n",
      "\n",
      "The classification loss after processing this batch is:  0.11941935122013092\n",
      "The representation loss after processing this batch is:  0.002834014594554901\n",
      "\n",
      "The classification loss after processing this batch is:  0.18285176157951355\n",
      "The representation loss after processing this batch is:  0.0031205564737319946\n",
      "\n",
      "The classification loss after processing this batch is:  0.22906336188316345\n",
      "The representation loss after processing this batch is:  0.002955302596092224\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.22733338177204132\n",
      "The representation loss after processing this batch is:  0.00247897207736969\n",
      "\n",
      "The classification loss after processing this batch is:  0.1658281832933426\n",
      "The representation loss after processing this batch is:  0.0025004446506500244\n",
      "\n",
      "The classification loss after processing this batch is:  0.07298468798398972\n",
      "The representation loss after processing this batch is:  0.0024141445755958557\n",
      "\n",
      "The classification loss after processing this batch is:  0.0959264263510704\n",
      "The representation loss after processing this batch is:  0.0026542991399765015\n",
      "\n",
      "The classification loss after processing this batch is:  0.2097415030002594\n",
      "The representation loss after processing this batch is:  0.002282414585351944\n",
      "\n",
      "The classification loss after processing this batch is:  0.0874025970697403\n",
      "The representation loss after processing this batch is:  0.0024916306138038635\n",
      "\n",
      "The classification loss after processing this batch is:  0.094114750623703\n",
      "The representation loss after processing this batch is:  0.002298615872859955\n",
      "\n",
      "The classification loss after processing this batch is:  0.07900689542293549\n",
      "The representation loss after processing this batch is:  0.002623938024044037\n",
      "\n",
      "The classification loss after processing this batch is:  0.030296998098492622\n",
      "The representation loss after processing this batch is:  0.0025376826524734497\n",
      "\n",
      "The classification loss after processing this batch is:  0.09751380234956741\n",
      "The representation loss after processing this batch is:  0.0027439817786216736\n",
      "\n",
      "The classification loss after processing this batch is:  0.10030723363161087\n",
      "The representation loss after processing this batch is:  0.003010805696249008\n",
      "\n",
      "The classification loss after processing this batch is:  0.1332651972770691\n",
      "The representation loss after processing this batch is:  0.0024535134434700012\n",
      "\n",
      "The classification loss after processing this batch is:  0.12748636305332184\n",
      "The representation loss after processing this batch is:  0.0023190975189208984\n",
      "\n",
      "The classification loss after processing this batch is:  0.10686109960079193\n",
      "The representation loss after processing this batch is:  0.0026683062314987183\n",
      "\n",
      "The classification loss after processing this batch is:  0.1516112983226776\n",
      "The representation loss after processing this batch is:  0.0025675147771835327\n",
      "\n",
      "The classification loss after processing this batch is:  0.11032452434301376\n",
      "The representation loss after processing this batch is:  0.00260264053940773\n",
      "\n",
      "The classification loss after processing this batch is:  0.12682051956653595\n",
      "The representation loss after processing this batch is:  0.0031701326370239258\n",
      "\n",
      "The classification loss after processing this batch is:  0.09302115440368652\n",
      "The representation loss after processing this batch is:  0.0028021782636642456\n",
      "\n",
      "The classification loss after processing this batch is:  0.11603651195764542\n",
      "The representation loss after processing this batch is:  0.0025637224316596985\n",
      "\n",
      "The classification loss after processing this batch is:  0.16935113072395325\n",
      "The representation loss after processing this batch is:  0.0023705139756202698\n",
      "\n",
      "The classification loss after processing this batch is:  0.23002643883228302\n",
      "The representation loss after processing this batch is:  0.0024559348821640015\n",
      "\n",
      "The classification loss after processing this batch is:  0.1763843446969986\n",
      "The representation loss after processing this batch is:  0.0027456730604171753\n",
      "\n",
      "The classification loss after processing this batch is:  0.08438324183225632\n",
      "The representation loss after processing this batch is:  0.0023546554148197174\n",
      "\n",
      "The classification loss after processing this batch is:  0.14888662099838257\n",
      "The representation loss after processing this batch is:  0.0027204565703868866\n",
      "\n",
      "The classification loss after processing this batch is:  0.12670740485191345\n",
      "The representation loss after processing this batch is:  0.0026443637907505035\n",
      "\n",
      "The classification loss after processing this batch is:  0.16251184046268463\n",
      "The representation loss after processing this batch is:  0.0025294795632362366\n",
      "\n",
      "The classification loss after processing this batch is:  0.18395955860614777\n",
      "The representation loss after processing this batch is:  0.0029663369059562683\n",
      "\n",
      "The classification loss after processing this batch is:  0.17092379927635193\n",
      "The representation loss after processing this batch is:  0.0026474297046661377\n",
      "\n",
      "The classification loss after processing this batch is:  0.2527066171169281\n",
      "The representation loss after processing this batch is:  0.0030709877610206604\n",
      "\n",
      "The classification loss after processing this batch is:  0.12270534783601761\n",
      "The representation loss after processing this batch is:  0.0028420165181159973\n",
      "\n",
      "The classification loss after processing this batch is:  0.12042588740587234\n",
      "The representation loss after processing this batch is:  0.0026291273534297943\n",
      "\n",
      "The classification loss after processing this batch is:  0.13286815583705902\n",
      "The representation loss after processing this batch is:  0.0029392018914222717\n",
      "\n",
      "The classification loss after processing this batch is:  0.07221669703722\n",
      "The representation loss after processing this batch is:  0.00281408429145813\n",
      "\n",
      "The classification loss after processing this batch is:  0.15883168578147888\n",
      "The representation loss after processing this batch is:  0.0026934966444969177\n",
      "\n",
      "The classification loss after processing this batch is:  0.1164642721414566\n",
      "The representation loss after processing this batch is:  0.0024453699588775635\n",
      "\n",
      "The classification loss after processing this batch is:  0.09564673155546188\n",
      "The representation loss after processing this batch is:  0.0024443604052066803\n",
      "\n",
      "The classification loss after processing this batch is:  0.10493718087673187\n",
      "The representation loss after processing this batch is:  0.0026419535279273987\n",
      "\n",
      "The classification loss after processing this batch is:  0.13762067258358002\n",
      "The representation loss after processing this batch is:  0.002956882119178772\n",
      "\n",
      "The classification loss after processing this batch is:  0.15390107035636902\n",
      "The representation loss after processing this batch is:  0.002452664077281952\n",
      "\n",
      "The classification loss after processing this batch is:  0.13146303594112396\n",
      "The representation loss after processing this batch is:  0.002582840621471405\n",
      "\n",
      "The classification loss after processing this batch is:  0.09993349760770798\n",
      "The representation loss after processing this batch is:  0.0023844540119171143\n",
      "\n",
      "The classification loss after processing this batch is:  0.05426834523677826\n",
      "The representation loss after processing this batch is:  0.002323184162378311\n",
      "\n",
      "The classification loss after processing this batch is:  0.12971438467502594\n",
      "The representation loss after processing this batch is:  0.0021006502211093903\n",
      "\n",
      "The classification loss after processing this batch is:  0.08913686126470566\n",
      "The representation loss after processing this batch is:  0.002134092152118683\n",
      "\n",
      "The classification loss after processing this batch is:  0.4334101378917694\n",
      "The representation loss after processing this batch is:  0.0026628077030181885\n",
      "\n",
      "The classification loss after processing this batch is:  0.0961829200387001\n",
      "The representation loss after processing this batch is:  0.002489715814590454\n",
      "\n",
      "The classification loss after processing this batch is:  0.147746279835701\n",
      "The representation loss after processing this batch is:  0.0024283789098262787\n",
      "\n",
      "The classification loss after processing this batch is:  0.28123122453689575\n",
      "The representation loss after processing this batch is:  0.002646207809448242\n",
      "\n",
      "The classification loss after processing this batch is:  0.08193980902433395\n",
      "The representation loss after processing this batch is:  0.0023131296038627625\n",
      "\n",
      "The classification loss after processing this batch is:  0.1903761476278305\n",
      "The representation loss after processing this batch is:  0.002798423171043396\n",
      "\n",
      "The classification loss after processing this batch is:  0.11282650381326675\n",
      "The representation loss after processing this batch is:  0.0027158036828041077\n",
      "\n",
      "The classification loss after processing this batch is:  0.26514071226119995\n",
      "The representation loss after processing this batch is:  0.0022326745092868805\n",
      "\n",
      "The classification loss after processing this batch is:  0.051290079951286316\n",
      "The representation loss after processing this batch is:  0.002515919506549835\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10197863727807999\n",
      "The representation loss after processing this batch is:  0.002575695514678955\n",
      "\n",
      "The classification loss after processing this batch is:  0.03189827874302864\n",
      "The representation loss after processing this batch is:  0.00275363028049469\n",
      "\n",
      "The classification loss after processing this batch is:  0.03088901750743389\n",
      "The representation loss after processing this batch is:  0.002728097140789032\n",
      "\n",
      "The classification loss after processing this batch is:  0.07007858157157898\n",
      "The representation loss after processing this batch is:  0.0026195943355560303\n",
      "\n",
      "The classification loss after processing this batch is:  0.049535226076841354\n",
      "The representation loss after processing this batch is:  0.002204686403274536\n",
      "\n",
      "The classification loss after processing this batch is:  0.10728073120117188\n",
      "The representation loss after processing this batch is:  0.0026034265756607056\n",
      "\n",
      "The classification loss after processing this batch is:  0.09077858179807663\n",
      "The representation loss after processing this batch is:  0.00319092720746994\n",
      "\n",
      "The classification loss after processing this batch is:  0.0981888696551323\n",
      "The representation loss after processing this batch is:  0.00241176038980484\n",
      "\n",
      "The classification loss after processing this batch is:  0.10024692118167877\n",
      "The representation loss after processing this batch is:  0.0023582279682159424\n",
      "\n",
      "The classification loss after processing this batch is:  0.051550157368183136\n",
      "The representation loss after processing this batch is:  0.002516724169254303\n",
      "\n",
      "The classification loss after processing this batch is:  0.13729630410671234\n",
      "The representation loss after processing this batch is:  0.002452179789543152\n",
      "\n",
      "The classification loss after processing this batch is:  0.12469180673360825\n",
      "The representation loss after processing this batch is:  0.002813190221786499\n",
      "\n",
      "The classification loss after processing this batch is:  0.17647311091423035\n",
      "The representation loss after processing this batch is:  0.0029122531414031982\n",
      "\n",
      "The classification loss after processing this batch is:  0.10067442059516907\n",
      "The representation loss after processing this batch is:  0.002425961196422577\n",
      "\n",
      "The classification loss after processing this batch is:  0.08418091386556625\n",
      "The representation loss after processing this batch is:  0.0024624131619930267\n",
      "\n",
      "The classification loss after processing this batch is:  0.19918014109134674\n",
      "The representation loss after processing this batch is:  0.0026063919067382812\n",
      "\n",
      "The classification loss after processing this batch is:  0.17016778886318207\n",
      "The representation loss after processing this batch is:  0.0026770830154418945\n",
      "\n",
      "The classification loss after processing this batch is:  0.14630058407783508\n",
      "The representation loss after processing this batch is:  0.0024452880024909973\n",
      "\n",
      "The classification loss after processing this batch is:  0.05365865305066109\n",
      "The representation loss after processing this batch is:  0.0026293694972991943\n",
      "\n",
      "The classification loss after processing this batch is:  0.10384394973516464\n",
      "The representation loss after processing this batch is:  0.00273335725069046\n",
      "\n",
      "The classification loss after processing this batch is:  0.121829554438591\n",
      "The representation loss after processing this batch is:  0.002440318465232849\n",
      "\n",
      "The classification loss after processing this batch is:  0.13484959304332733\n",
      "The representation loss after processing this batch is:  0.002702523022890091\n",
      "\n",
      "The classification loss after processing this batch is:  0.14025786519050598\n",
      "The representation loss after processing this batch is:  0.003376346081495285\n",
      "\n",
      "The classification loss after processing this batch is:  0.07452309876680374\n",
      "The representation loss after processing this batch is:  0.0030230358242988586\n",
      "\n",
      "The classification loss after processing this batch is:  0.1466553956270218\n",
      "The representation loss after processing this batch is:  0.0028425678610801697\n",
      "\n",
      "The classification loss after processing this batch is:  0.16911453008651733\n",
      "The representation loss after processing this batch is:  0.00248723104596138\n",
      "\n",
      "The classification loss after processing this batch is:  0.08078520745038986\n",
      "The representation loss after processing this batch is:  0.003122970461845398\n",
      "\n",
      "The classification loss after processing this batch is:  0.13824157416820526\n",
      "The representation loss after processing this batch is:  0.0022841915488243103\n",
      "\n",
      "The classification loss after processing this batch is:  0.07378725707530975\n",
      "The representation loss after processing this batch is:  0.002124294638633728\n",
      "\n",
      "The classification loss after processing this batch is:  0.14988300204277039\n",
      "The representation loss after processing this batch is:  0.0023539960384368896\n",
      "\n",
      "The classification loss after processing this batch is:  0.07795803248882294\n",
      "The representation loss after processing this batch is:  0.00248679518699646\n",
      "\n",
      "The classification loss after processing this batch is:  0.13756005465984344\n",
      "The representation loss after processing this batch is:  0.0027398616075515747\n",
      "\n",
      "The classification loss after processing this batch is:  0.10434319078922272\n",
      "The representation loss after processing this batch is:  0.002841167151927948\n",
      "\n",
      "The classification loss after processing this batch is:  0.09341344982385635\n",
      "The representation loss after processing this batch is:  0.0024239197373390198\n",
      "\n",
      "The classification loss after processing this batch is:  0.09826330095529556\n",
      "The representation loss after processing this batch is:  0.0027290210127830505\n",
      "\n",
      "The classification loss after processing this batch is:  0.14633581042289734\n",
      "The representation loss after processing this batch is:  0.002958625555038452\n",
      "\n",
      "The classification loss after processing this batch is:  0.16008569300174713\n",
      "The representation loss after processing this batch is:  0.0029060468077659607\n",
      "\n",
      "The classification loss after processing this batch is:  0.1408635526895523\n",
      "The representation loss after processing this batch is:  0.002766605466604233\n",
      "\n",
      "The classification loss after processing this batch is:  0.12323249131441116\n",
      "The representation loss after processing this batch is:  0.0028254538774490356\n",
      "\n",
      "The classification loss after processing this batch is:  0.08713670819997787\n",
      "The representation loss after processing this batch is:  0.0024746879935264587\n",
      "\n",
      "The classification loss after processing this batch is:  0.09086719900369644\n",
      "The representation loss after processing this batch is:  0.0028776079416275024\n",
      "\n",
      "The classification loss after processing this batch is:  0.07519254833459854\n",
      "The representation loss after processing this batch is:  0.002678312361240387\n",
      "\n",
      "The classification loss after processing this batch is:  0.10305105149745941\n",
      "The representation loss after processing this batch is:  0.0025356560945510864\n",
      "\n",
      "The classification loss after processing this batch is:  0.05145867168903351\n",
      "The representation loss after processing this batch is:  0.0025174878537654877\n",
      "\n",
      "The classification loss after processing this batch is:  0.053546514362096786\n",
      "The representation loss after processing this batch is:  0.002392694354057312\n",
      "\n",
      "The classification loss after processing this batch is:  0.08191721886396408\n",
      "The representation loss after processing this batch is:  0.002774149179458618\n",
      "\n",
      "The classification loss after processing this batch is:  0.036192815750837326\n",
      "The representation loss after processing this batch is:  0.0028246715664863586\n",
      "\n",
      "The classification loss after processing this batch is:  0.15581698715686798\n",
      "The representation loss after processing this batch is:  0.002496190369129181\n",
      "\n",
      "The classification loss after processing this batch is:  0.09621059894561768\n",
      "The representation loss after processing this batch is:  0.002226017415523529\n",
      "\n",
      "The classification loss after processing this batch is:  0.10955620557069778\n",
      "The representation loss after processing this batch is:  0.0026813074946403503\n",
      "\n",
      "The classification loss after processing this batch is:  0.04062801972031593\n",
      "The representation loss after processing this batch is:  0.002800092101097107\n",
      "\n",
      "The classification loss after processing this batch is:  0.1647435873746872\n",
      "The representation loss after processing this batch is:  0.0025332532823085785\n",
      "\n",
      "The classification loss after processing this batch is:  0.11912719160318375\n",
      "The representation loss after processing this batch is:  0.00257110595703125\n",
      "\n",
      "The classification loss after processing this batch is:  0.10315164923667908\n",
      "The representation loss after processing this batch is:  0.0023968443274497986\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10878366976976395\n",
      "The representation loss after processing this batch is:  0.002593584358692169\n",
      "\n",
      "The classification loss after processing this batch is:  0.09224232286214828\n",
      "The representation loss after processing this batch is:  0.002640239894390106\n",
      "\n",
      "The classification loss after processing this batch is:  0.06873789429664612\n",
      "The representation loss after processing this batch is:  0.0025383085012435913\n",
      "\n",
      "The classification loss after processing this batch is:  0.07300850003957748\n",
      "The representation loss after processing this batch is:  0.0026496872305870056\n",
      "\n",
      "The classification loss after processing this batch is:  0.06618126481771469\n",
      "The representation loss after processing this batch is:  0.0024451017379760742\n",
      "\n",
      "The classification loss after processing this batch is:  0.19047538936138153\n",
      "The representation loss after processing this batch is:  0.0026348158717155457\n",
      "\n",
      "The classification loss after processing this batch is:  0.1243601068854332\n",
      "The representation loss after processing this batch is:  0.002408009022474289\n",
      "\n",
      "The classification loss after processing this batch is:  0.14329229295253754\n",
      "The representation loss after processing this batch is:  0.003064393997192383\n",
      "\n",
      "The classification loss after processing this batch is:  0.16995461285114288\n",
      "The representation loss after processing this batch is:  0.002649247646331787\n",
      "\n",
      "The classification loss after processing this batch is:  0.16901369392871857\n",
      "The representation loss after processing this batch is:  0.0026693642139434814\n",
      "\n",
      "The classification loss after processing this batch is:  0.16429191827774048\n",
      "The representation loss after processing this batch is:  0.002691008150577545\n",
      "\n",
      "The classification loss after processing this batch is:  0.2573810815811157\n",
      "The representation loss after processing this batch is:  0.0023892074823379517\n",
      "\n",
      "The classification loss after processing this batch is:  0.18355321884155273\n",
      "The representation loss after processing this batch is:  0.002317506819963455\n",
      "\n",
      "The classification loss after processing this batch is:  0.11801309883594513\n",
      "The representation loss after processing this batch is:  0.002252340316772461\n",
      "\n",
      "The classification loss after processing this batch is:  0.09600668400526047\n",
      "The representation loss after processing this batch is:  0.0023856423795223236\n",
      "\n",
      "The classification loss after processing this batch is:  0.06564153730869293\n",
      "The representation loss after processing this batch is:  0.002477690577507019\n",
      "\n",
      "The classification loss after processing this batch is:  0.051376812160015106\n",
      "The representation loss after processing this batch is:  0.0024432912468910217\n",
      "\n",
      "The classification loss after processing this batch is:  0.0847807377576828\n",
      "The representation loss after processing this batch is:  0.002960778772830963\n",
      "\n",
      "The classification loss after processing this batch is:  0.14214591681957245\n",
      "The representation loss after processing this batch is:  0.0025236904621124268\n",
      "\n",
      "The classification loss after processing this batch is:  0.07327606528997421\n",
      "The representation loss after processing this batch is:  0.002512991428375244\n",
      "\n",
      "The classification loss after processing this batch is:  0.2077542245388031\n",
      "The representation loss after processing this batch is:  0.0026524364948272705\n",
      "\n",
      "The classification loss after processing this batch is:  0.11336524039506912\n",
      "The representation loss after processing this batch is:  0.0026607289910316467\n",
      "\n",
      "The classification loss after processing this batch is:  0.13887976109981537\n",
      "The representation loss after processing this batch is:  0.002490166574716568\n",
      "\n",
      "The classification loss after processing this batch is:  0.13004568219184875\n",
      "The representation loss after processing this batch is:  0.002397477626800537\n",
      "\n",
      "The classification loss after processing this batch is:  0.1765868216753006\n",
      "The representation loss after processing this batch is:  0.002281568944454193\n",
      "\n",
      "The classification loss after processing this batch is:  0.1310778558254242\n",
      "The representation loss after processing this batch is:  0.002405282109975815\n",
      "\n",
      "The classification loss after processing this batch is:  0.09771348536014557\n",
      "The representation loss after processing this batch is:  0.0028558820486068726\n",
      "\n",
      "The classification loss after processing this batch is:  0.14553207159042358\n",
      "The representation loss after processing this batch is:  0.0023826733231544495\n",
      "\n",
      "The classification loss after processing this batch is:  0.04791200906038284\n",
      "The representation loss after processing this batch is:  0.002421148121356964\n",
      "\n",
      "The classification loss after processing this batch is:  0.04939983785152435\n",
      "The representation loss after processing this batch is:  0.002379275858402252\n",
      "\n",
      "The classification loss after processing this batch is:  0.12196846306324005\n",
      "The representation loss after processing this batch is:  0.002736233174800873\n",
      "\n",
      "The classification loss after processing this batch is:  0.17279228568077087\n",
      "The representation loss after processing this batch is:  0.0025018230080604553\n",
      "\n",
      "The classification loss after processing this batch is:  0.14089931547641754\n",
      "The representation loss after processing this batch is:  0.0026965588331222534\n",
      "\n",
      "The classification loss after processing this batch is:  0.0725657269358635\n",
      "The representation loss after processing this batch is:  0.003260865807533264\n",
      "\n",
      "The classification loss after processing this batch is:  0.10758019238710403\n",
      "The representation loss after processing this batch is:  0.002826392650604248\n",
      "\n",
      "The classification loss after processing this batch is:  0.07600654661655426\n",
      "The representation loss after processing this batch is:  0.0026080161333084106\n",
      "\n",
      "The classification loss after processing this batch is:  0.1944061815738678\n",
      "The representation loss after processing this batch is:  0.002454429864883423\n",
      "\n",
      "The classification loss after processing this batch is:  0.055461183190345764\n",
      "The representation loss after processing this batch is:  0.0021830126643180847\n",
      "\n",
      "The classification loss after processing this batch is:  0.05355754867196083\n",
      "The representation loss after processing this batch is:  0.0028048381209373474\n",
      "\n",
      "The classification loss after processing this batch is:  0.12898336350917816\n",
      "The representation loss after processing this batch is:  0.003140777349472046\n",
      "\n",
      "The classification loss after processing this batch is:  0.11582072824239731\n",
      "The representation loss after processing this batch is:  0.002654828131198883\n",
      "\n",
      "The classification loss after processing this batch is:  0.0804784744977951\n",
      "The representation loss after processing this batch is:  0.002891942858695984\n",
      "\n",
      "The classification loss after processing this batch is:  0.049762897193431854\n",
      "The representation loss after processing this batch is:  0.0024709440767765045\n",
      "\n",
      "The classification loss after processing this batch is:  0.12235192209482193\n",
      "The representation loss after processing this batch is:  0.0028733909130096436\n",
      "\n",
      "The classification loss after processing this batch is:  0.1384279727935791\n",
      "The representation loss after processing this batch is:  0.0027216896414756775\n",
      "\n",
      "The classification loss after processing this batch is:  0.17861953377723694\n",
      "The representation loss after processing this batch is:  0.0024728141725063324\n",
      "\n",
      "The classification loss after processing this batch is:  0.14569830894470215\n",
      "The representation loss after processing this batch is:  0.0028608739376068115\n",
      "\n",
      "The classification loss after processing this batch is:  0.06382573395967484\n",
      "The representation loss after processing this batch is:  0.0025607794523239136\n",
      "\n",
      "The classification loss after processing this batch is:  0.0897543728351593\n",
      "The representation loss after processing this batch is:  0.0024294406175613403\n",
      "\n",
      "The classification loss after processing this batch is:  0.17595206201076508\n",
      "The representation loss after processing this batch is:  0.002732895314693451\n",
      "\n",
      "The classification loss after processing this batch is:  0.19452545046806335\n",
      "The representation loss after processing this batch is:  0.0029624029994010925\n",
      "\n",
      "The classification loss after processing this batch is:  0.20659472048282623\n",
      "The representation loss after processing this batch is:  0.0032239779829978943\n",
      "\n",
      "The classification loss after processing this batch is:  0.25957828760147095\n",
      "The representation loss after processing this batch is:  0.0026542693376541138\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.06949584931135178\n",
      "The representation loss after processing this batch is:  0.002334184944629669\n",
      "\n",
      "The classification loss after processing this batch is:  0.16379457712173462\n",
      "The representation loss after processing this batch is:  0.002601172775030136\n",
      "\n",
      "The classification loss after processing this batch is:  0.0922912135720253\n",
      "The representation loss after processing this batch is:  0.002328537404537201\n",
      "\n",
      "The classification loss after processing this batch is:  0.09022187441587448\n",
      "The representation loss after processing this batch is:  0.0024646520614624023\n",
      "\n",
      "The classification loss after processing this batch is:  0.0832507535815239\n",
      "The representation loss after processing this batch is:  0.0026171132922172546\n",
      "\n",
      "The classification loss after processing this batch is:  0.16690094769001007\n",
      "The representation loss after processing this batch is:  0.0025526955723762512\n",
      "\n",
      "The classification loss after processing this batch is:  0.12194549292325974\n",
      "The representation loss after processing this batch is:  0.0023647621273994446\n",
      "\n",
      "The classification loss after processing this batch is:  0.08310583233833313\n",
      "The representation loss after processing this batch is:  0.0024853795766830444\n",
      "\n",
      "The classification loss after processing this batch is:  0.15526427328586578\n",
      "The representation loss after processing this batch is:  0.002554386854171753\n",
      "\n",
      "The classification loss after processing this batch is:  0.04172489792108536\n",
      "The representation loss after processing this batch is:  0.0028569698333740234\n",
      "\n",
      "The classification loss after processing this batch is:  0.10987630486488342\n",
      "The representation loss after processing this batch is:  0.0029176175594329834\n",
      "\n",
      "The classification loss after processing this batch is:  0.13970978558063507\n",
      "The representation loss after processing this batch is:  0.0025434494018554688\n",
      "\n",
      "The classification loss after processing this batch is:  0.14378659427165985\n",
      "The representation loss after processing this batch is:  0.0026478543877601624\n",
      "\n",
      "The classification loss after processing this batch is:  0.04790889844298363\n",
      "The representation loss after processing this batch is:  0.003043361008167267\n",
      "\n",
      "The classification loss after processing this batch is:  0.07037734985351562\n",
      "The representation loss after processing this batch is:  0.0024127699434757233\n",
      "\n",
      "The classification loss after processing this batch is:  0.16312584280967712\n",
      "The representation loss after processing this batch is:  0.002879321575164795\n",
      "\n",
      "The classification loss after processing this batch is:  0.15661582350730896\n",
      "The representation loss after processing this batch is:  0.0024150535464286804\n",
      "\n",
      "The classification loss after processing this batch is:  0.13302098214626312\n",
      "The representation loss after processing this batch is:  0.002428494393825531\n",
      "\n",
      "The classification loss after processing this batch is:  0.09507443010807037\n",
      "The representation loss after processing this batch is:  0.0025077685713768005\n",
      "\n",
      "The classification loss after processing this batch is:  0.06586306542158127\n",
      "The representation loss after processing this batch is:  0.002559565007686615\n",
      "\n",
      "The classification loss after processing this batch is:  0.11154583841562271\n",
      "The representation loss after processing this batch is:  0.0023096688091754913\n",
      "\n",
      "The classification loss after processing this batch is:  0.11703144013881683\n",
      "The representation loss after processing this batch is:  0.002587839961051941\n",
      "\n",
      "The classification loss after processing this batch is:  0.15059760212898254\n",
      "The representation loss after processing this batch is:  0.00250370055437088\n",
      "\n",
      "The classification loss after processing this batch is:  0.0905858650803566\n",
      "The representation loss after processing this batch is:  0.0027809664607048035\n",
      "\n",
      "The classification loss after processing this batch is:  0.05737152323126793\n",
      "The representation loss after processing this batch is:  0.0024649277329444885\n",
      "\n",
      "The classification loss after processing this batch is:  0.13715536892414093\n",
      "The representation loss after processing this batch is:  0.0026289932429790497\n",
      "\n",
      "The classification loss after processing this batch is:  0.1915949434041977\n",
      "The representation loss after processing this batch is:  0.00254126638174057\n",
      "\n",
      "The classification loss after processing this batch is:  0.05755040794610977\n",
      "The representation loss after processing this batch is:  0.002702362835407257\n",
      "\n",
      "The classification loss after processing this batch is:  0.08523953706026077\n",
      "The representation loss after processing this batch is:  0.0023309066891670227\n",
      "\n",
      "The classification loss after processing this batch is:  0.16925114393234253\n",
      "The representation loss after processing this batch is:  0.002449318766593933\n",
      "\n",
      "The classification loss after processing this batch is:  0.18608340620994568\n",
      "The representation loss after processing this batch is:  0.002483278512954712\n",
      "\n",
      "The classification loss after processing this batch is:  0.0940135270357132\n",
      "The representation loss after processing this batch is:  0.0023873820900917053\n",
      "\n",
      "The classification loss after processing this batch is:  0.146804541349411\n",
      "The representation loss after processing this batch is:  0.0023225173354148865\n",
      "\n",
      "The classification loss after processing this batch is:  0.17690147459506989\n",
      "The representation loss after processing this batch is:  0.0027446970343589783\n",
      "\n",
      "The classification loss after processing this batch is:  0.19419769942760468\n",
      "The representation loss after processing this batch is:  0.0026946216821670532\n",
      "\n",
      "The classification loss after processing this batch is:  0.12267930805683136\n",
      "The representation loss after processing this batch is:  0.002759672701358795\n",
      "\n",
      "The classification loss after processing this batch is:  0.1689653992652893\n",
      "The representation loss after processing this batch is:  0.00248514860868454\n",
      "\n",
      "The classification loss after processing this batch is:  0.11677911877632141\n",
      "The representation loss after processing this batch is:  0.003473222255706787\n",
      "\n",
      "The classification loss after processing this batch is:  0.1011865884065628\n",
      "The representation loss after processing this batch is:  0.00269162654876709\n",
      "\n",
      "The classification loss after processing this batch is:  0.08710145950317383\n",
      "The representation loss after processing this batch is:  0.002388976514339447\n",
      "\n",
      "The classification loss after processing this batch is:  0.09282230585813522\n",
      "The representation loss after processing this batch is:  0.002323884516954422\n",
      "\n",
      "The classification loss after processing this batch is:  0.10451475530862808\n",
      "The representation loss after processing this batch is:  0.0025628283619880676\n",
      "\n",
      "The classification loss after processing this batch is:  0.1080949455499649\n",
      "The representation loss after processing this batch is:  0.0024885758757591248\n",
      "\n",
      "The classification loss after processing this batch is:  0.17382927238941193\n",
      "The representation loss after processing this batch is:  0.002470269799232483\n",
      "\n",
      "The classification loss after processing this batch is:  0.0670730397105217\n",
      "The representation loss after processing this batch is:  0.0026761218905448914\n",
      "\n",
      "The classification loss after processing this batch is:  0.05638986453413963\n",
      "The representation loss after processing this batch is:  0.0029928982257843018\n",
      "\n",
      "The classification loss after processing this batch is:  0.12200117111206055\n",
      "The representation loss after processing this batch is:  0.002855531871318817\n",
      "\n",
      "The classification loss after processing this batch is:  0.037393130362033844\n",
      "The representation loss after processing this batch is:  0.0022953450679779053\n",
      "\n",
      "The classification loss after processing this batch is:  0.08080614358186722\n",
      "The representation loss after processing this batch is:  0.002664618194103241\n",
      "\n",
      "The classification loss after processing this batch is:  0.03590777888894081\n",
      "The representation loss after processing this batch is:  0.0026169195771217346\n",
      "\n",
      "The classification loss after processing this batch is:  0.11394906789064407\n",
      "The representation loss after processing this batch is:  0.0023396313190460205\n",
      "\n",
      "The classification loss after processing this batch is:  0.16428762674331665\n",
      "The representation loss after processing this batch is:  0.0026409775018692017\n",
      "\n",
      "The classification loss after processing this batch is:  0.15223906934261322\n",
      "The representation loss after processing this batch is:  0.003129228949546814\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.13083107769489288\n",
      "The representation loss after processing this batch is:  0.003063894808292389\n",
      "\n",
      "The classification loss after processing this batch is:  0.08286244422197342\n",
      "The representation loss after processing this batch is:  0.0027474388480186462\n",
      "\n",
      "The classification loss after processing this batch is:  0.09801434725522995\n",
      "The representation loss after processing this batch is:  0.0025743618607521057\n",
      "\n",
      "The classification loss after processing this batch is:  0.09138666093349457\n",
      "The representation loss after processing this batch is:  0.002440318465232849\n",
      "\n",
      "The classification loss after processing this batch is:  0.053926799446344376\n",
      "The representation loss after processing this batch is:  0.002854611724615097\n",
      "\n",
      "The classification loss after processing this batch is:  0.06478089839220047\n",
      "The representation loss after processing this batch is:  0.0026240274310112\n",
      "\n",
      "The classification loss after processing this batch is:  0.03984454646706581\n",
      "The representation loss after processing this batch is:  0.002637147903442383\n",
      "\n",
      "The classification loss after processing this batch is:  0.08997440338134766\n",
      "The representation loss after processing this batch is:  0.0027053505182266235\n",
      "\n",
      "The classification loss after processing this batch is:  0.14610980451107025\n",
      "The representation loss after processing this batch is:  0.0026417337357997894\n",
      "\n",
      "The classification loss after processing this batch is:  0.16725434362888336\n",
      "The representation loss after processing this batch is:  0.00270119309425354\n",
      "\n",
      "The classification loss after processing this batch is:  0.12984099984169006\n",
      "The representation loss after processing this batch is:  0.003109067678451538\n",
      "\n",
      "The classification loss after processing this batch is:  0.09915702044963837\n",
      "The representation loss after processing this batch is:  0.002818182110786438\n",
      "\n",
      "The classification loss after processing this batch is:  0.1351970136165619\n",
      "The representation loss after processing this batch is:  0.0027864426374435425\n",
      "\n",
      "The classification loss after processing this batch is:  0.096886545419693\n",
      "The representation loss after processing this batch is:  0.002712741494178772\n",
      "\n",
      "The classification loss after processing this batch is:  0.31872671842575073\n",
      "The representation loss after processing this batch is:  0.003148593008518219\n",
      "\n",
      "The classification loss after processing this batch is:  0.1312689483165741\n",
      "The representation loss after processing this batch is:  0.0028875768184661865\n",
      "\n",
      "The classification loss after processing this batch is:  0.19409489631652832\n",
      "The representation loss after processing this batch is:  0.0031589195132255554\n",
      "\n",
      "The classification loss after processing this batch is:  0.08032544702291489\n",
      "The representation loss after processing this batch is:  0.002428494393825531\n",
      "\n",
      "The classification loss after processing this batch is:  0.09410062432289124\n",
      "The representation loss after processing this batch is:  0.0024519264698028564\n",
      "\n",
      "The classification loss after processing this batch is:  0.14640095829963684\n",
      "The representation loss after processing this batch is:  0.0024579614400863647\n",
      "\n",
      "The classification loss after processing this batch is:  0.10721494257450104\n",
      "The representation loss after processing this batch is:  0.0027236230671405792\n",
      "\n",
      "The classification loss after processing this batch is:  0.20887552201747894\n",
      "The representation loss after processing this batch is:  0.0025743991136550903\n",
      "\n",
      "The classification loss after processing this batch is:  0.12762734293937683\n",
      "The representation loss after processing this batch is:  0.0030607953667640686\n",
      "\n",
      "The classification loss after processing this batch is:  0.17428989708423615\n",
      "The representation loss after processing this batch is:  0.0030929744243621826\n",
      "\n",
      "The classification loss after processing this batch is:  0.125834658741951\n",
      "The representation loss after processing this batch is:  0.0028772950172424316\n",
      "\n",
      "The classification loss after processing this batch is:  0.040726158767938614\n",
      "The representation loss after processing this batch is:  0.002718321979045868\n",
      "\n",
      "The classification loss after processing this batch is:  0.09242364019155502\n",
      "The representation loss after processing this batch is:  0.002442318946123123\n",
      "\n",
      "The classification loss after processing this batch is:  0.09952333569526672\n",
      "The representation loss after processing this batch is:  0.002439495176076889\n",
      "\n",
      "The classification loss after processing this batch is:  0.07735409587621689\n",
      "The representation loss after processing this batch is:  0.002666175365447998\n",
      "\n",
      "The classification loss after processing this batch is:  0.15373684465885162\n",
      "The representation loss after processing this batch is:  0.0023351162672042847\n",
      "\n",
      "The classification loss after processing this batch is:  0.23662586510181427\n",
      "The representation loss after processing this batch is:  0.002329401671886444\n",
      "\n",
      "The classification loss after processing this batch is:  0.12095163017511368\n",
      "The representation loss after processing this batch is:  0.002242043614387512\n",
      "\n",
      "The classification loss after processing this batch is:  0.08868665993213654\n",
      "The representation loss after processing this batch is:  0.0025739558041095734\n",
      "\n",
      "The classification loss after processing this batch is:  0.11456622183322906\n",
      "The representation loss after processing this batch is:  0.0025640055537223816\n",
      "\n",
      "The classification loss after processing this batch is:  0.0746631845831871\n",
      "The representation loss after processing this batch is:  0.002833828330039978\n",
      "\n",
      "The classification loss after processing this batch is:  0.120418481528759\n",
      "The representation loss after processing this batch is:  0.002813108265399933\n",
      "\n",
      "The classification loss after processing this batch is:  0.051353249698877335\n",
      "The representation loss after processing this batch is:  0.0026878491044044495\n",
      "\n",
      "The classification loss after processing this batch is:  0.1142931655049324\n",
      "The representation loss after processing this batch is:  0.002343490719795227\n",
      "\n",
      "The classification loss after processing this batch is:  0.1784573495388031\n",
      "The representation loss after processing this batch is:  0.002615746110677719\n",
      "\n",
      "The classification loss after processing this batch is:  0.05753779783844948\n",
      "The representation loss after processing this batch is:  0.002437181770801544\n",
      "\n",
      "The classification loss after processing this batch is:  0.16577161848545074\n",
      "The representation loss after processing this batch is:  0.00218760222196579\n",
      "\n",
      "The classification loss after processing this batch is:  0.09965392202138901\n",
      "The representation loss after processing this batch is:  0.0021813958883285522\n",
      "\n",
      "The classification loss after processing this batch is:  0.1130661815404892\n",
      "The representation loss after processing this batch is:  0.0025301501154899597\n",
      "\n",
      "The classification loss after processing this batch is:  0.06315568834543228\n",
      "The representation loss after processing this batch is:  0.0025311633944511414\n",
      "\n",
      "The classification loss after processing this batch is:  0.12031824886798859\n",
      "The representation loss after processing this batch is:  0.002485997974872589\n",
      "\n",
      "The classification loss after processing this batch is:  0.06943780928850174\n",
      "The representation loss after processing this batch is:  0.0026296377182006836\n",
      "\n",
      "The classification loss after processing this batch is:  0.31871193647384644\n",
      "The representation loss after processing this batch is:  0.0027139782905578613\n",
      "\n",
      "The classification loss after processing this batch is:  0.14771802723407745\n",
      "The representation loss after processing this batch is:  0.0027318671345710754\n",
      "\n",
      "The classification loss after processing this batch is:  0.1586112082004547\n",
      "The representation loss after processing this batch is:  0.002426460385322571\n",
      "\n",
      "The classification loss after processing this batch is:  0.07931048423051834\n",
      "The representation loss after processing this batch is:  0.0021796151995658875\n",
      "\n",
      "The classification loss after processing this batch is:  0.12861225008964539\n",
      "The representation loss after processing this batch is:  0.002491191029548645\n",
      "\n",
      "The classification loss after processing this batch is:  0.05100144445896149\n",
      "The representation loss after processing this batch is:  0.0023585744202136993\n",
      "\n",
      "The classification loss after processing this batch is:  0.13201096653938293\n",
      "The representation loss after processing this batch is:  0.0024129562079906464\n",
      "\n",
      "The classification loss after processing this batch is:  0.17876319587230682\n",
      "The representation loss after processing this batch is:  0.0024874508380889893\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.15628619492053986\n",
      "The representation loss after processing this batch is:  0.0029106661677360535\n",
      "\n",
      "The classification loss after processing this batch is:  0.17384831607341766\n",
      "The representation loss after processing this batch is:  0.0026452504098415375\n",
      "\n",
      "The classification loss after processing this batch is:  0.09389758110046387\n",
      "The representation loss after processing this batch is:  0.002378113567829132\n",
      "\n",
      "The classification loss after processing this batch is:  0.19535429775714874\n",
      "The representation loss after processing this batch is:  0.0026732608675956726\n",
      "\n",
      "The classification loss after processing this batch is:  0.13361984491348267\n",
      "The representation loss after processing this batch is:  0.00272524356842041\n",
      "\n",
      "The classification loss after processing this batch is:  0.18089623749256134\n",
      "The representation loss after processing this batch is:  0.002604439854621887\n",
      "\n",
      "The classification loss after processing this batch is:  0.10999415069818497\n",
      "The representation loss after processing this batch is:  0.0027109459042549133\n",
      "\n",
      "The classification loss after processing this batch is:  0.10457076877355576\n",
      "The representation loss after processing this batch is:  0.002826206386089325\n",
      "\n",
      "The classification loss after processing this batch is:  0.04961806535720825\n",
      "The representation loss after processing this batch is:  0.002286221832036972\n",
      "\n",
      "The classification loss after processing this batch is:  0.17165417969226837\n",
      "The representation loss after processing this batch is:  0.002340894192457199\n",
      "\n",
      "The classification loss after processing this batch is:  0.24037417769432068\n",
      "The representation loss after processing this batch is:  0.002721041440963745\n",
      "\n",
      "The classification loss after processing this batch is:  0.1102432981133461\n",
      "The representation loss after processing this batch is:  0.002805545926094055\n",
      "\n",
      "The classification loss after processing this batch is:  0.13736039400100708\n",
      "The representation loss after processing this batch is:  0.0032909438014030457\n",
      "\n",
      "The classification loss after processing this batch is:  0.16795626282691956\n",
      "The representation loss after processing this batch is:  0.0025244057178497314\n",
      "\n",
      "The classification loss after processing this batch is:  0.1410907357931137\n",
      "The representation loss after processing this batch is:  0.002860143780708313\n",
      "\n",
      "The classification loss after processing this batch is:  0.05350341275334358\n",
      "The representation loss after processing this batch is:  0.002290472388267517\n",
      "\n",
      "The classification loss after processing this batch is:  0.14142608642578125\n",
      "The representation loss after processing this batch is:  0.0025228559970855713\n",
      "\n",
      "The classification loss after processing this batch is:  0.1478613168001175\n",
      "The representation loss after processing this batch is:  0.0027591511607170105\n",
      "\n",
      "The classification loss after processing this batch is:  0.10127295553684235\n",
      "The representation loss after processing this batch is:  0.002547111362218857\n",
      "\n",
      "The classification loss after processing this batch is:  0.0401441715657711\n",
      "The representation loss after processing this batch is:  0.0026094019412994385\n",
      "\n",
      "The classification loss after processing this batch is:  0.08907298743724823\n",
      "The representation loss after processing this batch is:  0.002660021185874939\n",
      "\n",
      "The classification loss after processing this batch is:  0.08155392110347748\n",
      "The representation loss after processing this batch is:  0.0028371289372444153\n",
      "\n",
      "The classification loss after processing this batch is:  0.12179891020059586\n",
      "The representation loss after processing this batch is:  0.0023884139955043793\n",
      "\n",
      "The classification loss after processing this batch is:  0.1756950169801712\n",
      "The representation loss after processing this batch is:  0.0025301389396190643\n",
      "\n",
      "The classification loss after processing this batch is:  0.1493227332830429\n",
      "The representation loss after processing this batch is:  0.0023529306054115295\n",
      "\n",
      "The classification loss after processing this batch is:  0.10519976913928986\n",
      "The representation loss after processing this batch is:  0.0026825927197933197\n",
      "\n",
      "The classification loss after processing this batch is:  0.15373948216438293\n",
      "The representation loss after processing this batch is:  0.0030410215258598328\n",
      "\n",
      "The classification loss after processing this batch is:  0.11993253231048584\n",
      "The representation loss after processing this batch is:  0.002929195761680603\n",
      "\n",
      "The classification loss after processing this batch is:  0.09585847705602646\n",
      "The representation loss after processing this batch is:  0.0028389543294906616\n",
      "\n",
      "The classification loss after processing this batch is:  0.19723309576511383\n",
      "The representation loss after processing this batch is:  0.0027248263359069824\n",
      "\n",
      "The classification loss after processing this batch is:  0.17641876637935638\n",
      "The representation loss after processing this batch is:  0.003129146993160248\n",
      "\n",
      "The classification loss after processing this batch is:  0.07760129868984222\n",
      "The representation loss after processing this batch is:  0.002561047673225403\n",
      "\n",
      "The classification loss after processing this batch is:  0.07141167670488358\n",
      "The representation loss after processing this batch is:  0.0026582181453704834\n",
      "\n",
      "The classification loss after processing this batch is:  0.08677893131971359\n",
      "The representation loss after processing this batch is:  0.0023061856627464294\n",
      "\n",
      "The classification loss after processing this batch is:  0.08713727444410324\n",
      "The representation loss after processing this batch is:  0.002533242106437683\n",
      "\n",
      "The classification loss after processing this batch is:  0.11598718166351318\n",
      "The representation loss after processing this batch is:  0.002525757998228073\n",
      "\n",
      "The classification loss after processing this batch is:  0.2030782252550125\n",
      "The representation loss after processing this batch is:  0.0023297667503356934\n",
      "\n",
      "The classification loss after processing this batch is:  0.18562307953834534\n",
      "The representation loss after processing this batch is:  0.002889864146709442\n",
      "\n",
      "The classification loss after processing this batch is:  0.1551395058631897\n",
      "The representation loss after processing this batch is:  0.0021964237093925476\n",
      "\n",
      "The classification loss after processing this batch is:  0.1309521347284317\n",
      "The representation loss after processing this batch is:  0.0021866746246814728\n",
      "\n",
      "The classification loss after processing this batch is:  0.10389471799135208\n",
      "The representation loss after processing this batch is:  0.0022649839520454407\n",
      "\n",
      "The classification loss after processing this batch is:  0.12930196523666382\n",
      "The representation loss after processing this batch is:  0.002241041511297226\n",
      "\n",
      "The classification loss after processing this batch is:  0.2000674307346344\n",
      "The representation loss after processing this batch is:  0.0023762546479701996\n",
      "\n",
      "The classification loss after processing this batch is:  0.17651596665382385\n",
      "The representation loss after processing this batch is:  0.002380460500717163\n",
      "\n",
      "The classification loss after processing this batch is:  0.32789766788482666\n",
      "The representation loss after processing this batch is:  0.0024487003684043884\n",
      "\n",
      "The classification loss after processing this batch is:  0.13723871111869812\n",
      "The representation loss after processing this batch is:  0.0026144608855247498\n",
      "\n",
      "The classification loss after processing this batch is:  0.03997758403420448\n",
      "The representation loss after processing this batch is:  0.002821706235408783\n",
      "\n",
      "The classification loss after processing this batch is:  0.15422342717647552\n",
      "The representation loss after processing this batch is:  0.002672675997018814\n",
      "\n",
      "The classification loss after processing this batch is:  0.10292110592126846\n",
      "The representation loss after processing this batch is:  0.002550192177295685\n",
      "\n",
      "The classification loss after processing this batch is:  0.15821117162704468\n",
      "The representation loss after processing this batch is:  0.0029987916350364685\n",
      "\n",
      "The classification loss after processing this batch is:  0.16031304001808167\n",
      "The representation loss after processing this batch is:  0.0024916157126426697\n",
      "\n",
      "The classification loss after processing this batch is:  0.1475747525691986\n",
      "The representation loss after processing this batch is:  0.002547435462474823\n",
      "\n",
      "The classification loss after processing this batch is:  0.12340908497571945\n",
      "The representation loss after processing this batch is:  0.0024788230657577515\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1652555763721466\n",
      "The representation loss after processing this batch is:  0.002268146723508835\n",
      "\n",
      "The classification loss after processing this batch is:  0.22599594295024872\n",
      "The representation loss after processing this batch is:  0.002510085701942444\n",
      "\n",
      "The classification loss after processing this batch is:  0.22865280508995056\n",
      "The representation loss after processing this batch is:  0.0027956515550613403\n",
      "\n",
      "The classification loss after processing this batch is:  0.13218925893306732\n",
      "The representation loss after processing this batch is:  0.0024176612496376038\n",
      "\n",
      "The classification loss after processing this batch is:  0.045964039862155914\n",
      "The representation loss after processing this batch is:  0.002926267683506012\n",
      "\n",
      "The classification loss after processing this batch is:  0.031039392575621605\n",
      "The representation loss after processing this batch is:  0.0025484710931777954\n",
      "\n",
      "The classification loss after processing this batch is:  0.1118060052394867\n",
      "The representation loss after processing this batch is:  0.0025615468621253967\n",
      "\n",
      "The classification loss after processing this batch is:  0.07355690747499466\n",
      "The representation loss after processing this batch is:  0.0038887038826942444\n",
      "\n",
      "The classification loss after processing this batch is:  0.16601286828517914\n",
      "The representation loss after processing this batch is:  0.0024431422352790833\n",
      "\n",
      "The classification loss after processing this batch is:  0.07878804206848145\n",
      "The representation loss after processing this batch is:  0.0027819573879241943\n",
      "\n",
      "The classification loss after processing this batch is:  0.18022872507572174\n",
      "The representation loss after processing this batch is:  0.0023921430110931396\n",
      "\n",
      "The classification loss after processing this batch is:  0.06420599669218063\n",
      "The representation loss after processing this batch is:  0.0029502660036087036\n",
      "\n",
      "The classification loss after processing this batch is:  0.1364877074956894\n",
      "The representation loss after processing this batch is:  0.002648625522851944\n",
      "\n",
      "The classification loss after processing this batch is:  0.12579959630966187\n",
      "The representation loss after processing this batch is:  0.003023296594619751\n",
      "\n",
      "The classification loss after processing this batch is:  0.16033495962619781\n",
      "The representation loss after processing this batch is:  0.0029255151748657227\n",
      "\n",
      "The classification loss after processing this batch is:  0.10041476041078568\n",
      "The representation loss after processing this batch is:  0.002528958022594452\n",
      "\n",
      "The classification loss after processing this batch is:  0.06953778117895126\n",
      "The representation loss after processing this batch is:  0.00220591202378273\n",
      "\n",
      "The classification loss after processing this batch is:  0.1333613097667694\n",
      "The representation loss after processing this batch is:  0.0026888176798820496\n",
      "\n",
      "The classification loss after processing this batch is:  0.108285091817379\n",
      "The representation loss after processing this batch is:  0.0024818703532218933\n",
      "\n",
      "The classification loss after processing this batch is:  0.1438794732093811\n",
      "The representation loss after processing this batch is:  0.0025023967027664185\n",
      "\n",
      "The classification loss after processing this batch is:  0.15824051201343536\n",
      "The representation loss after processing this batch is:  0.002786882221698761\n",
      "\n",
      "The classification loss after processing this batch is:  0.07866112142801285\n",
      "The representation loss after processing this batch is:  0.002666942775249481\n",
      "\n",
      "The classification loss after processing this batch is:  0.04247443750500679\n",
      "The representation loss after processing this batch is:  0.0024778544902801514\n",
      "\n",
      "The classification loss after processing this batch is:  0.047806721180677414\n",
      "The representation loss after processing this batch is:  0.0028568729758262634\n",
      "\n",
      "The classification loss after processing this batch is:  0.030010005459189415\n",
      "The representation loss after processing this batch is:  0.0027566105127334595\n",
      "\n",
      "The classification loss after processing this batch is:  0.09975037723779678\n",
      "The representation loss after processing this batch is:  0.0026515349745750427\n",
      "\n",
      "The classification loss after processing this batch is:  0.05938854441046715\n",
      "The representation loss after processing this batch is:  0.0027038753032684326\n",
      "\n",
      "The classification loss after processing this batch is:  0.03129812702536583\n",
      "The representation loss after processing this batch is:  0.0025464147329330444\n",
      "\n",
      "The classification loss after processing this batch is:  0.11938432604074478\n",
      "The representation loss after processing this batch is:  0.0031236261129379272\n",
      "\n",
      "The classification loss after processing this batch is:  0.07054898142814636\n",
      "The representation loss after processing this batch is:  0.002714201807975769\n",
      "\n",
      "The classification loss after processing this batch is:  0.04122655466198921\n",
      "The representation loss after processing this batch is:  0.0025000721216201782\n",
      "\n",
      "The classification loss after processing this batch is:  0.06091731786727905\n",
      "The representation loss after processing this batch is:  0.002532653510570526\n",
      "\n",
      "The classification loss after processing this batch is:  0.05033053085207939\n",
      "The representation loss after processing this batch is:  0.00240190327167511\n",
      "\n",
      "The classification loss after processing this batch is:  0.03503589704632759\n",
      "The representation loss after processing this batch is:  0.0026654228568077087\n",
      "\n",
      "The classification loss after processing this batch is:  0.13961394131183624\n",
      "The representation loss after processing this batch is:  0.002733469009399414\n",
      "\n",
      "The classification loss after processing this batch is:  0.1518765538930893\n",
      "The representation loss after processing this batch is:  0.0026848316192626953\n",
      "\n",
      "The classification loss after processing this batch is:  0.07096969336271286\n",
      "The representation loss after processing this batch is:  0.002604953944683075\n",
      "\n",
      "The classification loss after processing this batch is:  0.17743033170700073\n",
      "The representation loss after processing this batch is:  0.0025610625743865967\n",
      "\n",
      "The classification loss after processing this batch is:  0.06665641814470291\n",
      "The representation loss after processing this batch is:  0.0024256333708763123\n",
      "\n",
      "The classification loss after processing this batch is:  0.13662198185920715\n",
      "The representation loss after processing this batch is:  0.0023957788944244385\n",
      "\n",
      "The classification loss after processing this batch is:  0.14186017215251923\n",
      "The representation loss after processing this batch is:  0.0029847174882888794\n",
      "\n",
      "The classification loss after processing this batch is:  0.08011237531900406\n",
      "The representation loss after processing this batch is:  0.0026751160621643066\n",
      "\n",
      "The classification loss after processing this batch is:  0.1765669733285904\n",
      "The representation loss after processing this batch is:  0.0025342032313346863\n",
      "\n",
      "The classification loss after processing this batch is:  0.14468494057655334\n",
      "The representation loss after processing this batch is:  0.0023849979043006897\n",
      "\n",
      "The classification loss after processing this batch is:  0.15333588421344757\n",
      "The representation loss after processing this batch is:  0.0025768205523490906\n",
      "\n",
      "The classification loss after processing this batch is:  0.13679422438144684\n",
      "The representation loss after processing this batch is:  0.002558469772338867\n",
      "\n",
      "The classification loss after processing this batch is:  0.11262691020965576\n",
      "The representation loss after processing this batch is:  0.0025772154331207275\n",
      "\n",
      "The classification loss after processing this batch is:  0.11745710670948029\n",
      "The representation loss after processing this batch is:  0.0023560822010040283\n",
      "\n",
      "The classification loss after processing this batch is:  0.08780861645936966\n",
      "The representation loss after processing this batch is:  0.0027443841099739075\n",
      "\n",
      "The classification loss after processing this batch is:  0.1854747086763382\n",
      "The representation loss after processing this batch is:  0.0024411752820014954\n",
      "\n",
      "The classification loss after processing this batch is:  0.14094975590705872\n",
      "The representation loss after processing this batch is:  0.002387098968029022\n",
      "\n",
      "The classification loss after processing this batch is:  0.054335471242666245\n",
      "The representation loss after processing this batch is:  0.002560444176197052\n",
      "\n",
      "The classification loss after processing this batch is:  0.07800355553627014\n",
      "The representation loss after processing this batch is:  0.002409525215625763\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.18980368971824646\n",
      "The representation loss after processing this batch is:  0.0019897259771823883\n",
      "\n",
      "The classification loss after processing this batch is:  0.07765801250934601\n",
      "The representation loss after processing this batch is:  0.0027526244521141052\n",
      "\n",
      "The classification loss after processing this batch is:  0.10428830236196518\n",
      "The representation loss after processing this batch is:  0.0023842379450798035\n",
      "\n",
      "The classification loss after processing this batch is:  0.12333972007036209\n",
      "The representation loss after processing this batch is:  0.0023673251271247864\n",
      "\n",
      "The classification loss after processing this batch is:  0.07754310220479965\n",
      "The representation loss after processing this batch is:  0.0027698352932929993\n",
      "\n",
      "The classification loss after processing this batch is:  0.04214172810316086\n",
      "The representation loss after processing this batch is:  0.002591744065284729\n",
      "\n",
      "The classification loss after processing this batch is:  0.09641218185424805\n",
      "The representation loss after processing this batch is:  0.002794496715068817\n",
      "\n",
      "The classification loss after processing this batch is:  0.11226661503314972\n",
      "The representation loss after processing this batch is:  0.0026350505650043488\n",
      "\n",
      "The classification loss after processing this batch is:  0.1221187636256218\n",
      "The representation loss after processing this batch is:  0.0024649202823638916\n",
      "\n",
      "The classification loss after processing this batch is:  0.19605770707130432\n",
      "The representation loss after processing this batch is:  0.002502724528312683\n",
      "\n",
      "The classification loss after processing this batch is:  0.1144791916012764\n",
      "The representation loss after processing this batch is:  0.0026589669287204742\n",
      "\n",
      "The classification loss after processing this batch is:  0.17636947333812714\n",
      "The representation loss after processing this batch is:  0.002209428697824478\n",
      "\n",
      "The classification loss after processing this batch is:  0.16085074841976166\n",
      "The representation loss after processing this batch is:  0.0028595924377441406\n",
      "\n",
      "The classification loss after processing this batch is:  0.06093643605709076\n",
      "The representation loss after processing this batch is:  0.002697892487049103\n",
      "\n",
      "The classification loss after processing this batch is:  0.05763792619109154\n",
      "The representation loss after processing this batch is:  0.0026550516486167908\n",
      "\n",
      "The classification loss after processing this batch is:  0.09429994970560074\n",
      "The representation loss after processing this batch is:  0.002591930329799652\n",
      "\n",
      "The classification loss after processing this batch is:  0.1446240246295929\n",
      "The representation loss after processing this batch is:  0.0026684030890464783\n",
      "\n",
      "The classification loss after processing this batch is:  0.10860111564397812\n",
      "The representation loss after processing this batch is:  0.0025932416319847107\n",
      "\n",
      "The classification loss after processing this batch is:  0.1476491093635559\n",
      "The representation loss after processing this batch is:  0.002657197415828705\n",
      "\n",
      "The classification loss after processing this batch is:  0.11803187429904938\n",
      "The representation loss after processing this batch is:  0.002989061176776886\n",
      "\n",
      "The classification loss after processing this batch is:  0.13310199975967407\n",
      "The representation loss after processing this batch is:  0.0028773844242095947\n",
      "\n",
      "The classification loss after processing this batch is:  0.1468905806541443\n",
      "The representation loss after processing this batch is:  0.002506949007511139\n",
      "\n",
      "The classification loss after processing this batch is:  0.11994597315788269\n",
      "The representation loss after processing this batch is:  0.0025278106331825256\n",
      "\n",
      "The classification loss after processing this batch is:  0.11301389336585999\n",
      "The representation loss after processing this batch is:  0.002398379147052765\n",
      "\n",
      "The classification loss after processing this batch is:  0.06408193707466125\n",
      "The representation loss after processing this batch is:  0.0029149800539016724\n",
      "\n",
      "The classification loss after processing this batch is:  0.053615961223840714\n",
      "The representation loss after processing this batch is:  0.0026977285742759705\n",
      "\n",
      "The classification loss after processing this batch is:  0.15906591713428497\n",
      "The representation loss after processing this batch is:  0.0023138970136642456\n",
      "\n",
      "The classification loss after processing this batch is:  0.12753088772296906\n",
      "The representation loss after processing this batch is:  0.002452760934829712\n",
      "\n",
      "The classification loss after processing this batch is:  0.12025021761655807\n",
      "The representation loss after processing this batch is:  0.0024912208318710327\n",
      "\n",
      "The classification loss after processing this batch is:  0.1225147694349289\n",
      "The representation loss after processing this batch is:  0.0025874972343444824\n",
      "\n",
      "The classification loss after processing this batch is:  0.10580039769411087\n",
      "The representation loss after processing this batch is:  0.0026289448142051697\n",
      "\n",
      "The classification loss after processing this batch is:  0.13909383118152618\n",
      "The representation loss after processing this batch is:  0.002443186938762665\n",
      "\n",
      "The classification loss after processing this batch is:  0.1588856279850006\n",
      "The representation loss after processing this batch is:  0.002590131014585495\n",
      "\n",
      "The classification loss after processing this batch is:  0.20168203115463257\n",
      "The representation loss after processing this batch is:  0.002517685294151306\n",
      "\n",
      "The classification loss after processing this batch is:  0.19211120903491974\n",
      "The representation loss after processing this batch is:  0.0023333467543125153\n",
      "\n",
      "The classification loss after processing this batch is:  0.08716501295566559\n",
      "The representation loss after processing this batch is:  0.0027766674757003784\n",
      "\n",
      "The classification loss after processing this batch is:  0.05977340415120125\n",
      "The representation loss after processing this batch is:  0.0029332339763641357\n",
      "\n",
      "The classification loss after processing this batch is:  0.10757546871900558\n",
      "The representation loss after processing this batch is:  0.002771753817796707\n",
      "\n",
      "The classification loss after processing this batch is:  0.1190892904996872\n",
      "The representation loss after processing this batch is:  0.00243261456489563\n",
      "\n",
      "The classification loss after processing this batch is:  0.049729038029909134\n",
      "The representation loss after processing this batch is:  0.0025170035660266876\n",
      "\n",
      "The classification loss after processing this batch is:  0.06490697711706161\n",
      "The representation loss after processing this batch is:  0.002623889595270157\n",
      "\n",
      "The classification loss after processing this batch is:  0.09820593148469925\n",
      "The representation loss after processing this batch is:  0.0023669302463531494\n",
      "\n",
      "The classification loss after processing this batch is:  0.09209757298231125\n",
      "The representation loss after processing this batch is:  0.0026936158537864685\n",
      "\n",
      "The classification loss after processing this batch is:  0.07893870025873184\n",
      "The representation loss after processing this batch is:  0.0027327872812747955\n",
      "\n",
      "The classification loss after processing this batch is:  0.09004443138837814\n",
      "The representation loss after processing this batch is:  0.002369500696659088\n",
      "\n",
      "The classification loss after processing this batch is:  0.07008584588766098\n",
      "The representation loss after processing this batch is:  0.0025299973785877228\n",
      "\n",
      "The classification loss after processing this batch is:  0.11622841656208038\n",
      "The representation loss after processing this batch is:  0.0030028820037841797\n",
      "\n",
      "The classification loss after processing this batch is:  0.09428746998310089\n",
      "The representation loss after processing this batch is:  0.002473931759595871\n",
      "\n",
      "The classification loss after processing this batch is:  0.15808646380901337\n",
      "The representation loss after processing this batch is:  0.002626083791255951\n",
      "\n",
      "The classification loss after processing this batch is:  0.03245989978313446\n",
      "The representation loss after processing this batch is:  0.002716958522796631\n",
      "\n",
      "The classification loss after processing this batch is:  0.05082589015364647\n",
      "The representation loss after processing this batch is:  0.0026143044233322144\n",
      "\n",
      "The classification loss after processing this batch is:  0.15978142619132996\n",
      "The representation loss after processing this batch is:  0.00228022038936615\n",
      "\n",
      "The classification loss after processing this batch is:  0.16902616620063782\n",
      "The representation loss after processing this batch is:  0.002377025783061981\n",
      "\n",
      "The classification loss after processing this batch is:  0.08137617260217667\n",
      "The representation loss after processing this batch is:  0.002364523708820343\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.0391019731760025\n",
      "The representation loss after processing this batch is:  0.0023473426699638367\n",
      "\n",
      "The classification loss after processing this batch is:  0.12364613264799118\n",
      "The representation loss after processing this batch is:  0.0021057911217212677\n",
      "\n",
      "The classification loss after processing this batch is:  0.028216656297445297\n",
      "The representation loss after processing this batch is:  0.0027026161551475525\n",
      "\n",
      "The classification loss after processing this batch is:  0.1435064673423767\n",
      "The representation loss after processing this batch is:  0.0024379268288612366\n",
      "\n",
      "The classification loss after processing this batch is:  0.1331150382757187\n",
      "The representation loss after processing this batch is:  0.0026488453149795532\n",
      "\n",
      "The classification loss after processing this batch is:  0.07000672072172165\n",
      "The representation loss after processing this batch is:  0.002353876829147339\n",
      "\n",
      "The classification loss after processing this batch is:  0.08648868650197983\n",
      "The representation loss after processing this batch is:  0.002684168517589569\n",
      "\n",
      "The classification loss after processing this batch is:  0.08259820193052292\n",
      "The representation loss after processing this batch is:  0.0026663318276405334\n",
      "\n",
      "The classification loss after processing this batch is:  0.04617585614323616\n",
      "The representation loss after processing this batch is:  0.0024175122380256653\n",
      "\n",
      "The classification loss after processing this batch is:  0.21934612095355988\n",
      "The representation loss after processing this batch is:  0.00240480899810791\n",
      "\n",
      "The classification loss after processing this batch is:  0.20484450459480286\n",
      "The representation loss after processing this batch is:  0.0023963451385498047\n",
      "\n",
      "The classification loss after processing this batch is:  0.19314874708652496\n",
      "The representation loss after processing this batch is:  0.002579953521490097\n",
      "\n",
      "The classification loss after processing this batch is:  0.20015721023082733\n",
      "The representation loss after processing this batch is:  0.002376668155193329\n",
      "\n",
      "The classification loss after processing this batch is:  0.13428020477294922\n",
      "The representation loss after processing this batch is:  0.002624817192554474\n",
      "\n",
      "The classification loss after processing this batch is:  0.07673905789852142\n",
      "The representation loss after processing this batch is:  0.0026731491088867188\n",
      "\n",
      "The classification loss after processing this batch is:  0.16812731325626373\n",
      "The representation loss after processing this batch is:  0.002553105354309082\n",
      "\n",
      "The classification loss after processing this batch is:  0.11186286807060242\n",
      "The representation loss after processing this batch is:  0.0026410818099975586\n",
      "\n",
      "The classification loss after processing this batch is:  0.15977120399475098\n",
      "The representation loss after processing this batch is:  0.002562146633863449\n",
      "\n",
      "The classification loss after processing this batch is:  0.10856518149375916\n",
      "The representation loss after processing this batch is:  0.0026721730828285217\n",
      "\n",
      "The classification loss after processing this batch is:  0.16116522252559662\n",
      "The representation loss after processing this batch is:  0.0024655163288116455\n",
      "\n",
      "The classification loss after processing this batch is:  0.0785466656088829\n",
      "The representation loss after processing this batch is:  0.002628777176141739\n",
      "\n",
      "The classification loss after processing this batch is:  0.07746361196041107\n",
      "The representation loss after processing this batch is:  0.002527788281440735\n",
      "\n",
      "The classification loss after processing this batch is:  0.14230254292488098\n",
      "The representation loss after processing this batch is:  0.002323918044567108\n",
      "\n",
      "The classification loss after processing this batch is:  0.039287082850933075\n",
      "The representation loss after processing this batch is:  0.0027880296111106873\n",
      "\n",
      "The classification loss after processing this batch is:  0.05662016198039055\n",
      "The representation loss after processing this batch is:  0.002671852707862854\n",
      "\n",
      "The classification loss after processing this batch is:  0.11071053147315979\n",
      "The representation loss after processing this batch is:  0.002508498728275299\n",
      "\n",
      "The classification loss after processing this batch is:  0.20467834174633026\n",
      "The representation loss after processing this batch is:  0.0024048611521720886\n",
      "\n",
      "The classification loss after processing this batch is:  0.048350147902965546\n",
      "The representation loss after processing this batch is:  0.0022855326533317566\n",
      "\n",
      "The classification loss after processing this batch is:  0.07176149636507034\n",
      "The representation loss after processing this batch is:  0.0023076683282852173\n",
      "\n",
      "The classification loss after processing this batch is:  0.1461908370256424\n",
      "The representation loss after processing this batch is:  0.002458728849887848\n",
      "\n",
      "The classification loss after processing this batch is:  0.21679779887199402\n",
      "The representation loss after processing this batch is:  0.0023238584399223328\n",
      "\n",
      "The classification loss after processing this batch is:  0.09518168866634369\n",
      "The representation loss after processing this batch is:  0.0024261102080345154\n",
      "\n",
      "The classification loss after processing this batch is:  0.20157550275325775\n",
      "The representation loss after processing this batch is:  0.002295989543199539\n",
      "\n",
      "The classification loss after processing this batch is:  0.07540901005268097\n",
      "The representation loss after processing this batch is:  0.0029199346899986267\n",
      "\n",
      "The classification loss after processing this batch is:  0.026717256754636765\n",
      "The representation loss after processing this batch is:  0.002253204584121704\n",
      "\n",
      "The classification loss after processing this batch is:  0.03388654440641403\n",
      "The representation loss after processing this batch is:  0.002493433654308319\n",
      "\n",
      "The classification loss after processing this batch is:  0.15435762703418732\n",
      "The representation loss after processing this batch is:  0.0027800947427749634\n",
      "\n",
      "The classification loss after processing this batch is:  0.1433878242969513\n",
      "The representation loss after processing this batch is:  0.002802528440952301\n",
      "\n",
      "The classification loss after processing this batch is:  0.0876443162560463\n",
      "The representation loss after processing this batch is:  0.003364376723766327\n",
      "\n",
      "The classification loss after processing this batch is:  0.10173209011554718\n",
      "The representation loss after processing this batch is:  0.002505160868167877\n",
      "\n",
      "The classification loss after processing this batch is:  0.10356401652097702\n",
      "The representation loss after processing this batch is:  0.002388976514339447\n",
      "\n",
      "The classification loss after processing this batch is:  0.12316785752773285\n",
      "The representation loss after processing this batch is:  0.0024626292288303375\n",
      "\n",
      "The classification loss after processing this batch is:  0.11158477514982224\n",
      "The representation loss after processing this batch is:  0.002110719680786133\n",
      "\n",
      "The classification loss after processing this batch is:  0.1487283855676651\n",
      "The representation loss after processing this batch is:  0.002402365207672119\n",
      "\n",
      "The classification loss after processing this batch is:  0.13774937391281128\n",
      "The representation loss after processing this batch is:  0.0028168335556983948\n",
      "\n",
      "The classification loss after processing this batch is:  0.25782477855682373\n",
      "The representation loss after processing this batch is:  0.0023571662604808807\n",
      "\n",
      "The classification loss after processing this batch is:  0.12742453813552856\n",
      "The representation loss after processing this batch is:  0.002315111458301544\n",
      "\n",
      "The classification loss after processing this batch is:  0.1302831470966339\n",
      "The representation loss after processing this batch is:  0.002462327480316162\n",
      "\n",
      "The classification loss after processing this batch is:  0.15372447669506073\n",
      "The representation loss after processing this batch is:  0.002395741641521454\n",
      "\n",
      "The classification loss after processing this batch is:  0.05687647685408592\n",
      "The representation loss after processing this batch is:  0.002434544265270233\n",
      "\n",
      "The classification loss after processing this batch is:  0.10190996527671814\n",
      "The representation loss after processing this batch is:  0.0031644441187381744\n",
      "\n",
      "The classification loss after processing this batch is:  0.07244445383548737\n",
      "The representation loss after processing this batch is:  0.002714581787586212\n",
      "\n",
      "The classification loss after processing this batch is:  0.13717350363731384\n",
      "The representation loss after processing this batch is:  0.002540070563554764\n",
      "\n",
      "The classification loss after processing this batch is:  0.07278697192668915\n",
      "The representation loss after processing this batch is:  0.0021128058433532715\n",
      "\n",
      "The classification loss after processing this batch is:  0.1071377620100975\n",
      "The representation loss after processing this batch is:  0.0023677758872509003\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1021161749958992\n",
      "The representation loss after processing this batch is:  0.0024444684386253357\n",
      "\n",
      "The classification loss after processing this batch is:  0.1407107710838318\n",
      "The representation loss after processing this batch is:  0.0023122578859329224\n",
      "\n",
      "The classification loss after processing this batch is:  0.12022104114294052\n",
      "The representation loss after processing this batch is:  0.002626940608024597\n",
      "\n",
      "The classification loss after processing this batch is:  0.2006099820137024\n",
      "The representation loss after processing this batch is:  0.0024799779057502747\n",
      "\n",
      "The classification loss after processing this batch is:  0.09645970910787582\n",
      "The representation loss after processing this batch is:  0.002840176224708557\n",
      "\n",
      "The classification loss after processing this batch is:  0.10181673616170883\n",
      "The representation loss after processing this batch is:  0.0022103115916252136\n",
      "\n",
      "The classification loss after processing this batch is:  0.09990449249744415\n",
      "The representation loss after processing this batch is:  0.002598866820335388\n",
      "\n",
      "The classification loss after processing this batch is:  0.2267412692308426\n",
      "The representation loss after processing this batch is:  0.002879135310649872\n",
      "\n",
      "The classification loss after processing this batch is:  0.24733544886112213\n",
      "The representation loss after processing this batch is:  0.0027245432138442993\n",
      "\n",
      "The classification loss after processing this batch is:  0.04186487942934036\n",
      "The representation loss after processing this batch is:  0.002216629683971405\n",
      "\n",
      "The classification loss after processing this batch is:  0.050199784338474274\n",
      "The representation loss after processing this batch is:  0.0027986690402030945\n",
      "\n",
      "The classification loss after processing this batch is:  0.21202205121517181\n",
      "The representation loss after processing this batch is:  0.0026421882212162018\n",
      "\n",
      "The classification loss after processing this batch is:  0.07305831462144852\n",
      "The representation loss after processing this batch is:  0.002840295433998108\n",
      "\n",
      "The classification loss after processing this batch is:  0.06835246831178665\n",
      "The representation loss after processing this batch is:  0.0024344846606254578\n",
      "\n",
      "The classification loss after processing this batch is:  0.12260738760232925\n",
      "The representation loss after processing this batch is:  0.0023582279682159424\n",
      "\n",
      "The classification loss after processing this batch is:  0.08849214017391205\n",
      "The representation loss after processing this batch is:  0.002771437168121338\n",
      "\n",
      "The classification loss after processing this batch is:  0.22961218655109406\n",
      "The representation loss after processing this batch is:  0.0029442012310028076\n",
      "\n",
      "The classification loss after processing this batch is:  0.13065849244594574\n",
      "The representation loss after processing this batch is:  0.0028873756527900696\n",
      "\n",
      "The classification loss after processing this batch is:  0.13718952238559723\n",
      "The representation loss after processing this batch is:  0.0031252503395080566\n",
      "\n",
      "The classification loss after processing this batch is:  0.07663512974977493\n",
      "The representation loss after processing this batch is:  0.002123568207025528\n",
      "\n",
      "The classification loss after processing this batch is:  0.18472208082675934\n",
      "The representation loss after processing this batch is:  0.002414550632238388\n",
      "\n",
      "The classification loss after processing this batch is:  0.04539338871836662\n",
      "The representation loss after processing this batch is:  0.002389281988143921\n",
      "\n",
      "The classification loss after processing this batch is:  0.0548415444791317\n",
      "The representation loss after processing this batch is:  0.002635575830936432\n",
      "\n",
      "The classification loss after processing this batch is:  0.1067085936665535\n",
      "The representation loss after processing this batch is:  0.002385146915912628\n",
      "\n",
      "The classification loss after processing this batch is:  0.05371847376227379\n",
      "The representation loss after processing this batch is:  0.002450399100780487\n",
      "\n",
      "The classification loss after processing this batch is:  0.07223735004663467\n",
      "The representation loss after processing this batch is:  0.0027824342250823975\n",
      "\n",
      "The classification loss after processing this batch is:  0.05408038944005966\n",
      "The representation loss after processing this batch is:  0.0026735030114650726\n",
      "\n",
      "The classification loss after processing this batch is:  0.08478201925754547\n",
      "The representation loss after processing this batch is:  0.0025448761880397797\n",
      "\n",
      "The classification loss after processing this batch is:  0.10651744902133942\n",
      "The representation loss after processing this batch is:  0.00260968878865242\n",
      "\n",
      "The classification loss after processing this batch is:  0.13316188752651215\n",
      "The representation loss after processing this batch is:  0.0027156248688697815\n",
      "\n",
      "The classification loss after processing this batch is:  0.1769900768995285\n",
      "The representation loss after processing this batch is:  0.0023293234407901764\n",
      "\n",
      "The classification loss after processing this batch is:  0.1430809050798416\n",
      "The representation loss after processing this batch is:  0.0030512064695358276\n",
      "\n",
      "The classification loss after processing this batch is:  0.20863956212997437\n",
      "The representation loss after processing this batch is:  0.0025920309126377106\n",
      "\n",
      "The classification loss after processing this batch is:  0.0496893972158432\n",
      "The representation loss after processing this batch is:  0.0023748502135276794\n",
      "\n",
      "The classification loss after processing this batch is:  0.15963606536388397\n",
      "The representation loss after processing this batch is:  0.002480901777744293\n",
      "\n",
      "The classification loss after processing this batch is:  0.25873807072639465\n",
      "The representation loss after processing this batch is:  0.0025937333703041077\n",
      "\n",
      "The classification loss after processing this batch is:  0.11567376554012299\n",
      "The representation loss after processing this batch is:  0.0021777376532554626\n",
      "\n",
      "The classification loss after processing this batch is:  0.16146892309188843\n",
      "The representation loss after processing this batch is:  0.002493392676115036\n",
      "\n",
      "The classification loss after processing this batch is:  0.15374872088432312\n",
      "The representation loss after processing this batch is:  0.002431824803352356\n",
      "\n",
      "The classification loss after processing this batch is:  0.15674641728401184\n",
      "The representation loss after processing this batch is:  0.002451222389936447\n",
      "\n",
      "The classification loss after processing this batch is:  0.1211332157254219\n",
      "The representation loss after processing this batch is:  0.0026385411620140076\n",
      "\n",
      "The classification loss after processing this batch is:  0.08643381297588348\n",
      "The representation loss after processing this batch is:  0.002406880259513855\n",
      "\n",
      "The classification loss after processing this batch is:  0.09508850425481796\n",
      "The representation loss after processing this batch is:  0.0025411993265151978\n",
      "\n",
      "The classification loss after processing this batch is:  0.05107890069484711\n",
      "The representation loss after processing this batch is:  0.0025753676891326904\n",
      "\n",
      "The classification loss after processing this batch is:  0.04317737743258476\n",
      "The representation loss after processing this batch is:  0.002325311303138733\n",
      "\n",
      "The classification loss after processing this batch is:  0.10476765036582947\n",
      "The representation loss after processing this batch is:  0.0028299465775489807\n",
      "\n",
      "The classification loss after processing this batch is:  0.051869310438632965\n",
      "The representation loss after processing this batch is:  0.0026253387331962585\n",
      "\n",
      "The classification loss after processing this batch is:  0.2193576842546463\n",
      "The representation loss after processing this batch is:  0.0031530559062957764\n",
      "\n",
      "The classification loss after processing this batch is:  0.13444095849990845\n",
      "The representation loss after processing this batch is:  0.002377822995185852\n",
      "\n",
      "The classification loss after processing this batch is:  0.177727609872818\n",
      "The representation loss after processing this batch is:  0.002831578254699707\n",
      "\n",
      "The classification loss after processing this batch is:  0.3211521804332733\n",
      "The representation loss after processing this batch is:  0.002339199185371399\n",
      "\n",
      "The classification loss after processing this batch is:  0.14082010090351105\n",
      "The representation loss after processing this batch is:  0.002518974244594574\n",
      "\n",
      "The classification loss after processing this batch is:  0.042758990079164505\n",
      "The representation loss after processing this batch is:  0.002415984869003296\n",
      "\n",
      "The classification loss after processing this batch is:  0.06745504587888718\n",
      "The representation loss after processing this batch is:  0.0027632936835289\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.0689738541841507\n",
      "The representation loss after processing this batch is:  0.0027690082788467407\n",
      "\n",
      "The classification loss after processing this batch is:  0.08048500120639801\n",
      "The representation loss after processing this batch is:  0.0026904121041297913\n",
      "\n",
      "The classification loss after processing this batch is:  0.09025748074054718\n",
      "The representation loss after processing this batch is:  0.0022275224328041077\n",
      "\n",
      "The classification loss after processing this batch is:  0.21558167040348053\n",
      "The representation loss after processing this batch is:  0.0022215694189071655\n",
      "\n",
      "The classification loss after processing this batch is:  0.18124131858348846\n",
      "The representation loss after processing this batch is:  0.0023824572563171387\n",
      "\n",
      "The classification loss after processing this batch is:  0.14832338690757751\n",
      "The representation loss after processing this batch is:  0.0028779730200767517\n",
      "\n",
      "The classification loss after processing this batch is:  0.215082585811615\n",
      "The representation loss after processing this batch is:  0.0028451010584831238\n",
      "\n",
      "The classification loss after processing this batch is:  0.08747290819883347\n",
      "The representation loss after processing this batch is:  0.0024708211421966553\n",
      "\n",
      "The classification loss after processing this batch is:  0.11086661368608475\n",
      "The representation loss after processing this batch is:  0.0025322064757347107\n",
      "\n",
      "The classification loss after processing this batch is:  0.1868334710597992\n",
      "The representation loss after processing this batch is:  0.0023771561682224274\n",
      "\n",
      "The classification loss after processing this batch is:  0.10259189456701279\n",
      "The representation loss after processing this batch is:  0.0028598159551620483\n",
      "\n",
      "The classification loss after processing this batch is:  0.1446256786584854\n",
      "The representation loss after processing this batch is:  0.003398619592189789\n",
      "\n",
      "The classification loss after processing this batch is:  0.07157920300960541\n",
      "The representation loss after processing this batch is:  0.0028125494718551636\n",
      "\n",
      "The classification loss after processing this batch is:  0.14360761642456055\n",
      "The representation loss after processing this batch is:  0.0032110363245010376\n",
      "\n",
      "The classification loss after processing this batch is:  0.16569805145263672\n",
      "The representation loss after processing this batch is:  0.0028959326446056366\n",
      "\n",
      "The classification loss after processing this batch is:  0.09760351479053497\n",
      "The representation loss after processing this batch is:  0.0027298107743263245\n",
      "\n",
      "The classification loss after processing this batch is:  0.14120306074619293\n",
      "The representation loss after processing this batch is:  0.00302751362323761\n",
      "\n",
      "The classification loss after processing this batch is:  0.19862796366214752\n",
      "The representation loss after processing this batch is:  0.0021603181958198547\n",
      "\n",
      "The classification loss after processing this batch is:  0.10830289870500565\n",
      "The representation loss after processing this batch is:  0.0025046542286872864\n",
      "\n",
      "The classification loss after processing this batch is:  0.14489229023456573\n",
      "The representation loss after processing this batch is:  0.002487972378730774\n",
      "\n",
      "The classification loss after processing this batch is:  0.07072917371988297\n",
      "The representation loss after processing this batch is:  0.0030632317066192627\n",
      "\n",
      "The classification loss after processing this batch is:  0.025910155847668648\n",
      "The representation loss after processing this batch is:  0.002836950123310089\n",
      "\n",
      "The classification loss after processing this batch is:  0.10235115885734558\n",
      "The representation loss after processing this batch is:  0.0027461647987365723\n",
      "\n",
      "The classification loss after processing this batch is:  0.07005848735570908\n",
      "The representation loss after processing this batch is:  0.0027999207377433777\n",
      "\n",
      "The classification loss after processing this batch is:  0.25142186880111694\n",
      "The representation loss after processing this batch is:  0.0023614242672920227\n",
      "\n",
      "The classification loss after processing this batch is:  0.048689305782318115\n",
      "The representation loss after processing this batch is:  0.002596057951450348\n",
      "\n",
      "The classification loss after processing this batch is:  0.09323610365390778\n",
      "The representation loss after processing this batch is:  0.00243387371301651\n",
      "\n",
      "The classification loss after processing this batch is:  0.13357962667942047\n",
      "The representation loss after processing this batch is:  0.002565935254096985\n",
      "\n",
      "The classification loss after processing this batch is:  0.10275378823280334\n",
      "The representation loss after processing this batch is:  0.0025309547781944275\n",
      "\n",
      "The classification loss after processing this batch is:  0.11943305283784866\n",
      "The representation loss after processing this batch is:  0.002620302140712738\n",
      "\n",
      "The classification loss after processing this batch is:  0.05227527394890785\n",
      "The representation loss after processing this batch is:  0.0025548338890075684\n",
      "\n",
      "The classification loss after processing this batch is:  0.04612123221158981\n",
      "The representation loss after processing this batch is:  0.002545710653066635\n",
      "\n",
      "The classification loss after processing this batch is:  0.06944084912538528\n",
      "The representation loss after processing this batch is:  0.0026095062494277954\n",
      "\n",
      "The classification loss after processing this batch is:  0.16448625922203064\n",
      "The representation loss after processing this batch is:  0.0031181350350379944\n",
      "\n",
      "The classification loss after processing this batch is:  0.20449431240558624\n",
      "The representation loss after processing this batch is:  0.00252678245306015\n",
      "\n",
      "The classification loss after processing this batch is:  0.12118799239397049\n",
      "The representation loss after processing this batch is:  0.0021132230758666992\n",
      "\n",
      "The classification loss after processing this batch is:  0.1472288817167282\n",
      "The representation loss after processing this batch is:  0.002605527639389038\n",
      "\n",
      "The classification loss after processing this batch is:  0.22051657736301422\n",
      "The representation loss after processing this batch is:  0.0023177266120910645\n",
      "\n",
      "The classification loss after processing this batch is:  0.10064694285392761\n",
      "The representation loss after processing this batch is:  0.0027035102248191833\n",
      "\n",
      "The classification loss after processing this batch is:  0.21493910253047943\n",
      "The representation loss after processing this batch is:  0.002622932195663452\n",
      "\n",
      "The classification loss after processing this batch is:  0.09101460129022598\n",
      "The representation loss after processing this batch is:  0.002703920006752014\n",
      "\n",
      "The classification loss after processing this batch is:  0.07009145617485046\n",
      "The representation loss after processing this batch is:  0.0024124085903167725\n",
      "\n",
      "The classification loss after processing this batch is:  0.05944786220788956\n",
      "The representation loss after processing this batch is:  0.002384096384048462\n",
      "\n",
      "The classification loss after processing this batch is:  0.07403311878442764\n",
      "The representation loss after processing this batch is:  0.0025024861097335815\n",
      "\n",
      "The classification loss after processing this batch is:  0.25991520285606384\n",
      "The representation loss after processing this batch is:  0.0026425644755363464\n",
      "\n",
      "The classification loss after processing this batch is:  0.07888062298297882\n",
      "The representation loss after processing this batch is:  0.0024708211421966553\n",
      "\n",
      "The classification loss after processing this batch is:  0.1398954540491104\n",
      "The representation loss after processing this batch is:  0.0029038935899734497\n",
      "\n",
      "The classification loss after processing this batch is:  0.1268380582332611\n",
      "The representation loss after processing this batch is:  0.0028847455978393555\n",
      "\n",
      "The classification loss after processing this batch is:  0.10774507373571396\n",
      "The representation loss after processing this batch is:  0.0026679933071136475\n",
      "\n",
      "The classification loss after processing this batch is:  0.07320848107337952\n",
      "The representation loss after processing this batch is:  0.0026136115193367004\n",
      "\n",
      "The classification loss after processing this batch is:  0.16350357234477997\n",
      "The representation loss after processing this batch is:  0.0023993104696273804\n",
      "\n",
      "The classification loss after processing this batch is:  0.19056564569473267\n",
      "The representation loss after processing this batch is:  0.0023877806961536407\n",
      "\n",
      "The classification loss after processing this batch is:  0.1643785983324051\n",
      "The representation loss after processing this batch is:  0.002929888665676117\n",
      "\n",
      "The classification loss after processing this batch is:  0.06896839290857315\n",
      "The representation loss after processing this batch is:  0.0025210045278072357\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.3031516373157501\n",
      "The representation loss after processing this batch is:  0.002254597842693329\n",
      "\n",
      "The classification loss after processing this batch is:  0.07181157916784286\n",
      "The representation loss after processing this batch is:  0.002273283898830414\n",
      "\n",
      "The classification loss after processing this batch is:  0.07750184834003448\n",
      "The representation loss after processing this batch is:  0.002297591418027878\n",
      "\n",
      "The classification loss after processing this batch is:  0.12167689204216003\n",
      "The representation loss after processing this batch is:  0.00281631201505661\n",
      "\n",
      "The classification loss after processing this batch is:  0.08535005152225494\n",
      "The representation loss after processing this batch is:  0.0024525299668312073\n",
      "\n",
      "The classification loss after processing this batch is:  0.09186306595802307\n",
      "The representation loss after processing this batch is:  0.002481609582901001\n",
      "\n",
      "The classification loss after processing this batch is:  0.0799754336476326\n",
      "The representation loss after processing this batch is:  0.0027791112661361694\n",
      "\n",
      "The classification loss after processing this batch is:  0.1718224436044693\n",
      "The representation loss after processing this batch is:  0.0025489740073680878\n",
      "\n",
      "The classification loss after processing this batch is:  0.18439875543117523\n",
      "The representation loss after processing this batch is:  0.002528805285692215\n",
      "\n",
      "The classification loss after processing this batch is:  0.15491285920143127\n",
      "The representation loss after processing this batch is:  0.0024433284997940063\n",
      "\n",
      "The classification loss after processing this batch is:  0.11501619219779968\n",
      "The representation loss after processing this batch is:  0.0027947165071964264\n",
      "\n",
      "The classification loss after processing this batch is:  0.12360044568777084\n",
      "The representation loss after processing this batch is:  0.003210492432117462\n",
      "\n",
      "The classification loss after processing this batch is:  0.15087562799453735\n",
      "The representation loss after processing this batch is:  0.002294301986694336\n",
      "\n",
      "The classification loss after processing this batch is:  0.1296161562204361\n",
      "The representation loss after processing this batch is:  0.0023712925612926483\n",
      "\n",
      "The classification loss after processing this batch is:  0.022632082924246788\n",
      "The representation loss after processing this batch is:  0.0026838481426239014\n",
      "\n",
      "The classification loss after processing this batch is:  0.10242932289838791\n",
      "The representation loss after processing this batch is:  0.002306845039129257\n",
      "\n",
      "The classification loss after processing this batch is:  0.23437601327896118\n",
      "The representation loss after processing this batch is:  0.0025664344429969788\n",
      "\n",
      "The classification loss after processing this batch is:  0.2919814884662628\n",
      "The representation loss after processing this batch is:  0.002653151750564575\n",
      "\n",
      "The classification loss after processing this batch is:  0.22976884245872498\n",
      "The representation loss after processing this batch is:  0.002350989729166031\n",
      "\n",
      "The classification loss after processing this batch is:  0.15990310907363892\n",
      "The representation loss after processing this batch is:  0.002196364104747772\n",
      "\n",
      "The classification loss after processing this batch is:  0.04459698125720024\n",
      "The representation loss after processing this batch is:  0.0024227723479270935\n",
      "\n",
      "The classification loss after processing this batch is:  0.10614683479070663\n",
      "The representation loss after processing this batch is:  0.0023030638694763184\n",
      "\n",
      "The classification loss after processing this batch is:  0.10749994218349457\n",
      "The representation loss after processing this batch is:  0.0028640329837799072\n",
      "\n",
      "The classification loss after processing this batch is:  0.17247089743614197\n",
      "The representation loss after processing this batch is:  0.002837933599948883\n",
      "\n",
      "The classification loss after processing this batch is:  0.14752139151096344\n",
      "The representation loss after processing this batch is:  0.002753816545009613\n",
      "\n",
      "The classification loss after processing this batch is:  0.13973741233348846\n",
      "The representation loss after processing this batch is:  0.002900063991546631\n",
      "\n",
      "The classification loss after processing this batch is:  0.09069795161485672\n",
      "The representation loss after processing this batch is:  0.0025120750069618225\n",
      "\n",
      "The classification loss after processing this batch is:  0.10357822477817535\n",
      "The representation loss after processing this batch is:  0.002532489597797394\n",
      "\n",
      "The classification loss after processing this batch is:  0.16452687978744507\n",
      "The representation loss after processing this batch is:  0.0027564987540245056\n",
      "\n",
      "The classification loss after processing this batch is:  0.15251360833644867\n",
      "The representation loss after processing this batch is:  0.00257062166929245\n",
      "\n",
      "The classification loss after processing this batch is:  0.1002187728881836\n",
      "The representation loss after processing this batch is:  0.0021526068449020386\n",
      "\n",
      "The classification loss after processing this batch is:  0.23672987520694733\n",
      "The representation loss after processing this batch is:  0.0031981095671653748\n",
      "\n",
      "The classification loss after processing this batch is:  0.30687108635902405\n",
      "The representation loss after processing this batch is:  0.002777665853500366\n",
      "\n",
      "The classification loss after processing this batch is:  0.16126708686351776\n",
      "The representation loss after processing this batch is:  0.0028829649090766907\n",
      "\n",
      "The classification loss after processing this batch is:  0.11515109986066818\n",
      "The representation loss after processing this batch is:  0.0026782378554344177\n",
      "\n",
      "The classification loss after processing this batch is:  0.08863480389118195\n",
      "The representation loss after processing this batch is:  0.002957776188850403\n",
      "\n",
      "The classification loss after processing this batch is:  0.03922398015856743\n",
      "The representation loss after processing this batch is:  0.00258452445268631\n",
      "\n",
      "The classification loss after processing this batch is:  0.18051685392856598\n",
      "The representation loss after processing this batch is:  0.0024369582533836365\n",
      "\n",
      "The classification loss after processing this batch is:  0.1527044028043747\n",
      "The representation loss after processing this batch is:  0.00283205509185791\n",
      "\n",
      "The classification loss after processing this batch is:  0.10039624571800232\n",
      "The representation loss after processing this batch is:  0.003058619797229767\n",
      "\n",
      "The classification loss after processing this batch is:  0.23543936014175415\n",
      "The representation loss after processing this batch is:  0.0025635063648223877\n",
      "\n",
      "The classification loss after processing this batch is:  0.05429913476109505\n",
      "The representation loss after processing this batch is:  0.002558380365371704\n",
      "\n",
      "The classification loss after processing this batch is:  0.059310492128133774\n",
      "The representation loss after processing this batch is:  0.002802550792694092\n",
      "\n",
      "The classification loss after processing this batch is:  0.09194337576627731\n",
      "The representation loss after processing this batch is:  0.002484552562236786\n",
      "\n",
      "The classification loss after processing this batch is:  0.11233950406312943\n",
      "The representation loss after processing this batch is:  0.0024737976491451263\n",
      "\n",
      "The classification loss after processing this batch is:  0.1447218507528305\n",
      "The representation loss after processing this batch is:  0.002890661358833313\n",
      "\n",
      "The classification loss after processing this batch is:  0.11666279286146164\n",
      "The representation loss after processing this batch is:  0.0025406479835510254\n",
      "\n",
      "The classification loss after processing this batch is:  0.10021944344043732\n",
      "The representation loss after processing this batch is:  0.002594582736492157\n",
      "\n",
      "The classification loss after processing this batch is:  0.05488451570272446\n",
      "The representation loss after processing this batch is:  0.0026273950934410095\n",
      "\n",
      "The classification loss after processing this batch is:  0.04971446841955185\n",
      "The representation loss after processing this batch is:  0.0024940669536590576\n",
      "\n",
      "The classification loss after processing this batch is:  0.08245746046304703\n",
      "The representation loss after processing this batch is:  0.002771615982055664\n",
      "\n",
      "The classification loss after processing this batch is:  0.04707813262939453\n",
      "The representation loss after processing this batch is:  0.0026794373989105225\n",
      "\n",
      "The classification loss after processing this batch is:  0.09294147789478302\n",
      "The representation loss after processing this batch is:  0.0022381730377674103\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.16098693013191223\n",
      "The representation loss after processing this batch is:  0.0024608448147773743\n",
      "\n",
      "The classification loss after processing this batch is:  0.18415918946266174\n",
      "The representation loss after processing this batch is:  0.0028454065322875977\n",
      "\n",
      "The classification loss after processing this batch is:  0.041954442858695984\n",
      "The representation loss after processing this batch is:  0.0021129511296749115\n",
      "\n",
      "The classification loss after processing this batch is:  0.06072521209716797\n",
      "The representation loss after processing this batch is:  0.0023734942078590393\n",
      "\n",
      "The classification loss after processing this batch is:  0.1079389750957489\n",
      "The representation loss after processing this batch is:  0.0029060617089271545\n",
      "\n",
      "The classification loss after processing this batch is:  0.15324638783931732\n",
      "The representation loss after processing this batch is:  0.0024866722524166107\n",
      "\n",
      "The classification loss after processing this batch is:  0.05524330958724022\n",
      "The representation loss after processing this batch is:  0.0028863027691841125\n",
      "\n",
      "The classification loss after processing this batch is:  0.17082637548446655\n",
      "The representation loss after processing this batch is:  0.0031859278678894043\n",
      "\n",
      "The classification loss after processing this batch is:  0.17505811154842377\n",
      "The representation loss after processing this batch is:  0.002565227448940277\n",
      "\n",
      "The classification loss after processing this batch is:  0.20333115756511688\n",
      "The representation loss after processing this batch is:  0.0026793405413627625\n",
      "\n",
      "The classification loss after processing this batch is:  0.10592673718929291\n",
      "The representation loss after processing this batch is:  0.0025209560990333557\n",
      "\n",
      "The classification loss after processing this batch is:  0.0690513402223587\n",
      "The representation loss after processing this batch is:  0.0025767311453819275\n",
      "\n",
      "The classification loss after processing this batch is:  0.09564367681741714\n",
      "The representation loss after processing this batch is:  0.0024697184562683105\n",
      "\n",
      "The classification loss after processing this batch is:  0.15026164054870605\n",
      "The representation loss after processing this batch is:  0.0025831013917922974\n",
      "\n",
      "The classification loss after processing this batch is:  0.06701571494340897\n",
      "The representation loss after processing this batch is:  0.002548426389694214\n",
      "\n",
      "The classification loss after processing this batch is:  0.03172202780842781\n",
      "The representation loss after processing this batch is:  0.002302400767803192\n",
      "\n",
      "The classification loss after processing this batch is:  0.21641011536121368\n",
      "The representation loss after processing this batch is:  0.002617865800857544\n",
      "\n",
      "The classification loss after processing this batch is:  0.19816462695598602\n",
      "The representation loss after processing this batch is:  0.002469167113304138\n",
      "\n",
      "The classification loss after processing this batch is:  0.08967392146587372\n",
      "The representation loss after processing this batch is:  0.002228356897830963\n",
      "\n",
      "The classification loss after processing this batch is:  0.24931710958480835\n",
      "The representation loss after processing this batch is:  0.0023985207080841064\n",
      "\n",
      "The classification loss after processing this batch is:  0.22741477191448212\n",
      "The representation loss after processing this batch is:  0.002586930990219116\n",
      "\n",
      "The classification loss after processing this batch is:  0.28674015402793884\n",
      "The representation loss after processing this batch is:  0.0025260448455810547\n",
      "\n",
      "The classification loss after processing this batch is:  0.14480753242969513\n",
      "The representation loss after processing this batch is:  0.002460755407810211\n",
      "\n",
      "The classification loss after processing this batch is:  0.0842723399400711\n",
      "The representation loss after processing this batch is:  0.002363137900829315\n",
      "\n",
      "The classification loss after processing this batch is:  0.15557648241519928\n",
      "The representation loss after processing this batch is:  0.0025832578539848328\n",
      "\n",
      "The classification loss after processing this batch is:  0.08242204040288925\n",
      "The representation loss after processing this batch is:  0.002618744969367981\n",
      "\n",
      "The classification loss after processing this batch is:  0.06794743984937668\n",
      "The representation loss after processing this batch is:  0.0025892257690429688\n",
      "\n",
      "The classification loss after processing this batch is:  0.07416918128728867\n",
      "The representation loss after processing this batch is:  0.002373676747083664\n",
      "\n",
      "The classification loss after processing this batch is:  0.05484914034605026\n",
      "The representation loss after processing this batch is:  0.002416566014289856\n",
      "\n",
      "The classification loss after processing this batch is:  0.02870281971991062\n",
      "The representation loss after processing this batch is:  0.0028981342911720276\n",
      "\n",
      "The classification loss after processing this batch is:  0.11981458216905594\n",
      "The representation loss after processing this batch is:  0.002681031823158264\n",
      "\n",
      "The classification loss after processing this batch is:  0.1593790054321289\n",
      "The representation loss after processing this batch is:  0.0023804381489753723\n",
      "\n",
      "The classification loss after processing this batch is:  0.060592684894800186\n",
      "The representation loss after processing this batch is:  0.002806432545185089\n",
      "\n",
      "The classification loss after processing this batch is:  0.0858021005988121\n",
      "The representation loss after processing this batch is:  0.002364691346883774\n",
      "\n",
      "The classification loss after processing this batch is:  0.10817258805036545\n",
      "The representation loss after processing this batch is:  0.002488069236278534\n",
      "\n",
      "The classification loss after processing this batch is:  0.029497090727090836\n",
      "The representation loss after processing this batch is:  0.0024686530232429504\n",
      "\n",
      "The classification loss after processing this batch is:  0.18560227751731873\n",
      "The representation loss after processing this batch is:  0.0025195032358169556\n",
      "\n",
      "The classification loss after processing this batch is:  0.08366362005472183\n",
      "The representation loss after processing this batch is:  0.002390265464782715\n",
      "\n",
      "The classification loss after processing this batch is:  0.2499748021364212\n",
      "The representation loss after processing this batch is:  0.0024855956435203552\n",
      "\n",
      "The classification loss after processing this batch is:  0.12581446766853333\n",
      "The representation loss after processing this batch is:  0.0025207549333572388\n",
      "\n",
      "The classification loss after processing this batch is:  0.13975492119789124\n",
      "The representation loss after processing this batch is:  0.0023823902010917664\n",
      "\n",
      "The classification loss after processing this batch is:  0.030430443584918976\n",
      "The representation loss after processing this batch is:  0.0026426613330841064\n",
      "\n",
      "The classification loss after processing this batch is:  0.04436987265944481\n",
      "The representation loss after processing this batch is:  0.0022544413805007935\n",
      "\n",
      "The classification loss after processing this batch is:  0.15630511939525604\n",
      "The representation loss after processing this batch is:  0.002342972904443741\n",
      "\n",
      "The classification loss after processing this batch is:  0.06435377895832062\n",
      "The representation loss after processing this batch is:  0.002772390842437744\n",
      "\n",
      "The classification loss after processing this batch is:  0.11597598344087601\n",
      "The representation loss after processing this batch is:  0.002575390040874481\n",
      "\n",
      "The classification loss after processing this batch is:  0.09114880114793777\n",
      "The representation loss after processing this batch is:  0.002675563097000122\n",
      "\n",
      "The classification loss after processing this batch is:  0.08013897389173508\n",
      "The representation loss after processing this batch is:  0.0028846338391304016\n",
      "\n",
      "The classification loss after processing this batch is:  0.14862030744552612\n",
      "The representation loss after processing this batch is:  0.0024337172508239746\n",
      "\n",
      "The classification loss after processing this batch is:  0.06368985027074814\n",
      "The representation loss after processing this batch is:  0.002713702619075775\n",
      "\n",
      "The classification loss after processing this batch is:  0.12887342274188995\n",
      "The representation loss after processing this batch is:  0.0027754083275794983\n",
      "\n",
      "The classification loss after processing this batch is:  0.21032924950122833\n",
      "The representation loss after processing this batch is:  0.002576291561126709\n",
      "\n",
      "The classification loss after processing this batch is:  0.15556582808494568\n",
      "The representation loss after processing this batch is:  0.0027356892824172974\n",
      "\n",
      "The classification loss after processing this batch is:  0.20639720559120178\n",
      "The representation loss after processing this batch is:  0.002377912402153015\n",
      "\n",
      "The classification loss after processing this batch is:  0.18580372631549835\n",
      "The representation loss after processing this batch is:  0.002610214054584503\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1154407411813736\n",
      "The representation loss after processing this batch is:  0.0022498294711112976\n",
      "\n",
      "The classification loss after processing this batch is:  0.08489679545164108\n",
      "The representation loss after processing this batch is:  0.002460181713104248\n",
      "\n",
      "The classification loss after processing this batch is:  0.060858823359012604\n",
      "The representation loss after processing this batch is:  0.0023711472749710083\n",
      "\n",
      "The classification loss after processing this batch is:  0.09228353947401047\n",
      "The representation loss after processing this batch is:  0.0025528520345687866\n",
      "\n",
      "The classification loss after processing this batch is:  0.047769881784915924\n",
      "The representation loss after processing this batch is:  0.0026332810521125793\n",
      "\n",
      "The classification loss after processing this batch is:  0.09562316536903381\n",
      "The representation loss after processing this batch is:  0.0021174997091293335\n",
      "\n",
      "The classification loss after processing this batch is:  0.09954376518726349\n",
      "The representation loss after processing this batch is:  0.0024111419916152954\n",
      "\n",
      "The classification loss after processing this batch is:  0.09437151253223419\n",
      "The representation loss after processing this batch is:  0.002862885594367981\n",
      "\n",
      "The classification loss after processing this batch is:  0.07836220413446426\n",
      "The representation loss after processing this batch is:  0.002421066164970398\n",
      "\n",
      "The classification loss after processing this batch is:  0.1378791183233261\n",
      "The representation loss after processing this batch is:  0.0022214874625205994\n",
      "\n",
      "The classification loss after processing this batch is:  0.06636052578687668\n",
      "The representation loss after processing this batch is:  0.002578727900981903\n",
      "\n",
      "The classification loss after processing this batch is:  0.1330239176750183\n",
      "The representation loss after processing this batch is:  0.002513997256755829\n",
      "\n",
      "The classification loss after processing this batch is:  0.13238710165023804\n",
      "The representation loss after processing this batch is:  0.002470053732395172\n",
      "\n",
      "The classification loss after processing this batch is:  0.10236536711454391\n",
      "The representation loss after processing this batch is:  0.002682790160179138\n",
      "\n",
      "The classification loss after processing this batch is:  0.0656423345208168\n",
      "The representation loss after processing this batch is:  0.0027782246470451355\n",
      "\n",
      "The classification loss after processing this batch is:  0.18288516998291016\n",
      "The representation loss after processing this batch is:  0.002485118806362152\n",
      "\n",
      "The classification loss after processing this batch is:  0.0648215189576149\n",
      "The representation loss after processing this batch is:  0.0025572627782821655\n",
      "\n",
      "The classification loss after processing this batch is:  0.06360610574483871\n",
      "The representation loss after processing this batch is:  0.0025274232029914856\n",
      "\n",
      "The classification loss after processing this batch is:  0.11169729381799698\n",
      "The representation loss after processing this batch is:  0.0024898648262023926\n",
      "\n",
      "The classification loss after processing this batch is:  0.05127710476517677\n",
      "The representation loss after processing this batch is:  0.0027250200510025024\n",
      "\n",
      "The classification loss after processing this batch is:  0.11826891452074051\n",
      "The representation loss after processing this batch is:  0.0023289360105991364\n",
      "\n",
      "The classification loss after processing this batch is:  0.15866824984550476\n",
      "The representation loss after processing this batch is:  0.002695266157388687\n",
      "\n",
      "The classification loss after processing this batch is:  0.08180726319551468\n",
      "The representation loss after processing this batch is:  0.0027287453413009644\n",
      "\n",
      "The classification loss after processing this batch is:  0.08474672585725784\n",
      "The representation loss after processing this batch is:  0.0029160529375076294\n",
      "\n",
      "The classification loss after processing this batch is:  0.08186515420675278\n",
      "The representation loss after processing this batch is:  0.002547040581703186\n",
      "\n",
      "The classification loss after processing this batch is:  0.23623409867286682\n",
      "The representation loss after processing this batch is:  0.0026658475399017334\n",
      "\n",
      "The classification loss after processing this batch is:  0.046688683331012726\n",
      "The representation loss after processing this batch is:  0.0025296732783317566\n",
      "\n",
      "The classification loss after processing this batch is:  0.08242230117321014\n",
      "The representation loss after processing this batch is:  0.002712465822696686\n",
      "\n",
      "The classification loss after processing this batch is:  0.16601170599460602\n",
      "The representation loss after processing this batch is:  0.0023173168301582336\n",
      "\n",
      "The classification loss after processing this batch is:  0.3087485730648041\n",
      "The representation loss after processing this batch is:  0.0027112066745758057\n",
      "\n",
      "The classification loss after processing this batch is:  0.08963596820831299\n",
      "The representation loss after processing this batch is:  0.0023856759071350098\n",
      "\n",
      "The classification loss after processing this batch is:  0.10543660074472427\n",
      "The representation loss after processing this batch is:  0.0024202950298786163\n",
      "\n",
      "The classification loss after processing this batch is:  0.08159521222114563\n",
      "The representation loss after processing this batch is:  0.002534620463848114\n",
      "\n",
      "The classification loss after processing this batch is:  0.03433750569820404\n",
      "The representation loss after processing this batch is:  0.002479173243045807\n",
      "\n",
      "The classification loss after processing this batch is:  0.12542448937892914\n",
      "The representation loss after processing this batch is:  0.002984374761581421\n",
      "\n",
      "The classification loss after processing this batch is:  0.08393821120262146\n",
      "The representation loss after processing this batch is:  0.0033098384737968445\n",
      "\n",
      "The classification loss after processing this batch is:  0.05072376877069473\n",
      "The representation loss after processing this batch is:  0.0026803500950336456\n",
      "\n",
      "The classification loss after processing this batch is:  0.06809832155704498\n",
      "The representation loss after processing this batch is:  0.002281390130519867\n",
      "\n",
      "The classification loss after processing this batch is:  0.1582820564508438\n",
      "The representation loss after processing this batch is:  0.00236603245139122\n",
      "\n",
      "The classification loss after processing this batch is:  0.1272396445274353\n",
      "The representation loss after processing this batch is:  0.0024934932589530945\n",
      "\n",
      "The classification loss after processing this batch is:  0.07969073951244354\n",
      "The representation loss after processing this batch is:  0.002239428460597992\n",
      "\n",
      "The classification loss after processing this batch is:  0.07385500520467758\n",
      "The representation loss after processing this batch is:  0.0026822611689567566\n",
      "\n",
      "The classification loss after processing this batch is:  0.19868172705173492\n",
      "The representation loss after processing this batch is:  0.0023466497659683228\n",
      "\n",
      "The classification loss after processing this batch is:  0.14724430441856384\n",
      "The representation loss after processing this batch is:  0.0025341957807540894\n",
      "\n",
      "The classification loss after processing this batch is:  0.19400805234909058\n",
      "The representation loss after processing this batch is:  0.002248696982860565\n",
      "\n",
      "The classification loss after processing this batch is:  0.12945538759231567\n",
      "The representation loss after processing this batch is:  0.0028143301606178284\n",
      "\n",
      "The classification loss after processing this batch is:  0.18382342159748077\n",
      "The representation loss after processing this batch is:  0.0024909302592277527\n",
      "\n",
      "The classification loss after processing this batch is:  0.08903130143880844\n",
      "The representation loss after processing this batch is:  0.002526320517063141\n",
      "\n",
      "The classification loss after processing this batch is:  0.07077521830797195\n",
      "The representation loss after processing this batch is:  0.0027895793318748474\n",
      "\n",
      "The classification loss after processing this batch is:  0.04231290519237518\n",
      "The representation loss after processing this batch is:  0.0023876726627349854\n",
      "\n",
      "The classification loss after processing this batch is:  0.0726458877325058\n",
      "The representation loss after processing this batch is:  0.0024512186646461487\n",
      "\n",
      "The classification loss after processing this batch is:  0.208084836602211\n",
      "The representation loss after processing this batch is:  0.002632502466440201\n",
      "\n",
      "The classification loss after processing this batch is:  0.13315317034721375\n",
      "The representation loss after processing this batch is:  0.002903260290622711\n",
      "\n",
      "The classification loss after processing this batch is:  0.04276548698544502\n",
      "The representation loss after processing this batch is:  0.0022929012775421143\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.03189263492822647\n",
      "The representation loss after processing this batch is:  0.002872079610824585\n",
      "\n",
      "The classification loss after processing this batch is:  0.033220116049051285\n",
      "The representation loss after processing this batch is:  0.0029895082116127014\n",
      "\n",
      "The classification loss after processing this batch is:  0.06449105590581894\n",
      "The representation loss after processing this batch is:  0.003306262195110321\n",
      "\n",
      "The classification loss after processing this batch is:  0.07325701415538788\n",
      "The representation loss after processing this batch is:  0.002777189016342163\n",
      "\n",
      "The classification loss after processing this batch is:  0.0534607358276844\n",
      "The representation loss after processing this batch is:  0.0028587430715560913\n",
      "\n",
      "The classification loss after processing this batch is:  0.022490806877613068\n",
      "The representation loss after processing this batch is:  0.002872288227081299\n",
      "\n",
      "The classification loss after processing this batch is:  0.04677601531147957\n",
      "The representation loss after processing this batch is:  0.0030976012349128723\n",
      "\n",
      "The classification loss after processing this batch is:  0.07893490791320801\n",
      "The representation loss after processing this batch is:  0.003419913351535797\n",
      "\n",
      "The classification loss after processing this batch is:  0.014854240231215954\n",
      "The representation loss after processing this batch is:  0.003414742648601532\n",
      "\n",
      "The classification loss after processing this batch is:  0.04015782102942467\n",
      "The representation loss after processing this batch is:  0.0030440017580986023\n",
      "\n",
      "The classification loss after processing this batch is:  0.14741668105125427\n",
      "The representation loss after processing this batch is:  0.0028602704405784607\n",
      "\n",
      "The classification loss after processing this batch is:  0.028994480147957802\n",
      "The representation loss after processing this batch is:  0.0031834766268730164\n",
      "\n",
      "The classification loss after processing this batch is:  0.013994121924042702\n",
      "The representation loss after processing this batch is:  0.002930857241153717\n",
      "\n",
      "The classification loss after processing this batch is:  0.02083176001906395\n",
      "The representation loss after processing this batch is:  0.0030160322785377502\n",
      "\n",
      "The classification loss after processing this batch is:  0.02891027182340622\n",
      "The representation loss after processing this batch is:  0.0031071677803993225\n",
      "\n",
      "The classification loss after processing this batch is:  0.03496869280934334\n",
      "The representation loss after processing this batch is:  0.002755001187324524\n",
      "\n",
      "The classification loss after processing this batch is:  0.02732546254992485\n",
      "The representation loss after processing this batch is:  0.003285124897956848\n",
      "\n",
      "The classification loss after processing this batch is:  0.016145681962370872\n",
      "The representation loss after processing this batch is:  0.0035484731197357178\n",
      "\n",
      "The classification loss after processing this batch is:  0.24601033329963684\n",
      "The representation loss after processing this batch is:  0.0033243298530578613\n",
      "\n",
      "The classification loss after processing this batch is:  0.2728775143623352\n",
      "The representation loss after processing this batch is:  0.0032580122351646423\n",
      "\n",
      "The classification loss after processing this batch is:  0.2200906127691269\n",
      "The representation loss after processing this batch is:  0.003650069236755371\n",
      "\n",
      "The classification loss after processing this batch is:  0.03799043968319893\n",
      "The representation loss after processing this batch is:  0.002602405846118927\n",
      "\n",
      "The classification loss after processing this batch is:  0.018727589398622513\n",
      "The representation loss after processing this batch is:  0.003233402967453003\n",
      "\n",
      "The classification loss after processing this batch is:  0.01309746503829956\n",
      "The representation loss after processing this batch is:  0.002254277467727661\n",
      "\n",
      "The classification loss after processing this batch is:  0.13058212399482727\n",
      "The representation loss after processing this batch is:  0.002443358302116394\n",
      "\n",
      "The classification loss after processing this batch is:  0.3271905183792114\n",
      "The representation loss after processing this batch is:  0.002725936472415924\n",
      "\n",
      "The classification loss after processing this batch is:  0.07721017301082611\n",
      "The representation loss after processing this batch is:  0.002507805824279785\n",
      "\n",
      "The classification loss after processing this batch is:  0.04677022248506546\n",
      "The representation loss after processing this batch is:  0.0030505508184432983\n",
      "\n",
      "The classification loss after processing this batch is:  0.040817055851221085\n",
      "The representation loss after processing this batch is:  0.0028888434171676636\n",
      "\n",
      "The classification loss after processing this batch is:  0.04634010046720505\n",
      "The representation loss after processing this batch is:  0.0033470094203948975\n",
      "\n",
      "The classification loss after processing this batch is:  0.08592984080314636\n",
      "The representation loss after processing this batch is:  0.002396814525127411\n",
      "\n",
      "The classification loss after processing this batch is:  0.04716299846768379\n",
      "The representation loss after processing this batch is:  0.0025650784373283386\n",
      "\n",
      "The classification loss after processing this batch is:  0.10053156316280365\n",
      "The representation loss after processing this batch is:  0.002531658858060837\n",
      "\n",
      "The classification loss after processing this batch is:  0.09483381360769272\n",
      "The representation loss after processing this batch is:  0.0023348182439804077\n",
      "\n",
      "The classification loss after processing this batch is:  0.1461568921804428\n",
      "The representation loss after processing this batch is:  0.0026607736945152283\n",
      "\n",
      "The classification loss after processing this batch is:  0.07155656069517136\n",
      "The representation loss after processing this batch is:  0.002792142331600189\n",
      "\n",
      "The classification loss after processing this batch is:  0.07045458257198334\n",
      "The representation loss after processing this batch is:  0.0029537007212638855\n",
      "\n",
      "The classification loss after processing this batch is:  0.14127080142498016\n",
      "The representation loss after processing this batch is:  0.002301279455423355\n",
      "\n",
      "The classification loss after processing this batch is:  0.12514573335647583\n",
      "The representation loss after processing this batch is:  0.002274874597787857\n",
      "\n",
      "The classification loss after processing this batch is:  0.07049228996038437\n",
      "The representation loss after processing this batch is:  0.00260123610496521\n",
      "\n",
      "The classification loss after processing this batch is:  0.14515814185142517\n",
      "The representation loss after processing this batch is:  0.002400636672973633\n",
      "\n",
      "The classification loss after processing this batch is:  0.0924859344959259\n",
      "The representation loss after processing this batch is:  0.002526957541704178\n",
      "\n",
      "The classification loss after processing this batch is:  0.12417219579219818\n",
      "The representation loss after processing this batch is:  0.003073364496231079\n",
      "\n",
      "The classification loss after processing this batch is:  0.0734526589512825\n",
      "The representation loss after processing this batch is:  0.0024960488080978394\n",
      "\n",
      "The classification loss after processing this batch is:  0.22731061279773712\n",
      "The representation loss after processing this batch is:  0.002541095018386841\n",
      "\n",
      "The classification loss after processing this batch is:  0.09393240511417389\n",
      "The representation loss after processing this batch is:  0.002307988703250885\n",
      "\n",
      "The classification loss after processing this batch is:  0.0960216224193573\n",
      "The representation loss after processing this batch is:  0.00260297954082489\n",
      "\n",
      "The classification loss after processing this batch is:  0.20717677474021912\n",
      "The representation loss after processing this batch is:  0.0026533976197242737\n",
      "\n",
      "The classification loss after processing this batch is:  0.1159052848815918\n",
      "The representation loss after processing this batch is:  0.0026733875274658203\n",
      "\n",
      "The classification loss after processing this batch is:  0.07214846462011337\n",
      "The representation loss after processing this batch is:  0.002749621868133545\n",
      "\n",
      "The classification loss after processing this batch is:  0.22326233983039856\n",
      "The representation loss after processing this batch is:  0.0030416548252105713\n",
      "\n",
      "The classification loss after processing this batch is:  0.11614309251308441\n",
      "The representation loss after processing this batch is:  0.0026260018348693848\n",
      "\n",
      "The classification loss after processing this batch is:  0.31166091561317444\n",
      "The representation loss after processing this batch is:  0.0024462342262268066\n",
      "\n",
      "The classification loss after processing this batch is:  0.08924119919538498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.0021788552403450012\n",
      "\n",
      "The classification loss after processing this batch is:  0.061073847115039825\n",
      "The representation loss after processing this batch is:  0.0025548040866851807\n",
      "\n",
      "The classification loss after processing this batch is:  0.07807720452547073\n",
      "The representation loss after processing this batch is:  0.0022682063281536102\n",
      "\n",
      "The classification loss after processing this batch is:  0.10419468581676483\n",
      "The representation loss after processing this batch is:  0.0022746361792087555\n",
      "\n",
      "The classification loss after processing this batch is:  0.07768462598323822\n",
      "The representation loss after processing this batch is:  0.002430953085422516\n",
      "\n",
      "The classification loss after processing this batch is:  0.04535850137472153\n",
      "The representation loss after processing this batch is:  0.0025084838271141052\n",
      "\n",
      "The classification loss after processing this batch is:  0.03627944737672806\n",
      "The representation loss after processing this batch is:  0.0026160627603530884\n",
      "\n",
      "The classification loss after processing this batch is:  0.041860613971948624\n",
      "The representation loss after processing this batch is:  0.002461768686771393\n",
      "\n",
      "The classification loss after processing this batch is:  0.07649470120668411\n",
      "The representation loss after processing this batch is:  0.0024697966873645782\n",
      "\n",
      "The classification loss after processing this batch is:  0.1764853447675705\n",
      "The representation loss after processing this batch is:  0.00265498086810112\n",
      "\n",
      "The classification loss after processing this batch is:  0.08138568699359894\n",
      "The representation loss after processing this batch is:  0.002800237387418747\n",
      "\n",
      "The classification loss after processing this batch is:  0.10011671483516693\n",
      "The representation loss after processing this batch is:  0.0024435706436634064\n",
      "\n",
      "The classification loss after processing this batch is:  0.040026746690273285\n",
      "The representation loss after processing this batch is:  0.002390928566455841\n",
      "\n",
      "The classification loss after processing this batch is:  0.05623302236199379\n",
      "The representation loss after processing this batch is:  0.0026044324040412903\n",
      "\n",
      "The classification loss after processing this batch is:  0.09383727610111237\n",
      "The representation loss after processing this batch is:  0.002340756356716156\n",
      "\n",
      "The classification loss after processing this batch is:  0.04617097228765488\n",
      "The representation loss after processing this batch is:  0.002551257610321045\n",
      "\n",
      "The classification loss after processing this batch is:  0.0734306201338768\n",
      "The representation loss after processing this batch is:  0.002470962703227997\n",
      "\n",
      "The classification loss after processing this batch is:  0.16219733655452728\n",
      "The representation loss after processing this batch is:  0.0030285492539405823\n",
      "\n",
      "The classification loss after processing this batch is:  0.1135135218501091\n",
      "The representation loss after processing this batch is:  0.0026370882987976074\n",
      "\n",
      "The classification loss after processing this batch is:  0.11220776289701462\n",
      "The representation loss after processing this batch is:  0.0021640732884407043\n",
      "\n",
      "The classification loss after processing this batch is:  0.14657288789749146\n",
      "The representation loss after processing this batch is:  0.002449728548526764\n",
      "\n",
      "The classification loss after processing this batch is:  0.082956962287426\n",
      "The representation loss after processing this batch is:  0.0023021847009658813\n",
      "\n",
      "The classification loss after processing this batch is:  0.07749266922473907\n",
      "The representation loss after processing this batch is:  0.002513345330953598\n",
      "\n",
      "The classification loss after processing this batch is:  0.19465826451778412\n",
      "The representation loss after processing this batch is:  0.0030045509338378906\n",
      "\n",
      "The classification loss after processing this batch is:  0.05137543007731438\n",
      "The representation loss after processing this batch is:  0.002515554428100586\n",
      "\n",
      "The classification loss after processing this batch is:  0.14009419083595276\n",
      "The representation loss after processing this batch is:  0.0022605881094932556\n",
      "\n",
      "The classification loss after processing this batch is:  0.05705248564481735\n",
      "The representation loss after processing this batch is:  0.0023436062037944794\n",
      "\n",
      "The classification loss after processing this batch is:  0.10714667290449142\n",
      "The representation loss after processing this batch is:  0.002271536737680435\n",
      "\n",
      "The classification loss after processing this batch is:  0.12965506315231323\n",
      "The representation loss after processing this batch is:  0.0026025623083114624\n",
      "\n",
      "The classification loss after processing this batch is:  0.05879729613661766\n",
      "The representation loss after processing this batch is:  0.002588968724012375\n",
      "\n",
      "The classification loss after processing this batch is:  0.1135685071349144\n",
      "The representation loss after processing this batch is:  0.002774953842163086\n",
      "\n",
      "The classification loss after processing this batch is:  0.10638647526502609\n",
      "The representation loss after processing this batch is:  0.002735048532485962\n",
      "\n",
      "The classification loss after processing this batch is:  0.10261600464582443\n",
      "The representation loss after processing this batch is:  0.0026074275374412537\n",
      "\n",
      "The classification loss after processing this batch is:  0.13260965049266815\n",
      "The representation loss after processing this batch is:  0.0023792684078216553\n",
      "\n",
      "The classification loss after processing this batch is:  0.08130190521478653\n",
      "The representation loss after processing this batch is:  0.0028869956731796265\n",
      "\n",
      "The classification loss after processing this batch is:  0.16109471023082733\n",
      "The representation loss after processing this batch is:  0.0026099085807800293\n",
      "\n",
      "The classification loss after processing this batch is:  0.07827537506818771\n",
      "The representation loss after processing this batch is:  0.002333175390958786\n",
      "\n",
      "The classification loss after processing this batch is:  0.06030051410198212\n",
      "The representation loss after processing this batch is:  0.0023264549672603607\n",
      "\n",
      "The classification loss after processing this batch is:  0.14333979785442352\n",
      "The representation loss after processing this batch is:  0.002468019723892212\n",
      "\n",
      "The classification loss after processing this batch is:  0.11315201222896576\n",
      "The representation loss after processing this batch is:  0.002307608723640442\n",
      "\n",
      "The classification loss after processing this batch is:  0.0703749805688858\n",
      "The representation loss after processing this batch is:  0.002252139151096344\n",
      "\n",
      "The classification loss after processing this batch is:  0.07837963104248047\n",
      "The representation loss after processing this batch is:  0.002326779067516327\n",
      "\n",
      "The classification loss after processing this batch is:  0.04124173894524574\n",
      "The representation loss after processing this batch is:  0.0024414807558059692\n",
      "\n",
      "The classification loss after processing this batch is:  0.07098978012800217\n",
      "The representation loss after processing this batch is:  0.0026033148169517517\n",
      "\n",
      "The classification loss after processing this batch is:  0.10640576481819153\n",
      "The representation loss after processing this batch is:  0.002033401280641556\n",
      "\n",
      "The classification loss after processing this batch is:  0.06338538974523544\n",
      "The representation loss after processing this batch is:  0.0025379806756973267\n",
      "\n",
      "The classification loss after processing this batch is:  0.156786248087883\n",
      "The representation loss after processing this batch is:  0.0024496465921401978\n",
      "\n",
      "The classification loss after processing this batch is:  0.11710912734270096\n",
      "The representation loss after processing this batch is:  0.0024440214037895203\n",
      "\n",
      "The classification loss after processing this batch is:  0.09250657260417938\n",
      "The representation loss after processing this batch is:  0.0027068480849266052\n",
      "\n",
      "The classification loss after processing this batch is:  0.06998036056756973\n",
      "The representation loss after processing this batch is:  0.0022276565432548523\n",
      "\n",
      "The classification loss after processing this batch is:  0.059053659439086914\n",
      "The representation loss after processing this batch is:  0.002611294388771057\n",
      "\n",
      "The classification loss after processing this batch is:  0.11809812486171722\n",
      "The representation loss after processing this batch is:  0.002320844680070877\n",
      "\n",
      "The classification loss after processing this batch is:  0.16138462722301483\n",
      "The representation loss after processing this batch is:  0.0023346617817878723\n",
      "\n",
      "The classification loss after processing this batch is:  0.08045986294746399\n",
      "The representation loss after processing this batch is:  0.0023825764656066895\n",
      "\n",
      "The classification loss after processing this batch is:  0.25116410851478577\n",
      "The representation loss after processing this batch is:  0.0022926554083824158\n",
      "\n",
      "The classification loss after processing this batch is:  0.10124766081571579\n",
      "The representation loss after processing this batch is:  0.0023103170096874237\n",
      "\n",
      "The classification loss after processing this batch is:  0.055167485028505325\n",
      "The representation loss after processing this batch is:  0.003047041594982147\n",
      "\n",
      "The classification loss after processing this batch is:  0.11349692940711975\n",
      "The representation loss after processing this batch is:  0.0023112744092941284\n",
      "\n",
      "The classification loss after processing this batch is:  0.04635786637663841\n",
      "The representation loss after processing this batch is:  0.0025469213724136353\n",
      "\n",
      "The classification loss after processing this batch is:  0.23506999015808105\n",
      "The representation loss after processing this batch is:  0.0026358067989349365\n",
      "\n",
      "The classification loss after processing this batch is:  0.12351325154304504\n",
      "The representation loss after processing this batch is:  0.0022746995091438293\n",
      "\n",
      "The classification loss after processing this batch is:  0.10900277644395828\n",
      "The representation loss after processing this batch is:  0.0022454634308815002\n",
      "\n",
      "The classification loss after processing this batch is:  0.26230210065841675\n",
      "The representation loss after processing this batch is:  0.0022590309381484985\n",
      "\n",
      "The classification loss after processing this batch is:  0.12226962298154831\n",
      "The representation loss after processing this batch is:  0.002507336437702179\n",
      "\n",
      "The classification loss after processing this batch is:  0.0677819699048996\n",
      "The representation loss after processing this batch is:  0.0024731680750846863\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10612710565328598\n",
      "The representation loss after processing this batch is:  0.002222929149866104\n",
      "\n",
      "The classification loss after processing this batch is:  0.11205410957336426\n",
      "The representation loss after processing this batch is:  0.0024634525179862976\n",
      "\n",
      "The classification loss after processing this batch is:  0.15857155621051788\n",
      "The representation loss after processing this batch is:  0.0026924535632133484\n",
      "\n",
      "The classification loss after processing this batch is:  0.05530022829771042\n",
      "The representation loss after processing this batch is:  0.002496950328350067\n",
      "\n",
      "The classification loss after processing this batch is:  0.09606800973415375\n",
      "The representation loss after processing this batch is:  0.002486594021320343\n",
      "\n",
      "The classification loss after processing this batch is:  0.14323709905147552\n",
      "The representation loss after processing this batch is:  0.0023931562900543213\n",
      "\n",
      "The classification loss after processing this batch is:  0.1479402333498001\n",
      "The representation loss after processing this batch is:  0.0026423782110214233\n",
      "\n",
      "The classification loss after processing this batch is:  0.16035042703151703\n",
      "The representation loss after processing this batch is:  0.0023889057338237762\n",
      "\n",
      "The classification loss after processing this batch is:  0.1889335811138153\n",
      "The representation loss after processing this batch is:  0.002852723002433777\n",
      "\n",
      "The classification loss after processing this batch is:  0.11122184246778488\n",
      "The representation loss after processing this batch is:  0.0028875023126602173\n",
      "\n",
      "The classification loss after processing this batch is:  0.0648365467786789\n",
      "The representation loss after processing this batch is:  0.0025577396154403687\n",
      "\n",
      "The classification loss after processing this batch is:  0.08687736093997955\n",
      "The representation loss after processing this batch is:  0.0024760961532592773\n",
      "\n",
      "The classification loss after processing this batch is:  0.03977286443114281\n",
      "The representation loss after processing this batch is:  0.0023220255970954895\n",
      "\n",
      "The classification loss after processing this batch is:  0.10444729030132294\n",
      "The representation loss after processing this batch is:  0.002508223056793213\n",
      "\n",
      "The classification loss after processing this batch is:  0.15433992445468903\n",
      "The representation loss after processing this batch is:  0.0024377331137657166\n",
      "\n",
      "The classification loss after processing this batch is:  0.19815656542778015\n",
      "The representation loss after processing this batch is:  0.002597123384475708\n",
      "\n",
      "The classification loss after processing this batch is:  0.23453813791275024\n",
      "The representation loss after processing this batch is:  0.002653658390045166\n",
      "\n",
      "The classification loss after processing this batch is:  0.07202199101448059\n",
      "The representation loss after processing this batch is:  0.0026553794741630554\n",
      "\n",
      "The classification loss after processing this batch is:  0.09714845567941666\n",
      "The representation loss after processing this batch is:  0.0026569366455078125\n",
      "\n",
      "The classification loss after processing this batch is:  0.1504262536764145\n",
      "The representation loss after processing this batch is:  0.002285987138748169\n",
      "\n",
      "The classification loss after processing this batch is:  0.044369686394929886\n",
      "The representation loss after processing this batch is:  0.002697587013244629\n",
      "\n",
      "The classification loss after processing this batch is:  0.06227143853902817\n",
      "The representation loss after processing this batch is:  0.002585001289844513\n",
      "\n",
      "The classification loss after processing this batch is:  0.1354711502790451\n",
      "The representation loss after processing this batch is:  0.0022257864475250244\n",
      "\n",
      "The classification loss after processing this batch is:  0.08832597732543945\n",
      "The representation loss after processing this batch is:  0.0033260881900787354\n",
      "\n",
      "The classification loss after processing this batch is:  0.09364505857229233\n",
      "The representation loss after processing this batch is:  0.0026342496275901794\n",
      "\n",
      "The classification loss after processing this batch is:  0.197342649102211\n",
      "The representation loss after processing this batch is:  0.0033997222781181335\n",
      "\n",
      "The classification loss after processing this batch is:  0.25782114267349243\n",
      "The representation loss after processing this batch is:  0.002169691026210785\n",
      "\n",
      "The classification loss after processing this batch is:  0.10784313827753067\n",
      "The representation loss after processing this batch is:  0.0024886205792427063\n",
      "\n",
      "The classification loss after processing this batch is:  0.20658369362354279\n",
      "The representation loss after processing this batch is:  0.0023995935916900635\n",
      "\n",
      "The classification loss after processing this batch is:  0.1299440711736679\n",
      "The representation loss after processing this batch is:  0.002399235963821411\n",
      "\n",
      "The classification loss after processing this batch is:  0.04309739172458649\n",
      "The representation loss after processing this batch is:  0.0025060325860977173\n",
      "\n",
      "The classification loss after processing this batch is:  0.12202263623476028\n",
      "The representation loss after processing this batch is:  0.002343691885471344\n",
      "\n",
      "The classification loss after processing this batch is:  0.3268202543258667\n",
      "The representation loss after processing this batch is:  0.002954915165901184\n",
      "\n",
      "The classification loss after processing this batch is:  0.15062789618968964\n",
      "The representation loss after processing this batch is:  0.002793367952108383\n",
      "\n",
      "The classification loss after processing this batch is:  0.0570559985935688\n",
      "The representation loss after processing this batch is:  0.0027059465646743774\n",
      "\n",
      "The classification loss after processing this batch is:  0.06214354932308197\n",
      "The representation loss after processing this batch is:  0.0025948770344257355\n",
      "\n",
      "The classification loss after processing this batch is:  0.04559008777141571\n",
      "The representation loss after processing this batch is:  0.002727113664150238\n",
      "\n",
      "The classification loss after processing this batch is:  0.08395552635192871\n",
      "The representation loss after processing this batch is:  0.0027427151799201965\n",
      "\n",
      "The classification loss after processing this batch is:  0.0844535157084465\n",
      "The representation loss after processing this batch is:  0.0027593597769737244\n",
      "\n",
      "The classification loss after processing this batch is:  0.12177428603172302\n",
      "The representation loss after processing this batch is:  0.0026532597839832306\n",
      "\n",
      "The classification loss after processing this batch is:  0.10821812599897385\n",
      "The representation loss after processing this batch is:  0.0025232508778572083\n",
      "\n",
      "The classification loss after processing this batch is:  0.18160155415534973\n",
      "The representation loss after processing this batch is:  0.0027942731976509094\n",
      "\n",
      "The classification loss after processing this batch is:  0.08182546496391296\n",
      "The representation loss after processing this batch is:  0.002299141138792038\n",
      "\n",
      "The classification loss after processing this batch is:  0.11919927597045898\n",
      "The representation loss after processing this batch is:  0.0021103136241436005\n",
      "\n",
      "The classification loss after processing this batch is:  0.13721825182437897\n",
      "The representation loss after processing this batch is:  0.002434566617012024\n",
      "\n",
      "The classification loss after processing this batch is:  0.11818365007638931\n",
      "The representation loss after processing this batch is:  0.002455286681652069\n",
      "\n",
      "The classification loss after processing this batch is:  0.08872806280851364\n",
      "The representation loss after processing this batch is:  0.0023783594369888306\n",
      "\n",
      "The classification loss after processing this batch is:  0.1941283643245697\n",
      "The representation loss after processing this batch is:  0.0023775622248649597\n",
      "\n",
      "The classification loss after processing this batch is:  0.15024112164974213\n",
      "The representation loss after processing this batch is:  0.0027146190404891968\n",
      "\n",
      "The classification loss after processing this batch is:  0.125064879655838\n",
      "The representation loss after processing this batch is:  0.0024120546877384186\n",
      "\n",
      "The classification loss after processing this batch is:  0.12201321870088577\n",
      "The representation loss after processing this batch is:  0.002543337643146515\n",
      "\n",
      "The classification loss after processing this batch is:  0.17264051735401154\n",
      "The representation loss after processing this batch is:  0.002395547926425934\n",
      "\n",
      "The classification loss after processing this batch is:  0.17609529197216034\n",
      "The representation loss after processing this batch is:  0.0025693848729133606\n",
      "\n",
      "The classification loss after processing this batch is:  0.17161191999912262\n",
      "The representation loss after processing this batch is:  0.0028411149978637695\n",
      "\n",
      "The classification loss after processing this batch is:  0.1378026008605957\n",
      "The representation loss after processing this batch is:  0.002791263163089752\n",
      "\n",
      "The classification loss after processing this batch is:  0.08095802366733551\n",
      "The representation loss after processing this batch is:  0.0028781816363334656\n",
      "\n",
      "The classification loss after processing this batch is:  0.2436331808567047\n",
      "The representation loss after processing this batch is:  0.0026676952838897705\n",
      "\n",
      "The classification loss after processing this batch is:  0.19950351119041443\n",
      "The representation loss after processing this batch is:  0.0023842230439186096\n",
      "\n",
      "The classification loss after processing this batch is:  0.25962209701538086\n",
      "The representation loss after processing this batch is:  0.00258617103099823\n",
      "\n",
      "The classification loss after processing this batch is:  0.2914527356624603\n",
      "The representation loss after processing this batch is:  0.0022993087768554688\n",
      "\n",
      "The classification loss after processing this batch is:  0.20760856568813324\n",
      "The representation loss after processing this batch is:  0.002211451530456543\n",
      "\n",
      "The classification loss after processing this batch is:  0.09502537548542023\n",
      "The representation loss after processing this batch is:  0.0022992566227912903\n",
      "\n",
      "The classification loss after processing this batch is:  0.0760205090045929\n",
      "The representation loss after processing this batch is:  0.0023772045969963074\n",
      "\n",
      "The classification loss after processing this batch is:  0.049996037036180496\n",
      "The representation loss after processing this batch is:  0.002612672746181488\n",
      "\n",
      "The classification loss after processing this batch is:  0.09171954542398453\n",
      "The representation loss after processing this batch is:  0.003040023148059845\n",
      "\n",
      "The classification loss after processing this batch is:  0.035987887531518936\n",
      "The representation loss after processing this batch is:  0.002730153501033783\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.22573217749595642\n",
      "The representation loss after processing this batch is:  0.0034505948424339294\n",
      "\n",
      "The classification loss after processing this batch is:  0.13835835456848145\n",
      "The representation loss after processing this batch is:  0.0023930855095386505\n",
      "\n",
      "The classification loss after processing this batch is:  0.07199365645647049\n",
      "The representation loss after processing this batch is:  0.0025804154574871063\n",
      "\n",
      "The classification loss after processing this batch is:  0.15192000567913055\n",
      "The representation loss after processing this batch is:  0.0023262053728103638\n",
      "\n",
      "The classification loss after processing this batch is:  0.05722969025373459\n",
      "The representation loss after processing this batch is:  0.0028612837195396423\n",
      "\n",
      "The classification loss after processing this batch is:  0.1252589225769043\n",
      "The representation loss after processing this batch is:  0.0029224231839179993\n",
      "\n",
      "The classification loss after processing this batch is:  0.16353313624858856\n",
      "The representation loss after processing this batch is:  0.0031235888600349426\n",
      "\n",
      "The classification loss after processing this batch is:  0.10662771761417389\n",
      "The representation loss after processing this batch is:  0.0030563026666641235\n",
      "\n",
      "The classification loss after processing this batch is:  0.12655891478061676\n",
      "The representation loss after processing this batch is:  0.0021909698843955994\n",
      "\n",
      "The classification loss after processing this batch is:  0.08086540549993515\n",
      "The representation loss after processing this batch is:  0.0023796334862709045\n",
      "\n",
      "The classification loss after processing this batch is:  0.023506300523877144\n",
      "The representation loss after processing this batch is:  0.002562478184700012\n",
      "\n",
      "The classification loss after processing this batch is:  0.068033866584301\n",
      "The representation loss after processing this batch is:  0.002633228898048401\n",
      "\n",
      "The classification loss after processing this batch is:  0.061316754668951035\n",
      "The representation loss after processing this batch is:  0.002304062247276306\n",
      "\n",
      "The classification loss after processing this batch is:  0.1042771115899086\n",
      "The representation loss after processing this batch is:  0.0023070834577083588\n",
      "\n",
      "The classification loss after processing this batch is:  0.10412129014730453\n",
      "The representation loss after processing this batch is:  0.002514198422431946\n",
      "\n",
      "The classification loss after processing this batch is:  0.10153469443321228\n",
      "The representation loss after processing this batch is:  0.0024757608771324158\n",
      "\n",
      "The classification loss after processing this batch is:  0.3124169111251831\n",
      "The representation loss after processing this batch is:  0.003066428005695343\n",
      "\n",
      "The classification loss after processing this batch is:  0.21476922929286957\n",
      "The representation loss after processing this batch is:  0.002688169479370117\n",
      "\n",
      "The classification loss after processing this batch is:  0.07253675162792206\n",
      "The representation loss after processing this batch is:  0.002396419644355774\n",
      "\n",
      "The classification loss after processing this batch is:  0.05086839199066162\n",
      "The representation loss after processing this batch is:  0.0027355030179023743\n",
      "\n",
      "The classification loss after processing this batch is:  0.07174854725599289\n",
      "The representation loss after processing this batch is:  0.002439744770526886\n",
      "\n",
      "The classification loss after processing this batch is:  0.0531851127743721\n",
      "The representation loss after processing this batch is:  0.002447769045829773\n",
      "\n",
      "The classification loss after processing this batch is:  0.02472328394651413\n",
      "The representation loss after processing this batch is:  0.0027160421013832092\n",
      "\n",
      "The classification loss after processing this batch is:  0.054282188415527344\n",
      "The representation loss after processing this batch is:  0.002909816801548004\n",
      "\n",
      "The classification loss after processing this batch is:  0.1095857322216034\n",
      "The representation loss after processing this batch is:  0.0022664405405521393\n",
      "\n",
      "The classification loss after processing this batch is:  0.15903107821941376\n",
      "The representation loss after processing this batch is:  0.0025580674409866333\n",
      "\n",
      "The classification loss after processing this batch is:  0.10668803006410599\n",
      "The representation loss after processing this batch is:  0.0027062296867370605\n",
      "\n",
      "The classification loss after processing this batch is:  0.06284267455339432\n",
      "The representation loss after processing this batch is:  0.0025604888796806335\n",
      "\n",
      "The classification loss after processing this batch is:  0.03875613957643509\n",
      "The representation loss after processing this batch is:  0.0023610517382621765\n",
      "\n",
      "The classification loss after processing this batch is:  0.2603478729724884\n",
      "The representation loss after processing this batch is:  0.002455715090036392\n",
      "\n",
      "The classification loss after processing this batch is:  0.11462031304836273\n",
      "The representation loss after processing this batch is:  0.0026915743947029114\n",
      "\n",
      "The classification loss after processing this batch is:  0.04803100973367691\n",
      "The representation loss after processing this batch is:  0.002652496099472046\n",
      "\n",
      "The classification loss after processing this batch is:  0.11344097554683685\n",
      "The representation loss after processing this batch is:  0.002523355185985565\n",
      "\n",
      "The classification loss after processing this batch is:  0.10096218436956406\n",
      "The representation loss after processing this batch is:  0.0021736621856689453\n",
      "\n",
      "The classification loss after processing this batch is:  0.06584113091230392\n",
      "The representation loss after processing this batch is:  0.00221378356218338\n",
      "\n",
      "The classification loss after processing this batch is:  0.1013924852013588\n",
      "The representation loss after processing this batch is:  0.0022005774080753326\n",
      "\n",
      "The classification loss after processing this batch is:  0.0685974732041359\n",
      "The representation loss after processing this batch is:  0.0024873316287994385\n",
      "\n",
      "The classification loss after processing this batch is:  0.06943356990814209\n",
      "The representation loss after processing this batch is:  0.002339668571949005\n",
      "\n",
      "The classification loss after processing this batch is:  0.11006245762109756\n",
      "The representation loss after processing this batch is:  0.0022571682929992676\n",
      "\n",
      "The classification loss after processing this batch is:  0.16788606345653534\n",
      "The representation loss after processing this batch is:  0.002575494349002838\n",
      "\n",
      "The classification loss after processing this batch is:  0.13082942366600037\n",
      "The representation loss after processing this batch is:  0.0023881718516349792\n",
      "\n",
      "The classification loss after processing this batch is:  0.10943052172660828\n",
      "The representation loss after processing this batch is:  0.00226747989654541\n",
      "\n",
      "The classification loss after processing this batch is:  0.08626954257488251\n",
      "The representation loss after processing this batch is:  0.0024110600352287292\n",
      "\n",
      "The classification loss after processing this batch is:  0.15010413527488708\n",
      "The representation loss after processing this batch is:  0.0022314563393592834\n",
      "\n",
      "The classification loss after processing this batch is:  0.056738775223493576\n",
      "The representation loss after processing this batch is:  0.0026440322399139404\n",
      "\n",
      "The classification loss after processing this batch is:  0.14151814579963684\n",
      "The representation loss after processing this batch is:  0.0024172738194465637\n",
      "\n",
      "The classification loss after processing this batch is:  0.060207970440387726\n",
      "The representation loss after processing this batch is:  0.00233323872089386\n",
      "\n",
      "The classification loss after processing this batch is:  0.12262652814388275\n",
      "The representation loss after processing this batch is:  0.0024712979793548584\n",
      "\n",
      "The classification loss after processing this batch is:  0.07394298166036606\n",
      "The representation loss after processing this batch is:  0.002526320517063141\n",
      "\n",
      "The classification loss after processing this batch is:  0.09738972038030624\n",
      "The representation loss after processing this batch is:  0.002230767160654068\n",
      "\n",
      "The classification loss after processing this batch is:  0.09544382989406586\n",
      "The representation loss after processing this batch is:  0.0022267773747444153\n",
      "\n",
      "The classification loss after processing this batch is:  0.09415510296821594\n",
      "The representation loss after processing this batch is:  0.0025884807109832764\n",
      "\n",
      "The classification loss after processing this batch is:  0.12816907465457916\n",
      "The representation loss after processing this batch is:  0.002382531762123108\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.09586121141910553\n",
      "The representation loss after processing this batch is:  0.0022177323698997498\n",
      "\n",
      "The classification loss after processing this batch is:  0.15511742234230042\n",
      "The representation loss after processing this batch is:  0.0022029057145118713\n",
      "\n",
      "The classification loss after processing this batch is:  0.16009071469306946\n",
      "The representation loss after processing this batch is:  0.0021311938762664795\n",
      "\n",
      "The classification loss after processing this batch is:  0.21471664309501648\n",
      "The representation loss after processing this batch is:  0.0021889396011829376\n",
      "\n",
      "The classification loss after processing this batch is:  0.16293685138225555\n",
      "The representation loss after processing this batch is:  0.0022880584001541138\n",
      "\n",
      "The classification loss after processing this batch is:  0.07778988033533096\n",
      "The representation loss after processing this batch is:  0.0026067793369293213\n",
      "\n",
      "The classification loss after processing this batch is:  0.16284365952014923\n",
      "The representation loss after processing this batch is:  0.002712152898311615\n",
      "\n",
      "The classification loss after processing this batch is:  0.0792875662446022\n",
      "The representation loss after processing this batch is:  0.002513296902179718\n",
      "\n",
      "The classification loss after processing this batch is:  0.10803931206464767\n",
      "The representation loss after processing this batch is:  0.0027070418000221252\n",
      "\n",
      "The classification loss after processing this batch is:  0.1760217696428299\n",
      "The representation loss after processing this batch is:  0.003004796802997589\n",
      "\n",
      "The classification loss after processing this batch is:  0.20963630080223083\n",
      "The representation loss after processing this batch is:  0.0029085054993629456\n",
      "\n",
      "The classification loss after processing this batch is:  0.21662870049476624\n",
      "The representation loss after processing this batch is:  0.0024753957986831665\n",
      "\n",
      "The classification loss after processing this batch is:  0.15451259911060333\n",
      "The representation loss after processing this batch is:  0.0025314688682556152\n",
      "\n",
      "The classification loss after processing this batch is:  0.06846697628498077\n",
      "The representation loss after processing this batch is:  0.0024001896381378174\n",
      "\n",
      "The classification loss after processing this batch is:  0.08905012905597687\n",
      "The representation loss after processing this batch is:  0.002555258572101593\n",
      "\n",
      "The classification loss after processing this batch is:  0.19875408709049225\n",
      "The representation loss after processing this batch is:  0.0022467561066150665\n",
      "\n",
      "The classification loss after processing this batch is:  0.0785558670759201\n",
      "The representation loss after processing this batch is:  0.0024572163820266724\n",
      "\n",
      "The classification loss after processing this batch is:  0.09429352730512619\n",
      "The representation loss after processing this batch is:  0.0021775662899017334\n",
      "\n",
      "The classification loss after processing this batch is:  0.07144466042518616\n",
      "The representation loss after processing this batch is:  0.0025531500577926636\n",
      "\n",
      "The classification loss after processing this batch is:  0.028446972370147705\n",
      "The representation loss after processing this batch is:  0.0024745315313339233\n",
      "\n",
      "The classification loss after processing this batch is:  0.09444913268089294\n",
      "The representation loss after processing this batch is:  0.0026215799152851105\n",
      "\n",
      "The classification loss after processing this batch is:  0.10359298437833786\n",
      "The representation loss after processing this batch is:  0.002803981304168701\n",
      "\n",
      "The classification loss after processing this batch is:  0.1246279701590538\n",
      "The representation loss after processing this batch is:  0.0024314038455486298\n",
      "\n",
      "The classification loss after processing this batch is:  0.12055020779371262\n",
      "The representation loss after processing this batch is:  0.002263173460960388\n",
      "\n",
      "The classification loss after processing this batch is:  0.09671898186206818\n",
      "The representation loss after processing this batch is:  0.0025739073753356934\n",
      "\n",
      "The classification loss after processing this batch is:  0.14293837547302246\n",
      "The representation loss after processing this batch is:  0.002489909529685974\n",
      "\n",
      "The classification loss after processing this batch is:  0.10312972962856293\n",
      "The representation loss after processing this batch is:  0.00250827893614769\n",
      "\n",
      "The classification loss after processing this batch is:  0.12073605507612228\n",
      "The representation loss after processing this batch is:  0.003180302679538727\n",
      "\n",
      "The classification loss after processing this batch is:  0.08902741223573685\n",
      "The representation loss after processing this batch is:  0.002711258828639984\n",
      "\n",
      "The classification loss after processing this batch is:  0.10281746089458466\n",
      "The representation loss after processing this batch is:  0.0025409236550331116\n",
      "\n",
      "The classification loss after processing this batch is:  0.1614418476819992\n",
      "The representation loss after processing this batch is:  0.002269655466079712\n",
      "\n",
      "The classification loss after processing this batch is:  0.22383077442646027\n",
      "The representation loss after processing this batch is:  0.002374395728111267\n",
      "\n",
      "The classification loss after processing this batch is:  0.1687934547662735\n",
      "The representation loss after processing this batch is:  0.0026643648743629456\n",
      "\n",
      "The classification loss after processing this batch is:  0.07177411019802094\n",
      "The representation loss after processing this batch is:  0.00223570317029953\n",
      "\n",
      "The classification loss after processing this batch is:  0.13528244197368622\n",
      "The representation loss after processing this batch is:  0.002723127603530884\n",
      "\n",
      "The classification loss after processing this batch is:  0.11747977137565613\n",
      "The representation loss after processing this batch is:  0.0026265867054462433\n",
      "\n",
      "The classification loss after processing this batch is:  0.15395568311214447\n",
      "The representation loss after processing this batch is:  0.0023424476385116577\n",
      "\n",
      "The classification loss after processing this batch is:  0.173178568482399\n",
      "The representation loss after processing this batch is:  0.0029015615582466125\n",
      "\n",
      "The classification loss after processing this batch is:  0.15479326248168945\n",
      "The representation loss after processing this batch is:  0.0025387704372406006\n",
      "\n",
      "The classification loss after processing this batch is:  0.2395075112581253\n",
      "The representation loss after processing this batch is:  0.002899274230003357\n",
      "\n",
      "The classification loss after processing this batch is:  0.10210563242435455\n",
      "The representation loss after processing this batch is:  0.0027376115322113037\n",
      "\n",
      "The classification loss after processing this batch is:  0.11096392571926117\n",
      "The representation loss after processing this batch is:  0.002529207617044449\n",
      "\n",
      "The classification loss after processing this batch is:  0.12023236602544785\n",
      "The representation loss after processing this batch is:  0.0028648748993873596\n",
      "\n",
      "The classification loss after processing this batch is:  0.06135537102818489\n",
      "The representation loss after processing this batch is:  0.0027382299304008484\n",
      "\n",
      "The classification loss after processing this batch is:  0.15701545774936676\n",
      "The representation loss after processing this batch is:  0.0025498569011688232\n",
      "\n",
      "The classification loss after processing this batch is:  0.09914211928844452\n",
      "The representation loss after processing this batch is:  0.0023861154913902283\n",
      "\n",
      "The classification loss after processing this batch is:  0.0864718109369278\n",
      "The representation loss after processing this batch is:  0.002350788563489914\n",
      "\n",
      "The classification loss after processing this batch is:  0.0966842919588089\n",
      "The representation loss after processing this batch is:  0.002537097781896591\n",
      "\n",
      "The classification loss after processing this batch is:  0.12482190132141113\n",
      "The representation loss after processing this batch is:  0.002913445234298706\n",
      "\n",
      "The classification loss after processing this batch is:  0.14819811284542084\n",
      "The representation loss after processing this batch is:  0.00238630548119545\n",
      "\n",
      "The classification loss after processing this batch is:  0.12933607399463654\n",
      "The representation loss after processing this batch is:  0.002529844641685486\n",
      "\n",
      "The classification loss after processing this batch is:  0.09665874391794205\n",
      "The representation loss after processing this batch is:  0.0023482218384742737\n",
      "\n",
      "The classification loss after processing this batch is:  0.04684272035956383\n",
      "The representation loss after processing this batch is:  0.0022916533052921295\n",
      "\n",
      "The classification loss after processing this batch is:  0.12424440681934357\n",
      "The representation loss after processing this batch is:  0.002046782523393631\n",
      "\n",
      "The classification loss after processing this batch is:  0.08553553372621536\n",
      "The representation loss after processing this batch is:  0.0020822733640670776\n",
      "\n",
      "The classification loss after processing this batch is:  0.42445632815361023\n",
      "The representation loss after processing this batch is:  0.002551130950450897\n",
      "\n",
      "The classification loss after processing this batch is:  0.08694515377283096\n",
      "The representation loss after processing this batch is:  0.002452448010444641\n",
      "\n",
      "The classification loss after processing this batch is:  0.13333620131015778\n",
      "The representation loss after processing this batch is:  0.002385556697845459\n",
      "\n",
      "The classification loss after processing this batch is:  0.27798303961753845\n",
      "The representation loss after processing this batch is:  0.0025749579071998596\n",
      "\n",
      "The classification loss after processing this batch is:  0.06973598897457123\n",
      "The representation loss after processing this batch is:  0.0023407936096191406\n",
      "\n",
      "The classification loss after processing this batch is:  0.17651282250881195\n",
      "The representation loss after processing this batch is:  0.0027530118823051453\n",
      "\n",
      "The classification loss after processing this batch is:  0.10854120552539825\n",
      "The representation loss after processing this batch is:  0.0026685036718845367\n",
      "\n",
      "The classification loss after processing this batch is:  0.24685755372047424\n",
      "The representation loss after processing this batch is:  0.0021525733172893524\n",
      "\n",
      "The classification loss after processing this batch is:  0.044814351946115494\n",
      "The representation loss after processing this batch is:  0.0024221614003181458\n",
      "\n",
      "The classification loss after processing this batch is:  0.10024236142635345\n",
      "The representation loss after processing this batch is:  0.0024673566222190857\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.027225585654377937\n",
      "The representation loss after processing this batch is:  0.0026877447962760925\n",
      "\n",
      "The classification loss after processing this batch is:  0.028379488736391068\n",
      "The representation loss after processing this batch is:  0.002678312361240387\n",
      "\n",
      "The classification loss after processing this batch is:  0.06324704736471176\n",
      "The representation loss after processing this batch is:  0.002601899206638336\n",
      "\n",
      "The classification loss after processing this batch is:  0.0459921769797802\n",
      "The representation loss after processing this batch is:  0.002147890627384186\n",
      "\n",
      "The classification loss after processing this batch is:  0.1100638210773468\n",
      "The representation loss after processing this batch is:  0.0025724023580551147\n",
      "\n",
      "The classification loss after processing this batch is:  0.08560297638177872\n",
      "The representation loss after processing this batch is:  0.00300801545381546\n",
      "\n",
      "The classification loss after processing this batch is:  0.08688999712467194\n",
      "The representation loss after processing this batch is:  0.0022857636213302612\n",
      "\n",
      "The classification loss after processing this batch is:  0.09228064119815826\n",
      "The representation loss after processing this batch is:  0.002286680042743683\n",
      "\n",
      "The classification loss after processing this batch is:  0.040154580026865005\n",
      "The representation loss after processing this batch is:  0.0024720653891563416\n",
      "\n",
      "The classification loss after processing this batch is:  0.11958415806293488\n",
      "The representation loss after processing this batch is:  0.002401508390903473\n",
      "\n",
      "The classification loss after processing this batch is:  0.11765730381011963\n",
      "The representation loss after processing this batch is:  0.0027000010013580322\n",
      "\n",
      "The classification loss after processing this batch is:  0.1581992208957672\n",
      "The representation loss after processing this batch is:  0.0027709007263183594\n",
      "\n",
      "The classification loss after processing this batch is:  0.09248658269643784\n",
      "The representation loss after processing this batch is:  0.0023236125707626343\n",
      "\n",
      "The classification loss after processing this batch is:  0.07135812193155289\n",
      "The representation loss after processing this batch is:  0.002324271947145462\n",
      "\n",
      "The classification loss after processing this batch is:  0.18802092969417572\n",
      "The representation loss after processing this batch is:  0.002516917884349823\n",
      "\n",
      "The classification loss after processing this batch is:  0.1615888923406601\n",
      "The representation loss after processing this batch is:  0.0025483518838882446\n",
      "\n",
      "The classification loss after processing this batch is:  0.1383925825357437\n",
      "The representation loss after processing this batch is:  0.0024542510509490967\n",
      "\n",
      "The classification loss after processing this batch is:  0.047728605568408966\n",
      "The representation loss after processing this batch is:  0.002522081136703491\n",
      "\n",
      "The classification loss after processing this batch is:  0.09331154823303223\n",
      "The representation loss after processing this batch is:  0.0026792362332344055\n",
      "\n",
      "The classification loss after processing this batch is:  0.118554025888443\n",
      "The representation loss after processing this batch is:  0.002354539930820465\n",
      "\n",
      "The classification loss after processing this batch is:  0.12085482478141785\n",
      "The representation loss after processing this batch is:  0.00270041823387146\n",
      "\n",
      "The classification loss after processing this batch is:  0.13855527341365814\n",
      "The representation loss after processing this batch is:  0.003289211541414261\n",
      "\n",
      "The classification loss after processing this batch is:  0.06977199763059616\n",
      "The representation loss after processing this batch is:  0.002963986247777939\n",
      "\n",
      "The classification loss after processing this batch is:  0.12832027673721313\n",
      "The representation loss after processing this batch is:  0.0027279630303382874\n",
      "\n",
      "The classification loss after processing this batch is:  0.16874662041664124\n",
      "The representation loss after processing this batch is:  0.0023843199014663696\n",
      "\n",
      "The classification loss after processing this batch is:  0.07211567461490631\n",
      "The representation loss after processing this batch is:  0.003073371946811676\n",
      "\n",
      "The classification loss after processing this batch is:  0.1273919641971588\n",
      "The representation loss after processing this batch is:  0.0022343844175338745\n",
      "\n",
      "The classification loss after processing this batch is:  0.06382394582033157\n",
      "The representation loss after processing this batch is:  0.002092856913805008\n",
      "\n",
      "The classification loss after processing this batch is:  0.14333948493003845\n",
      "The representation loss after processing this batch is:  0.0023101791739463806\n",
      "\n",
      "The classification loss after processing this batch is:  0.07199723273515701\n",
      "The representation loss after processing this batch is:  0.002439044415950775\n",
      "\n",
      "The classification loss after processing this batch is:  0.13056224584579468\n",
      "The representation loss after processing this batch is:  0.0026383250951766968\n",
      "\n",
      "The classification loss after processing this batch is:  0.10107468068599701\n",
      "The representation loss after processing this batch is:  0.00278288871049881\n",
      "\n",
      "The classification loss after processing this batch is:  0.08210090547800064\n",
      "The representation loss after processing this batch is:  0.0024203136563301086\n",
      "\n",
      "The classification loss after processing this batch is:  0.09658505022525787\n",
      "The representation loss after processing this batch is:  0.002627037465572357\n",
      "\n",
      "The classification loss after processing this batch is:  0.13713781535625458\n",
      "The representation loss after processing this batch is:  0.0028895437717437744\n",
      "\n",
      "The classification loss after processing this batch is:  0.14080442488193512\n",
      "The representation loss after processing this batch is:  0.0028707459568977356\n",
      "\n",
      "The classification loss after processing this batch is:  0.12553557753562927\n",
      "The representation loss after processing this batch is:  0.0026086904108524323\n",
      "\n",
      "The classification loss after processing this batch is:  0.12371133267879486\n",
      "The representation loss after processing this batch is:  0.0027103275060653687\n",
      "\n",
      "The classification loss after processing this batch is:  0.08378314971923828\n",
      "The representation loss after processing this batch is:  0.0023863688111305237\n",
      "\n",
      "The classification loss after processing this batch is:  0.08654472231864929\n",
      "The representation loss after processing this batch is:  0.0027654096484184265\n",
      "\n",
      "The classification loss after processing this batch is:  0.06255244463682175\n",
      "The representation loss after processing this batch is:  0.002546347677707672\n",
      "\n",
      "The classification loss after processing this batch is:  0.09151788800954819\n",
      "The representation loss after processing this batch is:  0.0024595335125923157\n",
      "\n",
      "The classification loss after processing this batch is:  0.04992607980966568\n",
      "The representation loss after processing this batch is:  0.0024906806647777557\n",
      "\n",
      "The classification loss after processing this batch is:  0.0472944974899292\n",
      "The representation loss after processing this batch is:  0.002290882170200348\n",
      "\n",
      "The classification loss after processing this batch is:  0.06730939447879791\n",
      "The representation loss after processing this batch is:  0.002718009054660797\n",
      "\n",
      "The classification loss after processing this batch is:  0.03256314620375633\n",
      "The representation loss after processing this batch is:  0.0028313398361206055\n",
      "\n",
      "The classification loss after processing this batch is:  0.14888152480125427\n",
      "The representation loss after processing this batch is:  0.0023811906576156616\n",
      "\n",
      "The classification loss after processing this batch is:  0.08372258394956589\n",
      "The representation loss after processing this batch is:  0.002194169908761978\n",
      "\n",
      "The classification loss after processing this batch is:  0.08977971971035004\n",
      "The representation loss after processing this batch is:  0.0026361942291259766\n",
      "\n",
      "The classification loss after processing this batch is:  0.039236851036548615\n",
      "The representation loss after processing this batch is:  0.0027028918266296387\n",
      "\n",
      "The classification loss after processing this batch is:  0.1542961299419403\n",
      "The representation loss after processing this batch is:  0.0024908781051635742\n",
      "\n",
      "The classification loss after processing this batch is:  0.10703738778829575\n",
      "The representation loss after processing this batch is:  0.002547129988670349\n",
      "\n",
      "The classification loss after processing this batch is:  0.09699232876300812\n",
      "The representation loss after processing this batch is:  0.002346642315387726\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10145943611860275\n",
      "The representation loss after processing this batch is:  0.0025018006563186646\n",
      "\n",
      "The classification loss after processing this batch is:  0.07985080778598785\n",
      "The representation loss after processing this batch is:  0.0025115907192230225\n",
      "\n",
      "The classification loss after processing this batch is:  0.0586618147790432\n",
      "The representation loss after processing this batch is:  0.0024334490299224854\n",
      "\n",
      "The classification loss after processing this batch is:  0.07179506123065948\n",
      "The representation loss after processing this batch is:  0.0025837644934654236\n",
      "\n",
      "The classification loss after processing this batch is:  0.055774059146642685\n",
      "The representation loss after processing this batch is:  0.002397768199443817\n",
      "\n",
      "The classification loss after processing this batch is:  0.18253488838672638\n",
      "The representation loss after processing this batch is:  0.002528764307498932\n",
      "\n",
      "The classification loss after processing this batch is:  0.12140980362892151\n",
      "The representation loss after processing this batch is:  0.002391442656517029\n",
      "\n",
      "The classification loss after processing this batch is:  0.13837432861328125\n",
      "The representation loss after processing this batch is:  0.0029499009251594543\n",
      "\n",
      "The classification loss after processing this batch is:  0.1505114883184433\n",
      "The representation loss after processing this batch is:  0.0025964677333831787\n",
      "\n",
      "The classification loss after processing this batch is:  0.1683841198682785\n",
      "The representation loss after processing this batch is:  0.0025725513696670532\n",
      "\n",
      "The classification loss after processing this batch is:  0.1629742980003357\n",
      "The representation loss after processing this batch is:  0.0026591047644615173\n",
      "\n",
      "The classification loss after processing this batch is:  0.2460031509399414\n",
      "The representation loss after processing this batch is:  0.00234038382768631\n",
      "\n",
      "The classification loss after processing this batch is:  0.17970600724220276\n",
      "The representation loss after processing this batch is:  0.0022713802754878998\n",
      "\n",
      "The classification loss after processing this batch is:  0.11173953115940094\n",
      "The representation loss after processing this batch is:  0.0021251216530799866\n",
      "\n",
      "The classification loss after processing this batch is:  0.08399932831525803\n",
      "The representation loss after processing this batch is:  0.002337254583835602\n",
      "\n",
      "The classification loss after processing this batch is:  0.06041589751839638\n",
      "The representation loss after processing this batch is:  0.0024196282029151917\n",
      "\n",
      "The classification loss after processing this batch is:  0.046148184686899185\n",
      "The representation loss after processing this batch is:  0.0023986995220184326\n",
      "\n",
      "The classification loss after processing this batch is:  0.074486643075943\n",
      "The representation loss after processing this batch is:  0.0029359981417655945\n",
      "\n",
      "The classification loss after processing this batch is:  0.13535426557064056\n",
      "The representation loss after processing this batch is:  0.002486608922481537\n",
      "\n",
      "The classification loss after processing this batch is:  0.06582233309745789\n",
      "The representation loss after processing this batch is:  0.0023954063653945923\n",
      "\n",
      "The classification loss after processing this batch is:  0.19749107956886292\n",
      "The representation loss after processing this batch is:  0.0025728903710842133\n",
      "\n",
      "The classification loss after processing this batch is:  0.10711114853620529\n",
      "The representation loss after processing this batch is:  0.002574928104877472\n",
      "\n",
      "The classification loss after processing this batch is:  0.12759940326213837\n",
      "The representation loss after processing this batch is:  0.0023515447974205017\n",
      "\n",
      "The classification loss after processing this batch is:  0.11727002263069153\n",
      "The representation loss after processing this batch is:  0.0022688880562782288\n",
      "\n",
      "The classification loss after processing this batch is:  0.15722621977329254\n",
      "The representation loss after processing this batch is:  0.0021755360066890717\n",
      "\n",
      "The classification loss after processing this batch is:  0.11048316955566406\n",
      "The representation loss after processing this batch is:  0.0023411139845848083\n",
      "\n",
      "The classification loss after processing this batch is:  0.10091724991798401\n",
      "The representation loss after processing this batch is:  0.0027619749307632446\n",
      "\n",
      "The classification loss after processing this batch is:  0.14041350781917572\n",
      "The representation loss after processing this batch is:  0.0023597925901412964\n",
      "\n",
      "The classification loss after processing this batch is:  0.04362201690673828\n",
      "The representation loss after processing this batch is:  0.0023537948727607727\n",
      "\n",
      "The classification loss after processing this batch is:  0.04602224379777908\n",
      "The representation loss after processing this batch is:  0.0022839680314064026\n",
      "\n",
      "The classification loss after processing this batch is:  0.1146734207868576\n",
      "The representation loss after processing this batch is:  0.0026450753211975098\n",
      "\n",
      "The classification loss after processing this batch is:  0.17549815773963928\n",
      "The representation loss after processing this batch is:  0.0024645403027534485\n",
      "\n",
      "The classification loss after processing this batch is:  0.1390446275472641\n",
      "The representation loss after processing this batch is:  0.0026888400316238403\n",
      "\n",
      "The classification loss after processing this batch is:  0.07038704305887222\n",
      "The representation loss after processing this batch is:  0.00319681316614151\n",
      "\n",
      "The classification loss after processing this batch is:  0.10299287736415863\n",
      "The representation loss after processing this batch is:  0.00272996723651886\n",
      "\n",
      "The classification loss after processing this batch is:  0.06740709394216537\n",
      "The representation loss after processing this batch is:  0.0025338083505630493\n",
      "\n",
      "The classification loss after processing this batch is:  0.19270099699497223\n",
      "The representation loss after processing this batch is:  0.0024476535618305206\n",
      "\n",
      "The classification loss after processing this batch is:  0.049774833023548126\n",
      "The representation loss after processing this batch is:  0.002145439386367798\n",
      "\n",
      "The classification loss after processing this batch is:  0.048353396356105804\n",
      "The representation loss after processing this batch is:  0.0026259273290634155\n",
      "\n",
      "The classification loss after processing this batch is:  0.1212187185883522\n",
      "The representation loss after processing this batch is:  0.003039047122001648\n",
      "\n",
      "The classification loss after processing this batch is:  0.10556455701589584\n",
      "The representation loss after processing this batch is:  0.0026723146438598633\n",
      "\n",
      "The classification loss after processing this batch is:  0.07864861190319061\n",
      "The representation loss after processing this batch is:  0.0028053000569343567\n",
      "\n",
      "The classification loss after processing this batch is:  0.04070879518985748\n",
      "The representation loss after processing this batch is:  0.0023869313299655914\n",
      "\n",
      "The classification loss after processing this batch is:  0.11953102797269821\n",
      "The representation loss after processing this batch is:  0.002783939242362976\n",
      "\n",
      "The classification loss after processing this batch is:  0.12522727251052856\n",
      "The representation loss after processing this batch is:  0.0026093795895576477\n",
      "\n",
      "The classification loss after processing this batch is:  0.16624675691127777\n",
      "The representation loss after processing this batch is:  0.002327442169189453\n",
      "\n",
      "The classification loss after processing this batch is:  0.13920587301254272\n",
      "The representation loss after processing this batch is:  0.002756640315055847\n",
      "\n",
      "The classification loss after processing this batch is:  0.06254322081804276\n",
      "The representation loss after processing this batch is:  0.00248090922832489\n",
      "\n",
      "The classification loss after processing this batch is:  0.07990369945764542\n",
      "The representation loss after processing this batch is:  0.0023159123957157135\n",
      "\n",
      "The classification loss after processing this batch is:  0.15501132607460022\n",
      "The representation loss after processing this batch is:  0.0027045905590057373\n",
      "\n",
      "The classification loss after processing this batch is:  0.17003707587718964\n",
      "The representation loss after processing this batch is:  0.0028933510184288025\n",
      "\n",
      "The classification loss after processing this batch is:  0.19883635640144348\n",
      "The representation loss after processing this batch is:  0.003087170422077179\n",
      "\n",
      "The classification loss after processing this batch is:  0.24076682329177856\n",
      "The representation loss after processing this batch is:  0.002567380666732788\n",
      "\n",
      "The classification loss after processing this batch is:  0.05945965275168419\n",
      "The representation loss after processing this batch is:  0.0022675246000289917\n",
      "\n",
      "The classification loss after processing this batch is:  0.16186028718948364\n",
      "The representation loss after processing this batch is:  0.002483207732439041\n",
      "\n",
      "The classification loss after processing this batch is:  0.08231746405363083\n",
      "The representation loss after processing this batch is:  0.0022624358534812927\n",
      "\n",
      "The classification loss after processing this batch is:  0.0853961706161499\n",
      "The representation loss after processing this batch is:  0.002407379448413849\n",
      "\n",
      "The classification loss after processing this batch is:  0.07256133109331131\n",
      "The representation loss after processing this batch is:  0.002535790205001831\n",
      "\n",
      "The classification loss after processing this batch is:  0.16113543510437012\n",
      "The representation loss after processing this batch is:  0.002411477267742157\n",
      "\n",
      "The classification loss after processing this batch is:  0.10588233917951584\n",
      "The representation loss after processing this batch is:  0.0023340731859207153\n",
      "\n",
      "The classification loss after processing this batch is:  0.07483435422182083\n",
      "The representation loss after processing this batch is:  0.0024863332509994507\n",
      "\n",
      "The classification loss after processing this batch is:  0.14283591508865356\n",
      "The representation loss after processing this batch is:  0.002557627856731415\n",
      "\n",
      "The classification loss after processing this batch is:  0.03770877420902252\n",
      "The representation loss after processing this batch is:  0.002802520990371704\n",
      "\n",
      "The classification loss after processing this batch is:  0.10241018980741501\n",
      "The representation loss after processing this batch is:  0.0028343945741653442\n",
      "\n",
      "The classification loss after processing this batch is:  0.13475696742534637\n",
      "The representation loss after processing this batch is:  0.002434447407722473\n",
      "\n",
      "The classification loss after processing this batch is:  0.1284882128238678\n",
      "The representation loss after processing this batch is:  0.0025149360299110413\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.0393734835088253\n",
      "The representation loss after processing this batch is:  0.002928502857685089\n",
      "\n",
      "The classification loss after processing this batch is:  0.06493906676769257\n",
      "The representation loss after processing this batch is:  0.0023955032229423523\n",
      "\n",
      "The classification loss after processing this batch is:  0.14975430071353912\n",
      "The representation loss after processing this batch is:  0.0028222650289535522\n",
      "\n",
      "The classification loss after processing this batch is:  0.1374223530292511\n",
      "The representation loss after processing this batch is:  0.0022610537707805634\n",
      "\n",
      "The classification loss after processing this batch is:  0.12408684194087982\n",
      "The representation loss after processing this batch is:  0.0023908838629722595\n",
      "\n",
      "The classification loss after processing this batch is:  0.08313548564910889\n",
      "The representation loss after processing this batch is:  0.002480272203683853\n",
      "\n",
      "The classification loss after processing this batch is:  0.05794983729720116\n",
      "The representation loss after processing this batch is:  0.0025625228881835938\n",
      "\n",
      "The classification loss after processing this batch is:  0.10644354671239853\n",
      "The representation loss after processing this batch is:  0.002233017235994339\n",
      "\n",
      "The classification loss after processing this batch is:  0.10149528086185455\n",
      "The representation loss after processing this batch is:  0.002535484731197357\n",
      "\n",
      "The classification loss after processing this batch is:  0.14300145208835602\n",
      "The representation loss after processing this batch is:  0.002385944128036499\n",
      "\n",
      "The classification loss after processing this batch is:  0.08253772556781769\n",
      "The representation loss after processing this batch is:  0.0027455314993858337\n",
      "\n",
      "The classification loss after processing this batch is:  0.051756851375103\n",
      "The representation loss after processing this batch is:  0.0024350881576538086\n",
      "\n",
      "The classification loss after processing this batch is:  0.12596233189105988\n",
      "The representation loss after processing this batch is:  0.002503279596567154\n",
      "\n",
      "The classification loss after processing this batch is:  0.17715483903884888\n",
      "The representation loss after processing this batch is:  0.0025104880332946777\n",
      "\n",
      "The classification loss after processing this batch is:  0.048957280814647675\n",
      "The representation loss after processing this batch is:  0.002576500177383423\n",
      "\n",
      "The classification loss after processing this batch is:  0.08585846424102783\n",
      "The representation loss after processing this batch is:  0.0022944845259189606\n",
      "\n",
      "The classification loss after processing this batch is:  0.15029264986515045\n",
      "The representation loss after processing this batch is:  0.0024218186736106873\n",
      "\n",
      "The classification loss after processing this batch is:  0.18759924173355103\n",
      "The representation loss after processing this batch is:  0.0023632049560546875\n",
      "\n",
      "The classification loss after processing this batch is:  0.08606423437595367\n",
      "The representation loss after processing this batch is:  0.002366870641708374\n",
      "\n",
      "The classification loss after processing this batch is:  0.1328260600566864\n",
      "The representation loss after processing this batch is:  0.002286761999130249\n",
      "\n",
      "The classification loss after processing this batch is:  0.16917464137077332\n",
      "The representation loss after processing this batch is:  0.002702943980693817\n",
      "\n",
      "The classification loss after processing this batch is:  0.18243373930454254\n",
      "The representation loss after processing this batch is:  0.002631925046443939\n",
      "\n",
      "The classification loss after processing this batch is:  0.1113143116235733\n",
      "The representation loss after processing this batch is:  0.00263996422290802\n",
      "\n",
      "The classification loss after processing this batch is:  0.16212581098079681\n",
      "The representation loss after processing this batch is:  0.0024240463972091675\n",
      "\n",
      "The classification loss after processing this batch is:  0.11161985248327255\n",
      "The representation loss after processing this batch is:  0.0033971741795539856\n",
      "\n",
      "The classification loss after processing this batch is:  0.09449264407157898\n",
      "The representation loss after processing this batch is:  0.0026588812470436096\n",
      "\n",
      "The classification loss after processing this batch is:  0.07682041078805923\n",
      "The representation loss after processing this batch is:  0.0023749619722366333\n",
      "\n",
      "The classification loss after processing this batch is:  0.08514483273029327\n",
      "The representation loss after processing this batch is:  0.0022360719740390778\n",
      "\n",
      "The classification loss after processing this batch is:  0.09355272352695465\n",
      "The representation loss after processing this batch is:  0.0024833902716636658\n",
      "\n",
      "The classification loss after processing this batch is:  0.09980858862400055\n",
      "The representation loss after processing this batch is:  0.0023975670337677\n",
      "\n",
      "The classification loss after processing this batch is:  0.16225701570510864\n",
      "The representation loss after processing this batch is:  0.0024592652916908264\n",
      "\n",
      "The classification loss after processing this batch is:  0.06013024225831032\n",
      "The representation loss after processing this batch is:  0.0026302486658096313\n",
      "\n",
      "The classification loss after processing this batch is:  0.04848635569214821\n",
      "The representation loss after processing this batch is:  0.002839989960193634\n",
      "\n",
      "The classification loss after processing this batch is:  0.11641965806484222\n",
      "The representation loss after processing this batch is:  0.00277584046125412\n",
      "\n",
      "The classification loss after processing this batch is:  0.03360209986567497\n",
      "The representation loss after processing this batch is:  0.0022666901350021362\n",
      "\n",
      "The classification loss after processing this batch is:  0.07175979763269424\n",
      "The representation loss after processing this batch is:  0.002610422670841217\n",
      "\n",
      "The classification loss after processing this batch is:  0.03242350369691849\n",
      "The representation loss after processing this batch is:  0.0025810524821281433\n",
      "\n",
      "The classification loss after processing this batch is:  0.11754793673753738\n",
      "The representation loss after processing this batch is:  0.002252645790576935\n",
      "\n",
      "The classification loss after processing this batch is:  0.16202552616596222\n",
      "The representation loss after processing this batch is:  0.002582460641860962\n",
      "\n",
      "The classification loss after processing this batch is:  0.13383778929710388\n",
      "The representation loss after processing this batch is:  0.003027096390724182\n",
      "\n",
      "The classification loss after processing this batch is:  0.12226283550262451\n",
      "The representation loss after processing this batch is:  0.0030175969004631042\n",
      "\n",
      "The classification loss after processing this batch is:  0.07936349511146545\n",
      "The representation loss after processing this batch is:  0.0027593672275543213\n",
      "\n",
      "The classification loss after processing this batch is:  0.09194476902484894\n",
      "The representation loss after processing this batch is:  0.0024446360766887665\n",
      "\n",
      "The classification loss after processing this batch is:  0.09434535354375839\n",
      "The representation loss after processing this batch is:  0.0023576170206069946\n",
      "\n",
      "The classification loss after processing this batch is:  0.047653678804636\n",
      "The representation loss after processing this batch is:  0.002714160829782486\n",
      "\n",
      "The classification loss after processing this batch is:  0.06763755530118942\n",
      "The representation loss after processing this batch is:  0.0025487393140792847\n",
      "\n",
      "The classification loss after processing this batch is:  0.03530704230070114\n",
      "The representation loss after processing this batch is:  0.00252668559551239\n",
      "\n",
      "The classification loss after processing this batch is:  0.08466650545597076\n",
      "The representation loss after processing this batch is:  0.002594396471977234\n",
      "\n",
      "The classification loss after processing this batch is:  0.1355011761188507\n",
      "The representation loss after processing this batch is:  0.002566032111644745\n",
      "\n",
      "The classification loss after processing this batch is:  0.16552291810512543\n",
      "The representation loss after processing this batch is:  0.002626650035381317\n",
      "\n",
      "The classification loss after processing this batch is:  0.13236884772777557\n",
      "The representation loss after processing this batch is:  0.0030591413378715515\n",
      "\n",
      "The classification loss after processing this batch is:  0.092658132314682\n",
      "The representation loss after processing this batch is:  0.002701960504055023\n",
      "\n",
      "The classification loss after processing this batch is:  0.12600737810134888\n",
      "The representation loss after processing this batch is:  0.0026883259415626526\n",
      "\n",
      "The classification loss after processing this batch is:  0.09201400727033615\n",
      "The representation loss after processing this batch is:  0.0025204867124557495\n",
      "\n",
      "The classification loss after processing this batch is:  0.30710452795028687\n",
      "The representation loss after processing this batch is:  0.003026247024536133\n",
      "\n",
      "The classification loss after processing this batch is:  0.11264179646968842\n",
      "The representation loss after processing this batch is:  0.0028632506728172302\n",
      "\n",
      "The classification loss after processing this batch is:  0.18894736468791962\n",
      "The representation loss after processing this batch is:  0.0029920190572738647\n",
      "\n",
      "The classification loss after processing this batch is:  0.07530579715967178\n",
      "The representation loss after processing this batch is:  0.0023939907550811768\n",
      "\n",
      "The classification loss after processing this batch is:  0.0886707529425621\n",
      "The representation loss after processing this batch is:  0.0023755505681037903\n",
      "\n",
      "The classification loss after processing this batch is:  0.1447039693593979\n",
      "The representation loss after processing this batch is:  0.002435840666294098\n",
      "\n",
      "The classification loss after processing this batch is:  0.10418451577425003\n",
      "The representation loss after processing this batch is:  0.002534259110689163\n",
      "\n",
      "The classification loss after processing this batch is:  0.20070841908454895\n",
      "The representation loss after processing this batch is:  0.0024267733097076416\n",
      "\n",
      "The classification loss after processing this batch is:  0.12088314443826675\n",
      "The representation loss after processing this batch is:  0.0029358714818954468\n",
      "\n",
      "The classification loss after processing this batch is:  0.16684049367904663\n",
      "The representation loss after processing this batch is:  0.0030197426676750183\n",
      "\n",
      "The classification loss after processing this batch is:  0.11997624486684799\n",
      "The representation loss after processing this batch is:  0.002828344702720642\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.03633109852671623\n",
      "The representation loss after processing this batch is:  0.0026011988520622253\n",
      "\n",
      "The classification loss after processing this batch is:  0.08227067440748215\n",
      "The representation loss after processing this batch is:  0.0023678988218307495\n",
      "\n",
      "The classification loss after processing this batch is:  0.08770108222961426\n",
      "The representation loss after processing this batch is:  0.002349279820919037\n",
      "\n",
      "The classification loss after processing this batch is:  0.07275927811861038\n",
      "The representation loss after processing this batch is:  0.0025674551725387573\n",
      "\n",
      "The classification loss after processing this batch is:  0.14880770444869995\n",
      "The representation loss after processing this batch is:  0.0023437440395355225\n",
      "\n",
      "The classification loss after processing this batch is:  0.22713348269462585\n",
      "The representation loss after processing this batch is:  0.0022851526737213135\n",
      "\n",
      "The classification loss after processing this batch is:  0.11012373119592667\n",
      "The representation loss after processing this batch is:  0.0021793730556964874\n",
      "\n",
      "The classification loss after processing this batch is:  0.0782221332192421\n",
      "The representation loss after processing this batch is:  0.0025155358016490936\n",
      "\n",
      "The classification loss after processing this batch is:  0.10671553015708923\n",
      "The representation loss after processing this batch is:  0.002567283809185028\n",
      "\n",
      "The classification loss after processing this batch is:  0.0644351989030838\n",
      "The representation loss after processing this batch is:  0.0027348995208740234\n",
      "\n",
      "The classification loss after processing this batch is:  0.11337223649024963\n",
      "The representation loss after processing this batch is:  0.0027529075741767883\n",
      "\n",
      "The classification loss after processing this batch is:  0.04467610642313957\n",
      "The representation loss after processing this batch is:  0.002626664936542511\n",
      "\n",
      "The classification loss after processing this batch is:  0.09964727610349655\n",
      "The representation loss after processing this batch is:  0.002298019826412201\n",
      "\n",
      "The classification loss after processing this batch is:  0.1618281751871109\n",
      "The representation loss after processing this batch is:  0.0025827623903751373\n",
      "\n",
      "The classification loss after processing this batch is:  0.05075773224234581\n",
      "The representation loss after processing this batch is:  0.0023399367928504944\n",
      "\n",
      "The classification loss after processing this batch is:  0.15978148579597473\n",
      "The representation loss after processing this batch is:  0.0021638497710227966\n",
      "\n",
      "The classification loss after processing this batch is:  0.08681228756904602\n",
      "The representation loss after processing this batch is:  0.0021338537335395813\n",
      "\n",
      "The classification loss after processing this batch is:  0.10243191570043564\n",
      "The representation loss after processing this batch is:  0.0024049952626228333\n",
      "\n",
      "The classification loss after processing this batch is:  0.056082263588905334\n",
      "The representation loss after processing this batch is:  0.002493426203727722\n",
      "\n",
      "The classification loss after processing this batch is:  0.11182413250207901\n",
      "The representation loss after processing this batch is:  0.0024794787168502808\n",
      "\n",
      "The classification loss after processing this batch is:  0.0670403242111206\n",
      "The representation loss after processing this batch is:  0.002527296543121338\n",
      "\n",
      "The classification loss after processing this batch is:  0.29872483015060425\n",
      "The representation loss after processing this batch is:  0.002553708851337433\n",
      "\n",
      "The classification loss after processing this batch is:  0.1373620480298996\n",
      "The representation loss after processing this batch is:  0.002673819661140442\n",
      "\n",
      "The classification loss after processing this batch is:  0.15530070662498474\n",
      "The representation loss after processing this batch is:  0.002346612513065338\n",
      "\n",
      "The classification loss after processing this batch is:  0.07716329395771027\n",
      "The representation loss after processing this batch is:  0.0021070949733257294\n",
      "\n",
      "The classification loss after processing this batch is:  0.12369319051504135\n",
      "The representation loss after processing this batch is:  0.00246603786945343\n",
      "\n",
      "The classification loss after processing this batch is:  0.04402487352490425\n",
      "The representation loss after processing this batch is:  0.00228109210729599\n",
      "\n",
      "The classification loss after processing this batch is:  0.12153696268796921\n",
      "The representation loss after processing this batch is:  0.0023085661232471466\n",
      "\n",
      "The classification loss after processing this batch is:  0.163879856467247\n",
      "The representation loss after processing this batch is:  0.002424534410238266\n",
      "\n",
      "The classification loss after processing this batch is:  0.14374962449073792\n",
      "The representation loss after processing this batch is:  0.0027429908514022827\n",
      "\n",
      "The classification loss after processing this batch is:  0.16643206775188446\n",
      "The representation loss after processing this batch is:  0.002570994198322296\n",
      "\n",
      "The classification loss after processing this batch is:  0.08838160336017609\n",
      "The representation loss after processing this batch is:  0.0023446306586265564\n",
      "\n",
      "The classification loss after processing this batch is:  0.18060757219791412\n",
      "The representation loss after processing this batch is:  0.0025922060012817383\n",
      "\n",
      "The classification loss after processing this batch is:  0.12826107442378998\n",
      "The representation loss after processing this batch is:  0.002676665782928467\n",
      "\n",
      "The classification loss after processing this batch is:  0.1738440841436386\n",
      "The representation loss after processing this batch is:  0.0024947747588157654\n",
      "\n",
      "The classification loss after processing this batch is:  0.10128512233495712\n",
      "The representation loss after processing this batch is:  0.0026860907673835754\n",
      "\n",
      "The classification loss after processing this batch is:  0.09562677890062332\n",
      "The representation loss after processing this batch is:  0.0028442740440368652\n",
      "\n",
      "The classification loss after processing this batch is:  0.04621756449341774\n",
      "The representation loss after processing this batch is:  0.002308383584022522\n",
      "\n",
      "The classification loss after processing this batch is:  0.16404619812965393\n",
      "The representation loss after processing this batch is:  0.002308949828147888\n",
      "\n",
      "The classification loss after processing this batch is:  0.23364849388599396\n",
      "The representation loss after processing this batch is:  0.002715565264225006\n",
      "\n",
      "The classification loss after processing this batch is:  0.10222890973091125\n",
      "The representation loss after processing this batch is:  0.00278395414352417\n",
      "\n",
      "The classification loss after processing this batch is:  0.12955379486083984\n",
      "The representation loss after processing this batch is:  0.0030838623642921448\n",
      "\n",
      "The classification loss after processing this batch is:  0.1575622409582138\n",
      "The representation loss after processing this batch is:  0.002457365393638611\n",
      "\n",
      "The classification loss after processing this batch is:  0.1283493936061859\n",
      "The representation loss after processing this batch is:  0.002885855734348297\n",
      "\n",
      "The classification loss after processing this batch is:  0.04865971580147743\n",
      "The representation loss after processing this batch is:  0.00226510688662529\n",
      "\n",
      "The classification loss after processing this batch is:  0.12397967278957367\n",
      "The representation loss after processing this batch is:  0.002515837550163269\n",
      "\n",
      "The classification loss after processing this batch is:  0.13128194212913513\n",
      "The representation loss after processing this batch is:  0.0027148276567459106\n",
      "\n",
      "The classification loss after processing this batch is:  0.08428371697664261\n",
      "The representation loss after processing this batch is:  0.0025481022894382477\n",
      "\n",
      "The classification loss after processing this batch is:  0.034760333597660065\n",
      "The representation loss after processing this batch is:  0.0025573447346687317\n",
      "\n",
      "The classification loss after processing this batch is:  0.08015166223049164\n",
      "The representation loss after processing this batch is:  0.002566203474998474\n",
      "\n",
      "The classification loss after processing this batch is:  0.070185586810112\n",
      "The representation loss after processing this batch is:  0.002786502242088318\n",
      "\n",
      "The classification loss after processing this batch is:  0.11501984298229218\n",
      "The representation loss after processing this batch is:  0.0023171529173851013\n",
      "\n",
      "The classification loss after processing this batch is:  0.16306695342063904\n",
      "The representation loss after processing this batch is:  0.0024749115109443665\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14432008564472198\n",
      "The representation loss after processing this batch is:  0.0022324100136756897\n",
      "\n",
      "The classification loss after processing this batch is:  0.10256311297416687\n",
      "The representation loss after processing this batch is:  0.002707540988922119\n",
      "\n",
      "The classification loss after processing this batch is:  0.1420622020959854\n",
      "The representation loss after processing this batch is:  0.0029375553131103516\n",
      "\n",
      "The classification loss after processing this batch is:  0.11087890714406967\n",
      "The representation loss after processing this batch is:  0.0027841776609420776\n",
      "\n",
      "The classification loss after processing this batch is:  0.09059175103902817\n",
      "The representation loss after processing this batch is:  0.0027323663234710693\n",
      "\n",
      "The classification loss after processing this batch is:  0.1816193014383316\n",
      "The representation loss after processing this batch is:  0.0026525408029556274\n",
      "\n",
      "The classification loss after processing this batch is:  0.15643714368343353\n",
      "The representation loss after processing this batch is:  0.003176383674144745\n",
      "\n",
      "The classification loss after processing this batch is:  0.07583055645227432\n",
      "The representation loss after processing this batch is:  0.002460010349750519\n",
      "\n",
      "The classification loss after processing this batch is:  0.06903307139873505\n",
      "The representation loss after processing this batch is:  0.002614784985780716\n",
      "\n",
      "The classification loss after processing this batch is:  0.07332058250904083\n",
      "The representation loss after processing this batch is:  0.002247944474220276\n",
      "\n",
      "The classification loss after processing this batch is:  0.07748256623744965\n",
      "The representation loss after processing this batch is:  0.0024867579340934753\n",
      "\n",
      "The classification loss after processing this batch is:  0.11334320157766342\n",
      "The representation loss after processing this batch is:  0.00247984379529953\n",
      "\n",
      "The classification loss after processing this batch is:  0.19442586600780487\n",
      "The representation loss after processing this batch is:  0.0022972337901592255\n",
      "\n",
      "The classification loss after processing this batch is:  0.17806454002857208\n",
      "The representation loss after processing this batch is:  0.0028214305639266968\n",
      "\n",
      "The classification loss after processing this batch is:  0.14233480393886566\n",
      "The representation loss after processing this batch is:  0.0022377222776412964\n",
      "\n",
      "The classification loss after processing this batch is:  0.12584348022937775\n",
      "The representation loss after processing this batch is:  0.0021220482885837555\n",
      "\n",
      "The classification loss after processing this batch is:  0.09191083163022995\n",
      "The representation loss after processing this batch is:  0.0022675655782222748\n",
      "\n",
      "The classification loss after processing this batch is:  0.12639810144901276\n",
      "The representation loss after processing this batch is:  0.0021800026297569275\n",
      "\n",
      "The classification loss after processing this batch is:  0.18903332948684692\n",
      "The representation loss after processing this batch is:  0.0023680664598941803\n",
      "\n",
      "The classification loss after processing this batch is:  0.1661825180053711\n",
      "The representation loss after processing this batch is:  0.0023173317313194275\n",
      "\n",
      "The classification loss after processing this batch is:  0.33045753836631775\n",
      "The representation loss after processing this batch is:  0.0024584904313087463\n",
      "\n",
      "The classification loss after processing this batch is:  0.1374119222164154\n",
      "The representation loss after processing this batch is:  0.0025315284729003906\n",
      "\n",
      "The classification loss after processing this batch is:  0.03654143959283829\n",
      "The representation loss after processing this batch is:  0.0026931539177894592\n",
      "\n",
      "The classification loss after processing this batch is:  0.1480599343776703\n",
      "The representation loss after processing this batch is:  0.0026240013539791107\n",
      "\n",
      "The classification loss after processing this batch is:  0.0900179073214531\n",
      "The representation loss after processing this batch is:  0.0024948567152023315\n",
      "\n",
      "The classification loss after processing this batch is:  0.1466309279203415\n",
      "The representation loss after processing this batch is:  0.00291229784488678\n",
      "\n",
      "The classification loss after processing this batch is:  0.15478381514549255\n",
      "The representation loss after processing this batch is:  0.002359095960855484\n",
      "\n",
      "The classification loss after processing this batch is:  0.13405580818653107\n",
      "The representation loss after processing this batch is:  0.002510763704776764\n",
      "\n",
      "The classification loss after processing this batch is:  0.11174450814723969\n",
      "The representation loss after processing this batch is:  0.002492152154445648\n",
      "\n",
      "The classification loss after processing this batch is:  0.15763603150844574\n",
      "The representation loss after processing this batch is:  0.002191726118326187\n",
      "\n",
      "The classification loss after processing this batch is:  0.20701199769973755\n",
      "The representation loss after processing this batch is:  0.0024342909455299377\n",
      "\n",
      "The classification loss after processing this batch is:  0.21197198331356049\n",
      "The representation loss after processing this batch is:  0.002648383378982544\n",
      "\n",
      "The classification loss after processing this batch is:  0.1236393004655838\n",
      "The representation loss after processing this batch is:  0.0022911429405212402\n",
      "\n",
      "The classification loss after processing this batch is:  0.040915485471487045\n",
      "The representation loss after processing this batch is:  0.0028115585446357727\n",
      "\n",
      "The classification loss after processing this batch is:  0.02656244859099388\n",
      "The representation loss after processing this batch is:  0.0025395378470420837\n",
      "\n",
      "The classification loss after processing this batch is:  0.10236679017543793\n",
      "The representation loss after processing this batch is:  0.0025074556469917297\n",
      "\n",
      "The classification loss after processing this batch is:  0.06362295150756836\n",
      "The representation loss after processing this batch is:  0.0037729665637016296\n",
      "\n",
      "The classification loss after processing this batch is:  0.15995603799819946\n",
      "The representation loss after processing this batch is:  0.002403765916824341\n",
      "\n",
      "The classification loss after processing this batch is:  0.07690224796533585\n",
      "The representation loss after processing this batch is:  0.002682231366634369\n",
      "\n",
      "The classification loss after processing this batch is:  0.17774365842342377\n",
      "The representation loss after processing this batch is:  0.0023501403629779816\n",
      "\n",
      "The classification loss after processing this batch is:  0.06237536296248436\n",
      "The representation loss after processing this batch is:  0.002802513539791107\n",
      "\n",
      "The classification loss after processing this batch is:  0.13137692213058472\n",
      "The representation loss after processing this batch is:  0.0026366673409938812\n",
      "\n",
      "The classification loss after processing this batch is:  0.13387157022953033\n",
      "The representation loss after processing this batch is:  0.0028822198510169983\n",
      "\n",
      "The classification loss after processing this batch is:  0.1579168289899826\n",
      "The representation loss after processing this batch is:  0.0028457120060920715\n",
      "\n",
      "The classification loss after processing this batch is:  0.09475121647119522\n",
      "The representation loss after processing this batch is:  0.0024989470839500427\n",
      "\n",
      "The classification loss after processing this batch is:  0.06436017155647278\n",
      "The representation loss after processing this batch is:  0.002108383923768997\n",
      "\n",
      "The classification loss after processing this batch is:  0.12902164459228516\n",
      "The representation loss after processing this batch is:  0.002645835280418396\n",
      "\n",
      "The classification loss after processing this batch is:  0.0944121703505516\n",
      "The representation loss after processing this batch is:  0.002406083047389984\n",
      "\n",
      "The classification loss after processing this batch is:  0.13158400356769562\n",
      "The representation loss after processing this batch is:  0.0024439096450805664\n",
      "\n",
      "The classification loss after processing this batch is:  0.15101712942123413\n",
      "The representation loss after processing this batch is:  0.0027217119932174683\n",
      "\n",
      "The classification loss after processing this batch is:  0.08173839002847672\n",
      "The representation loss after processing this batch is:  0.002553775906562805\n",
      "\n",
      "The classification loss after processing this batch is:  0.03809754177927971\n",
      "The representation loss after processing this batch is:  0.00244024395942688\n",
      "\n",
      "The classification loss after processing this batch is:  0.0456945039331913\n",
      "The representation loss after processing this batch is:  0.0028818100690841675\n",
      "\n",
      "The classification loss after processing this batch is:  0.025667846202850342\n",
      "The representation loss after processing this batch is:  0.002682909369468689\n",
      "\n",
      "The classification loss after processing this batch is:  0.09533708542585373\n",
      "The representation loss after processing this batch is:  0.0025492385029792786\n",
      "\n",
      "The classification loss after processing this batch is:  0.050256047397851944\n",
      "The representation loss after processing this batch is:  0.0026213526725769043\n",
      "\n",
      "The classification loss after processing this batch is:  0.029208891093730927\n",
      "The representation loss after processing this batch is:  0.002497144043445587\n",
      "\n",
      "The classification loss after processing this batch is:  0.1085696741938591\n",
      "The representation loss after processing this batch is:  0.0030582621693611145\n",
      "\n",
      "The classification loss after processing this batch is:  0.06737402826547623\n",
      "The representation loss after processing this batch is:  0.0026435256004333496\n",
      "\n",
      "The classification loss after processing this batch is:  0.03803074359893799\n",
      "The representation loss after processing this batch is:  0.0024856477975845337\n",
      "\n",
      "The classification loss after processing this batch is:  0.05631350353360176\n",
      "The representation loss after processing this batch is:  0.002474270761013031\n",
      "\n",
      "The classification loss after processing this batch is:  0.046793028712272644\n",
      "The representation loss after processing this batch is:  0.0023500025272369385\n",
      "\n",
      "The classification loss after processing this batch is:  0.03315940126776695\n",
      "The representation loss after processing this batch is:  0.002582043409347534\n",
      "\n",
      "The classification loss after processing this batch is:  0.12570731341838837\n",
      "The representation loss after processing this batch is:  0.0026273801922798157\n",
      "\n",
      "The classification loss after processing this batch is:  0.13471578061580658\n",
      "The representation loss after processing this batch is:  0.0026341527700424194\n",
      "\n",
      "The classification loss after processing this batch is:  0.05985311418771744\n",
      "The representation loss after processing this batch is:  0.002487584948539734\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1695134937763214\n",
      "The representation loss after processing this batch is:  0.0024670101702213287\n",
      "\n",
      "The classification loss after processing this batch is:  0.06014758348464966\n",
      "The representation loss after processing this batch is:  0.002406306564807892\n",
      "\n",
      "The classification loss after processing this batch is:  0.12330340594053268\n",
      "The representation loss after processing this batch is:  0.0024359971284866333\n",
      "\n",
      "The classification loss after processing this batch is:  0.12637875974178314\n",
      "The representation loss after processing this batch is:  0.002996377646923065\n",
      "\n",
      "The classification loss after processing this batch is:  0.07079606503248215\n",
      "The representation loss after processing this batch is:  0.002616085112094879\n",
      "\n",
      "The classification loss after processing this batch is:  0.1659725159406662\n",
      "The representation loss after processing this batch is:  0.002433374524116516\n",
      "\n",
      "The classification loss after processing this batch is:  0.1466723531484604\n",
      "The representation loss after processing this batch is:  0.0023338645696640015\n",
      "\n",
      "The classification loss after processing this batch is:  0.14046193659305573\n",
      "The representation loss after processing this batch is:  0.002521730959415436\n",
      "\n",
      "The classification loss after processing this batch is:  0.13456577062606812\n",
      "The representation loss after processing this batch is:  0.0024728626012802124\n",
      "\n",
      "The classification loss after processing this batch is:  0.11145489662885666\n",
      "The representation loss after processing this batch is:  0.0024783164262771606\n",
      "\n",
      "The classification loss after processing this batch is:  0.11000139266252518\n",
      "The representation loss after processing this batch is:  0.0023647062480449677\n",
      "\n",
      "The classification loss after processing this batch is:  0.07712189108133316\n",
      "The representation loss after processing this batch is:  0.002694159746170044\n",
      "\n",
      "The classification loss after processing this batch is:  0.17699410021305084\n",
      "The representation loss after processing this batch is:  0.00241997092962265\n",
      "\n",
      "The classification loss after processing this batch is:  0.13430429995059967\n",
      "The representation loss after processing this batch is:  0.002270430326461792\n",
      "\n",
      "The classification loss after processing this batch is:  0.044685088098049164\n",
      "The representation loss after processing this batch is:  0.0024463385343551636\n",
      "\n",
      "The classification loss after processing this batch is:  0.0676979273557663\n",
      "The representation loss after processing this batch is:  0.0023491978645324707\n",
      "\n",
      "The classification loss after processing this batch is:  0.1879085898399353\n",
      "The representation loss after processing this batch is:  0.002001289278268814\n",
      "\n",
      "The classification loss after processing this batch is:  0.07761608809232712\n",
      "The representation loss after processing this batch is:  0.002669490873813629\n",
      "\n",
      "The classification loss after processing this batch is:  0.10121864825487137\n",
      "The representation loss after processing this batch is:  0.0023575052618980408\n",
      "\n",
      "The classification loss after processing this batch is:  0.11755403876304626\n",
      "The representation loss after processing this batch is:  0.0023653432726860046\n",
      "\n",
      "The classification loss after processing this batch is:  0.07541064918041229\n",
      "The representation loss after processing this batch is:  0.0026568323373794556\n",
      "\n",
      "The classification loss after processing this batch is:  0.03761737793684006\n",
      "The representation loss after processing this batch is:  0.002519354224205017\n",
      "\n",
      "The classification loss after processing this batch is:  0.08736363053321838\n",
      "The representation loss after processing this batch is:  0.0027705803513526917\n",
      "\n",
      "The classification loss after processing this batch is:  0.10990019142627716\n",
      "The representation loss after processing this batch is:  0.002586565911769867\n",
      "\n",
      "The classification loss after processing this batch is:  0.11177213490009308\n",
      "The representation loss after processing this batch is:  0.0023626573383808136\n",
      "\n",
      "The classification loss after processing this batch is:  0.20210762321949005\n",
      "The representation loss after processing this batch is:  0.0024672113358974457\n",
      "\n",
      "The classification loss after processing this batch is:  0.11117352545261383\n",
      "The representation loss after processing this batch is:  0.0025828108191490173\n",
      "\n",
      "The classification loss after processing this batch is:  0.16366323828697205\n",
      "The representation loss after processing this batch is:  0.0022381991147994995\n",
      "\n",
      "The classification loss after processing this batch is:  0.14998330175876617\n",
      "The representation loss after processing this batch is:  0.0028330013155937195\n",
      "\n",
      "The classification loss after processing this batch is:  0.05626017227768898\n",
      "The representation loss after processing this batch is:  0.002646803855895996\n",
      "\n",
      "The classification loss after processing this batch is:  0.05359186232089996\n",
      "The representation loss after processing this batch is:  0.002624236047267914\n",
      "\n",
      "The classification loss after processing this batch is:  0.08487243205308914\n",
      "The representation loss after processing this batch is:  0.0025779157876968384\n",
      "\n",
      "The classification loss after processing this batch is:  0.14813333749771118\n",
      "The representation loss after processing this batch is:  0.0026164650917053223\n",
      "\n",
      "The classification loss after processing this batch is:  0.09867479652166367\n",
      "The representation loss after processing this batch is:  0.0025369077920913696\n",
      "\n",
      "The classification loss after processing this batch is:  0.1311669945716858\n",
      "The representation loss after processing this batch is:  0.0025568604469299316\n",
      "\n",
      "The classification loss after processing this batch is:  0.12143560498952866\n",
      "The representation loss after processing this batch is:  0.002843014895915985\n",
      "\n",
      "The classification loss after processing this batch is:  0.12832066416740417\n",
      "The representation loss after processing this batch is:  0.002837546169757843\n",
      "\n",
      "The classification loss after processing this batch is:  0.13763412833213806\n",
      "The representation loss after processing this batch is:  0.0024492964148521423\n",
      "\n",
      "The classification loss after processing this batch is:  0.11144884675741196\n",
      "The representation loss after processing this batch is:  0.002453930675983429\n",
      "\n",
      "The classification loss after processing this batch is:  0.10880392044782639\n",
      "The representation loss after processing this batch is:  0.0023233890533447266\n",
      "\n",
      "The classification loss after processing this batch is:  0.057113900780677795\n",
      "The representation loss after processing this batch is:  0.002902798354625702\n",
      "\n",
      "The classification loss after processing this batch is:  0.049412891268730164\n",
      "The representation loss after processing this batch is:  0.0026262477040290833\n",
      "\n",
      "The classification loss after processing this batch is:  0.14811690151691437\n",
      "The representation loss after processing this batch is:  0.002241164445877075\n",
      "\n",
      "The classification loss after processing this batch is:  0.115993432700634\n",
      "The representation loss after processing this batch is:  0.0023663341999053955\n",
      "\n",
      "The classification loss after processing this batch is:  0.10598588734865189\n",
      "The representation loss after processing this batch is:  0.0024868398904800415\n",
      "\n",
      "The classification loss after processing this batch is:  0.11511240154504776\n",
      "The representation loss after processing this batch is:  0.002532750368118286\n",
      "\n",
      "The classification loss after processing this batch is:  0.09413982927799225\n",
      "The representation loss after processing this batch is:  0.0025600790977478027\n",
      "\n",
      "The classification loss after processing this batch is:  0.13423408567905426\n",
      "The representation loss after processing this batch is:  0.002394050359725952\n",
      "\n",
      "The classification loss after processing this batch is:  0.15671974420547485\n",
      "The representation loss after processing this batch is:  0.0025418177247047424\n",
      "\n",
      "The classification loss after processing this batch is:  0.20250311493873596\n",
      "The representation loss after processing this batch is:  0.0025081858038902283\n",
      "\n",
      "The classification loss after processing this batch is:  0.18915493786334991\n",
      "The representation loss after processing this batch is:  0.0023003704845905304\n",
      "\n",
      "The classification loss after processing this batch is:  0.07806957513093948\n",
      "The representation loss after processing this batch is:  0.002715788781642914\n",
      "\n",
      "The classification loss after processing this batch is:  0.0565725602209568\n",
      "The representation loss after processing this batch is:  0.002845779061317444\n",
      "\n",
      "The classification loss after processing this batch is:  0.10447262972593307\n",
      "The representation loss after processing this batch is:  0.002740476280450821\n",
      "\n",
      "The classification loss after processing this batch is:  0.11138240993022919\n",
      "The representation loss after processing this batch is:  0.0023595914244651794\n",
      "\n",
      "The classification loss after processing this batch is:  0.04325713962316513\n",
      "The representation loss after processing this batch is:  0.0024072788655757904\n",
      "\n",
      "The classification loss after processing this batch is:  0.05437999963760376\n",
      "The representation loss after processing this batch is:  0.0025408975780010223\n",
      "\n",
      "The classification loss after processing this batch is:  0.08901166915893555\n",
      "The representation loss after processing this batch is:  0.002272188663482666\n",
      "\n",
      "The classification loss after processing this batch is:  0.08262891322374344\n",
      "The representation loss after processing this batch is:  0.0026226043701171875\n",
      "\n",
      "The classification loss after processing this batch is:  0.07057135552167892\n",
      "The representation loss after processing this batch is:  0.0026207715272903442\n",
      "\n",
      "The classification loss after processing this batch is:  0.08165851980447769\n",
      "The representation loss after processing this batch is:  0.0023086071014404297\n",
      "\n",
      "The classification loss after processing this batch is:  0.0627720057964325\n",
      "The representation loss after processing this batch is:  0.0024439655244350433\n",
      "\n",
      "The classification loss after processing this batch is:  0.10666468739509583\n",
      "The representation loss after processing this batch is:  0.002883009612560272\n",
      "\n",
      "The classification loss after processing this batch is:  0.09314645081758499\n",
      "The representation loss after processing this batch is:  0.0023664049804210663\n",
      "\n",
      "The classification loss after processing this batch is:  0.15602940320968628\n",
      "The representation loss after processing this batch is:  0.002562887966632843\n",
      "\n",
      "The classification loss after processing this batch is:  0.027638396248221397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.00264904648065567\n",
      "\n",
      "The classification loss after processing this batch is:  0.047684576362371445\n",
      "The representation loss after processing this batch is:  0.00253305584192276\n",
      "\n",
      "The classification loss after processing this batch is:  0.14517413079738617\n",
      "The representation loss after processing this batch is:  0.002229921519756317\n",
      "\n",
      "The classification loss after processing this batch is:  0.1575734168291092\n",
      "The representation loss after processing this batch is:  0.0023317933082580566\n",
      "\n",
      "The classification loss after processing this batch is:  0.07757218927145004\n",
      "The representation loss after processing this batch is:  0.002302803099155426\n",
      "\n",
      "The classification loss after processing this batch is:  0.03497805446386337\n",
      "The representation loss after processing this batch is:  0.0022377632558345795\n",
      "\n",
      "The classification loss after processing this batch is:  0.12222714722156525\n",
      "The representation loss after processing this batch is:  0.0020258910953998566\n",
      "\n",
      "The classification loss after processing this batch is:  0.025694219395518303\n",
      "The representation loss after processing this batch is:  0.0026246458292007446\n",
      "\n",
      "The classification loss after processing this batch is:  0.1357121616601944\n",
      "The representation loss after processing this batch is:  0.002357274293899536\n",
      "\n",
      "The classification loss after processing this batch is:  0.12206343561410904\n",
      "The representation loss after processing this batch is:  0.002573348581790924\n",
      "\n",
      "The classification loss after processing this batch is:  0.06768177449703217\n",
      "The representation loss after processing this batch is:  0.002316877245903015\n",
      "\n",
      "The classification loss after processing this batch is:  0.08286947757005692\n",
      "The representation loss after processing this batch is:  0.0025972574949264526\n",
      "\n",
      "The classification loss after processing this batch is:  0.07880175113677979\n",
      "The representation loss after processing this batch is:  0.002629421651363373\n",
      "\n",
      "The classification loss after processing this batch is:  0.03800119459629059\n",
      "The representation loss after processing this batch is:  0.00237080454826355\n",
      "\n",
      "The classification loss after processing this batch is:  0.21540848910808563\n",
      "The representation loss after processing this batch is:  0.002363428473472595\n",
      "\n",
      "The classification loss after processing this batch is:  0.20376048982143402\n",
      "The representation loss after processing this batch is:  0.0023523233830928802\n",
      "\n",
      "The classification loss after processing this batch is:  0.18953832983970642\n",
      "The representation loss after processing this batch is:  0.002489708364009857\n",
      "\n",
      "The classification loss after processing this batch is:  0.19811893999576569\n",
      "The representation loss after processing this batch is:  0.0023019686341285706\n",
      "\n",
      "The classification loss after processing this batch is:  0.11480424553155899\n",
      "The representation loss after processing this batch is:  0.0025535374879837036\n",
      "\n",
      "The classification loss after processing this batch is:  0.06680445373058319\n",
      "The representation loss after processing this batch is:  0.002554759383201599\n",
      "\n",
      "The classification loss after processing this batch is:  0.16334836184978485\n",
      "The representation loss after processing this batch is:  0.0024293065071105957\n",
      "\n",
      "The classification loss after processing this batch is:  0.10743023455142975\n",
      "The representation loss after processing this batch is:  0.002573702484369278\n",
      "\n",
      "The classification loss after processing this batch is:  0.16094376146793365\n",
      "The representation loss after processing this batch is:  0.002528466284275055\n",
      "\n",
      "The classification loss after processing this batch is:  0.09493093937635422\n",
      "The representation loss after processing this batch is:  0.0026239529252052307\n",
      "\n",
      "The classification loss after processing this batch is:  0.15450353920459747\n",
      "The representation loss after processing this batch is:  0.0024525150656700134\n",
      "\n",
      "The classification loss after processing this batch is:  0.06826239079236984\n",
      "The representation loss after processing this batch is:  0.0025368593633174896\n",
      "\n",
      "The classification loss after processing this batch is:  0.07038775831460953\n",
      "The representation loss after processing this batch is:  0.0024400800466537476\n",
      "\n",
      "The classification loss after processing this batch is:  0.13463880121707916\n",
      "The representation loss after processing this batch is:  0.002352021634578705\n",
      "\n",
      "The classification loss after processing this batch is:  0.03424718230962753\n",
      "The representation loss after processing this batch is:  0.002749986946582794\n",
      "\n",
      "The classification loss after processing this batch is:  0.05011618509888649\n",
      "The representation loss after processing this batch is:  0.0026133880019187927\n",
      "\n",
      "The classification loss after processing this batch is:  0.09970119595527649\n",
      "The representation loss after processing this batch is:  0.002394437789916992\n",
      "\n",
      "The classification loss after processing this batch is:  0.20048905909061432\n",
      "The representation loss after processing this batch is:  0.0023916885256767273\n",
      "\n",
      "The classification loss after processing this batch is:  0.039531052112579346\n",
      "The representation loss after processing this batch is:  0.002204492688179016\n",
      "\n",
      "The classification loss after processing this batch is:  0.06301213800907135\n",
      "The representation loss after processing this batch is:  0.0022710002958774567\n",
      "\n",
      "The classification loss after processing this batch is:  0.13684304058551788\n",
      "The representation loss after processing this batch is:  0.00237322598695755\n",
      "\n",
      "The classification loss after processing this batch is:  0.20635385811328888\n",
      "The representation loss after processing this batch is:  0.002268463373184204\n",
      "\n",
      "The classification loss after processing this batch is:  0.09033501893281937\n",
      "The representation loss after processing this batch is:  0.0024130791425704956\n",
      "\n",
      "The classification loss after processing this batch is:  0.18331323564052582\n",
      "The representation loss after processing this batch is:  0.002228669822216034\n",
      "\n",
      "The classification loss after processing this batch is:  0.0721692219376564\n",
      "The representation loss after processing this batch is:  0.002832569181919098\n",
      "\n",
      "The classification loss after processing this batch is:  0.023624248802661896\n",
      "The representation loss after processing this batch is:  0.00220562145113945\n",
      "\n",
      "The classification loss after processing this batch is:  0.030187133699655533\n",
      "The representation loss after processing this batch is:  0.002391524612903595\n",
      "\n",
      "The classification loss after processing this batch is:  0.15347303450107574\n",
      "The representation loss after processing this batch is:  0.002716630697250366\n",
      "\n",
      "The classification loss after processing this batch is:  0.13376624882221222\n",
      "The representation loss after processing this batch is:  0.0027261674404144287\n",
      "\n",
      "The classification loss after processing this batch is:  0.08871753513813019\n",
      "The representation loss after processing this batch is:  0.0031244084239006042\n",
      "\n",
      "The classification loss after processing this batch is:  0.09542204439640045\n",
      "The representation loss after processing this batch is:  0.0024054646492004395\n",
      "\n",
      "The classification loss after processing this batch is:  0.09201925247907639\n",
      "The representation loss after processing this batch is:  0.0023555532097816467\n",
      "\n",
      "The classification loss after processing this batch is:  0.11468758434057236\n",
      "The representation loss after processing this batch is:  0.0023856088519096375\n",
      "\n",
      "The classification loss after processing this batch is:  0.09979290515184402\n",
      "The representation loss after processing this batch is:  0.00206167995929718\n",
      "\n",
      "The classification loss after processing this batch is:  0.14293353259563446\n",
      "The representation loss after processing this batch is:  0.0023659951984882355\n",
      "\n",
      "The classification loss after processing this batch is:  0.13259665668010712\n",
      "The representation loss after processing this batch is:  0.002766616642475128\n",
      "\n",
      "The classification loss after processing this batch is:  0.2484915554523468\n",
      "The representation loss after processing this batch is:  0.002252589911222458\n",
      "\n",
      "The classification loss after processing this batch is:  0.11963499337434769\n",
      "The representation loss after processing this batch is:  0.0022560954093933105\n",
      "\n",
      "The classification loss after processing this batch is:  0.12111957371234894\n",
      "The representation loss after processing this batch is:  0.0024342238903045654\n",
      "\n",
      "The classification loss after processing this batch is:  0.14974604547023773\n",
      "The representation loss after processing this batch is:  0.0023571550846099854\n",
      "\n",
      "The classification loss after processing this batch is:  0.05632654204964638\n",
      "The representation loss after processing this batch is:  0.002436622977256775\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.09214124083518982\n",
      "The representation loss after processing this batch is:  0.0031027309596538544\n",
      "\n",
      "The classification loss after processing this batch is:  0.06564170122146606\n",
      "The representation loss after processing this batch is:  0.0026777461171150208\n",
      "\n",
      "The classification loss after processing this batch is:  0.1412343531847\n",
      "The representation loss after processing this batch is:  0.0024604685604572296\n",
      "\n",
      "The classification loss after processing this batch is:  0.06907260417938232\n",
      "The representation loss after processing this batch is:  0.002042662352323532\n",
      "\n",
      "The classification loss after processing this batch is:  0.0999278724193573\n",
      "The representation loss after processing this batch is:  0.002339717000722885\n",
      "\n",
      "The classification loss after processing this batch is:  0.10062321275472641\n",
      "The representation loss after processing this batch is:  0.0024900510907173157\n",
      "\n",
      "The classification loss after processing this batch is:  0.12983755767345428\n",
      "The representation loss after processing this batch is:  0.0022733286023139954\n",
      "\n",
      "The classification loss after processing this batch is:  0.11954327672719955\n",
      "The representation loss after processing this batch is:  0.0025411248207092285\n",
      "\n",
      "The classification loss after processing this batch is:  0.18982137739658356\n",
      "The representation loss after processing this batch is:  0.0024277567863464355\n",
      "\n",
      "The classification loss after processing this batch is:  0.09132160246372223\n",
      "The representation loss after processing this batch is:  0.0028150975704193115\n",
      "\n",
      "The classification loss after processing this batch is:  0.09103512018918991\n",
      "The representation loss after processing this batch is:  0.002182096242904663\n",
      "\n",
      "The classification loss after processing this batch is:  0.09625812619924545\n",
      "The representation loss after processing this batch is:  0.002529434859752655\n",
      "\n",
      "The classification loss after processing this batch is:  0.22357895970344543\n",
      "The representation loss after processing this batch is:  0.0028364211320877075\n",
      "\n",
      "The classification loss after processing this batch is:  0.24010157585144043\n",
      "The representation loss after processing this batch is:  0.002701103687286377\n",
      "\n",
      "The classification loss after processing this batch is:  0.03773696348071098\n",
      "The representation loss after processing this batch is:  0.0021588020026683807\n",
      "\n",
      "The classification loss after processing this batch is:  0.04572528600692749\n",
      "The representation loss after processing this batch is:  0.0027426481246948242\n",
      "\n",
      "The classification loss after processing this batch is:  0.1987326592206955\n",
      "The representation loss after processing this batch is:  0.00252382829785347\n",
      "\n",
      "The classification loss after processing this batch is:  0.06418673694133759\n",
      "The representation loss after processing this batch is:  0.0027196258306503296\n",
      "\n",
      "The classification loss after processing this batch is:  0.06393669545650482\n",
      "The representation loss after processing this batch is:  0.0023926421999931335\n",
      "\n",
      "The classification loss after processing this batch is:  0.1158028393983841\n",
      "The representation loss after processing this batch is:  0.0022911131381988525\n",
      "\n",
      "The classification loss after processing this batch is:  0.08451219648122787\n",
      "The representation loss after processing this batch is:  0.002739701420068741\n",
      "\n",
      "The classification loss after processing this batch is:  0.22345773875713348\n",
      "The representation loss after processing this batch is:  0.0027536675333976746\n",
      "\n",
      "The classification loss after processing this batch is:  0.12586519122123718\n",
      "The representation loss after processing this batch is:  0.002807438373565674\n",
      "\n",
      "The classification loss after processing this batch is:  0.12421978265047073\n",
      "The representation loss after processing this batch is:  0.003046005964279175\n",
      "\n",
      "The classification loss after processing this batch is:  0.07509830594062805\n",
      "The representation loss after processing this batch is:  0.0020738989114761353\n",
      "\n",
      "The classification loss after processing this batch is:  0.1706089824438095\n",
      "The representation loss after processing this batch is:  0.0023471899330615997\n",
      "\n",
      "The classification loss after processing this batch is:  0.041392430663108826\n",
      "The representation loss after processing this batch is:  0.002382330596446991\n",
      "\n",
      "The classification loss after processing this batch is:  0.0455193929374218\n",
      "The representation loss after processing this batch is:  0.002584405243396759\n",
      "\n",
      "The classification loss after processing this batch is:  0.10371585190296173\n",
      "The representation loss after processing this batch is:  0.002322632819414139\n",
      "\n",
      "The classification loss after processing this batch is:  0.050036899745464325\n",
      "The representation loss after processing this batch is:  0.0024325624108314514\n",
      "\n",
      "The classification loss after processing this batch is:  0.05979446321725845\n",
      "The representation loss after processing this batch is:  0.002780534327030182\n",
      "\n",
      "The classification loss after processing this batch is:  0.0434885248541832\n",
      "The representation loss after processing this batch is:  0.0025880448520183563\n",
      "\n",
      "The classification loss after processing this batch is:  0.08095798641443253\n",
      "The representation loss after processing this batch is:  0.0024309754371643066\n",
      "\n",
      "The classification loss after processing this batch is:  0.09730271995067596\n",
      "The representation loss after processing this batch is:  0.0024803541600704193\n",
      "\n",
      "The classification loss after processing this batch is:  0.11854097247123718\n",
      "The representation loss after processing this batch is:  0.0026323720812797546\n",
      "\n",
      "The classification loss after processing this batch is:  0.16100896894931793\n",
      "The representation loss after processing this batch is:  0.0023067258298397064\n",
      "\n",
      "The classification loss after processing this batch is:  0.1446858048439026\n",
      "The representation loss after processing this batch is:  0.002971433103084564\n",
      "\n",
      "The classification loss after processing this batch is:  0.20714148879051208\n",
      "The representation loss after processing this batch is:  0.002568494528532028\n",
      "\n",
      "The classification loss after processing this batch is:  0.040678925812244415\n",
      "The representation loss after processing this batch is:  0.0023393817245960236\n",
      "\n",
      "The classification loss after processing this batch is:  0.16190578043460846\n",
      "The representation loss after processing this batch is:  0.0024235397577285767\n",
      "\n",
      "The classification loss after processing this batch is:  0.2545427680015564\n",
      "The representation loss after processing this batch is:  0.002592898905277252\n",
      "\n",
      "The classification loss after processing this batch is:  0.10531540960073471\n",
      "The representation loss after processing this batch is:  0.0021578818559646606\n",
      "\n",
      "The classification loss after processing this batch is:  0.13864269852638245\n",
      "The representation loss after processing this batch is:  0.002424236387014389\n",
      "\n",
      "The classification loss after processing this batch is:  0.14712874591350555\n",
      "The representation loss after processing this batch is:  0.002372950315475464\n",
      "\n",
      "The classification loss after processing this batch is:  0.1515808403491974\n",
      "The representation loss after processing this batch is:  0.0023434944450855255\n",
      "\n",
      "The classification loss after processing this batch is:  0.114447221159935\n",
      "The representation loss after processing this batch is:  0.0026085898280143738\n",
      "\n",
      "The classification loss after processing this batch is:  0.08468780666589737\n",
      "The representation loss after processing this batch is:  0.0023606866598129272\n",
      "\n",
      "The classification loss after processing this batch is:  0.08623065054416656\n",
      "The representation loss after processing this batch is:  0.002544216811656952\n",
      "\n",
      "The classification loss after processing this batch is:  0.04603218287229538\n",
      "The representation loss after processing this batch is:  0.0024792924523353577\n",
      "\n",
      "The classification loss after processing this batch is:  0.03913428261876106\n",
      "The representation loss after processing this batch is:  0.0022889375686645508\n",
      "\n",
      "The classification loss after processing this batch is:  0.10322859138250351\n",
      "The representation loss after processing this batch is:  0.002724982798099518\n",
      "\n",
      "The classification loss after processing this batch is:  0.04389134421944618\n",
      "The representation loss after processing this batch is:  0.002594277262687683\n",
      "\n",
      "The classification loss after processing this batch is:  0.21377722918987274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation loss after processing this batch is:  0.003004875034093857\n",
      "\n",
      "The classification loss after processing this batch is:  0.13370420038700104\n",
      "The representation loss after processing this batch is:  0.0022911056876182556\n",
      "\n",
      "The classification loss after processing this batch is:  0.17315511405467987\n",
      "The representation loss after processing this batch is:  0.0027428939938545227\n",
      "\n",
      "The classification loss after processing this batch is:  0.30677953362464905\n",
      "The representation loss after processing this batch is:  0.0021942369639873505\n",
      "\n",
      "The classification loss after processing this batch is:  0.12370338290929794\n",
      "The representation loss after processing this batch is:  0.0024127066135406494\n",
      "\n",
      "The classification loss after processing this batch is:  0.03831086680293083\n",
      "The representation loss after processing this batch is:  0.0023250430822372437\n",
      "\n",
      "The classification loss after processing this batch is:  0.06393828988075256\n",
      "The representation loss after processing this batch is:  0.0026889070868492126\n",
      "\n",
      "The classification loss after processing this batch is:  0.06956835836172104\n",
      "The representation loss after processing this batch is:  0.0026880651712417603\n",
      "\n",
      "The classification loss after processing this batch is:  0.073525071144104\n",
      "The representation loss after processing this batch is:  0.002633199095726013\n",
      "\n",
      "The classification loss after processing this batch is:  0.08671578764915466\n",
      "The representation loss after processing this batch is:  0.0021657682955265045\n",
      "\n",
      "The classification loss after processing this batch is:  0.21674060821533203\n",
      "The representation loss after processing this batch is:  0.0022605545818805695\n",
      "\n",
      "The classification loss after processing this batch is:  0.16932789981365204\n",
      "The representation loss after processing this batch is:  0.0022449269890785217\n",
      "\n",
      "The classification loss after processing this batch is:  0.14646963775157928\n",
      "The representation loss after processing this batch is:  0.0027626678347587585\n",
      "\n",
      "The classification loss after processing this batch is:  0.1994868665933609\n",
      "The representation loss after processing this batch is:  0.0028164759278297424\n",
      "\n",
      "The classification loss after processing this batch is:  0.08445677161216736\n",
      "The representation loss after processing this batch is:  0.00236385315656662\n",
      "\n",
      "The classification loss after processing this batch is:  0.10258809477090836\n",
      "The representation loss after processing this batch is:  0.002483520656824112\n",
      "\n",
      "The classification loss after processing this batch is:  0.17809642851352692\n",
      "The representation loss after processing this batch is:  0.0023445896804332733\n",
      "\n",
      "The classification loss after processing this batch is:  0.0965401753783226\n",
      "The representation loss after processing this batch is:  0.002789907157421112\n",
      "\n",
      "The classification loss after processing this batch is:  0.14326094090938568\n",
      "The representation loss after processing this batch is:  0.003289349377155304\n",
      "\n",
      "The classification loss after processing this batch is:  0.06709010899066925\n",
      "The representation loss after processing this batch is:  0.0027477331459522247\n",
      "\n",
      "The classification loss after processing this batch is:  0.1284710168838501\n",
      "The representation loss after processing this batch is:  0.0031267330050468445\n",
      "\n",
      "The classification loss after processing this batch is:  0.16731461882591248\n",
      "The representation loss after processing this batch is:  0.002797003835439682\n",
      "\n",
      "The classification loss after processing this batch is:  0.08749905228614807\n",
      "The representation loss after processing this batch is:  0.002708129584789276\n",
      "\n",
      "The classification loss after processing this batch is:  0.1400027871131897\n",
      "The representation loss after processing this batch is:  0.00293683260679245\n",
      "\n",
      "The classification loss after processing this batch is:  0.18591628968715668\n",
      "The representation loss after processing this batch is:  0.0021178722381591797\n",
      "\n",
      "The classification loss after processing this batch is:  0.10254089534282684\n",
      "The representation loss after processing this batch is:  0.00243426114320755\n",
      "\n",
      "The classification loss after processing this batch is:  0.13809815049171448\n",
      "The representation loss after processing this batch is:  0.0023858249187469482\n",
      "\n",
      "The classification loss after processing this batch is:  0.06730486452579498\n",
      "The representation loss after processing this batch is:  0.002978481352329254\n",
      "\n",
      "The classification loss after processing this batch is:  0.02228468284010887\n",
      "The representation loss after processing this batch is:  0.0027672946453094482\n",
      "\n",
      "The classification loss after processing this batch is:  0.09302544593811035\n",
      "The representation loss after processing this batch is:  0.0026911720633506775\n",
      "\n",
      "The classification loss after processing this batch is:  0.06389495730400085\n",
      "The representation loss after processing this batch is:  0.0027765557169914246\n",
      "\n",
      "The classification loss after processing this batch is:  0.24569417536258698\n",
      "The representation loss after processing this batch is:  0.00240490585565567\n",
      "\n",
      "The classification loss after processing this batch is:  0.04497525468468666\n",
      "The representation loss after processing this batch is:  0.002532854676246643\n",
      "\n",
      "The classification loss after processing this batch is:  0.08943574130535126\n",
      "The representation loss after processing this batch is:  0.0023925676941871643\n",
      "\n",
      "The classification loss after processing this batch is:  0.1263672411441803\n",
      "The representation loss after processing this batch is:  0.002501577138900757\n",
      "\n",
      "The classification loss after processing this batch is:  0.09707877039909363\n",
      "The representation loss after processing this batch is:  0.002483069896697998\n",
      "\n",
      "The classification loss after processing this batch is:  0.10762675106525421\n",
      "The representation loss after processing this batch is:  0.0025549232959747314\n",
      "\n",
      "The classification loss after processing this batch is:  0.0504203662276268\n",
      "The representation loss after processing this batch is:  0.0025522708892822266\n",
      "\n",
      "The classification loss after processing this batch is:  0.044582486152648926\n",
      "The representation loss after processing this batch is:  0.0025246813893318176\n",
      "\n",
      "The classification loss after processing this batch is:  0.07228133082389832\n",
      "The representation loss after processing this batch is:  0.0025999881327152252\n",
      "\n",
      "The classification loss after processing this batch is:  0.17152608931064606\n",
      "The representation loss after processing this batch is:  0.003030247986316681\n",
      "\n",
      "The classification loss after processing this batch is:  0.19680310785770416\n",
      "The representation loss after processing this batch is:  0.0025150254368782043\n",
      "\n",
      "The classification loss after processing this batch is:  0.11487974226474762\n",
      "The representation loss after processing this batch is:  0.002071145921945572\n",
      "\n",
      "The classification loss after processing this batch is:  0.14667755365371704\n",
      "The representation loss after processing this batch is:  0.002518337219953537\n",
      "\n",
      "The classification loss after processing this batch is:  0.22101902961730957\n",
      "The representation loss after processing this batch is:  0.002256680279970169\n",
      "\n",
      "The classification loss after processing this batch is:  0.09388788044452667\n",
      "The representation loss after processing this batch is:  0.0026897042989730835\n",
      "\n",
      "The classification loss after processing this batch is:  0.21103669703006744\n",
      "The representation loss after processing this batch is:  0.0025981441140174866\n",
      "\n",
      "The classification loss after processing this batch is:  0.08320679515600204\n",
      "The representation loss after processing this batch is:  0.0026611462235450745\n",
      "\n",
      "The classification loss after processing this batch is:  0.07094549387693405\n",
      "The representation loss after processing this batch is:  0.002341337502002716\n",
      "\n",
      "The classification loss after processing this batch is:  0.05900835990905762\n",
      "The representation loss after processing this batch is:  0.0023964717984199524\n",
      "\n",
      "The classification loss after processing this batch is:  0.06728091090917587\n",
      "The representation loss after processing this batch is:  0.0024832338094711304\n",
      "\n",
      "The classification loss after processing this batch is:  0.25208503007888794\n",
      "The representation loss after processing this batch is:  0.0025334134697914124\n",
      "\n",
      "The classification loss after processing this batch is:  0.07105071097612381\n",
      "The representation loss after processing this batch is:  0.0024144574999809265\n",
      "\n",
      "The classification loss after processing this batch is:  0.13795804977416992\n",
      "The representation loss after processing this batch is:  0.002841748297214508\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1183241754770279\n",
      "The representation loss after processing this batch is:  0.0028095394372940063\n",
      "\n",
      "The classification loss after processing this batch is:  0.09422032535076141\n",
      "The representation loss after processing this batch is:  0.0026181116700172424\n",
      "\n",
      "The classification loss after processing this batch is:  0.07071932405233383\n",
      "The representation loss after processing this batch is:  0.0025211796164512634\n",
      "\n",
      "The classification loss after processing this batch is:  0.15780504047870636\n",
      "The representation loss after processing this batch is:  0.002373121678829193\n",
      "\n",
      "The classification loss after processing this batch is:  0.19108626246452332\n",
      "The representation loss after processing this batch is:  0.002400677651166916\n",
      "\n",
      "The classification loss after processing this batch is:  0.15725499391555786\n",
      "The representation loss after processing this batch is:  0.0029060691595077515\n",
      "\n",
      "The classification loss after processing this batch is:  0.06381981819868088\n",
      "The representation loss after processing this batch is:  0.0024983659386634827\n",
      "\n",
      "The classification loss after processing this batch is:  0.3105316758155823\n",
      "The representation loss after processing this batch is:  0.002257205545902252\n",
      "\n",
      "The classification loss after processing this batch is:  0.0671560987830162\n",
      "The representation loss after processing this batch is:  0.0022030994296073914\n",
      "\n",
      "The classification loss after processing this batch is:  0.07256825268268585\n",
      "The representation loss after processing this batch is:  0.0022881031036376953\n",
      "\n",
      "The classification loss after processing this batch is:  0.12046966701745987\n",
      "The representation loss after processing this batch is:  0.002705097198486328\n",
      "\n",
      "The classification loss after processing this batch is:  0.08451003581285477\n",
      "The representation loss after processing this batch is:  0.0024270787835121155\n",
      "\n",
      "The classification loss after processing this batch is:  0.09237562119960785\n",
      "The representation loss after processing this batch is:  0.0024612918496131897\n",
      "\n",
      "The classification loss after processing this batch is:  0.07487208396196365\n",
      "The representation loss after processing this batch is:  0.0027894750237464905\n",
      "\n",
      "The classification loss after processing this batch is:  0.16158056259155273\n",
      "The representation loss after processing this batch is:  0.0025124289095401764\n",
      "\n",
      "The classification loss after processing this batch is:  0.17617447674274445\n",
      "The representation loss after processing this batch is:  0.002507448196411133\n",
      "\n",
      "The classification loss after processing this batch is:  0.14839135110378265\n",
      "The representation loss after processing this batch is:  0.002411767840385437\n",
      "\n",
      "The classification loss after processing this batch is:  0.11132337152957916\n",
      "The representation loss after processing this batch is:  0.0027527660131454468\n",
      "\n",
      "The classification loss after processing this batch is:  0.11124231666326523\n",
      "The representation loss after processing this batch is:  0.0031197071075439453\n",
      "\n",
      "The classification loss after processing this batch is:  0.1349397748708725\n",
      "The representation loss after processing this batch is:  0.002269495278596878\n",
      "\n",
      "The classification loss after processing this batch is:  0.1257990300655365\n",
      "The representation loss after processing this batch is:  0.0022814981639385223\n",
      "\n",
      "The classification loss after processing this batch is:  0.019301820546388626\n",
      "The representation loss after processing this batch is:  0.0026272758841514587\n",
      "\n",
      "The classification loss after processing this batch is:  0.09836295247077942\n",
      "The representation loss after processing this batch is:  0.002252090722322464\n",
      "\n",
      "The classification loss after processing this batch is:  0.21720625460147858\n",
      "The representation loss after processing this batch is:  0.0025478415191173553\n",
      "\n",
      "The classification loss after processing this batch is:  0.2831045389175415\n",
      "The representation loss after processing this batch is:  0.0025654062628746033\n",
      "\n",
      "The classification loss after processing this batch is:  0.2149701863527298\n",
      "The representation loss after processing this batch is:  0.0022693052887916565\n",
      "\n",
      "The classification loss after processing this batch is:  0.16032861173152924\n",
      "The representation loss after processing this batch is:  0.002175748348236084\n",
      "\n",
      "The classification loss after processing this batch is:  0.037892818450927734\n",
      "The representation loss after processing this batch is:  0.002399485558271408\n",
      "\n",
      "The classification loss after processing this batch is:  0.09673937410116196\n",
      "The representation loss after processing this batch is:  0.002240993082523346\n",
      "\n",
      "The classification loss after processing this batch is:  0.10541796684265137\n",
      "The representation loss after processing this batch is:  0.0027564242482185364\n",
      "\n",
      "The classification loss after processing this batch is:  0.16152264177799225\n",
      "The representation loss after processing this batch is:  0.0027306675910949707\n",
      "\n",
      "The classification loss after processing this batch is:  0.15026967227458954\n",
      "The representation loss after processing this batch is:  0.002650901675224304\n",
      "\n",
      "The classification loss after processing this batch is:  0.12481582909822464\n",
      "The representation loss after processing this batch is:  0.002816610038280487\n",
      "\n",
      "The classification loss after processing this batch is:  0.08205828070640564\n",
      "The representation loss after processing this batch is:  0.002491988241672516\n",
      "\n",
      "The classification loss after processing this batch is:  0.09640657901763916\n",
      "The representation loss after processing this batch is:  0.002459302544593811\n",
      "\n",
      "The classification loss after processing this batch is:  0.15676727890968323\n",
      "The representation loss after processing this batch is:  0.0027277469635009766\n",
      "\n",
      "The classification loss after processing this batch is:  0.14128753542900085\n",
      "The representation loss after processing this batch is:  0.0025294944643974304\n",
      "\n",
      "The classification loss after processing this batch is:  0.09261879324913025\n",
      "The representation loss after processing this batch is:  0.0021016746759414673\n",
      "\n",
      "The classification loss after processing this batch is:  0.22017352283000946\n",
      "The representation loss after processing this batch is:  0.003190338611602783\n",
      "\n",
      "The classification loss after processing this batch is:  0.3065882623195648\n",
      "The representation loss after processing this batch is:  0.0027248188853263855\n",
      "\n",
      "The classification loss after processing this batch is:  0.15334109961986542\n",
      "The representation loss after processing this batch is:  0.0028603598475456238\n",
      "\n",
      "The classification loss after processing this batch is:  0.100312240421772\n",
      "The representation loss after processing this batch is:  0.002597019076347351\n",
      "\n",
      "The classification loss after processing this batch is:  0.0763125866651535\n",
      "The representation loss after processing this batch is:  0.002795279026031494\n",
      "\n",
      "The classification loss after processing this batch is:  0.036596231162548065\n",
      "The representation loss after processing this batch is:  0.0025036856532096863\n",
      "\n",
      "The classification loss after processing this batch is:  0.16991037130355835\n",
      "The representation loss after processing this batch is:  0.002406209707260132\n",
      "\n",
      "The classification loss after processing this batch is:  0.14101916551589966\n",
      "The representation loss after processing this batch is:  0.0027835145592689514\n",
      "\n",
      "The classification loss after processing this batch is:  0.09972354024648666\n",
      "The representation loss after processing this batch is:  0.002970091998577118\n",
      "\n",
      "The classification loss after processing this batch is:  0.22680656611919403\n",
      "The representation loss after processing this batch is:  0.002538636326789856\n",
      "\n",
      "The classification loss after processing this batch is:  0.04863613843917847\n",
      "The representation loss after processing this batch is:  0.002551548182964325\n",
      "\n",
      "The classification loss after processing this batch is:  0.052763938903808594\n",
      "The representation loss after processing this batch is:  0.0027670711278915405\n",
      "\n",
      "The classification loss after processing this batch is:  0.09058057516813278\n",
      "The representation loss after processing this batch is:  0.002460859715938568\n",
      "\n",
      "The classification loss after processing this batch is:  0.09906337410211563\n",
      "The representation loss after processing this batch is:  0.0024235881865024567\n",
      "\n",
      "The classification loss after processing this batch is:  0.13364531099796295\n",
      "The representation loss after processing this batch is:  0.002848796546459198\n",
      "\n",
      "The classification loss after processing this batch is:  0.11175625771284103\n",
      "The representation loss after processing this batch is:  0.002491310238838196\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10397429764270782\n",
      "The representation loss after processing this batch is:  0.00258471816778183\n",
      "\n",
      "The classification loss after processing this batch is:  0.0518965870141983\n",
      "The representation loss after processing this batch is:  0.002579338848590851\n",
      "\n",
      "The classification loss after processing this batch is:  0.047918159514665604\n",
      "The representation loss after processing this batch is:  0.0024826303124427795\n",
      "\n",
      "The classification loss after processing this batch is:  0.07463869452476501\n",
      "The representation loss after processing this batch is:  0.002688869833946228\n",
      "\n",
      "The classification loss after processing this batch is:  0.042812932282686234\n",
      "The representation loss after processing this batch is:  0.002646900713443756\n",
      "\n",
      "The classification loss after processing this batch is:  0.08540376275777817\n",
      "The representation loss after processing this batch is:  0.002219412475824356\n",
      "\n",
      "The classification loss after processing this batch is:  0.1492862105369568\n",
      "The representation loss after processing this batch is:  0.002345249056816101\n",
      "\n",
      "The classification loss after processing this batch is:  0.18124471604824066\n",
      "The representation loss after processing this batch is:  0.00276811420917511\n",
      "\n",
      "The classification loss after processing this batch is:  0.039049182087183\n",
      "The representation loss after processing this batch is:  0.0021271072328090668\n",
      "\n",
      "The classification loss after processing this batch is:  0.05311662331223488\n",
      "The representation loss after processing this batch is:  0.0023769065737724304\n",
      "\n",
      "The classification loss after processing this batch is:  0.10071448981761932\n",
      "The representation loss after processing this batch is:  0.002889573574066162\n",
      "\n",
      "The classification loss after processing this batch is:  0.15264418721199036\n",
      "The representation loss after processing this batch is:  0.0024703554809093475\n",
      "\n",
      "The classification loss after processing this batch is:  0.05006895586848259\n",
      "The representation loss after processing this batch is:  0.002879314124584198\n",
      "\n",
      "The classification loss after processing this batch is:  0.155504047870636\n",
      "The representation loss after processing this batch is:  0.0031817182898521423\n",
      "\n",
      "The classification loss after processing this batch is:  0.17198355495929718\n",
      "The representation loss after processing this batch is:  0.0025104135274887085\n",
      "\n",
      "The classification loss after processing this batch is:  0.1983986347913742\n",
      "The representation loss after processing this batch is:  0.0025836266577243805\n",
      "\n",
      "The classification loss after processing this batch is:  0.09485448151826859\n",
      "The representation loss after processing this batch is:  0.0024342387914657593\n",
      "\n",
      "The classification loss after processing this batch is:  0.05773841589689255\n",
      "The representation loss after processing this batch is:  0.0024894773960113525\n",
      "\n",
      "The classification loss after processing this batch is:  0.08473954349756241\n",
      "The representation loss after processing this batch is:  0.0024247244000434875\n",
      "\n",
      "The classification loss after processing this batch is:  0.14757995307445526\n",
      "The representation loss after processing this batch is:  0.002539902925491333\n",
      "\n",
      "The classification loss after processing this batch is:  0.06187248229980469\n",
      "The representation loss after processing this batch is:  0.0026244372129440308\n",
      "\n",
      "The classification loss after processing this batch is:  0.029626348987221718\n",
      "The representation loss after processing this batch is:  0.0022743716835975647\n",
      "\n",
      "The classification loss after processing this batch is:  0.20673257112503052\n",
      "The representation loss after processing this batch is:  0.0025641396641731262\n",
      "\n",
      "The classification loss after processing this batch is:  0.1890745311975479\n",
      "The representation loss after processing this batch is:  0.0024343393743038177\n",
      "\n",
      "The classification loss after processing this batch is:  0.08030928671360016\n",
      "The representation loss after processing this batch is:  0.002228386700153351\n",
      "\n",
      "The classification loss after processing this batch is:  0.24056193232536316\n",
      "The representation loss after processing this batch is:  0.002360031008720398\n",
      "\n",
      "The classification loss after processing this batch is:  0.2112129181623459\n",
      "The representation loss after processing this batch is:  0.0025450214743614197\n",
      "\n",
      "The classification loss after processing this batch is:  0.27225902676582336\n",
      "The representation loss after processing this batch is:  0.0024965405464172363\n",
      "\n",
      "The classification loss after processing this batch is:  0.14586420357227325\n",
      "The representation loss after processing this batch is:  0.0024143680930137634\n",
      "\n",
      "The classification loss after processing this batch is:  0.07899047434329987\n",
      "The representation loss after processing this batch is:  0.002318471670150757\n",
      "\n",
      "The classification loss after processing this batch is:  0.14209073781967163\n",
      "The representation loss after processing this batch is:  0.0025384649634361267\n",
      "\n",
      "The classification loss after processing this batch is:  0.07376475632190704\n",
      "The representation loss after processing this batch is:  0.0025594905018806458\n",
      "\n",
      "The classification loss after processing this batch is:  0.06601656973361969\n",
      "The representation loss after processing this batch is:  0.002491287887096405\n",
      "\n",
      "The classification loss after processing this batch is:  0.06519200652837753\n",
      "The representation loss after processing this batch is:  0.00227457657456398\n",
      "\n",
      "The classification loss after processing this batch is:  0.050156425684690475\n",
      "The representation loss after processing this batch is:  0.002381548285484314\n",
      "\n",
      "The classification loss after processing this batch is:  0.02570635825395584\n",
      "The representation loss after processing this batch is:  0.0027133896946907043\n",
      "\n",
      "The classification loss after processing this batch is:  0.11803629994392395\n",
      "The representation loss after processing this batch is:  0.002680651843547821\n",
      "\n",
      "The classification loss after processing this batch is:  0.1508759707212448\n",
      "The representation loss after processing this batch is:  0.0023598000407218933\n",
      "\n",
      "The classification loss after processing this batch is:  0.0587211437523365\n",
      "The representation loss after processing this batch is:  0.0027596428990364075\n",
      "\n",
      "The classification loss after processing this batch is:  0.08053326606750488\n",
      "The representation loss after processing this batch is:  0.002299446612596512\n",
      "\n",
      "The classification loss after processing this batch is:  0.10153745114803314\n",
      "The representation loss after processing this batch is:  0.0024227797985076904\n",
      "\n",
      "The classification loss after processing this batch is:  0.026381604373455048\n",
      "The representation loss after processing this batch is:  0.002427242696285248\n",
      "\n",
      "The classification loss after processing this batch is:  0.17054830491542816\n",
      "The representation loss after processing this batch is:  0.0024994760751724243\n",
      "\n",
      "The classification loss after processing this batch is:  0.07936982065439224\n",
      "The representation loss after processing this batch is:  0.002348087728023529\n",
      "\n",
      "The classification loss after processing this batch is:  0.2433592826128006\n",
      "The representation loss after processing this batch is:  0.002441398799419403\n",
      "\n",
      "The classification loss after processing this batch is:  0.11800841242074966\n",
      "The representation loss after processing this batch is:  0.0024446845054626465\n",
      "\n",
      "The classification loss after processing this batch is:  0.12686048448085785\n",
      "The representation loss after processing this batch is:  0.0023251064121723175\n",
      "\n",
      "The classification loss after processing this batch is:  0.02923331968486309\n",
      "The representation loss after processing this batch is:  0.0025486350059509277\n",
      "\n",
      "The classification loss after processing this batch is:  0.04160682484507561\n",
      "The representation loss after processing this batch is:  0.0022364407777786255\n",
      "\n",
      "The classification loss after processing this batch is:  0.15335668623447418\n",
      "The representation loss after processing this batch is:  0.0023192279040813446\n",
      "\n",
      "The classification loss after processing this batch is:  0.058446697890758514\n",
      "The representation loss after processing this batch is:  0.0027044862508773804\n",
      "\n",
      "The classification loss after processing this batch is:  0.1056203544139862\n",
      "The representation loss after processing this batch is:  0.002518385648727417\n",
      "\n",
      "The classification loss after processing this batch is:  0.08292169868946075\n",
      "The representation loss after processing this batch is:  0.002641141414642334\n",
      "\n",
      "The classification loss after processing this batch is:  0.07188639789819717\n",
      "The representation loss after processing this batch is:  0.0028209909796714783\n",
      "\n",
      "The classification loss after processing this batch is:  0.13542023301124573\n",
      "The representation loss after processing this batch is:  0.0024230927228927612\n",
      "\n",
      "The classification loss after processing this batch is:  0.054871540516614914\n",
      "The representation loss after processing this batch is:  0.0026514604687690735\n",
      "\n",
      "The classification loss after processing this batch is:  0.1266692876815796\n",
      "The representation loss after processing this batch is:  0.0027009546756744385\n",
      "\n",
      "The classification loss after processing this batch is:  0.20233146846294403\n",
      "The representation loss after processing this batch is:  0.00250224769115448\n",
      "\n",
      "The classification loss after processing this batch is:  0.15597254037857056\n",
      "The representation loss after processing this batch is:  0.0027586668729782104\n",
      "\n",
      "The classification loss after processing this batch is:  0.19192463159561157\n",
      "The representation loss after processing this batch is:  0.0023777633905410767\n",
      "\n",
      "The classification loss after processing this batch is:  0.17668339610099792\n",
      "The representation loss after processing this batch is:  0.002600535750389099\n",
      "\n",
      "The classification loss after processing this batch is:  0.09634283185005188\n",
      "The representation loss after processing this batch is:  0.0022271275520324707\n",
      "\n",
      "The classification loss after processing this batch is:  0.075615294277668\n",
      "The representation loss after processing this batch is:  0.0023583248257637024\n",
      "\n",
      "The classification loss after processing this batch is:  0.05527467653155327\n",
      "The representation loss after processing this batch is:  0.00232696533203125\n",
      "\n",
      "The classification loss after processing this batch is:  0.08689992874860764\n",
      "The representation loss after processing this batch is:  0.0025268271565437317\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.04369744285941124\n",
      "The representation loss after processing this batch is:  0.0025526508688926697\n",
      "\n",
      "The classification loss after processing this batch is:  0.08623114973306656\n",
      "The representation loss after processing this batch is:  0.0021194443106651306\n",
      "\n",
      "The classification loss after processing this batch is:  0.09446705132722855\n",
      "The representation loss after processing this batch is:  0.0023629367351531982\n",
      "\n",
      "The classification loss after processing this batch is:  0.08794400840997696\n",
      "The representation loss after processing this batch is:  0.0028255581855773926\n",
      "\n",
      "The classification loss after processing this batch is:  0.06936012208461761\n",
      "The representation loss after processing this batch is:  0.002360813319683075\n",
      "\n",
      "The classification loss after processing this batch is:  0.13489873707294464\n",
      "The representation loss after processing this batch is:  0.002215065062046051\n",
      "\n",
      "The classification loss after processing this batch is:  0.061142366379499435\n",
      "The representation loss after processing this batch is:  0.0025453343987464905\n",
      "\n",
      "The classification loss after processing this batch is:  0.11715229600667953\n",
      "The representation loss after processing this batch is:  0.0024705007672309875\n",
      "\n",
      "The classification loss after processing this batch is:  0.12906450033187866\n",
      "The representation loss after processing this batch is:  0.002434954047203064\n",
      "\n",
      "The classification loss after processing this batch is:  0.0946291908621788\n",
      "The representation loss after processing this batch is:  0.0026277899742126465\n",
      "\n",
      "The classification loss after processing this batch is:  0.06213802471756935\n",
      "The representation loss after processing this batch is:  0.002714797854423523\n",
      "\n",
      "The classification loss after processing this batch is:  0.17000852525234222\n",
      "The representation loss after processing this batch is:  0.002427048981189728\n",
      "\n",
      "The classification loss after processing this batch is:  0.06491299718618393\n",
      "The representation loss after processing this batch is:  0.0025175735354423523\n",
      "\n",
      "The classification loss after processing this batch is:  0.05930285155773163\n",
      "The representation loss after processing this batch is:  0.002480633556842804\n",
      "\n",
      "The classification loss after processing this batch is:  0.10158658027648926\n",
      "The representation loss after processing this batch is:  0.0024636536836624146\n",
      "\n",
      "The classification loss after processing this batch is:  0.04812077805399895\n",
      "The representation loss after processing this batch is:  0.002624981105327606\n",
      "\n",
      "The classification loss after processing this batch is:  0.10882211476564407\n",
      "The representation loss after processing this batch is:  0.0022582337260246277\n",
      "\n",
      "The classification loss after processing this batch is:  0.1515970081090927\n",
      "The representation loss after processing this batch is:  0.0026501640677452087\n",
      "\n",
      "The classification loss after processing this batch is:  0.07665757834911346\n",
      "The representation loss after processing this batch is:  0.0027503743767738342\n",
      "\n",
      "The classification loss after processing this batch is:  0.08094720542430878\n",
      "The representation loss after processing this batch is:  0.0029382407665252686\n",
      "\n",
      "The classification loss after processing this batch is:  0.08201215416193008\n",
      "The representation loss after processing this batch is:  0.0025053173303604126\n",
      "\n",
      "The classification loss after processing this batch is:  0.23571665585041046\n",
      "The representation loss after processing this batch is:  0.0025965161621570587\n",
      "\n",
      "The classification loss after processing this batch is:  0.04431275278329849\n",
      "The representation loss after processing this batch is:  0.0024451538920402527\n",
      "\n",
      "The classification loss after processing this batch is:  0.07463947683572769\n",
      "The representation loss after processing this batch is:  0.0026489868760108948\n",
      "\n",
      "The classification loss after processing this batch is:  0.15784946084022522\n",
      "The representation loss after processing this batch is:  0.002226453274488449\n",
      "\n",
      "The classification loss after processing this batch is:  0.2978822588920593\n",
      "The representation loss after processing this batch is:  0.002617381513118744\n",
      "\n",
      "The classification loss after processing this batch is:  0.08670471608638763\n",
      "The representation loss after processing this batch is:  0.0023080110549926758\n",
      "\n",
      "The classification loss after processing this batch is:  0.10053513944149017\n",
      "The representation loss after processing this batch is:  0.0022968314588069916\n",
      "\n",
      "The classification loss after processing this batch is:  0.07773220539093018\n",
      "The representation loss after processing this batch is:  0.002493821084499359\n",
      "\n",
      "The classification loss after processing this batch is:  0.03375603258609772\n",
      "The representation loss after processing this batch is:  0.0024020448327064514\n",
      "\n",
      "The classification loss after processing this batch is:  0.12285976856946945\n",
      "The representation loss after processing this batch is:  0.002946898341178894\n",
      "\n",
      "The classification loss after processing this batch is:  0.0779467299580574\n",
      "The representation loss after processing this batch is:  0.003266662359237671\n",
      "\n",
      "The classification loss after processing this batch is:  0.04583223536610603\n",
      "The representation loss after processing this batch is:  0.0025956369936466217\n",
      "\n",
      "The classification loss after processing this batch is:  0.06249348446726799\n",
      "The representation loss after processing this batch is:  0.0023438408970832825\n",
      "\n",
      "The classification loss after processing this batch is:  0.1556949019432068\n",
      "The representation loss after processing this batch is:  0.002360556274652481\n",
      "\n",
      "The classification loss after processing this batch is:  0.12234249711036682\n",
      "The representation loss after processing this batch is:  0.002406895160675049\n",
      "\n",
      "The classification loss after processing this batch is:  0.0726851150393486\n",
      "The representation loss after processing this batch is:  0.0022134073078632355\n",
      "\n",
      "The classification loss after processing this batch is:  0.06568284332752228\n",
      "The representation loss after processing this batch is:  0.0026425719261169434\n",
      "\n",
      "The classification loss after processing this batch is:  0.1993989497423172\n",
      "The representation loss after processing this batch is:  0.002312310039997101\n",
      "\n",
      "The classification loss after processing this batch is:  0.1383359730243683\n",
      "The representation loss after processing this batch is:  0.0025035738945007324\n",
      "\n",
      "The classification loss after processing this batch is:  0.185459703207016\n",
      "The representation loss after processing this batch is:  0.002203516662120819\n",
      "\n",
      "The classification loss after processing this batch is:  0.12319297343492508\n",
      "The representation loss after processing this batch is:  0.0027294307947158813\n",
      "\n",
      "The classification loss after processing this batch is:  0.17021964490413666\n",
      "The representation loss after processing this batch is:  0.0024108663201332092\n",
      "\n",
      "The classification loss after processing this batch is:  0.08543781191110611\n",
      "The representation loss after processing this batch is:  0.0024737194180488586\n",
      "\n",
      "The classification loss after processing this batch is:  0.06430784612894058\n",
      "The representation loss after processing this batch is:  0.002771809697151184\n",
      "\n",
      "The classification loss after processing this batch is:  0.03509146347641945\n",
      "The representation loss after processing this batch is:  0.002331852912902832\n",
      "\n",
      "The classification loss after processing this batch is:  0.06379304081201553\n",
      "The representation loss after processing this batch is:  0.0023961588740348816\n",
      "\n",
      "The classification loss after processing this batch is:  0.19839639961719513\n",
      "The representation loss after processing this batch is:  0.0025465041399002075\n",
      "\n",
      "The classification loss after processing this batch is:  0.11851818114519119\n",
      "The representation loss after processing this batch is:  0.002856515347957611\n",
      "\n",
      "The classification loss after processing this batch is:  0.041460584849119186\n",
      "The representation loss after processing this batch is:  0.0022425279021263123\n",
      "\n",
      "The classification loss after processing this batch is:  0.029271738603711128\n",
      "The representation loss after processing this batch is:  0.002828747034072876\n",
      "\n",
      "The classification loss after processing this batch is:  0.028207866474986076\n",
      "The representation loss after processing this batch is:  0.0029415860772132874\n",
      "\n",
      "The classification loss after processing this batch is:  0.05717367306351662\n",
      "The representation loss after processing this batch is:  0.0032786205410957336\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.06839756667613983\n",
      "The representation loss after processing this batch is:  0.002766355872154236\n",
      "\n",
      "The classification loss after processing this batch is:  0.04477383568882942\n",
      "The representation loss after processing this batch is:  0.002819068729877472\n",
      "\n",
      "The classification loss after processing this batch is:  0.019964147359132767\n",
      "The representation loss after processing this batch is:  0.0028151050209999084\n",
      "\n",
      "The classification loss after processing this batch is:  0.04221426695585251\n",
      "The representation loss after processing this batch is:  0.0030589625239372253\n",
      "\n",
      "The classification loss after processing this batch is:  0.07388796657323837\n",
      "The representation loss after processing this batch is:  0.0034460872411727905\n",
      "\n",
      "The classification loss after processing this batch is:  0.013125952333211899\n",
      "The representation loss after processing this batch is:  0.0033590421080589294\n",
      "\n",
      "The classification loss after processing this batch is:  0.03856027126312256\n",
      "The representation loss after processing this batch is:  0.0028980597853660583\n",
      "\n",
      "The classification loss after processing this batch is:  0.13599543273448944\n",
      "The representation loss after processing this batch is:  0.0028832480311393738\n",
      "\n",
      "The classification loss after processing this batch is:  0.023273896425962448\n",
      "The representation loss after processing this batch is:  0.0031508207321166992\n",
      "\n",
      "The classification loss after processing this batch is:  0.013196643441915512\n",
      "The representation loss after processing this batch is:  0.0027932003140449524\n",
      "\n",
      "The classification loss after processing this batch is:  0.01839759759604931\n",
      "The representation loss after processing this batch is:  0.002976849675178528\n",
      "\n",
      "The classification loss after processing this batch is:  0.024968760088086128\n",
      "The representation loss after processing this batch is:  0.003084830939769745\n",
      "\n",
      "The classification loss after processing this batch is:  0.032159216701984406\n",
      "The representation loss after processing this batch is:  0.0027870312333106995\n",
      "\n",
      "The classification loss after processing this batch is:  0.025533637031912804\n",
      "The representation loss after processing this batch is:  0.003252759575843811\n",
      "\n",
      "The classification loss after processing this batch is:  0.013572708703577518\n",
      "The representation loss after processing this batch is:  0.003458775579929352\n",
      "\n",
      "The classification loss after processing this batch is:  0.23026452958583832\n",
      "The representation loss after processing this batch is:  0.003218531608581543\n",
      "\n",
      "The classification loss after processing this batch is:  0.2646397650241852\n",
      "The representation loss after processing this batch is:  0.003181278705596924\n",
      "\n",
      "The classification loss after processing this batch is:  0.21278586983680725\n",
      "The representation loss after processing this batch is:  0.003617227077484131\n",
      "\n",
      "The classification loss after processing this batch is:  0.0348232127726078\n",
      "The representation loss after processing this batch is:  0.0025723204016685486\n",
      "\n",
      "The classification loss after processing this batch is:  0.016092317178845406\n",
      "The representation loss after processing this batch is:  0.0032428577542304993\n",
      "\n",
      "The classification loss after processing this batch is:  0.010756492614746094\n",
      "The representation loss after processing this batch is:  0.0022080913186073303\n",
      "\n",
      "The classification loss after processing this batch is:  0.1220797449350357\n",
      "The representation loss after processing this batch is:  0.0024014413356781006\n",
      "\n",
      "The classification loss after processing this batch is:  0.32470276951789856\n",
      "The representation loss after processing this batch is:  0.002665698528289795\n",
      "\n",
      "The classification loss after processing this batch is:  0.07047156989574432\n",
      "The representation loss after processing this batch is:  0.0024772584438323975\n",
      "\n",
      "The classification loss after processing this batch is:  0.03887040540575981\n",
      "The representation loss after processing this batch is:  0.0030484944581985474\n",
      "\n",
      "The classification loss after processing this batch is:  0.03709980472922325\n",
      "The representation loss after processing this batch is:  0.002912759780883789\n",
      "\n",
      "The classification loss after processing this batch is:  0.04558436945080757\n",
      "The representation loss after processing this batch is:  0.003324948251247406\n",
      "\n",
      "The classification loss after processing this batch is:  0.07637815922498703\n",
      "The representation loss after processing this batch is:  0.002338610589504242\n",
      "\n",
      "The classification loss after processing this batch is:  0.042483139783144\n",
      "The representation loss after processing this batch is:  0.002542071044445038\n",
      "\n",
      "The classification loss after processing this batch is:  0.09875348210334778\n",
      "The representation loss after processing this batch is:  0.0024649351835250854\n",
      "\n",
      "The classification loss after processing this batch is:  0.0913463905453682\n",
      "The representation loss after processing this batch is:  0.0023025088012218475\n",
      "\n",
      "The classification loss after processing this batch is:  0.1275939643383026\n",
      "The representation loss after processing this batch is:  0.002645932137966156\n",
      "\n",
      "The classification loss after processing this batch is:  0.06438715755939484\n",
      "The representation loss after processing this batch is:  0.0026971623301506042\n",
      "\n",
      "The classification loss after processing this batch is:  0.06325041502714157\n",
      "The representation loss after processing this batch is:  0.0028800368309020996\n",
      "\n",
      "The classification loss after processing this batch is:  0.1346450001001358\n",
      "The representation loss after processing this batch is:  0.0022516176104545593\n",
      "\n",
      "The classification loss after processing this batch is:  0.11620786041021347\n",
      "The representation loss after processing this batch is:  0.0022085905075073242\n",
      "\n",
      "The classification loss after processing this batch is:  0.06650128215551376\n",
      "The representation loss after processing this batch is:  0.0025408826768398285\n",
      "\n",
      "The classification loss after processing this batch is:  0.13726074993610382\n",
      "The representation loss after processing this batch is:  0.002368435263633728\n",
      "\n",
      "The classification loss after processing this batch is:  0.08761749416589737\n",
      "The representation loss after processing this batch is:  0.0024995841085910797\n",
      "\n",
      "The classification loss after processing this batch is:  0.11475123465061188\n",
      "The representation loss after processing this batch is:  0.0030576884746551514\n",
      "\n",
      "The classification loss after processing this batch is:  0.07115276157855988\n",
      "The representation loss after processing this batch is:  0.0024650320410728455\n",
      "\n",
      "The classification loss after processing this batch is:  0.21772126853466034\n",
      "The representation loss after processing this batch is:  0.0025650225579738617\n",
      "\n",
      "The classification loss after processing this batch is:  0.0880509540438652\n",
      "The representation loss after processing this batch is:  0.002294786274433136\n",
      "\n",
      "The classification loss after processing this batch is:  0.0926959440112114\n",
      "The representation loss after processing this batch is:  0.0025380775332450867\n",
      "\n",
      "The classification loss after processing this batch is:  0.2034166157245636\n",
      "The representation loss after processing this batch is:  0.002575516700744629\n",
      "\n",
      "The classification loss after processing this batch is:  0.10842647403478622\n",
      "The representation loss after processing this batch is:  0.0025748461484909058\n",
      "\n",
      "The classification loss after processing this batch is:  0.07100451737642288\n",
      "The representation loss after processing this batch is:  0.0026879161596298218\n",
      "\n",
      "The classification loss after processing this batch is:  0.2105131596326828\n",
      "The representation loss after processing this batch is:  0.002917572855949402\n",
      "\n",
      "The classification loss after processing this batch is:  0.11573751270771027\n",
      "The representation loss after processing this batch is:  0.002550959587097168\n",
      "\n",
      "The classification loss after processing this batch is:  0.3018437623977661\n",
      "The representation loss after processing this batch is:  0.0023826882243156433\n",
      "\n",
      "The classification loss after processing this batch is:  0.08242178708314896\n",
      "The representation loss after processing this batch is:  0.002158883959054947\n",
      "\n",
      "The classification loss after processing this batch is:  0.05636487901210785\n",
      "The representation loss after processing this batch is:  0.002482764422893524\n",
      "\n",
      "The classification loss after processing this batch is:  0.07293741405010223\n",
      "The representation loss after processing this batch is:  0.0021994411945343018\n",
      "\n",
      "The classification loss after processing this batch is:  0.1001773327589035\n",
      "The representation loss after processing this batch is:  0.002245761454105377\n",
      "\n",
      "The classification loss after processing this batch is:  0.06949461996555328\n",
      "The representation loss after processing this batch is:  0.00235077366232872\n",
      "\n",
      "The classification loss after processing this batch is:  0.04226651042699814\n",
      "The representation loss after processing this batch is:  0.0024315565824508667\n",
      "\n",
      "The classification loss after processing this batch is:  0.03472961485385895\n",
      "The representation loss after processing this batch is:  0.002598963677883148\n",
      "\n",
      "The classification loss after processing this batch is:  0.03811538964509964\n",
      "The representation loss after processing this batch is:  0.0024312101304531097\n",
      "\n",
      "The classification loss after processing this batch is:  0.06949548423290253\n",
      "The representation loss after processing this batch is:  0.0024645179510116577\n",
      "\n",
      "The classification loss after processing this batch is:  0.17499683797359467\n",
      "The representation loss after processing this batch is:  0.0025528445839881897\n",
      "\n",
      "The classification loss after processing this batch is:  0.07272288203239441\n",
      "The representation loss after processing this batch is:  0.002781003713607788\n",
      "\n",
      "The classification loss after processing this batch is:  0.09585105627775192\n",
      "The representation loss after processing this batch is:  0.002411443740129471\n",
      "\n",
      "The classification loss after processing this batch is:  0.03602401167154312\n",
      "The representation loss after processing this batch is:  0.0023240000009536743\n",
      "\n",
      "The classification loss after processing this batch is:  0.04785005748271942\n",
      "The representation loss after processing this batch is:  0.0025392062962055206\n",
      "\n",
      "The classification loss after processing this batch is:  0.08658172190189362\n",
      "The representation loss after processing this batch is:  0.0023173466324806213\n",
      "\n",
      "The classification loss after processing this batch is:  0.04249924421310425\n",
      "The representation loss after processing this batch is:  0.0025122761726379395\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.06632401049137115\n",
      "The representation loss after processing this batch is:  0.0024556219577789307\n",
      "\n",
      "The classification loss after processing this batch is:  0.14508174359798431\n",
      "The representation loss after processing this batch is:  0.002909146249294281\n",
      "\n",
      "The classification loss after processing this batch is:  0.10717085748910904\n",
      "The representation loss after processing this batch is:  0.0025650784373283386\n",
      "\n",
      "The classification loss after processing this batch is:  0.10242307186126709\n",
      "The representation loss after processing this batch is:  0.0021396949887275696\n",
      "\n",
      "The classification loss after processing this batch is:  0.14571668207645416\n",
      "The representation loss after processing this batch is:  0.0024496763944625854\n",
      "\n",
      "The classification loss after processing this batch is:  0.07215750217437744\n",
      "The representation loss after processing this batch is:  0.0022748708724975586\n",
      "\n",
      "The classification loss after processing this batch is:  0.07507741451263428\n",
      "The representation loss after processing this batch is:  0.002416372299194336\n",
      "\n",
      "The classification loss after processing this batch is:  0.18720409274101257\n",
      "The representation loss after processing this batch is:  0.0030134841799736023\n",
      "\n",
      "The classification loss after processing this batch is:  0.043268170207738876\n",
      "The representation loss after processing this batch is:  0.0024813227355480194\n",
      "\n",
      "The classification loss after processing this batch is:  0.13088960945606232\n",
      "The representation loss after processing this batch is:  0.002221114933490753\n",
      "\n",
      "The classification loss after processing this batch is:  0.04733553156256676\n",
      "The representation loss after processing this batch is:  0.0022956058382987976\n",
      "\n",
      "The classification loss after processing this batch is:  0.09924688190221786\n",
      "The representation loss after processing this batch is:  0.0022408030927181244\n",
      "\n",
      "The classification loss after processing this batch is:  0.11964332312345505\n",
      "The representation loss after processing this batch is:  0.002648327499628067\n",
      "\n",
      "The classification loss after processing this batch is:  0.05772660672664642\n",
      "The representation loss after processing this batch is:  0.002531677484512329\n",
      "\n",
      "The classification loss after processing this batch is:  0.11239072680473328\n",
      "The representation loss after processing this batch is:  0.002703428268432617\n",
      "\n",
      "The classification loss after processing this batch is:  0.10272036492824554\n",
      "The representation loss after processing this batch is:  0.0026980191469192505\n",
      "\n",
      "The classification loss after processing this batch is:  0.09381803870201111\n",
      "The representation loss after processing this batch is:  0.0025659799575805664\n",
      "\n",
      "The classification loss after processing this batch is:  0.13442964851856232\n",
      "The representation loss after processing this batch is:  0.0023315399885177612\n",
      "\n",
      "The classification loss after processing this batch is:  0.07742559164762497\n",
      "The representation loss after processing this batch is:  0.0028741806745529175\n",
      "\n",
      "The classification loss after processing this batch is:  0.1610141098499298\n",
      "The representation loss after processing this batch is:  0.002547547221183777\n",
      "\n",
      "The classification loss after processing this batch is:  0.08087673038244247\n",
      "The representation loss after processing this batch is:  0.0023545250296592712\n",
      "\n",
      "The classification loss after processing this batch is:  0.05751041695475578\n",
      "The representation loss after processing this batch is:  0.0022593624889850616\n",
      "\n",
      "The classification loss after processing this batch is:  0.14023524522781372\n",
      "The representation loss after processing this batch is:  0.002400800585746765\n",
      "\n",
      "The classification loss after processing this batch is:  0.10190970450639725\n",
      "The representation loss after processing this batch is:  0.0022599175572395325\n",
      "\n",
      "The classification loss after processing this batch is:  0.07172942906618118\n",
      "The representation loss after processing this batch is:  0.002218984067440033\n",
      "\n",
      "The classification loss after processing this batch is:  0.07902339100837708\n",
      "The representation loss after processing this batch is:  0.0022695735096931458\n",
      "\n",
      "The classification loss after processing this batch is:  0.03784090653061867\n",
      "The representation loss after processing this batch is:  0.002380847930908203\n",
      "\n",
      "The classification loss after processing this batch is:  0.05937333405017853\n",
      "The representation loss after processing this batch is:  0.002574436366558075\n",
      "\n",
      "The classification loss after processing this batch is:  0.10016987472772598\n",
      "The representation loss after processing this batch is:  0.001989182084798813\n",
      "\n",
      "The classification loss after processing this batch is:  0.06321871280670166\n",
      "The representation loss after processing this batch is:  0.002400122582912445\n",
      "\n",
      "The classification loss after processing this batch is:  0.14875812828540802\n",
      "The representation loss after processing this batch is:  0.002425301820039749\n",
      "\n",
      "The classification loss after processing this batch is:  0.1108916774392128\n",
      "The representation loss after processing this batch is:  0.002429679036140442\n",
      "\n",
      "The classification loss after processing this batch is:  0.08107545971870422\n",
      "The representation loss after processing this batch is:  0.002604052424430847\n",
      "\n",
      "The classification loss after processing this batch is:  0.06697238236665726\n",
      "The representation loss after processing this batch is:  0.0021722018718719482\n",
      "\n",
      "The classification loss after processing this batch is:  0.05622674524784088\n",
      "The representation loss after processing this batch is:  0.0025155097246170044\n",
      "\n",
      "The classification loss after processing this batch is:  0.11718060821294785\n",
      "The representation loss after processing this batch is:  0.002306699752807617\n",
      "\n",
      "The classification loss after processing this batch is:  0.15066078305244446\n",
      "The representation loss after processing this batch is:  0.002290576696395874\n",
      "\n",
      "The classification loss after processing this batch is:  0.07330653816461563\n",
      "The representation loss after processing this batch is:  0.0023483410477638245\n",
      "\n",
      "The classification loss after processing this batch is:  0.2437269389629364\n",
      "The representation loss after processing this batch is:  0.0022234246134757996\n",
      "\n",
      "The classification loss after processing this batch is:  0.09490256756544113\n",
      "The representation loss after processing this batch is:  0.0022466368973255157\n",
      "\n",
      "The classification loss after processing this batch is:  0.04902331903576851\n",
      "The representation loss after processing this batch is:  0.0030006468296051025\n",
      "\n",
      "The classification loss after processing this batch is:  0.10980220884084702\n",
      "The representation loss after processing this batch is:  0.0022735223174095154\n",
      "\n",
      "The classification loss after processing this batch is:  0.03921913355588913\n",
      "The representation loss after processing this batch is:  0.0025151148438453674\n",
      "\n",
      "The classification loss after processing this batch is:  0.2223842442035675\n",
      "The representation loss after processing this batch is:  0.0025651082396507263\n",
      "\n",
      "The classification loss after processing this batch is:  0.11748024821281433\n",
      "The representation loss after processing this batch is:  0.0022175833582878113\n",
      "\n",
      "The classification loss after processing this batch is:  0.1061009019613266\n",
      "The representation loss after processing this batch is:  0.0023084282875061035\n",
      "\n",
      "The classification loss after processing this batch is:  0.24213489890098572\n",
      "The representation loss after processing this batch is:  0.002270076423883438\n",
      "\n",
      "The classification loss after processing this batch is:  0.11410405486822128\n",
      "The representation loss after processing this batch is:  0.002415195107460022\n",
      "\n",
      "The classification loss after processing this batch is:  0.06436173617839813\n",
      "The representation loss after processing this batch is:  0.0024384111166000366\n",
      "\n",
      "The classification loss after processing this batch is:  0.10095168650150299\n",
      "The representation loss after processing this batch is:  0.0022195465862751007\n",
      "\n",
      "The classification loss after processing this batch is:  0.10394256561994553\n",
      "The representation loss after processing this batch is:  0.0023589879274368286\n",
      "\n",
      "The classification loss after processing this batch is:  0.14857441186904907\n",
      "The representation loss after processing this batch is:  0.0026322677731513977\n",
      "\n",
      "The classification loss after processing this batch is:  0.05197355896234512\n",
      "The representation loss after processing this batch is:  0.002468399703502655\n",
      "\n",
      "The classification loss after processing this batch is:  0.09140051901340485\n",
      "The representation loss after processing this batch is:  0.0024219155311584473\n",
      "\n",
      "The classification loss after processing this batch is:  0.13321545720100403\n",
      "The representation loss after processing this batch is:  0.0023989304900169373\n",
      "\n",
      "The classification loss after processing this batch is:  0.1447376161813736\n",
      "The representation loss after processing this batch is:  0.0025477707386016846\n",
      "\n",
      "The classification loss after processing this batch is:  0.14784961938858032\n",
      "The representation loss after processing this batch is:  0.0023693442344665527\n",
      "\n",
      "The classification loss after processing this batch is:  0.17936868965625763\n",
      "The representation loss after processing this batch is:  0.002788953483104706\n",
      "\n",
      "The classification loss after processing this batch is:  0.09633371233940125\n",
      "The representation loss after processing this batch is:  0.0029283761978149414\n",
      "\n",
      "The classification loss after processing this batch is:  0.059512317180633545\n",
      "The representation loss after processing this batch is:  0.002535410225391388\n",
      "\n",
      "The classification loss after processing this batch is:  0.07928331941366196\n",
      "The representation loss after processing this batch is:  0.002440318465232849\n",
      "\n",
      "The classification loss after processing this batch is:  0.03756264969706535\n",
      "The representation loss after processing this batch is:  0.002252019941806793\n",
      "\n",
      "The classification loss after processing this batch is:  0.09787728637456894\n",
      "The representation loss after processing this batch is:  0.0024756193161010742\n",
      "\n",
      "The classification loss after processing this batch is:  0.1429966539144516\n",
      "The representation loss after processing this batch is:  0.0023904815316200256\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.1858924925327301\n",
      "The representation loss after processing this batch is:  0.002574145793914795\n",
      "\n",
      "The classification loss after processing this batch is:  0.22130605578422546\n",
      "The representation loss after processing this batch is:  0.0025769993662834167\n",
      "\n",
      "The classification loss after processing this batch is:  0.06362170726060867\n",
      "The representation loss after processing this batch is:  0.0026061832904815674\n",
      "\n",
      "The classification loss after processing this batch is:  0.08944869041442871\n",
      "The representation loss after processing this batch is:  0.0026199743151664734\n",
      "\n",
      "The classification loss after processing this batch is:  0.14624792337417603\n",
      "The representation loss after processing this batch is:  0.0022617317736148834\n",
      "\n",
      "The classification loss after processing this batch is:  0.042486246675252914\n",
      "The representation loss after processing this batch is:  0.002641037106513977\n",
      "\n",
      "The classification loss after processing this batch is:  0.05719665437936783\n",
      "The representation loss after processing this batch is:  0.0025246217846870422\n",
      "\n",
      "The classification loss after processing this batch is:  0.12853585183620453\n",
      "The representation loss after processing this batch is:  0.002164021134376526\n",
      "\n",
      "The classification loss after processing this batch is:  0.08408625423908234\n",
      "The representation loss after processing this batch is:  0.003185644745826721\n",
      "\n",
      "The classification loss after processing this batch is:  0.09667029976844788\n",
      "The representation loss after processing this batch is:  0.0026037171483039856\n",
      "\n",
      "The classification loss after processing this batch is:  0.18327634036540985\n",
      "The representation loss after processing this batch is:  0.0033427029848098755\n",
      "\n",
      "The classification loss after processing this batch is:  0.2517412304878235\n",
      "The representation loss after processing this batch is:  0.0022174865007400513\n",
      "\n",
      "The classification loss after processing this batch is:  0.09339974075555801\n",
      "The representation loss after processing this batch is:  0.0024755075573921204\n",
      "\n",
      "The classification loss after processing this batch is:  0.1971493363380432\n",
      "The representation loss after processing this batch is:  0.002341344952583313\n",
      "\n",
      "The classification loss after processing this batch is:  0.123411625623703\n",
      "The representation loss after processing this batch is:  0.0023313499987125397\n",
      "\n",
      "The classification loss after processing this batch is:  0.0397050641477108\n",
      "The representation loss after processing this batch is:  0.0024833977222442627\n",
      "\n",
      "The classification loss after processing this batch is:  0.11359858512878418\n",
      "The representation loss after processing this batch is:  0.002278760075569153\n",
      "\n",
      "The classification loss after processing this batch is:  0.3173271715641022\n",
      "The representation loss after processing this batch is:  0.00281602144241333\n",
      "\n",
      "The classification loss after processing this batch is:  0.13697010278701782\n",
      "The representation loss after processing this batch is:  0.0026893392205238342\n",
      "\n",
      "The classification loss after processing this batch is:  0.05056765303015709\n",
      "The representation loss after processing this batch is:  0.002656586468219757\n",
      "\n",
      "The classification loss after processing this batch is:  0.05688286945223808\n",
      "The representation loss after processing this batch is:  0.0025893598794937134\n",
      "\n",
      "The classification loss after processing this batch is:  0.041962310671806335\n",
      "The representation loss after processing this batch is:  0.002707280218601227\n",
      "\n",
      "The classification loss after processing this batch is:  0.07840581238269806\n",
      "The representation loss after processing this batch is:  0.002622857689857483\n",
      "\n",
      "The classification loss after processing this batch is:  0.08108687400817871\n",
      "The representation loss after processing this batch is:  0.0027645379304885864\n",
      "\n",
      "The classification loss after processing this batch is:  0.11700590699911118\n",
      "The representation loss after processing this batch is:  0.0026408806443214417\n",
      "\n",
      "The classification loss after processing this batch is:  0.10415291041135788\n",
      "The representation loss after processing this batch is:  0.002492547035217285\n",
      "\n",
      "The classification loss after processing this batch is:  0.1694868505001068\n",
      "The representation loss after processing this batch is:  0.00277545303106308\n",
      "\n",
      "The classification loss after processing this batch is:  0.07732847332954407\n",
      "The representation loss after processing this batch is:  0.002254541963338852\n",
      "\n",
      "The classification loss after processing this batch is:  0.11139533668756485\n",
      "The representation loss after processing this batch is:  0.002119004726409912\n",
      "\n",
      "The classification loss after processing this batch is:  0.129988431930542\n",
      "The representation loss after processing this batch is:  0.00242643803358078\n",
      "\n",
      "The classification loss after processing this batch is:  0.10755001753568649\n",
      "The representation loss after processing this batch is:  0.002409879118204117\n",
      "\n",
      "The classification loss after processing this batch is:  0.08246973901987076\n",
      "The representation loss after processing this batch is:  0.0022980347275733948\n",
      "\n",
      "The classification loss after processing this batch is:  0.19491717219352722\n",
      "The representation loss after processing this batch is:  0.0023232847452163696\n",
      "\n",
      "The classification loss after processing this batch is:  0.13935431838035583\n",
      "The representation loss after processing this batch is:  0.002648979425430298\n",
      "\n",
      "The classification loss after processing this batch is:  0.11937598139047623\n",
      "The representation loss after processing this batch is:  0.0023904964327812195\n",
      "\n",
      "The classification loss after processing this batch is:  0.11709757149219513\n",
      "The representation loss after processing this batch is:  0.0024839192628860474\n",
      "\n",
      "The classification loss after processing this batch is:  0.17077293992042542\n",
      "The representation loss after processing this batch is:  0.0023399069905281067\n",
      "\n",
      "The classification loss after processing this batch is:  0.1637195199728012\n",
      "The representation loss after processing this batch is:  0.002538807690143585\n",
      "\n",
      "The classification loss after processing this batch is:  0.1691320687532425\n",
      "The representation loss after processing this batch is:  0.002733983099460602\n",
      "\n",
      "The classification loss after processing this batch is:  0.13011611998081207\n",
      "The representation loss after processing this batch is:  0.002609439194202423\n",
      "\n",
      "The classification loss after processing this batch is:  0.07995816320180893\n",
      "The representation loss after processing this batch is:  0.002686537802219391\n",
      "\n",
      "The classification loss after processing this batch is:  0.23913903534412384\n",
      "The representation loss after processing this batch is:  0.0025398656725883484\n",
      "\n",
      "The classification loss after processing this batch is:  0.19742892682552338\n",
      "The representation loss after processing this batch is:  0.0022401250898838043\n",
      "\n",
      "The classification loss after processing this batch is:  0.2587425112724304\n",
      "The representation loss after processing this batch is:  0.002494432032108307\n",
      "\n",
      "The classification loss after processing this batch is:  0.2873571217060089\n",
      "The representation loss after processing this batch is:  0.0022912919521331787\n",
      "\n",
      "The classification loss after processing this batch is:  0.203739732503891\n",
      "The representation loss after processing this batch is:  0.0021806322038173676\n",
      "\n",
      "The classification loss after processing this batch is:  0.08552786707878113\n",
      "The representation loss after processing this batch is:  0.002242758870124817\n",
      "\n",
      "The classification loss after processing this batch is:  0.07425577938556671\n",
      "The representation loss after processing this batch is:  0.002306222915649414\n",
      "\n",
      "The classification loss after processing this batch is:  0.0445590503513813\n",
      "The representation loss after processing this batch is:  0.0025654137134552\n",
      "\n",
      "The classification loss after processing this batch is:  0.08585379272699356\n",
      "The representation loss after processing this batch is:  0.0029356777667999268\n",
      "\n",
      "The classification loss after processing this batch is:  0.03516820818185806\n",
      "The representation loss after processing this batch is:  0.0027201324701309204\n",
      "\n",
      "The classification loss after processing this batch is:  0.22453437745571136\n",
      "The representation loss after processing this batch is:  0.0033966228365898132\n",
      "\n",
      "The classification loss after processing this batch is:  0.13095608353614807\n",
      "The representation loss after processing this batch is:  0.002321198582649231\n",
      "\n",
      "The classification loss after processing this batch is:  0.06983187794685364\n",
      "The representation loss after processing this batch is:  0.0025581419467926025\n",
      "\n",
      "The classification loss after processing this batch is:  0.14415310323238373\n",
      "The representation loss after processing this batch is:  0.0022974014282226562\n",
      "\n",
      "The classification loss after processing this batch is:  0.053071871399879456\n",
      "The representation loss after processing this batch is:  0.0027697160840034485\n",
      "\n",
      "The classification loss after processing this batch is:  0.11952190101146698\n",
      "The representation loss after processing this batch is:  0.0028176680207252502\n",
      "\n",
      "The classification loss after processing this batch is:  0.15733203291893005\n",
      "The representation loss after processing this batch is:  0.0031267106533050537\n",
      "\n",
      "The classification loss after processing this batch is:  0.10416316241025925\n",
      "The representation loss after processing this batch is:  0.0030044689774513245\n",
      "\n",
      "The classification loss after processing this batch is:  0.12450257688760757\n",
      "The representation loss after processing this batch is:  0.0021217316389083862\n",
      "\n",
      "The classification loss after processing this batch is:  0.07303391396999359\n",
      "The representation loss after processing this batch is:  0.0023101791739463806\n",
      "\n",
      "The classification loss after processing this batch is:  0.01971602439880371\n",
      "The representation loss after processing this batch is:  0.0025127679109573364\n",
      "\n",
      "The classification loss after processing this batch is:  0.0703609436750412\n",
      "The representation loss after processing this batch is:  0.002631649374961853\n",
      "\n",
      "The classification loss after processing this batch is:  0.05214167758822441\n",
      "The representation loss after processing this batch is:  0.0022901035845279694\n",
      "\n",
      "The classification loss after processing this batch is:  0.10144611448049545\n",
      "The representation loss after processing this batch is:  0.002264309674501419\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.09574500471353531\n",
      "The representation loss after processing this batch is:  0.002442657947540283\n",
      "\n",
      "The classification loss after processing this batch is:  0.0983588919043541\n",
      "The representation loss after processing this batch is:  0.0024252980947494507\n",
      "\n",
      "The classification loss after processing this batch is:  0.30184027552604675\n",
      "The representation loss after processing this batch is:  0.0030020251870155334\n",
      "\n",
      "The classification loss after processing this batch is:  0.20340463519096375\n",
      "The representation loss after processing this batch is:  0.002626962959766388\n",
      "\n",
      "The classification loss after processing this batch is:  0.06832080334424973\n",
      "The representation loss after processing this batch is:  0.0023776963353157043\n",
      "\n",
      "The classification loss after processing this batch is:  0.04644862189888954\n",
      "The representation loss after processing this batch is:  0.002782575786113739\n",
      "\n",
      "The classification loss after processing this batch is:  0.06368885934352875\n",
      "The representation loss after processing this batch is:  0.002454690635204315\n",
      "\n",
      "The classification loss after processing this batch is:  0.050207074731588364\n",
      "The representation loss after processing this batch is:  0.0024574846029281616\n",
      "\n",
      "The classification loss after processing this batch is:  0.02246660739183426\n",
      "The representation loss after processing this batch is:  0.002685070037841797\n",
      "\n",
      "The classification loss after processing this batch is:  0.05175010487437248\n",
      "The representation loss after processing this batch is:  0.0028468742966651917\n",
      "\n",
      "The classification loss after processing this batch is:  0.10553917288780212\n",
      "The representation loss after processing this batch is:  0.0022229813039302826\n",
      "\n",
      "The classification loss after processing this batch is:  0.15109749138355255\n",
      "The representation loss after processing this batch is:  0.0024408623576164246\n",
      "\n",
      "The classification loss after processing this batch is:  0.11438155919313431\n",
      "The representation loss after processing this batch is:  0.0026812776923179626\n",
      "\n",
      "The classification loss after processing this batch is:  0.05781165510416031\n",
      "The representation loss after processing this batch is:  0.0024962350726127625\n",
      "\n",
      "The classification loss after processing this batch is:  0.03641267865896225\n",
      "The representation loss after processing this batch is:  0.002341587096452713\n",
      "\n",
      "The classification loss after processing this batch is:  0.2510008215904236\n",
      "The representation loss after processing this batch is:  0.0023536905646324158\n",
      "\n",
      "The classification loss after processing this batch is:  0.1107335016131401\n",
      "The representation loss after processing this batch is:  0.002696707844734192\n",
      "\n",
      "The classification loss after processing this batch is:  0.043733976781368256\n",
      "The representation loss after processing this batch is:  0.0026389360427856445\n",
      "\n",
      "The classification loss after processing this batch is:  0.10131397843360901\n",
      "The representation loss after processing this batch is:  0.0024136528372764587\n",
      "\n",
      "The classification loss after processing this batch is:  0.09152043610811234\n",
      "The representation loss after processing this batch is:  0.0021786391735076904\n",
      "\n",
      "The classification loss after processing this batch is:  0.05445728451013565\n",
      "The representation loss after processing this batch is:  0.002188757061958313\n",
      "\n",
      "The classification loss after processing this batch is:  0.10115178674459457\n",
      "The representation loss after processing this batch is:  0.0021734796464443207\n",
      "\n",
      "The classification loss after processing this batch is:  0.06370332837104797\n",
      "The representation loss after processing this batch is:  0.0024320408701896667\n",
      "\n",
      "The classification loss after processing this batch is:  0.058999333530664444\n",
      "The representation loss after processing this batch is:  0.002315513789653778\n",
      "\n",
      "The classification loss after processing this batch is:  0.10218824446201324\n",
      "The representation loss after processing this batch is:  0.002202041447162628\n",
      "\n",
      "The classification loss after processing this batch is:  0.15231314301490784\n",
      "The representation loss after processing this batch is:  0.0025574862957000732\n",
      "\n",
      "The classification loss after processing this batch is:  0.1180124506354332\n",
      "The representation loss after processing this batch is:  0.002350717782974243\n",
      "\n",
      "The classification loss after processing this batch is:  0.10671539604663849\n",
      "The representation loss after processing this batch is:  0.0022142380475997925\n",
      "\n",
      "The classification loss after processing this batch is:  0.0855279415845871\n",
      "The representation loss after processing this batch is:  0.002339959144592285\n",
      "\n",
      "The classification loss after processing this batch is:  0.15609194338321686\n",
      "The representation loss after processing this batch is:  0.0021833255887031555\n",
      "\n",
      "The classification loss after processing this batch is:  0.055991873145103455\n",
      "The representation loss after processing this batch is:  0.0025894269347190857\n",
      "\n",
      "The classification loss after processing this batch is:  0.13688287138938904\n",
      "The representation loss after processing this batch is:  0.002340983599424362\n",
      "\n",
      "The classification loss after processing this batch is:  0.05664587393403053\n",
      "The representation loss after processing this batch is:  0.0022947415709495544\n",
      "\n",
      "The classification loss after processing this batch is:  0.12685373425483704\n",
      "The representation loss after processing this batch is:  0.002405494451522827\n",
      "\n",
      "The classification loss after processing this batch is:  0.07021376490592957\n",
      "The representation loss after processing this batch is:  0.0025798603892326355\n",
      "\n",
      "The classification loss after processing this batch is:  0.08595045655965805\n",
      "The representation loss after processing this batch is:  0.002203114330768585\n",
      "\n",
      "The classification loss after processing this batch is:  0.08878441154956818\n",
      "The representation loss after processing this batch is:  0.002164151519536972\n",
      "\n",
      "The classification loss after processing this batch is:  0.09520921856164932\n",
      "The representation loss after processing this batch is:  0.002531297504901886\n",
      "\n",
      "The classification loss after processing this batch is:  0.12236830592155457\n",
      "The representation loss after processing this batch is:  0.0023448094725608826\n",
      "\n",
      "The classification loss after processing this batch is:  0.08899616450071335\n",
      "The representation loss after processing this batch is:  0.002149302512407303\n",
      "\n",
      "The classification loss after processing this batch is:  0.14579005539417267\n",
      "The representation loss after processing this batch is:  0.0021581798791885376\n",
      "\n",
      "The classification loss after processing this batch is:  0.15608282387256622\n",
      "The representation loss after processing this batch is:  0.002139367163181305\n",
      "\n",
      "The classification loss after processing this batch is:  0.20245419442653656\n",
      "The representation loss after processing this batch is:  0.0021282024681568146\n",
      "\n",
      "The classification loss after processing this batch is:  0.1482974737882614\n",
      "The representation loss after processing this batch is:  0.002234026789665222\n",
      "\n",
      "The classification loss after processing this batch is:  0.0758182555437088\n",
      "The representation loss after processing this batch is:  0.002548612654209137\n",
      "\n",
      "The classification loss after processing this batch is:  0.15800541639328003\n",
      "The representation loss after processing this batch is:  0.0026635974645614624\n",
      "\n",
      "The classification loss after processing this batch is:  0.077967070043087\n",
      "The representation loss after processing this batch is:  0.002485044300556183\n",
      "\n",
      "The classification loss after processing this batch is:  0.09921390563249588\n",
      "The representation loss after processing this batch is:  0.0026004500687122345\n",
      "\n",
      "The classification loss after processing this batch is:  0.1752568930387497\n",
      "The representation loss after processing this batch is:  0.002966158092021942\n",
      "\n",
      "The classification loss after processing this batch is:  0.19799140095710754\n",
      "The representation loss after processing this batch is:  0.0027998462319374084\n",
      "\n",
      "The classification loss after processing this batch is:  0.21063899993896484\n",
      "The representation loss after processing this batch is:  0.002471230924129486\n",
      "\n",
      "The classification loss after processing this batch is:  0.14604230225086212\n",
      "The representation loss after processing this batch is:  0.002530723810195923\n",
      "\n",
      "The classification loss after processing this batch is:  0.06380240619182587\n",
      "The representation loss after processing this batch is:  0.0023814886808395386\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.080999955534935\n",
      "The representation loss after processing this batch is:  0.002504095435142517\n",
      "\n",
      "The classification loss after processing this batch is:  0.19436289370059967\n",
      "The representation loss after processing this batch is:  0.0021904073655605316\n",
      "\n",
      "The classification loss after processing this batch is:  0.06714879721403122\n",
      "The representation loss after processing this batch is:  0.002486005425453186\n",
      "\n",
      "The classification loss after processing this batch is:  0.09076634794473648\n",
      "The representation loss after processing this batch is:  0.002116061747074127\n",
      "\n",
      "The classification loss after processing this batch is:  0.06385455280542374\n",
      "The representation loss after processing this batch is:  0.002531997859477997\n",
      "\n",
      "The classification loss after processing this batch is:  0.02631855010986328\n",
      "The representation loss after processing this batch is:  0.002438783645629883\n",
      "\n",
      "The classification loss after processing this batch is:  0.08379785716533661\n",
      "The representation loss after processing this batch is:  0.0025168433785438538\n",
      "\n",
      "The classification loss after processing this batch is:  0.10505755245685577\n",
      "The representation loss after processing this batch is:  0.0027444064617156982\n",
      "\n",
      "The classification loss after processing this batch is:  0.11752127856016159\n",
      "The representation loss after processing this batch is:  0.00238940492272377\n",
      "\n",
      "The classification loss after processing this batch is:  0.11601640284061432\n",
      "The representation loss after processing this batch is:  0.002233687788248062\n",
      "\n",
      "The classification loss after processing this batch is:  0.0897449404001236\n",
      "The representation loss after processing this batch is:  0.0024903565645217896\n",
      "\n",
      "The classification loss after processing this batch is:  0.14369307458400726\n",
      "The representation loss after processing this batch is:  0.0024596452713012695\n",
      "\n",
      "The classification loss after processing this batch is:  0.09081410616636276\n",
      "The representation loss after processing this batch is:  0.0024838894605636597\n",
      "\n",
      "The classification loss after processing this batch is:  0.11625650525093079\n",
      "The representation loss after processing this batch is:  0.003202669322490692\n",
      "\n",
      "The classification loss after processing this batch is:  0.08689169585704803\n",
      "The representation loss after processing this batch is:  0.002628929913043976\n",
      "\n",
      "The classification loss after processing this batch is:  0.09657229483127594\n",
      "The representation loss after processing this batch is:  0.002484530210494995\n",
      "\n",
      "The classification loss after processing this batch is:  0.15478505194187164\n",
      "The representation loss after processing this batch is:  0.0022474080324172974\n",
      "\n",
      "The classification loss after processing this batch is:  0.21558623015880585\n",
      "The representation loss after processing this batch is:  0.0023462995886802673\n",
      "\n",
      "The classification loss after processing this batch is:  0.15805479884147644\n",
      "The representation loss after processing this batch is:  0.0026498064398765564\n",
      "\n",
      "The classification loss after processing this batch is:  0.06448990851640701\n",
      "The representation loss after processing this batch is:  0.002162780612707138\n",
      "\n",
      "The classification loss after processing this batch is:  0.12355122715234756\n",
      "The representation loss after processing this batch is:  0.002692773938179016\n",
      "\n",
      "The classification loss after processing this batch is:  0.11264219135046005\n",
      "The representation loss after processing this batch is:  0.0025864802300930023\n",
      "\n",
      "The classification loss after processing this batch is:  0.14170703291893005\n",
      "The representation loss after processing this batch is:  0.002279173582792282\n",
      "\n",
      "The classification loss after processing this batch is:  0.15749169886112213\n",
      "The representation loss after processing this batch is:  0.002795308828353882\n",
      "\n",
      "The classification loss after processing this batch is:  0.14631876349449158\n",
      "The representation loss after processing this batch is:  0.0024962425231933594\n",
      "\n",
      "The classification loss after processing this batch is:  0.23898519575595856\n",
      "The representation loss after processing this batch is:  0.002842627465724945\n",
      "\n",
      "The classification loss after processing this batch is:  0.09589778631925583\n",
      "The representation loss after processing this batch is:  0.0026677027344703674\n",
      "\n",
      "The classification loss after processing this batch is:  0.10435009747743607\n",
      "The representation loss after processing this batch is:  0.002468302845954895\n",
      "\n",
      "The classification loss after processing this batch is:  0.11392375826835632\n",
      "The representation loss after processing this batch is:  0.002779059112071991\n",
      "\n",
      "The classification loss after processing this batch is:  0.05694198235869408\n",
      "The representation loss after processing this batch is:  0.002736501395702362\n",
      "\n",
      "The classification loss after processing this batch is:  0.15062256157398224\n",
      "The representation loss after processing this batch is:  0.002506650984287262\n",
      "\n",
      "The classification loss after processing this batch is:  0.09068728983402252\n",
      "The representation loss after processing this batch is:  0.0023610293865203857\n",
      "\n",
      "The classification loss after processing this batch is:  0.0849420577287674\n",
      "The representation loss after processing this batch is:  0.0022931694984436035\n",
      "\n",
      "The classification loss after processing this batch is:  0.08696690946817398\n",
      "The representation loss after processing this batch is:  0.00241740420460701\n",
      "\n",
      "The classification loss after processing this batch is:  0.11543501168489456\n",
      "The representation loss after processing this batch is:  0.0029107779264450073\n",
      "\n",
      "The classification loss after processing this batch is:  0.14135392010211945\n",
      "The representation loss after processing this batch is:  0.0023207589983940125\n",
      "\n",
      "The classification loss after processing this batch is:  0.1212364211678505\n",
      "The representation loss after processing this batch is:  0.0025274530053138733\n",
      "\n",
      "The classification loss after processing this batch is:  0.09302853047847748\n",
      "The representation loss after processing this batch is:  0.0022852569818496704\n",
      "\n",
      "The classification loss after processing this batch is:  0.039284542202949524\n",
      "The representation loss after processing this batch is:  0.0022377148270606995\n",
      "\n",
      "The classification loss after processing this batch is:  0.12584277987480164\n",
      "The representation loss after processing this batch is:  0.0020020008087158203\n",
      "\n",
      "The classification loss after processing this batch is:  0.08240603655576706\n",
      "The representation loss after processing this batch is:  0.0020013824105262756\n",
      "\n",
      "The classification loss after processing this batch is:  0.4099588990211487\n",
      "The representation loss after processing this batch is:  0.0025016367435455322\n",
      "\n",
      "The classification loss after processing this batch is:  0.08333133906126022\n",
      "The representation loss after processing this batch is:  0.0024299174547195435\n",
      "\n",
      "The classification loss after processing this batch is:  0.12231722474098206\n",
      "The representation loss after processing this batch is:  0.002403654158115387\n",
      "\n",
      "The classification loss after processing this batch is:  0.26746901869773865\n",
      "The representation loss after processing this batch is:  0.002558372914791107\n",
      "\n",
      "The classification loss after processing this batch is:  0.06341273337602615\n",
      "The representation loss after processing this batch is:  0.0023058950901031494\n",
      "\n",
      "The classification loss after processing this batch is:  0.16943202912807465\n",
      "The representation loss after processing this batch is:  0.002687312662601471\n",
      "\n",
      "The classification loss after processing this batch is:  0.10263573378324509\n",
      "The representation loss after processing this batch is:  0.00268438458442688\n",
      "\n",
      "The classification loss after processing this batch is:  0.23355767130851746\n",
      "The representation loss after processing this batch is:  0.0021325387060642242\n",
      "\n",
      "The classification loss after processing this batch is:  0.042852114886045456\n",
      "The representation loss after processing this batch is:  0.002396814525127411\n",
      "\n",
      "The classification loss after processing this batch is:  0.09767881035804749\n",
      "The representation loss after processing this batch is:  0.0024539828300476074\n",
      "\n",
      "The classification loss after processing this batch is:  0.02691642753779888\n",
      "The representation loss after processing this batch is:  0.002595551311969757\n",
      "\n",
      "The classification loss after processing this batch is:  0.028299009427428246\n",
      "The representation loss after processing this batch is:  0.002645634114742279\n",
      "\n",
      "The classification loss after processing this batch is:  0.058043546974658966\n",
      "The representation loss after processing this batch is:  0.002564631402492523\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.043128155171871185\n",
      "The representation loss after processing this batch is:  0.0021272972226142883\n",
      "\n",
      "The classification loss after processing this batch is:  0.10478226840496063\n",
      "The representation loss after processing this batch is:  0.002612009644508362\n",
      "\n",
      "The classification loss after processing this batch is:  0.08520306646823883\n",
      "The representation loss after processing this batch is:  0.0029642507433891296\n",
      "\n",
      "The classification loss after processing this batch is:  0.08515811711549759\n",
      "The representation loss after processing this batch is:  0.002266816794872284\n",
      "\n",
      "The classification loss after processing this batch is:  0.09013774991035461\n",
      "The representation loss after processing this batch is:  0.0022113509476184845\n",
      "\n",
      "The classification loss after processing this batch is:  0.03569899499416351\n",
      "The representation loss after processing this batch is:  0.0024576336145401\n",
      "\n",
      "The classification loss after processing this batch is:  0.10849884152412415\n",
      "The representation loss after processing this batch is:  0.0024069249629974365\n",
      "\n",
      "The classification loss after processing this batch is:  0.11380895227193832\n",
      "The representation loss after processing this batch is:  0.002624429762363434\n",
      "\n",
      "The classification loss after processing this batch is:  0.14958415925502777\n",
      "The representation loss after processing this batch is:  0.0026795491576194763\n",
      "\n",
      "The classification loss after processing this batch is:  0.09013011306524277\n",
      "The representation loss after processing this batch is:  0.002320658415555954\n",
      "\n",
      "The classification loss after processing this batch is:  0.06755518168210983\n",
      "The representation loss after processing this batch is:  0.002309311181306839\n",
      "\n",
      "The classification loss after processing this batch is:  0.1808033287525177\n",
      "The representation loss after processing this batch is:  0.002498060464859009\n",
      "\n",
      "The classification loss after processing this batch is:  0.1578783094882965\n",
      "The representation loss after processing this batch is:  0.0025255754590034485\n",
      "\n",
      "The classification loss after processing this batch is:  0.13317960500717163\n",
      "The representation loss after processing this batch is:  0.0024733617901802063\n",
      "\n",
      "The classification loss after processing this batch is:  0.042216233909130096\n",
      "The representation loss after processing this batch is:  0.0024288147687911987\n",
      "\n",
      "The classification loss after processing this batch is:  0.08986951410770416\n",
      "The representation loss after processing this batch is:  0.002619601786136627\n",
      "\n",
      "The classification loss after processing this batch is:  0.11401452124118805\n",
      "The representation loss after processing this batch is:  0.0023140348494052887\n",
      "\n",
      "The classification loss after processing this batch is:  0.10840411484241486\n",
      "The representation loss after processing this batch is:  0.0026431307196617126\n",
      "\n",
      "The classification loss after processing this batch is:  0.13224752247333527\n",
      "The representation loss after processing this batch is:  0.0032612457871437073\n",
      "\n",
      "The classification loss after processing this batch is:  0.06691073626279831\n",
      "The representation loss after processing this batch is:  0.0028456002473831177\n",
      "\n",
      "The classification loss after processing this batch is:  0.11770840734243393\n",
      "The representation loss after processing this batch is:  0.002736330032348633\n",
      "\n",
      "The classification loss after processing this batch is:  0.16274996101856232\n",
      "The representation loss after processing this batch is:  0.002339757978916168\n",
      "\n",
      "The classification loss after processing this batch is:  0.06833004951477051\n",
      "The representation loss after processing this batch is:  0.00301535427570343\n",
      "\n",
      "The classification loss after processing this batch is:  0.1197284683585167\n",
      "The representation loss after processing this batch is:  0.0022148042917251587\n",
      "\n",
      "The classification loss after processing this batch is:  0.05348258838057518\n",
      "The representation loss after processing this batch is:  0.002075210213661194\n",
      "\n",
      "The classification loss after processing this batch is:  0.13654416799545288\n",
      "The representation loss after processing this batch is:  0.0022926032543182373\n",
      "\n",
      "The classification loss after processing this batch is:  0.06932427734136581\n",
      "The representation loss after processing this batch is:  0.0023518428206443787\n",
      "\n",
      "The classification loss after processing this batch is:  0.12847469747066498\n",
      "The representation loss after processing this batch is:  0.002573944628238678\n",
      "\n",
      "The classification loss after processing this batch is:  0.09344875812530518\n",
      "The representation loss after processing this batch is:  0.0026927590370178223\n",
      "\n",
      "The classification loss after processing this batch is:  0.07780656963586807\n",
      "The representation loss after processing this batch is:  0.0023845061659812927\n",
      "\n",
      "The classification loss after processing this batch is:  0.09647120535373688\n",
      "The representation loss after processing this batch is:  0.0025751814246177673\n",
      "\n",
      "The classification loss after processing this batch is:  0.13131190836429596\n",
      "The representation loss after processing this batch is:  0.00282914936542511\n",
      "\n",
      "The classification loss after processing this batch is:  0.12393729388713837\n",
      "The representation loss after processing this batch is:  0.0028526633977890015\n",
      "\n",
      "The classification loss after processing this batch is:  0.112221360206604\n",
      "The representation loss after processing this batch is:  0.0025261081755161285\n",
      "\n",
      "The classification loss after processing this batch is:  0.11961743235588074\n",
      "The representation loss after processing this batch is:  0.0026684775948524475\n",
      "\n",
      "The classification loss after processing this batch is:  0.07849748432636261\n",
      "The representation loss after processing this batch is:  0.0023677051067352295\n",
      "\n",
      "The classification loss after processing this batch is:  0.08319713920354843\n",
      "The representation loss after processing this batch is:  0.002681814134120941\n",
      "\n",
      "The classification loss after processing this batch is:  0.05765620991587639\n",
      "The representation loss after processing this batch is:  0.00254058837890625\n",
      "\n",
      "The classification loss after processing this batch is:  0.08446715027093887\n",
      "The representation loss after processing this batch is:  0.0023944824934005737\n",
      "\n",
      "The classification loss after processing this batch is:  0.048539407551288605\n",
      "The representation loss after processing this batch is:  0.0024175792932510376\n",
      "\n",
      "The classification loss after processing this batch is:  0.0420149490237236\n",
      "The representation loss after processing this batch is:  0.002233259379863739\n",
      "\n",
      "The classification loss after processing this batch is:  0.060623593628406525\n",
      "The representation loss after processing this batch is:  0.0026375800371170044\n",
      "\n",
      "The classification loss after processing this batch is:  0.029525112360715866\n",
      "The representation loss after processing this batch is:  0.0027579590678215027\n",
      "\n",
      "The classification loss after processing this batch is:  0.14154405891895294\n",
      "The representation loss after processing this batch is:  0.0022497177124023438\n",
      "\n",
      "The classification loss after processing this batch is:  0.0759798064827919\n",
      "The representation loss after processing this batch is:  0.0021412521600723267\n",
      "\n",
      "The classification loss after processing this batch is:  0.07997961342334747\n",
      "The representation loss after processing this batch is:  0.0025928691029548645\n",
      "\n",
      "The classification loss after processing this batch is:  0.039262041449546814\n",
      "The representation loss after processing this batch is:  0.0026525110006332397\n",
      "\n",
      "The classification loss after processing this batch is:  0.14431193470954895\n",
      "The representation loss after processing this batch is:  0.0025195591151714325\n",
      "\n",
      "The classification loss after processing this batch is:  0.10042812675237656\n",
      "The representation loss after processing this batch is:  0.0025293901562690735\n",
      "\n",
      "The classification loss after processing this batch is:  0.0919015035033226\n",
      "The representation loss after processing this batch is:  0.002321988344192505\n",
      "\n",
      "The classification loss after processing this batch is:  0.09648441523313522\n",
      "The representation loss after processing this batch is:  0.0025158897042274475\n",
      "\n",
      "The classification loss after processing this batch is:  0.07202054560184479\n",
      "The representation loss after processing this batch is:  0.00246453657746315\n",
      "\n",
      "The classification loss after processing this batch is:  0.05290798842906952\n",
      "The representation loss after processing this batch is:  0.002364896237850189\n",
      "\n",
      "The classification loss after processing this batch is:  0.06923433393239975\n",
      "The representation loss after processing this batch is:  0.0025189369916915894\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.046142999082803726\n",
      "The representation loss after processing this batch is:  0.0023625940084457397\n",
      "\n",
      "The classification loss after processing this batch is:  0.1743619740009308\n",
      "The representation loss after processing this batch is:  0.0024521276354789734\n",
      "\n",
      "The classification loss after processing this batch is:  0.12184490263462067\n",
      "The representation loss after processing this batch is:  0.0023040063679218292\n",
      "\n",
      "The classification loss after processing this batch is:  0.12585116922855377\n",
      "The representation loss after processing this batch is:  0.0028732270002365112\n",
      "\n",
      "The classification loss after processing this batch is:  0.13692757487297058\n",
      "The representation loss after processing this batch is:  0.002566225826740265\n",
      "\n",
      "The classification loss after processing this batch is:  0.1636090874671936\n",
      "The representation loss after processing this batch is:  0.0024885013699531555\n",
      "\n",
      "The classification loss after processing this batch is:  0.15753881633281708\n",
      "The representation loss after processing this batch is:  0.002637431025505066\n",
      "\n",
      "The classification loss after processing this batch is:  0.2353638857603073\n",
      "The representation loss after processing this batch is:  0.002279955893754959\n",
      "\n",
      "The classification loss after processing this batch is:  0.16772368550300598\n",
      "The representation loss after processing this batch is:  0.002206403762102127\n",
      "\n",
      "The classification loss after processing this batch is:  0.10562478005886078\n",
      "The representation loss after processing this batch is:  0.002031933516263962\n",
      "\n",
      "The classification loss after processing this batch is:  0.07558493316173553\n",
      "The representation loss after processing this batch is:  0.002292778342962265\n",
      "\n",
      "The classification loss after processing this batch is:  0.05566871911287308\n",
      "The representation loss after processing this batch is:  0.002362847328186035\n",
      "\n",
      "The classification loss after processing this batch is:  0.04189760982990265\n",
      "The representation loss after processing this batch is:  0.0023666247725486755\n",
      "\n",
      "The classification loss after processing this batch is:  0.06561318039894104\n",
      "The representation loss after processing this batch is:  0.0028961673378944397\n",
      "\n",
      "The classification loss after processing this batch is:  0.127828910946846\n",
      "The representation loss after processing this batch is:  0.0024380236864089966\n",
      "\n",
      "The classification loss after processing this batch is:  0.05827797204256058\n",
      "The representation loss after processing this batch is:  0.002346143126487732\n",
      "\n",
      "The classification loss after processing this batch is:  0.18901248276233673\n",
      "The representation loss after processing this batch is:  0.002579234540462494\n",
      "\n",
      "The classification loss after processing this batch is:  0.10067418217658997\n",
      "The representation loss after processing this batch is:  0.0024966374039649963\n",
      "\n",
      "The classification loss after processing this batch is:  0.11995761841535568\n",
      "The representation loss after processing this batch is:  0.0022724568843841553\n",
      "\n",
      "The classification loss after processing this batch is:  0.10673585534095764\n",
      "The representation loss after processing this batch is:  0.0022576525807380676\n",
      "\n",
      "The classification loss after processing this batch is:  0.1515740603208542\n",
      "The representation loss after processing this batch is:  0.0021065548062324524\n",
      "\n",
      "The classification loss after processing this batch is:  0.09936092793941498\n",
      "The representation loss after processing this batch is:  0.0023442693054676056\n",
      "\n",
      "The classification loss after processing this batch is:  0.0939389020204544\n",
      "The representation loss after processing this batch is:  0.002732694149017334\n",
      "\n",
      "The classification loss after processing this batch is:  0.13237395882606506\n",
      "The representation loss after processing this batch is:  0.0023606792092323303\n",
      "\n",
      "The classification loss after processing this batch is:  0.042201511561870575\n",
      "The representation loss after processing this batch is:  0.002339109778404236\n",
      "\n",
      "The classification loss after processing this batch is:  0.0417027547955513\n",
      "The representation loss after processing this batch is:  0.002283833920955658\n",
      "\n",
      "The classification loss after processing this batch is:  0.10987695306539536\n",
      "The representation loss after processing this batch is:  0.0026867836713790894\n",
      "\n",
      "The classification loss after processing this batch is:  0.16796381771564484\n",
      "The representation loss after processing this batch is:  0.0024170726537704468\n",
      "\n",
      "The classification loss after processing this batch is:  0.13425546884536743\n",
      "The representation loss after processing this batch is:  0.002712920308113098\n",
      "\n",
      "The classification loss after processing this batch is:  0.06440028548240662\n",
      "The representation loss after processing this batch is:  0.0031305328011512756\n",
      "\n",
      "The classification loss after processing this batch is:  0.09854653477668762\n",
      "The representation loss after processing this batch is:  0.0027276501059532166\n",
      "\n",
      "The classification loss after processing this batch is:  0.060085229575634\n",
      "The representation loss after processing this batch is:  0.0025431886315345764\n",
      "\n",
      "The classification loss after processing this batch is:  0.1854572594165802\n",
      "The representation loss after processing this batch is:  0.002476770430803299\n",
      "\n",
      "The classification loss after processing this batch is:  0.04493279382586479\n",
      "The representation loss after processing this batch is:  0.002184741199016571\n",
      "\n",
      "The classification loss after processing this batch is:  0.04488731175661087\n",
      "The representation loss after processing this batch is:  0.0025862157344818115\n",
      "\n",
      "The classification loss after processing this batch is:  0.11596085131168365\n",
      "The representation loss after processing this batch is:  0.003028273582458496\n",
      "\n",
      "The classification loss after processing this batch is:  0.09078612178564072\n",
      "The representation loss after processing this batch is:  0.002688862383365631\n",
      "\n",
      "The classification loss after processing this batch is:  0.0730283185839653\n",
      "The representation loss after processing this batch is:  0.0027793720364570618\n",
      "\n",
      "The classification loss after processing this batch is:  0.03747863322496414\n",
      "The representation loss after processing this batch is:  0.0024053268134593964\n",
      "\n",
      "The classification loss after processing this batch is:  0.11159154027700424\n",
      "The representation loss after processing this batch is:  0.0027328506112098694\n",
      "\n",
      "The classification loss after processing this batch is:  0.11522862315177917\n",
      "The representation loss after processing this batch is:  0.0026245862245559692\n",
      "\n",
      "The classification loss after processing this batch is:  0.15205495059490204\n",
      "The representation loss after processing this batch is:  0.0022919028997421265\n",
      "\n",
      "The classification loss after processing this batch is:  0.12940235435962677\n",
      "The representation loss after processing this batch is:  0.0026985853910446167\n",
      "\n",
      "The classification loss after processing this batch is:  0.05823623389005661\n",
      "The representation loss after processing this batch is:  0.0023672282695770264\n",
      "\n",
      "The classification loss after processing this batch is:  0.07216303795576096\n",
      "The representation loss after processing this batch is:  0.0022799596190452576\n",
      "\n",
      "The classification loss after processing this batch is:  0.14093373715877533\n",
      "The representation loss after processing this batch is:  0.0027153268456459045\n",
      "\n",
      "The classification loss after processing this batch is:  0.15320728719234467\n",
      "The representation loss after processing this batch is:  0.002873748540878296\n",
      "\n",
      "The classification loss after processing this batch is:  0.19200929999351501\n",
      "The representation loss after processing this batch is:  0.0030499622225761414\n",
      "\n",
      "The classification loss after processing this batch is:  0.23381049931049347\n",
      "The representation loss after processing this batch is:  0.0025632530450820923\n",
      "\n",
      "The classification loss after processing this batch is:  0.052193719893693924\n",
      "The representation loss after processing this batch is:  0.0022257715463638306\n",
      "\n",
      "The classification loss after processing this batch is:  0.1597260981798172\n",
      "The representation loss after processing this batch is:  0.002436485141515732\n",
      "\n",
      "The classification loss after processing this batch is:  0.07829117029905319\n",
      "The representation loss after processing this batch is:  0.0022234171628952026\n",
      "\n",
      "The classification loss after processing this batch is:  0.07845902442932129\n",
      "The representation loss after processing this batch is:  0.0023578032851219177\n",
      "\n",
      "The classification loss after processing this batch is:  0.06509368866682053\n",
      "The representation loss after processing this batch is:  0.002537280321121216\n",
      "\n",
      "The classification loss after processing this batch is:  0.15654173493385315\n",
      "The representation loss after processing this batch is:  0.002345941960811615\n",
      "\n",
      "The classification loss after processing this batch is:  0.09647616744041443\n",
      "The representation loss after processing this batch is:  0.0023415759205818176\n",
      "\n",
      "The classification loss after processing this batch is:  0.06785301864147186\n",
      "The representation loss after processing this batch is:  0.002430453896522522\n",
      "\n",
      "The classification loss after processing this batch is:  0.13043378293514252\n",
      "The representation loss after processing this batch is:  0.0025036856532096863\n",
      "\n",
      "The classification loss after processing this batch is:  0.031519923359155655\n",
      "The representation loss after processing this batch is:  0.0027342811226844788\n",
      "\n",
      "The classification loss after processing this batch is:  0.10262255370616913\n",
      "The representation loss after processing this batch is:  0.002767406404018402\n",
      "\n",
      "The classification loss after processing this batch is:  0.1323269009590149\n",
      "The representation loss after processing this batch is:  0.002379372715950012\n",
      "\n",
      "The classification loss after processing this batch is:  0.12425745278596878\n",
      "The representation loss after processing this batch is:  0.0024834349751472473\n",
      "\n",
      "The classification loss after processing this batch is:  0.03491564840078354\n",
      "The representation loss after processing this batch is:  0.002871699631214142\n",
      "\n",
      "The classification loss after processing this batch is:  0.06254490464925766\n",
      "The representation loss after processing this batch is:  0.0023117661476135254\n",
      "\n",
      "The classification loss after processing this batch is:  0.14552071690559387\n",
      "The representation loss after processing this batch is:  0.0027449950575828552\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.12414219230413437\n",
      "The representation loss after processing this batch is:  0.0022282227873802185\n",
      "\n",
      "The classification loss after processing this batch is:  0.12069522589445114\n",
      "The representation loss after processing this batch is:  0.0023758411407470703\n",
      "\n",
      "The classification loss after processing this batch is:  0.07654757797718048\n",
      "The representation loss after processing this batch is:  0.0024298913776874542\n",
      "\n",
      "The classification loss after processing this batch is:  0.05376725643873215\n",
      "The representation loss after processing this batch is:  0.002557903528213501\n",
      "\n",
      "The classification loss after processing this batch is:  0.10508302599191666\n",
      "The representation loss after processing this batch is:  0.0021517127752304077\n",
      "\n",
      "The classification loss after processing this batch is:  0.09140324592590332\n",
      "The representation loss after processing this batch is:  0.0025403276085853577\n",
      "\n",
      "The classification loss after processing this batch is:  0.1323625147342682\n",
      "The representation loss after processing this batch is:  0.002363830804824829\n",
      "\n",
      "The classification loss after processing this batch is:  0.07896945625543594\n",
      "The representation loss after processing this batch is:  0.002668440341949463\n",
      "\n",
      "The classification loss after processing this batch is:  0.046087488532066345\n",
      "The representation loss after processing this batch is:  0.002426423132419586\n",
      "\n",
      "The classification loss after processing this batch is:  0.11991562694311142\n",
      "The representation loss after processing this batch is:  0.0024464093148708344\n",
      "\n",
      "The classification loss after processing this batch is:  0.16591684520244598\n",
      "The representation loss after processing this batch is:  0.002483777701854706\n",
      "\n",
      "The classification loss after processing this batch is:  0.04658186435699463\n",
      "The representation loss after processing this batch is:  0.002523355185985565\n",
      "\n",
      "The classification loss after processing this batch is:  0.08000669628381729\n",
      "The representation loss after processing this batch is:  0.0022679828107357025\n",
      "\n",
      "The classification loss after processing this batch is:  0.13867418467998505\n",
      "The representation loss after processing this batch is:  0.00234009325504303\n",
      "\n",
      "The classification loss after processing this batch is:  0.17605601251125336\n",
      "The representation loss after processing this batch is:  0.002293519675731659\n",
      "\n",
      "The classification loss after processing this batch is:  0.08782201260328293\n",
      "The representation loss after processing this batch is:  0.002285569906234741\n",
      "\n",
      "The classification loss after processing this batch is:  0.1264825463294983\n",
      "The representation loss after processing this batch is:  0.0022006183862686157\n",
      "\n",
      "The classification loss after processing this batch is:  0.16314871609210968\n",
      "The representation loss after processing this batch is:  0.002651706337928772\n",
      "\n",
      "The classification loss after processing this batch is:  0.17638352513313293\n",
      "The representation loss after processing this batch is:  0.0026355907320976257\n",
      "\n",
      "The classification loss after processing this batch is:  0.1029047891497612\n",
      "The representation loss after processing this batch is:  0.0025990158319473267\n",
      "\n",
      "The classification loss after processing this batch is:  0.16595998406410217\n",
      "The representation loss after processing this batch is:  0.0023838579654693604\n",
      "\n",
      "The classification loss after processing this batch is:  0.10871495306491852\n",
      "The representation loss after processing this batch is:  0.003321826457977295\n",
      "\n",
      "The classification loss after processing this batch is:  0.08736889809370041\n",
      "The representation loss after processing this batch is:  0.0025938674807548523\n",
      "\n",
      "The classification loss after processing this batch is:  0.07018182426691055\n",
      "The representation loss after processing this batch is:  0.0023037418723106384\n",
      "\n",
      "The classification loss after processing this batch is:  0.07986126840114594\n",
      "The representation loss after processing this batch is:  0.0021912939846515656\n",
      "\n",
      "The classification loss after processing this batch is:  0.0863451436161995\n",
      "The representation loss after processing this batch is:  0.002439640462398529\n",
      "\n",
      "The classification loss after processing this batch is:  0.08942440152168274\n",
      "The representation loss after processing this batch is:  0.0023330524563789368\n",
      "\n",
      "The classification loss after processing this batch is:  0.15267321467399597\n",
      "The representation loss after processing this batch is:  0.002377435564994812\n",
      "\n",
      "The classification loss after processing this batch is:  0.05913449823856354\n",
      "The representation loss after processing this batch is:  0.002600841224193573\n",
      "\n",
      "The classification loss after processing this batch is:  0.04489380493760109\n",
      "The representation loss after processing this batch is:  0.002804093062877655\n",
      "\n",
      "The classification loss after processing this batch is:  0.1153205931186676\n",
      "The representation loss after processing this batch is:  0.002769574522972107\n",
      "\n",
      "The classification loss after processing this batch is:  0.03300578147172928\n",
      "The representation loss after processing this batch is:  0.0022492632269859314\n",
      "\n",
      "The classification loss after processing this batch is:  0.06498096883296967\n",
      "The representation loss after processing this batch is:  0.002519756555557251\n",
      "\n",
      "The classification loss after processing this batch is:  0.029707884415984154\n",
      "The representation loss after processing this batch is:  0.0026235170662403107\n",
      "\n",
      "The classification loss after processing this batch is:  0.11950608342885971\n",
      "The representation loss after processing this batch is:  0.002202831208705902\n",
      "\n",
      "The classification loss after processing this batch is:  0.1680469959974289\n",
      "The representation loss after processing this batch is:  0.002545498311519623\n",
      "\n",
      "The classification loss after processing this batch is:  0.1243005022406578\n",
      "The representation loss after processing this batch is:  0.0030484721064567566\n",
      "\n",
      "The classification loss after processing this batch is:  0.11288654804229736\n",
      "The representation loss after processing this batch is:  0.002895064651966095\n",
      "\n",
      "The classification loss after processing this batch is:  0.07499651610851288\n",
      "The representation loss after processing this batch is:  0.002773888409137726\n",
      "\n",
      "The classification loss after processing this batch is:  0.08901511877775192\n",
      "The representation loss after processing this batch is:  0.002431754022836685\n",
      "\n",
      "The classification loss after processing this batch is:  0.09642443060874939\n",
      "The representation loss after processing this batch is:  0.0023548826575279236\n",
      "\n",
      "The classification loss after processing this batch is:  0.04359997436404228\n",
      "The representation loss after processing this batch is:  0.0026573501527309418\n",
      "\n",
      "The classification loss after processing this batch is:  0.06630531698465347\n",
      "The representation loss after processing this batch is:  0.0024954602122306824\n",
      "\n",
      "The classification loss after processing this batch is:  0.031516335904598236\n",
      "The representation loss after processing this batch is:  0.0024513080716133118\n",
      "\n",
      "The classification loss after processing this batch is:  0.07874123752117157\n",
      "The representation loss after processing this batch is:  0.0025630109012126923\n",
      "\n",
      "The classification loss after processing this batch is:  0.13446611166000366\n",
      "The representation loss after processing this batch is:  0.002548821270465851\n",
      "\n",
      "The classification loss after processing this batch is:  0.15807007253170013\n",
      "The representation loss after processing this batch is:  0.00255449116230011\n",
      "\n",
      "The classification loss after processing this batch is:  0.12827834486961365\n",
      "The representation loss after processing this batch is:  0.003061138093471527\n",
      "\n",
      "The classification loss after processing this batch is:  0.09247541427612305\n",
      "The representation loss after processing this batch is:  0.0025992244482040405\n",
      "\n",
      "The classification loss after processing this batch is:  0.12099972367286682\n",
      "The representation loss after processing this batch is:  0.002635020762681961\n",
      "\n",
      "The classification loss after processing this batch is:  0.09121096879243851\n",
      "The representation loss after processing this batch is:  0.0024404004216194153\n",
      "\n",
      "The classification loss after processing this batch is:  0.2966451942920685\n",
      "The representation loss after processing this batch is:  0.0029828473925590515\n",
      "\n",
      "The classification loss after processing this batch is:  0.1068224087357521\n",
      "The representation loss after processing this batch is:  0.0028328970074653625\n",
      "\n",
      "The classification loss after processing this batch is:  0.18031883239746094\n",
      "The representation loss after processing this batch is:  0.0029370859265327454\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.06780944764614105\n",
      "The representation loss after processing this batch is:  0.002378493547439575\n",
      "\n",
      "The classification loss after processing this batch is:  0.0830238088965416\n",
      "The representation loss after processing this batch is:  0.002343572676181793\n",
      "\n",
      "The classification loss after processing this batch is:  0.14921651780605316\n",
      "The representation loss after processing this batch is:  0.002451084554195404\n",
      "\n",
      "The classification loss after processing this batch is:  0.09507881104946136\n",
      "The representation loss after processing this batch is:  0.002440083771944046\n",
      "\n",
      "The classification loss after processing this batch is:  0.19032354652881622\n",
      "The representation loss after processing this batch is:  0.0023541226983070374\n",
      "\n",
      "The classification loss after processing this batch is:  0.1084362342953682\n",
      "The representation loss after processing this batch is:  0.0028508007526397705\n",
      "\n",
      "The classification loss after processing this batch is:  0.15777269005775452\n",
      "The representation loss after processing this batch is:  0.0029440894722938538\n",
      "\n",
      "The classification loss after processing this batch is:  0.11605974286794662\n",
      "The representation loss after processing this batch is:  0.002807304263114929\n",
      "\n",
      "The classification loss after processing this batch is:  0.03264594078063965\n",
      "The representation loss after processing this batch is:  0.002488180994987488\n",
      "\n",
      "The classification loss after processing this batch is:  0.0739789679646492\n",
      "The representation loss after processing this batch is:  0.0023237578570842743\n",
      "\n",
      "The classification loss after processing this batch is:  0.07624854147434235\n",
      "The representation loss after processing this batch is:  0.0023221485316753387\n",
      "\n",
      "The classification loss after processing this batch is:  0.06796973198652267\n",
      "The representation loss after processing this batch is:  0.0025198757648468018\n",
      "\n",
      "The classification loss after processing this batch is:  0.1486629694700241\n",
      "The representation loss after processing this batch is:  0.0023586004972457886\n",
      "\n",
      "The classification loss after processing this batch is:  0.22510798275470734\n",
      "The representation loss after processing this batch is:  0.0023515671491622925\n",
      "\n",
      "The classification loss after processing this batch is:  0.10227411240339279\n",
      "The representation loss after processing this batch is:  0.002157852053642273\n",
      "\n",
      "The classification loss after processing this batch is:  0.0729575902223587\n",
      "The representation loss after processing this batch is:  0.0025114119052886963\n",
      "\n",
      "The classification loss after processing this batch is:  0.1030486449599266\n",
      "The representation loss after processing this batch is:  0.002523660659790039\n",
      "\n",
      "The classification loss after processing this batch is:  0.059881627559661865\n",
      "The representation loss after processing this batch is:  0.0027026906609535217\n",
      "\n",
      "The classification loss after processing this batch is:  0.10635431110858917\n",
      "The representation loss after processing this batch is:  0.002708815038204193\n",
      "\n",
      "The classification loss after processing this batch is:  0.04139753803610802\n",
      "The representation loss after processing this batch is:  0.0026474669575691223\n",
      "\n",
      "The classification loss after processing this batch is:  0.09407330304384232\n",
      "The representation loss after processing this batch is:  0.002268873155117035\n",
      "\n",
      "The classification loss after processing this batch is:  0.1503143608570099\n",
      "The representation loss after processing this batch is:  0.0025673620402812958\n",
      "\n",
      "The classification loss after processing this batch is:  0.04833948239684105\n",
      "The representation loss after processing this batch is:  0.002309240400791168\n",
      "\n",
      "The classification loss after processing this batch is:  0.1556778848171234\n",
      "The representation loss after processing this batch is:  0.002183064818382263\n",
      "\n",
      "The classification loss after processing this batch is:  0.0808718353509903\n",
      "The representation loss after processing this batch is:  0.0021106526255607605\n",
      "\n",
      "The classification loss after processing this batch is:  0.09863683581352234\n",
      "The representation loss after processing this batch is:  0.0023764222860336304\n",
      "\n",
      "The classification loss after processing this batch is:  0.05036969482898712\n",
      "The representation loss after processing this batch is:  0.0024101510643959045\n",
      "\n",
      "The classification loss after processing this batch is:  0.10299039632081985\n",
      "The representation loss after processing this batch is:  0.002478480339050293\n",
      "\n",
      "The classification loss after processing this batch is:  0.06688626855611801\n",
      "The representation loss after processing this batch is:  0.0024732276797294617\n",
      "\n",
      "The classification loss after processing this batch is:  0.2864074110984802\n",
      "The representation loss after processing this batch is:  0.002523280680179596\n",
      "\n",
      "The classification loss after processing this batch is:  0.13291744887828827\n",
      "The representation loss after processing this batch is:  0.002632550895214081\n",
      "\n",
      "The classification loss after processing this batch is:  0.15732631087303162\n",
      "The representation loss after processing this batch is:  0.0022865906357765198\n",
      "\n",
      "The classification loss after processing this batch is:  0.07301124930381775\n",
      "The representation loss after processing this batch is:  0.0020725056529045105\n",
      "\n",
      "The classification loss after processing this batch is:  0.11349251866340637\n",
      "The representation loss after processing this batch is:  0.0024125203490257263\n",
      "\n",
      "The classification loss after processing this batch is:  0.03696592524647713\n",
      "The representation loss after processing this batch is:  0.0022078529000282288\n",
      "\n",
      "The classification loss after processing this batch is:  0.10892076790332794\n",
      "The representation loss after processing this batch is:  0.002272050827741623\n",
      "\n",
      "The classification loss after processing this batch is:  0.141000434756279\n",
      "The representation loss after processing this batch is:  0.0024004392325878143\n",
      "\n",
      "The classification loss after processing this batch is:  0.1310901939868927\n",
      "The representation loss after processing this batch is:  0.0026615262031555176\n",
      "\n",
      "The classification loss after processing this batch is:  0.15745827555656433\n",
      "The representation loss after processing this batch is:  0.0025009028613567352\n",
      "\n",
      "The classification loss after processing this batch is:  0.07813499122858047\n",
      "The representation loss after processing this batch is:  0.002310827374458313\n",
      "\n",
      "The classification loss after processing this batch is:  0.16485126316547394\n",
      "The representation loss after processing this batch is:  0.002559944987297058\n",
      "\n",
      "The classification loss after processing this batch is:  0.11898335069417953\n",
      "The representation loss after processing this batch is:  0.002651020884513855\n",
      "\n",
      "The classification loss after processing this batch is:  0.16233733296394348\n",
      "The representation loss after processing this batch is:  0.0024296343326568604\n",
      "\n",
      "The classification loss after processing this batch is:  0.09227171540260315\n",
      "The representation loss after processing this batch is:  0.002636536955833435\n",
      "\n",
      "The classification loss after processing this batch is:  0.08718706667423248\n",
      "The representation loss after processing this batch is:  0.0028341561555862427\n",
      "\n",
      "The classification loss after processing this batch is:  0.04125627130270004\n",
      "The representation loss after processing this batch is:  0.0023341104388237\n",
      "\n",
      "The classification loss after processing this batch is:  0.15562839806079865\n",
      "The representation loss after processing this batch is:  0.0022930093109607697\n",
      "\n",
      "The classification loss after processing this batch is:  0.22411149740219116\n",
      "The representation loss after processing this batch is:  0.0026876479387283325\n",
      "\n",
      "The classification loss after processing this batch is:  0.09295789152383804\n",
      "The representation loss after processing this batch is:  0.002781219780445099\n",
      "\n",
      "The classification loss after processing this batch is:  0.1205659955739975\n",
      "The representation loss after processing this batch is:  0.0029811933636665344\n",
      "\n",
      "The classification loss after processing this batch is:  0.14654213190078735\n",
      "The representation loss after processing this batch is:  0.00242045521736145\n",
      "\n",
      "The classification loss after processing this batch is:  0.11726053059101105\n",
      "The representation loss after processing this batch is:  0.0028245896100997925\n",
      "\n",
      "The classification loss after processing this batch is:  0.04213757812976837\n",
      "The representation loss after processing this batch is:  0.002273034304380417\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10933177918195724\n",
      "The representation loss after processing this batch is:  0.0024823322892189026\n",
      "\n",
      "The classification loss after processing this batch is:  0.11754784733057022\n",
      "The representation loss after processing this batch is:  0.0027238130569458008\n",
      "\n",
      "The classification loss after processing this batch is:  0.07258772104978561\n",
      "The representation loss after processing this batch is:  0.0025687851011753082\n",
      "\n",
      "The classification loss after processing this batch is:  0.03173169121146202\n",
      "The representation loss after processing this batch is:  0.002536483108997345\n",
      "\n",
      "The classification loss after processing this batch is:  0.07646409422159195\n",
      "The representation loss after processing this batch is:  0.0025546178221702576\n",
      "\n",
      "The classification loss after processing this batch is:  0.06648866832256317\n",
      "The representation loss after processing this batch is:  0.00277845561504364\n",
      "\n",
      "The classification loss after processing this batch is:  0.10585880279541016\n",
      "The representation loss after processing this batch is:  0.0022959373891353607\n",
      "\n",
      "The classification loss after processing this batch is:  0.15092164278030396\n",
      "The representation loss after processing this batch is:  0.0024422965943813324\n",
      "\n",
      "The classification loss after processing this batch is:  0.13315507769584656\n",
      "The representation loss after processing this batch is:  0.002164483070373535\n",
      "\n",
      "The classification loss after processing this batch is:  0.09933880716562271\n",
      "The representation loss after processing this batch is:  0.002692215144634247\n",
      "\n",
      "The classification loss after processing this batch is:  0.1373930424451828\n",
      "The representation loss after processing this batch is:  0.0028590448200702667\n",
      "\n",
      "The classification loss after processing this batch is:  0.0985221192240715\n",
      "The representation loss after processing this batch is:  0.002744428813457489\n",
      "\n",
      "The classification loss after processing this batch is:  0.08612947165966034\n",
      "The representation loss after processing this batch is:  0.0026859864592552185\n",
      "\n",
      "The classification loss after processing this batch is:  0.16592080891132355\n",
      "The representation loss after processing this batch is:  0.002614416182041168\n",
      "\n",
      "The classification loss after processing this batch is:  0.14926663041114807\n",
      "The representation loss after processing this batch is:  0.003228232264518738\n",
      "\n",
      "The classification loss after processing this batch is:  0.07233764976263046\n",
      "The representation loss after processing this batch is:  0.002421736717224121\n",
      "\n",
      "The classification loss after processing this batch is:  0.06571326404809952\n",
      "The representation loss after processing this batch is:  0.0025774724781513214\n",
      "\n",
      "The classification loss after processing this batch is:  0.0666450560092926\n",
      "The representation loss after processing this batch is:  0.002208016812801361\n",
      "\n",
      "The classification loss after processing this batch is:  0.06794314086437225\n",
      "The representation loss after processing this batch is:  0.002415977418422699\n",
      "\n",
      "The classification loss after processing this batch is:  0.10458376258611679\n",
      "The representation loss after processing this batch is:  0.002401873469352722\n",
      "\n",
      "The classification loss after processing this batch is:  0.18235938251018524\n",
      "The representation loss after processing this batch is:  0.0022958964109420776\n",
      "\n",
      "The classification loss after processing this batch is:  0.1707545667886734\n",
      "The representation loss after processing this batch is:  0.002741686999797821\n",
      "\n",
      "The classification loss after processing this batch is:  0.13329117000102997\n",
      "The representation loss after processing this batch is:  0.002236567437648773\n",
      "\n",
      "The classification loss after processing this batch is:  0.12063176929950714\n",
      "The representation loss after processing this batch is:  0.00210435688495636\n",
      "\n",
      "The classification loss after processing this batch is:  0.08699080348014832\n",
      "The representation loss after processing this batch is:  0.0022919513285160065\n",
      "\n",
      "The classification loss after processing this batch is:  0.12879912555217743\n",
      "The representation loss after processing this batch is:  0.0021955929696559906\n",
      "\n",
      "The classification loss after processing this batch is:  0.182630255818367\n",
      "The representation loss after processing this batch is:  0.0023339837789535522\n",
      "\n",
      "The classification loss after processing this batch is:  0.15488722920417786\n",
      "The representation loss after processing this batch is:  0.0022813118994235992\n",
      "\n",
      "The classification loss after processing this batch is:  0.32564735412597656\n",
      "The representation loss after processing this batch is:  0.0024617165327072144\n",
      "\n",
      "The classification loss after processing this batch is:  0.13890966773033142\n",
      "The representation loss after processing this batch is:  0.0024579614400863647\n",
      "\n",
      "The classification loss after processing this batch is:  0.03148465231060982\n",
      "The representation loss after processing this batch is:  0.0026506558060646057\n",
      "\n",
      "The classification loss after processing this batch is:  0.13630154728889465\n",
      "The representation loss after processing this batch is:  0.00251799076795578\n",
      "\n",
      "The classification loss after processing this batch is:  0.08127102255821228\n",
      "The representation loss after processing this batch is:  0.0024473369121551514\n",
      "\n",
      "The classification loss after processing this batch is:  0.1376962959766388\n",
      "The representation loss after processing this batch is:  0.002881944179534912\n",
      "\n",
      "The classification loss after processing this batch is:  0.14799252152442932\n",
      "The representation loss after processing this batch is:  0.0023007653653621674\n",
      "\n",
      "The classification loss after processing this batch is:  0.12617769837379456\n",
      "The representation loss after processing this batch is:  0.002492956817150116\n",
      "\n",
      "The classification loss after processing this batch is:  0.10202556103467941\n",
      "The representation loss after processing this batch is:  0.0024517476558685303\n",
      "\n",
      "The classification loss after processing this batch is:  0.15320253372192383\n",
      "The representation loss after processing this batch is:  0.0021750666201114655\n",
      "\n",
      "The classification loss after processing this batch is:  0.19238419830799103\n",
      "The representation loss after processing this batch is:  0.0024172812700271606\n",
      "\n",
      "The classification loss after processing this batch is:  0.20668326318264008\n",
      "The representation loss after processing this batch is:  0.0025907084345817566\n",
      "\n",
      "The classification loss after processing this batch is:  0.11987707763910294\n",
      "The representation loss after processing this batch is:  0.0022468790411949158\n",
      "\n",
      "The classification loss after processing this batch is:  0.041335467249155045\n",
      "The representation loss after processing this batch is:  0.002767220139503479\n",
      "\n",
      "The classification loss after processing this batch is:  0.023173753172159195\n",
      "The representation loss after processing this batch is:  0.002540186047554016\n",
      "\n",
      "The classification loss after processing this batch is:  0.09304693341255188\n",
      "The representation loss after processing this batch is:  0.0025229081511497498\n",
      "\n",
      "The classification loss after processing this batch is:  0.05925551801919937\n",
      "The representation loss after processing this batch is:  0.003682360053062439\n",
      "\n",
      "The classification loss after processing this batch is:  0.15383563935756683\n",
      "The representation loss after processing this batch is:  0.002376943826675415\n",
      "\n",
      "The classification loss after processing this batch is:  0.07614831626415253\n",
      "The representation loss after processing this batch is:  0.0025967583060264587\n",
      "\n",
      "The classification loss after processing this batch is:  0.171653613448143\n",
      "The representation loss after processing this batch is:  0.0023067928850650787\n",
      "\n",
      "The classification loss after processing this batch is:  0.0598171092569828\n",
      "The representation loss after processing this batch is:  0.0027380138635635376\n",
      "\n",
      "The classification loss after processing this batch is:  0.12557461857795715\n",
      "The representation loss after processing this batch is:  0.0026022791862487793\n",
      "\n",
      "The classification loss after processing this batch is:  0.13454008102416992\n",
      "The representation loss after processing this batch is:  0.002846553921699524\n",
      "\n",
      "The classification loss after processing this batch is:  0.15343138575553894\n",
      "The representation loss after processing this batch is:  0.002772390842437744\n",
      "\n",
      "The classification loss after processing this batch is:  0.0883444994688034\n",
      "The representation loss after processing this batch is:  0.0024693235754966736\n",
      "\n",
      "The classification loss after processing this batch is:  0.06191862374544144\n",
      "The representation loss after processing this batch is:  0.0020461231470108032\n",
      "\n",
      "The classification loss after processing this batch is:  0.12926100194454193\n",
      "The representation loss after processing this batch is:  0.0026407167315483093\n",
      "\n",
      "The classification loss after processing this batch is:  0.0840088501572609\n",
      "The representation loss after processing this batch is:  0.0023681670427322388\n",
      "\n",
      "The classification loss after processing this batch is:  0.11649159342050552\n",
      "The representation loss after processing this batch is:  0.0024155452847480774\n",
      "\n",
      "The classification loss after processing this batch is:  0.14756160974502563\n",
      "The representation loss after processing this batch is:  0.0026884227991104126\n",
      "\n",
      "The classification loss after processing this batch is:  0.08091054856777191\n",
      "The representation loss after processing this batch is:  0.002470076084136963\n",
      "\n",
      "The classification loss after processing this batch is:  0.03428550437092781\n",
      "The representation loss after processing this batch is:  0.0024240463972091675\n",
      "\n",
      "The classification loss after processing this batch is:  0.043421633541584015\n",
      "The representation loss after processing this batch is:  0.002797819674015045\n",
      "\n",
      "The classification loss after processing this batch is:  0.021722884848713875\n",
      "The representation loss after processing this batch is:  0.002634473145008087\n",
      "\n",
      "The classification loss after processing this batch is:  0.08850046992301941\n",
      "The representation loss after processing this batch is:  0.0024982839822769165\n",
      "\n",
      "The classification loss after processing this batch is:  0.0449216365814209\n",
      "The representation loss after processing this batch is:  0.0025371387600898743\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.02878408506512642\n",
      "The representation loss after processing this batch is:  0.002453938126564026\n",
      "\n",
      "The classification loss after processing this batch is:  0.09573677182197571\n",
      "The representation loss after processing this batch is:  0.0029994919896125793\n",
      "\n",
      "The classification loss after processing this batch is:  0.06343875825405121\n",
      "The representation loss after processing this batch is:  0.0026670098304748535\n",
      "\n",
      "The classification loss after processing this batch is:  0.03442080691456795\n",
      "The representation loss after processing this batch is:  0.002488519996404648\n",
      "\n",
      "The classification loss after processing this batch is:  0.04963015764951706\n",
      "The representation loss after processing this batch is:  0.0024495646357536316\n",
      "\n",
      "The classification loss after processing this batch is:  0.04571733996272087\n",
      "The representation loss after processing this batch is:  0.0023095980286598206\n",
      "\n",
      "The classification loss after processing this batch is:  0.0297036562114954\n",
      "The representation loss after processing this batch is:  0.002541869878768921\n",
      "\n",
      "The classification loss after processing this batch is:  0.11829373240470886\n",
      "The representation loss after processing this batch is:  0.0025859177112579346\n",
      "\n",
      "The classification loss after processing this batch is:  0.12339875102043152\n",
      "The representation loss after processing this batch is:  0.002595767378807068\n",
      "\n",
      "The classification loss after processing this batch is:  0.0556844025850296\n",
      "The representation loss after processing this batch is:  0.002407774329185486\n",
      "\n",
      "The classification loss after processing this batch is:  0.16246095299720764\n",
      "The representation loss after processing this batch is:  0.0023950934410095215\n",
      "\n",
      "The classification loss after processing this batch is:  0.05369793251156807\n",
      "The representation loss after processing this batch is:  0.002377912402153015\n",
      "\n",
      "The classification loss after processing this batch is:  0.11061426252126694\n",
      "The representation loss after processing this batch is:  0.0023905783891677856\n",
      "\n",
      "The classification loss after processing this batch is:  0.12404022365808487\n",
      "The representation loss after processing this batch is:  0.002971045672893524\n",
      "\n",
      "The classification loss after processing this batch is:  0.06537026911973953\n",
      "The representation loss after processing this batch is:  0.0025817304849624634\n",
      "\n",
      "The classification loss after processing this batch is:  0.15469078719615936\n",
      "The representation loss after processing this batch is:  0.002370111644268036\n",
      "\n",
      "The classification loss after processing this batch is:  0.14303860068321228\n",
      "The representation loss after processing this batch is:  0.002281494438648224\n",
      "\n",
      "The classification loss after processing this batch is:  0.14049454033374786\n",
      "The representation loss after processing this batch is:  0.002447567880153656\n",
      "\n",
      "The classification loss after processing this batch is:  0.1340845227241516\n",
      "The representation loss after processing this batch is:  0.002429760992527008\n",
      "\n",
      "The classification loss after processing this batch is:  0.11130020022392273\n",
      "The representation loss after processing this batch is:  0.002434857189655304\n",
      "\n",
      "The classification loss after processing this batch is:  0.10789110511541367\n",
      "The representation loss after processing this batch is:  0.002292785793542862\n",
      "\n",
      "The classification loss after processing this batch is:  0.07243175804615021\n",
      "The representation loss after processing this batch is:  0.0026519671082496643\n",
      "\n",
      "The classification loss after processing this batch is:  0.16859109699726105\n",
      "The representation loss after processing this batch is:  0.002402693033218384\n",
      "\n",
      "The classification loss after processing this batch is:  0.13828366994857788\n",
      "The representation loss after processing this batch is:  0.0022288039326667786\n",
      "\n",
      "The classification loss after processing this batch is:  0.04071216657757759\n",
      "The representation loss after processing this batch is:  0.002394147217273712\n",
      "\n",
      "The classification loss after processing this batch is:  0.0632687509059906\n",
      "The representation loss after processing this batch is:  0.0023359209299087524\n",
      "\n",
      "The classification loss after processing this batch is:  0.1862509697675705\n",
      "The representation loss after processing this batch is:  0.0019953958690166473\n",
      "\n",
      "The classification loss after processing this batch is:  0.07211562246084213\n",
      "The representation loss after processing this batch is:  0.0026064813137054443\n",
      "\n",
      "The classification loss after processing this batch is:  0.09416835755109787\n",
      "The representation loss after processing this batch is:  0.0022930502891540527\n",
      "\n",
      "The classification loss after processing this batch is:  0.10825970023870468\n",
      "The representation loss after processing this batch is:  0.0023707151412963867\n",
      "\n",
      "The classification loss after processing this batch is:  0.07271585613489151\n",
      "The representation loss after processing this batch is:  0.002630576491355896\n",
      "\n",
      "The classification loss after processing this batch is:  0.0326065756380558\n",
      "The representation loss after processing this batch is:  0.0025305747985839844\n",
      "\n",
      "The classification loss after processing this batch is:  0.08271314203739166\n",
      "The representation loss after processing this batch is:  0.0026939064264297485\n",
      "\n",
      "The classification loss after processing this batch is:  0.1060003712773323\n",
      "The representation loss after processing this batch is:  0.0025558099150657654\n",
      "\n",
      "The classification loss after processing this batch is:  0.11012236773967743\n",
      "The representation loss after processing this batch is:  0.0023741088807582855\n",
      "\n",
      "The classification loss after processing this batch is:  0.20364698767662048\n",
      "The representation loss after processing this batch is:  0.0024931058287620544\n",
      "\n",
      "The classification loss after processing this batch is:  0.10747559368610382\n",
      "The representation loss after processing this batch is:  0.0025646761059761047\n",
      "\n",
      "The classification loss after processing this batch is:  0.14381931722164154\n",
      "The representation loss after processing this batch is:  0.0022498294711112976\n",
      "\n",
      "The classification loss after processing this batch is:  0.14043933153152466\n",
      "The representation loss after processing this batch is:  0.002798989415168762\n",
      "\n",
      "The classification loss after processing this batch is:  0.05170440673828125\n",
      "The representation loss after processing this batch is:  0.0026327744126319885\n",
      "\n",
      "The classification loss after processing this batch is:  0.04876019060611725\n",
      "The representation loss after processing this batch is:  0.0025810450315475464\n",
      "\n",
      "The classification loss after processing this batch is:  0.08032942563295364\n",
      "The representation loss after processing this batch is:  0.002600260078907013\n",
      "\n",
      "The classification loss after processing this batch is:  0.14889363944530487\n",
      "The representation loss after processing this batch is:  0.002593196928501129\n",
      "\n",
      "The classification loss after processing this batch is:  0.09475239366292953\n",
      "The representation loss after processing this batch is:  0.0025134459137916565\n",
      "\n",
      "The classification loss after processing this batch is:  0.11591009795665741\n",
      "The representation loss after processing this batch is:  0.002481505274772644\n",
      "\n",
      "The classification loss after processing this batch is:  0.11803876608610153\n",
      "The representation loss after processing this batch is:  0.0028014332056045532\n",
      "\n",
      "The classification loss after processing this batch is:  0.11842821538448334\n",
      "The representation loss after processing this batch is:  0.002767018973827362\n",
      "\n",
      "The classification loss after processing this batch is:  0.13170713186264038\n",
      "The representation loss after processing this batch is:  0.002399332821369171\n",
      "\n",
      "The classification loss after processing this batch is:  0.10489705204963684\n",
      "The representation loss after processing this batch is:  0.002416186034679413\n",
      "\n",
      "The classification loss after processing this batch is:  0.09936628490686417\n",
      "The representation loss after processing this batch is:  0.002334095537662506\n",
      "\n",
      "The classification loss after processing this batch is:  0.05345654860138893\n",
      "The representation loss after processing this batch is:  0.0028708726167678833\n",
      "\n",
      "The classification loss after processing this batch is:  0.048585645854473114\n",
      "The representation loss after processing this batch is:  0.002616278827190399\n",
      "\n",
      "The classification loss after processing this batch is:  0.13737672567367554\n",
      "The representation loss after processing this batch is:  0.0022617876529693604\n",
      "\n",
      "The classification loss after processing this batch is:  0.11432871967554092\n",
      "The representation loss after processing this batch is:  0.002320416271686554\n",
      "\n",
      "The classification loss after processing this batch is:  0.09533391147851944\n",
      "The representation loss after processing this batch is:  0.002418622374534607\n",
      "\n",
      "The classification loss after processing this batch is:  0.10869050025939941\n",
      "The representation loss after processing this batch is:  0.0024803131818771362\n",
      "\n",
      "The classification loss after processing this batch is:  0.0835483968257904\n",
      "The representation loss after processing this batch is:  0.0025208070874214172\n",
      "\n",
      "The classification loss after processing this batch is:  0.1254294216632843\n",
      "The representation loss after processing this batch is:  0.0023333579301834106\n",
      "\n",
      "The classification loss after processing this batch is:  0.14575354754924774\n",
      "The representation loss after processing this batch is:  0.0024784430861473083\n",
      "\n",
      "The classification loss after processing this batch is:  0.20397838950157166\n",
      "The representation loss after processing this batch is:  0.0024883896112442017\n",
      "\n",
      "The classification loss after processing this batch is:  0.1818828284740448\n",
      "The representation loss after processing this batch is:  0.0022483915090560913\n",
      "\n",
      "The classification loss after processing this batch is:  0.07215193659067154\n",
      "The representation loss after processing this batch is:  0.0026485398411750793\n",
      "\n",
      "The classification loss after processing this batch is:  0.05332789942622185\n",
      "The representation loss after processing this batch is:  0.002851709723472595\n",
      "\n",
      "The classification loss after processing this batch is:  0.10759828984737396\n",
      "The representation loss after processing this batch is:  0.002690061926841736\n",
      "\n",
      "The classification loss after processing this batch is:  0.10891999304294586\n",
      "The representation loss after processing this batch is:  0.002289392054080963\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.04043010249733925\n",
      "The representation loss after processing this batch is:  0.0023358091711997986\n",
      "\n",
      "The classification loss after processing this batch is:  0.047000814229249954\n",
      "The representation loss after processing this batch is:  0.0024778395891189575\n",
      "\n",
      "The classification loss after processing this batch is:  0.08743860572576523\n",
      "The representation loss after processing this batch is:  0.0021912455558776855\n",
      "\n",
      "The classification loss after processing this batch is:  0.07638946920633316\n",
      "The representation loss after processing this batch is:  0.0025495514273643494\n",
      "\n",
      "The classification loss after processing this batch is:  0.06578013300895691\n",
      "The representation loss after processing this batch is:  0.0025401227176189423\n",
      "\n",
      "The classification loss after processing this batch is:  0.07749717682600021\n",
      "The representation loss after processing this batch is:  0.002274461090564728\n",
      "\n",
      "The classification loss after processing this batch is:  0.0605265311896801\n",
      "The representation loss after processing this batch is:  0.0023897849023342133\n",
      "\n",
      "The classification loss after processing this batch is:  0.09712989628314972\n",
      "The representation loss after processing this batch is:  0.002860739827156067\n",
      "\n",
      "The classification loss after processing this batch is:  0.08732199668884277\n",
      "The representation loss after processing this batch is:  0.002321820706129074\n",
      "\n",
      "The classification loss after processing this batch is:  0.15279099345207214\n",
      "The representation loss after processing this batch is:  0.0024869218468666077\n",
      "\n",
      "The classification loss after processing this batch is:  0.02661343477666378\n",
      "The representation loss after processing this batch is:  0.0025916993618011475\n",
      "\n",
      "The classification loss after processing this batch is:  0.04386811703443527\n",
      "The representation loss after processing this batch is:  0.0024674758315086365\n",
      "\n",
      "The classification loss after processing this batch is:  0.13893921673297882\n",
      "The representation loss after processing this batch is:  0.0021539106965065002\n",
      "\n",
      "The classification loss after processing this batch is:  0.15565647184848785\n",
      "The representation loss after processing this batch is:  0.0022794604301452637\n",
      "\n",
      "The classification loss after processing this batch is:  0.07345742732286453\n",
      "The representation loss after processing this batch is:  0.002283252775669098\n",
      "\n",
      "The classification loss after processing this batch is:  0.03408319130539894\n",
      "The representation loss after processing this batch is:  0.002173088490962982\n",
      "\n",
      "The classification loss after processing this batch is:  0.12276104092597961\n",
      "The representation loss after processing this batch is:  0.001985538750886917\n",
      "\n",
      "The classification loss after processing this batch is:  0.022007156163454056\n",
      "The representation loss after processing this batch is:  0.0025737136602401733\n",
      "\n",
      "The classification loss after processing this batch is:  0.13187040388584137\n",
      "The representation loss after processing this batch is:  0.002322778105735779\n",
      "\n",
      "The classification loss after processing this batch is:  0.12204036861658096\n",
      "The representation loss after processing this batch is:  0.0025468990206718445\n",
      "\n",
      "The classification loss after processing this batch is:  0.06678839027881622\n",
      "The representation loss after processing this batch is:  0.002300150692462921\n",
      "\n",
      "The classification loss after processing this batch is:  0.07404796034097672\n",
      "The representation loss after processing this batch is:  0.0025716200470924377\n",
      "\n",
      "The classification loss after processing this batch is:  0.07349564135074615\n",
      "The representation loss after processing this batch is:  0.002600528299808502\n",
      "\n",
      "The classification loss after processing this batch is:  0.03357282653450966\n",
      "The representation loss after processing this batch is:  0.002324819564819336\n",
      "\n",
      "The classification loss after processing this batch is:  0.20470745861530304\n",
      "The representation loss after processing this batch is:  0.0022984594106674194\n",
      "\n",
      "The classification loss after processing this batch is:  0.19780342280864716\n",
      "The representation loss after processing this batch is:  0.0023073814809322357\n",
      "\n",
      "The classification loss after processing this batch is:  0.1859487146139145\n",
      "The representation loss after processing this batch is:  0.002406597137451172\n",
      "\n",
      "The classification loss after processing this batch is:  0.19328099489212036\n",
      "The representation loss after processing this batch is:  0.002255033701658249\n",
      "\n",
      "The classification loss after processing this batch is:  0.1089627668261528\n",
      "The representation loss after processing this batch is:  0.00252687931060791\n",
      "\n",
      "The classification loss after processing this batch is:  0.06012358516454697\n",
      "The representation loss after processing this batch is:  0.0024879202246665955\n",
      "\n",
      "The classification loss after processing this batch is:  0.158624067902565\n",
      "The representation loss after processing this batch is:  0.0023814216256141663\n",
      "\n",
      "The classification loss after processing this batch is:  0.1066068634390831\n",
      "The representation loss after processing this batch is:  0.0025160647928714752\n",
      "\n",
      "The classification loss after processing this batch is:  0.15318280458450317\n",
      "The representation loss after processing this batch is:  0.0024525634944438934\n",
      "\n",
      "The classification loss after processing this batch is:  0.08741802722215652\n",
      "The representation loss after processing this batch is:  0.0025962069630622864\n",
      "\n",
      "The classification loss after processing this batch is:  0.1407177448272705\n",
      "The representation loss after processing this batch is:  0.0024214647710323334\n",
      "\n",
      "The classification loss after processing this batch is:  0.05914134532213211\n",
      "The representation loss after processing this batch is:  0.00252668559551239\n",
      "\n",
      "The classification loss after processing this batch is:  0.06405029445886612\n",
      "The representation loss after processing this batch is:  0.0024160370230674744\n",
      "\n",
      "The classification loss after processing this batch is:  0.1231670156121254\n",
      "The representation loss after processing this batch is:  0.0023897141218185425\n",
      "\n",
      "The classification loss after processing this batch is:  0.030464256182312965\n",
      "The representation loss after processing this batch is:  0.0026993080973625183\n",
      "\n",
      "The classification loss after processing this batch is:  0.0434161014854908\n",
      "The representation loss after processing this batch is:  0.0025981292128562927\n",
      "\n",
      "The classification loss after processing this batch is:  0.09112676233053207\n",
      "The representation loss after processing this batch is:  0.0023262202739715576\n",
      "\n",
      "The classification loss after processing this batch is:  0.19990529119968414\n",
      "The representation loss after processing this batch is:  0.0023868605494499207\n",
      "\n",
      "The classification loss after processing this batch is:  0.03330777958035469\n",
      "The representation loss after processing this batch is:  0.00217997282743454\n",
      "\n",
      "The classification loss after processing this batch is:  0.05470927059650421\n",
      "The representation loss after processing this batch is:  0.0022654011845588684\n",
      "\n",
      "The classification loss after processing this batch is:  0.12465990334749222\n",
      "The representation loss after processing this batch is:  0.0023265406489372253\n",
      "\n",
      "The classification loss after processing this batch is:  0.19664248824119568\n",
      "The representation loss after processing this batch is:  0.0022115930914878845\n",
      "\n",
      "The classification loss after processing this batch is:  0.08140052109956741\n",
      "The representation loss after processing this batch is:  0.0023543238639831543\n",
      "\n",
      "The classification loss after processing this batch is:  0.1708832085132599\n",
      "The representation loss after processing this batch is:  0.0021979920566082\n",
      "\n",
      "The classification loss after processing this batch is:  0.06892235577106476\n",
      "The representation loss after processing this batch is:  0.002815239131450653\n",
      "\n",
      "The classification loss after processing this batch is:  0.021442364901304245\n",
      "The representation loss after processing this batch is:  0.0021864213049411774\n",
      "\n",
      "The classification loss after processing this batch is:  0.026412097737193108\n",
      "The representation loss after processing this batch is:  0.0024157539010047913\n",
      "\n",
      "The classification loss after processing this batch is:  0.152471125125885\n",
      "The representation loss after processing this batch is:  0.0026969462633132935\n",
      "\n",
      "The classification loss after processing this batch is:  0.12756185233592987\n",
      "The representation loss after processing this batch is:  0.0027096718549728394\n",
      "\n",
      "The classification loss after processing this batch is:  0.0856814831495285\n",
      "The representation loss after processing this batch is:  0.0030240416526794434\n",
      "\n",
      "The classification loss after processing this batch is:  0.08762984722852707\n",
      "The representation loss after processing this batch is:  0.0024137645959854126\n",
      "\n",
      "The classification loss after processing this batch is:  0.08228210359811783\n",
      "The representation loss after processing this batch is:  0.00234038382768631\n",
      "\n",
      "The classification loss after processing this batch is:  0.10971322655677795\n",
      "The representation loss after processing this batch is:  0.0023403093218803406\n",
      "\n",
      "The classification loss after processing this batch is:  0.09625406563282013\n",
      "The representation loss after processing this batch is:  0.002033822238445282\n",
      "\n",
      "The classification loss after processing this batch is:  0.14085981249809265\n",
      "The representation loss after processing this batch is:  0.0023630931973457336\n",
      "\n",
      "The classification loss after processing this batch is:  0.12609101831912994\n",
      "The representation loss after processing this batch is:  0.0026511922478675842\n",
      "\n",
      "The classification loss after processing this batch is:  0.23655933141708374\n",
      "The representation loss after processing this batch is:  0.00216061994433403\n",
      "\n",
      "The classification loss after processing this batch is:  0.11519923806190491\n",
      "The representation loss after processing this batch is:  0.0022178515791893005\n",
      "\n",
      "The classification loss after processing this batch is:  0.11879374831914902\n",
      "The representation loss after processing this batch is:  0.0023539140820503235\n",
      "\n",
      "The classification loss after processing this batch is:  0.14332018792629242\n",
      "The representation loss after processing this batch is:  0.00231296569108963\n",
      "\n",
      "The classification loss after processing this batch is:  0.049593035131692886\n",
      "The representation loss after processing this batch is:  0.0024033784866333008\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08627055585384369\n",
      "The representation loss after processing this batch is:  0.0029982440173625946\n",
      "\n",
      "The classification loss after processing this batch is:  0.060023486614227295\n",
      "The representation loss after processing this batch is:  0.0025945380330085754\n",
      "\n",
      "The classification loss after processing this batch is:  0.1462727189064026\n",
      "The representation loss after processing this batch is:  0.0024091042578220367\n",
      "\n",
      "The classification loss after processing this batch is:  0.06974311172962189\n",
      "The representation loss after processing this batch is:  0.0020192451775074005\n",
      "\n",
      "The classification loss after processing this batch is:  0.09226184338331223\n",
      "The representation loss after processing this batch is:  0.002316795289516449\n",
      "\n",
      "The classification loss after processing this batch is:  0.0925714448094368\n",
      "The representation loss after processing this batch is:  0.0024459287524223328\n",
      "\n",
      "The classification loss after processing this batch is:  0.12064454704523087\n",
      "The representation loss after processing this batch is:  0.0022779256105422974\n",
      "\n",
      "The classification loss after processing this batch is:  0.11284609138965607\n",
      "The representation loss after processing this batch is:  0.0025281235575675964\n",
      "\n",
      "The classification loss after processing this batch is:  0.16865845024585724\n",
      "The representation loss after processing this batch is:  0.002411879599094391\n",
      "\n",
      "The classification loss after processing this batch is:  0.09058430045843124\n",
      "The representation loss after processing this batch is:  0.0028124824166297913\n",
      "\n",
      "The classification loss after processing this batch is:  0.08386620134115219\n",
      "The representation loss after processing this batch is:  0.0022084973752498627\n",
      "\n",
      "The classification loss after processing this batch is:  0.09349969029426575\n",
      "The representation loss after processing this batch is:  0.002525828778743744\n",
      "\n",
      "The classification loss after processing this batch is:  0.2122945934534073\n",
      "The representation loss after processing this batch is:  0.0027770325541496277\n",
      "\n",
      "The classification loss after processing this batch is:  0.23839345574378967\n",
      "The representation loss after processing this batch is:  0.0025956183671951294\n",
      "\n",
      "The classification loss after processing this batch is:  0.0344114825129509\n",
      "The representation loss after processing this batch is:  0.002102002501487732\n",
      "\n",
      "The classification loss after processing this batch is:  0.040603358298540115\n",
      "The representation loss after processing this batch is:  0.002713710069656372\n",
      "\n",
      "The classification loss after processing this batch is:  0.18825703859329224\n",
      "The representation loss after processing this batch is:  0.0024512633681297302\n",
      "\n",
      "The classification loss after processing this batch is:  0.05687481164932251\n",
      "The representation loss after processing this batch is:  0.0026510506868362427\n",
      "\n",
      "The classification loss after processing this batch is:  0.05601905286312103\n",
      "The representation loss after processing this batch is:  0.0023426860570907593\n",
      "\n",
      "The classification loss after processing this batch is:  0.11329126358032227\n",
      "The representation loss after processing this batch is:  0.0022839978337287903\n",
      "\n",
      "The classification loss after processing this batch is:  0.07746242731809616\n",
      "The representation loss after processing this batch is:  0.002688329666852951\n",
      "\n",
      "The classification loss after processing this batch is:  0.22585663199424744\n",
      "The representation loss after processing this batch is:  0.002788841724395752\n",
      "\n",
      "The classification loss after processing this batch is:  0.12570996582508087\n",
      "The representation loss after processing this batch is:  0.002811059355735779\n",
      "\n",
      "The classification loss after processing this batch is:  0.11505726724863052\n",
      "The representation loss after processing this batch is:  0.003013238310813904\n",
      "\n",
      "The classification loss after processing this batch is:  0.07657264173030853\n",
      "The representation loss after processing this batch is:  0.002038460224866867\n",
      "\n",
      "The classification loss after processing this batch is:  0.1626385748386383\n",
      "The representation loss after processing this batch is:  0.002323463559150696\n",
      "\n",
      "The classification loss after processing this batch is:  0.037283919751644135\n",
      "The representation loss after processing this batch is:  0.0024243518710136414\n",
      "\n",
      "The classification loss after processing this batch is:  0.039578866213560104\n",
      "The representation loss after processing this batch is:  0.0026394054293632507\n",
      "\n",
      "The classification loss after processing this batch is:  0.1002667099237442\n",
      "The representation loss after processing this batch is:  0.0023192167282104492\n",
      "\n",
      "The classification loss after processing this batch is:  0.04854036867618561\n",
      "The representation loss after processing this batch is:  0.002487555146217346\n",
      "\n",
      "The classification loss after processing this batch is:  0.055373165756464005\n",
      "The representation loss after processing this batch is:  0.0028006285429000854\n",
      "\n",
      "The classification loss after processing this batch is:  0.03929208219051361\n",
      "The representation loss after processing this batch is:  0.002594590187072754\n",
      "\n",
      "The classification loss after processing this batch is:  0.07664594054222107\n",
      "The representation loss after processing this batch is:  0.0023794658482074738\n",
      "\n",
      "The classification loss after processing this batch is:  0.090874083340168\n",
      "The representation loss after processing this batch is:  0.0024294890463352203\n",
      "\n",
      "The classification loss after processing this batch is:  0.10897567868232727\n",
      "The representation loss after processing this batch is:  0.0026251375675201416\n",
      "\n",
      "The classification loss after processing this batch is:  0.15167570114135742\n",
      "The representation loss after processing this batch is:  0.002253018319606781\n",
      "\n",
      "The classification loss after processing this batch is:  0.13859185576438904\n",
      "The representation loss after processing this batch is:  0.0028915777802467346\n",
      "\n",
      "The classification loss after processing this batch is:  0.19726432859897614\n",
      "The representation loss after processing this batch is:  0.002490714192390442\n",
      "\n",
      "The classification loss after processing this batch is:  0.03839957341551781\n",
      "The representation loss after processing this batch is:  0.0022702552378177643\n",
      "\n",
      "The classification loss after processing this batch is:  0.16416679322719574\n",
      "The representation loss after processing this batch is:  0.0024064183235168457\n",
      "\n",
      "The classification loss after processing this batch is:  0.25726351141929626\n",
      "The representation loss after processing this batch is:  0.0025404617190361023\n",
      "\n",
      "The classification loss after processing this batch is:  0.09670967608690262\n",
      "The representation loss after processing this batch is:  0.002123326063156128\n",
      "\n",
      "The classification loss after processing this batch is:  0.12375573068857193\n",
      "The representation loss after processing this batch is:  0.002380508929491043\n",
      "\n",
      "The classification loss after processing this batch is:  0.14307761192321777\n",
      "The representation loss after processing this batch is:  0.00234299898147583\n",
      "\n",
      "The classification loss after processing this batch is:  0.15445835888385773\n",
      "The representation loss after processing this batch is:  0.0023281052708625793\n",
      "\n",
      "The classification loss after processing this batch is:  0.10936404019594193\n",
      "The representation loss after processing this batch is:  0.0026042237877845764\n",
      "\n",
      "The classification loss after processing this batch is:  0.08552782237529755\n",
      "The representation loss after processing this batch is:  0.0023336261510849\n",
      "\n",
      "The classification loss after processing this batch is:  0.08099635690450668\n",
      "The representation loss after processing this batch is:  0.0025257766246795654\n",
      "\n",
      "The classification loss after processing this batch is:  0.04552653804421425\n",
      "The representation loss after processing this batch is:  0.0024363920092582703\n",
      "\n",
      "The classification loss after processing this batch is:  0.037960249930620193\n",
      "The representation loss after processing this batch is:  0.0022397637367248535\n",
      "\n",
      "The classification loss after processing this batch is:  0.10288912802934647\n",
      "The representation loss after processing this batch is:  0.002683393657207489\n",
      "\n",
      "The classification loss after processing this batch is:  0.04300566017627716\n",
      "The representation loss after processing this batch is:  0.002538517117500305\n",
      "\n",
      "The classification loss after processing this batch is:  0.20280641317367554\n",
      "The representation loss after processing this batch is:  0.002900082617998123\n",
      "\n",
      "The classification loss after processing this batch is:  0.13250090181827545\n",
      "The representation loss after processing this batch is:  0.0022555142641067505\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.17094191908836365\n",
      "The representation loss after processing this batch is:  0.0026615262031555176\n",
      "\n",
      "The classification loss after processing this batch is:  0.29277071356773376\n",
      "The representation loss after processing this batch is:  0.0021629519760608673\n",
      "\n",
      "The classification loss after processing this batch is:  0.1124662384390831\n",
      "The representation loss after processing this batch is:  0.002384655177593231\n",
      "\n",
      "The classification loss after processing this batch is:  0.0363222099840641\n",
      "The representation loss after processing this batch is:  0.002221927046775818\n",
      "\n",
      "The classification loss after processing this batch is:  0.06250690668821335\n",
      "The representation loss after processing this batch is:  0.0026537179946899414\n",
      "\n",
      "The classification loss after processing this batch is:  0.07042022049427032\n",
      "The representation loss after processing this batch is:  0.0026942044496536255\n",
      "\n",
      "The classification loss after processing this batch is:  0.06586889177560806\n",
      "The representation loss after processing this batch is:  0.0025855228304862976\n",
      "\n",
      "The classification loss after processing this batch is:  0.08104287832975388\n",
      "The representation loss after processing this batch is:  0.0021104253828525543\n",
      "\n",
      "The classification loss after processing this batch is:  0.20416443049907684\n",
      "The representation loss after processing this batch is:  0.0021717101335525513\n",
      "\n",
      "The classification loss after processing this batch is:  0.15628042817115784\n",
      "The representation loss after processing this batch is:  0.0021992065012454987\n",
      "\n",
      "The classification loss after processing this batch is:  0.14476142823696136\n",
      "The representation loss after processing this batch is:  0.00270988792181015\n",
      "\n",
      "The classification loss after processing this batch is:  0.19495455920696259\n",
      "The representation loss after processing this batch is:  0.0027701780200004578\n",
      "\n",
      "The classification loss after processing this batch is:  0.07603052258491516\n",
      "The representation loss after processing this batch is:  0.002338513731956482\n",
      "\n",
      "The classification loss after processing this batch is:  0.10117295384407043\n",
      "The representation loss after processing this batch is:  0.0024215802550315857\n",
      "\n",
      "The classification loss after processing this batch is:  0.16209663450717926\n",
      "The representation loss after processing this batch is:  0.00232141837477684\n",
      "\n",
      "The classification loss after processing this batch is:  0.09209571778774261\n",
      "The representation loss after processing this batch is:  0.002761557698249817\n",
      "\n",
      "The classification loss after processing this batch is:  0.13686934113502502\n",
      "The representation loss after processing this batch is:  0.0032246559858322144\n",
      "\n",
      "The classification loss after processing this batch is:  0.06502225995063782\n",
      "The representation loss after processing this batch is:  0.0027501992881298065\n",
      "\n",
      "The classification loss after processing this batch is:  0.11595939099788666\n",
      "The representation loss after processing this batch is:  0.0030579641461372375\n",
      "\n",
      "The classification loss after processing this batch is:  0.16765336692333221\n",
      "The representation loss after processing this batch is:  0.0027671977877616882\n",
      "\n",
      "The classification loss after processing this batch is:  0.08343051373958588\n",
      "The representation loss after processing this batch is:  0.0026700422167778015\n",
      "\n",
      "The classification loss after processing this batch is:  0.14416363835334778\n",
      "The representation loss after processing this batch is:  0.002899371087551117\n",
      "\n",
      "The classification loss after processing this batch is:  0.18177147209644318\n",
      "The representation loss after processing this batch is:  0.0021192505955696106\n",
      "\n",
      "The classification loss after processing this batch is:  0.09843581169843674\n",
      "The representation loss after processing this batch is:  0.002430364489555359\n",
      "\n",
      "The classification loss after processing this batch is:  0.12964566051959991\n",
      "The representation loss after processing this batch is:  0.0023130178451538086\n",
      "\n",
      "The classification loss after processing this batch is:  0.059033460915088654\n",
      "The representation loss after processing this batch is:  0.0029662400484085083\n",
      "\n",
      "The classification loss after processing this batch is:  0.020103955641388893\n",
      "The representation loss after processing this batch is:  0.002721041440963745\n",
      "\n",
      "The classification loss after processing this batch is:  0.08594619482755661\n",
      "The representation loss after processing this batch is:  0.002679169178009033\n",
      "\n",
      "The classification loss after processing this batch is:  0.058647360652685165\n",
      "The representation loss after processing this batch is:  0.0027934834361076355\n",
      "\n",
      "The classification loss after processing this batch is:  0.23076438903808594\n",
      "The representation loss after processing this batch is:  0.002406015992164612\n",
      "\n",
      "The classification loss after processing this batch is:  0.04227147623896599\n",
      "The representation loss after processing this batch is:  0.002521105110645294\n",
      "\n",
      "The classification loss after processing this batch is:  0.08765856921672821\n",
      "The representation loss after processing this batch is:  0.0023815929889678955\n",
      "\n",
      "The classification loss after processing this batch is:  0.1235259547829628\n",
      "The representation loss after processing this batch is:  0.0024423375725746155\n",
      "\n",
      "The classification loss after processing this batch is:  0.08830951154232025\n",
      "The representation loss after processing this batch is:  0.0024535953998565674\n",
      "\n",
      "The classification loss after processing this batch is:  0.1001584455370903\n",
      "The representation loss after processing this batch is:  0.002496577799320221\n",
      "\n",
      "The classification loss after processing this batch is:  0.04727288708090782\n",
      "The representation loss after processing this batch is:  0.002483084797859192\n",
      "\n",
      "The classification loss after processing this batch is:  0.0388917475938797\n",
      "The representation loss after processing this batch is:  0.0024813711643218994\n",
      "\n",
      "The classification loss after processing this batch is:  0.07533255964517593\n",
      "The representation loss after processing this batch is:  0.0025343522429466248\n",
      "\n",
      "The classification loss after processing this batch is:  0.16991887986660004\n",
      "The representation loss after processing this batch is:  0.002950146794319153\n",
      "\n",
      "The classification loss after processing this batch is:  0.18481533229351044\n",
      "The representation loss after processing this batch is:  0.0025149621069431305\n",
      "\n",
      "The classification loss after processing this batch is:  0.1027359664440155\n",
      "The representation loss after processing this batch is:  0.002053402364253998\n",
      "\n",
      "The classification loss after processing this batch is:  0.14393599331378937\n",
      "The representation loss after processing this batch is:  0.002414342015981674\n",
      "\n",
      "The classification loss after processing this batch is:  0.20542971789836884\n",
      "The representation loss after processing this batch is:  0.002176247537136078\n",
      "\n",
      "The classification loss after processing this batch is:  0.08525355905294418\n",
      "The representation loss after processing this batch is:  0.002620905637741089\n",
      "\n",
      "The classification loss after processing this batch is:  0.20904119312763214\n",
      "The representation loss after processing this batch is:  0.00261051207780838\n",
      "\n",
      "The classification loss after processing this batch is:  0.076424241065979\n",
      "The representation loss after processing this batch is:  0.0026457980275154114\n",
      "\n",
      "The classification loss after processing this batch is:  0.06674591451883316\n",
      "The representation loss after processing this batch is:  0.0023117363452911377\n",
      "\n",
      "The classification loss after processing this batch is:  0.056261733174324036\n",
      "The representation loss after processing this batch is:  0.0023890063166618347\n",
      "\n",
      "The classification loss after processing this batch is:  0.06272020190954208\n",
      "The representation loss after processing this batch is:  0.0024764910340309143\n",
      "\n",
      "The classification loss after processing this batch is:  0.2494691014289856\n",
      "The representation loss after processing this batch is:  0.002434462308883667\n",
      "\n",
      "The classification loss after processing this batch is:  0.06855858117341995\n",
      "The representation loss after processing this batch is:  0.002407871186733246\n",
      "\n",
      "The classification loss after processing this batch is:  0.13095711171627045\n",
      "The representation loss after processing this batch is:  0.002803407609462738\n",
      "\n",
      "The classification loss after processing this batch is:  0.11569084972143173\n",
      "The representation loss after processing this batch is:  0.002769060432910919\n",
      "\n",
      "The classification loss after processing this batch is:  0.09071488678455353\n",
      "The representation loss after processing this batch is:  0.0025583431124687195\n",
      "\n",
      "The classification loss after processing this batch is:  0.0670645534992218\n",
      "The representation loss after processing this batch is:  0.0024445950984954834\n",
      "\n",
      "The classification loss after processing this batch is:  0.1569625586271286\n",
      "The representation loss after processing this batch is:  0.0023222044110298157\n",
      "\n",
      "The classification loss after processing this batch is:  0.1908188760280609\n",
      "The representation loss after processing this batch is:  0.00241122767329216\n",
      "\n",
      "The classification loss after processing this batch is:  0.14198149740695953\n",
      "The representation loss after processing this batch is:  0.0028465017676353455\n",
      "\n",
      "The classification loss after processing this batch is:  0.05952874571084976\n",
      "The representation loss after processing this batch is:  0.002456407994031906\n",
      "\n",
      "The classification loss after processing this batch is:  0.2955586016178131\n",
      "The representation loss after processing this batch is:  0.002257782965898514\n",
      "\n",
      "The classification loss after processing this batch is:  0.06616092473268509\n",
      "The representation loss after processing this batch is:  0.002193693071603775\n",
      "\n",
      "The classification loss after processing this batch is:  0.07067845016717911\n",
      "The representation loss after processing this batch is:  0.0022999420762062073\n",
      "\n",
      "The classification loss after processing this batch is:  0.12025514990091324\n",
      "The representation loss after processing this batch is:  0.0027093663811683655\n",
      "\n",
      "The classification loss after processing this batch is:  0.0828762799501419\n",
      "The representation loss after processing this batch is:  0.002379894256591797\n",
      "\n",
      "The classification loss after processing this batch is:  0.08272862434387207\n",
      "The representation loss after processing this batch is:  0.0024547353386878967\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.06811363250017166\n",
      "The representation loss after processing this batch is:  0.0027006641030311584\n",
      "\n",
      "The classification loss after processing this batch is:  0.1539371758699417\n",
      "The representation loss after processing this batch is:  0.002451125532388687\n",
      "\n",
      "The classification loss after processing this batch is:  0.1765318512916565\n",
      "The representation loss after processing this batch is:  0.002458631992340088\n",
      "\n",
      "The classification loss after processing this batch is:  0.14498423039913177\n",
      "The representation loss after processing this batch is:  0.0023511722683906555\n",
      "\n",
      "The classification loss after processing this batch is:  0.10712709277868271\n",
      "The representation loss after processing this batch is:  0.0027170591056346893\n",
      "\n",
      "The classification loss after processing this batch is:  0.10533778369426727\n",
      "The representation loss after processing this batch is:  0.003010496497154236\n",
      "\n",
      "The classification loss after processing this batch is:  0.12372685968875885\n",
      "The representation loss after processing this batch is:  0.0022578611969947815\n",
      "\n",
      "The classification loss after processing this batch is:  0.12338890135288239\n",
      "The representation loss after processing this batch is:  0.0022383034229278564\n",
      "\n",
      "The classification loss after processing this batch is:  0.017967693507671356\n",
      "The representation loss after processing this batch is:  0.002550065517425537\n",
      "\n",
      "The classification loss after processing this batch is:  0.09913234412670135\n",
      "The representation loss after processing this batch is:  0.0022016800940036774\n",
      "\n",
      "The classification loss after processing this batch is:  0.2060411423444748\n",
      "The representation loss after processing this batch is:  0.0025523193180561066\n",
      "\n",
      "The classification loss after processing this batch is:  0.2726892828941345\n",
      "The representation loss after processing this batch is:  0.0025204792618751526\n",
      "\n",
      "The classification loss after processing this batch is:  0.21060174703598022\n",
      "The representation loss after processing this batch is:  0.0022304020822048187\n",
      "\n",
      "The classification loss after processing this batch is:  0.1635427176952362\n",
      "The representation loss after processing this batch is:  0.002120811492204666\n",
      "\n",
      "The classification loss after processing this batch is:  0.03408471867442131\n",
      "The representation loss after processing this batch is:  0.0022956468164920807\n",
      "\n",
      "The classification loss after processing this batch is:  0.09048126637935638\n",
      "The representation loss after processing this batch is:  0.002217791974544525\n",
      "\n",
      "The classification loss after processing this batch is:  0.09780135750770569\n",
      "The representation loss after processing this batch is:  0.0027206987142562866\n",
      "\n",
      "The classification loss after processing this batch is:  0.1571931540966034\n",
      "The representation loss after processing this batch is:  0.00267753005027771\n",
      "\n",
      "The classification loss after processing this batch is:  0.15627840161323547\n",
      "The representation loss after processing this batch is:  0.0026020705699920654\n",
      "\n",
      "The classification loss after processing this batch is:  0.11301563680171967\n",
      "The representation loss after processing this batch is:  0.0028365105390548706\n",
      "\n",
      "The classification loss after processing this batch is:  0.07409078627824783\n",
      "The representation loss after processing this batch is:  0.0024502724409103394\n",
      "\n",
      "The classification loss after processing this batch is:  0.09485843032598495\n",
      "The representation loss after processing this batch is:  0.0023973658680915833\n",
      "\n",
      "The classification loss after processing this batch is:  0.1472133994102478\n",
      "The representation loss after processing this batch is:  0.0026703551411628723\n",
      "\n",
      "The classification loss after processing this batch is:  0.13919299840927124\n",
      "The representation loss after processing this batch is:  0.0024902448058128357\n",
      "\n",
      "The classification loss after processing this batch is:  0.08829457312822342\n",
      "The representation loss after processing this batch is:  0.002073332667350769\n",
      "\n",
      "The classification loss after processing this batch is:  0.2113296389579773\n",
      "The representation loss after processing this batch is:  0.003127817064523697\n",
      "\n",
      "The classification loss after processing this batch is:  0.30608028173446655\n",
      "The representation loss after processing this batch is:  0.0027108602225780487\n",
      "\n",
      "The classification loss after processing this batch is:  0.15136662125587463\n",
      "The representation loss after processing this batch is:  0.0028131231665611267\n",
      "\n",
      "The classification loss after processing this batch is:  0.09685871005058289\n",
      "The representation loss after processing this batch is:  0.002549782395362854\n",
      "\n",
      "The classification loss after processing this batch is:  0.06789452582597733\n",
      "The representation loss after processing this batch is:  0.002732016146183014\n",
      "\n",
      "The classification loss after processing this batch is:  0.03753973916172981\n",
      "The representation loss after processing this batch is:  0.002410203218460083\n",
      "\n",
      "The classification loss after processing this batch is:  0.164638951420784\n",
      "The representation loss after processing this batch is:  0.002395346760749817\n",
      "\n",
      "The classification loss after processing this batch is:  0.12693266570568085\n",
      "The representation loss after processing this batch is:  0.002754002809524536\n",
      "\n",
      "The classification loss after processing this batch is:  0.09346313029527664\n",
      "The representation loss after processing this batch is:  0.0028839409351348877\n",
      "\n",
      "The classification loss after processing this batch is:  0.21883615851402283\n",
      "The representation loss after processing this batch is:  0.0025026127696037292\n",
      "\n",
      "The classification loss after processing this batch is:  0.04383186995983124\n",
      "The representation loss after processing this batch is:  0.0025204047560691833\n",
      "\n",
      "The classification loss after processing this batch is:  0.04740335792303085\n",
      "The representation loss after processing this batch is:  0.0027168914675712585\n",
      "\n",
      "The classification loss after processing this batch is:  0.09366516023874283\n",
      "The representation loss after processing this batch is:  0.002435818314552307\n",
      "\n",
      "The classification loss after processing this batch is:  0.08984814584255219\n",
      "The representation loss after processing this batch is:  0.0023176372051239014\n",
      "\n",
      "The classification loss after processing this batch is:  0.12926755845546722\n",
      "The representation loss after processing this batch is:  0.0028055310249328613\n",
      "\n",
      "The classification loss after processing this batch is:  0.1103057935833931\n",
      "The representation loss after processing this batch is:  0.002498820424079895\n",
      "\n",
      "The classification loss after processing this batch is:  0.09878073632717133\n",
      "The representation loss after processing this batch is:  0.002547234296798706\n",
      "\n",
      "The classification loss after processing this batch is:  0.04502825811505318\n",
      "The representation loss after processing this batch is:  0.0024835169315338135\n",
      "\n",
      "The classification loss after processing this batch is:  0.04799648001790047\n",
      "The representation loss after processing this batch is:  0.002470068633556366\n",
      "\n",
      "The classification loss after processing this batch is:  0.06922753155231476\n",
      "The representation loss after processing this batch is:  0.0026115402579307556\n",
      "\n",
      "The classification loss after processing this batch is:  0.037970270961523056\n",
      "The representation loss after processing this batch is:  0.0025974586606025696\n",
      "\n",
      "The classification loss after processing this batch is:  0.0797215923666954\n",
      "The representation loss after processing this batch is:  0.0022436752915382385\n",
      "\n",
      "The classification loss after processing this batch is:  0.1312914788722992\n",
      "The representation loss after processing this batch is:  0.002267099916934967\n",
      "\n",
      "The classification loss after processing this batch is:  0.16891826689243317\n",
      "The representation loss after processing this batch is:  0.002632513642311096\n",
      "\n",
      "The classification loss after processing this batch is:  0.038108453154563904\n",
      "The representation loss after processing this batch is:  0.002138674259185791\n",
      "\n",
      "The classification loss after processing this batch is:  0.05022173002362251\n",
      "The representation loss after processing this batch is:  0.002365812659263611\n",
      "\n",
      "The classification loss after processing this batch is:  0.0986119732260704\n",
      "The representation loss after processing this batch is:  0.0028716325759887695\n",
      "\n",
      "The classification loss after processing this batch is:  0.14651475846767426\n",
      "The representation loss after processing this batch is:  0.002406034618616104\n",
      "\n",
      "The classification loss after processing this batch is:  0.04680662229657173\n",
      "The representation loss after processing this batch is:  0.0028122812509536743\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.14439445734024048\n",
      "The representation loss after processing this batch is:  0.0031714290380477905\n",
      "\n",
      "The classification loss after processing this batch is:  0.17251144349575043\n",
      "The representation loss after processing this batch is:  0.002443969249725342\n",
      "\n",
      "The classification loss after processing this batch is:  0.19792203605175018\n",
      "The representation loss after processing this batch is:  0.0025666169822216034\n",
      "\n",
      "The classification loss after processing this batch is:  0.08943667262792587\n",
      "The representation loss after processing this batch is:  0.0024096667766571045\n",
      "\n",
      "The classification loss after processing this batch is:  0.050168659538030624\n",
      "The representation loss after processing this batch is:  0.002419807016849518\n",
      "\n",
      "The classification loss after processing this batch is:  0.07517015933990479\n",
      "The representation loss after processing this batch is:  0.002370167523622513\n",
      "\n",
      "The classification loss after processing this batch is:  0.1438053399324417\n",
      "The representation loss after processing this batch is:  0.0024969205260276794\n",
      "\n",
      "The classification loss after processing this batch is:  0.05736755579710007\n",
      "The representation loss after processing this batch is:  0.002653449773788452\n",
      "\n",
      "The classification loss after processing this batch is:  0.029270267114043236\n",
      "The representation loss after processing this batch is:  0.0022332072257995605\n",
      "\n",
      "The classification loss after processing this batch is:  0.19683371484279633\n",
      "The representation loss after processing this batch is:  0.00252387672662735\n",
      "\n",
      "The classification loss after processing this batch is:  0.1818554550409317\n",
      "The representation loss after processing this batch is:  0.0023758113384246826\n",
      "\n",
      "The classification loss after processing this batch is:  0.07647911459207535\n",
      "The representation loss after processing this batch is:  0.002194605767726898\n",
      "\n",
      "The classification loss after processing this batch is:  0.23313435912132263\n",
      "The representation loss after processing this batch is:  0.0023063570261001587\n",
      "\n",
      "The classification loss after processing this batch is:  0.19826889038085938\n",
      "The representation loss after processing this batch is:  0.0025215670466423035\n",
      "\n",
      "The classification loss after processing this batch is:  0.25455859303474426\n",
      "The representation loss after processing this batch is:  0.0024949833750724792\n",
      "\n",
      "The classification loss after processing this batch is:  0.14164645969867706\n",
      "The representation loss after processing this batch is:  0.002391606569290161\n",
      "\n",
      "The classification loss after processing this batch is:  0.07444162666797638\n",
      "The representation loss after processing this batch is:  0.002288907766342163\n",
      "\n",
      "The classification loss after processing this batch is:  0.13019472360610962\n",
      "The representation loss after processing this batch is:  0.002527274191379547\n",
      "\n",
      "The classification loss after processing this batch is:  0.06958875805139542\n",
      "The representation loss after processing this batch is:  0.002528570592403412\n",
      "\n",
      "The classification loss after processing this batch is:  0.06498215347528458\n",
      "The representation loss after processing this batch is:  0.00244256854057312\n",
      "\n",
      "The classification loss after processing this batch is:  0.060972172766923904\n",
      "The representation loss after processing this batch is:  0.002199653536081314\n",
      "\n",
      "The classification loss after processing this batch is:  0.047165680676698685\n",
      "The representation loss after processing this batch is:  0.002414226531982422\n",
      "\n",
      "The classification loss after processing this batch is:  0.022906191647052765\n",
      "The representation loss after processing this batch is:  0.0026380494236946106\n",
      "\n",
      "The classification loss after processing this batch is:  0.11494617164134979\n",
      "The representation loss after processing this batch is:  0.0026811063289642334\n",
      "\n",
      "The classification loss after processing this batch is:  0.1406678557395935\n",
      "The representation loss after processing this batch is:  0.0023476406931877136\n",
      "\n",
      "The classification loss after processing this batch is:  0.05501061677932739\n",
      "The representation loss after processing this batch is:  0.002803310751914978\n",
      "\n",
      "The classification loss after processing this batch is:  0.07700248062610626\n",
      "The representation loss after processing this batch is:  0.0022961795330047607\n",
      "\n",
      "The classification loss after processing this batch is:  0.10008703172206879\n",
      "The representation loss after processing this batch is:  0.002400308847427368\n",
      "\n",
      "The classification loss after processing this batch is:  0.02472369745373726\n",
      "The representation loss after processing this batch is:  0.0023733749985694885\n",
      "\n",
      "The classification loss after processing this batch is:  0.15704424679279327\n",
      "The representation loss after processing this batch is:  0.002500474452972412\n",
      "\n",
      "The classification loss after processing this batch is:  0.07403775304555893\n",
      "The representation loss after processing this batch is:  0.0022869035601615906\n",
      "\n",
      "The classification loss after processing this batch is:  0.24117176234722137\n",
      "The representation loss after processing this batch is:  0.0024503767490386963\n",
      "\n",
      "The classification loss after processing this batch is:  0.11657688766717911\n",
      "The representation loss after processing this batch is:  0.0023823082447052\n",
      "\n",
      "The classification loss after processing this batch is:  0.11489490419626236\n",
      "The representation loss after processing this batch is:  0.00227200984954834\n",
      "\n",
      "The classification loss after processing this batch is:  0.02788115292787552\n",
      "The representation loss after processing this batch is:  0.0025214552879333496\n",
      "\n",
      "The classification loss after processing this batch is:  0.03920265659689903\n",
      "The representation loss after processing this batch is:  0.0021845102310180664\n",
      "\n",
      "The classification loss after processing this batch is:  0.14915762841701508\n",
      "The representation loss after processing this batch is:  0.0023614130914211273\n",
      "\n",
      "The classification loss after processing this batch is:  0.049845997244119644\n",
      "The representation loss after processing this batch is:  0.0026840344071388245\n",
      "\n",
      "The classification loss after processing this batch is:  0.09467568248510361\n",
      "The representation loss after processing this batch is:  0.0025262683629989624\n",
      "\n",
      "The classification loss after processing this batch is:  0.07641267031431198\n",
      "The representation loss after processing this batch is:  0.002609342336654663\n",
      "\n",
      "The classification loss after processing this batch is:  0.0685444325208664\n",
      "The representation loss after processing this batch is:  0.0028185248374938965\n",
      "\n",
      "The classification loss after processing this batch is:  0.12407480180263519\n",
      "The representation loss after processing this batch is:  0.0024355873465538025\n",
      "\n",
      "The classification loss after processing this batch is:  0.04791272431612015\n",
      "The representation loss after processing this batch is:  0.0026232898235321045\n",
      "\n",
      "The classification loss after processing this batch is:  0.12924796342849731\n",
      "The representation loss after processing this batch is:  0.002663813531398773\n",
      "\n",
      "The classification loss after processing this batch is:  0.19821183383464813\n",
      "The representation loss after processing this batch is:  0.002473875880241394\n",
      "\n",
      "The classification loss after processing this batch is:  0.15030844509601593\n",
      "The representation loss after processing this batch is:  0.0027614086866378784\n",
      "\n",
      "The classification loss after processing this batch is:  0.18423622846603394\n",
      "The representation loss after processing this batch is:  0.0023323222994804382\n",
      "\n",
      "The classification loss after processing this batch is:  0.16153858602046967\n",
      "The representation loss after processing this batch is:  0.002603873610496521\n",
      "\n",
      "The classification loss after processing this batch is:  0.08283018320798874\n",
      "The representation loss after processing this batch is:  0.0021905601024627686\n",
      "\n",
      "The classification loss after processing this batch is:  0.07205335050821304\n",
      "The representation loss after processing this batch is:  0.00235198438167572\n",
      "\n",
      "The classification loss after processing this batch is:  0.05327548086643219\n",
      "The representation loss after processing this batch is:  0.002300746738910675\n",
      "\n",
      "The classification loss after processing this batch is:  0.08569473773241043\n",
      "The representation loss after processing this batch is:  0.0025527924299240112\n",
      "\n",
      "The classification loss after processing this batch is:  0.039872679859399796\n",
      "The representation loss after processing this batch is:  0.00251615047454834\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.08244244754314423\n",
      "The representation loss after processing this batch is:  0.002096734941005707\n",
      "\n",
      "The classification loss after processing this batch is:  0.09027860313653946\n",
      "The representation loss after processing this batch is:  0.00234154611825943\n",
      "\n",
      "The classification loss after processing this batch is:  0.08295582979917526\n",
      "The representation loss after processing this batch is:  0.0027347207069396973\n",
      "\n",
      "The classification loss after processing this batch is:  0.06449969857931137\n",
      "The representation loss after processing this batch is:  0.0023251771926879883\n",
      "\n",
      "The classification loss after processing this batch is:  0.12942908704280853\n",
      "The representation loss after processing this batch is:  0.002189725637435913\n",
      "\n",
      "The classification loss after processing this batch is:  0.055410318076610565\n",
      "The representation loss after processing this batch is:  0.0025196149945259094\n",
      "\n",
      "The classification loss after processing this batch is:  0.10153405368328094\n",
      "The representation loss after processing this batch is:  0.00244990736246109\n",
      "\n",
      "The classification loss after processing this batch is:  0.12721751630306244\n",
      "The representation loss after processing this batch is:  0.002421364188194275\n",
      "\n",
      "The classification loss after processing this batch is:  0.08426669985055923\n",
      "The representation loss after processing this batch is:  0.0026242434978485107\n",
      "\n",
      "The classification loss after processing this batch is:  0.05783804506063461\n",
      "The representation loss after processing this batch is:  0.0026667192578315735\n",
      "\n",
      "The classification loss after processing this batch is:  0.16641196608543396\n",
      "The representation loss after processing this batch is:  0.0024265795946121216\n",
      "\n",
      "The classification loss after processing this batch is:  0.06030618026852608\n",
      "The representation loss after processing this batch is:  0.0024805963039398193\n",
      "\n",
      "The classification loss after processing this batch is:  0.05888007581233978\n",
      "The representation loss after processing this batch is:  0.002460673451423645\n",
      "\n",
      "The classification loss after processing this batch is:  0.08807572722434998\n",
      "The representation loss after processing this batch is:  0.0024081245064735413\n",
      "\n",
      "The classification loss after processing this batch is:  0.04547626152634621\n",
      "The representation loss after processing this batch is:  0.0025270283222198486\n",
      "\n",
      "The classification loss after processing this batch is:  0.10768059641122818\n",
      "The representation loss after processing this batch is:  0.002258405089378357\n",
      "\n",
      "The classification loss after processing this batch is:  0.1383565068244934\n",
      "The representation loss after processing this batch is:  0.002549353986978531\n",
      "\n",
      "The classification loss after processing this batch is:  0.0699065625667572\n",
      "The representation loss after processing this batch is:  0.0027261823415756226\n",
      "\n",
      "The classification loss after processing this batch is:  0.07896795868873596\n",
      "The representation loss after processing this batch is:  0.002937428653240204\n",
      "\n",
      "The classification loss after processing this batch is:  0.08059252053499222\n",
      "The representation loss after processing this batch is:  0.0025395825505256653\n",
      "\n",
      "The classification loss after processing this batch is:  0.2289230227470398\n",
      "The representation loss after processing this batch is:  0.0025138147175312042\n",
      "\n",
      "The classification loss after processing this batch is:  0.041651275008916855\n",
      "The representation loss after processing this batch is:  0.002400614321231842\n",
      "\n",
      "The classification loss after processing this batch is:  0.07404360920190811\n",
      "The representation loss after processing this batch is:  0.002620398998260498\n",
      "\n",
      "The classification loss after processing this batch is:  0.14644567668437958\n",
      "The representation loss after processing this batch is:  0.0021590739488601685\n",
      "\n",
      "The classification loss after processing this batch is:  0.29107025265693665\n",
      "The representation loss after processing this batch is:  0.002572394907474518\n",
      "\n",
      "The classification loss after processing this batch is:  0.07956662774085999\n",
      "The representation loss after processing this batch is:  0.0022834911942481995\n",
      "\n",
      "The classification loss after processing this batch is:  0.09721381217241287\n",
      "The representation loss after processing this batch is:  0.0022379495203495026\n",
      "\n",
      "The classification loss after processing this batch is:  0.07586364448070526\n",
      "The representation loss after processing this batch is:  0.002453044056892395\n",
      "\n",
      "The classification loss after processing this batch is:  0.03224935382604599\n",
      "The representation loss after processing this batch is:  0.0023136138916015625\n",
      "\n",
      "The classification loss after processing this batch is:  0.11528323590755463\n",
      "The representation loss after processing this batch is:  0.002914145588874817\n",
      "\n",
      "The classification loss after processing this batch is:  0.0745263546705246\n",
      "The representation loss after processing this batch is:  0.0032333657145500183\n",
      "\n",
      "The classification loss after processing this batch is:  0.04156466946005821\n",
      "The representation loss after processing this batch is:  0.0025897547602653503\n",
      "\n",
      "The classification loss after processing this batch is:  0.0581168457865715\n",
      "The representation loss after processing this batch is:  0.002405121922492981\n",
      "\n",
      "The classification loss after processing this batch is:  0.1456991285085678\n",
      "The representation loss after processing this batch is:  0.0023764893412590027\n",
      "\n",
      "The classification loss after processing this batch is:  0.11393524706363678\n",
      "The representation loss after processing this batch is:  0.002358384430408478\n",
      "\n",
      "The classification loss after processing this batch is:  0.062015458941459656\n",
      "The representation loss after processing this batch is:  0.0021840110421180725\n",
      "\n",
      "The classification loss after processing this batch is:  0.05658690258860588\n",
      "The representation loss after processing this batch is:  0.002601519227027893\n",
      "\n",
      "The classification loss after processing this batch is:  0.2003869116306305\n",
      "The representation loss after processing this batch is:  0.002294398844242096\n",
      "\n",
      "The classification loss after processing this batch is:  0.13386516273021698\n",
      "The representation loss after processing this batch is:  0.002430260181427002\n",
      "\n",
      "The classification loss after processing this batch is:  0.18289156258106232\n",
      "The representation loss after processing this batch is:  0.0021727681159973145\n",
      "\n",
      "The classification loss after processing this batch is:  0.11510681360960007\n",
      "The representation loss after processing this batch is:  0.0026569217443466187\n",
      "\n",
      "The classification loss after processing this batch is:  0.1611495465040207\n",
      "The representation loss after processing this batch is:  0.002392403781414032\n",
      "\n",
      "The classification loss after processing this batch is:  0.0804189145565033\n",
      "The representation loss after processing this batch is:  0.002498157322406769\n",
      "\n",
      "The classification loss after processing this batch is:  0.05629754066467285\n",
      "The representation loss after processing this batch is:  0.002761833369731903\n",
      "\n",
      "The classification loss after processing this batch is:  0.03015541285276413\n",
      "The representation loss after processing this batch is:  0.0023002997040748596\n",
      "\n",
      "The classification loss after processing this batch is:  0.052276454865932465\n",
      "The representation loss after processing this batch is:  0.002345636487007141\n",
      "\n",
      "The classification loss after processing this batch is:  0.19181551039218903\n",
      "The representation loss after processing this batch is:  0.002500385046005249\n",
      "\n",
      "The classification loss after processing this batch is:  0.10958520323038101\n",
      "The representation loss after processing this batch is:  0.0028280094265937805\n",
      "\n",
      "The classification loss after processing this batch is:  0.03803523629903793\n",
      "The representation loss after processing this batch is:  0.0022720322012901306\n",
      "\n",
      "The classification loss after processing this batch is:  0.02718644216656685\n",
      "The representation loss after processing this batch is:  0.002791851758956909\n",
      "\n",
      "The classification loss after processing this batch is:  0.024754447862505913\n",
      "The representation loss after processing this batch is:  0.002926863729953766\n",
      "\n",
      "The classification loss after processing this batch is:  0.05274347588419914\n",
      "The representation loss after processing this batch is:  0.0032424703240394592\n",
      "\n",
      "The classification loss after processing this batch is:  0.06115484982728958\n",
      "The representation loss after processing this batch is:  0.0026824548840522766\n",
      "\n",
      "The classification loss after processing this batch is:  0.04154174029827118\n",
      "The representation loss after processing this batch is:  0.002757713198661804\n",
      "\n",
      "The classification loss after processing this batch is:  0.018592465668916702\n",
      "The representation loss after processing this batch is:  0.002806246280670166\n",
      "\n",
      "The classification loss after processing this batch is:  0.036315061151981354\n",
      "The representation loss after processing this batch is:  0.00302211195230484\n",
      "\n",
      "The classification loss after processing this batch is:  0.07134187966585159\n",
      "The representation loss after processing this batch is:  0.003391370177268982\n",
      "\n",
      "The classification loss after processing this batch is:  0.011189294047653675\n",
      "The representation loss after processing this batch is:  0.0034175440669059753\n",
      "\n",
      "The classification loss after processing this batch is:  0.03655635938048363\n",
      "The representation loss after processing this batch is:  0.0028722137212753296\n",
      "\n",
      "The classification loss after processing this batch is:  0.13055258989334106\n",
      "The representation loss after processing this batch is:  0.002914540469646454\n",
      "\n",
      "The classification loss after processing this batch is:  0.020367177203297615\n",
      "The representation loss after processing this batch is:  0.0031387433409690857\n",
      "\n",
      "The classification loss after processing this batch is:  0.012078388594090939\n",
      "The representation loss after processing this batch is:  0.002746880054473877\n",
      "\n",
      "The classification loss after processing this batch is:  0.015951840206980705\n",
      "The representation loss after processing this batch is:  0.0029557719826698303\n",
      "\n",
      "The classification loss after processing this batch is:  0.022083265706896782\n",
      "The representation loss after processing this batch is:  0.003062121570110321\n",
      "\n",
      "The classification loss after processing this batch is:  0.032091185450553894\n",
      "The representation loss after processing this batch is:  0.002798616886138916\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.026859665289521217\n",
      "The representation loss after processing this batch is:  0.0031694918870925903\n",
      "\n",
      "The classification loss after processing this batch is:  0.012619010172784328\n",
      "The representation loss after processing this batch is:  0.0034019574522972107\n",
      "\n",
      "The classification loss after processing this batch is:  0.20949871838092804\n",
      "The representation loss after processing this batch is:  0.0031749308109283447\n",
      "\n",
      "The classification loss after processing this batch is:  0.2594659626483917\n",
      "The representation loss after processing this batch is:  0.0032173320651054382\n",
      "\n",
      "The classification loss after processing this batch is:  0.21003273129463196\n",
      "The representation loss after processing this batch is:  0.0036155208945274353\n",
      "\n",
      "The classification loss after processing this batch is:  0.03527740761637688\n",
      "The representation loss after processing this batch is:  0.002524659037590027\n",
      "\n",
      "The classification loss after processing this batch is:  0.01391779538244009\n",
      "The representation loss after processing this batch is:  0.003241993486881256\n",
      "\n",
      "The classification loss after processing this batch is:  0.008875871077179909\n",
      "The representation loss after processing this batch is:  0.002147577702999115\n",
      "\n",
      "The classification loss after processing this batch is:  0.11908959597349167\n",
      "The representation loss after processing this batch is:  0.0023723840713500977\n",
      "\n",
      "The classification loss after processing this batch is:  0.3183680474758148\n",
      "The representation loss after processing this batch is:  0.00260964035987854\n",
      "\n",
      "The classification loss after processing this batch is:  0.05890389159321785\n",
      "The representation loss after processing this batch is:  0.002510286867618561\n",
      "\n",
      "The classification loss after processing this batch is:  0.03225797414779663\n",
      "The representation loss after processing this batch is:  0.003052137792110443\n",
      "\n",
      "The classification loss after processing this batch is:  0.03352021798491478\n",
      "The representation loss after processing this batch is:  0.0028862878680229187\n",
      "\n",
      "The classification loss after processing this batch is:  0.040952205657958984\n",
      "The representation loss after processing this batch is:  0.003298260271549225\n",
      "\n",
      "The classification loss after processing this batch is:  0.07007487118244171\n",
      "The representation loss after processing this batch is:  0.002329830080270767\n",
      "\n",
      "The classification loss after processing this batch is:  0.03681314364075661\n",
      "The representation loss after processing this batch is:  0.0025473684072494507\n",
      "\n",
      "The classification loss after processing this batch is:  0.09680990129709244\n",
      "The representation loss after processing this batch is:  0.0024402402341365814\n",
      "\n",
      "The classification loss after processing this batch is:  0.09234268963336945\n",
      "The representation loss after processing this batch is:  0.0022497735917568207\n",
      "\n",
      "The classification loss after processing this batch is:  0.1168307512998581\n",
      "The representation loss after processing this batch is:  0.0026075802743434906\n",
      "\n",
      "The classification loss after processing this batch is:  0.05595638230443001\n",
      "The representation loss after processing this batch is:  0.002623133361339569\n",
      "\n",
      "The classification loss after processing this batch is:  0.05618318170309067\n",
      "The representation loss after processing this batch is:  0.0027810782194137573\n",
      "\n",
      "The classification loss after processing this batch is:  0.12516151368618011\n",
      "The representation loss after processing this batch is:  0.0022040195763111115\n",
      "\n",
      "The classification loss after processing this batch is:  0.10781972855329514\n",
      "The representation loss after processing this batch is:  0.0021550804376602173\n",
      "\n",
      "The classification loss after processing this batch is:  0.05863828584551811\n",
      "The representation loss after processing this batch is:  0.002484425902366638\n",
      "\n",
      "The classification loss after processing this batch is:  0.12390118092298508\n",
      "The representation loss after processing this batch is:  0.0023332200944423676\n",
      "\n",
      "The classification loss after processing this batch is:  0.08292350172996521\n",
      "The representation loss after processing this batch is:  0.0024522989988327026\n",
      "\n",
      "The classification loss after processing this batch is:  0.1062382385134697\n",
      "The representation loss after processing this batch is:  0.0030075088143348694\n",
      "\n",
      "The classification loss after processing this batch is:  0.06948251277208328\n",
      "The representation loss after processing this batch is:  0.00244767963886261\n",
      "\n",
      "The classification loss after processing this batch is:  0.21626530587673187\n",
      "The representation loss after processing this batch is:  0.002571757882833481\n",
      "\n",
      "The classification loss after processing this batch is:  0.08341685682535172\n",
      "The representation loss after processing this batch is:  0.0022315382957458496\n",
      "\n",
      "The classification loss after processing this batch is:  0.09014887362718582\n",
      "The representation loss after processing this batch is:  0.002495158463716507\n",
      "\n",
      "The classification loss after processing this batch is:  0.19611097872257233\n",
      "The representation loss after processing this batch is:  0.002595420926809311\n",
      "\n",
      "The classification loss after processing this batch is:  0.10327590256929398\n",
      "The representation loss after processing this batch is:  0.0024808794260025024\n",
      "\n",
      "The classification loss after processing this batch is:  0.06639354676008224\n",
      "The representation loss after processing this batch is:  0.0026721470057964325\n",
      "\n",
      "The classification loss after processing this batch is:  0.2001437395811081\n",
      "The representation loss after processing this batch is:  0.002871207892894745\n",
      "\n",
      "The classification loss after processing this batch is:  0.11054316908121109\n",
      "The representation loss after processing this batch is:  0.0025377050042152405\n",
      "\n",
      "The classification loss after processing this batch is:  0.28653112053871155\n",
      "The representation loss after processing this batch is:  0.002354443073272705\n",
      "\n",
      "The classification loss after processing this batch is:  0.07595367729663849\n",
      "The representation loss after processing this batch is:  0.0021378882229328156\n",
      "\n",
      "The classification loss after processing this batch is:  0.053182318806648254\n",
      "The representation loss after processing this batch is:  0.002402558922767639\n",
      "\n",
      "The classification loss after processing this batch is:  0.06872109323740005\n",
      "The representation loss after processing this batch is:  0.0021864883601665497\n",
      "\n",
      "The classification loss after processing this batch is:  0.0916292741894722\n",
      "The representation loss after processing this batch is:  0.0022238492965698242\n",
      "\n",
      "The classification loss after processing this batch is:  0.06823131442070007\n",
      "The representation loss after processing this batch is:  0.002286437898874283\n",
      "\n",
      "The classification loss after processing this batch is:  0.038352951407432556\n",
      "The representation loss after processing this batch is:  0.002376250922679901\n",
      "\n",
      "The classification loss after processing this batch is:  0.0313696451485157\n",
      "The representation loss after processing this batch is:  0.0025719255208969116\n",
      "\n",
      "The classification loss after processing this batch is:  0.03353222832083702\n",
      "The representation loss after processing this batch is:  0.0023937970399856567\n",
      "\n",
      "The classification loss after processing this batch is:  0.06411580741405487\n",
      "The representation loss after processing this batch is:  0.0024355873465538025\n",
      "\n",
      "The classification loss after processing this batch is:  0.16667570173740387\n",
      "The representation loss after processing this batch is:  0.0024739429354667664\n",
      "\n",
      "The classification loss after processing this batch is:  0.0660606250166893\n",
      "The representation loss after processing this batch is:  0.0027463920414447784\n",
      "\n",
      "The classification loss after processing this batch is:  0.08959643542766571\n",
      "The representation loss after processing this batch is:  0.0023553818464279175\n",
      "\n",
      "The classification loss after processing this batch is:  0.032047729939222336\n",
      "The representation loss after processing this batch is:  0.0022590607404708862\n",
      "\n",
      "The classification loss after processing this batch is:  0.042232971638441086\n",
      "The representation loss after processing this batch is:  0.0024835914373397827\n",
      "\n",
      "The classification loss after processing this batch is:  0.08184445649385452\n",
      "The representation loss after processing this batch is:  0.002285085618495941\n",
      "\n",
      "The classification loss after processing this batch is:  0.03992241993546486\n",
      "The representation loss after processing this batch is:  0.002486109733581543\n",
      "\n",
      "The classification loss after processing this batch is:  0.06139735132455826\n",
      "The representation loss after processing this batch is:  0.002430759370326996\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.13064801692962646\n",
      "The representation loss after processing this batch is:  0.002917572855949402\n",
      "\n",
      "The classification loss after processing this batch is:  0.10305183380842209\n",
      "The representation loss after processing this batch is:  0.0025611072778701782\n",
      "\n",
      "The classification loss after processing this batch is:  0.09590795636177063\n",
      "The representation loss after processing this batch is:  0.0021294578909873962\n",
      "\n",
      "The classification loss after processing this batch is:  0.13775832951068878\n",
      "The representation loss after processing this batch is:  0.002406574785709381\n",
      "\n",
      "The classification loss after processing this batch is:  0.07063855975866318\n",
      "The representation loss after processing this batch is:  0.002277754247188568\n",
      "\n",
      "The classification loss after processing this batch is:  0.07428120821714401\n",
      "The representation loss after processing this batch is:  0.0023492127656936646\n",
      "\n",
      "The classification loss after processing this batch is:  0.17870338261127472\n",
      "The representation loss after processing this batch is:  0.00296156108379364\n",
      "\n",
      "The classification loss after processing this batch is:  0.03697638958692551\n",
      "The representation loss after processing this batch is:  0.0024726316332817078\n",
      "\n",
      "The classification loss after processing this batch is:  0.1169406920671463\n",
      "The representation loss after processing this batch is:  0.002195097506046295\n",
      "\n",
      "The classification loss after processing this batch is:  0.04173593968153\n",
      "The representation loss after processing this batch is:  0.0023011937737464905\n",
      "\n",
      "The classification loss after processing this batch is:  0.09303220361471176\n",
      "The representation loss after processing this batch is:  0.002273671329021454\n",
      "\n",
      "The classification loss after processing this batch is:  0.1118818148970604\n",
      "The representation loss after processing this batch is:  0.0026151128113269806\n",
      "\n",
      "The classification loss after processing this batch is:  0.054710257798433304\n",
      "The representation loss after processing this batch is:  0.00249660387635231\n",
      "\n",
      "The classification loss after processing this batch is:  0.11072955280542374\n",
      "The representation loss after processing this batch is:  0.002615496516227722\n",
      "\n",
      "The classification loss after processing this batch is:  0.10008091479539871\n",
      "The representation loss after processing this batch is:  0.0026753395795822144\n",
      "\n",
      "The classification loss after processing this batch is:  0.0862778052687645\n",
      "The representation loss after processing this batch is:  0.0025165900588035583\n",
      "\n",
      "The classification loss after processing this batch is:  0.1284579634666443\n",
      "The representation loss after processing this batch is:  0.0022949352860450745\n",
      "\n",
      "The classification loss after processing this batch is:  0.07556770741939545\n",
      "The representation loss after processing this batch is:  0.0028463751077651978\n",
      "\n",
      "The classification loss after processing this batch is:  0.16082432866096497\n",
      "The representation loss after processing this batch is:  0.0025403574109077454\n",
      "\n",
      "The classification loss after processing this batch is:  0.07842060923576355\n",
      "The representation loss after processing this batch is:  0.002339012920856476\n",
      "\n",
      "The classification loss after processing this batch is:  0.05411098152399063\n",
      "The representation loss after processing this batch is:  0.002237088978290558\n",
      "\n",
      "The classification loss after processing this batch is:  0.13927669823169708\n",
      "The representation loss after processing this batch is:  0.002370990812778473\n",
      "\n",
      "The classification loss after processing this batch is:  0.09390874952077866\n",
      "The representation loss after processing this batch is:  0.0022290050983428955\n",
      "\n",
      "The classification loss after processing this batch is:  0.06915661692619324\n",
      "The representation loss after processing this batch is:  0.0022283755242824554\n",
      "\n",
      "The classification loss after processing this batch is:  0.077501580119133\n",
      "The representation loss after processing this batch is:  0.002235807478427887\n",
      "\n",
      "The classification loss after processing this batch is:  0.03458569943904877\n",
      "The representation loss after processing this batch is:  0.0023389793932437897\n",
      "\n",
      "The classification loss after processing this batch is:  0.05457393825054169\n",
      "The representation loss after processing this batch is:  0.0025317370891571045\n",
      "\n",
      "The classification loss after processing this batch is:  0.09232566505670547\n",
      "The representation loss after processing this batch is:  0.0019608139991760254\n",
      "\n",
      "The classification loss after processing this batch is:  0.06065024062991142\n",
      "The representation loss after processing this batch is:  0.002338409423828125\n",
      "\n",
      "The classification loss after processing this batch is:  0.14166277647018433\n",
      "The representation loss after processing this batch is:  0.0024149008095264435\n",
      "\n",
      "The classification loss after processing this batch is:  0.10595090687274933\n",
      "The representation loss after processing this batch is:  0.002389702945947647\n",
      "\n",
      "The classification loss after processing this batch is:  0.07837260514497757\n",
      "The representation loss after processing this batch is:  0.0025550425052642822\n",
      "\n",
      "The classification loss after processing this batch is:  0.06622298806905746\n",
      "The representation loss after processing this batch is:  0.002122946083545685\n",
      "\n",
      "The classification loss after processing this batch is:  0.055909547954797745\n",
      "The representation loss after processing this batch is:  0.0024655237793922424\n",
      "\n",
      "The classification loss after processing this batch is:  0.11463132500648499\n",
      "The representation loss after processing this batch is:  0.0022841356694698334\n",
      "\n",
      "The classification loss after processing this batch is:  0.1447714865207672\n",
      "The representation loss after processing this batch is:  0.00229528546333313\n",
      "\n",
      "The classification loss after processing this batch is:  0.0671490728855133\n",
      "The representation loss after processing this batch is:  0.0023633018136024475\n",
      "\n",
      "The classification loss after processing this batch is:  0.23194852471351624\n",
      "The representation loss after processing this batch is:  0.0021947473287582397\n",
      "\n",
      "The classification loss after processing this batch is:  0.0934913158416748\n",
      "The representation loss after processing this batch is:  0.00221184641122818\n",
      "\n",
      "The classification loss after processing this batch is:  0.04598018154501915\n",
      "The representation loss after processing this batch is:  0.002971455454826355\n",
      "\n",
      "The classification loss after processing this batch is:  0.11149553954601288\n",
      "The representation loss after processing this batch is:  0.002262979745864868\n",
      "\n",
      "The classification loss after processing this batch is:  0.03553996980190277\n",
      "The representation loss after processing this batch is:  0.0025011971592903137\n",
      "\n",
      "The classification loss after processing this batch is:  0.2069069892168045\n",
      "The representation loss after processing this batch is:  0.002512522041797638\n",
      "\n",
      "The classification loss after processing this batch is:  0.10995312035083771\n",
      "The representation loss after processing this batch is:  0.0021901577711105347\n",
      "\n",
      "The classification loss after processing this batch is:  0.10946973413228989\n",
      "The representation loss after processing this batch is:  0.002286326140165329\n",
      "\n",
      "The classification loss after processing this batch is:  0.2361680418252945\n",
      "The representation loss after processing this batch is:  0.0022834166884422302\n",
      "\n",
      "The classification loss after processing this batch is:  0.11149952560663223\n",
      "The representation loss after processing this batch is:  0.002369120717048645\n",
      "\n",
      "The classification loss after processing this batch is:  0.059931278228759766\n",
      "The representation loss after processing this batch is:  0.0024017468094825745\n",
      "\n",
      "The classification loss after processing this batch is:  0.09717113524675369\n",
      "The representation loss after processing this batch is:  0.0022126957774162292\n",
      "\n",
      "The classification loss after processing this batch is:  0.09450394660234451\n",
      "The representation loss after processing this batch is:  0.002287156879901886\n",
      "\n",
      "The classification loss after processing this batch is:  0.14390698075294495\n",
      "The representation loss after processing this batch is:  0.0025776103138923645\n",
      "\n",
      "The classification loss after processing this batch is:  0.047776225954294205\n",
      "The representation loss after processing this batch is:  0.002407766878604889\n",
      "\n",
      "The classification loss after processing this batch is:  0.08919458836317062\n",
      "The representation loss after processing this batch is:  0.0023961514234542847\n",
      "\n",
      "The classification loss after processing this batch is:  0.1260809451341629\n",
      "The representation loss after processing this batch is:  0.0023973658680915833\n",
      "\n",
      "The classification loss after processing this batch is:  0.13650913536548615\n",
      "The representation loss after processing this batch is:  0.0024654269218444824\n",
      "\n",
      "The classification loss after processing this batch is:  0.140557199716568\n",
      "The representation loss after processing this batch is:  0.002299148589372635\n",
      "\n",
      "The classification loss after processing this batch is:  0.17233772575855255\n",
      "The representation loss after processing this batch is:  0.002706266939640045\n",
      "\n",
      "The classification loss after processing this batch is:  0.08535433560609818\n",
      "The representation loss after processing this batch is:  0.002909630537033081\n",
      "\n",
      "The classification loss after processing this batch is:  0.055951815098524094\n",
      "The representation loss after processing this batch is:  0.0025036707520484924\n",
      "\n",
      "The classification loss after processing this batch is:  0.07673794776201248\n",
      "The representation loss after processing this batch is:  0.0024045631289482117\n",
      "\n",
      "The classification loss after processing this batch is:  0.035936590284109116\n",
      "The representation loss after processing this batch is:  0.0022089332342147827\n",
      "\n",
      "The classification loss after processing this batch is:  0.09554586559534073\n",
      "The representation loss after processing this batch is:  0.0024529844522476196\n",
      "\n",
      "The classification loss after processing this batch is:  0.13740739226341248\n",
      "The representation loss after processing this batch is:  0.0023506805300712585\n",
      "\n",
      "The classification loss after processing this batch is:  0.1774383932352066\n",
      "The representation loss after processing this batch is:  0.0025636330246925354\n",
      "\n",
      "The classification loss after processing this batch is:  0.21215257048606873\n",
      "The representation loss after processing this batch is:  0.0025545507669448853\n",
      "\n",
      "The classification loss after processing this batch is:  0.056527577340602875\n",
      "The representation loss after processing this batch is:  0.0025655850768089294\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.0870913490653038\n",
      "The representation loss after processing this batch is:  0.002601839601993561\n",
      "\n",
      "The classification loss after processing this batch is:  0.13971729576587677\n",
      "The representation loss after processing this batch is:  0.002252396196126938\n",
      "\n",
      "The classification loss after processing this batch is:  0.03982776775956154\n",
      "The representation loss after processing this batch is:  0.002579234540462494\n",
      "\n",
      "The classification loss after processing this batch is:  0.055487897247076035\n",
      "The representation loss after processing this batch is:  0.002460002899169922\n",
      "\n",
      "The classification loss after processing this batch is:  0.11874423176050186\n",
      "The representation loss after processing this batch is:  0.0021402016282081604\n",
      "\n",
      "The classification loss after processing this batch is:  0.07306622713804245\n",
      "The representation loss after processing this batch is:  0.0031547918915748596\n",
      "\n",
      "The classification loss after processing this batch is:  0.09846147149801254\n",
      "The representation loss after processing this batch is:  0.0025587379932403564\n",
      "\n",
      "The classification loss after processing this batch is:  0.16912397742271423\n",
      "The representation loss after processing this batch is:  0.003296308219432831\n",
      "\n",
      "The classification loss after processing this batch is:  0.2479802519083023\n",
      "The representation loss after processing this batch is:  0.002203837037086487\n",
      "\n",
      "The classification loss after processing this batch is:  0.08525476604700089\n",
      "The representation loss after processing this batch is:  0.0024362578988075256\n",
      "\n",
      "The classification loss after processing this batch is:  0.1891356110572815\n",
      "The representation loss after processing this batch is:  0.0023084059357643127\n",
      "\n",
      "The classification loss after processing this batch is:  0.11763358116149902\n",
      "The representation loss after processing this batch is:  0.0022705160081386566\n",
      "\n",
      "The classification loss after processing this batch is:  0.03627438470721245\n",
      "The representation loss after processing this batch is:  0.0024450868368148804\n",
      "\n",
      "The classification loss after processing this batch is:  0.10858498513698578\n",
      "The representation loss after processing this batch is:  0.0022343844175338745\n",
      "\n",
      "The classification loss after processing this batch is:  0.30142125487327576\n",
      "The representation loss after processing this batch is:  0.0027517005801200867\n",
      "\n",
      "The classification loss after processing this batch is:  0.12622720003128052\n",
      "The representation loss after processing this batch is:  0.002612851560115814\n",
      "\n",
      "The classification loss after processing this batch is:  0.04388667270541191\n",
      "The representation loss after processing this batch is:  0.0026331692934036255\n",
      "\n",
      "The classification loss after processing this batch is:  0.05108381062746048\n",
      "The representation loss after processing this batch is:  0.002583462744951248\n",
      "\n",
      "The classification loss after processing this batch is:  0.03917451575398445\n",
      "The representation loss after processing this batch is:  0.0027238279581069946\n",
      "\n",
      "The classification loss after processing this batch is:  0.07277122884988785\n",
      "The representation loss after processing this batch is:  0.002601608633995056\n",
      "\n",
      "The classification loss after processing this batch is:  0.08042021095752716\n",
      "The representation loss after processing this batch is:  0.002702876925468445\n",
      "\n",
      "The classification loss after processing this batch is:  0.11429142206907272\n",
      "The representation loss after processing this batch is:  0.002530798316001892\n",
      "\n",
      "The classification loss after processing this batch is:  0.10196030139923096\n",
      "The representation loss after processing this batch is:  0.0024288445711135864\n",
      "\n",
      "The classification loss after processing this batch is:  0.1624486893415451\n",
      "The representation loss after processing this batch is:  0.002717427909374237\n",
      "\n",
      "The classification loss after processing this batch is:  0.07332112640142441\n",
      "The representation loss after processing this batch is:  0.0022344551980495453\n",
      "\n",
      "The classification loss after processing this batch is:  0.1093466728925705\n",
      "The representation loss after processing this batch is:  0.0021068453788757324\n",
      "\n",
      "The classification loss after processing this batch is:  0.12217719852924347\n",
      "The representation loss after processing this batch is:  0.0024290457367897034\n",
      "\n",
      "The classification loss after processing this batch is:  0.10479899495840073\n",
      "The representation loss after processing this batch is:  0.0023531727492809296\n",
      "\n",
      "The classification loss after processing this batch is:  0.0769055187702179\n",
      "The representation loss after processing this batch is:  0.00226043164730072\n",
      "\n",
      "The classification loss after processing this batch is:  0.19037386775016785\n",
      "The representation loss after processing this batch is:  0.002309538424015045\n",
      "\n",
      "The classification loss after processing this batch is:  0.12644436955451965\n",
      "The representation loss after processing this batch is:  0.0026915594935417175\n",
      "\n",
      "The classification loss after processing this batch is:  0.11324378848075867\n",
      "The representation loss after processing this batch is:  0.0024006590247154236\n",
      "\n",
      "The classification loss after processing this batch is:  0.11388850957155228\n",
      "The representation loss after processing this batch is:  0.002465352416038513\n",
      "\n",
      "The classification loss after processing this batch is:  0.1676609367132187\n",
      "The representation loss after processing this batch is:  0.002321690320968628\n",
      "\n",
      "The classification loss after processing this batch is:  0.15435631573200226\n",
      "The representation loss after processing this batch is:  0.0025180652737617493\n",
      "\n",
      "The classification loss after processing this batch is:  0.160636767745018\n",
      "The representation loss after processing this batch is:  0.0026901960372924805\n",
      "\n",
      "The classification loss after processing this batch is:  0.12117951363325119\n",
      "The representation loss after processing this batch is:  0.002542749047279358\n",
      "\n",
      "The classification loss after processing this batch is:  0.07709222286939621\n",
      "The representation loss after processing this batch is:  0.0026131197810173035\n",
      "\n",
      "The classification loss after processing this batch is:  0.23691193759441376\n",
      "The representation loss after processing this batch is:  0.00246371328830719\n",
      "\n",
      "The classification loss after processing this batch is:  0.17351701855659485\n",
      "The representation loss after processing this batch is:  0.0021699145436286926\n",
      "\n",
      "The classification loss after processing this batch is:  0.25829270482063293\n",
      "The representation loss after processing this batch is:  0.002451527863740921\n",
      "\n",
      "The classification loss after processing this batch is:  0.26854878664016724\n",
      "The representation loss after processing this batch is:  0.002318449318408966\n",
      "\n",
      "The classification loss after processing this batch is:  0.19279935956001282\n",
      "The representation loss after processing this batch is:  0.0021898336708545685\n",
      "\n",
      "The classification loss after processing this batch is:  0.07993369549512863\n",
      "The representation loss after processing this batch is:  0.002242729067802429\n",
      "\n",
      "The classification loss after processing this batch is:  0.0704180970788002\n",
      "The representation loss after processing this batch is:  0.0022895559668540955\n",
      "\n",
      "The classification loss after processing this batch is:  0.03994133695960045\n",
      "The representation loss after processing this batch is:  0.002590358257293701\n",
      "\n",
      "The classification loss after processing this batch is:  0.07547750324010849\n",
      "The representation loss after processing this batch is:  0.002865016460418701\n",
      "\n",
      "The classification loss after processing this batch is:  0.034448083490133286\n",
      "The representation loss after processing this batch is:  0.002635374665260315\n",
      "\n",
      "The classification loss after processing this batch is:  0.22276030480861664\n",
      "The representation loss after processing this batch is:  0.003275640308856964\n",
      "\n",
      "The classification loss after processing this batch is:  0.12780992686748505\n",
      "The representation loss after processing this batch is:  0.0022982098162174225\n",
      "\n",
      "The classification loss after processing this batch is:  0.06721523404121399\n",
      "The representation loss after processing this batch is:  0.0025578998029232025\n",
      "\n",
      "The classification loss after processing this batch is:  0.13813668489456177\n",
      "The representation loss after processing this batch is:  0.002340395003557205\n",
      "\n",
      "The classification loss after processing this batch is:  0.04894142970442772\n",
      "The representation loss after processing this batch is:  0.0026998966932296753\n",
      "\n",
      "The classification loss after processing this batch is:  0.1129947155714035\n",
      "The representation loss after processing this batch is:  0.002758108079433441\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.16070492565631866\n",
      "The representation loss after processing this batch is:  0.003114454448223114\n",
      "\n",
      "The classification loss after processing this batch is:  0.09971452504396439\n",
      "The representation loss after processing this batch is:  0.0029835477471351624\n",
      "\n",
      "The classification loss after processing this batch is:  0.11636121571063995\n",
      "The representation loss after processing this batch is:  0.002135511487722397\n",
      "\n",
      "The classification loss after processing this batch is:  0.0664794072508812\n",
      "The representation loss after processing this batch is:  0.0022601038217544556\n",
      "\n",
      "The classification loss after processing this batch is:  0.017607713118195534\n",
      "The representation loss after processing this batch is:  0.0024597719311714172\n",
      "\n",
      "The classification loss after processing this batch is:  0.07134509086608887\n",
      "The representation loss after processing this batch is:  0.002524353563785553\n",
      "\n",
      "The classification loss after processing this batch is:  0.048129789531230927\n",
      "The representation loss after processing this batch is:  0.00229857861995697\n",
      "\n",
      "The classification loss after processing this batch is:  0.09703667461872101\n",
      "The representation loss after processing this batch is:  0.0022219866514205933\n",
      "\n",
      "The classification loss after processing this batch is:  0.09422013908624649\n",
      "The representation loss after processing this batch is:  0.0023975446820259094\n",
      "\n",
      "The classification loss after processing this batch is:  0.09373414516448975\n",
      "The representation loss after processing this batch is:  0.0024392977356910706\n",
      "\n",
      "The classification loss after processing this batch is:  0.2827364504337311\n",
      "The representation loss after processing this batch is:  0.0030238255858421326\n",
      "\n",
      "The classification loss after processing this batch is:  0.1889411360025406\n",
      "The representation loss after processing this batch is:  0.002695612609386444\n",
      "\n",
      "The classification loss after processing this batch is:  0.06684816628694534\n",
      "The representation loss after processing this batch is:  0.002332627773284912\n",
      "\n",
      "The classification loss after processing this batch is:  0.043576519936323166\n",
      "The representation loss after processing this batch is:  0.002765130251646042\n",
      "\n",
      "The classification loss after processing this batch is:  0.058775581419467926\n",
      "The representation loss after processing this batch is:  0.002419419586658478\n",
      "\n",
      "The classification loss after processing this batch is:  0.04828440397977829\n",
      "The representation loss after processing this batch is:  0.0024672821164131165\n",
      "\n",
      "The classification loss after processing this batch is:  0.021428963169455528\n",
      "The representation loss after processing this batch is:  0.0026580244302749634\n",
      "\n",
      "The classification loss after processing this batch is:  0.04733699932694435\n",
      "The representation loss after processing this batch is:  0.002762541174888611\n",
      "\n",
      "The classification loss after processing this batch is:  0.1021130234003067\n",
      "The representation loss after processing this batch is:  0.00218045711517334\n",
      "\n",
      "The classification loss after processing this batch is:  0.14343039691448212\n",
      "The representation loss after processing this batch is:  0.002387791872024536\n",
      "\n",
      "The classification loss after processing this batch is:  0.12140430510044098\n",
      "The representation loss after processing this batch is:  0.0026429668068885803\n",
      "\n",
      "The classification loss after processing this batch is:  0.05379936471581459\n",
      "The representation loss after processing this batch is:  0.0024639591574668884\n",
      "\n",
      "The classification loss after processing this batch is:  0.03403240069746971\n",
      "The representation loss after processing this batch is:  0.0022623054683208466\n",
      "\n",
      "The classification loss after processing this batch is:  0.2474239319562912\n",
      "The representation loss after processing this batch is:  0.0023423805832862854\n",
      "\n",
      "The classification loss after processing this batch is:  0.09933499246835709\n",
      "The representation loss after processing this batch is:  0.002651892602443695\n",
      "\n",
      "The classification loss after processing this batch is:  0.04134043678641319\n",
      "The representation loss after processing this batch is:  0.0025709420442581177\n",
      "\n",
      "The classification loss after processing this batch is:  0.09167704731225967\n",
      "The representation loss after processing this batch is:  0.0024320855736732483\n",
      "\n",
      "The classification loss after processing this batch is:  0.08078192174434662\n",
      "The representation loss after processing this batch is:  0.002151869237422943\n",
      "\n",
      "The classification loss after processing this batch is:  0.04535578936338425\n",
      "The representation loss after processing this batch is:  0.002191215753555298\n",
      "\n",
      "The classification loss after processing this batch is:  0.09488631039857864\n",
      "The representation loss after processing this batch is:  0.002164989709854126\n",
      "\n",
      "The classification loss after processing this batch is:  0.062029171735048294\n",
      "The representation loss after processing this batch is:  0.0023690611124038696\n",
      "\n",
      "The classification loss after processing this batch is:  0.053130947053432465\n",
      "The representation loss after processing this batch is:  0.002332538366317749\n",
      "\n",
      "The classification loss after processing this batch is:  0.09534894675016403\n",
      "The representation loss after processing this batch is:  0.0021545961499214172\n",
      "\n",
      "The classification loss after processing this batch is:  0.13864019513130188\n",
      "The representation loss after processing this batch is:  0.002534613013267517\n",
      "\n",
      "The classification loss after processing this batch is:  0.11798360198736191\n",
      "The representation loss after processing this batch is:  0.0023439303040504456\n",
      "\n",
      "The classification loss after processing this batch is:  0.10677646100521088\n",
      "The representation loss after processing this batch is:  0.0021737292408943176\n",
      "\n",
      "The classification loss after processing this batch is:  0.0855986624956131\n",
      "The representation loss after processing this batch is:  0.002291802316904068\n",
      "\n",
      "The classification loss after processing this batch is:  0.1595967710018158\n",
      "The representation loss after processing this batch is:  0.002155520021915436\n",
      "\n",
      "The classification loss after processing this batch is:  0.05484047159552574\n",
      "The representation loss after processing this batch is:  0.002595864236354828\n",
      "\n",
      "The classification loss after processing this batch is:  0.13011999428272247\n",
      "The representation loss after processing this batch is:  0.002286061644554138\n",
      "\n",
      "The classification loss after processing this batch is:  0.05417180806398392\n",
      "The representation loss after processing this batch is:  0.002230420708656311\n",
      "\n",
      "The classification loss after processing this batch is:  0.1205301433801651\n",
      "The representation loss after processing this batch is:  0.002409987151622772\n",
      "\n",
      "The classification loss after processing this batch is:  0.06043044850230217\n",
      "The representation loss after processing this batch is:  0.002625413239002228\n",
      "\n",
      "The classification loss after processing this batch is:  0.0755281150341034\n",
      "The representation loss after processing this batch is:  0.002167530357837677\n",
      "\n",
      "The classification loss after processing this batch is:  0.08550901710987091\n",
      "The representation loss after processing this batch is:  0.002161361277103424\n",
      "\n",
      "The classification loss after processing this batch is:  0.0919281616806984\n",
      "The representation loss after processing this batch is:  0.0024640336632728577\n",
      "\n",
      "The classification loss after processing this batch is:  0.12392734736204147\n",
      "The representation loss after processing this batch is:  0.0023045241832733154\n",
      "\n",
      "The classification loss after processing this batch is:  0.0847332701086998\n",
      "The representation loss after processing this batch is:  0.0021073780953884125\n",
      "\n",
      "The classification loss after processing this batch is:  0.13700957596302032\n",
      "The representation loss after processing this batch is:  0.002144530415534973\n",
      "\n",
      "The classification loss after processing this batch is:  0.14284761250019073\n",
      "The representation loss after processing this batch is:  0.0021957606077194214\n",
      "\n",
      "The classification loss after processing this batch is:  0.19352096319198608\n",
      "The representation loss after processing this batch is:  0.0021064504981040955\n",
      "\n",
      "The classification loss after processing this batch is:  0.13629703223705292\n",
      "The representation loss after processing this batch is:  0.0022047720849514008\n",
      "\n",
      "The classification loss after processing this batch is:  0.07365931570529938\n",
      "The representation loss after processing this batch is:  0.0025372207164764404\n",
      "\n",
      "The classification loss after processing this batch is:  0.15447796881198883\n",
      "The representation loss after processing this batch is:  0.002572864294052124\n",
      "\n",
      "The classification loss after processing this batch is:  0.07803724706172943\n",
      "The representation loss after processing this batch is:  0.0024867653846740723\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.09183286875486374\n",
      "The representation loss after processing this batch is:  0.002551693469285965\n",
      "\n",
      "The classification loss after processing this batch is:  0.17056512832641602\n",
      "The representation loss after processing this batch is:  0.002919815480709076\n",
      "\n",
      "The classification loss after processing this batch is:  0.19207634031772614\n",
      "The representation loss after processing this batch is:  0.0027960389852523804\n",
      "\n",
      "The classification loss after processing this batch is:  0.19966652989387512\n",
      "The representation loss after processing this batch is:  0.0024000778794288635\n",
      "\n",
      "The classification loss after processing this batch is:  0.14172397553920746\n",
      "The representation loss after processing this batch is:  0.002540871500968933\n",
      "\n",
      "The classification loss after processing this batch is:  0.05751414969563484\n",
      "The representation loss after processing this batch is:  0.002347007393836975\n",
      "\n",
      "The classification loss after processing this batch is:  0.08110728114843369\n",
      "The representation loss after processing this batch is:  0.002434864640235901\n",
      "\n",
      "The classification loss after processing this batch is:  0.1804242581129074\n",
      "The representation loss after processing this batch is:  0.0021807216107845306\n",
      "\n",
      "The classification loss after processing this batch is:  0.06317473202943802\n",
      "The representation loss after processing this batch is:  0.0025008320808410645\n",
      "\n",
      "The classification loss after processing this batch is:  0.08795894682407379\n",
      "The representation loss after processing this batch is:  0.0020751431584358215\n",
      "\n",
      "The classification loss after processing this batch is:  0.057194773107767105\n",
      "The representation loss after processing this batch is:  0.0024905353784561157\n",
      "\n",
      "The classification loss after processing this batch is:  0.02355656586587429\n",
      "The representation loss after processing this batch is:  0.0023766160011291504\n",
      "\n",
      "The classification loss after processing this batch is:  0.07564593851566315\n",
      "The representation loss after processing this batch is:  0.0024937577545642853\n",
      "\n",
      "The classification loss after processing this batch is:  0.10497894138097763\n",
      "The representation loss after processing this batch is:  0.002701893448829651\n",
      "\n",
      "The classification loss after processing this batch is:  0.11265824735164642\n",
      "The representation loss after processing this batch is:  0.002382386475801468\n",
      "\n",
      "The classification loss after processing this batch is:  0.10878559201955795\n",
      "The representation loss after processing this batch is:  0.0022346414625644684\n",
      "\n",
      "The classification loss after processing this batch is:  0.08595316857099533\n",
      "The representation loss after processing this batch is:  0.002469390630722046\n",
      "\n",
      "The classification loss after processing this batch is:  0.1404670923948288\n",
      "The representation loss after processing this batch is:  0.002443648874759674\n",
      "\n",
      "The classification loss after processing this batch is:  0.08105252683162689\n",
      "The representation loss after processing this batch is:  0.0024897195398807526\n",
      "\n",
      "The classification loss after processing this batch is:  0.10261065512895584\n",
      "The representation loss after processing this batch is:  0.0031574517488479614\n",
      "\n",
      "The classification loss after processing this batch is:  0.08259309083223343\n",
      "The representation loss after processing this batch is:  0.002577558159828186\n",
      "\n",
      "The classification loss after processing this batch is:  0.09489728510379791\n",
      "The representation loss after processing this batch is:  0.0024453550577163696\n",
      "\n",
      "The classification loss after processing this batch is:  0.16045333445072174\n",
      "The representation loss after processing this batch is:  0.0022018030285835266\n",
      "\n",
      "The classification loss after processing this batch is:  0.2147558182477951\n",
      "The representation loss after processing this batch is:  0.002373065799474716\n",
      "\n",
      "The classification loss after processing this batch is:  0.14454956352710724\n",
      "The representation loss after processing this batch is:  0.0026278868317604065\n",
      "\n",
      "The classification loss after processing this batch is:  0.06002958491444588\n",
      "The representation loss after processing this batch is:  0.002111043781042099\n",
      "\n",
      "The classification loss after processing this batch is:  0.11286841332912445\n",
      "The representation loss after processing this batch is:  0.002681143581867218\n",
      "\n",
      "The classification loss after processing this batch is:  0.10151504725217819\n",
      "The representation loss after processing this batch is:  0.002585317939519882\n",
      "\n",
      "The classification loss after processing this batch is:  0.12941303849220276\n",
      "The representation loss after processing this batch is:  0.002219267189502716\n",
      "\n",
      "The classification loss after processing this batch is:  0.14787334203720093\n",
      "The representation loss after processing this batch is:  0.0027678757905960083\n",
      "\n",
      "The classification loss after processing this batch is:  0.13650546967983246\n",
      "The representation loss after processing this batch is:  0.0025016367435455322\n",
      "\n",
      "The classification loss after processing this batch is:  0.239711731672287\n",
      "The representation loss after processing this batch is:  0.0027752071619033813\n",
      "\n",
      "The classification loss after processing this batch is:  0.09280955791473389\n",
      "The representation loss after processing this batch is:  0.0026618093252182007\n",
      "\n",
      "The classification loss after processing this batch is:  0.09209496527910233\n",
      "The representation loss after processing this batch is:  0.0024174898862838745\n",
      "\n",
      "The classification loss after processing this batch is:  0.10604669153690338\n",
      "The representation loss after processing this batch is:  0.002780698239803314\n",
      "\n",
      "The classification loss after processing this batch is:  0.05494576692581177\n",
      "The representation loss after processing this batch is:  0.0026664137840270996\n",
      "\n",
      "The classification loss after processing this batch is:  0.14623473584651947\n",
      "The representation loss after processing this batch is:  0.0025031641125679016\n",
      "\n",
      "The classification loss after processing this batch is:  0.08237417042255402\n",
      "The representation loss after processing this batch is:  0.0022969134151935577\n",
      "\n",
      "The classification loss after processing this batch is:  0.08534125983715057\n",
      "The representation loss after processing this batch is:  0.0022685378789901733\n",
      "\n",
      "The classification loss after processing this batch is:  0.0803145095705986\n",
      "The representation loss after processing this batch is:  0.0023944154381752014\n",
      "\n",
      "The classification loss after processing this batch is:  0.10949882864952087\n",
      "The representation loss after processing this batch is:  0.0029056966304779053\n",
      "\n",
      "The classification loss after processing this batch is:  0.1410079449415207\n",
      "The representation loss after processing this batch is:  0.002276528626680374\n",
      "\n",
      "The classification loss after processing this batch is:  0.12018003314733505\n",
      "The representation loss after processing this batch is:  0.002540096640586853\n",
      "\n",
      "The classification loss after processing this batch is:  0.09243340790271759\n",
      "The representation loss after processing this batch is:  0.0022687241435050964\n",
      "\n",
      "The classification loss after processing this batch is:  0.03330685570836067\n",
      "The representation loss after processing this batch is:  0.002212073653936386\n",
      "\n",
      "The classification loss after processing this batch is:  0.12964680790901184\n",
      "The representation loss after processing this batch is:  0.001986764371395111\n",
      "\n",
      "The classification loss after processing this batch is:  0.0760706439614296\n",
      "The representation loss after processing this batch is:  0.0019849762320518494\n",
      "\n",
      "The classification loss after processing this batch is:  0.38876786828041077\n",
      "The representation loss after processing this batch is:  0.0025122910737991333\n",
      "\n",
      "The classification loss after processing this batch is:  0.07636688649654388\n",
      "The representation loss after processing this batch is:  0.00238674134016037\n",
      "\n",
      "The classification loss after processing this batch is:  0.11048264056444168\n",
      "The representation loss after processing this batch is:  0.0023455992341041565\n",
      "\n",
      "The classification loss after processing this batch is:  0.25693514943122864\n",
      "The representation loss after processing this batch is:  0.0025078468024730682\n",
      "\n",
      "The classification loss after processing this batch is:  0.06325715780258179\n",
      "The representation loss after processing this batch is:  0.0022593364119529724\n",
      "\n",
      "The classification loss after processing this batch is:  0.16331714391708374\n",
      "The representation loss after processing this batch is:  0.002671077847480774\n",
      "\n",
      "The classification loss after processing this batch is:  0.1032847985625267\n",
      "The representation loss after processing this batch is:  0.0026509352028369904\n",
      "\n",
      "The classification loss after processing this batch is:  0.22227424383163452\n",
      "The representation loss after processing this batch is:  0.0021022260189056396\n",
      "\n",
      "The classification loss after processing this batch is:  0.03931301832199097\n",
      "The representation loss after processing this batch is:  0.0023619607090950012\n",
      "\n",
      "The classification loss after processing this batch is:  0.09257623553276062\n",
      "The representation loss after processing this batch is:  0.002438463270664215\n",
      "\n",
      "The classification loss after processing this batch is:  0.024279601871967316\n",
      "The representation loss after processing this batch is:  0.002543330192565918\n",
      "\n",
      "The classification loss after processing this batch is:  0.028035283088684082\n",
      "The representation loss after processing this batch is:  0.0026323944330215454\n",
      "\n",
      "The classification loss after processing this batch is:  0.05455677956342697\n",
      "The representation loss after processing this batch is:  0.0025381892919540405\n",
      "\n",
      "The classification loss after processing this batch is:  0.046102650463581085\n",
      "The representation loss after processing this batch is:  0.002108559012413025\n",
      "\n",
      "The classification loss after processing this batch is:  0.11036299914121628\n",
      "The representation loss after processing this batch is:  0.0026154741644859314\n",
      "\n",
      "The classification loss after processing this batch is:  0.07852200418710709\n",
      "The representation loss after processing this batch is:  0.0029217377305030823\n",
      "\n",
      "The classification loss after processing this batch is:  0.0805741399526596\n",
      "The representation loss after processing this batch is:  0.0022387877106666565\n",
      "\n",
      "The classification loss after processing this batch is:  0.08743409067392349\n",
      "The representation loss after processing this batch is:  0.002205636352300644\n",
      "\n",
      "The classification loss after processing this batch is:  0.030271904543042183\n",
      "The representation loss after processing this batch is:  0.0024348944425582886\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10509060323238373\n",
      "The representation loss after processing this batch is:  0.002420395612716675\n",
      "\n",
      "The classification loss after processing this batch is:  0.1058291345834732\n",
      "The representation loss after processing this batch is:  0.0026548653841018677\n",
      "\n",
      "The classification loss after processing this batch is:  0.1437259018421173\n",
      "The representation loss after processing this batch is:  0.0026462525129318237\n",
      "\n",
      "The classification loss after processing this batch is:  0.08746500313282013\n",
      "The representation loss after processing this batch is:  0.002258073538541794\n",
      "\n",
      "The classification loss after processing this batch is:  0.06349556893110275\n",
      "The representation loss after processing this batch is:  0.0023138821125030518\n",
      "\n",
      "The classification loss after processing this batch is:  0.17582009732723236\n",
      "The representation loss after processing this batch is:  0.002457655966281891\n",
      "\n",
      "The classification loss after processing this batch is:  0.14761558175086975\n",
      "The representation loss after processing this batch is:  0.0025191158056259155\n",
      "\n",
      "The classification loss after processing this batch is:  0.12275978177785873\n",
      "The representation loss after processing this batch is:  0.0024756789207458496\n",
      "\n",
      "The classification loss after processing this batch is:  0.04065569117665291\n",
      "The representation loss after processing this batch is:  0.002374418079853058\n",
      "\n",
      "The classification loss after processing this batch is:  0.08412889391183853\n",
      "The representation loss after processing this batch is:  0.002566099166870117\n",
      "\n",
      "The classification loss after processing this batch is:  0.10544288903474808\n",
      "The representation loss after processing this batch is:  0.002262178808450699\n",
      "\n",
      "The classification loss after processing this batch is:  0.0984172374010086\n",
      "The representation loss after processing this batch is:  0.0026672780513763428\n",
      "\n",
      "The classification loss after processing this batch is:  0.12659673392772675\n",
      "The representation loss after processing this batch is:  0.003214225172996521\n",
      "\n",
      "The classification loss after processing this batch is:  0.06638017296791077\n",
      "The representation loss after processing this batch is:  0.002823326736688614\n",
      "\n",
      "The classification loss after processing this batch is:  0.10894492268562317\n",
      "The representation loss after processing this batch is:  0.0027227848768234253\n",
      "\n",
      "The classification loss after processing this batch is:  0.15388186275959015\n",
      "The representation loss after processing this batch is:  0.0023750290274620056\n",
      "\n",
      "The classification loss after processing this batch is:  0.06715340167284012\n",
      "The representation loss after processing this batch is:  0.0029340386390686035\n",
      "\n",
      "The classification loss after processing this batch is:  0.11415683478116989\n",
      "The representation loss after processing this batch is:  0.0021754875779151917\n",
      "\n",
      "The classification loss after processing this batch is:  0.04732993617653847\n",
      "The representation loss after processing this batch is:  0.002043910324573517\n",
      "\n",
      "The classification loss after processing this batch is:  0.1325886994600296\n",
      "The representation loss after processing this batch is:  0.0023080408573150635\n",
      "\n",
      "The classification loss after processing this batch is:  0.07056370377540588\n",
      "The representation loss after processing this batch is:  0.00230523943901062\n",
      "\n",
      "The classification loss after processing this batch is:  0.1214771494269371\n",
      "The representation loss after processing this batch is:  0.0025158822536468506\n",
      "\n",
      "The classification loss after processing this batch is:  0.08227138966321945\n",
      "The representation loss after processing this batch is:  0.002630464732646942\n",
      "\n",
      "The classification loss after processing this batch is:  0.07431898266077042\n",
      "The representation loss after processing this batch is:  0.0023652836680412292\n",
      "\n",
      "The classification loss after processing this batch is:  0.10072663426399231\n",
      "The representation loss after processing this batch is:  0.0025358647108078003\n",
      "\n",
      "The classification loss after processing this batch is:  0.1330653578042984\n",
      "The representation loss after processing this batch is:  0.0028414055705070496\n",
      "\n",
      "The classification loss after processing this batch is:  0.11228028684854507\n",
      "The representation loss after processing this batch is:  0.0028102174401283264\n",
      "\n",
      "The classification loss after processing this batch is:  0.10625774413347244\n",
      "The representation loss after processing this batch is:  0.002467285841703415\n",
      "\n",
      "The classification loss after processing this batch is:  0.11862646788358688\n",
      "The representation loss after processing this batch is:  0.002664439380168915\n",
      "\n",
      "The classification loss after processing this batch is:  0.0746251568198204\n",
      "The representation loss after processing this batch is:  0.0024004094302654266\n",
      "\n",
      "The classification loss after processing this batch is:  0.08254027366638184\n",
      "The representation loss after processing this batch is:  0.002634108066558838\n",
      "\n",
      "The classification loss after processing this batch is:  0.049866218119859695\n",
      "The representation loss after processing this batch is:  0.002502046525478363\n",
      "\n",
      "The classification loss after processing this batch is:  0.08177594840526581\n",
      "The representation loss after processing this batch is:  0.0023599080741405487\n",
      "\n",
      "The classification loss after processing this batch is:  0.04714765399694443\n",
      "The representation loss after processing this batch is:  0.002369347959756851\n",
      "\n",
      "The classification loss after processing this batch is:  0.04148952290415764\n",
      "The representation loss after processing this batch is:  0.0021879151463508606\n",
      "\n",
      "The classification loss after processing this batch is:  0.05570749565958977\n",
      "The representation loss after processing this batch is:  0.002588242292404175\n",
      "\n",
      "The classification loss after processing this batch is:  0.029271932318806648\n",
      "The representation loss after processing this batch is:  0.0026879385113716125\n",
      "\n",
      "The classification loss after processing this batch is:  0.14085248112678528\n",
      "The representation loss after processing this batch is:  0.002168312668800354\n",
      "\n",
      "The classification loss after processing this batch is:  0.07709959894418716\n",
      "The representation loss after processing this batch is:  0.0021027326583862305\n",
      "\n",
      "The classification loss after processing this batch is:  0.07501302659511566\n",
      "The representation loss after processing this batch is:  0.0025027692317962646\n",
      "\n",
      "The classification loss after processing this batch is:  0.04070667922496796\n",
      "The representation loss after processing this batch is:  0.002601221203804016\n",
      "\n",
      "The classification loss after processing this batch is:  0.1369272917509079\n",
      "The representation loss after processing this batch is:  0.002524379640817642\n",
      "\n",
      "The classification loss after processing this batch is:  0.09319593757390976\n",
      "The representation loss after processing this batch is:  0.0024738460779190063\n",
      "\n",
      "The classification loss after processing this batch is:  0.08835968375205994\n",
      "The representation loss after processing this batch is:  0.0022839978337287903\n",
      "\n",
      "The classification loss after processing this batch is:  0.08782806992530823\n",
      "The representation loss after processing this batch is:  0.0025446340441703796\n",
      "\n",
      "The classification loss after processing this batch is:  0.06863889843225479\n",
      "The representation loss after processing this batch is:  0.00238698348402977\n",
      "\n",
      "The classification loss after processing this batch is:  0.048725612461566925\n",
      "The representation loss after processing this batch is:  0.0023020803928375244\n",
      "\n",
      "The classification loss after processing this batch is:  0.06715100258588791\n",
      "The representation loss after processing this batch is:  0.002487592399120331\n",
      "\n",
      "The classification loss after processing this batch is:  0.04009907320141792\n",
      "The representation loss after processing this batch is:  0.0023549050092697144\n",
      "\n",
      "The classification loss after processing this batch is:  0.17139312624931335\n",
      "The representation loss after processing this batch is:  0.002390816807746887\n",
      "\n",
      "The classification loss after processing this batch is:  0.1207771748304367\n",
      "The representation loss after processing this batch is:  0.0022432319819927216\n",
      "\n",
      "The classification loss after processing this batch is:  0.12033393234014511\n",
      "The representation loss after processing this batch is:  0.002830818295478821\n",
      "\n",
      "The classification loss after processing this batch is:  0.12282894551753998\n",
      "The representation loss after processing this batch is:  0.0025371015071868896\n",
      "\n",
      "The classification loss after processing this batch is:  0.15857082605361938\n",
      "The representation loss after processing this batch is:  0.0023991018533706665\n",
      "\n",
      "The classification loss after processing this batch is:  0.15379223227500916\n",
      "The representation loss after processing this batch is:  0.002545267343521118\n",
      "\n",
      "The classification loss after processing this batch is:  0.2241055816411972\n",
      "The representation loss after processing this batch is:  0.002244800329208374\n",
      "\n",
      "The classification loss after processing this batch is:  0.16410471498966217\n",
      "The representation loss after processing this batch is:  0.0021832697093486786\n",
      "\n",
      "The classification loss after processing this batch is:  0.09951729327440262\n",
      "The representation loss after processing this batch is:  0.002006717026233673\n",
      "\n",
      "The classification loss after processing this batch is:  0.0707123801112175\n",
      "The representation loss after processing this batch is:  0.0022192783653736115\n",
      "\n",
      "The classification loss after processing this batch is:  0.055320773273706436\n",
      "The representation loss after processing this batch is:  0.002304069697856903\n",
      "\n",
      "The classification loss after processing this batch is:  0.038775596767663956\n",
      "The representation loss after processing this batch is:  0.0023291856050491333\n",
      "\n",
      "The classification loss after processing this batch is:  0.06088768690824509\n",
      "The representation loss after processing this batch is:  0.002804987132549286\n",
      "\n",
      "The classification loss after processing this batch is:  0.12282487004995346\n",
      "The representation loss after processing this batch is:  0.002408493310213089\n",
      "\n",
      "The classification loss after processing this batch is:  0.05358656495809555\n",
      "The representation loss after processing this batch is:  0.0023279786109924316\n",
      "\n",
      "The classification loss after processing this batch is:  0.1882963627576828\n",
      "The representation loss after processing this batch is:  0.002608664333820343\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.09372463822364807\n",
      "The representation loss after processing this batch is:  0.00245869904756546\n",
      "\n",
      "The classification loss after processing this batch is:  0.11995872855186462\n",
      "The representation loss after processing this batch is:  0.0021974779665470123\n",
      "\n",
      "The classification loss after processing this batch is:  0.09456692636013031\n",
      "The representation loss after processing this batch is:  0.002216555178165436\n",
      "\n",
      "The classification loss after processing this batch is:  0.14879386126995087\n",
      "The representation loss after processing this batch is:  0.002078745514154434\n",
      "\n",
      "The classification loss after processing this batch is:  0.0981091633439064\n",
      "The representation loss after processing this batch is:  0.002337466925382614\n",
      "\n",
      "The classification loss after processing this batch is:  0.08698870986700058\n",
      "The representation loss after processing this batch is:  0.0026922672986984253\n",
      "\n",
      "The classification loss after processing this batch is:  0.12530742585659027\n",
      "The representation loss after processing this batch is:  0.0023333802819252014\n",
      "\n",
      "The classification loss after processing this batch is:  0.042017027735710144\n",
      "The representation loss after processing this batch is:  0.002299197018146515\n",
      "\n",
      "The classification loss after processing this batch is:  0.03993212804198265\n",
      "The representation loss after processing this batch is:  0.0022756755352020264\n",
      "\n",
      "The classification loss after processing this batch is:  0.10600105673074722\n",
      "The representation loss after processing this batch is:  0.002704612910747528\n",
      "\n",
      "The classification loss after processing this batch is:  0.16718599200248718\n",
      "The representation loss after processing this batch is:  0.0023819580674171448\n",
      "\n",
      "The classification loss after processing this batch is:  0.1337273269891739\n",
      "The representation loss after processing this batch is:  0.0026948973536491394\n",
      "\n",
      "The classification loss after processing this batch is:  0.06136610731482506\n",
      "The representation loss after processing this batch is:  0.003038369119167328\n",
      "\n",
      "The classification loss after processing this batch is:  0.09697280079126358\n",
      "The representation loss after processing this batch is:  0.00273287296295166\n",
      "\n",
      "The classification loss after processing this batch is:  0.06017637252807617\n",
      "The representation loss after processing this batch is:  0.0025087669491767883\n",
      "\n",
      "The classification loss after processing this batch is:  0.1860872209072113\n",
      "The representation loss after processing this batch is:  0.002471916377544403\n",
      "\n",
      "The classification loss after processing this batch is:  0.045978594571352005\n",
      "The representation loss after processing this batch is:  0.0021466612815856934\n",
      "\n",
      "The classification loss after processing this batch is:  0.04456881061196327\n",
      "The representation loss after processing this batch is:  0.0025646165013313293\n",
      "\n",
      "The classification loss after processing this batch is:  0.12257977575063705\n",
      "The representation loss after processing this batch is:  0.0030035972595214844\n",
      "\n",
      "The classification loss after processing this batch is:  0.08537419885396957\n",
      "The representation loss after processing this batch is:  0.0026262030005455017\n",
      "\n",
      "The classification loss after processing this batch is:  0.06607789546251297\n",
      "The representation loss after processing this batch is:  0.0027033835649490356\n",
      "\n",
      "The classification loss after processing this batch is:  0.03270959109067917\n",
      "The representation loss after processing this batch is:  0.002353508025407791\n",
      "\n",
      "The classification loss after processing this batch is:  0.10813464969396591\n",
      "The representation loss after processing this batch is:  0.002646133303642273\n",
      "\n",
      "The classification loss after processing this batch is:  0.1044212281703949\n",
      "The representation loss after processing this batch is:  0.0026203319430351257\n",
      "\n",
      "The classification loss after processing this batch is:  0.14709612727165222\n",
      "The representation loss after processing this batch is:  0.0022219568490982056\n",
      "\n",
      "The classification loss after processing this batch is:  0.12528058886528015\n",
      "The representation loss after processing this batch is:  0.002654045820236206\n",
      "\n",
      "The classification loss after processing this batch is:  0.05591747909784317\n",
      "The representation loss after processing this batch is:  0.0023123547434806824\n",
      "\n",
      "The classification loss after processing this batch is:  0.06976635754108429\n",
      "The representation loss after processing this batch is:  0.0021989531815052032\n",
      "\n",
      "The classification loss after processing this batch is:  0.12878860533237457\n",
      "The representation loss after processing this batch is:  0.00274021178483963\n",
      "\n",
      "The classification loss after processing this batch is:  0.146884486079216\n",
      "The representation loss after processing this batch is:  0.002835609018802643\n",
      "\n",
      "The classification loss after processing this batch is:  0.18957582116127014\n",
      "The representation loss after processing this batch is:  0.0030372068285942078\n",
      "\n",
      "The classification loss after processing this batch is:  0.2286345660686493\n",
      "The representation loss after processing this batch is:  0.0025704652070999146\n",
      "\n",
      "The classification loss after processing this batch is:  0.05030923709273338\n",
      "The representation loss after processing this batch is:  0.002241849899291992\n",
      "\n",
      "The classification loss after processing this batch is:  0.15839862823486328\n",
      "The representation loss after processing this batch is:  0.0024151839315891266\n",
      "\n",
      "The classification loss after processing this batch is:  0.07594600319862366\n",
      "The representation loss after processing this batch is:  0.002188563346862793\n",
      "\n",
      "The classification loss after processing this batch is:  0.07670512795448303\n",
      "The representation loss after processing this batch is:  0.0023581460118293762\n",
      "\n",
      "The classification loss after processing this batch is:  0.05718513950705528\n",
      "The representation loss after processing this batch is:  0.002581089735031128\n",
      "\n",
      "The classification loss after processing this batch is:  0.1495274007320404\n",
      "The representation loss after processing this batch is:  0.00238741934299469\n",
      "\n",
      "The classification loss after processing this batch is:  0.08857453614473343\n",
      "The representation loss after processing this batch is:  0.0023665130138397217\n",
      "\n",
      "The classification loss after processing this batch is:  0.06259440630674362\n",
      "The representation loss after processing this batch is:  0.002401299774646759\n",
      "\n",
      "The classification loss after processing this batch is:  0.12564235925674438\n",
      "The representation loss after processing this batch is:  0.002481803297996521\n",
      "\n",
      "The classification loss after processing this batch is:  0.02827884443104267\n",
      "The representation loss after processing this batch is:  0.0026696771383285522\n",
      "\n",
      "The classification loss after processing this batch is:  0.09656328707933426\n",
      "The representation loss after processing this batch is:  0.002715282142162323\n",
      "\n",
      "The classification loss after processing this batch is:  0.12981346249580383\n",
      "The representation loss after processing this batch is:  0.0023749396204948425\n",
      "\n",
      "The classification loss after processing this batch is:  0.11927774548530579\n",
      "The representation loss after processing this batch is:  0.0024625882506370544\n",
      "\n",
      "The classification loss after processing this batch is:  0.032513637095689774\n",
      "The representation loss after processing this batch is:  0.0028177574276924133\n",
      "\n",
      "The classification loss after processing this batch is:  0.06138842552900314\n",
      "The representation loss after processing this batch is:  0.002213273197412491\n",
      "\n",
      "The classification loss after processing this batch is:  0.14746278524398804\n",
      "The representation loss after processing this batch is:  0.002722233533859253\n",
      "\n",
      "The classification loss after processing this batch is:  0.11394355446100235\n",
      "The representation loss after processing this batch is:  0.002198450267314911\n",
      "\n",
      "The classification loss after processing this batch is:  0.12488220632076263\n",
      "The representation loss after processing this batch is:  0.0023756399750709534\n",
      "\n",
      "The classification loss after processing this batch is:  0.06674611568450928\n",
      "The representation loss after processing this batch is:  0.0023954808712005615\n",
      "\n",
      "The classification loss after processing this batch is:  0.051030077040195465\n",
      "The representation loss after processing this batch is:  0.00257226824760437\n",
      "\n",
      "The classification loss after processing this batch is:  0.10522697865962982\n",
      "The representation loss after processing this batch is:  0.0020729675889015198\n",
      "\n",
      "The classification loss after processing this batch is:  0.08316008001565933\n",
      "The representation loss after processing this batch is:  0.002451501786708832\n",
      "\n",
      "The classification loss after processing this batch is:  0.12465779483318329\n",
      "The representation loss after processing this batch is:  0.002327173948287964\n",
      "\n",
      "The classification loss after processing this batch is:  0.07535215467214584\n",
      "The representation loss after processing this batch is:  0.0025866329669952393\n",
      "\n",
      "The classification loss after processing this batch is:  0.04086689278483391\n",
      "The representation loss after processing this batch is:  0.002384297549724579\n",
      "\n",
      "The classification loss after processing this batch is:  0.11526744812726974\n",
      "The representation loss after processing this batch is:  0.0023904182016849518\n",
      "\n",
      "The classification loss after processing this batch is:  0.15392760932445526\n",
      "The representation loss after processing this batch is:  0.002459980547428131\n",
      "\n",
      "The classification loss after processing this batch is:  0.04402143508195877\n",
      "The representation loss after processing this batch is:  0.0024598315358161926\n",
      "\n",
      "The classification loss after processing this batch is:  0.07708583772182465\n",
      "The representation loss after processing this batch is:  0.0022381283342838287\n",
      "\n",
      "The classification loss after processing this batch is:  0.12636230885982513\n",
      "The representation loss after processing this batch is:  0.0022941380739212036\n",
      "\n",
      "The classification loss after processing this batch is:  0.1701563149690628\n",
      "The representation loss after processing this batch is:  0.0022339969873428345\n",
      "\n",
      "The classification loss after processing this batch is:  0.08619574457406998\n",
      "The representation loss after processing this batch is:  0.0022571831941604614\n",
      "\n",
      "The classification loss after processing this batch is:  0.12155675888061523\n",
      "The representation loss after processing this batch is:  0.0021578148007392883\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.15222598612308502\n",
      "The representation loss after processing this batch is:  0.0025625675916671753\n",
      "\n",
      "The classification loss after processing this batch is:  0.17109231650829315\n",
      "The representation loss after processing this batch is:  0.0025915205478668213\n",
      "\n",
      "The classification loss after processing this batch is:  0.09548487514257431\n",
      "The representation loss after processing this batch is:  0.0025608763098716736\n",
      "\n",
      "The classification loss after processing this batch is:  0.1584712415933609\n",
      "The representation loss after processing this batch is:  0.0023230910301208496\n",
      "\n",
      "The classification loss after processing this batch is:  0.10663656145334244\n",
      "The representation loss after processing this batch is:  0.003289133310317993\n",
      "\n",
      "The classification loss after processing this batch is:  0.07971896976232529\n",
      "The representation loss after processing this batch is:  0.002566710114479065\n",
      "\n",
      "The classification loss after processing this batch is:  0.05891319736838341\n",
      "The representation loss after processing this batch is:  0.0022488534450531006\n",
      "\n",
      "The classification loss after processing this batch is:  0.0735960528254509\n",
      "The representation loss after processing this batch is:  0.0021653510630130768\n",
      "\n",
      "The classification loss after processing this batch is:  0.0832553431391716\n",
      "The representation loss after processing this batch is:  0.002424284815788269\n",
      "\n",
      "The classification loss after processing this batch is:  0.08071402460336685\n",
      "The representation loss after processing this batch is:  0.0022892653942108154\n",
      "\n",
      "The classification loss after processing this batch is:  0.14219442009925842\n",
      "The representation loss after processing this batch is:  0.0023519620299339294\n",
      "\n",
      "The classification loss after processing this batch is:  0.05412488803267479\n",
      "The representation loss after processing this batch is:  0.0025409385561943054\n",
      "\n",
      "The classification loss after processing this batch is:  0.037290606647729874\n",
      "The representation loss after processing this batch is:  0.002799972891807556\n",
      "\n",
      "The classification loss after processing this batch is:  0.11558235436677933\n",
      "The representation loss after processing this batch is:  0.0027407631278038025\n",
      "\n",
      "The classification loss after processing this batch is:  0.028991373255848885\n",
      "The representation loss after processing this batch is:  0.002214469015598297\n",
      "\n",
      "The classification loss after processing this batch is:  0.06420662999153137\n",
      "The representation loss after processing this batch is:  0.0025180503726005554\n",
      "\n",
      "The classification loss after processing this batch is:  0.02613019198179245\n",
      "The representation loss after processing this batch is:  0.0025838464498519897\n",
      "\n",
      "The classification loss after processing this batch is:  0.11446861922740936\n",
      "The representation loss after processing this batch is:  0.0022072941064834595\n",
      "\n",
      "The classification loss after processing this batch is:  0.16203847527503967\n",
      "The representation loss after processing this batch is:  0.0025546327233314514\n",
      "\n",
      "The classification loss after processing this batch is:  0.11665702611207962\n",
      "The representation loss after processing this batch is:  0.0030430033802986145\n",
      "\n",
      "The classification loss after processing this batch is:  0.10716307163238525\n",
      "The representation loss after processing this batch is:  0.002868548035621643\n",
      "\n",
      "The classification loss after processing this batch is:  0.06954861432313919\n",
      "The representation loss after processing this batch is:  0.0027637556195259094\n",
      "\n",
      "The classification loss after processing this batch is:  0.08285216242074966\n",
      "The representation loss after processing this batch is:  0.0024109259247779846\n",
      "\n",
      "The classification loss after processing this batch is:  0.09784586727619171\n",
      "The representation loss after processing this batch is:  0.0023216083645820618\n",
      "\n",
      "The classification loss after processing this batch is:  0.03970201313495636\n",
      "The representation loss after processing this batch is:  0.002634834498167038\n",
      "\n",
      "The classification loss after processing this batch is:  0.06510628014802933\n",
      "The representation loss after processing this batch is:  0.002436608076095581\n",
      "\n",
      "The classification loss after processing this batch is:  0.02727852575480938\n",
      "The representation loss after processing this batch is:  0.0024040862917900085\n",
      "\n",
      "The classification loss after processing this batch is:  0.07571279257535934\n",
      "The representation loss after processing this batch is:  0.002521812915802002\n",
      "\n",
      "The classification loss after processing this batch is:  0.1322493702173233\n",
      "The representation loss after processing this batch is:  0.002568315714597702\n",
      "\n",
      "The classification loss after processing this batch is:  0.15302947163581848\n",
      "The representation loss after processing this batch is:  0.0024781376123428345\n",
      "\n",
      "The classification loss after processing this batch is:  0.12933403253555298\n",
      "The representation loss after processing this batch is:  0.0030676499009132385\n",
      "\n",
      "The classification loss after processing this batch is:  0.08873584866523743\n",
      "The representation loss after processing this batch is:  0.0025733932852745056\n",
      "\n",
      "The classification loss after processing this batch is:  0.11805374175310135\n",
      "The representation loss after processing this batch is:  0.0026350021362304688\n",
      "\n",
      "The classification loss after processing this batch is:  0.08650892227888107\n",
      "The representation loss after processing this batch is:  0.0023887082934379578\n",
      "\n",
      "The classification loss after processing this batch is:  0.2874602675437927\n",
      "The representation loss after processing this batch is:  0.002946421504020691\n",
      "\n",
      "The classification loss after processing this batch is:  0.1052013710141182\n",
      "The representation loss after processing this batch is:  0.002788059413433075\n",
      "\n",
      "The classification loss after processing this batch is:  0.1782039850950241\n",
      "The representation loss after processing this batch is:  0.002865605056285858\n",
      "\n",
      "The classification loss after processing this batch is:  0.06560232490301132\n",
      "The representation loss after processing this batch is:  0.002318181097507477\n",
      "\n",
      "The classification loss after processing this batch is:  0.08029181510210037\n",
      "The representation loss after processing this batch is:  0.002358555793762207\n",
      "\n",
      "The classification loss after processing this batch is:  0.15599021315574646\n",
      "The representation loss after processing this batch is:  0.0024287253618240356\n",
      "\n",
      "The classification loss after processing this batch is:  0.08840571343898773\n",
      "The representation loss after processing this batch is:  0.002429477870464325\n",
      "\n",
      "The classification loss after processing this batch is:  0.18698886036872864\n",
      "The representation loss after processing this batch is:  0.00231325626373291\n",
      "\n",
      "The classification loss after processing this batch is:  0.10617431253194809\n",
      "The representation loss after processing this batch is:  0.0027845799922943115\n",
      "\n",
      "The classification loss after processing this batch is:  0.1567932814359665\n",
      "The representation loss after processing this batch is:  0.002903558313846588\n",
      "\n",
      "The classification loss after processing this batch is:  0.11374882608652115\n",
      "The representation loss after processing this batch is:  0.002789139747619629\n",
      "\n",
      "The classification loss after processing this batch is:  0.031725361943244934\n",
      "The representation loss after processing this batch is:  0.002408459782600403\n",
      "\n",
      "The classification loss after processing this batch is:  0.07084647566080093\n",
      "The representation loss after processing this batch is:  0.0022879019379615784\n",
      "\n",
      "The classification loss after processing this batch is:  0.06799428910017014\n",
      "The representation loss after processing this batch is:  0.0022866539657115936\n",
      "\n",
      "The classification loss after processing this batch is:  0.06310328841209412\n",
      "The representation loss after processing this batch is:  0.002446874976158142\n",
      "\n",
      "The classification loss after processing this batch is:  0.15016679465770721\n",
      "The representation loss after processing this batch is:  0.0023641958832740784\n",
      "\n",
      "The classification loss after processing this batch is:  0.22026023268699646\n",
      "The representation loss after processing this batch is:  0.0023217350244522095\n",
      "\n",
      "The classification loss after processing this batch is:  0.09724700450897217\n",
      "The representation loss after processing this batch is:  0.002142801880836487\n",
      "\n",
      "The classification loss after processing this batch is:  0.07162699103355408\n",
      "The representation loss after processing this batch is:  0.002500038594007492\n",
      "\n",
      "The classification loss after processing this batch is:  0.09544774144887924\n",
      "The representation loss after processing this batch is:  0.002460390329360962\n",
      "\n",
      "The classification loss after processing this batch is:  0.054980210959911346\n",
      "The representation loss after processing this batch is:  0.0026888400316238403\n",
      "\n",
      "The classification loss after processing this batch is:  0.09686855971813202\n",
      "The representation loss after processing this batch is:  0.002667240798473358\n",
      "\n",
      "The classification loss after processing this batch is:  0.03922569751739502\n",
      "The representation loss after processing this batch is:  0.002651013433933258\n",
      "\n",
      "The classification loss after processing this batch is:  0.089028000831604\n",
      "The representation loss after processing this batch is:  0.0022330954670906067\n",
      "\n",
      "The classification loss after processing this batch is:  0.1438356190919876\n",
      "The representation loss after processing this batch is:  0.0025358274579048157\n",
      "\n",
      "The classification loss after processing this batch is:  0.048687342554330826\n",
      "The representation loss after processing this batch is:  0.002299092710018158\n",
      "\n",
      "The classification loss after processing this batch is:  0.15133005380630493\n",
      "The representation loss after processing this batch is:  0.002231806516647339\n",
      "\n",
      "The classification loss after processing this batch is:  0.07437916100025177\n",
      "The representation loss after processing this batch is:  0.002070702612400055\n",
      "\n",
      "The classification loss after processing this batch is:  0.09304244071245193\n",
      "The representation loss after processing this batch is:  0.002368226647377014\n",
      "\n",
      "The classification loss after processing this batch is:  0.047721460461616516\n",
      "The representation loss after processing this batch is:  0.0023693889379501343\n",
      "\n",
      "The classification loss after processing this batch is:  0.10127972066402435\n",
      "The representation loss after processing this batch is:  0.002498120069503784\n",
      "\n",
      "The classification loss after processing this batch is:  0.06457304209470749\n",
      "The representation loss after processing this batch is:  0.002454690635204315\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.27746936678886414\n",
      "The representation loss after processing this batch is:  0.0024913549423217773\n",
      "\n",
      "The classification loss after processing this batch is:  0.13313035666942596\n",
      "The representation loss after processing this batch is:  0.0025807395577430725\n",
      "\n",
      "The classification loss after processing this batch is:  0.15636295080184937\n",
      "The representation loss after processing this batch is:  0.002246260643005371\n",
      "\n",
      "The classification loss after processing this batch is:  0.06872410327196121\n",
      "The representation loss after processing this batch is:  0.002061992883682251\n",
      "\n",
      "The classification loss after processing this batch is:  0.11036963015794754\n",
      "The representation loss after processing this batch is:  0.0023873671889305115\n",
      "\n",
      "The classification loss after processing this batch is:  0.034648578613996506\n",
      "The representation loss after processing this batch is:  0.0021749883890151978\n",
      "\n",
      "The classification loss after processing this batch is:  0.10005872696638107\n",
      "The representation loss after processing this batch is:  0.002213176339864731\n",
      "\n",
      "The classification loss after processing this batch is:  0.12864230573177338\n",
      "The representation loss after processing this batch is:  0.0023741796612739563\n",
      "\n",
      "The classification loss after processing this batch is:  0.12481843680143356\n",
      "The representation loss after processing this batch is:  0.0026428401470184326\n",
      "\n",
      "The classification loss after processing this batch is:  0.15414047241210938\n",
      "The representation loss after processing this batch is:  0.002481352537870407\n",
      "\n",
      "The classification loss after processing this batch is:  0.07616954296827316\n",
      "The representation loss after processing this batch is:  0.0022791698575019836\n",
      "\n",
      "The classification loss after processing this batch is:  0.16207876801490784\n",
      "The representation loss after processing this batch is:  0.0025807395577430725\n",
      "\n",
      "The classification loss after processing this batch is:  0.11277232319116592\n",
      "The representation loss after processing this batch is:  0.002610243856906891\n",
      "\n",
      "The classification loss after processing this batch is:  0.14820559322834015\n",
      "The representation loss after processing this batch is:  0.002387508749961853\n",
      "\n",
      "The classification loss after processing this batch is:  0.08479075133800507\n",
      "The representation loss after processing this batch is:  0.0026258230209350586\n",
      "\n",
      "The classification loss after processing this batch is:  0.08079525083303452\n",
      "The representation loss after processing this batch is:  0.0028269588947296143\n",
      "\n",
      "The classification loss after processing this batch is:  0.037676941603422165\n",
      "The representation loss after processing this batch is:  0.0023350752890110016\n",
      "\n",
      "The classification loss after processing this batch is:  0.15242543816566467\n",
      "The representation loss after processing this batch is:  0.002225242555141449\n",
      "\n",
      "The classification loss after processing this batch is:  0.2226511389017105\n",
      "The representation loss after processing this batch is:  0.0026195570826530457\n",
      "\n",
      "The classification loss after processing this batch is:  0.08562060445547104\n",
      "The representation loss after processing this batch is:  0.0027000010013580322\n",
      "\n",
      "The classification loss after processing this batch is:  0.11327990144491196\n",
      "The representation loss after processing this batch is:  0.002957940101623535\n",
      "\n",
      "The classification loss after processing this batch is:  0.13321754336357117\n",
      "The representation loss after processing this batch is:  0.0024142973124980927\n",
      "\n",
      "The classification loss after processing this batch is:  0.1066080629825592\n",
      "The representation loss after processing this batch is:  0.002766348421573639\n",
      "\n",
      "The classification loss after processing this batch is:  0.03979044035077095\n",
      "The representation loss after processing this batch is:  0.0022382214665412903\n",
      "\n",
      "The classification loss after processing this batch is:  0.10238652676343918\n",
      "The representation loss after processing this batch is:  0.0024213269352912903\n",
      "\n",
      "The classification loss after processing this batch is:  0.1085411086678505\n",
      "The representation loss after processing this batch is:  0.002692572772502899\n",
      "\n",
      "The classification loss after processing this batch is:  0.06673061102628708\n",
      "The representation loss after processing this batch is:  0.0025685131549835205\n",
      "\n",
      "The classification loss after processing this batch is:  0.02882324904203415\n",
      "The representation loss after processing this batch is:  0.0025347918272018433\n",
      "\n",
      "The classification loss after processing this batch is:  0.07671748846769333\n",
      "The representation loss after processing this batch is:  0.002560153603553772\n",
      "\n",
      "The classification loss after processing this batch is:  0.06335785239934921\n",
      "The representation loss after processing this batch is:  0.002759285271167755\n",
      "\n",
      "The classification loss after processing this batch is:  0.09223853796720505\n",
      "The representation loss after processing this batch is:  0.0022881627082824707\n",
      "\n",
      "The classification loss after processing this batch is:  0.14094893634319305\n",
      "The representation loss after processing this batch is:  0.0024611838161945343\n",
      "\n",
      "The classification loss after processing this batch is:  0.12028560042381287\n",
      "The representation loss after processing this batch is:  0.0021663643419742584\n",
      "\n",
      "The classification loss after processing this batch is:  0.09594316780567169\n",
      "The representation loss after processing this batch is:  0.002718597650527954\n",
      "\n",
      "The classification loss after processing this batch is:  0.1322067379951477\n",
      "The representation loss after processing this batch is:  0.002775285392999649\n",
      "\n",
      "The classification loss after processing this batch is:  0.08651428669691086\n",
      "The representation loss after processing this batch is:  0.0027381330728530884\n",
      "\n",
      "The classification loss after processing this batch is:  0.08498333394527435\n",
      "The representation loss after processing this batch is:  0.002691522240638733\n",
      "\n",
      "The classification loss after processing this batch is:  0.15950852632522583\n",
      "The representation loss after processing this batch is:  0.0026215389370918274\n",
      "\n",
      "The classification loss after processing this batch is:  0.13283182680606842\n",
      "The representation loss after processing this batch is:  0.0032537132501602173\n",
      "\n",
      "The classification loss after processing this batch is:  0.07143740355968475\n",
      "The representation loss after processing this batch is:  0.0024032220244407654\n",
      "\n",
      "The classification loss after processing this batch is:  0.06172122806310654\n",
      "The representation loss after processing this batch is:  0.0026136599481105804\n",
      "\n",
      "The classification loss after processing this batch is:  0.055862054228782654\n",
      "The representation loss after processing this batch is:  0.0022090449929237366\n",
      "\n",
      "The classification loss after processing this batch is:  0.06098903343081474\n",
      "The representation loss after processing this batch is:  0.002368435263633728\n",
      "\n",
      "The classification loss after processing this batch is:  0.10066144168376923\n",
      "The representation loss after processing this batch is:  0.002338118851184845\n",
      "\n",
      "The classification loss after processing this batch is:  0.16484087705612183\n",
      "The representation loss after processing this batch is:  0.002233073115348816\n",
      "\n",
      "The classification loss after processing this batch is:  0.15922880172729492\n",
      "The representation loss after processing this batch is:  0.002733752131462097\n",
      "\n",
      "The classification loss after processing this batch is:  0.128193661570549\n",
      "The representation loss after processing this batch is:  0.0022446438670158386\n",
      "\n",
      "The classification loss after processing this batch is:  0.11235622316598892\n",
      "The representation loss after processing this batch is:  0.002100840210914612\n",
      "\n",
      "The classification loss after processing this batch is:  0.07915057241916656\n",
      "The representation loss after processing this batch is:  0.002296723425388336\n",
      "\n",
      "The classification loss after processing this batch is:  0.12837862968444824\n",
      "The representation loss after processing this batch is:  0.002221442759037018\n",
      "\n",
      "The classification loss after processing this batch is:  0.17226317524909973\n",
      "The representation loss after processing this batch is:  0.002311456948518753\n",
      "\n",
      "The classification loss after processing this batch is:  0.14821535348892212\n",
      "The representation loss after processing this batch is:  0.0022452659904956818\n",
      "\n",
      "The classification loss after processing this batch is:  0.33575108647346497\n",
      "The representation loss after processing this batch is:  0.0024346336722373962\n",
      "\n",
      "The classification loss after processing this batch is:  0.13615430891513824\n",
      "The representation loss after processing this batch is:  0.0024164170026779175\n",
      "\n",
      "The classification loss after processing this batch is:  0.03205478936433792\n",
      "The representation loss after processing this batch is:  0.0026231184601783752\n",
      "\n",
      "The classification loss after processing this batch is:  0.12916159629821777\n",
      "The representation loss after processing this batch is:  0.002431478351354599\n",
      "\n",
      "The classification loss after processing this batch is:  0.07536318898200989\n",
      "The representation loss after processing this batch is:  0.002416551113128662\n",
      "\n",
      "The classification loss after processing this batch is:  0.13418228924274445\n",
      "The representation loss after processing this batch is:  0.002839982509613037\n",
      "\n",
      "The classification loss after processing this batch is:  0.14131905138492584\n",
      "The representation loss after processing this batch is:  0.0022680163383483887\n",
      "\n",
      "The classification loss after processing this batch is:  0.12071061134338379\n",
      "The representation loss after processing this batch is:  0.002457141876220703\n",
      "\n",
      "The classification loss after processing this batch is:  0.0956246629357338\n",
      "The representation loss after processing this batch is:  0.0024046674370765686\n",
      "\n",
      "The classification loss after processing this batch is:  0.14218464493751526\n",
      "The representation loss after processing this batch is:  0.0021768473088741302\n",
      "\n",
      "The classification loss after processing this batch is:  0.18128013610839844\n",
      "The representation loss after processing this batch is:  0.0023871883749961853\n",
      "\n",
      "The classification loss after processing this batch is:  0.1971042901277542\n",
      "The representation loss after processing this batch is:  0.0025210529565811157\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.11681941151618958\n",
      "The representation loss after processing this batch is:  0.0021473467350006104\n",
      "\n",
      "The classification loss after processing this batch is:  0.03963380679488182\n",
      "The representation loss after processing this batch is:  0.002682231366634369\n",
      "\n",
      "The classification loss after processing this batch is:  0.02126871794462204\n",
      "The representation loss after processing this batch is:  0.002515345811843872\n",
      "\n",
      "The classification loss after processing this batch is:  0.08675899356603622\n",
      "The representation loss after processing this batch is:  0.0025302767753601074\n",
      "\n",
      "The classification loss after processing this batch is:  0.06112080067396164\n",
      "The representation loss after processing this batch is:  0.003577187657356262\n",
      "\n",
      "The classification loss after processing this batch is:  0.1512913852930069\n",
      "The representation loss after processing this batch is:  0.0023871585726737976\n",
      "\n",
      "The classification loss after processing this batch is:  0.07574636489152908\n",
      "The representation loss after processing this batch is:  0.0025510936975479126\n",
      "\n",
      "The classification loss after processing this batch is:  0.16553865373134613\n",
      "The representation loss after processing this batch is:  0.0023290030658245087\n",
      "\n",
      "The classification loss after processing this batch is:  0.058517925441265106\n",
      "The representation loss after processing this batch is:  0.0027228370308876038\n",
      "\n",
      "The classification loss after processing this batch is:  0.11645352840423584\n",
      "The representation loss after processing this batch is:  0.0026051439344882965\n",
      "\n",
      "The classification loss after processing this batch is:  0.1346432864665985\n",
      "The representation loss after processing this batch is:  0.0028119757771492004\n",
      "\n",
      "The classification loss after processing this batch is:  0.1488594114780426\n",
      "The representation loss after processing this batch is:  0.0027239173650741577\n",
      "\n",
      "The classification loss after processing this batch is:  0.08238300681114197\n",
      "The representation loss after processing this batch is:  0.00245608389377594\n",
      "\n",
      "The classification loss after processing this batch is:  0.05796743184328079\n",
      "The representation loss after processing this batch is:  0.001994144171476364\n",
      "\n",
      "The classification loss after processing this batch is:  0.12538179755210876\n",
      "The representation loss after processing this batch is:  0.002671569585800171\n",
      "\n",
      "The classification loss after processing this batch is:  0.07606562227010727\n",
      "The representation loss after processing this batch is:  0.002318046987056732\n",
      "\n",
      "The classification loss after processing this batch is:  0.10689348727464676\n",
      "The representation loss after processing this batch is:  0.002377718687057495\n",
      "\n",
      "The classification loss after processing this batch is:  0.14921711385250092\n",
      "The representation loss after processing this batch is:  0.002554371953010559\n",
      "\n",
      "The classification loss after processing this batch is:  0.08144063502550125\n",
      "The representation loss after processing this batch is:  0.0024205371737480164\n",
      "\n",
      "The classification loss after processing this batch is:  0.03156190738081932\n",
      "The representation loss after processing this batch is:  0.002400696277618408\n",
      "\n",
      "The classification loss after processing this batch is:  0.04694431647658348\n",
      "The representation loss after processing this batch is:  0.002705782651901245\n",
      "\n",
      "The classification loss after processing this batch is:  0.019929103553295135\n",
      "The representation loss after processing this batch is:  0.0026031360030174255\n",
      "\n",
      "The classification loss after processing this batch is:  0.08541341125965118\n",
      "The representation loss after processing this batch is:  0.002453126013278961\n",
      "\n",
      "The classification loss after processing this batch is:  0.04246297851204872\n",
      "The representation loss after processing this batch is:  0.002462714910507202\n",
      "\n",
      "The classification loss after processing this batch is:  0.028237732127308846\n",
      "The representation loss after processing this batch is:  0.002406492829322815\n",
      "\n",
      "The classification loss after processing this batch is:  0.08344753086566925\n",
      "The representation loss after processing this batch is:  0.002979770302772522\n",
      "\n",
      "The classification loss after processing this batch is:  0.059811342507600784\n",
      "The representation loss after processing this batch is:  0.002621069550514221\n",
      "\n",
      "The classification loss after processing this batch is:  0.03349822759628296\n",
      "The representation loss after processing this batch is:  0.0024950839579105377\n",
      "\n",
      "The classification loss after processing this batch is:  0.04334988817572594\n",
      "The representation loss after processing this batch is:  0.0024454519152641296\n",
      "\n",
      "The classification loss after processing this batch is:  0.043942827731370926\n",
      "The representation loss after processing this batch is:  0.002313360571861267\n",
      "\n",
      "The classification loss after processing this batch is:  0.02763804979622364\n",
      "The representation loss after processing this batch is:  0.002505175769329071\n",
      "\n",
      "The classification loss after processing this batch is:  0.11261961609125137\n",
      "The representation loss after processing this batch is:  0.0025578737258911133\n",
      "\n",
      "The classification loss after processing this batch is:  0.11282036453485489\n",
      "The representation loss after processing this batch is:  0.0025817453861236572\n",
      "\n",
      "The classification loss after processing this batch is:  0.050296980887651443\n",
      "The representation loss after processing this batch is:  0.0023484081029891968\n",
      "\n",
      "The classification loss after processing this batch is:  0.15073595941066742\n",
      "The representation loss after processing this batch is:  0.0023038461804389954\n",
      "\n",
      "The classification loss after processing this batch is:  0.049372609704732895\n",
      "The representation loss after processing this batch is:  0.0023447275161743164\n",
      "\n",
      "The classification loss after processing this batch is:  0.09853878617286682\n",
      "The representation loss after processing this batch is:  0.002360265702009201\n",
      "\n",
      "The classification loss after processing this batch is:  0.12087292969226837\n",
      "The representation loss after processing this batch is:  0.0029507577419281006\n",
      "\n",
      "The classification loss after processing this batch is:  0.06012079492211342\n",
      "The representation loss after processing this batch is:  0.0025885552167892456\n",
      "\n",
      "The classification loss after processing this batch is:  0.1450958549976349\n",
      "The representation loss after processing this batch is:  0.0023316144943237305\n",
      "\n",
      "The classification loss after processing this batch is:  0.14205890893936157\n",
      "The representation loss after processing this batch is:  0.002231195569038391\n",
      "\n",
      "The classification loss after processing this batch is:  0.14454467594623566\n",
      "The representation loss after processing this batch is:  0.002418927848339081\n",
      "\n",
      "The classification loss after processing this batch is:  0.13000281155109406\n",
      "The representation loss after processing this batch is:  0.0023906007409095764\n",
      "\n",
      "The classification loss after processing this batch is:  0.10496656596660614\n",
      "The representation loss after processing this batch is:  0.0024152398109436035\n",
      "\n",
      "The classification loss after processing this batch is:  0.10283443331718445\n",
      "The representation loss after processing this batch is:  0.0022527165710926056\n",
      "\n",
      "The classification loss after processing this batch is:  0.06606893241405487\n",
      "The representation loss after processing this batch is:  0.0025993138551712036\n",
      "\n",
      "The classification loss after processing this batch is:  0.15827493369579315\n",
      "The representation loss after processing this batch is:  0.002388782799243927\n",
      "\n",
      "The classification loss after processing this batch is:  0.13495288789272308\n",
      "The representation loss after processing this batch is:  0.0022208690643310547\n",
      "\n",
      "The classification loss after processing this batch is:  0.03692025691270828\n",
      "The representation loss after processing this batch is:  0.002361580729484558\n",
      "\n",
      "The classification loss after processing this batch is:  0.0632343739271164\n",
      "The representation loss after processing this batch is:  0.0023292601108551025\n",
      "\n",
      "The classification loss after processing this batch is:  0.1834138184785843\n",
      "The representation loss after processing this batch is:  0.0020021088421344757\n",
      "\n",
      "The classification loss after processing this batch is:  0.06795434653759003\n",
      "The representation loss after processing this batch is:  0.0025723129510879517\n",
      "\n",
      "The classification loss after processing this batch is:  0.09025891870260239\n",
      "The representation loss after processing this batch is:  0.0022613108158111572\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10017666220664978\n",
      "The representation loss after processing this batch is:  0.002374120056629181\n",
      "\n",
      "The classification loss after processing this batch is:  0.06553972512483597\n",
      "The representation loss after processing this batch is:  0.0026156827807426453\n",
      "\n",
      "The classification loss after processing this batch is:  0.02971477434039116\n",
      "The representation loss after processing this batch is:  0.002500399947166443\n",
      "\n",
      "The classification loss after processing this batch is:  0.07553080469369888\n",
      "The representation loss after processing this batch is:  0.0026756078004837036\n",
      "\n",
      "The classification loss after processing this batch is:  0.10337508469820023\n",
      "The representation loss after processing this batch is:  0.0025216564536094666\n",
      "\n",
      "The classification loss after processing this batch is:  0.1028144508600235\n",
      "The representation loss after processing this batch is:  0.00242459774017334\n",
      "\n",
      "The classification loss after processing this batch is:  0.20095334947109222\n",
      "The representation loss after processing this batch is:  0.0024625472724437714\n",
      "\n",
      "The classification loss after processing this batch is:  0.09437332302331924\n",
      "The representation loss after processing this batch is:  0.0025577396154403687\n",
      "\n",
      "The classification loss after processing this batch is:  0.13861753046512604\n",
      "The representation loss after processing this batch is:  0.002236872911453247\n",
      "\n",
      "The classification loss after processing this batch is:  0.13439622521400452\n",
      "The representation loss after processing this batch is:  0.002759769558906555\n",
      "\n",
      "The classification loss after processing this batch is:  0.04817039147019386\n",
      "The representation loss after processing this batch is:  0.0026106461882591248\n",
      "\n",
      "The classification loss after processing this batch is:  0.04526977241039276\n",
      "The representation loss after processing this batch is:  0.0025500282645225525\n",
      "\n",
      "The classification loss after processing this batch is:  0.07299190014600754\n",
      "The representation loss after processing this batch is:  0.0026290491223335266\n",
      "\n",
      "The classification loss after processing this batch is:  0.14671802520751953\n",
      "The representation loss after processing this batch is:  0.0025633126497268677\n",
      "\n",
      "The classification loss after processing this batch is:  0.0887334793806076\n",
      "The representation loss after processing this batch is:  0.0024999678134918213\n",
      "\n",
      "The classification loss after processing this batch is:  0.10487433522939682\n",
      "The representation loss after processing this batch is:  0.002446018159389496\n",
      "\n",
      "The classification loss after processing this batch is:  0.11385641992092133\n",
      "The representation loss after processing this batch is:  0.002787962555885315\n",
      "\n",
      "The classification loss after processing this batch is:  0.1149098351597786\n",
      "The representation loss after processing this batch is:  0.0027346238493919373\n",
      "\n",
      "The classification loss after processing this batch is:  0.12854288518428802\n",
      "The representation loss after processing this batch is:  0.0023820921778678894\n",
      "\n",
      "The classification loss after processing this batch is:  0.09964494407176971\n",
      "The representation loss after processing this batch is:  0.002406090497970581\n",
      "\n",
      "The classification loss after processing this batch is:  0.09633537381887436\n",
      "The representation loss after processing this batch is:  0.0023392178118228912\n",
      "\n",
      "The classification loss after processing this batch is:  0.05048113688826561\n",
      "The representation loss after processing this batch is:  0.0028782784938812256\n",
      "\n",
      "The classification loss after processing this batch is:  0.048030052334070206\n",
      "The representation loss after processing this batch is:  0.0025651082396507263\n",
      "\n",
      "The classification loss after processing this batch is:  0.13101395964622498\n",
      "The representation loss after processing this batch is:  0.002281680703163147\n",
      "\n",
      "The classification loss after processing this batch is:  0.11330293118953705\n",
      "The representation loss after processing this batch is:  0.0023068785667419434\n",
      "\n",
      "The classification loss after processing this batch is:  0.08898863196372986\n",
      "The representation loss after processing this batch is:  0.00238645076751709\n",
      "\n",
      "The classification loss after processing this batch is:  0.10534500330686569\n",
      "The representation loss after processing this batch is:  0.0024649351835250854\n",
      "\n",
      "The classification loss after processing this batch is:  0.07546214014291763\n",
      "The representation loss after processing this batch is:  0.0024936124682426453\n",
      "\n",
      "The classification loss after processing this batch is:  0.12340987473726273\n",
      "The representation loss after processing this batch is:  0.00234878808259964\n",
      "\n",
      "The classification loss after processing this batch is:  0.1398143321275711\n",
      "The representation loss after processing this batch is:  0.002459745854139328\n",
      "\n",
      "The classification loss after processing this batch is:  0.20181336998939514\n",
      "The representation loss after processing this batch is:  0.002495698630809784\n",
      "\n",
      "The classification loss after processing this batch is:  0.17776460945606232\n",
      "The representation loss after processing this batch is:  0.0022618696093559265\n",
      "\n",
      "The classification loss after processing this batch is:  0.06271529942750931\n",
      "The representation loss after processing this batch is:  0.002641543745994568\n",
      "\n",
      "The classification loss after processing this batch is:  0.05052744597196579\n",
      "The representation loss after processing this batch is:  0.0028236955404281616\n",
      "\n",
      "The classification loss after processing this batch is:  0.0999370813369751\n",
      "The representation loss after processing this batch is:  0.002663295716047287\n",
      "\n",
      "The classification loss after processing this batch is:  0.10316698998212814\n",
      "The representation loss after processing this batch is:  0.0022566691040992737\n",
      "\n",
      "The classification loss after processing this batch is:  0.03783169761300087\n",
      "The representation loss after processing this batch is:  0.002322278916835785\n",
      "\n",
      "The classification loss after processing this batch is:  0.04196907952427864\n",
      "The representation loss after processing this batch is:  0.0024650655686855316\n",
      "\n",
      "The classification loss after processing this batch is:  0.08126597106456757\n",
      "The representation loss after processing this batch is:  0.002163618803024292\n",
      "\n",
      "The classification loss after processing this batch is:  0.07008114457130432\n",
      "The representation loss after processing this batch is:  0.0025201067328453064\n",
      "\n",
      "The classification loss after processing this batch is:  0.06049460545182228\n",
      "The representation loss after processing this batch is:  0.002454787492752075\n",
      "\n",
      "The classification loss after processing this batch is:  0.07143894582986832\n",
      "The representation loss after processing this batch is:  0.0022185370326042175\n",
      "\n",
      "The classification loss after processing this batch is:  0.05809494107961655\n",
      "The representation loss after processing this batch is:  0.002316836267709732\n",
      "\n",
      "The classification loss after processing this batch is:  0.09459618479013443\n",
      "The representation loss after processing this batch is:  0.002783559262752533\n",
      "\n",
      "The classification loss after processing this batch is:  0.083297960460186\n",
      "The representation loss after processing this batch is:  0.0023087486624717712\n",
      "\n",
      "The classification loss after processing this batch is:  0.14981882274150848\n",
      "The representation loss after processing this batch is:  0.0024441778659820557\n",
      "\n",
      "The classification loss after processing this batch is:  0.025367295369505882\n",
      "The representation loss after processing this batch is:  0.0024987459182739258\n",
      "\n",
      "The classification loss after processing this batch is:  0.04299435764551163\n",
      "The representation loss after processing this batch is:  0.0024727657437324524\n",
      "\n",
      "The classification loss after processing this batch is:  0.13518854975700378\n",
      "The representation loss after processing this batch is:  0.002124197781085968\n",
      "\n",
      "The classification loss after processing this batch is:  0.14861473441123962\n",
      "The representation loss after processing this batch is:  0.002226274460554123\n",
      "\n",
      "The classification loss after processing this batch is:  0.06970937550067902\n",
      "The representation loss after processing this batch is:  0.0022798851132392883\n",
      "\n",
      "The classification loss after processing this batch is:  0.0312870591878891\n",
      "The representation loss after processing this batch is:  0.0021181292831897736\n",
      "\n",
      "The classification loss after processing this batch is:  0.12225309759378433\n",
      "The representation loss after processing this batch is:  0.001950196921825409\n",
      "\n",
      "The classification loss after processing this batch is:  0.01922597922384739\n",
      "The representation loss after processing this batch is:  0.0025427639484405518\n",
      "\n",
      "The classification loss after processing this batch is:  0.12860070168972015\n",
      "The representation loss after processing this batch is:  0.0023398324847221375\n",
      "\n",
      "The classification loss after processing this batch is:  0.11362848430871964\n",
      "The representation loss after processing this batch is:  0.0025183632969856262\n",
      "\n",
      "The classification loss after processing this batch is:  0.06567694991827011\n",
      "The representation loss after processing this batch is:  0.00225231796503067\n",
      "\n",
      "The classification loss after processing this batch is:  0.07089967280626297\n",
      "The representation loss after processing this batch is:  0.0025825873017311096\n",
      "\n",
      "The classification loss after processing this batch is:  0.06878690421581268\n",
      "The representation loss after processing this batch is:  0.002592138946056366\n",
      "\n",
      "The classification loss after processing this batch is:  0.030214285477995872\n",
      "The representation loss after processing this batch is:  0.002340361475944519\n",
      "\n",
      "The classification loss after processing this batch is:  0.190460205078125\n",
      "The representation loss after processing this batch is:  0.0022733286023139954\n",
      "\n",
      "The classification loss after processing this batch is:  0.1911892294883728\n",
      "The representation loss after processing this batch is:  0.0023154690861701965\n",
      "\n",
      "The classification loss after processing this batch is:  0.18856295943260193\n",
      "The representation loss after processing this batch is:  0.002372339367866516\n",
      "\n",
      "The classification loss after processing this batch is:  0.1896696537733078\n",
      "The representation loss after processing this batch is:  0.002222970128059387\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10154823958873749\n",
      "The representation loss after processing this batch is:  0.0024547725915908813\n",
      "\n",
      "The classification loss after processing this batch is:  0.05370708927512169\n",
      "The representation loss after processing this batch is:  0.0024513080716133118\n",
      "\n",
      "The classification loss after processing this batch is:  0.1511518806219101\n",
      "The representation loss after processing this batch is:  0.0023548975586891174\n",
      "\n",
      "The classification loss after processing this batch is:  0.10973061621189117\n",
      "The representation loss after processing this batch is:  0.0024676769971847534\n",
      "\n",
      "The classification loss after processing this batch is:  0.15086235105991364\n",
      "The representation loss after processing this batch is:  0.0023899897933006287\n",
      "\n",
      "The classification loss after processing this batch is:  0.07853605598211288\n",
      "The representation loss after processing this batch is:  0.0025393441319465637\n",
      "\n",
      "The classification loss after processing this batch is:  0.13491590321063995\n",
      "The representation loss after processing this batch is:  0.0023914985358715057\n",
      "\n",
      "The classification loss after processing this batch is:  0.054304931312799454\n",
      "The representation loss after processing this batch is:  0.0024894848465919495\n",
      "\n",
      "The classification loss after processing this batch is:  0.05772514268755913\n",
      "The representation loss after processing this batch is:  0.0023891255259513855\n",
      "\n",
      "The classification loss after processing this batch is:  0.1159716323018074\n",
      "The representation loss after processing this batch is:  0.002424106001853943\n",
      "\n",
      "The classification loss after processing this batch is:  0.02769787237048149\n",
      "The representation loss after processing this batch is:  0.0026522204279899597\n",
      "\n",
      "The classification loss after processing this batch is:  0.03947000578045845\n",
      "The representation loss after processing this batch is:  0.002552524209022522\n",
      "\n",
      "The classification loss after processing this batch is:  0.08335686475038528\n",
      "The representation loss after processing this batch is:  0.0022580623626708984\n",
      "\n",
      "The classification loss after processing this batch is:  0.19162318110466003\n",
      "The representation loss after processing this batch is:  0.002369813621044159\n",
      "\n",
      "The classification loss after processing this batch is:  0.029226453974843025\n",
      "The representation loss after processing this batch is:  0.0021843165159225464\n",
      "\n",
      "The classification loss after processing this batch is:  0.05099873244762421\n",
      "The representation loss after processing this batch is:  0.00227554515004158\n",
      "\n",
      "The classification loss after processing this batch is:  0.11466172337532043\n",
      "The representation loss after processing this batch is:  0.002305828034877777\n",
      "\n",
      "The classification loss after processing this batch is:  0.1891169250011444\n",
      "The representation loss after processing this batch is:  0.0022014155983924866\n",
      "\n",
      "The classification loss after processing this batch is:  0.07363053411245346\n",
      "The representation loss after processing this batch is:  0.002357974648475647\n",
      "\n",
      "The classification loss after processing this batch is:  0.15596941113471985\n",
      "The representation loss after processing this batch is:  0.0021408013999462128\n",
      "\n",
      "The classification loss after processing this batch is:  0.06432242691516876\n",
      "The representation loss after processing this batch is:  0.0027933642268180847\n",
      "\n",
      "The classification loss after processing this batch is:  0.020296191796660423\n",
      "The representation loss after processing this batch is:  0.0021727122366428375\n",
      "\n",
      "The classification loss after processing this batch is:  0.024029787629842758\n",
      "The representation loss after processing this batch is:  0.002423800528049469\n",
      "\n",
      "The classification loss after processing this batch is:  0.1457040011882782\n",
      "The representation loss after processing this batch is:  0.002634108066558838\n",
      "\n",
      "The classification loss after processing this batch is:  0.11852902919054031\n",
      "The representation loss after processing this batch is:  0.002699822187423706\n",
      "\n",
      "The classification loss after processing this batch is:  0.08416389673948288\n",
      "The representation loss after processing this batch is:  0.0029158294200897217\n",
      "\n",
      "The classification loss after processing this batch is:  0.08214423805475235\n",
      "The representation loss after processing this batch is:  0.002385459840297699\n",
      "\n",
      "The classification loss after processing this batch is:  0.07583949714899063\n",
      "The representation loss after processing this batch is:  0.0023148134350776672\n",
      "\n",
      "The classification loss after processing this batch is:  0.10757359117269516\n",
      "The representation loss after processing this batch is:  0.0023018307983875275\n",
      "\n",
      "The classification loss after processing this batch is:  0.08971226960420609\n",
      "The representation loss after processing this batch is:  0.0020256564021110535\n",
      "\n",
      "The classification loss after processing this batch is:  0.14258940517902374\n",
      "The representation loss after processing this batch is:  0.00238678976893425\n",
      "\n",
      "The classification loss after processing this batch is:  0.12203001976013184\n",
      "The representation loss after processing this batch is:  0.0026132315397262573\n",
      "\n",
      "The classification loss after processing this batch is:  0.21865110099315643\n",
      "The representation loss after processing this batch is:  0.0021320469677448273\n",
      "\n",
      "The classification loss after processing this batch is:  0.10925928503274918\n",
      "The representation loss after processing this batch is:  0.002195127308368683\n",
      "\n",
      "The classification loss after processing this batch is:  0.11799563467502594\n",
      "The representation loss after processing this batch is:  0.002319909632205963\n",
      "\n",
      "The classification loss after processing this batch is:  0.14097966253757477\n",
      "The representation loss after processing this batch is:  0.0023097097873687744\n",
      "\n",
      "The classification loss after processing this batch is:  0.04506373405456543\n",
      "The representation loss after processing this batch is:  0.0023348256945610046\n",
      "\n",
      "The classification loss after processing this batch is:  0.07999350875616074\n",
      "The representation loss after processing this batch is:  0.0029283687472343445\n",
      "\n",
      "The classification loss after processing this batch is:  0.05625654757022858\n",
      "The representation loss after processing this batch is:  0.0025506317615509033\n",
      "\n",
      "The classification loss after processing this batch is:  0.14702698588371277\n",
      "The representation loss after processing this batch is:  0.0023897700011730194\n",
      "\n",
      "The classification loss after processing this batch is:  0.06857581436634064\n",
      "The representation loss after processing this batch is:  0.0020360536873340607\n",
      "\n",
      "The classification loss after processing this batch is:  0.08553358167409897\n",
      "The representation loss after processing this batch is:  0.0023038797080516815\n",
      "\n",
      "The classification loss after processing this batch is:  0.0865318700671196\n",
      "The representation loss after processing this batch is:  0.002450980246067047\n",
      "\n",
      "The classification loss after processing this batch is:  0.10893549025058746\n",
      "The representation loss after processing this batch is:  0.0022836104035377502\n",
      "\n",
      "The classification loss after processing this batch is:  0.10827020555734634\n",
      "The representation loss after processing this batch is:  0.002533555030822754\n",
      "\n",
      "The classification loss after processing this batch is:  0.1576623171567917\n",
      "The representation loss after processing this batch is:  0.002382121980190277\n",
      "\n",
      "The classification loss after processing this batch is:  0.08608651906251907\n",
      "The representation loss after processing this batch is:  0.002822302281856537\n",
      "\n",
      "The classification loss after processing this batch is:  0.07629659026861191\n",
      "The representation loss after processing this batch is:  0.0021984241902828217\n",
      "\n",
      "The classification loss after processing this batch is:  0.09013205021619797\n",
      "The representation loss after processing this batch is:  0.0025118812918663025\n",
      "\n",
      "The classification loss after processing this batch is:  0.2056632936000824\n",
      "The representation loss after processing this batch is:  0.0027397051453590393\n",
      "\n",
      "The classification loss after processing this batch is:  0.23615150153636932\n",
      "The representation loss after processing this batch is:  0.0025841817259788513\n",
      "\n",
      "The classification loss after processing this batch is:  0.030992722138762474\n",
      "The representation loss after processing this batch is:  0.0020859241485595703\n",
      "\n",
      "The classification loss after processing this batch is:  0.03607086464762688\n",
      "The representation loss after processing this batch is:  0.0027073845267295837\n",
      "\n",
      "The classification loss after processing this batch is:  0.17623339593410492\n",
      "The representation loss after processing this batch is:  0.002414766699075699\n",
      "\n",
      "The classification loss after processing this batch is:  0.053359560668468475\n",
      "The representation loss after processing this batch is:  0.002564556896686554\n",
      "\n",
      "The classification loss after processing this batch is:  0.05166233330965042\n",
      "The representation loss after processing this batch is:  0.0023229531943798065\n",
      "\n",
      "The classification loss after processing this batch is:  0.11146368086338043\n",
      "The representation loss after processing this batch is:  0.002297617495059967\n",
      "\n",
      "The classification loss after processing this batch is:  0.07046225666999817\n",
      "The representation loss after processing this batch is:  0.002639312297105789\n",
      "\n",
      "The classification loss after processing this batch is:  0.21483160555362701\n",
      "The representation loss after processing this batch is:  0.0028130337595939636\n",
      "\n",
      "The classification loss after processing this batch is:  0.11906979978084564\n",
      "The representation loss after processing this batch is:  0.0027636289596557617\n",
      "\n",
      "The classification loss after processing this batch is:  0.10187957435846329\n",
      "The representation loss after processing this batch is:  0.0029616132378578186\n",
      "\n",
      "The classification loss after processing this batch is:  0.07472074776887894\n",
      "The representation loss after processing this batch is:  0.002000190317630768\n",
      "\n",
      "The classification loss after processing this batch is:  0.16036956012248993\n",
      "The representation loss after processing this batch is:  0.002294544130563736\n",
      "\n",
      "The classification loss after processing this batch is:  0.03637184202671051\n",
      "The representation loss after processing this batch is:  0.002394556999206543\n",
      "\n",
      "The classification loss after processing this batch is:  0.034533560276031494\n",
      "The representation loss after processing this batch is:  0.0026163384318351746\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.10064711421728134\n",
      "The representation loss after processing this batch is:  0.002296037971973419\n",
      "\n",
      "The classification loss after processing this batch is:  0.04750479757785797\n",
      "The representation loss after processing this batch is:  0.002489447593688965\n",
      "\n",
      "The classification loss after processing this batch is:  0.05498850345611572\n",
      "The representation loss after processing this batch is:  0.002791706472635269\n",
      "\n",
      "The classification loss after processing this batch is:  0.03541911393404007\n",
      "The representation loss after processing this batch is:  0.0026042163372039795\n",
      "\n",
      "The classification loss after processing this batch is:  0.07231929153203964\n",
      "The representation loss after processing this batch is:  0.0023472197353839874\n",
      "\n",
      "The classification loss after processing this batch is:  0.08939043432474136\n",
      "The representation loss after processing this batch is:  0.0024005845189094543\n",
      "\n",
      "The classification loss after processing this batch is:  0.09994126856327057\n",
      "The representation loss after processing this batch is:  0.002631261944770813\n",
      "\n",
      "The classification loss after processing this batch is:  0.1496402621269226\n",
      "The representation loss after processing this batch is:  0.002242468297481537\n",
      "\n",
      "The classification loss after processing this batch is:  0.13453933596611023\n",
      "The representation loss after processing this batch is:  0.00286855548620224\n",
      "\n",
      "The classification loss after processing this batch is:  0.19406896829605103\n",
      "The representation loss after processing this batch is:  0.0024586021900177\n",
      "\n",
      "The classification loss after processing this batch is:  0.03725914657115936\n",
      "The representation loss after processing this batch is:  0.002248607575893402\n",
      "\n",
      "The classification loss after processing this batch is:  0.15856249630451202\n",
      "The representation loss after processing this batch is:  0.002383515238761902\n",
      "\n",
      "The classification loss after processing this batch is:  0.2567867338657379\n",
      "The representation loss after processing this batch is:  0.0025143250823020935\n",
      "\n",
      "The classification loss after processing this batch is:  0.08953268826007843\n",
      "The representation loss after processing this batch is:  0.002097710967063904\n",
      "\n",
      "The classification loss after processing this batch is:  0.11549714207649231\n",
      "The representation loss after processing this batch is:  0.002343360334634781\n",
      "\n",
      "The classification loss after processing this batch is:  0.1388327181339264\n",
      "The representation loss after processing this batch is:  0.0023150593042373657\n",
      "\n",
      "The classification loss after processing this batch is:  0.15644806623458862\n",
      "The representation loss after processing this batch is:  0.0022976472973823547\n",
      "\n",
      "The classification loss after processing this batch is:  0.10526720434427261\n",
      "The representation loss after processing this batch is:  0.002587646245956421\n",
      "\n",
      "The classification loss after processing this batch is:  0.08211466670036316\n",
      "The representation loss after processing this batch is:  0.002307400107383728\n",
      "\n",
      "The classification loss after processing this batch is:  0.07439533621072769\n",
      "The representation loss after processing this batch is:  0.0024804845452308655\n",
      "\n",
      "The classification loss after processing this batch is:  0.039663854986429214\n",
      "The representation loss after processing this batch is:  0.002382710576057434\n",
      "\n",
      "The classification loss after processing this batch is:  0.03660084679722786\n",
      "The representation loss after processing this batch is:  0.002236083149909973\n",
      "\n",
      "The classification loss after processing this batch is:  0.10177884995937347\n",
      "The representation loss after processing this batch is:  0.002620197832584381\n",
      "\n",
      "The classification loss after processing this batch is:  0.038708314299583435\n",
      "The representation loss after processing this batch is:  0.002495013177394867\n",
      "\n",
      "The classification loss after processing this batch is:  0.19669777154922485\n",
      "The representation loss after processing this batch is:  0.0028712227940559387\n",
      "\n",
      "The classification loss after processing this batch is:  0.13360603153705597\n",
      "The representation loss after processing this batch is:  0.0022453665733337402\n",
      "\n",
      "The classification loss after processing this batch is:  0.17036040127277374\n",
      "The representation loss after processing this batch is:  0.002602614462375641\n",
      "\n",
      "The classification loss after processing this batch is:  0.2926040589809418\n",
      "The representation loss after processing this batch is:  0.002148229628801346\n",
      "\n",
      "The classification loss after processing this batch is:  0.10609229654073715\n",
      "The representation loss after processing this batch is:  0.002368185669183731\n",
      "\n",
      "The classification loss after processing this batch is:  0.03400690108537674\n",
      "The representation loss after processing this batch is:  0.00216800719499588\n",
      "\n",
      "The classification loss after processing this batch is:  0.06076544523239136\n",
      "The representation loss after processing this batch is:  0.002626776695251465\n",
      "\n",
      "The classification loss after processing this batch is:  0.06601652503013611\n",
      "The representation loss after processing this batch is:  0.0026810169219970703\n",
      "\n",
      "The classification loss after processing this batch is:  0.0625639483332634\n",
      "The representation loss after processing this batch is:  0.0025545060634613037\n",
      "\n",
      "The classification loss after processing this batch is:  0.07936226576566696\n",
      "The representation loss after processing this batch is:  0.0020612478256225586\n",
      "\n",
      "The classification loss after processing this batch is:  0.19080451130867004\n",
      "The representation loss after processing this batch is:  0.0021441467106342316\n",
      "\n",
      "The classification loss after processing this batch is:  0.14572666585445404\n",
      "The representation loss after processing this batch is:  0.0021852776408195496\n",
      "\n",
      "The classification loss after processing this batch is:  0.14052076637744904\n",
      "The representation loss after processing this batch is:  0.002653367817401886\n",
      "\n",
      "The classification loss after processing this batch is:  0.17944294214248657\n",
      "The representation loss after processing this batch is:  0.002720870077610016\n",
      "\n",
      "The classification loss after processing this batch is:  0.073249951004982\n",
      "The representation loss after processing this batch is:  0.0023024752736091614\n",
      "\n",
      "The classification loss after processing this batch is:  0.09604675322771072\n",
      "The representation loss after processing this batch is:  0.0023805350065231323\n",
      "\n",
      "The classification loss after processing this batch is:  0.14582817256450653\n",
      "The representation loss after processing this batch is:  0.0023132264614105225\n",
      "\n",
      "The classification loss after processing this batch is:  0.09104742109775543\n",
      "The representation loss after processing this batch is:  0.0027383342385292053\n",
      "\n",
      "The classification loss after processing this batch is:  0.1341513693332672\n",
      "The representation loss after processing this batch is:  0.0032120347023010254\n",
      "\n",
      "The classification loss after processing this batch is:  0.06291273981332779\n",
      "The representation loss after processing this batch is:  0.0027555525302886963\n",
      "\n",
      "The classification loss after processing this batch is:  0.11220581084489822\n",
      "The representation loss after processing this batch is:  0.0030488595366477966\n",
      "\n",
      "The classification loss after processing this batch is:  0.1648423820734024\n",
      "The representation loss after processing this batch is:  0.0027445778250694275\n",
      "\n",
      "The classification loss after processing this batch is:  0.08142869174480438\n",
      "The representation loss after processing this batch is:  0.002651713788509369\n",
      "\n",
      "The classification loss after processing this batch is:  0.14533430337905884\n",
      "The representation loss after processing this batch is:  0.00283079594373703\n",
      "\n",
      "The classification loss after processing this batch is:  0.18178513646125793\n",
      "The representation loss after processing this batch is:  0.0021175816655158997\n",
      "\n",
      "The classification loss after processing this batch is:  0.1001025065779686\n",
      "The representation loss after processing this batch is:  0.002380862832069397\n",
      "\n",
      "The classification loss after processing this batch is:  0.12567493319511414\n",
      "The representation loss after processing this batch is:  0.002265453338623047\n",
      "\n",
      "The classification loss after processing this batch is:  0.05786775052547455\n",
      "The representation loss after processing this batch is:  0.0028963983058929443\n",
      "\n",
      "The classification loss after processing this batch is:  0.01822020299732685\n",
      "The representation loss after processing this batch is:  0.0026439279317855835\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.07932410389184952\n",
      "The representation loss after processing this batch is:  0.0026761144399642944\n",
      "\n",
      "The classification loss after processing this batch is:  0.052410002797842026\n",
      "The representation loss after processing this batch is:  0.0027978941798210144\n",
      "\n",
      "The classification loss after processing this batch is:  0.2241801619529724\n",
      "The representation loss after processing this batch is:  0.002388566732406616\n",
      "\n",
      "The classification loss after processing this batch is:  0.03932064771652222\n",
      "The representation loss after processing this batch is:  0.0024975091218948364\n",
      "\n",
      "The classification loss after processing this batch is:  0.08998330682516098\n",
      "The representation loss after processing this batch is:  0.0023593902587890625\n",
      "\n",
      "The classification loss after processing this batch is:  0.12102045863866806\n",
      "The representation loss after processing this batch is:  0.002408750355243683\n",
      "\n",
      "The classification loss after processing this batch is:  0.08509530127048492\n",
      "The representation loss after processing this batch is:  0.00242576003074646\n",
      "\n",
      "The classification loss after processing this batch is:  0.0961761400103569\n",
      "The representation loss after processing this batch is:  0.0024584531784057617\n",
      "\n",
      "The classification loss after processing this batch is:  0.045974306762218475\n",
      "The representation loss after processing this batch is:  0.002459399402141571\n",
      "\n",
      "The classification loss after processing this batch is:  0.037479110062122345\n",
      "The representation loss after processing this batch is:  0.0024357661604881287\n",
      "\n",
      "The classification loss after processing this batch is:  0.07190605252981186\n",
      "The representation loss after processing this batch is:  0.0024803876876831055\n",
      "\n",
      "The classification loss after processing this batch is:  0.17445597052574158\n",
      "The representation loss after processing this batch is:  0.0029281899333000183\n",
      "\n",
      "The classification loss after processing this batch is:  0.1728658825159073\n",
      "The representation loss after processing this batch is:  0.002495367079973221\n",
      "\n",
      "The classification loss after processing this batch is:  0.09337614476680756\n",
      "The representation loss after processing this batch is:  0.0020304471254348755\n",
      "\n",
      "The classification loss after processing this batch is:  0.13755053281784058\n",
      "The representation loss after processing this batch is:  0.0023557543754577637\n",
      "\n",
      "The classification loss after processing this batch is:  0.2040211707353592\n",
      "The representation loss after processing this batch is:  0.0021578483283519745\n",
      "\n",
      "The classification loss after processing this batch is:  0.07717141509056091\n",
      "The representation loss after processing this batch is:  0.0026015639305114746\n",
      "\n",
      "The classification loss after processing this batch is:  0.20532184839248657\n",
      "The representation loss after processing this batch is:  0.0026059821248054504\n",
      "\n",
      "The classification loss after processing this batch is:  0.07202314585447311\n",
      "The representation loss after processing this batch is:  0.002661973237991333\n",
      "\n",
      "The classification loss after processing this batch is:  0.06522859632968903\n",
      "The representation loss after processing this batch is:  0.002282381057739258\n",
      "\n",
      "The classification loss after processing this batch is:  0.05115022510290146\n",
      "The representation loss after processing this batch is:  0.002369023859500885\n",
      "\n",
      "The classification loss after processing this batch is:  0.060448963195085526\n",
      "The representation loss after processing this batch is:  0.00247279554605484\n",
      "\n",
      "The classification loss after processing this batch is:  0.24282068014144897\n",
      "The representation loss after processing this batch is:  0.0024073943495750427\n",
      "\n",
      "The classification loss after processing this batch is:  0.06327279657125473\n",
      "The representation loss after processing this batch is:  0.00244169682264328\n",
      "\n",
      "The classification loss after processing this batch is:  0.12219839543104172\n",
      "The representation loss after processing this batch is:  0.0027593672275543213\n",
      "\n",
      "The classification loss after processing this batch is:  0.11478792876005173\n",
      "The representation loss after processing this batch is:  0.0027538612484931946\n",
      "\n",
      "The classification loss after processing this batch is:  0.08178386837244034\n",
      "The representation loss after processing this batch is:  0.0025158897042274475\n",
      "\n",
      "The classification loss after processing this batch is:  0.06384340673685074\n",
      "The representation loss after processing this batch is:  0.0024191364645957947\n",
      "\n",
      "The classification loss after processing this batch is:  0.1620725691318512\n",
      "The representation loss after processing this batch is:  0.0022965744137763977\n",
      "\n",
      "The classification loss after processing this batch is:  0.19127708673477173\n",
      "The representation loss after processing this batch is:  0.0024533122777938843\n",
      "\n",
      "The classification loss after processing this batch is:  0.1316850334405899\n",
      "The representation loss after processing this batch is:  0.0027914270758628845\n",
      "\n",
      "The classification loss after processing this batch is:  0.058792248368263245\n",
      "The representation loss after processing this batch is:  0.0024232082068920135\n",
      "\n",
      "The classification loss after processing this batch is:  0.28955593705177307\n",
      "The representation loss after processing this batch is:  0.002246987074613571\n",
      "\n",
      "The classification loss after processing this batch is:  0.06211226433515549\n",
      "The representation loss after processing this batch is:  0.0021890252828598022\n",
      "\n",
      "The classification loss after processing this batch is:  0.06479279696941376\n",
      "The representation loss after processing this batch is:  0.002311199903488159\n",
      "\n",
      "The classification loss after processing this batch is:  0.12366313487291336\n",
      "The representation loss after processing this batch is:  0.0026742592453956604\n",
      "\n",
      "The classification loss after processing this batch is:  0.0839717760682106\n",
      "The representation loss after processing this batch is:  0.002356830984354019\n",
      "\n",
      "The classification loss after processing this batch is:  0.08461146801710129\n",
      "The representation loss after processing this batch is:  0.00244913250207901\n",
      "\n",
      "The classification loss after processing this batch is:  0.06355173885822296\n",
      "The representation loss after processing this batch is:  0.002669289708137512\n",
      "\n",
      "The classification loss after processing this batch is:  0.14747501909732819\n",
      "The representation loss after processing this batch is:  0.002419598400592804\n",
      "\n",
      "The classification loss after processing this batch is:  0.17609164118766785\n",
      "The representation loss after processing this batch is:  0.002464570105075836\n",
      "\n",
      "The classification loss after processing this batch is:  0.13776905834674835\n",
      "The representation loss after processing this batch is:  0.0023605525493621826\n",
      "\n",
      "The classification loss after processing this batch is:  0.1031607836484909\n",
      "The representation loss after processing this batch is:  0.002700161188840866\n",
      "\n",
      "The classification loss after processing this batch is:  0.10087791830301285\n",
      "The representation loss after processing this batch is:  0.0029587894678115845\n",
      "\n",
      "The classification loss after processing this batch is:  0.1142672672867775\n",
      "The representation loss after processing this batch is:  0.0022291839122772217\n",
      "\n",
      "The classification loss after processing this batch is:  0.1226942390203476\n",
      "The representation loss after processing this batch is:  0.002215832471847534\n",
      "\n",
      "The classification loss after processing this batch is:  0.016628121957182884\n",
      "The representation loss after processing this batch is:  0.0024970918893814087\n",
      "\n",
      "The classification loss after processing this batch is:  0.09801896661520004\n",
      "The representation loss after processing this batch is:  0.0021490678191184998\n",
      "\n",
      "The classification loss after processing this batch is:  0.20216232538223267\n",
      "The representation loss after processing this batch is:  0.002578556537628174\n",
      "\n",
      "The classification loss after processing this batch is:  0.26143723726272583\n",
      "The representation loss after processing this batch is:  0.002485990524291992\n",
      "\n",
      "The classification loss after processing this batch is:  0.2048526108264923\n",
      "The representation loss after processing this batch is:  0.002207081764936447\n",
      "\n",
      "The classification loss after processing this batch is:  0.16921578347682953\n",
      "The representation loss after processing this batch is:  0.0021307989954948425\n",
      "\n",
      "The classification loss after processing this batch is:  0.03176217898726463\n",
      "The representation loss after processing this batch is:  0.002248067408800125\n",
      "\n",
      "The classification loss after processing this batch is:  0.08822297304868698\n",
      "The representation loss after processing this batch is:  0.00215815007686615\n",
      "\n",
      "The classification loss after processing this batch is:  0.09494570642709732\n",
      "The representation loss after processing this batch is:  0.0026946812868118286\n",
      "\n",
      "The classification loss after processing this batch is:  0.15559513866901398\n",
      "The representation loss after processing this batch is:  0.002608068287372589\n",
      "\n",
      "The classification loss after processing this batch is:  0.1558041274547577\n",
      "The representation loss after processing this batch is:  0.0025573596358299255\n",
      "\n",
      "The classification loss after processing this batch is:  0.1041383221745491\n",
      "The representation loss after processing this batch is:  0.0028245002031326294\n",
      "\n",
      "The classification loss after processing this batch is:  0.0661943107843399\n",
      "The representation loss after processing this batch is:  0.002445600926876068\n",
      "\n",
      "The classification loss after processing this batch is:  0.0867098867893219\n",
      "The representation loss after processing this batch is:  0.002375662326812744\n",
      "\n",
      "The classification loss after processing this batch is:  0.1446528136730194\n",
      "The representation loss after processing this batch is:  0.002649471163749695\n",
      "\n",
      "The classification loss after processing this batch is:  0.13409212231636047\n",
      "The representation loss after processing this batch is:  0.0024884864687919617\n",
      "\n",
      "The classification loss after processing this batch is:  0.08435162901878357\n",
      "The representation loss after processing this batch is:  0.002047274261713028\n",
      "\n",
      "The classification loss after processing this batch is:  0.20307187736034393\n",
      "The representation loss after processing this batch is:  0.0030211322009563446\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.3032286465167999\n",
      "The representation loss after processing this batch is:  0.002706781029701233\n",
      "\n",
      "The classification loss after processing this batch is:  0.15059880912303925\n",
      "The representation loss after processing this batch is:  0.0028655454516410828\n",
      "\n",
      "The classification loss after processing this batch is:  0.09228596091270447\n",
      "The representation loss after processing this batch is:  0.0025258660316467285\n",
      "\n",
      "The classification loss after processing this batch is:  0.06246119365096092\n",
      "The representation loss after processing this batch is:  0.0026836395263671875\n",
      "\n",
      "The classification loss after processing this batch is:  0.037832919508218765\n",
      "The representation loss after processing this batch is:  0.0023672208189964294\n",
      "\n",
      "The classification loss after processing this batch is:  0.17039193212985992\n",
      "The representation loss after processing this batch is:  0.0023890510201454163\n",
      "\n",
      "The classification loss after processing this batch is:  0.12473075836896896\n",
      "The representation loss after processing this batch is:  0.0027461647987365723\n",
      "\n",
      "The classification loss after processing this batch is:  0.09135552495718002\n",
      "The representation loss after processing this batch is:  0.0028521493077278137\n",
      "\n",
      "The classification loss after processing this batch is:  0.21660205721855164\n",
      "The representation loss after processing this batch is:  0.002443157136440277\n",
      "\n",
      "The classification loss after processing this batch is:  0.0424196794629097\n",
      "The representation loss after processing this batch is:  0.0025270506739616394\n",
      "\n",
      "The classification loss after processing this batch is:  0.04675702378153801\n",
      "The representation loss after processing this batch is:  0.0026886239647865295\n",
      "\n",
      "The classification loss after processing this batch is:  0.09173101931810379\n",
      "The representation loss after processing this batch is:  0.0024047642946243286\n",
      "\n",
      "The classification loss after processing this batch is:  0.08529183268547058\n",
      "The representation loss after processing this batch is:  0.002300407737493515\n",
      "\n",
      "The classification loss after processing this batch is:  0.12885119020938873\n",
      "The representation loss after processing this batch is:  0.0027624741196632385\n",
      "\n",
      "The classification loss after processing this batch is:  0.11033279448747635\n",
      "The representation loss after processing this batch is:  0.002485834062099457\n",
      "\n",
      "The classification loss after processing this batch is:  0.09849906712770462\n",
      "The representation loss after processing this batch is:  0.0025259777903556824\n",
      "\n",
      "The classification loss after processing this batch is:  0.0410827212035656\n",
      "The representation loss after processing this batch is:  0.002484336495399475\n",
      "\n",
      "The classification loss after processing this batch is:  0.04816344752907753\n",
      "The representation loss after processing this batch is:  0.002446472644805908\n",
      "\n",
      "The classification loss after processing this batch is:  0.06608883291482925\n",
      "The representation loss after processing this batch is:  0.002566814422607422\n",
      "\n",
      "The classification loss after processing this batch is:  0.03622416779398918\n",
      "The representation loss after processing this batch is:  0.0025737732648849487\n",
      "\n",
      "The classification loss after processing this batch is:  0.07289984822273254\n",
      "The representation loss after processing this batch is:  0.0022532790899276733\n",
      "\n",
      "The classification loss after processing this batch is:  0.12699978053569794\n",
      "The representation loss after processing this batch is:  0.0022633597254753113\n",
      "\n",
      "The classification loss after processing this batch is:  0.1631321907043457\n",
      "The representation loss after processing this batch is:  0.002590164542198181\n",
      "\n",
      "The classification loss after processing this batch is:  0.03853128105401993\n",
      "The representation loss after processing this batch is:  0.002107463777065277\n",
      "\n",
      "The classification loss after processing this batch is:  0.047772765159606934\n",
      "The representation loss after processing this batch is:  0.0023948773741722107\n",
      "\n",
      "The classification loss after processing this batch is:  0.09035253524780273\n",
      "The representation loss after processing this batch is:  0.0028263255953788757\n",
      "\n",
      "The classification loss after processing this batch is:  0.13790269196033478\n",
      "The representation loss after processing this batch is:  0.002320285886526108\n",
      "\n",
      "The classification loss after processing this batch is:  0.04451775550842285\n",
      "The representation loss after processing this batch is:  0.0027436092495918274\n",
      "\n",
      "The classification loss after processing this batch is:  0.1344713568687439\n",
      "The representation loss after processing this batch is:  0.0031791403889656067\n",
      "\n",
      "The classification loss after processing this batch is:  0.1678689867258072\n",
      "The representation loss after processing this batch is:  0.0023534633219242096\n",
      "\n",
      "The classification loss after processing this batch is:  0.19233252108097076\n",
      "The representation loss after processing this batch is:  0.0025630220770835876\n",
      "\n",
      "The classification loss after processing this batch is:  0.08720853924751282\n",
      "The representation loss after processing this batch is:  0.002419784665107727\n",
      "\n",
      "The classification loss after processing this batch is:  0.04437195509672165\n",
      "The representation loss after processing this batch is:  0.0023675188422203064\n",
      "\n",
      "The classification loss after processing this batch is:  0.06665464490652084\n",
      "The representation loss after processing this batch is:  0.00232146680355072\n",
      "\n",
      "The classification loss after processing this batch is:  0.14407120645046234\n",
      "The representation loss after processing this batch is:  0.0024708881974220276\n",
      "\n",
      "The classification loss after processing this batch is:  0.05215240269899368\n",
      "The representation loss after processing this batch is:  0.0026571154594421387\n",
      "\n",
      "The classification loss after processing this batch is:  0.02752356044948101\n",
      "The representation loss after processing this batch is:  0.002227485179901123\n",
      "\n",
      "The classification loss after processing this batch is:  0.192111998796463\n",
      "The representation loss after processing this batch is:  0.0024820268154144287\n",
      "\n",
      "The classification loss after processing this batch is:  0.17453813552856445\n",
      "The representation loss after processing this batch is:  0.0023042261600494385\n",
      "\n",
      "The classification loss after processing this batch is:  0.07204921543598175\n",
      "The representation loss after processing this batch is:  0.0021568499505519867\n",
      "\n",
      "The classification loss after processing this batch is:  0.22671206295490265\n",
      "The representation loss after processing this batch is:  0.0023081451654434204\n",
      "\n",
      "The classification loss after processing this batch is:  0.18235740065574646\n",
      "The representation loss after processing this batch is:  0.002510949969291687\n",
      "\n",
      "The classification loss after processing this batch is:  0.2529328465461731\n",
      "The representation loss after processing this batch is:  0.002463430166244507\n",
      "\n",
      "The classification loss after processing this batch is:  0.1332889199256897\n",
      "The representation loss after processing this batch is:  0.0023566782474517822\n",
      "\n",
      "The classification loss after processing this batch is:  0.06809064745903015\n",
      "The representation loss after processing this batch is:  0.0022676512598991394\n",
      "\n",
      "The classification loss after processing this batch is:  0.12415663152933121\n",
      "The representation loss after processing this batch is:  0.0025028064846992493\n",
      "\n",
      "The classification loss after processing this batch is:  0.06693265587091446\n",
      "The representation loss after processing this batch is:  0.0025067776441574097\n",
      "\n",
      "The classification loss after processing this batch is:  0.061280589550733566\n",
      "The representation loss after processing this batch is:  0.0024555549025535583\n",
      "\n",
      "The classification loss after processing this batch is:  0.05765477195382118\n",
      "The representation loss after processing this batch is:  0.002180863171815872\n",
      "\n",
      "The classification loss after processing this batch is:  0.04615716263651848\n",
      "The representation loss after processing this batch is:  0.0024267882108688354\n",
      "\n",
      "The classification loss after processing this batch is:  0.01948072947561741\n",
      "The representation loss after processing this batch is:  0.002616778016090393\n",
      "\n",
      "The classification loss after processing this batch is:  0.11209707707166672\n",
      "The representation loss after processing this batch is:  0.0026562921702861786\n",
      "\n",
      "The classification loss after processing this batch is:  0.1312122642993927\n",
      "The representation loss after processing this batch is:  0.002317085862159729\n",
      "\n",
      "The classification loss after processing this batch is:  0.05337417870759964\n",
      "The representation loss after processing this batch is:  0.0028383880853652954\n",
      "\n",
      "The classification loss after processing this batch is:  0.0740426629781723\n",
      "The representation loss after processing this batch is:  0.002279866486787796\n",
      "\n",
      "The classification loss after processing this batch is:  0.09877094626426697\n",
      "The representation loss after processing this batch is:  0.0023935213685035706\n",
      "\n",
      "The classification loss after processing this batch is:  0.022261865437030792\n",
      "The representation loss after processing this batch is:  0.0023814886808395386\n",
      "\n",
      "The classification loss after processing this batch is:  0.14873681962490082\n",
      "The representation loss after processing this batch is:  0.0024933740496635437\n",
      "\n",
      "The classification loss after processing this batch is:  0.06995894759893417\n",
      "The representation loss after processing this batch is:  0.0022505000233650208\n",
      "\n",
      "The classification loss after processing this batch is:  0.24204854667186737\n",
      "The representation loss after processing this batch is:  0.002446293830871582\n",
      "\n",
      "The classification loss after processing this batch is:  0.11256027221679688\n",
      "The representation loss after processing this batch is:  0.002387724816799164\n",
      "\n",
      "The classification loss after processing this batch is:  0.11100268363952637\n",
      "The representation loss after processing this batch is:  0.002268001437187195\n",
      "\n",
      "The classification loss after processing this batch is:  0.02520325966179371\n",
      "The representation loss after processing this batch is:  0.0025119781494140625\n",
      "\n",
      "The classification loss after processing this batch is:  0.0378325916826725\n",
      "The representation loss after processing this batch is:  0.002167239785194397\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.13992570340633392\n",
      "The representation loss after processing this batch is:  0.002357490360736847\n",
      "\n",
      "The classification loss after processing this batch is:  0.048218682408332825\n",
      "The representation loss after processing this batch is:  0.002664804458618164\n",
      "\n",
      "The classification loss after processing this batch is:  0.09001355618238449\n",
      "The representation loss after processing this batch is:  0.0025169551372528076\n",
      "\n",
      "The classification loss after processing this batch is:  0.06780990213155746\n",
      "The representation loss after processing this batch is:  0.0025636106729507446\n",
      "\n",
      "The classification loss after processing this batch is:  0.06514718383550644\n",
      "The representation loss after processing this batch is:  0.0028108060359954834\n",
      "\n",
      "The classification loss after processing this batch is:  0.11375872790813446\n",
      "The representation loss after processing this batch is:  0.002421334385871887\n",
      "\n",
      "The classification loss after processing this batch is:  0.042654044926166534\n",
      "The representation loss after processing this batch is:  0.0025853365659713745\n",
      "\n",
      "The classification loss after processing this batch is:  0.13031046092510223\n",
      "The representation loss after processing this batch is:  0.0026447325944900513\n",
      "\n",
      "The classification loss after processing this batch is:  0.1908426284790039\n",
      "The representation loss after processing this batch is:  0.002516143023967743\n",
      "\n",
      "The classification loss after processing this batch is:  0.1439664512872696\n",
      "The representation loss after processing this batch is:  0.0027476847171783447\n",
      "\n",
      "The classification loss after processing this batch is:  0.1741340458393097\n",
      "The representation loss after processing this batch is:  0.002322189509868622\n",
      "\n",
      "The classification loss after processing this batch is:  0.15879692137241364\n",
      "The representation loss after processing this batch is:  0.0025935098528862\n",
      "\n",
      "The classification loss after processing this batch is:  0.07683547586202621\n",
      "The representation loss after processing this batch is:  0.0021852999925613403\n",
      "\n",
      "The classification loss after processing this batch is:  0.06670066714286804\n",
      "The representation loss after processing this batch is:  0.0022737085819244385\n",
      "\n",
      "The classification loss after processing this batch is:  0.05265115201473236\n",
      "The representation loss after processing this batch is:  0.002268567681312561\n",
      "\n",
      "The classification loss after processing this batch is:  0.08627471327781677\n",
      "The representation loss after processing this batch is:  0.00251789391040802\n",
      "\n",
      "The classification loss after processing this batch is:  0.03813575953245163\n",
      "The representation loss after processing this batch is:  0.0024652183055877686\n",
      "\n",
      "The classification loss after processing this batch is:  0.08137381076812744\n",
      "The representation loss after processing this batch is:  0.0020603127777576447\n",
      "\n",
      "The classification loss after processing this batch is:  0.08437695354223251\n",
      "The representation loss after processing this batch is:  0.002312399446964264\n",
      "\n",
      "The classification loss after processing this batch is:  0.08322367072105408\n",
      "The representation loss after processing this batch is:  0.0026507675647735596\n",
      "\n",
      "The classification loss after processing this batch is:  0.06317340582609177\n",
      "The representation loss after processing this batch is:  0.0023048371076583862\n",
      "\n",
      "The classification loss after processing this batch is:  0.126708522439003\n",
      "The representation loss after processing this batch is:  0.0021497756242752075\n",
      "\n",
      "The classification loss after processing this batch is:  0.05068046972155571\n",
      "The representation loss after processing this batch is:  0.0024804100394248962\n",
      "\n",
      "The classification loss after processing this batch is:  0.0915452390909195\n",
      "The representation loss after processing this batch is:  0.002414107322692871\n",
      "\n",
      "The classification loss after processing this batch is:  0.12279316037893295\n",
      "The representation loss after processing this batch is:  0.0024011358618736267\n",
      "\n",
      "The classification loss after processing this batch is:  0.08252374082803726\n",
      "The representation loss after processing this batch is:  0.0025915056467056274\n",
      "\n",
      "The classification loss after processing this batch is:  0.055430129170417786\n",
      "The representation loss after processing this batch is:  0.002627238631248474\n",
      "\n",
      "The classification loss after processing this batch is:  0.15701888501644135\n",
      "The representation loss after processing this batch is:  0.0024389028549194336\n",
      "\n",
      "The classification loss after processing this batch is:  0.06142368167638779\n",
      "The representation loss after processing this batch is:  0.0024615153670310974\n",
      "\n",
      "The classification loss after processing this batch is:  0.05638830363750458\n",
      "The representation loss after processing this batch is:  0.0024617984890937805\n",
      "\n",
      "The classification loss after processing this batch is:  0.0810684859752655\n",
      "The representation loss after processing this batch is:  0.0024028271436691284\n",
      "\n",
      "The classification loss after processing this batch is:  0.04270601272583008\n",
      "The representation loss after processing this batch is:  0.0024757683277130127\n",
      "\n",
      "The classification loss after processing this batch is:  0.10389447212219238\n",
      "The representation loss after processing this batch is:  0.0022300370037555695\n",
      "\n",
      "The classification loss after processing this batch is:  0.12929224967956543\n",
      "The representation loss after processing this batch is:  0.00250934436917305\n",
      "\n",
      "The classification loss after processing this batch is:  0.06629538536071777\n",
      "The representation loss after processing this batch is:  0.002714402973651886\n",
      "\n",
      "The classification loss after processing this batch is:  0.0753374770283699\n",
      "The representation loss after processing this batch is:  0.002896048128604889\n",
      "\n",
      "The classification loss after processing this batch is:  0.07803602516651154\n",
      "The representation loss after processing this batch is:  0.002543151378631592\n",
      "\n",
      "The classification loss after processing this batch is:  0.21650923788547516\n",
      "The representation loss after processing this batch is:  0.0024527721107006073\n",
      "\n",
      "The classification loss after processing this batch is:  0.039812829345464706\n",
      "The representation loss after processing this batch is:  0.002356491982936859\n",
      "\n",
      "The classification loss after processing this batch is:  0.06971172243356705\n",
      "The representation loss after processing this batch is:  0.0025665834546089172\n",
      "\n",
      "The classification loss after processing this batch is:  0.13897386193275452\n",
      "The representation loss after processing this batch is:  0.0021190010011196136\n",
      "\n",
      "The classification loss after processing this batch is:  0.28749629855155945\n",
      "The representation loss after processing this batch is:  0.0025147423148155212\n",
      "\n",
      "The classification loss after processing this batch is:  0.07568986713886261\n",
      "The representation loss after processing this batch is:  0.002229750156402588\n",
      "\n",
      "The classification loss after processing this batch is:  0.0940665453672409\n",
      "The representation loss after processing this batch is:  0.0021979771554470062\n",
      "\n",
      "The classification loss after processing this batch is:  0.07433651387691498\n",
      "The representation loss after processing this batch is:  0.002398088574409485\n",
      "\n",
      "The classification loss after processing this batch is:  0.029993215575814247\n",
      "The representation loss after processing this batch is:  0.002276316285133362\n",
      "\n",
      "The classification loss after processing this batch is:  0.10552015155553818\n",
      "The representation loss after processing this batch is:  0.0029084086418151855\n",
      "\n",
      "The classification loss after processing this batch is:  0.07162030786275864\n",
      "The representation loss after processing this batch is:  0.0031895041465759277\n",
      "\n",
      "The classification loss after processing this batch is:  0.03638318553566933\n",
      "The representation loss after processing this batch is:  0.0025534220039844513\n",
      "\n",
      "The classification loss after processing this batch is:  0.0540560819208622\n",
      "The representation loss after processing this batch is:  0.0023859813809394836\n",
      "\n",
      "The classification loss after processing this batch is:  0.13789434731006622\n",
      "The representation loss after processing this batch is:  0.0023883841931819916\n",
      "\n",
      "The classification loss after processing this batch is:  0.10960868746042252\n",
      "The representation loss after processing this batch is:  0.002344861626625061\n",
      "\n",
      "The classification loss after processing this batch is:  0.059783026576042175\n",
      "The representation loss after processing this batch is:  0.0021670088171958923\n",
      "\n",
      "The classification loss after processing this batch is:  0.05137362703680992\n",
      "The representation loss after processing this batch is:  0.002616800367832184\n",
      "\n",
      "The classification loss after processing this batch is:  0.20439840853214264\n",
      "The representation loss after processing this batch is:  0.0022868141531944275\n",
      "\n",
      "The classification loss after processing this batch is:  0.13153745234012604\n",
      "The representation loss after processing this batch is:  0.002376466989517212\n",
      "\n",
      "The classification loss after processing this batch is:  0.17803220450878143\n",
      "The representation loss after processing this batch is:  0.002172902226448059\n",
      "\n",
      "The classification loss after processing this batch is:  0.10944712907075882\n",
      "The representation loss after processing this batch is:  0.0025959983468055725\n",
      "\n",
      "The classification loss after processing this batch is:  0.15349002182483673\n",
      "The representation loss after processing this batch is:  0.0024029724299907684\n",
      "\n",
      "The classification loss after processing this batch is:  0.07510946691036224\n",
      "The representation loss after processing this batch is:  0.002485334873199463\n",
      "\n",
      "The classification loss after processing this batch is:  0.05122719332575798\n",
      "The representation loss after processing this batch is:  0.0027460604906082153\n",
      "\n",
      "The classification loss after processing this batch is:  0.027338223531842232\n",
      "The representation loss after processing this batch is:  0.0022758841514587402\n",
      "\n",
      "The classification loss after processing this batch is:  0.046052515506744385\n",
      "The representation loss after processing this batch is:  0.002289324998855591\n",
      "\n",
      "The classification loss after processing this batch is:  0.1842169463634491\n",
      "The representation loss after processing this batch is:  0.002445746213197708\n",
      "\n",
      "The classification loss after processing this batch is:  0.10374186933040619\n",
      "The representation loss after processing this batch is:  0.0028178617358207703\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  0.03353966400027275\n",
      "The representation loss after processing this batch is:  0.002269253134727478\n",
      "\n",
      "The classification loss after processing this batch is:  0.02479531802237034\n",
      "The representation loss after processing this batch is:  0.0027702301740646362\n",
      "\n",
      "The classification loss after processing this batch is:  0.02222696878015995\n",
      "The representation loss after processing this batch is:  0.0028984546661376953\n",
      "\n",
      "The classification loss after processing this batch is:  0.049761295318603516\n",
      "The representation loss after processing this batch is:  0.003194361925125122\n",
      "\n",
      "The classification loss after processing this batch is:  0.056589383631944656\n",
      "The representation loss after processing this batch is:  0.002636365592479706\n",
      "\n",
      "The classification loss after processing this batch is:  0.036829911172389984\n",
      "The representation loss after processing this batch is:  0.0027554184198379517\n",
      "\n",
      "The classification loss after processing this batch is:  0.017974726855754852\n",
      "The representation loss after processing this batch is:  0.0027568116784095764\n",
      "\n",
      "The classification loss after processing this batch is:  0.03217452019453049\n",
      "The representation loss after processing this batch is:  0.0029940232634544373\n",
      "\n",
      "The classification loss after processing this batch is:  0.0675358697772026\n",
      "The representation loss after processing this batch is:  0.003360353410243988\n",
      "\n",
      "The classification loss after processing this batch is:  0.009828639216721058\n",
      "The representation loss after processing this batch is:  0.0034538209438323975\n",
      "\n",
      "The classification loss after processing this batch is:  0.03377062827348709\n",
      "The representation loss after processing this batch is:  0.0028289631009101868\n",
      "\n",
      "The classification loss after processing this batch is:  0.12826435267925262\n",
      "The representation loss after processing this batch is:  0.0029010772705078125\n",
      "\n",
      "The classification loss after processing this batch is:  0.01949438638985157\n",
      "The representation loss after processing this batch is:  0.0031231045722961426\n",
      "\n",
      "The classification loss after processing this batch is:  0.011498554609715939\n",
      "The representation loss after processing this batch is:  0.0027301162481307983\n",
      "\n",
      "The classification loss after processing this batch is:  0.014592071063816547\n",
      "The representation loss after processing this batch is:  0.0028886497020721436\n",
      "\n",
      "The classification loss after processing this batch is:  0.020762864500284195\n",
      "The representation loss after processing this batch is:  0.003032967448234558\n",
      "\n",
      "The classification loss after processing this batch is:  0.03418799862265587\n",
      "The representation loss after processing this batch is:  0.0028289109468460083\n",
      "\n",
      "The classification loss after processing this batch is:  0.025280602276325226\n",
      "The representation loss after processing this batch is:  0.0031482279300689697\n",
      "\n",
      "The classification loss after processing this batch is:  0.011552032083272934\n",
      "The representation loss after processing this batch is:  0.003330416977405548\n",
      "\n",
      "The classification loss after processing this batch is:  0.2072550654411316\n",
      "The representation loss after processing this batch is:  0.0031777843832969666\n",
      "\n",
      "The classification loss after processing this batch is:  0.2572774589061737\n",
      "The representation loss after processing this batch is:  0.003214441239833832\n",
      "\n",
      "The classification loss after processing this batch is:  0.21016870439052582\n",
      "The representation loss after processing this batch is:  0.003624536097049713\n",
      "\n",
      "The classification loss after processing this batch is:  0.03360637277364731\n",
      "The representation loss after processing this batch is:  0.002478092908859253\n",
      "\n",
      "The classification loss after processing this batch is:  0.012877281755208969\n",
      "The representation loss after processing this batch is:  0.003248438239097595\n",
      "\n",
      "The classification loss after processing this batch is:  0.008175746537744999\n",
      "The representation loss after processing this batch is:  0.0021193623542785645\n",
      "\n",
      "The classification loss after processing this batch is:  0.11579238623380661\n",
      "The representation loss after processing this batch is:  0.0023158788681030273\n",
      "\n",
      "The classification loss after processing this batch is:  0.31498607993125916\n",
      "The representation loss after processing this batch is:  0.0026137307286262512\n",
      "\n",
      "The classification loss after processing this batch is:  0.053487200289964676\n",
      "The representation loss after processing this batch is:  0.0024891197681427\n",
      "\n",
      "The classification loss after processing this batch is:  0.029024649411439896\n",
      "The representation loss after processing this batch is:  0.003031224012374878\n",
      "\n",
      "The classification loss after processing this batch is:  0.03157946094870567\n",
      "The representation loss after processing this batch is:  0.002879530191421509\n",
      "\n",
      "The classification loss after processing this batch is:  0.037763841450214386\n",
      "The representation loss after processing this batch is:  0.003297872841358185\n",
      "\n",
      "Done training..\n",
      "=*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*=\n"
     ]
    }
   ],
   "source": [
    "modelMM = NeuralModel()\n",
    "model = train_model(modelMM, training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_data):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "\n",
    "    for batch in test_data:\n",
    "        batch_images, batch_labels = batch\n",
    "\n",
    "        batch_images = batch_images.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        predictions = model(batch_images)\n",
    "       \n",
    "        predictions = predictions.data.max(1, keepdim=True)[1]\n",
    "       \n",
    "        correct += predictions.eq(batch_labels.data.view_as(predictions)).sum()\n",
    "       \n",
    "\n",
    "    accuracy = float(correct.item() / len(test_data.dataset))\n",
    "    \n",
    "    print(\"The classifier accuracy is: \", 100 * accuracy)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier accuracy is:  96.61999999999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9662"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64)\n",
    "test_model(modelMM, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM Attack : \n",
      "0.4067\n",
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
      "Projected Gradient Attack : \n",
      "0.8515\n",
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
      "iFGSM Attack : \n",
      "0.9245\n",
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
      "Deep Fool Attack : \n",
      "0.5876\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=512)\n",
    "print(attack(modelMM, device, test_loader, fgsm, 0.3)[0])\n",
    "print(\"=*\" * 20)\n",
    "\n",
    "print(attack(modelMM, device, test_loader, pgd, 0.3, 1e-2, 50)[0])\n",
    "print(\"=*\" * 20)\n",
    "\n",
    "print(attack(modelMM, device, test_loader, pgd_linf, 0.3, 1e-3, 40)[0])\n",
    "print(\"=*\" * 20)\n",
    "\n",
    "print(attack(modelMM, device, test_loader, pgd_l2, 2, 0.3, 40)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
