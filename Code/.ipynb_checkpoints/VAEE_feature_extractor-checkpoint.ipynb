{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import data_loader\n",
    "from utils.viewer import show_batch\n",
    "import time\n",
    "from vae_models import VAE_CONV_NeuralModel\n",
    "from graphviz import Digraph\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from multiple_attacks import *\n",
    "from mnist_classifier import NeuralModel, test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = data_loader.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEEClassifier(nn.Module):\n",
    "    def __init__(self, beta):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vae = VAE_CONV_NeuralModel()\n",
    "        self.vae.load_state_dict(torch.load(\"models/trained_CONV_vae_B=\"+str(beta)))\n",
    "        \n",
    "        self.classifier_part = self.encoder = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(16, 14, kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(14),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(14, 12, kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(12),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(12, 10, kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(10),\n",
    "            #nn.linear(inplace=True),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(10 * 1 * 1, 10)\n",
    "        # no_of_last_channels* kernel_H * kernel_W, output_from_fully_conncected \n",
    "    def forward(self, x):\n",
    "        #with torch.no_grad():\n",
    "        vaee_features = self.vae.get_latent(x)\n",
    "        \n",
    "        convolved = self.classifier_part(vaee_features)\n",
    "        classification_logits = self.fc(convolved.view(convolved.size(0), -1))\n",
    "        \n",
    "        return  classification_logits\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    learning_rate = 0.01\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    n_epochs = 15\n",
    "    model.train()\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch %2 == 0:\n",
    "            learning_rate /= 2.5\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        for batch in train_data:\n",
    "            batch_images, batch_labels = batch\n",
    "            \n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            batch_output = model(batch_images)\n",
    "            loss = criterion(batch_output, batch_labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            model.vae = initial_classifier.vae\n",
    "        print(\"the loss after processing this epoch is: \", loss.item())\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsms = []\n",
    "pgds = []\n",
    "ifgsms=[]\n",
    "deepfools=[]\n",
    "eps = .3\n",
    "clean_accuracies =[]\n",
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*=\n",
      "the loss after processing this epoch is:  0.339106947183609\n",
      "the loss after processing this epoch is:  0.2425086498260498\n",
      "the loss after processing this epoch is:  0.13084815442562103\n",
      "the loss after processing this epoch is:  0.1342296153306961\n",
      "the loss after processing this epoch is:  0.13084277510643005\n",
      "the loss after processing this epoch is:  0.11264187097549438\n",
      "the loss after processing this epoch is:  0.1126878634095192\n",
      "the loss after processing this epoch is:  0.09328676015138626\n",
      "the loss after processing this epoch is:  0.09124740958213806\n",
      "the loss after processing this epoch is:  0.0781567394733429\n",
      "the loss after processing this epoch is:  0.08060861378908157\n",
      "the loss after processing this epoch is:  0.06776271015405655\n",
      "the loss after processing this epoch is:  0.06974335014820099\n",
      "the loss after processing this epoch is:  0.06260591000318527\n",
      "the loss after processing this epoch is:  0.06355322152376175\n",
      "test accuracy is:  0.9929\n",
      "FGSM Attack : \n",
      "Projected Gradient Attack : \n",
      "iFGSM Attack : \n",
      "Deep Fool Attack : \n",
      "=*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*=\n",
      "the loss after processing this epoch is:  0.3050033450126648\n",
      "the loss after processing this epoch is:  0.269048273563385\n",
      "the loss after processing this epoch is:  0.10540034621953964\n",
      "the loss after processing this epoch is:  0.10328327864408493\n",
      "the loss after processing this epoch is:  0.11311653256416321\n",
      "the loss after processing this epoch is:  0.1082700788974762\n",
      "the loss after processing this epoch is:  0.1119975820183754\n",
      "the loss after processing this epoch is:  0.09235483407974243\n",
      "the loss after processing this epoch is:  0.09087198972702026\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for b in range (1,10):\n",
    "    \n",
    "    print(\"=*=\"*20)\n",
    "    \n",
    "    initial_classifier = VAEEClassifier(beta=b).to(device)\n",
    "    model =  VAEEClassifier(beta=b).to(device)\n",
    "    model = train_model(model, train_loader)\n",
    "    \n",
    "    \n",
    "    testing_accuracy_before_attack = test_model(model, test_loader)\n",
    "    \n",
    "    print(\"test accuracy is: \", testing_accuracy_before_attack)\n",
    "    clean_accuracies.append(testing_accuracy_before_attack)\n",
    "    \n",
    "    fgsms.append(attack(model, device, test_loader, fgsm, eps)[0])\n",
    "\n",
    "    pgds.append(attack(model, device, test_loader, pgd, eps, 1e4, 50)[0])\n",
    "\n",
    "    ifgsms.append(attack(model, device, test_loader, pgd_linf, eps, 1e-2, 50)[0])\n",
    "\n",
    "    deepfools.append(attack(model, device, test_loader, pgd_l2, 1.3, eps, 50)[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fgsms, label = 'fgsm')\n",
    "plt.plot(pgds, label =\"pgd-ifgsm larg step\")\n",
    "plt.plot(ifgsms, label = 'ifgsm')\n",
    "plt.plot(deepfools, label = 'deep fool L2')\n",
    "plt.legend() \n",
    "\n",
    "plt.xlabel('$Beta$', size = 'xx-large', fontweight = 'demi')\n",
    "plt.ylabel('Accuracy', size = 'x-large')\n",
    "plt.savefig('figures/vaee_classifier.pdf', format='pdf', bbox_inches='tight', quality = 100)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
