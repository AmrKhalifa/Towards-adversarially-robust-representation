{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import data_loader\n",
    "from utils.viewer import show_batch\n",
    "import time\n",
    "from mnist_classifier import test_model\n",
    "from multiple_attacks import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = data_loader.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VFAE_CONV_NeuralModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True)\n",
    "\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(7 * 7 * 16, 50),\n",
    "            nn.BatchNorm1d(50),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.fc_mu = nn.Linear(50, 50)\n",
    "        self.fc_log_var = nn.Linear(50, 50)\n",
    "\n",
    "        # Sampling vector\n",
    "        self.latent = nn.Sequential(\n",
    "\n",
    "            nn.Linear(50, 50),\n",
    "            nn.BatchNorm1d(50),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(50, 7 * 7 * 16),\n",
    "            nn.BatchNorm1d(7 * 7 * 16),\n",
    "            nn.ReLU(inplace=True)\n",
    "\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mean, log_var):\n",
    "        if self.training:\n",
    "            std = log_var.mul(0.5).exp_()\n",
    "            eps = std.data.new(std.size()).normal_()\n",
    "            return eps.mul(std).add_(mean)\n",
    "        else:\n",
    "            return mean\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, log_var = self.get_latent(x)\n",
    "        feature_map_latent = z.view(-1, 16, 7, 7)\n",
    "\n",
    "        decoded = self.decoder(feature_map_latent)\n",
    "        output = decoded.view(-1, 1, 28, 28)\n",
    "\n",
    "        return output, mu, log_var\n",
    "    \n",
    "    def get_latent(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "\n",
    "        encoded = encoded.view(-1, 7 * 7 * 16)\n",
    "\n",
    "        fc = self.fc(encoded)\n",
    "\n",
    "        mu = self.fc_mu(fc)\n",
    "        log_var = self.fc_log_var(fc)\n",
    "\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        latent = self.latent(z)\n",
    "        \n",
    "        return latent, mu, log_var\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "# vae = VAE_FC_NeuralModel()\n",
    "\n",
    "def VAELoss(x_hat, x, mu, logvar, a, b):\n",
    "    BCE = nn.functional.binary_cross_entropy(\n",
    "        x_hat, x.view(-1, 784), reduction='sum'\n",
    "    )\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return a*BCE + b*KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size = 256\n",
    "def MMD_Loss(x, y):\n",
    "    \n",
    "    alpha =1\n",
    "    B=b_size\n",
    "\n",
    "    x = x.view(x.size(0), x.size(1) * 1)\n",
    "    y = y.view(y.size(0), y.size(1) * 1)\n",
    "\n",
    "    xx, yy, zz = torch.mm(x,x.t()), torch.mm(y,y.t()), torch.mm(x,y.t())\n",
    "\n",
    "    rx = (xx.diag().unsqueeze(0).expand_as(xx))\n",
    "    ry = (yy.diag().unsqueeze(0).expand_as(yy))\n",
    "\n",
    "    K = torch.exp(- alpha * (rx.t() + rx - 2*xx))\n",
    "    L = torch.exp(- alpha * (ry.t() + ry - 2*yy))\n",
    "    P = torch.exp(- alpha * (rx.t() + ry - 2*zz))\n",
    "\n",
    "    beta = (1./(B*(B-1)))\n",
    "    gamma = (2./(B*B)) \n",
    "\n",
    "    return beta * (torch.sum(K)+torch.sum(L)) - gamma * torch.sum(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(model, train_data,a, b, adv_examples = False):\n",
    "    learning_rate = 0.01\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    if adv_examples is True: \n",
    "    # invariant representation training\n",
    "        for train in train_data:\n",
    "            for batch in train:\n",
    "                batch_images, adv_images, batch_labels = batch\n",
    "\n",
    "                batch_images = batch_images.to(device)\n",
    "                batch_labels = batch_labels.to(device)\n",
    "                adv_images = adv_images.to(device)\n",
    "\n",
    "                batch_output, mean, log_var = model(batch_images)\n",
    "\n",
    "                latent_1, _, _ = model.get_latent(batch_images.detach())\n",
    "                latent_2, _, _ = model.get_latent(adv_images.detach())\n",
    "\n",
    "                down_stream_loss = VAELoss(batch_output, batch_images.detach(), mean, log_var, a, b)\n",
    "                representation_loss = MMD_Loss(latent_1, latent_2)\n",
    "\n",
    "                total_loss = .00001*down_stream_loss + 10000*representation_loss\n",
    "\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                total_loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "\n",
    "                print(\"The classification loss after processing this batch is: \", down_stream_loss.item())\n",
    "                print(\"The representation loss after processing this batch is: \", representation_loss.item())\n",
    "\n",
    "    else:\n",
    "        ## normal training\n",
    "        for batch in train_data:\n",
    "            batch_images, _ = batch\n",
    "            batch_images = batch_images.to(device)\n",
    "\n",
    "            batch_output, mean, log_var = model(batch_images)\n",
    "            loss = VAELoss(batch_output, batch_images, mean, log_var, a, b)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            print(\"*&**\"*30)\n",
    "            print(\"the loss after processing this batch is: \", loss.item())\n",
    "            optimizer.step()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_vae = VFAE_CONV_NeuralModel().to(device)\n",
    "#initial_vae = train_vae(initial_vae, train_loader, a=1, b=1, False)\n",
    "#torch.save(initial_vae.state_dict(), \"models/trained_vae_b=1_variant_rep\")\n",
    "initial_vae.load_state_dict(torch.load(\"models/trained_vae_b=1_variant_rep\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2wAAAB7CAYAAAAIVwPvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnXmUVNUV7r8dRzKBBjUEHMCg4gTOKI44BIlzFDWJwSExJpjB5cRT45DlikOMRmMeEZXIUyNR44CKDOKAw3JAQZlEQFFQIoliTGJiojnvj669+7tNXXqgu/pW1fdbi8Xu09VVt87d55x77/7O3pZSghBCCCGEEEKI4vGZzj4AIYQQQgghhBDl0Q2bEEIIIYQQQhQU3bAJIYQQQgghREHRDZsQQgghhBBCFBTdsAkhhBBCCCFEQdENmxBCCCGEEEIUFN2wCSGEEEIIIURBWa0bNjMbYmbzzWyhmY1sr4MSQgghhBBCCAFYWwtnm9kaAF4DcCCApQBeAHB8Smlu+x2eEEIIIYQQQtQva67G3+4KYGFK6XUAMLNxAA4HkHvDZmZtuzsUQgghhBBCiNrgrymlDVr64tWRRPYEsIR+Xlpqy2Bmp5rZdDObvhqfJYQQQgghhBC1wJutefHqRNisTNtKEbSU0mgAowFF2IQQQgghhBCiNaxOhG0pgI3p514A3lm9wxFCCCGEEEII4azODdsLAPqaWW8zWxvAcQDGt89hCSGEEEIIIYRosyQypfSJmZ0OYBKANQCMSSnNabcjE0IIIYQQQog6p81p/dv0YdrDJoQQQgghhKhvXkwp7dzSF69W4WwhhBBCCCGEEB2HbtiEEEIIIYQQoqDohk0IIYQQQgghCopu2IQQQgghhBCioOiGTQghhBBCCCEKim7YhBBCCCGEEKKg6IZNCCGEEEIIIQpKmwtnC9FWzKyszfzvf/+r1OEI0SbK+W4l61oKUW+sscYaYa+99tphd+vWLew99tgDALDllltG24IFC8J++umnw16+fHnYn3zySfserBCiall33XXD3nTTTcP2OWj+/PnR9umnn1bkmBRhE0IIIYQQQoiCohs2IYQQQgghhCgodSeJ/Mxnmr9HLSdrktSpbbhsrGvXrtF2/PHHhz1s2LCwWZIyatQoAMDEiROj7aOPPuqw4xQiD5Zh9e/fP+yTTz4ZALBixYpoGzt2bNivv/562JL4ipbA69OaazYuz+yDPqd+/PHH0VYpSU5n4f3y2c9+Ntp69+4d9re+9a2wfU3p3r17tP3zn/8M++GHHw774osvDnvJkiUA6nOs5m1TYNvPAfsl9xX7YDl/1DWUKCru21/4whei7aijjipr//3vfwcAXHDBBdH21ltvhd2R0mpF2IQQQgghhBCioNR0hM3vmrt06RJtm222Wdhf/OIXw15nnXXC9tfzE6G11lor7L/85S9h/+1vfwMAfPDBB9HGT5f4iSlvkva7cP97APj3v/9d9j2qDf7OX/nKVwAAP/7xj6PNIxNAdmMnP5nwJ3eLFy+OttmzZ4f9n//8p/0OuIPIe1LJflXJp455CV705HNl2Id5zvj5z38e9l577QUgO/ZfeOGFsN98882w6/GpvVg17GPrrbcegEafAoCDDz447D59+oS9cOFCAMCDDz4YbdOmTQvbnwDXItxnG2+8cdiDBg0K29dyXlt5/PHfeb8DjRG2WoTnfr7W8fV5v/32i7Ztt902bE/gAgA9e/YEAHz+858v+xkc8XUfnDlzZrSNGTMm7GeeeSZsnj9rDb6+2WijjcJmf3znnXcAVPc1X7WQdw3kUeNNNtkk2o444oiwt9tuu7D9mpRf6+cQUIRNCCGEEEIIIeoS3bAJIYQQQgghREGpOUlkudA/h/hPO+20sHnT8vrrrx+2SyJZSsmysXKSR5bosWyDZQKcNOOvf/0rgGxSjbvuuivsd999N+z//ve/KDr8nfv27Rv2JZdcAgAYOnRotPGmZf5uvDHcz83w4cOj7aqrrgp76dKlYRdB0sd+5xtXuQ4Qy0g4GcW//vWvsD/88EMAWV9qq3ySj8f9eIMNNog27vf3338/bP7sepTxuR+zXJqlEXvuuWfYLnfh+eC9994Lu5b7j8c7J8Qol5CAX8t9lZewoAjjuaMoJxcHgBNPPBEAcMopp0QbJ83gPh44cCAAYPDgwdF23nnnhf3QQw+FzTL7asZ9guVGLDdjn/Haajy38rz2xhtvhM3rc55cqhbI87tzzjkHQFZ+y+sEbwXx/snrJ07Y4NdT/Fnbb7992Cwt/+Mf/xh2NVzrNAf3D19XnnXWWWXbR44cCaB41zTVAvu2933edRPbfJ583dp5552jjf2V1yqfX19++eVo43mkI1GETQghhBBCCCEKim7YhBBCCCGEEKKg1JwkkiU5nsXlyCOPjLZ99tkn7C996Uths+TEaS6jTB4cPmWbZRku5/jyl78cbZxFiDNRFhXus6222irsa6+9NmyXkHFfchYzlgFwWLlHjx4AgEMPPTTaWMpy4403hs1SykrC33/DDTcM+7jjjgMAHHTQQdE2Y8aMsFkG+9prr4XtEt5y2TKB1skk2Ec33XRTAMAhhxwSbSzRvP/++8OeO3du2H4+al2ewb7pEqCtt9462k466aSwuQ6U98v06dOjbf78+WHXStYv7p9u3boByEpHuK7ijjvuGLb7IM97LAeeM2dO2Jw1zjNtcpa/au7LvMyGZ5xxRtg+Z3j/AtnvzFIxfz+WrrGPzpo1K+wFCxYAqP4x7MfP/fCPf/wjbPYVfy1nH2SJM2cezsskWWuwtJGvgYYMGQIge+2Rd33j61JrMh7za9n3Tz/99LA5wynXs6pWuB84M/guu+wSNmcePuaYYwAA119/fbRVQxbszoSvvVhe+rnPfQ5AdpsHzxN586Cfp5122mml9wKy2U7vu+8+AOXnnI6m2QibmY0xs+VmNpva1jezKWa2oPT/eqt6DyGEEEIIIYQQraclkshbAAxp0jYSwNSUUl8AU0s/CyGEEEIIIYRoR5qVRKaUppnZZk2aDwewb8keC+BxAOe243G1CpaccGj/G9/4BgBg2LBh0cYySMazNgKNoU6W6HGxSZZFuYyCZXmcKY7fg7PKuAyNJUKeJRAodrYkD0dzNsgbbrghbA79+7nhPhk/fnzYLBXs1atX2J61aosttog2Lr7N0rNHHnkEQOX7jLNi8Xd2f2N505/+9Kew+Zxz6N6Pvz3C6+VkuSxX4wyW7LvLli0L22W5HVkIsmj4OTvhhBOibfPNNw+b5xr36euuu26ltmqHJSf9+vUL27PK7b///tHGfl4uSyT7D0vAPdshABx22GFh/+Y3vwEAPPDAA9FWbdk3WQrGxZm/+93vhu0ySKBxLmEp1Ntvvx02y/t8jevatWu08TzJfexFtqtdEumwX3K/su0+yPMaSyK5yG29SM9YErnNNtuE7dcyPEb5OoSzVbtc8c0334y2vIzG/fv3BwAMGDAg2liGz+sPzwN+bmplzeFMpbwVhNcRl/SxBK9e/LI1cJ/xteKxxx4btmclveyyy6KN+53hOdrXeJb681zz4IMPhu3joDPWobbuYdsopbQMAFJKy8xsw7wXmtmpAE5t4+cIIYQQQgghRN3S4UlHUkqjAYwGADOrjcd8QgghhBBCCFEB2nrD9q6Z9ShF13oAWN6eB9VaOFTqGfGARlkdFyDlzFss/5owYULYzz33HIDGApxAeakPfzZndeQQLEsiWdbiIe9qDP27/Gbs2LHRxtIHxiUVLBvjjHAsRWW5qoerObMUZ2I8++yzw37llVcAZCVElYALt7Ksw4+ZM17Nnh05eypeFN1lGSwb4r7s06dP2OzntSKjag6eP7bbbjsAWYkeZ/ri+cP9/9lnn422au4zPve77rpr2L///e/D9vmV5SRcnHnFihVhu9yX+4QzerFMjceSzyVPPvlktH300UdlP8/n4qL1O0vQdthhh7C52DX3t68f7Evjxo0Lm+U52267LYCsbJdl+iw3e/rpp9v2BQoKn2eWPPL3d7/itZXXhnnz5pV9j6L5UHvCfcFZbX3NZene1KlTw+Ysxp5tj8ciXwuxpO/rX/86gKycnCWR7Ptf/epXw3Y/r8bronLwuGWpKdu9e/cGkJ0D8zJx1jMsAWdpuWfZBBqz4rKkNK8veZuTZzpmX+S1jOflztyu1NY6bOMBDC/ZwwHcv4rXCiGEEEIIIYRoA81G2MzsDjQkGOluZksBXATgcgB3mtkpAN4CcEz+O3Q8fAfNT8O7dOkCIPtElu+OOeEDP2HyyAhvTuYncRw18/fLqxOUtzGx2p6acHTmmmuuAZAfVeP6SldeeSWAxtpKQLZ+BZ8PfqIxefJkAMDee+8dbfykevvttw/bn1r/4Q9/iLaOqttUriYVkK3f4U8S//znP0cbR9sq8fSQ/cuf8vFTTR8bTe1q88v2gCM9HrnlGlcMJ4zxujnV/jTY58w99tgj2m655ZawfSM30DheOYHSqFGjwub+8af3u+++e7RxVIgjm1wrx5UI/ESVo9JFxucHfnrL447nAX8aDAD33nsvgGxEjNccjth5HTGPYgDZKDk/Jc6rJVqt8HrK/cdP1H1e5jWdI2wcISpycq/2hPvn8ccfD9vVKXlJ08r1D49b9m1OBOFJuDgxF8PnoBZqr+XB/cfXoazI8nmO1UQ839Xjmsz4+nT00UdH2/Dhw8Nmf/REVexf3H/sr5yo6aijjgKQjYg+9NBDYXOkuTOTXrUkS+TxOb/aP6ddCCGEEEIIIUQ70FZJpBBCCCGEEEKIDqbDs0RWAg5Ret0ZALjpppsAAAcccEC0sZSO69V4zTagcfPsY489Fm0sVWG5XXvWzioaHB7+yU9+EvZ+++0HICu3mTlzZtnXvvTSSwDK1wUDsv3GEhavz3bttddGGycuYbmUy6y8th2Q3dTbUfD35/p/Ll/i75kXou8o+Nx5X/GmZoaPk+V9tejTDksjDj300LBdFsj9x3559dVXh81Ji6oNlpG41Pjmm2+ONpZBsu9eeOGFALLyYx5r3K9e988TuQDZxAP8dyw/cfuNN96INj4HefNHkWD50/PPPx/2okWLyr7GJVJ59Ze43eWj5ZJfNaXWJJE8P7GMdu7cuWF7YhyWkXKyG147aq1/8uBrFpbj+fYEHrcMy+X9NSxzZCnuaaedFrZvZeDxzv46ZcqUsJ944omwa02iyvMTy8W53ZOOeDIhICs55y049QLPZ1tttRUA4Mwzz4w2TlDnSQKBxuSBPE/wGGffPemkk8L2+YHX9DvuuCNsnms6E0XYhBBCCCGEEKKg6IZNCCGEEEIIIQpKTUgiOdzPmR1vvfVWAMDDDz8cbVxfiGst7bnnniu1s5SHs8Y98sgjYbu8gOUtRZXptBYPRQPAiBEjwnZpBGcy4rponBGyNRKHclJTzmjF0qIhQ4aE7bVeWPZSCUkkn2eWjjic9ZLlOe1ZY4Xfi2UEnPmwX79+AIAePXpEG0tgWG5W7RkPVwX3FddrPP/888P2ek4s35k2bVrY99xzT9jV3FcsVfrZz34GICuD5JqRF1xwQdi33347gKxMh/uVx4HLzLlGIc8Hjz76aNgsfV66dOlKr60WqZSPZ/YNzorL0hoe++V8ifuVx6vLgbj2GL+WM/7lSSWrFe4z7kuWRR100EEAsms2yyA5uybXx+T5upZhn3CZPG8P6du3b9i77bZb2J7FkNdZ3mLC7Zyt23n11VfDZvk112LtzAx8HQGvrb49BGiUQQKN6zJv3WGJONcDrpVry3LwHMb+6DL8zTbbLNq41jFvU/C+4n7ia68jjzwybM5Y7OOAz9GSJUvCLopf1tZsLoQQQgghhBA1hG7YhBBCCCGEEKKg1IQkkmFZnUtDWCLCkknOAsmSyGOPPRZAtpDsRRddFPbJJ58ctmeSueuuu6KtmkP8LL3hbI9cJNrlOy6PArJyxfaQL3m/ceg7LyufZ/7hYrUdBYfaWerERbK7d+8OICsp5SKN7KPNZR9imQDbnsWQZSh8bPx5Q4cOBZA9h/xal6AB1eevrYH946c//WnYLE9xeAxfddVVYfM5rzZ5Sp7kxKXf/H2mT58eNkvKXU7FfckZu4YNGxb2EUccsdJrWWbCMkjOCOnzS7X1bx55smW2y2Ur5EylnIXWJX+c8Yzl6RMnTgyb55pag2W5XETbCzFzAXHuK/dLICtxdil/rfgdkydb9useLxwMZK97WFbqMkf2y7zskj6GOSPl3XffHTZLUWs5CyJLnXmM8nf266UNN9ww2lj+x31Yi77psEz/Bz/4QdgHHngggOx15ejRo8PmDO4O+zhL8s8555yweU7wewS+juVtTkXJJqsImxBCCCGEEEIUlJqLsDUH36XzU3Sv3wA01nS57LLLom3QoEFhe30hoDGSwZtvr7jiirAXL14cdjVEL/hJ7uGHHx42P2Hwzdljx46NNt5c257wE6VtttmmbLsnGOEnUZWAayPNmjUrbH865pu0AWDkyJFhv/LKK2G/9957YXskgp+8c0SHnwj5RmXeTM+RMo56uO/yU6f3338/bK5hxN+pKE+VVgd+Asz+/J3vfCdsfmLsT0Q5Yv7MM8+EXS3JL5qDo14+ljga47UogWySBvcxfi3Pfbyp232TFQ7crzxmaqVffexy0gVOAMTJbjji7WOTzws/cR8wYEDYe+21F4DsZvoHHnggbH6S77RnoqPOJC9RC8/9/sSdzwEn1OE1jmsw+rzMT9ZrBfaVXXbZJWyvbcVjmJPZ5EXQysFzgl8P8PrG61MtJmkrB/cJX//xWuxjk+dcPge8PlXDNWRr4Plu8ODBYZ944olh+zjma+lnn302bJ7bXHHkcySQVcfxNRlHOV988UUAwFNPPRVtrH4qSr8rwiaEEEIIIYQQBUU3bEIIIYQQQghRUOpOEpkHS8F8A7zLBYDsJshDDjkkbA+xHnPMMdHGIX6vIQEUe/Ooh5U5UQZLeTgk7HXoXn/99WjrqO/Tp0+fsLfccsuwOQz+2muvAai8lOWjjz4Ke/LkyWH75lmWzvL34HpoLI1wOy8pSbmN45yIhRM68LG5pIBlZyzLnDlzZtgsEyiKDKAteF/xhuNf/vKXYfMGZ/ZdTzzAr63FTfEsB/eaPywZ9dp9QLYOm8sb2Zd47uRkJi6nYr/02phN/66aYcmSy0C5fhUnuWDp2XrrrRc2y6EclqOxTNrlbXwOeZ7g+cXPF9el5PmFfT/PLio8P3GtqieffBJANsHYPvvsEzZLAnktnzRpEoCsBLqa50CG5fSc0MLloSyZZF8rVxuV29hmf/Ux0bNnz2g7+OCDw+b1khOL1Ro8jngd4fPh6zPLIPnvaiVxkK/JLFXma7ozzjgjbN7S4d+f1wuuWcfJhXbaaScA2S1MvCZxv3KN38svvxwAMH/+/GjjzyvKfKgImxBCCCGEEEIUFN2wCSGEEEIIIURBkSSyDJ59iiUVv/rVr8JmKeC5554LIBvC3XvvvcPmzIZPPPFE2EUJsTaFJZEsceBwvkuoOlKC6PIAlqVyVjWWZN12220dfjzl4JA5h9fdb/r37x9tnM2RYXmAy5fYv1hGy7IVl0Dl1XHzWk1Ao8SFpRUu/2n6GXlyqWrDM+xxrS+WivF34+xTF198MYBsXb1q7geGvwdnErz00ksBZL8zZ8/jDHsudeKxxva6664btvvdyy+/HG1vv/122eOpNngscv947UrOlsnzFs8ZPHZdwszSSJ5/uV99LuY5cNdddw2ba2d5xsR58+ZFG8uoObsvS9P8OIssCczLYuvzKEtxWQLOmeJ69eoVtm9f8DqsQGNG5GqEfZRlYeWy43Ffsd/NmDEjbJ8fuN9Z6u9yNKBRdsnbKlgOzD7K/ljNc0I5+PtwH/s2DqBRosuvrYUMzU3x78TST85+y/VQy8mz2Zd4vmP5o2fh5TmX5zDOAnnJJZeE7ZmyeT4soi8qwiaEEEIIIYQQBUU3bEIIIYQQQghRUCSJXAUcSmW5yOzZs8N2yQSH+DnzH2cDKnKY24+Nw84cEmb5DhfAbE8425pn3Rw2bFi0cfYqlhS4RLPSIWyWD7J/eNZFLgzM8pS84q9utyRbm58v9imWV3JhbH8NF+F2KQyQlWkVWQLVHCy1OOeccwAAW2+9dbRxX7EPu6wZAJ5//nkAtZOZKw8+zy51+vWvfx1tEyZMCJszRrpkj/2LJeDbbrtt2N7fjz76aLRVc4FsHsPsV2eddVbY++67L4Cs7Ozee+8Ne/r06WG/+eabYXvGSM6kx9nPuNizS/5Y1spzI2endekQZ4lcsGBB2Jxdcfz48WH7GsfzWtEkQizdY8mfS/P4eFnuO3Xq1LC5v7fYYgsAwPe///1ou+aaa8KuhmyxPMexvLZ79+5hexZsoFEOzfMBF7tmiZivT3kFyX/4wx+G7bJTPh7OzMvXGbVS1L0c3K88BidOnBj20UcfDSDbDyzFrZU+8es73j7EW4byrjc/+OADAFlZM8vwd95557DZrxy+Xuds77z1xNf7ovd1sxE2M9vYzB4zs3lmNsfMflJqX9/MppjZgtL/6zX3XkIIIYQQQgghWk5LJJGfADgzpdQPwEAAI8xsawAjAUxNKfUFMLX0sxBCCCGEEEKIdqJZSWRKaRmAZSX772Y2D0BPAIcD2Lf0srEAHgdwbpm3qApYUuJSi3XWWSfaPOscAHzve98L26UqeRnYOANdkcOtHo5nWSIfL/eFf2d+bWukdBz652w+xx9/fNierY/lpSzpGzFiRNgu2+nM/i0nc2S5Y3vLacp9Vz4HLMX1DHPlstIB1S3/43HL0ohvf/vbALIyNpeSAcDYsWPDZpman6cij9X2xr8ry984OxwXVve5kcc+Z9/kdpfasvSvGiW3Pl/xXHTggQeGzRnLPAsmFwh/5JFHwuY+ZmkQS8scnu/4fHhh6LfeeivaWG62++67r3RsnA2RM8hy8W0eK/7ZnF2yaGOC15GBAweG7Rk6eb6bNm1a2FwYmzPk+vqz//77R9u4cePC5rW8qPA55AyOnKGRJcouieW+4nWr3HhlWTNnfeXrHj8OPkc8V/NYaut1RLXB/cayZG/nfmf5ZNHGXVvx6wz2NV4b7rnnnrB5y4bLH3mu8syaAPC1r30tbPc39kveVsNy4Gr0tVbtYTOzzQDsAOA5ABuVbuaQUlpmZhvm/M2pAE5dvcMUQgghhBBCiPqjxTdsZvZ5AH8C8NOU0octTaCRUhoNYHTpPSr6qKBc1IifQHHUiDcreg0RfnI6fPjwsLmOiz9x5jt33qjMT1KKfEfvT3EWLlwYbRx54SdiHr146aWXoo2f9parJ8J1hDgxgUfSAGCvvfYK2zc281Pm888/P2xPDgEUu18rCfc7+6j7Pz9NrpU6Y7yx/kc/+lHYPp7ZhxctWhT25MmTw+anme5LtbwRviXkjSnvT55HOTEB4/3GT1SruS95HeEkF9zu6wA/Oc7bZM+12jxKyU/ZeY676aabwvZxzMmC2F+99hrQqAzhxDAcifa6RUA2IuPHOX/+/Ggr2jzLfcXRc+9vTtRSLlEYAEyZMiXsLbfcEkB2HWLVByflyfP5zoYVKxx54Osbfo1HxfKu58q1s7/7tRIADB48OGxOAOXwWs4Kj3qB5z7uQ1/DOPpeVP9aHXz+4EgZR7AZXrfXX399AMDmm28ebUOGDAmbfc3XmrPPPjvaqj2qxrQorb+ZrYWGm7XbU0oet3zXzHqUft8DwPK8vxdCCCGEEEII0XpakiXSANwMYF5K6Wr61XgAHnYaDuD+9j88IYQQQgghhKhfWiKJHATgBACzzMx3n58H4HIAd5rZKQDeAnBMxxxi83DYnqU6Xbt2BZCtmcObk1max3XUfIM2y8pYPslSjLlz5wIArrzyymjjTb1cL6LIeKj4ueeeizau0dOzZ8+wfcP99ddfH20c2mbp3SabbAIA2G233Vb6eyArW+FNyS7VOOOMM6Lt/vsbnwnwORANsI+yvMllu5z4hCUZ1QaPd6+5BGSlXu5LvNGbk2fwBnmWU1VLPZbOhseqj3Eg61c+RvPGeLUku3Ff4ONlGS23u1TSZeNAVrLDyUVYpvbOO+8AAH77299G26RJk8JmiVRzvslSSZdZsUST35clmi49AholhEWWEHG/+zoMNNZt8rpqQFau9+qrr4bNMjSvhcf9sMMOO4TN7X6+ijJP+LjiBECHHXZY2OxrvE7cfffdAIAlS5ZEG0sXGfdjvobiBGw8F/s8wNc/nHynXA2seoKvU30947WqKH7VEfD59rHaFJ4z/fqda6jx9SRfC3oyMa4pWeQ5rLW0JEvkUwDyNqztn9MuhBBCCCGEEGI1adEeNiGEEEIIIYQQladVaf2LRJ78a5999gl7u+22A5Ct2cBZsTjDHMusPJzPYWmWmTz77LNhe5ZDzpjI0rNqC2271AMARo0aFfZ5550XtoerDzjggGgbNGhQ2Pz9PfTPWSJdogdkw9WzZs0K++STTwaQze7FkgGxMiw3Y4mv+yD7Ir+22mA5CcvtWEbh35XljhMmTAibJZHN1R0Sq4ZrfDE+p/L54rFfbVIoliU+9dRTYffr1y/svn37Asj6JddEZLn4Qw89FPaYMWMAAK+99lq08ZrT1nXE/47nTs4Qy5JAnqNdqlTk8cDHxpLIW265BQBwwQUXRBtnM+SMzyxtdXkoy3p5LStyXzicfZHneL7u4cyXLmN8+eWXo439gPH+Yakp+zZ/nvsbj5Mbb7wxbN5uUQ392t6Uk4nnjctag+eyvGsS3oJz1llnAchmbefrdc70esUVVwDIzp21RPVetQkhhBBCCCFEjaMbNiGEEEIIIYQoKFUnifRQKBd/5ExF5TIQslSK5TkcjmW5i8tWXnnllWi7/fbbw+bCpO+//z6A2slayBKQG264IWzPoAUAJ5100kptLC9l22FJDhcyvOeee8Lmz/NC3NUmm+pM2LfLyQO5jTOeLV26NOxq628uSsy4v82ZMyfaeDyzdKgeJTmrC0tSWH5Sbh7kLJIsiWwPyV8l4bHxwgsvhM0ycs9oxpInlu+z7Hv69OlhuzSvEv3A/s5FzXlMVNsLj3ibAAAKOUlEQVQ8wOu3r9Xsa2eeeWbYedsiHO6TxYsXh92lS5ew3f+L5rd8Dn0NBbKZsnnO9Gx7LDdjWKbmNo99/v7l5OcXXnhhtHGm0lq5XmoN3G987eR9yPNBPW7/4PG6/fbbh927d28AWV/ktXzkyJFh+7V70cZle6EImxBCCCGEEEIUFN2wCSGEEEIIIURBqTpJpIc6uSAjyyFYFuYh+hUrVkTbsmXLwl60aFHYDzzwQNguo+JikizfqRcJFRfQ/MUvfhH25MmTAQAnnnhitHEBVi7S6f3N0sf77rsvbJbj1aNMoj1hyQVnnHLf5bHBkgzOilYNUiiWO/AY5YK4Xbt2BZAtoMnStXoZwx0Fy1NY6lQuOxf72tprrx02z+HV4HfsM5zFbcGCBWFzQWCH/ZXfo7O+c16WtloZE57h8rrrrou22267LeyhQ4eGvffee4ftaxVfF3CW4vfeey/sokmu/Nxx9lvPYM2/B7Lf2ddqXht4PeDv6eszX29xVtPf/e53YXvmPr7eqoYx3pHw+swFzn0byttvvx1t9XgtxP3DW3P8OpQz7I4YMSLseirCrgibEEIIIYQQQhSUqouwOfyEk+t7cJIBf6LOURyuu8J2NddO6yi4H7ivHn30UQDAY489ttrvK9oPjm7wk1Z/MsXjgKPO1XY+eEM211abOnVq2B4B4ihOPT61rARcU4nPjT+p79+/f7SVe7Lc1C4X6Smyj/JT3Vp/wltNsM9wdOzWW28ta9cCPMfxtdA3v/nNsLl2mid02GOPPVZqA7KJRGbMmAEAWLhwYbRxAjGOvNVKtLY94QgSqxIef/xxAMCkSZOircjzXUfB1y98bem+y9c0RY52dySKsAkhhBBCCCFEQdENmxBCCCGEEEIUlKqVRHLInWulsC06lnoKRVcDXIPHE8MAjbIWTsrByTqqWSrIEjT+/qJjYfkKz7kskerVqxeAbBIibwMak0MAWYm7y1h5jmdb844QrYPnSR53LnP0/0XHwedg4sSJYftaXc3rcHvA8zqvByztrXcUYRNCCCGEEEKIgqIbNiGEEEIIIYQoKFZJeYmZScsiRAVYc81GtbNnTFQ2O9ERcA2nPn36hL3jjjsCyEqwuGYZ1wrkLJHum8o0J4QQooZ5MaW0c0tfrAibEEIIIYQQQhQU3bAJIYQQQgghREFpVhJpZusCmAZgHTRklbw7pXSRmfUGMA7A+gBeAnBCSuk/+e8kSaQQQtQLXCi2OZT5UQghRJ3R7pLIjwEMTin1BzAAwBAzGwjgCgDXpJT6AlgB4JS2HK0QQgghhBBCiPI0e8OWGvhH6ce1Sv8SgMEA7i61jwVwRIccoRBCiKojpdTif0IIIYTIp0V72MxsDTObCWA5gCkAFgH4IKXklf6WAujZMYcohBBCCCGEEPVJi27YUkqfppQGAOgFYFcA/cq9rNzfmtmpZjbdzKa3/TCFEEIIIYQQov5oVZbIlNIHAB4HMBBANzPzYk+9ALyT8zejU0o7t2ZjnRBCCCGEEEKIFtywmdkGZtatZHcBcACAeQAeA3B06WXDAdzfUQcphBBCCCGEEPXIms2/BD0AjDWzNdBwg3dnSulBM5sLYJyZXQpgBoCbO/A4hRBCCCGEEKLuaLYOW7t+mNlfAPwTwF8r9qGimukO+YpoHvmJaCnyFdFS5CuiJchPREtp6iubppQ2aOkfV/SGDQDMbLr2s4mWIF8RLUF+IlqKfEW0FPmKaAnyE9FSVtdXWpV0RAghhBBCCCFE5dANmxBCCCGEEEIUlM64YRvdCZ8pqhP5imgJ8hPRUuQroqXIV0RLkJ+IlrJavlLxPWxCCCGEEEIIIVqGJJFCCCGEEEIIUVAqesNmZkPMbL6ZLTSzkZX8bFFszGyxmc0ys5lmNr3Utr6ZTTGzBaX/1+vs4xSVx8zGmNlyM5tNbWV9wxq4rjTHvGJmO3bekYtKk+MrF5vZ26W5ZaaZDaXf/Z+Sr8w3s691zlGLSmNmG5vZY2Y2z8zmmNlPSu2aV0SwCj/RnCIymNm6Zva8mb1c8pVLSu29zey50pzyRzNbu9S+TunnhaXfb9bcZ1Tshq1UePu3AA4GsDWA481s60p9vqgK9kspDaC0pyMBTE0p9QUwtfSzqD9uATCkSVuebxwMoG/p36kARlXoGEUxuAUr+woAXFOaWwaklCYAQGn9OQ7ANqW/+b+ldUrUPp8AODOl1A/AQAAjSv6geUUweX4CaE4RWT4GMDil1B/AAABDzGwggCvQ4Ct9AawAcErp9acAWJFS+iqAa0qvWyWVjLDtCmBhSun1lNJ/AIwDcHgFP19UH4cDGFuyxwI4ohOPRXQSKaVpAN5v0pznG4cD+H+pgWcBdDOzHpU5UtHZ5PhKHocDGJdS+jil9AaAhWhYp0SNk1JallJ6qWT/HcA8AD2heUUQq/CTPDSn1CmlueEfpR/XKv1LAAYDuLvU3nRO8bnmbgD7m5mt6jMqecPWE8AS+nkpVu34or5IACab2YtmdmqpbaOU0jKgYeIEsGGnHZ0oGnm+oXlGlOP0kpRtDEmr5SsCJSnSDgCeg+YVkUMTPwE0p4gmmNkaZjYTwHIAUwAsAvBBSumT0kvYH8JXSr//G4Avrer9K3nDVu7OUSkqhTMopbQjGqQnI8xs784+IFGVaJ4RTRkFYHM0yFSWAfhVqV2+UueY2ecB/AnAT1NKH67qpWXa5Ct1Qhk/0ZwiViKl9GlKaQCAXmiIrPYr97LS/632lUresC0FsDH93AvAOxX8fFFgUkrvlP5fDuBeNDj7uy47Kf2/vPOOUBSMPN/QPCMypJTeLS2k/wNwIxolSvKVOsbM1kLDRfjtKaV7Ss2aV0SGcn6iOUWsipTSBwAeR8O+x25mtmbpV+wP4Sul33dFM3L+St6wvQCgbyljytpo2Jg5voKfLwqKmX3OzL7gNoCDAMxGg38ML71sOID7O+cIRQHJ843xAL5Tyuo2EMDfXOIk6pMme42ORMPcAjT4ynGlbF290ZBQ4vlKH5+oPKW9IjcDmJdSupp+pXlFBHl+ojlFNMXMNjCzbiW7C4AD0LDn8TEAR5de1nRO8bnmaACPpmYKY6+5ql+2JymlT8zsdACTAKwBYExKaU6lPl8Umo0A3Fvab7kmgD+klCaa2QsA7jSzUwC8BeCYTjxG0UmY2R0A9gXQ3cyWArgIwOUo7xsTAAxFw2bvjwCcVPEDFp1Gjq/sa2YD0CA3WQzg+wCQUppjZncCmIuGbHAjUkqfdsZxi4ozCMAJAGaV9pwAwHnQvCKy5PnJ8ZpTRBN6ABhbygr6GQB3ppQeNLO5AMaZ2aUAZqDhAQBK/99qZgvREFk7rrkPsGZu6IQQQgghhBBCdBIVLZwthBBCCCGEEKLl6IZNCCGEEEIIIQqKbtiEEEIIIYQQoqDohk0IIYQQQgghCopu2IQQQgghhBCioOiGTQghhBBCCCEKim7YhBBCCCGEEKKg6IZNCCGEEEIIIQrK/wdBsS91DMr5LgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "train_loader_iter = iter(train_loader)\n",
    "first_images, first_labels = next(train_loader_iter)\n",
    "\n",
    "show_batch(first_images)\n",
    "\n",
    "recs, _, _ = initial_vae(first_images.to(device))\n",
    "show_batch(recs.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VFAEEClassifier(nn.Module):\n",
    "    def __init__(self, beta, initial_VAE):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vae = initial_vae\n",
    "        \n",
    "        self.classifier_part = self.encoder = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(16, 14, kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(14),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(14, 12, kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(12),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(12, 10, kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(10),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(10 * 1 * 1, 10)\n",
    "        # no_of_last_channels* kernel_H * kernel_W, output_from_fully_conncected \n",
    "    def forward(self, x):\n",
    "        #with torch.no_grad():\n",
    "        vaee_features, _, _ = self.vae.get_latent(x)\n",
    "\n",
    "        vaee_features = vaee_features.reshape(-1, 16, 7, 7)\n",
    "        convolved = self.classifier_part(vaee_features)\n",
    "\n",
    "        classification_logits = self.fc(convolved.view(convolved.size(0), -1))\n",
    "        \n",
    "        return  classification_logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(model, train_data):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    learning_rate = 0.01\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    n_epochs = 10\n",
    "    model.train()\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch %2 == 0:\n",
    "            learning_rate /= 2.5\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        for batch in train_data:\n",
    "            batch_images, batch_labels = batch\n",
    "            \n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            batch_output = model(batch_images)\n",
    "            loss = criterion(batch_output, batch_labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            model.vae = initial_classifier.vae\n",
    "        print(\"the loss after processing this epoch is: \", loss.item())\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss after processing this epoch is:  0.08678028732538223\n",
      "the loss after processing this epoch is:  0.0888054370880127\n",
      "the loss after processing this epoch is:  0.09813786298036575\n",
      "the loss after processing this epoch is:  0.09488239139318466\n",
      "the loss after processing this epoch is:  0.09651147574186325\n",
      "the loss after processing this epoch is:  0.09096448868513107\n",
      "the loss after processing this epoch is:  0.09139630943536758\n",
      "the loss after processing this epoch is:  0.08351952582597733\n",
      "the loss after processing this epoch is:  0.08495485037565231\n",
      "the loss after processing this epoch is:  0.07761388272047043\n"
     ]
    }
   ],
   "source": [
    "b=1\n",
    "\n",
    "initial_classifier = VFAEEClassifier(beta=b, initial_VAE=initial_vae).to(device)\n",
    "model =  VFAEEClassifier(beta=b, initial_VAE=initial_vae).to(device)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "model = train_classifier(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9923\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "testing_accuracy_before_attack = test_model(model, test_loader)\n",
    "print(testing_accuracy_before_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM Attack : \n",
      "0.38766666666666666\n",
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
      "Projected Gradient Attack : \n",
      "0.16535\n",
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
      "iFGSM Attack : \n",
      "8.333333333333333e-05\n",
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
      "Deep Fool Attack : \n",
      "0.11103333333333333\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=512)\n",
    "print(attack(model, device, train_loader, fgsm, 0.3)[0])\n",
    "print(\"=*\" * 20)\n",
    "\n",
    "print(attack(model, device, train_loader, pgd, 0.3, 1e4, 40)[0])\n",
    "print(\"=*\" * 20)\n",
    "\n",
    "print(attack(model, device, train_loader, pgd_linf, 0.3, 1e-2, 40)[0])\n",
    "print(\"=*\" * 20)\n",
    "\n",
    "print(attack(model, device, train_loader, pgd_l2, 1, 0.3, 40)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_examples(model): \n",
    "    training_examples = []\n",
    "\n",
    "    examples = get_examples(model, device, train_loader, fgsm, 0.3)\n",
    "    training_examples.append(examples)\n",
    "\n",
    "    examples = get_examples(model, device, train_loader, pgd, 0.3, 1e4, 40)\n",
    "    training_examples.append(examples)\n",
    "\n",
    "    examples = get_examples(model, device, train_loader, pgd_linf, 0.3, 1e-2, 40)\n",
    "    training_examples.append(examples)\n",
    "    \n",
    "    examples = get_examples(model, device, train_loader, pgd_l2, 1.3, 0.3, 40)\n",
    "\n",
    "    return training_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_adv(model, train_data):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    learning_rate = 0.01\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    n_epochs = 10\n",
    "    model.train()\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch %2 == 0:\n",
    "            learning_rate /= 2.5\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        for train in train_data:\n",
    "            for batch in train:\n",
    "                batch_images, adv_images, batch_labels = batch\n",
    "\n",
    "                batch_images = batch_images.to(device)\n",
    "                batch_labels = batch_labels.to(device)\n",
    "                adv_images = adv_images.to(device)\n",
    "\n",
    "                batch_output = model(batch_images)\n",
    "                loss = criterion(batch_output, batch_labels)\n",
    "                \n",
    "                adv_output = model(adv_images)\n",
    "                \n",
    "                loss += criterion(adv_output, batch_labels )\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "                model.vae = initial_classifier.vae\n",
    "        print(\"the loss after processing this epoch is: \", loss.item())\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: Using a target size (torch.Size([256, 784])) that is different to the input size (torch.Size([256, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  219106.46875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  185740.765625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  138281.6875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  109401.296875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  95115.3828125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  86211.140625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  75018.234375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  73858.8984375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  69975.4375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  66597.015625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  65338.60546875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  62383.15234375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  57411.65234375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  57290.64453125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  59798.17578125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  55134.98828125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  54670.0078125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  54697.55859375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  58032.49609375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  53427.2265625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  54261.13671875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  53554.8046875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  51088.26171875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  53702.4609375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  50970.67578125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  49730.09375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  46570.06640625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  48126.58203125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  45914.2734375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  46782.0546875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  49813.95703125\n",
      "The representation loss after processing this batch is:  0.007843127474188805\n",
      "The classification loss after processing this batch is:  48309.828125\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  46958.82421875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  49994.66015625\n",
      "The representation loss after processing this batch is:  0.00784314051270485\n",
      "The classification loss after processing this batch is:  46451.98046875\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  46474.36328125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  46929.37109375\n",
      "The representation loss after processing this batch is:  0.007843131199479103\n",
      "The classification loss after processing this batch is:  48831.3359375\n",
      "The representation loss after processing this batch is:  0.00784314051270485\n",
      "The classification loss after processing this batch is:  46820.0390625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  46400.3125\n",
      "The representation loss after processing this batch is:  0.007843139581382275\n",
      "The classification loss after processing this batch is:  49473.0078125\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  45218.5390625\n",
      "The representation loss after processing this batch is:  0.007843157276511192\n",
      "The classification loss after processing this batch is:  44622.82421875\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  44783.609375\n",
      "The representation loss after processing this batch is:  0.007843158207833767\n",
      "The classification loss after processing this batch is:  43302.21484375\n",
      "The representation loss after processing this batch is:  0.00784315075725317\n",
      "The classification loss after processing this batch is:  43753.25390625\n",
      "The representation loss after processing this batch is:  0.007843109779059887\n",
      "The classification loss after processing this batch is:  43590.1015625\n",
      "The representation loss after processing this batch is:  0.007843314670026302\n",
      "The classification loss after processing this batch is:  45367.15234375\n",
      "The representation loss after processing this batch is:  0.00784303992986679\n",
      "The classification loss after processing this batch is:  47020.66796875\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  47195.01171875\n",
      "The representation loss after processing this batch is:  0.007843276485800743\n",
      "The classification loss after processing this batch is:  45313.55078125\n",
      "The representation loss after processing this batch is:  0.007843123748898506\n",
      "The classification loss after processing this batch is:  47253.28515625\n",
      "The representation loss after processing this batch is:  0.007843132130801678\n",
      "The classification loss after processing this batch is:  45579.1015625\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  44540.08203125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  45614.59765625\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  48979.52734375\n",
      "The representation loss after processing this batch is:  0.007843130268156528\n",
      "The classification loss after processing this batch is:  44015.1875\n",
      "The representation loss after processing this batch is:  0.007843109779059887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  50711.10546875\n",
      "The representation loss after processing this batch is:  0.007843108847737312\n",
      "The classification loss after processing this batch is:  42550.16796875\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  43299.93359375\n",
      "The representation loss after processing this batch is:  0.007843167521059513\n",
      "The classification loss after processing this batch is:  42610.265625\n",
      "The representation loss after processing this batch is:  0.00784322526305914\n",
      "The classification loss after processing this batch is:  45770.05859375\n",
      "The representation loss after processing this batch is:  0.00784333236515522\n",
      "The classification loss after processing this batch is:  43584.8984375\n",
      "The representation loss after processing this batch is:  0.007843157276511192\n",
      "The classification loss after processing this batch is:  43195.9140625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  42396.21484375\n",
      "The representation loss after processing this batch is:  0.007843151688575745\n",
      "The classification loss after processing this batch is:  43812.09375\n",
      "The representation loss after processing this batch is:  0.007843196392059326\n",
      "The classification loss after processing this batch is:  43068.1953125\n",
      "The representation loss after processing this batch is:  0.007843131199479103\n",
      "The classification loss after processing this batch is:  46299.234375\n",
      "The representation loss after processing this batch is:  0.007843158207833767\n",
      "The classification loss after processing this batch is:  44806.0078125\n",
      "The representation loss after processing this batch is:  0.007843232713639736\n",
      "The classification loss after processing this batch is:  41795.81640625\n",
      "The representation loss after processing this batch is:  0.00784312654286623\n",
      "The classification loss after processing this batch is:  41840.984375\n",
      "The representation loss after processing this batch is:  0.007843175902962685\n",
      "The classification loss after processing this batch is:  41420.0234375\n",
      "The representation loss after processing this batch is:  0.007843129336833954\n",
      "The classification loss after processing this batch is:  44155.09765625\n",
      "The representation loss after processing this batch is:  0.007843153551220894\n",
      "The classification loss after processing this batch is:  42495.53125\n",
      "The representation loss after processing this batch is:  0.007843139581382275\n",
      "The classification loss after processing this batch is:  42394.25\n",
      "The representation loss after processing this batch is:  0.007843182422220707\n",
      "The classification loss after processing this batch is:  45626.79296875\n",
      "The representation loss after processing this batch is:  0.007843048311769962\n",
      "The classification loss after processing this batch is:  43614.4921875\n",
      "The representation loss after processing this batch is:  0.00784316472709179\n",
      "The classification loss after processing this batch is:  46693.9296875\n",
      "The representation loss after processing this batch is:  0.007843179628252983\n",
      "The classification loss after processing this batch is:  46139.3046875\n",
      "The representation loss after processing this batch is:  0.007843133062124252\n",
      "The classification loss after processing this batch is:  42978.75390625\n",
      "The representation loss after processing this batch is:  0.007843186147511005\n",
      "The classification loss after processing this batch is:  43580.546875\n",
      "The representation loss after processing this batch is:  0.007843188010156155\n",
      "The classification loss after processing this batch is:  43634.87890625\n",
      "The representation loss after processing this batch is:  0.007843186147511005\n",
      "The classification loss after processing this batch is:  41709.53515625\n",
      "The representation loss after processing this batch is:  0.007843347266316414\n",
      "The classification loss after processing this batch is:  44663.515625\n",
      "The representation loss after processing this batch is:  0.007843170315027237\n",
      "The classification loss after processing this batch is:  40813.21875\n",
      "The representation loss after processing this batch is:  0.00784314889460802\n",
      "The classification loss after processing this batch is:  45137.05078125\n",
      "The representation loss after processing this batch is:  0.007843145169317722\n",
      "The classification loss after processing this batch is:  46191.94921875\n",
      "The representation loss after processing this batch is:  0.007843153551220894\n",
      "The classification loss after processing this batch is:  43189.6640625\n",
      "The representation loss after processing this batch is:  0.007843144237995148\n",
      "The classification loss after processing this batch is:  45660.625\n",
      "The representation loss after processing this batch is:  0.007843139581382275\n",
      "The classification loss after processing this batch is:  44735.53515625\n",
      "The representation loss after processing this batch is:  0.007843163795769215\n",
      "The classification loss after processing this batch is:  43008.59765625\n",
      "The representation loss after processing this batch is:  0.007843119092285633\n",
      "The classification loss after processing this batch is:  42850.12109375\n",
      "The representation loss after processing this batch is:  0.007843139581382275\n",
      "The classification loss after processing this batch is:  43795.98046875\n",
      "The representation loss after processing this batch is:  0.007843175902962685\n",
      "The classification loss after processing this batch is:  42537.08984375\n",
      "The representation loss after processing this batch is:  0.007843149825930595\n",
      "The classification loss after processing this batch is:  40117.43359375\n",
      "The representation loss after processing this batch is:  0.007843139581382275\n",
      "The classification loss after processing this batch is:  41806.0703125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  41802.6796875\n",
      "The representation loss after processing this batch is:  0.007843144237995148\n",
      "The classification loss after processing this batch is:  38677.22265625\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  43726.171875\n",
      "The representation loss after processing this batch is:  0.00784314051270485\n",
      "The classification loss after processing this batch is:  41828.7109375\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  40446.48828125\n",
      "The representation loss after processing this batch is:  0.007843110710382462\n",
      "The classification loss after processing this batch is:  40411.8984375\n",
      "The representation loss after processing this batch is:  0.007843155413866043\n",
      "The classification loss after processing this batch is:  39423.50390625\n",
      "The representation loss after processing this batch is:  0.007843129336833954\n",
      "The classification loss after processing this batch is:  40364.03515625\n",
      "The representation loss after processing this batch is:  0.007843139581382275\n",
      "The classification loss after processing this batch is:  40649.18359375\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  41218.15234375\n",
      "The representation loss after processing this batch is:  0.007843133993446827\n",
      "The classification loss after processing this batch is:  45190.96875\n",
      "The representation loss after processing this batch is:  0.00784314051270485\n",
      "The classification loss after processing this batch is:  40790.13671875\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  41444.9375\n",
      "The representation loss after processing this batch is:  0.007843141444027424\n",
      "The classification loss after processing this batch is:  39662.55078125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  41651.2890625\n",
      "The representation loss after processing this batch is:  0.007843141444027424\n",
      "The classification loss after processing this batch is:  40870.9140625\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  43007.0\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  43612.98828125\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  40983.109375\n",
      "The representation loss after processing this batch is:  0.007843139581382275\n",
      "The classification loss after processing this batch is:  39350.2421875\n",
      "The representation loss after processing this batch is:  0.007843166589736938\n",
      "The classification loss after processing this batch is:  39824.578125\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  41327.66015625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  41977.3046875\n",
      "The representation loss after processing this batch is:  0.007843143306672573\n",
      "The classification loss after processing this batch is:  39644.21484375\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  39040.72265625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  40049.109375\n",
      "The representation loss after processing this batch is:  0.007843133993446827\n",
      "The classification loss after processing this batch is:  38992.5078125\n",
      "The representation loss after processing this batch is:  0.007843146100640297\n",
      "The classification loss after processing this batch is:  39757.7890625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  40992.734375\n",
      "The representation loss after processing this batch is:  0.007843143306672573\n",
      "The classification loss after processing this batch is:  40089.109375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  41034.16015625\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  40195.59765625\n",
      "The representation loss after processing this batch is:  0.007843122817575932\n",
      "The classification loss after processing this batch is:  40401.85546875\n",
      "The representation loss after processing this batch is:  0.007843145169317722\n",
      "The classification loss after processing this batch is:  39789.16796875\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  39047.5234375\n",
      "The representation loss after processing this batch is:  0.007843147963285446\n",
      "The classification loss after processing this batch is:  37942.984375\n",
      "The representation loss after processing this batch is:  0.00784314051270485\n",
      "The classification loss after processing this batch is:  37013.66796875\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  37799.66796875\n",
      "The representation loss after processing this batch is:  0.007843242026865482\n",
      "The classification loss after processing this batch is:  40478.26953125\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  39414.78125\n",
      "The representation loss after processing this batch is:  0.007843154482543468\n",
      "The classification loss after processing this batch is:  38866.421875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  39438.171875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  39195.3671875\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  38507.8125\n",
      "The representation loss after processing this batch is:  0.007843145169317722\n",
      "The classification loss after processing this batch is:  39443.91796875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  42809.21875\n",
      "The representation loss after processing this batch is:  0.007843084633350372\n",
      "The classification loss after processing this batch is:  39134.5546875\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  39834.40625\n",
      "The representation loss after processing this batch is:  0.007843131199479103\n",
      "The classification loss after processing this batch is:  38378.2421875\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  38853.2578125\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  40209.36328125\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  39672.16796875\n",
      "The representation loss after processing this batch is:  0.007843142375349998\n",
      "The classification loss after processing this batch is:  37489.30078125\n",
      "The representation loss after processing this batch is:  0.007843133062124252\n",
      "The classification loss after processing this batch is:  37920.484375\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  37730.7109375\n",
      "The representation loss after processing this batch is:  0.007843139581382275\n",
      "The classification loss after processing this batch is:  37451.86328125\n",
      "The representation loss after processing this batch is:  0.007843146100640297\n",
      "The classification loss after processing this batch is:  36967.9375\n",
      "The representation loss after processing this batch is:  0.007843125611543655\n",
      "The classification loss after processing this batch is:  37568.2265625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  36465.1015625\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  39170.3515625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  37062.73046875\n",
      "The representation loss after processing this batch is:  0.00784310046583414\n",
      "The classification loss after processing this batch is:  38145.140625\n",
      "The representation loss after processing this batch is:  0.007850416004657745\n",
      "The classification loss after processing this batch is:  38926.27734375\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  37558.73046875\n",
      "The representation loss after processing this batch is:  0.00784314051270485\n",
      "The classification loss after processing this batch is:  39940.421875\n",
      "The representation loss after processing this batch is:  0.007843133993446827\n",
      "The classification loss after processing this batch is:  43463.0234375\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  38653.328125\n",
      "The representation loss after processing this batch is:  0.00784312468022108\n",
      "The classification loss after processing this batch is:  38579.703125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  39264.49609375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  41857.37109375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  41802.11328125\n",
      "The representation loss after processing this batch is:  0.007843123748898506\n",
      "The classification loss after processing this batch is:  39593.18359375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  38623.18359375\n",
      "The representation loss after processing this batch is:  0.007843215949833393\n",
      "The classification loss after processing this batch is:  38208.06640625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  38007.92578125\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  37732.48828125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  41126.359375\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  38619.1640625\n",
      "The representation loss after processing this batch is:  0.007843139581382275\n",
      "The classification loss after processing this batch is:  38593.3046875\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  38573.26171875\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  40723.296875\n",
      "The representation loss after processing this batch is:  0.007843133993446827\n",
      "The classification loss after processing this batch is:  38883.37109375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  38214.3125\n",
      "The representation loss after processing this batch is:  0.007843139581382275\n",
      "The classification loss after processing this batch is:  38944.0859375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  37638.640625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  38279.43359375\n",
      "The representation loss after processing this batch is:  0.007843133062124252\n",
      "The classification loss after processing this batch is:  40027.9140625\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  37542.796875\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  36709.6484375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  40069.28515625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  37835.05078125\n",
      "The representation loss after processing this batch is:  0.00784306786954403\n",
      "The classification loss after processing this batch is:  36819.40625\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  37916.91796875\n",
      "The representation loss after processing this batch is:  0.00784312840551138\n",
      "The classification loss after processing this batch is:  37771.49609375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  37394.6796875\n",
      "The representation loss after processing this batch is:  0.007843129336833954\n",
      "The classification loss after processing this batch is:  39088.7265625\n",
      "The representation loss after processing this batch is:  0.007843115366995335\n",
      "The classification loss after processing this batch is:  37832.70703125\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  39678.30859375\n",
      "The representation loss after processing this batch is:  0.007843132130801678\n",
      "The classification loss after processing this batch is:  37372.12890625\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  36351.453125\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  37019.1484375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  37465.5\n",
      "The representation loss after processing this batch is:  0.007843145169317722\n",
      "The classification loss after processing this batch is:  36509.29296875\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  35776.98828125\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  36580.4609375\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  37574.5703125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  36825.9375\n",
      "The representation loss after processing this batch is:  0.00784314051270485\n",
      "The classification loss after processing this batch is:  37369.4921875\n",
      "The representation loss after processing this batch is:  0.007843156345188618\n",
      "The classification loss after processing this batch is:  34438.90625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34843.2734375\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  36592.89453125\n",
      "The representation loss after processing this batch is:  0.007843131199479103\n",
      "The classification loss after processing this batch is:  37416.63671875\n",
      "The representation loss after processing this batch is:  0.007843153551220894\n",
      "The classification loss after processing this batch is:  34722.171875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  35944.9375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  36435.890625\n",
      "The representation loss after processing this batch is:  0.007843143306672573\n",
      "The classification loss after processing this batch is:  35554.109375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  36384.10546875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  35129.02734375\n",
      "The representation loss after processing this batch is:  0.007843133062124252\n",
      "The classification loss after processing this batch is:  36711.48046875\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  34573.12890625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34146.41796875\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  36352.70703125\n",
      "The representation loss after processing this batch is:  0.00784312468022108\n",
      "The classification loss after processing this batch is:  34885.90625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  35031.5625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  35772.88671875\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  37099.0\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  33662.44921875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  35937.6328125\n",
      "The representation loss after processing this batch is:  0.00784314051270485\n",
      "The classification loss after processing this batch is:  37179.03515625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  34212.19140625\n",
      "The representation loss after processing this batch is:  0.00784317683428526\n",
      "The classification loss after processing this batch is:  35265.95703125\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  37588.25390625\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  35100.453125\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  35115.83984375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34705.3671875\n",
      "The representation loss after processing this batch is:  0.007843133062124252\n",
      "The classification loss after processing this batch is:  38456.703125\n",
      "The representation loss after processing this batch is:  0.007843139581382275\n",
      "The classification loss after processing this batch is:  36912.9921875\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  36523.015625\n",
      "The representation loss after processing this batch is:  0.007843144237995148\n",
      "The classification loss after processing this batch is:  17584.154296875\n",
      "The representation loss after processing this batch is:  0.002941176760941744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: Using a target size (torch.Size([96, 784])) that is different to the input size (torch.Size([96, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  36327.921875\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  35469.5234375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  35772.94921875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34589.6640625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  36153.76953125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  36818.1875\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  34921.58984375\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  35722.69921875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  37210.2109375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  35036.42578125\n",
      "The representation loss after processing this batch is:  0.007843139581382275\n",
      "The classification loss after processing this batch is:  36394.5859375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  36009.66015625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  33951.25390625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34378.14453125\n",
      "The representation loss after processing this batch is:  0.007843142375349998\n",
      "The classification loss after processing this batch is:  38291.84765625\n",
      "The representation loss after processing this batch is:  0.007843133062124252\n",
      "The classification loss after processing this batch is:  34540.015625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  34122.45703125\n",
      "The representation loss after processing this batch is:  0.00784312654286623\n",
      "The classification loss after processing this batch is:  34627.98046875\n",
      "The representation loss after processing this batch is:  0.007843184284865856\n",
      "The classification loss after processing this batch is:  40196.4375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34629.32421875\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  35855.3671875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  35606.35546875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  36270.46484375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34549.41796875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34695.19921875\n",
      "The representation loss after processing this batch is:  0.00784316100180149\n",
      "The classification loss after processing this batch is:  33605.234375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34026.32421875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34122.16796875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  35297.5859375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  33997.578125\n",
      "The representation loss after processing this batch is:  0.007843141444027424\n",
      "The classification loss after processing this batch is:  37586.0234375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34956.93359375\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  34349.390625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  36178.62109375\n",
      "The representation loss after processing this batch is:  0.007843133062124252\n",
      "The classification loss after processing this batch is:  34558.35546875\n",
      "The representation loss after processing this batch is:  0.007843139581382275\n",
      "The classification loss after processing this batch is:  36716.90234375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  36591.265625\n",
      "The representation loss after processing this batch is:  0.007843127474188805\n",
      "The classification loss after processing this batch is:  39095.29296875\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  35137.34375\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  33473.0390625\n",
      "The representation loss after processing this batch is:  0.007843127474188805\n",
      "The classification loss after processing this batch is:  36217.40625\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  33658.203125\n",
      "The representation loss after processing this batch is:  0.007843132130801678\n",
      "The classification loss after processing this batch is:  33049.1640625\n",
      "The representation loss after processing this batch is:  0.00784315075725317\n",
      "The classification loss after processing this batch is:  33064.69921875\n",
      "The representation loss after processing this batch is:  0.00784309208393097\n",
      "The classification loss after processing this batch is:  32666.05078125\n",
      "The representation loss after processing this batch is:  0.007843130268156528\n",
      "The classification loss after processing this batch is:  33269.3359375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  33028.94921875\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  33961.00390625\n",
      "The representation loss after processing this batch is:  0.00784317497164011\n",
      "The classification loss after processing this batch is:  35251.30859375\n",
      "The representation loss after processing this batch is:  0.007843133062124252\n",
      "The classification loss after processing this batch is:  36659.1875\n",
      "The representation loss after processing this batch is:  0.00784314051270485\n",
      "The classification loss after processing this batch is:  34407.94921875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  35585.07421875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  33658.12890625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34134.75390625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34550.5625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  37653.12109375\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  34190.9921875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  43804.4921875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  33334.859375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  33961.09375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32777.5546875\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  35964.7265625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34642.5625\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  33580.51953125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  33423.03125\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  34828.734375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  33354.71875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  36382.78125\n",
      "The representation loss after processing this batch is:  0.007843129336833954\n",
      "The classification loss after processing this batch is:  36226.37890625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  33753.87109375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32074.328125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32100.796875\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  34521.70703125\n",
      "The representation loss after processing this batch is:  0.00784312468022108\n",
      "The classification loss after processing this batch is:  32992.23828125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  33377.9609375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  36131.80078125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  33535.64453125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  36416.3984375\n",
      "The representation loss after processing this batch is:  0.007843129336833954\n",
      "The classification loss after processing this batch is:  37252.375\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  34268.78125\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  34127.06640625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  35324.59765625\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  33412.4453125\n",
      "The representation loss after processing this batch is:  0.007842865772545338\n",
      "The classification loss after processing this batch is:  35185.69140625\n",
      "The representation loss after processing this batch is:  0.007843139581382275\n",
      "The classification loss after processing this batch is:  32488.66015625\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  36628.171875\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  39336.578125\n",
      "The representation loss after processing this batch is:  0.007843133993446827\n",
      "The classification loss after processing this batch is:  35645.6640625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  36727.61328125\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  35073.0546875\n",
      "The representation loss after processing this batch is:  0.007843083702027798\n",
      "The classification loss after processing this batch is:  33833.515625\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  34732.78125\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  36971.1484375\n",
      "The representation loss after processing this batch is:  0.007843156345188618\n",
      "The classification loss after processing this batch is:  34929.22265625\n",
      "The representation loss after processing this batch is:  0.00784311629831791\n",
      "The classification loss after processing this batch is:  32611.5625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  33222.90625\n",
      "The representation loss after processing this batch is:  0.007843133062124252\n",
      "The classification loss after processing this batch is:  33611.37890625\n",
      "The representation loss after processing this batch is:  0.007843127474188805\n",
      "The classification loss after processing this batch is:  31854.349609375\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  35948.23828125\n",
      "The representation loss after processing this batch is:  0.007843130268156528\n",
      "The classification loss after processing this batch is:  34234.4375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32630.927734375\n",
      "The representation loss after processing this batch is:  0.00784312840551138\n",
      "The classification loss after processing this batch is:  32674.8125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  31956.2734375\n",
      "The representation loss after processing this batch is:  0.007843254134058952\n",
      "The classification loss after processing this batch is:  34235.2421875\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  34109.96484375\n",
      "The representation loss after processing this batch is:  0.007843133062124252\n",
      "The classification loss after processing this batch is:  33398.24609375\n",
      "The representation loss after processing this batch is:  0.007843143306672573\n",
      "The classification loss after processing this batch is:  37076.65625\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  33821.359375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34608.125\n",
      "The representation loss after processing this batch is:  0.0078436816111207\n",
      "The classification loss after processing this batch is:  32537.07421875\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  34577.203125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  33842.99609375\n",
      "The representation loss after processing this batch is:  0.007843133062124252\n",
      "The classification loss after processing this batch is:  35015.90625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  36677.06640625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  33820.0390625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  33356.8828125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34838.51953125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  35289.1171875\n",
      "The representation loss after processing this batch is:  0.007843133993446827\n",
      "The classification loss after processing this batch is:  35265.71484375\n",
      "The representation loss after processing this batch is:  0.007843133993446827\n",
      "The classification loss after processing this batch is:  33341.08203125\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  33517.19140625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  33658.203125\n",
      "The representation loss after processing this batch is:  0.007843133993446827\n",
      "The classification loss after processing this batch is:  33192.45703125\n",
      "The representation loss after processing this batch is:  0.00784312840551138\n",
      "The classification loss after processing this batch is:  33243.296875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34823.6484375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34911.0859375\n",
      "The representation loss after processing this batch is:  0.007843113504350185\n",
      "The classification loss after processing this batch is:  35279.875\n",
      "The representation loss after processing this batch is:  0.00784306414425373\n",
      "The classification loss after processing this batch is:  33808.1484375\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  34005.71875\n",
      "The representation loss after processing this batch is:  0.007843059487640858\n",
      "The classification loss after processing this batch is:  33620.8515625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34207.21875\n",
      "The representation loss after processing this batch is:  0.00784315075725317\n",
      "The classification loss after processing this batch is:  32829.03125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  30865.7734375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32018.859375\n",
      "The representation loss after processing this batch is:  0.007843120023608208\n",
      "The classification loss after processing this batch is:  34332.8359375\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  33749.9453125\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  33670.9765625\n",
      "The representation loss after processing this batch is:  0.007843133993446827\n",
      "The classification loss after processing this batch is:  33683.796875\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  33268.765625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32211.640625\n",
      "The representation loss after processing this batch is:  0.007843351922929287\n",
      "The classification loss after processing this batch is:  34492.109375\n",
      "The representation loss after processing this batch is:  0.007843145169317722\n",
      "The classification loss after processing this batch is:  35645.9765625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  33094.83203125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34116.48046875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  33178.21875\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  33289.72265625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  35203.890625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34045.4921875\n",
      "The representation loss after processing this batch is:  0.007843141444027424\n",
      "The classification loss after processing this batch is:  32158.91796875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32952.05078125\n",
      "The representation loss after processing this batch is:  0.007843145169317722\n",
      "The classification loss after processing this batch is:  32166.56640625\n",
      "The representation loss after processing this batch is:  0.00784314051270485\n",
      "The classification loss after processing this batch is:  32523.80078125\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  31493.322265625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  32964.234375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32127.90625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  33588.41796875\n",
      "The representation loss after processing this batch is:  0.00784312468022108\n",
      "The classification loss after processing this batch is:  32007.966796875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  33053.2265625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  33089.3984375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32075.0\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32884.74609375\n",
      "The representation loss after processing this batch is:  0.007843133993446827\n",
      "The classification loss after processing this batch is:  35424.2265625\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  31613.833984375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  30897.8125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32443.083984375\n",
      "The representation loss after processing this batch is:  0.00784314051270485\n",
      "The classification loss after processing this batch is:  34044.7578125\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  34381.0859375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32330.03125\n",
      "The representation loss after processing this batch is:  0.007843129336833954\n",
      "The classification loss after processing this batch is:  31614.515625\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  31580.56640625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  31487.78515625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  32321.55078125\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  34337.234375\n",
      "The representation loss after processing this batch is:  0.007843149825930595\n",
      "The classification loss after processing this batch is:  31733.623046875\n",
      "The representation loss after processing this batch is:  0.00784311443567276\n",
      "The classification loss after processing this batch is:  32953.2578125\n",
      "The representation loss after processing this batch is:  0.007843165658414364\n",
      "The classification loss after processing this batch is:  32733.65625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34354.2578125\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  32750.6484375\n",
      "The representation loss after processing this batch is:  0.007843198254704475\n",
      "The classification loss after processing this batch is:  32262.46875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  33312.1171875\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  32957.1875\n",
      "The representation loss after processing this batch is:  0.00784314051270485\n",
      "The classification loss after processing this batch is:  32305.0234375\n",
      "The representation loss after processing this batch is:  0.007843143306672573\n",
      "The classification loss after processing this batch is:  33129.5625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  31741.62890625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  32029.212890625\n",
      "The representation loss after processing this batch is:  0.00784312654286623\n",
      "The classification loss after processing this batch is:  34321.04296875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32738.0078125\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  31778.009765625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32382.3125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  31968.9453125\n",
      "The representation loss after processing this batch is:  0.007843133993446827\n",
      "The classification loss after processing this batch is:  32129.50390625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34770.6953125\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  33078.48828125\n",
      "The representation loss after processing this batch is:  0.007843108847737312\n",
      "The classification loss after processing this batch is:  34522.8203125\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  32703.70703125\n",
      "The representation loss after processing this batch is:  0.007843131199479103\n",
      "The classification loss after processing this batch is:  31851.48046875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32240.236328125\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32823.734375\n",
      "The representation loss after processing this batch is:  0.007843142375349998\n",
      "The classification loss after processing this batch is:  33064.828125\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  31379.05859375\n",
      "The representation loss after processing this batch is:  0.007843133993446827\n",
      "The classification loss after processing this batch is:  32210.73046875\n",
      "The representation loss after processing this batch is:  0.007843143306672573\n",
      "The classification loss after processing this batch is:  32446.119140625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32384.662109375\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  34087.20703125\n",
      "The representation loss after processing this batch is:  0.007843165658414364\n",
      "The classification loss after processing this batch is:  30839.390625\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  30526.583984375\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  31914.138671875\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  32416.232421875\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  30334.59375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  31695.732421875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32065.765625\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  31103.794921875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  32289.232421875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  31535.87890625\n",
      "The representation loss after processing this batch is:  0.007843134924769402\n",
      "The classification loss after processing this batch is:  32618.314453125\n",
      "The representation loss after processing this batch is:  0.00784312654286623\n",
      "The classification loss after processing this batch is:  30769.1015625\n",
      "The representation loss after processing this batch is:  0.007843133062124252\n",
      "The classification loss after processing this batch is:  30714.896484375\n",
      "The representation loss after processing this batch is:  0.007843139581382275\n",
      "The classification loss after processing this batch is:  31572.20703125\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  31188.296875\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  31108.8203125\n",
      "The representation loss after processing this batch is:  0.007843087427318096\n",
      "The classification loss after processing this batch is:  32082.84765625\n",
      "The representation loss after processing this batch is:  0.00784312468022108\n",
      "The classification loss after processing this batch is:  32719.21875\n",
      "The representation loss after processing this batch is:  0.00784313678741455\n",
      "The classification loss after processing this batch is:  29981.390625\n",
      "The representation loss after processing this batch is:  0.007843147031962872\n",
      "The classification loss after processing this batch is:  31542.21875\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  33217.39453125\n",
      "The representation loss after processing this batch is:  0.007843132130801678\n",
      "The classification loss after processing this batch is:  30617.544921875\n",
      "The representation loss after processing this batch is:  0.007843037135899067\n",
      "The classification loss after processing this batch is:  31618.52734375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  34115.515625\n",
      "The representation loss after processing this batch is:  0.007843139581382275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  31923.37109375\n",
      "The representation loss after processing this batch is:  0.007843137718737125\n",
      "The classification loss after processing this batch is:  31965.923828125\n",
      "The representation loss after processing this batch is:  0.007843093015253544\n",
      "The classification loss after processing this batch is:  31263.62890625\n",
      "The representation loss after processing this batch is:  0.007843143306672573\n",
      "The classification loss after processing this batch is:  33880.15234375\n",
      "The representation loss after processing this batch is:  0.007843142375349998\n",
      "The classification loss after processing this batch is:  33111.5390625\n",
      "The representation loss after processing this batch is:  0.007843135856091976\n",
      "The classification loss after processing this batch is:  32870.3359375\n",
      "The representation loss after processing this batch is:  0.0078431386500597\n",
      "The classification loss after processing this batch is:  16998.072265625\n",
      "The representation loss after processing this batch is:  0.0029412840958684683\n",
      "The classification loss after processing this batch is:  32425.5\n",
      "The representation loss after processing this batch is:  0.00784299150109291\n",
      "The classification loss after processing this batch is:  32139.44140625\n",
      "The representation loss after processing this batch is:  0.007843111641705036\n",
      "The classification loss after processing this batch is:  32023.763671875\n",
      "The representation loss after processing this batch is:  0.007843141444027424\n",
      "The classification loss after processing this batch is:  30922.939453125\n",
      "The representation loss after processing this batch is:  0.007843125611543655\n",
      "The classification loss after processing this batch is:  32093.8828125\n",
      "The representation loss after processing this batch is:  0.007843093946576118\n",
      "The classification loss after processing this batch is:  32629.63671875\n",
      "The representation loss after processing this batch is:  0.00784307811409235\n",
      "The classification loss after processing this batch is:  31417.904296875\n",
      "The representation loss after processing this batch is:  0.007843106985092163\n",
      "The classification loss after processing this batch is:  32099.669921875\n",
      "The representation loss after processing this batch is:  0.007842796854674816\n",
      "The classification loss after processing this batch is:  33714.24609375\n",
      "The representation loss after processing this batch is:  0.007842807099223137\n",
      "The classification loss after processing this batch is:  31199.857421875\n",
      "The representation loss after processing this batch is:  0.007841387763619423\n",
      "The classification loss after processing this batch is:  32624.0078125\n",
      "The representation loss after processing this batch is:  0.00783943384885788\n",
      "The classification loss after processing this batch is:  33108.8515625\n",
      "The representation loss after processing this batch is:  0.00783450622111559\n",
      "The classification loss after processing this batch is:  33571.11328125\n",
      "The representation loss after processing this batch is:  0.007792949676513672\n",
      "The classification loss after processing this batch is:  36986.203125\n",
      "The representation loss after processing this batch is:  0.007493320852518082\n",
      "The classification loss after processing this batch is:  45123.8984375\n",
      "The representation loss after processing this batch is:  0.005720075219869614\n",
      "The classification loss after processing this batch is:  50415.0859375\n",
      "The representation loss after processing this batch is:  0.0037489579990506172\n",
      "The classification loss after processing this batch is:  60114.10546875\n",
      "The representation loss after processing this batch is:  0.0016870088875293732\n",
      "The classification loss after processing this batch is:  72992.921875\n",
      "The representation loss after processing this batch is:  0.0013171834871172905\n",
      "The classification loss after processing this batch is:  91844.140625\n",
      "The representation loss after processing this batch is:  0.0009489357471466064\n",
      "The classification loss after processing this batch is:  94920.15625\n",
      "The representation loss after processing this batch is:  0.0006205663084983826\n",
      "The classification loss after processing this batch is:  107303.546875\n",
      "The representation loss after processing this batch is:  0.0006633196026086807\n",
      "The classification loss after processing this batch is:  115833.390625\n",
      "The representation loss after processing this batch is:  0.000537363812327385\n",
      "The classification loss after processing this batch is:  122091.109375\n",
      "The representation loss after processing this batch is:  0.0006089471280574799\n",
      "The classification loss after processing this batch is:  132128.203125\n",
      "The representation loss after processing this batch is:  0.0003894716501235962\n",
      "The classification loss after processing this batch is:  136391.46875\n",
      "The representation loss after processing this batch is:  0.0004162602126598358\n",
      "The classification loss after processing this batch is:  142739.34375\n",
      "The representation loss after processing this batch is:  0.00039804354310035706\n",
      "The classification loss after processing this batch is:  144685.75\n",
      "The representation loss after processing this batch is:  0.0003669522702693939\n",
      "The classification loss after processing this batch is:  151723.0\n",
      "The representation loss after processing this batch is:  0.0003198683261871338\n",
      "The classification loss after processing this batch is:  152707.1875\n",
      "The representation loss after processing this batch is:  0.00042599067091941833\n",
      "The classification loss after processing this batch is:  158851.5\n",
      "The representation loss after processing this batch is:  0.0003729723393917084\n",
      "The classification loss after processing this batch is:  164148.6875\n",
      "The representation loss after processing this batch is:  0.0003774017095565796\n",
      "The classification loss after processing this batch is:  166978.421875\n",
      "The representation loss after processing this batch is:  0.00038181617856025696\n",
      "The classification loss after processing this batch is:  166290.28125\n",
      "The representation loss after processing this batch is:  0.00032773613929748535\n",
      "The classification loss after processing this batch is:  171765.984375\n",
      "The representation loss after processing this batch is:  0.0003366023302078247\n",
      "The classification loss after processing this batch is:  170101.390625\n",
      "The representation loss after processing this batch is:  0.00029940158128738403\n",
      "The classification loss after processing this batch is:  171263.6875\n",
      "The representation loss after processing this batch is:  0.00030627474188804626\n",
      "The classification loss after processing this batch is:  172606.84375\n",
      "The representation loss after processing this batch is:  0.00027083978056907654\n",
      "The classification loss after processing this batch is:  172595.9375\n",
      "The representation loss after processing this batch is:  0.00031107664108276367\n",
      "The classification loss after processing this batch is:  172017.890625\n",
      "The representation loss after processing this batch is:  0.00027697905898094177\n",
      "The classification loss after processing this batch is:  169623.375\n",
      "The representation loss after processing this batch is:  0.00023514404892921448\n",
      "The classification loss after processing this batch is:  172830.78125\n",
      "The representation loss after processing this batch is:  0.00028501637279987335\n",
      "The classification loss after processing this batch is:  168005.484375\n",
      "The representation loss after processing this batch is:  0.0002673827111721039\n",
      "The classification loss after processing this batch is:  166492.671875\n",
      "The representation loss after processing this batch is:  0.0002838820219039917\n",
      "The classification loss after processing this batch is:  165916.546875\n",
      "The representation loss after processing this batch is:  0.00026485323905944824\n",
      "The classification loss after processing this batch is:  162467.140625\n",
      "The representation loss after processing this batch is:  0.00024761445820331573\n",
      "The classification loss after processing this batch is:  161501.03125\n",
      "The representation loss after processing this batch is:  0.0002556443214416504\n",
      "The classification loss after processing this batch is:  159677.21875\n",
      "The representation loss after processing this batch is:  0.00025412626564502716\n",
      "The classification loss after processing this batch is:  160876.328125\n",
      "The representation loss after processing this batch is:  0.0002466142177581787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  161132.96875\n",
      "The representation loss after processing this batch is:  0.00027091242372989655\n",
      "The classification loss after processing this batch is:  160112.0625\n",
      "The representation loss after processing this batch is:  0.00023331120610237122\n",
      "The classification loss after processing this batch is:  157174.90625\n",
      "The representation loss after processing this batch is:  0.00022364407777786255\n",
      "The classification loss after processing this batch is:  157562.28125\n",
      "The representation loss after processing this batch is:  0.00022716447710990906\n",
      "The classification loss after processing this batch is:  154629.1875\n",
      "The representation loss after processing this batch is:  0.00021237879991531372\n",
      "The classification loss after processing this batch is:  151150.234375\n",
      "The representation loss after processing this batch is:  0.00023238733410835266\n",
      "The classification loss after processing this batch is:  153372.65625\n",
      "The representation loss after processing this batch is:  0.00021764077246189117\n",
      "The classification loss after processing this batch is:  153252.0625\n",
      "The representation loss after processing this batch is:  0.00023977644741535187\n",
      "The classification loss after processing this batch is:  147938.515625\n",
      "The representation loss after processing this batch is:  0.00021606683731079102\n",
      "The classification loss after processing this batch is:  151335.78125\n",
      "The representation loss after processing this batch is:  0.0002579614520072937\n",
      "The classification loss after processing this batch is:  142698.578125\n",
      "The representation loss after processing this batch is:  0.0002275761216878891\n",
      "The classification loss after processing this batch is:  143005.15625\n",
      "The representation loss after processing this batch is:  0.00022466666996479034\n",
      "The classification loss after processing this batch is:  141392.859375\n",
      "The representation loss after processing this batch is:  0.00020898692309856415\n",
      "The classification loss after processing this batch is:  143050.125\n",
      "The representation loss after processing this batch is:  0.00021523050963878632\n",
      "The classification loss after processing this batch is:  138776.6875\n",
      "The representation loss after processing this batch is:  0.00023006461560726166\n",
      "The classification loss after processing this batch is:  137508.3125\n",
      "The representation loss after processing this batch is:  0.00021983496844768524\n",
      "The classification loss after processing this batch is:  136074.515625\n",
      "The representation loss after processing this batch is:  0.00022596865892410278\n",
      "The classification loss after processing this batch is:  137129.34375\n",
      "The representation loss after processing this batch is:  0.00020984560251235962\n",
      "The classification loss after processing this batch is:  134144.109375\n",
      "The representation loss after processing this batch is:  0.00019959360361099243\n",
      "The classification loss after processing this batch is:  138225.0\n",
      "The representation loss after processing this batch is:  0.00021462887525558472\n",
      "The classification loss after processing this batch is:  135252.8125\n",
      "The representation loss after processing this batch is:  0.00021029077470302582\n",
      "The classification loss after processing this batch is:  129464.59375\n",
      "The representation loss after processing this batch is:  0.0002347119152545929\n",
      "The classification loss after processing this batch is:  129673.09375\n",
      "The representation loss after processing this batch is:  0.00019245967268943787\n",
      "The classification loss after processing this batch is:  127055.765625\n",
      "The representation loss after processing this batch is:  0.00021934695541858673\n",
      "The classification loss after processing this batch is:  128999.921875\n",
      "The representation loss after processing this batch is:  0.00023050978779792786\n",
      "The classification loss after processing this batch is:  127144.96875\n",
      "The representation loss after processing this batch is:  0.00020822323858737946\n",
      "The classification loss after processing this batch is:  126559.5546875\n",
      "The representation loss after processing this batch is:  0.00019693002104759216\n",
      "The classification loss after processing this batch is:  129442.03125\n",
      "The representation loss after processing this batch is:  0.00023274682462215424\n",
      "The classification loss after processing this batch is:  125448.828125\n",
      "The representation loss after processing this batch is:  0.0002076420933008194\n",
      "The classification loss after processing this batch is:  127994.7421875\n",
      "The representation loss after processing this batch is:  0.00020514987409114838\n",
      "The classification loss after processing this batch is:  126961.546875\n",
      "The representation loss after processing this batch is:  0.00020292587578296661\n",
      "The classification loss after processing this batch is:  122700.84375\n",
      "The representation loss after processing this batch is:  0.00018767081201076508\n",
      "The classification loss after processing this batch is:  123250.921875\n",
      "The representation loss after processing this batch is:  0.00020407699048519135\n",
      "The classification loss after processing this batch is:  122023.03125\n",
      "The representation loss after processing this batch is:  0.0001781955361366272\n",
      "The classification loss after processing this batch is:  119537.578125\n",
      "The representation loss after processing this batch is:  0.00020085275173187256\n",
      "The classification loss after processing this batch is:  120103.5234375\n",
      "The representation loss after processing this batch is:  0.00021299906075000763\n",
      "The classification loss after processing this batch is:  116060.46875\n",
      "The representation loss after processing this batch is:  0.00022100657224655151\n",
      "The classification loss after processing this batch is:  118492.7421875\n",
      "The representation loss after processing this batch is:  0.00024250522255897522\n",
      "The classification loss after processing this batch is:  120564.421875\n",
      "The representation loss after processing this batch is:  0.00019255280494689941\n",
      "The classification loss after processing this batch is:  115488.265625\n",
      "The representation loss after processing this batch is:  0.0001751035451889038\n",
      "The classification loss after processing this batch is:  118365.421875\n",
      "The representation loss after processing this batch is:  0.00021481141448020935\n",
      "The classification loss after processing this batch is:  116507.7109375\n",
      "The representation loss after processing this batch is:  0.0001930035650730133\n",
      "The classification loss after processing this batch is:  114342.40625\n",
      "The representation loss after processing this batch is:  0.00018983148038387299\n",
      "The classification loss after processing this batch is:  112807.34375\n",
      "The representation loss after processing this batch is:  0.00019116513431072235\n",
      "The classification loss after processing this batch is:  114036.546875\n",
      "The representation loss after processing this batch is:  0.00017994828522205353\n",
      "The classification loss after processing this batch is:  112219.59375\n",
      "The representation loss after processing this batch is:  0.0001858305186033249\n",
      "The classification loss after processing this batch is:  109026.234375\n",
      "The representation loss after processing this batch is:  0.00018403120338916779\n",
      "The classification loss after processing this batch is:  110026.9296875\n",
      "The representation loss after processing this batch is:  0.00018045306205749512\n",
      "The classification loss after processing this batch is:  109339.4765625\n",
      "The representation loss after processing this batch is:  0.00017854757606983185\n",
      "The classification loss after processing this batch is:  105711.0234375\n",
      "The representation loss after processing this batch is:  0.00019912607967853546\n",
      "The classification loss after processing this batch is:  109870.6640625\n",
      "The representation loss after processing this batch is:  0.00018534064292907715\n",
      "The classification loss after processing this batch is:  107555.046875\n",
      "The representation loss after processing this batch is:  0.00021407566964626312\n",
      "The classification loss after processing this batch is:  105126.703125\n",
      "The representation loss after processing this batch is:  0.00018766894936561584\n",
      "The classification loss after processing this batch is:  104942.078125\n",
      "The representation loss after processing this batch is:  0.00019384920597076416\n",
      "The classification loss after processing this batch is:  103411.0\n",
      "The representation loss after processing this batch is:  0.00018527545034885406\n",
      "The classification loss after processing this batch is:  103895.65625\n",
      "The representation loss after processing this batch is:  0.0001983940601348877\n",
      "The classification loss after processing this batch is:  103483.046875\n",
      "The representation loss after processing this batch is:  0.00019537657499313354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  103555.0234375\n",
      "The representation loss after processing this batch is:  0.00018604658544063568\n",
      "The classification loss after processing this batch is:  107767.640625\n",
      "The representation loss after processing this batch is:  0.00020878203213214874\n",
      "The classification loss after processing this batch is:  103490.984375\n",
      "The representation loss after processing this batch is:  0.00018051639199256897\n",
      "The classification loss after processing this batch is:  103659.4296875\n",
      "The representation loss after processing this batch is:  0.00016970373690128326\n",
      "The classification loss after processing this batch is:  101669.5234375\n",
      "The representation loss after processing this batch is:  0.0002095382660627365\n",
      "The classification loss after processing this batch is:  102698.6328125\n",
      "The representation loss after processing this batch is:  0.00019606761634349823\n",
      "The classification loss after processing this batch is:  102111.65625\n",
      "The representation loss after processing this batch is:  0.00019019655883312225\n",
      "The classification loss after processing this batch is:  103968.8828125\n",
      "The representation loss after processing this batch is:  0.000203033909201622\n",
      "The classification loss after processing this batch is:  104821.6875\n",
      "The representation loss after processing this batch is:  0.00020181946456432343\n",
      "The classification loss after processing this batch is:  100994.9453125\n",
      "The representation loss after processing this batch is:  0.00019177794456481934\n",
      "The classification loss after processing this batch is:  99484.7890625\n",
      "The representation loss after processing this batch is:  0.00019650347530841827\n",
      "The classification loss after processing this batch is:  98657.078125\n",
      "The representation loss after processing this batch is:  0.00019174069166183472\n",
      "The classification loss after processing this batch is:  99816.0\n",
      "The representation loss after processing this batch is:  0.00020373240113258362\n",
      "The classification loss after processing this batch is:  101629.5078125\n",
      "The representation loss after processing this batch is:  0.0002029798924922943\n",
      "The classification loss after processing this batch is:  97640.6328125\n",
      "The representation loss after processing this batch is:  0.00019537284970283508\n",
      "The classification loss after processing this batch is:  97417.875\n",
      "The representation loss after processing this batch is:  0.0001893565058708191\n",
      "The classification loss after processing this batch is:  97786.609375\n",
      "The representation loss after processing this batch is:  0.00018941611051559448\n",
      "The classification loss after processing this batch is:  96203.6484375\n",
      "The representation loss after processing this batch is:  0.0001686103641986847\n",
      "The classification loss after processing this batch is:  96970.0546875\n",
      "The representation loss after processing this batch is:  0.0001833885908126831\n",
      "The classification loss after processing this batch is:  97926.21875\n",
      "The representation loss after processing this batch is:  0.00019777193665504456\n",
      "The classification loss after processing this batch is:  96855.6796875\n",
      "The representation loss after processing this batch is:  0.00019216351211071014\n",
      "The classification loss after processing this batch is:  98519.5625\n",
      "The representation loss after processing this batch is:  0.00019479356706142426\n",
      "The classification loss after processing this batch is:  96907.796875\n",
      "The representation loss after processing this batch is:  0.00019796378910541534\n",
      "The classification loss after processing this batch is:  96019.671875\n",
      "The representation loss after processing this batch is:  0.00017798133194446564\n",
      "The classification loss after processing this batch is:  96384.640625\n",
      "The representation loss after processing this batch is:  0.00019602663815021515\n",
      "The classification loss after processing this batch is:  94913.53125\n",
      "The representation loss after processing this batch is:  0.00017012283205986023\n",
      "The classification loss after processing this batch is:  93438.953125\n",
      "The representation loss after processing this batch is:  0.00019798055291175842\n",
      "The classification loss after processing this batch is:  92902.796875\n",
      "The representation loss after processing this batch is:  0.00019543617963790894\n",
      "The classification loss after processing this batch is:  93056.3125\n",
      "The representation loss after processing this batch is:  0.00018194504082202911\n",
      "The classification loss after processing this batch is:  94928.390625\n",
      "The representation loss after processing this batch is:  0.00021486356854438782\n",
      "The classification loss after processing this batch is:  94025.25\n",
      "The representation loss after processing this batch is:  0.00017421506345272064\n",
      "The classification loss after processing this batch is:  92903.5234375\n",
      "The representation loss after processing this batch is:  0.0001956447958946228\n",
      "The classification loss after processing this batch is:  93151.328125\n",
      "The representation loss after processing this batch is:  0.00020652823150157928\n",
      "The classification loss after processing this batch is:  92886.171875\n",
      "The representation loss after processing this batch is:  0.00017594732344150543\n",
      "The classification loss after processing this batch is:  91371.6875\n",
      "The representation loss after processing this batch is:  0.00017728470265865326\n",
      "The classification loss after processing this batch is:  93100.515625\n",
      "The representation loss after processing this batch is:  0.00019029714167118073\n",
      "The classification loss after processing this batch is:  96946.5859375\n",
      "The representation loss after processing this batch is:  0.00017643533647060394\n",
      "The classification loss after processing this batch is:  91409.15625\n",
      "The representation loss after processing this batch is:  0.00017349794507026672\n",
      "The classification loss after processing this batch is:  92907.171875\n",
      "The representation loss after processing this batch is:  0.0001925285905599594\n",
      "The classification loss after processing this batch is:  90443.65625\n",
      "The representation loss after processing this batch is:  0.000182395800948143\n",
      "The classification loss after processing this batch is:  91808.921875\n",
      "The representation loss after processing this batch is:  0.00017787516117095947\n",
      "The classification loss after processing this batch is:  91898.4140625\n",
      "The representation loss after processing this batch is:  0.0001736953854560852\n",
      "The classification loss after processing this batch is:  92308.03125\n",
      "The representation loss after processing this batch is:  0.00016804039478302002\n",
      "The classification loss after processing this batch is:  89054.5859375\n",
      "The representation loss after processing this batch is:  0.00016011297702789307\n",
      "The classification loss after processing this batch is:  89608.0625\n",
      "The representation loss after processing this batch is:  0.00016059540212154388\n",
      "The classification loss after processing this batch is:  89257.296875\n",
      "The representation loss after processing this batch is:  0.00016221962869167328\n",
      "The classification loss after processing this batch is:  88722.578125\n",
      "The representation loss after processing this batch is:  0.00018097274005413055\n",
      "The classification loss after processing this batch is:  87613.59375\n",
      "The representation loss after processing this batch is:  0.00017564557492733002\n",
      "The classification loss after processing this batch is:  89649.90625\n",
      "The representation loss after processing this batch is:  0.00015822239220142365\n",
      "The classification loss after processing this batch is:  87975.53125\n",
      "The representation loss after processing this batch is:  0.00016022846102714539\n",
      "The classification loss after processing this batch is:  88895.453125\n",
      "The representation loss after processing this batch is:  0.00017645582556724548\n",
      "The classification loss after processing this batch is:  86326.6640625\n",
      "The representation loss after processing this batch is:  0.00017254427075386047\n",
      "The classification loss after processing this batch is:  87786.765625\n",
      "The representation loss after processing this batch is:  0.00016301870346069336\n",
      "The classification loss after processing this batch is:  89114.796875\n",
      "The representation loss after processing this batch is:  0.00016886182129383087\n",
      "The classification loss after processing this batch is:  86203.71875\n",
      "The representation loss after processing this batch is:  0.00017828866839408875\n",
      "The classification loss after processing this batch is:  87432.4296875\n",
      "The representation loss after processing this batch is:  0.00017182715237140656\n",
      "The classification loss after processing this batch is:  89771.84375\n",
      "The representation loss after processing this batch is:  0.00017786957323551178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  85286.390625\n",
      "The representation loss after processing this batch is:  0.00016016885638237\n",
      "The classification loss after processing this batch is:  85027.1796875\n",
      "The representation loss after processing this batch is:  0.00016565993428230286\n",
      "The classification loss after processing this batch is:  85679.0\n",
      "The representation loss after processing this batch is:  0.00017782114446163177\n",
      "The classification loss after processing this batch is:  88971.1875\n",
      "The representation loss after processing this batch is:  0.00016874074935913086\n",
      "The classification loss after processing this batch is:  89090.09375\n",
      "The representation loss after processing this batch is:  0.00017203204333782196\n",
      "The classification loss after processing this batch is:  85081.703125\n",
      "The representation loss after processing this batch is:  0.0001767631620168686\n",
      "The classification loss after processing this batch is:  84147.078125\n",
      "The representation loss after processing this batch is:  0.00017381832003593445\n",
      "The classification loss after processing this batch is:  85020.7421875\n",
      "The representation loss after processing this batch is:  0.00016993656754493713\n",
      "The classification loss after processing this batch is:  84292.703125\n",
      "The representation loss after processing this batch is:  0.0001706331968307495\n",
      "The classification loss after processing this batch is:  84174.7109375\n",
      "The representation loss after processing this batch is:  0.000168507918715477\n",
      "The classification loss after processing this batch is:  87782.765625\n",
      "The representation loss after processing this batch is:  0.00018157437443733215\n",
      "The classification loss after processing this batch is:  84887.7734375\n",
      "The representation loss after processing this batch is:  0.0001524500548839569\n",
      "The classification loss after processing this batch is:  84707.1328125\n",
      "The representation loss after processing this batch is:  0.00016780011355876923\n",
      "The classification loss after processing this batch is:  84548.34375\n",
      "The representation loss after processing this batch is:  0.0001746155321598053\n",
      "The classification loss after processing this batch is:  86717.0625\n",
      "The representation loss after processing this batch is:  0.00018054619431495667\n",
      "The classification loss after processing this batch is:  84298.59375\n",
      "The representation loss after processing this batch is:  0.00016764551401138306\n",
      "The classification loss after processing this batch is:  84239.71875\n",
      "The representation loss after processing this batch is:  0.00017197057604789734\n",
      "The classification loss after processing this batch is:  84968.4453125\n",
      "The representation loss after processing this batch is:  0.00017067790031433105\n",
      "The classification loss after processing this batch is:  83738.3046875\n",
      "The representation loss after processing this batch is:  0.0001771543174982071\n",
      "The classification loss after processing this batch is:  83728.84375\n",
      "The representation loss after processing this batch is:  0.00016566365957260132\n",
      "The classification loss after processing this batch is:  84816.828125\n",
      "The representation loss after processing this batch is:  0.00016955845057964325\n",
      "The classification loss after processing this batch is:  82368.125\n",
      "The representation loss after processing this batch is:  0.00016305968165397644\n",
      "The classification loss after processing this batch is:  81294.71875\n",
      "The representation loss after processing this batch is:  0.00017865560948848724\n",
      "The classification loss after processing this batch is:  85511.015625\n",
      "The representation loss after processing this batch is:  0.00015883706510066986\n",
      "The classification loss after processing this batch is:  83308.375\n",
      "The representation loss after processing this batch is:  0.00017566047608852386\n",
      "The classification loss after processing this batch is:  80981.71875\n",
      "The representation loss after processing this batch is:  0.0001757051795721054\n",
      "The classification loss after processing this batch is:  83025.3125\n",
      "The representation loss after processing this batch is:  0.00017522647976875305\n",
      "The classification loss after processing this batch is:  82874.5859375\n",
      "The representation loss after processing this batch is:  0.00016836263239383698\n",
      "The classification loss after processing this batch is:  81827.78125\n",
      "The representation loss after processing this batch is:  0.00016554072499275208\n",
      "The classification loss after processing this batch is:  83692.421875\n",
      "The representation loss after processing this batch is:  0.00015198811888694763\n",
      "The classification loss after processing this batch is:  82041.046875\n",
      "The representation loss after processing this batch is:  0.00016934797167778015\n",
      "The classification loss after processing this batch is:  84678.859375\n",
      "The representation loss after processing this batch is:  0.00016053207218647003\n",
      "The classification loss after processing this batch is:  81230.8203125\n",
      "The representation loss after processing this batch is:  0.00016242638230323792\n",
      "The classification loss after processing this batch is:  80189.703125\n",
      "The representation loss after processing this batch is:  0.00016767531633377075\n",
      "The classification loss after processing this batch is:  80934.8125\n",
      "The representation loss after processing this batch is:  0.0001781657338142395\n",
      "The classification loss after processing this batch is:  80975.3125\n",
      "The representation loss after processing this batch is:  0.00018017180263996124\n",
      "The classification loss after processing this batch is:  80106.21875\n",
      "The representation loss after processing this batch is:  0.00019582919776439667\n",
      "The classification loss after processing this batch is:  79969.734375\n",
      "The representation loss after processing this batch is:  0.00017456524074077606\n",
      "The classification loss after processing this batch is:  81137.4765625\n",
      "The representation loss after processing this batch is:  0.0001636892557144165\n",
      "The classification loss after processing this batch is:  81576.203125\n",
      "The representation loss after processing this batch is:  0.0001767463982105255\n",
      "The classification loss after processing this batch is:  80413.1484375\n",
      "The representation loss after processing this batch is:  0.00016993284225463867\n",
      "The classification loss after processing this batch is:  81850.4609375\n",
      "The representation loss after processing this batch is:  0.0001621544361114502\n",
      "The classification loss after processing this batch is:  78044.640625\n",
      "The representation loss after processing this batch is:  0.0001585744321346283\n",
      "The classification loss after processing this batch is:  78315.890625\n",
      "The representation loss after processing this batch is:  0.00015465356409549713\n",
      "The classification loss after processing this batch is:  80034.53125\n",
      "The representation loss after processing this batch is:  0.00015747547149658203\n",
      "The classification loss after processing this batch is:  80239.796875\n",
      "The representation loss after processing this batch is:  0.00016925856471061707\n",
      "The classification loss after processing this batch is:  78279.875\n",
      "The representation loss after processing this batch is:  0.00016010738909244537\n",
      "The classification loss after processing this batch is:  79289.6875\n",
      "The representation loss after processing this batch is:  0.00016587600111961365\n",
      "The classification loss after processing this batch is:  79371.5234375\n",
      "The representation loss after processing this batch is:  0.00015799514949321747\n",
      "The classification loss after processing this batch is:  78759.796875\n",
      "The representation loss after processing this batch is:  0.0001844223588705063\n",
      "The classification loss after processing this batch is:  80077.5\n",
      "The representation loss after processing this batch is:  0.0001752842217683792\n",
      "The classification loss after processing this batch is:  78233.234375\n",
      "The representation loss after processing this batch is:  0.000154910609126091\n",
      "The classification loss after processing this batch is:  80485.703125\n",
      "The representation loss after processing this batch is:  0.00016313977539539337\n",
      "The classification loss after processing this batch is:  77225.125\n",
      "The representation loss after processing this batch is:  0.00016159005463123322\n",
      "The classification loss after processing this batch is:  76957.109375\n",
      "The representation loss after processing this batch is:  0.00016345642507076263\n",
      "The classification loss after processing this batch is:  78719.453125\n",
      "The representation loss after processing this batch is:  0.0001734476536512375\n",
      "The classification loss after processing this batch is:  76988.859375\n",
      "The representation loss after processing this batch is:  0.00017761997878551483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  77593.875\n",
      "The representation loss after processing this batch is:  0.0001591108739376068\n",
      "The classification loss after processing this batch is:  78160.0\n",
      "The representation loss after processing this batch is:  0.00017501041293144226\n",
      "The classification loss after processing this batch is:  79397.1796875\n",
      "The representation loss after processing this batch is:  0.000155523419380188\n",
      "The classification loss after processing this batch is:  75446.359375\n",
      "The representation loss after processing this batch is:  0.00017605535686016083\n",
      "The classification loss after processing this batch is:  79200.40625\n",
      "The representation loss after processing this batch is:  0.00017067231237888336\n",
      "The classification loss after processing this batch is:  80143.421875\n",
      "The representation loss after processing this batch is:  0.00016974471509456635\n",
      "The classification loss after processing this batch is:  75815.84375\n",
      "The representation loss after processing this batch is:  0.00016274861991405487\n",
      "The classification loss after processing this batch is:  77670.25\n",
      "The representation loss after processing this batch is:  0.00015738792717456818\n",
      "The classification loss after processing this batch is:  79828.609375\n",
      "The representation loss after processing this batch is:  0.0001931898295879364\n",
      "The classification loss after processing this batch is:  77430.859375\n",
      "The representation loss after processing this batch is:  0.00017577223479747772\n",
      "The classification loss after processing this batch is:  76267.5390625\n",
      "The representation loss after processing this batch is:  0.00016945227980613708\n",
      "The classification loss after processing this batch is:  75534.078125\n",
      "The representation loss after processing this batch is:  0.00019482336938381195\n",
      "The classification loss after processing this batch is:  80491.8359375\n",
      "The representation loss after processing this batch is:  0.00019018910825252533\n",
      "The classification loss after processing this batch is:  80186.4453125\n",
      "The representation loss after processing this batch is:  0.0001631118357181549\n",
      "The classification loss after processing this batch is:  77996.078125\n",
      "The representation loss after processing this batch is:  0.00019322894513607025\n",
      "The classification loss after processing this batch is:  32903.5234375\n",
      "The representation loss after processing this batch is:  8.068885654211044e-05\n",
      "The classification loss after processing this batch is:  77462.4765625\n",
      "The representation loss after processing this batch is:  0.00010199286043643951\n",
      "The classification loss after processing this batch is:  76473.5390625\n",
      "The representation loss after processing this batch is:  0.00010318495333194733\n",
      "The classification loss after processing this batch is:  77028.4609375\n",
      "The representation loss after processing this batch is:  9.728409349918365e-05\n",
      "The classification loss after processing this batch is:  76705.265625\n",
      "The representation loss after processing this batch is:  9.757839143276215e-05\n",
      "The classification loss after processing this batch is:  77732.953125\n",
      "The representation loss after processing this batch is:  9.192898869514465e-05\n",
      "The classification loss after processing this batch is:  78505.0\n",
      "The representation loss after processing this batch is:  8.223578333854675e-05\n",
      "The classification loss after processing this batch is:  75548.09375\n",
      "The representation loss after processing this batch is:  9.333528578281403e-05\n",
      "The classification loss after processing this batch is:  76844.71875\n",
      "The representation loss after processing this batch is:  8.83154571056366e-05\n",
      "The classification loss after processing this batch is:  78117.125\n",
      "The representation loss after processing this batch is:  8.847750723361969e-05\n",
      "The classification loss after processing this batch is:  76029.3125\n",
      "The representation loss after processing this batch is:  9.561888873577118e-05\n",
      "The classification loss after processing this batch is:  76329.46875\n",
      "The representation loss after processing this batch is:  8.365511894226074e-05\n",
      "The classification loss after processing this batch is:  76135.1875\n",
      "The representation loss after processing this batch is:  7.733050733804703e-05\n",
      "The classification loss after processing this batch is:  74113.6484375\n",
      "The representation loss after processing this batch is:  8.049607276916504e-05\n",
      "The classification loss after processing this batch is:  74830.796875\n",
      "The representation loss after processing this batch is:  8.128583431243896e-05\n",
      "The classification loss after processing this batch is:  77683.6328125\n",
      "The representation loss after processing this batch is:  8.682161569595337e-05\n",
      "The classification loss after processing this batch is:  75024.9296875\n",
      "The representation loss after processing this batch is:  8.302181959152222e-05\n",
      "The classification loss after processing this batch is:  74799.84375\n",
      "The representation loss after processing this batch is:  7.979478687047958e-05\n",
      "The classification loss after processing this batch is:  74631.578125\n",
      "The representation loss after processing this batch is:  7.964763790369034e-05\n",
      "The classification loss after processing this batch is:  81743.53125\n",
      "The representation loss after processing this batch is:  8.178409188985825e-05\n",
      "The classification loss after processing this batch is:  74352.765625\n",
      "The representation loss after processing this batch is:  9.48803499341011e-05\n",
      "The classification loss after processing this batch is:  76560.28125\n",
      "The representation loss after processing this batch is:  8.299760520458221e-05\n",
      "The classification loss after processing this batch is:  75914.890625\n",
      "The representation loss after processing this batch is:  7.904320955276489e-05\n",
      "The classification loss after processing this batch is:  76281.9375\n",
      "The representation loss after processing this batch is:  8.512474596500397e-05\n",
      "The classification loss after processing this batch is:  75727.4296875\n",
      "The representation loss after processing this batch is:  7.287226617336273e-05\n",
      "The classification loss after processing this batch is:  75422.3125\n",
      "The representation loss after processing this batch is:  7.370486855506897e-05\n",
      "The classification loss after processing this batch is:  73965.25\n",
      "The representation loss after processing this batch is:  7.606670260429382e-05\n",
      "The classification loss after processing this batch is:  74446.34375\n",
      "The representation loss after processing this batch is:  8.632522076368332e-05\n",
      "The classification loss after processing this batch is:  73825.9375\n",
      "The representation loss after processing this batch is:  7.50003382563591e-05\n",
      "The classification loss after processing this batch is:  75744.421875\n",
      "The representation loss after processing this batch is:  8.064974099397659e-05\n",
      "The classification loss after processing this batch is:  74941.328125\n",
      "The representation loss after processing this batch is:  8.47475603222847e-05\n",
      "The classification loss after processing this batch is:  79001.546875\n",
      "The representation loss after processing this batch is:  7.143337279558182e-05\n",
      "The classification loss after processing this batch is:  75551.734375\n",
      "The representation loss after processing this batch is:  7.673166692256927e-05\n",
      "The classification loss after processing this batch is:  75413.265625\n",
      "The representation loss after processing this batch is:  7.08065927028656e-05\n",
      "The classification loss after processing this batch is:  77304.125\n",
      "The representation loss after processing this batch is:  7.630418986082077e-05\n",
      "The classification loss after processing this batch is:  75087.46875\n",
      "The representation loss after processing this batch is:  7.157959043979645e-05\n",
      "The classification loss after processing this batch is:  76965.703125\n",
      "The representation loss after processing this batch is:  8.96630808711052e-05\n",
      "The classification loss after processing this batch is:  76600.25\n",
      "The representation loss after processing this batch is:  7.37970694899559e-05\n",
      "The classification loss after processing this batch is:  79230.765625\n",
      "The representation loss after processing this batch is:  7.870141416788101e-05\n",
      "The classification loss after processing this batch is:  75127.1015625\n",
      "The representation loss after processing this batch is:  8.510798215866089e-05\n",
      "The classification loss after processing this batch is:  74366.7109375\n",
      "The representation loss after processing this batch is:  7.272697985172272e-05\n",
      "The classification loss after processing this batch is:  77521.515625\n",
      "The representation loss after processing this batch is:  7.347296923398972e-05\n",
      "The classification loss after processing this batch is:  73788.125\n",
      "The representation loss after processing this batch is:  7.356330752372742e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  73794.453125\n",
      "The representation loss after processing this batch is:  6.963592022657394e-05\n",
      "The classification loss after processing this batch is:  73168.015625\n",
      "The representation loss after processing this batch is:  7.120799273252487e-05\n",
      "The classification loss after processing this batch is:  72040.9375\n",
      "The representation loss after processing this batch is:  6.965454667806625e-05\n",
      "The classification loss after processing this batch is:  73113.2421875\n",
      "The representation loss after processing this batch is:  7.485691457986832e-05\n",
      "The classification loss after processing this batch is:  72602.9765625\n",
      "The representation loss after processing this batch is:  7.242430001497269e-05\n",
      "The classification loss after processing this batch is:  74013.15625\n",
      "The representation loss after processing this batch is:  7.190648466348648e-05\n",
      "The classification loss after processing this batch is:  76186.3125\n",
      "The representation loss after processing this batch is:  7.18235969543457e-05\n",
      "The classification loss after processing this batch is:  76707.390625\n",
      "The representation loss after processing this batch is:  6.555020809173584e-05\n",
      "The classification loss after processing this batch is:  74122.359375\n",
      "The representation loss after processing this batch is:  6.72629103064537e-05\n",
      "The classification loss after processing this batch is:  75700.109375\n",
      "The representation loss after processing this batch is:  7.138773798942566e-05\n",
      "The classification loss after processing this batch is:  73560.3359375\n",
      "The representation loss after processing this batch is:  6.436370313167572e-05\n",
      "The classification loss after processing this batch is:  73380.859375\n",
      "The representation loss after processing this batch is:  7.08550214767456e-05\n",
      "The classification loss after processing this batch is:  75181.421875\n",
      "The representation loss after processing this batch is:  7.246620953083038e-05\n",
      "The classification loss after processing this batch is:  78788.2890625\n",
      "The representation loss after processing this batch is:  7.698219269514084e-05\n",
      "The classification loss after processing this batch is:  73356.59375\n",
      "The representation loss after processing this batch is:  6.606429815292358e-05\n",
      "The classification loss after processing this batch is:  82915.6171875\n",
      "The representation loss after processing this batch is:  8.882954716682434e-05\n",
      "The classification loss after processing this batch is:  71304.1796875\n",
      "The representation loss after processing this batch is:  7.627531886100769e-05\n",
      "The classification loss after processing this batch is:  72226.671875\n",
      "The representation loss after processing this batch is:  7.180217653512955e-05\n",
      "The classification loss after processing this batch is:  71900.21875\n",
      "The representation loss after processing this batch is:  7.428135722875595e-05\n",
      "The classification loss after processing this batch is:  75744.6796875\n",
      "The representation loss after processing this batch is:  6.911531090736389e-05\n",
      "The classification loss after processing this batch is:  72629.125\n",
      "The representation loss after processing this batch is:  7.497146725654602e-05\n",
      "The classification loss after processing this batch is:  71412.109375\n",
      "The representation loss after processing this batch is:  7.01630488038063e-05\n",
      "The classification loss after processing this batch is:  71020.40625\n",
      "The representation loss after processing this batch is:  7.648300379514694e-05\n",
      "The classification loss after processing this batch is:  73017.078125\n",
      "The representation loss after processing this batch is:  6.77742063999176e-05\n",
      "The classification loss after processing this batch is:  71453.1171875\n",
      "The representation loss after processing this batch is:  6.739608943462372e-05\n",
      "The classification loss after processing this batch is:  75376.9453125\n",
      "The representation loss after processing this batch is:  7.342547178268433e-05\n",
      "The classification loss after processing this batch is:  74928.9765625\n",
      "The representation loss after processing this batch is:  8.295010775327682e-05\n",
      "The classification loss after processing this batch is:  71516.0390625\n",
      "The representation loss after processing this batch is:  8.153822273015976e-05\n",
      "The classification loss after processing this batch is:  69943.265625\n",
      "The representation loss after processing this batch is:  7.251463830471039e-05\n",
      "The classification loss after processing this batch is:  70047.609375\n",
      "The representation loss after processing this batch is:  7.402896881103516e-05\n",
      "The classification loss after processing this batch is:  72470.484375\n",
      "The representation loss after processing this batch is:  7.48857855796814e-05\n",
      "The classification loss after processing this batch is:  70655.640625\n",
      "The representation loss after processing this batch is:  6.783939898014069e-05\n",
      "The classification loss after processing this batch is:  71194.484375\n",
      "The representation loss after processing this batch is:  6.84056431055069e-05\n",
      "The classification loss after processing this batch is:  73757.4609375\n",
      "The representation loss after processing this batch is:  6.831157952547073e-05\n",
      "The classification loss after processing this batch is:  70678.2578125\n",
      "The representation loss after processing this batch is:  7.179658859968185e-05\n",
      "The classification loss after processing this batch is:  74909.8125\n",
      "The representation loss after processing this batch is:  6.655789911746979e-05\n",
      "The classification loss after processing this batch is:  74370.25\n",
      "The representation loss after processing this batch is:  7.515400648117065e-05\n",
      "The classification loss after processing this batch is:  70949.5078125\n",
      "The representation loss after processing this batch is:  7.806997746229172e-05\n",
      "The classification loss after processing this batch is:  71523.546875\n",
      "The representation loss after processing this batch is:  6.988737732172012e-05\n",
      "The classification loss after processing this batch is:  72962.15625\n",
      "The representation loss after processing this batch is:  6.781145930290222e-05\n",
      "The classification loss after processing this batch is:  70120.984375\n",
      "The representation loss after processing this batch is:  7.137469947338104e-05\n",
      "The classification loss after processing this batch is:  71503.0234375\n",
      "The representation loss after processing this batch is:  8.228234946727753e-05\n",
      "The classification loss after processing this batch is:  68842.890625\n",
      "The representation loss after processing this batch is:  7.55777582526207e-05\n",
      "The classification loss after processing this batch is:  72575.3359375\n",
      "The representation loss after processing this batch is:  7.578637450933456e-05\n",
      "The classification loss after processing this batch is:  75984.6796875\n",
      "The representation loss after processing this batch is:  7.483363151550293e-05\n",
      "The classification loss after processing this batch is:  70915.578125\n",
      "The representation loss after processing this batch is:  7.187016308307648e-05\n",
      "The classification loss after processing this batch is:  73594.234375\n",
      "The representation loss after processing this batch is:  7.326900959014893e-05\n",
      "The classification loss after processing this batch is:  71077.734375\n",
      "The representation loss after processing this batch is:  6.805267184972763e-05\n",
      "The classification loss after processing this batch is:  69937.640625\n",
      "The representation loss after processing this batch is:  6.681587547063828e-05\n",
      "The classification loss after processing this batch is:  70564.859375\n",
      "The representation loss after processing this batch is:  7.358472794294357e-05\n",
      "The classification loss after processing this batch is:  72206.765625\n",
      "The representation loss after processing this batch is:  7.488112896680832e-05\n",
      "The classification loss after processing this batch is:  70183.3203125\n",
      "The representation loss after processing this batch is:  6.763637065887451e-05\n",
      "The classification loss after processing this batch is:  67739.953125\n",
      "The representation loss after processing this batch is:  6.751064211130142e-05\n",
      "The classification loss after processing this batch is:  68979.875\n",
      "The representation loss after processing this batch is:  6.112176924943924e-05\n",
      "The classification loss after processing this batch is:  69255.828125\n",
      "The representation loss after processing this batch is:  6.998702883720398e-05\n",
      "The classification loss after processing this batch is:  66371.5703125\n",
      "The representation loss after processing this batch is:  7.193908095359802e-05\n",
      "The classification loss after processing this batch is:  71274.0\n",
      "The representation loss after processing this batch is:  6.940960884094238e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  69951.125\n",
      "The representation loss after processing this batch is:  7.221661508083344e-05\n",
      "The classification loss after processing this batch is:  67487.421875\n",
      "The representation loss after processing this batch is:  7.100775837898254e-05\n",
      "The classification loss after processing this batch is:  67867.8125\n",
      "The representation loss after processing this batch is:  7.600151002407074e-05\n",
      "The classification loss after processing this batch is:  66387.5\n",
      "The representation loss after processing this batch is:  7.057469338178635e-05\n",
      "The classification loss after processing this batch is:  68346.96875\n",
      "The representation loss after processing this batch is:  8.36588442325592e-05\n",
      "The classification loss after processing this batch is:  68040.765625\n",
      "The representation loss after processing this batch is:  7.876008749008179e-05\n",
      "The classification loss after processing this batch is:  67744.765625\n",
      "The representation loss after processing this batch is:  7.08727166056633e-05\n",
      "The classification loss after processing this batch is:  72647.90625\n",
      "The representation loss after processing this batch is:  8.272100239992142e-05\n",
      "The classification loss after processing this batch is:  67889.0625\n",
      "The representation loss after processing this batch is:  6.95008784532547e-05\n",
      "The classification loss after processing this batch is:  69039.421875\n",
      "The representation loss after processing this batch is:  7.632095366716385e-05\n",
      "The classification loss after processing this batch is:  67027.671875\n",
      "The representation loss after processing this batch is:  7.299799472093582e-05\n",
      "The classification loss after processing this batch is:  69130.6484375\n",
      "The representation loss after processing this batch is:  6.749201565980911e-05\n",
      "The classification loss after processing this batch is:  67972.8125\n",
      "The representation loss after processing this batch is:  6.537791341543198e-05\n",
      "The classification loss after processing this batch is:  71067.0390625\n",
      "The representation loss after processing this batch is:  7.294118404388428e-05\n",
      "The classification loss after processing this batch is:  72048.578125\n",
      "The representation loss after processing this batch is:  6.739795207977295e-05\n",
      "The classification loss after processing this batch is:  68274.59375\n",
      "The representation loss after processing this batch is:  6.734486669301987e-05\n",
      "The classification loss after processing this batch is:  66633.109375\n",
      "The representation loss after processing this batch is:  6.994977593421936e-05\n",
      "The classification loss after processing this batch is:  68120.40625\n",
      "The representation loss after processing this batch is:  6.89830631017685e-05\n",
      "The classification loss after processing this batch is:  69211.75\n",
      "The representation loss after processing this batch is:  7.409509271383286e-05\n",
      "The classification loss after processing this batch is:  70842.0625\n",
      "The representation loss after processing this batch is:  7.28946179151535e-05\n",
      "The classification loss after processing this batch is:  67043.109375\n",
      "The representation loss after processing this batch is:  6.736814975738525e-05\n",
      "The classification loss after processing this batch is:  66014.578125\n",
      "The representation loss after processing this batch is:  6.979797035455704e-05\n",
      "The classification loss after processing this batch is:  67283.2578125\n",
      "The representation loss after processing this batch is:  7.223151624202728e-05\n",
      "The classification loss after processing this batch is:  66452.796875\n",
      "The representation loss after processing this batch is:  6.65951520204544e-05\n",
      "The classification loss after processing this batch is:  66936.34375\n",
      "The representation loss after processing this batch is:  6.574764847755432e-05\n",
      "The classification loss after processing this batch is:  69445.6171875\n",
      "The representation loss after processing this batch is:  7.560104131698608e-05\n",
      "The classification loss after processing this batch is:  68022.75\n",
      "The representation loss after processing this batch is:  7.368996739387512e-05\n",
      "The classification loss after processing this batch is:  69359.2734375\n",
      "The representation loss after processing this batch is:  7.190369069576263e-05\n",
      "The classification loss after processing this batch is:  68110.203125\n",
      "The representation loss after processing this batch is:  7.881596684455872e-05\n",
      "The classification loss after processing this batch is:  67770.0234375\n",
      "The representation loss after processing this batch is:  6.948504596948624e-05\n",
      "The classification loss after processing this batch is:  67249.515625\n",
      "The representation loss after processing this batch is:  7.356330752372742e-05\n",
      "The classification loss after processing this batch is:  66795.59375\n",
      "The representation loss after processing this batch is:  6.829015910625458e-05\n",
      "The classification loss after processing this batch is:  65694.21875\n",
      "The representation loss after processing this batch is:  6.766524165868759e-05\n",
      "The classification loss after processing this batch is:  64358.08984375\n",
      "The representation loss after processing this batch is:  6.943847984075546e-05\n",
      "The classification loss after processing this batch is:  65183.2890625\n",
      "The representation loss after processing this batch is:  6.677396595478058e-05\n",
      "The classification loss after processing this batch is:  67749.4375\n",
      "The representation loss after processing this batch is:  6.85378909111023e-05\n",
      "The classification loss after processing this batch is:  66724.078125\n",
      "The representation loss after processing this batch is:  6.744265556335449e-05\n",
      "The classification loss after processing this batch is:  66171.6796875\n",
      "The representation loss after processing this batch is:  7.328111678361893e-05\n",
      "The classification loss after processing this batch is:  66485.078125\n",
      "The representation loss after processing this batch is:  7.540173828601837e-05\n",
      "The classification loss after processing this batch is:  66273.5703125\n",
      "The representation loss after processing this batch is:  6.853695958852768e-05\n",
      "The classification loss after processing this batch is:  64614.92578125\n",
      "The representation loss after processing this batch is:  6.621330976486206e-05\n",
      "The classification loss after processing this batch is:  66630.1875\n",
      "The representation loss after processing this batch is:  7.407646626234055e-05\n",
      "The classification loss after processing this batch is:  70577.375\n",
      "The representation loss after processing this batch is:  6.502028554677963e-05\n",
      "The classification loss after processing this batch is:  65755.5546875\n",
      "The representation loss after processing this batch is:  6.486102938652039e-05\n",
      "The classification loss after processing this batch is:  66651.640625\n",
      "The representation loss after processing this batch is:  6.935372948646545e-05\n",
      "The classification loss after processing this batch is:  65248.328125\n",
      "The representation loss after processing this batch is:  7.278565317392349e-05\n",
      "The classification loss after processing this batch is:  66359.4921875\n",
      "The representation loss after processing this batch is:  6.488338112831116e-05\n",
      "The classification loss after processing this batch is:  67455.75\n",
      "The representation loss after processing this batch is:  7.798243314027786e-05\n",
      "The classification loss after processing this batch is:  66829.78125\n",
      "The representation loss after processing this batch is:  7.326249033212662e-05\n",
      "The classification loss after processing this batch is:  64136.46875\n",
      "The representation loss after processing this batch is:  6.482191383838654e-05\n",
      "The classification loss after processing this batch is:  64893.19140625\n",
      "The representation loss after processing this batch is:  6.824079900979996e-05\n",
      "The classification loss after processing this batch is:  64595.5859375\n",
      "The representation loss after processing this batch is:  7.428508251905441e-05\n",
      "The classification loss after processing this batch is:  64125.4921875\n",
      "The representation loss after processing this batch is:  6.398744881153107e-05\n",
      "The classification loss after processing this batch is:  63306.171875\n",
      "The representation loss after processing this batch is:  6.484799087047577e-05\n",
      "The classification loss after processing this batch is:  64587.71484375\n",
      "The representation loss after processing this batch is:  6.532203406095505e-05\n",
      "The classification loss after processing this batch is:  63870.74609375\n",
      "The representation loss after processing this batch is:  6.831623613834381e-05\n",
      "The classification loss after processing this batch is:  65653.453125\n",
      "The representation loss after processing this batch is:  6.874743849039078e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  63098.1875\n",
      "The representation loss after processing this batch is:  7.057376205921173e-05\n",
      "The classification loss after processing this batch is:  64271.4765625\n",
      "The representation loss after processing this batch is:  6.86226412653923e-05\n",
      "The classification loss after processing this batch is:  65045.359375\n",
      "The representation loss after processing this batch is:  6.656721234321594e-05\n",
      "The classification loss after processing this batch is:  62707.3984375\n",
      "The representation loss after processing this batch is:  7.009971886873245e-05\n",
      "The classification loss after processing this batch is:  64410.5703125\n",
      "The representation loss after processing this batch is:  6.69434666633606e-05\n",
      "The classification loss after processing this batch is:  66911.046875\n",
      "The representation loss after processing this batch is:  6.81169331073761e-05\n",
      "The classification loss after processing this batch is:  62483.640625\n",
      "The representation loss after processing this batch is:  7.073022425174713e-05\n",
      "The classification loss after processing this batch is:  62534.04296875\n",
      "The representation loss after processing this batch is:  6.383005529642105e-05\n",
      "The classification loss after processing this batch is:  63021.25\n",
      "The representation loss after processing this batch is:  6.838236004114151e-05\n",
      "The classification loss after processing this batch is:  67148.90625\n",
      "The representation loss after processing this batch is:  6.742961704730988e-05\n",
      "The classification loss after processing this batch is:  66820.0\n",
      "The representation loss after processing this batch is:  6.155576556921005e-05\n",
      "The classification loss after processing this batch is:  62448.90625\n",
      "The representation loss after processing this batch is:  7.147248834371567e-05\n",
      "The classification loss after processing this batch is:  61757.23046875\n",
      "The representation loss after processing this batch is:  6.926804780960083e-05\n",
      "The classification loss after processing this batch is:  62020.8203125\n",
      "The representation loss after processing this batch is:  6.281957030296326e-05\n",
      "The classification loss after processing this batch is:  61849.8125\n",
      "The representation loss after processing this batch is:  6.439071148633957e-05\n",
      "The classification loss after processing this batch is:  62775.03125\n",
      "The representation loss after processing this batch is:  6.53974711894989e-05\n",
      "The classification loss after processing this batch is:  65703.6328125\n",
      "The representation loss after processing this batch is:  7.10412859916687e-05\n",
      "The classification loss after processing this batch is:  62486.9296875\n",
      "The representation loss after processing this batch is:  6.232503801584244e-05\n",
      "The classification loss after processing this batch is:  62754.625\n",
      "The representation loss after processing this batch is:  7.035303860902786e-05\n",
      "The classification loss after processing this batch is:  63090.53125\n",
      "The representation loss after processing this batch is:  7.299426943063736e-05\n",
      "The classification loss after processing this batch is:  65377.94921875\n",
      "The representation loss after processing this batch is:  6.828363984823227e-05\n",
      "The classification loss after processing this batch is:  62784.10546875\n",
      "The representation loss after processing this batch is:  6.321631371974945e-05\n",
      "The classification loss after processing this batch is:  62821.7578125\n",
      "The representation loss after processing this batch is:  7.183849811553955e-05\n",
      "The classification loss after processing this batch is:  63919.546875\n",
      "The representation loss after processing this batch is:  7.314234972000122e-05\n",
      "The classification loss after processing this batch is:  62762.0390625\n",
      "The representation loss after processing this batch is:  7.249601185321808e-05\n",
      "The classification loss after processing this batch is:  62235.3828125\n",
      "The representation loss after processing this batch is:  6.92000612616539e-05\n",
      "The classification loss after processing this batch is:  63679.9140625\n",
      "The representation loss after processing this batch is:  6.254669278860092e-05\n",
      "The classification loss after processing this batch is:  61014.765625\n",
      "The representation loss after processing this batch is:  6.848480552434921e-05\n",
      "The classification loss after processing this batch is:  60888.953125\n",
      "The representation loss after processing this batch is:  7.326994091272354e-05\n",
      "The classification loss after processing this batch is:  65122.953125\n",
      "The representation loss after processing this batch is:  6.801355630159378e-05\n",
      "The classification loss after processing this batch is:  62579.5546875\n",
      "The representation loss after processing this batch is:  6.746780127286911e-05\n",
      "The classification loss after processing this batch is:  60547.109375\n",
      "The representation loss after processing this batch is:  7.447600364685059e-05\n",
      "The classification loss after processing this batch is:  62718.90625\n",
      "The representation loss after processing this batch is:  6.758328527212143e-05\n",
      "The classification loss after processing this batch is:  62276.37890625\n",
      "The representation loss after processing this batch is:  6.150826811790466e-05\n",
      "The classification loss after processing this batch is:  61726.3359375\n",
      "The representation loss after processing this batch is:  6.264820694923401e-05\n",
      "The classification loss after processing this batch is:  63793.16796875\n",
      "The representation loss after processing this batch is:  6.651133298873901e-05\n",
      "The classification loss after processing this batch is:  61931.8828125\n",
      "The representation loss after processing this batch is:  6.193947046995163e-05\n",
      "The classification loss after processing this batch is:  64663.140625\n",
      "The representation loss after processing this batch is:  6.917957216501236e-05\n",
      "The classification loss after processing this batch is:  61457.46875\n",
      "The representation loss after processing this batch is:  6.36046752333641e-05\n",
      "The classification loss after processing this batch is:  60392.6015625\n",
      "The representation loss after processing this batch is:  6.774161010980606e-05\n",
      "The classification loss after processing this batch is:  61260.4296875\n",
      "The representation loss after processing this batch is:  7.03195109963417e-05\n",
      "The classification loss after processing this batch is:  61253.0625\n",
      "The representation loss after processing this batch is:  6.974581629037857e-05\n",
      "The classification loss after processing this batch is:  61884.40625\n",
      "The representation loss after processing this batch is:  7.08429142832756e-05\n",
      "The classification loss after processing this batch is:  60596.6875\n",
      "The representation loss after processing this batch is:  6.721913814544678e-05\n",
      "The classification loss after processing this batch is:  61485.9453125\n",
      "The representation loss after processing this batch is:  6.630178540945053e-05\n",
      "The classification loss after processing this batch is:  61662.94140625\n",
      "The representation loss after processing this batch is:  6.769876927137375e-05\n",
      "The classification loss after processing this batch is:  60539.34375\n",
      "The representation loss after processing this batch is:  6.419606506824493e-05\n",
      "The classification loss after processing this batch is:  62838.640625\n",
      "The representation loss after processing this batch is:  6.974861025810242e-05\n",
      "The classification loss after processing this batch is:  59057.671875\n",
      "The representation loss after processing this batch is:  7.522944360971451e-05\n",
      "The classification loss after processing this batch is:  58912.26953125\n",
      "The representation loss after processing this batch is:  6.276648491621017e-05\n",
      "The classification loss after processing this batch is:  60467.5078125\n",
      "The representation loss after processing this batch is:  6.530527025461197e-05\n",
      "The classification loss after processing this batch is:  60998.65234375\n",
      "The representation loss after processing this batch is:  6.735138595104218e-05\n",
      "The classification loss after processing this batch is:  59096.9765625\n",
      "The representation loss after processing this batch is:  6.542541086673737e-05\n",
      "The classification loss after processing this batch is:  60050.2109375\n",
      "The representation loss after processing this batch is:  6.395764648914337e-05\n",
      "The classification loss after processing this batch is:  60415.4765625\n",
      "The representation loss after processing this batch is:  6.533507257699966e-05\n",
      "The classification loss after processing this batch is:  59148.4765625\n",
      "The representation loss after processing this batch is:  6.867386400699615e-05\n",
      "The classification loss after processing this batch is:  61192.796875\n",
      "The representation loss after processing this batch is:  7.488857954740524e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  59155.14453125\n",
      "The representation loss after processing this batch is:  6.170570850372314e-05\n",
      "The classification loss after processing this batch is:  61406.9921875\n",
      "The representation loss after processing this batch is:  6.705895066261292e-05\n",
      "The classification loss after processing this batch is:  58310.1015625\n",
      "The representation loss after processing this batch is:  7.006805390119553e-05\n",
      "The classification loss after processing this batch is:  58192.625\n",
      "The representation loss after processing this batch is:  6.77984207868576e-05\n",
      "The classification loss after processing this batch is:  60038.53515625\n",
      "The representation loss after processing this batch is:  6.755813956260681e-05\n",
      "The classification loss after processing this batch is:  58823.859375\n",
      "The representation loss after processing this batch is:  6.986036896705627e-05\n",
      "The classification loss after processing this batch is:  59044.6328125\n",
      "The representation loss after processing this batch is:  6.548315286636353e-05\n",
      "The classification loss after processing this batch is:  60082.4375\n",
      "The representation loss after processing this batch is:  7.178448140621185e-05\n",
      "The classification loss after processing this batch is:  61440.27734375\n",
      "The representation loss after processing this batch is:  6.617419421672821e-05\n",
      "The classification loss after processing this batch is:  56824.1875\n",
      "The representation loss after processing this batch is:  6.804428994655609e-05\n",
      "The classification loss after processing this batch is:  60397.7578125\n",
      "The representation loss after processing this batch is:  6.636511534452438e-05\n",
      "The classification loss after processing this batch is:  61858.21875\n",
      "The representation loss after processing this batch is:  6.61313533782959e-05\n",
      "The classification loss after processing this batch is:  58046.6953125\n",
      "The representation loss after processing this batch is:  6.664730608463287e-05\n",
      "The classification loss after processing this batch is:  59518.7890625\n",
      "The representation loss after processing this batch is:  6.509851664304733e-05\n",
      "The classification loss after processing this batch is:  61975.4609375\n",
      "The representation loss after processing this batch is:  7.444154471158981e-05\n",
      "The classification loss after processing this batch is:  59835.67578125\n",
      "The representation loss after processing this batch is:  7.464922964572906e-05\n",
      "The classification loss after processing this batch is:  58721.625\n",
      "The representation loss after processing this batch is:  7.30808824300766e-05\n",
      "The classification loss after processing this batch is:  57681.2421875\n",
      "The representation loss after processing this batch is:  7.518287748098373e-05\n",
      "The classification loss after processing this batch is:  62607.04296875\n",
      "The representation loss after processing this batch is:  7.446762174367905e-05\n",
      "The classification loss after processing this batch is:  61388.80078125\n",
      "The representation loss after processing this batch is:  6.86105340719223e-05\n",
      "The classification loss after processing this batch is:  60727.984375\n",
      "The representation loss after processing this batch is:  6.899610161781311e-05\n",
      "The classification loss after processing this batch is:  26502.3671875\n",
      "The representation loss after processing this batch is:  4.834565334022045e-05\n",
      "the loss after processing this epoch is:  0.17469114065170288\n",
      "the loss after processing this epoch is:  0.17021562159061432\n",
      "the loss after processing this epoch is:  0.1002032607793808\n",
      "the loss after processing this epoch is:  0.018018465489149094\n",
      "the loss after processing this epoch is:  0.0029216904658824205\n",
      "the loss after processing this epoch is:  0.0003545780782587826\n",
      "the loss after processing this epoch is:  0.0003034671244677156\n",
      "the loss after processing this epoch is:  0.00020781159400939941\n",
      "the loss after processing this epoch is:  0.00013167658471502364\n",
      "the loss after processing this epoch is:  8.81950109032914e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: Using a target size (torch.Size([128, 784])) that is different to the input size (torch.Size([128, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  29557.9296875\n",
      "The representation loss after processing this batch is:  0.0006529917009174824\n",
      "The classification loss after processing this batch is:  30029.6640625\n",
      "The representation loss after processing this batch is:  0.0004587369039654732\n",
      "The classification loss after processing this batch is:  28700.19921875\n",
      "The representation loss after processing this batch is:  0.0005044876597821712\n",
      "The classification loss after processing this batch is:  29762.185546875\n",
      "The representation loss after processing this batch is:  0.00041428767144680023\n",
      "The classification loss after processing this batch is:  31402.455078125\n",
      "The representation loss after processing this batch is:  0.0004945327527821064\n",
      "The classification loss after processing this batch is:  31519.90234375\n",
      "The representation loss after processing this batch is:  0.000363299623131752\n",
      "The classification loss after processing this batch is:  31507.107421875\n",
      "The representation loss after processing this batch is:  0.000425639096647501\n",
      "The classification loss after processing this batch is:  31937.31640625\n",
      "The representation loss after processing this batch is:  0.00028861314058303833\n",
      "The classification loss after processing this batch is:  32122.12890625\n",
      "The representation loss after processing this batch is:  0.00037354230880737305\n",
      "The classification loss after processing this batch is:  34811.94921875\n",
      "The representation loss after processing this batch is:  0.00033925939351320267\n",
      "The classification loss after processing this batch is:  34308.15625\n",
      "The representation loss after processing this batch is:  0.00023416709154844284\n",
      "The classification loss after processing this batch is:  33640.484375\n",
      "The representation loss after processing this batch is:  0.00024717580527067184\n",
      "The classification loss after processing this batch is:  34111.84765625\n",
      "The representation loss after processing this batch is:  0.00021449103951454163\n",
      "The classification loss after processing this batch is:  34056.65625\n",
      "The representation loss after processing this batch is:  0.0002207774668931961\n",
      "The classification loss after processing this batch is:  34203.3515625\n",
      "The representation loss after processing this batch is:  0.00022992584854364395\n",
      "The classification loss after processing this batch is:  34974.75\n",
      "The representation loss after processing this batch is:  0.0002709142863750458\n",
      "The classification loss after processing this batch is:  34944.6875\n",
      "The representation loss after processing this batch is:  0.00025875773280858994\n",
      "The classification loss after processing this batch is:  36248.2421875\n",
      "The representation loss after processing this batch is:  0.0003288472071290016\n",
      "The classification loss after processing this batch is:  36051.515625\n",
      "The representation loss after processing this batch is:  0.00028206687420606613\n",
      "The classification loss after processing this batch is:  36528.25\n",
      "The representation loss after processing this batch is:  0.0002170037478208542\n",
      "The classification loss after processing this batch is:  36077.3671875\n",
      "The representation loss after processing this batch is:  0.0002086944878101349\n",
      "The classification loss after processing this batch is:  36216.16015625\n",
      "The representation loss after processing this batch is:  0.0002058008685708046\n",
      "The classification loss after processing this batch is:  36575.1015625\n",
      "The representation loss after processing this batch is:  0.0002638101577758789\n",
      "The classification loss after processing this batch is:  35482.8828125\n",
      "The representation loss after processing this batch is:  0.00020825862884521484\n",
      "The classification loss after processing this batch is:  34528.6015625\n",
      "The representation loss after processing this batch is:  0.0001843385398387909\n",
      "The classification loss after processing this batch is:  33599.2578125\n",
      "The representation loss after processing this batch is:  0.00020333752036094666\n",
      "The classification loss after processing this batch is:  34716.00390625\n",
      "The representation loss after processing this batch is:  0.00018284283578395844\n",
      "The classification loss after processing this batch is:  34918.0625\n",
      "The representation loss after processing this batch is:  0.0001819208264350891\n",
      "The classification loss after processing this batch is:  39410.2578125\n",
      "The representation loss after processing this batch is:  0.00017667748034000397\n",
      "The classification loss after processing this batch is:  36150.3046875\n",
      "The representation loss after processing this batch is:  0.00016660802066326141\n",
      "The classification loss after processing this batch is:  34300.7109375\n",
      "The representation loss after processing this batch is:  0.00014886073768138885\n",
      "The classification loss after processing this batch is:  34639.4453125\n",
      "The representation loss after processing this batch is:  0.00016949698328971863\n",
      "The classification loss after processing this batch is:  34112.6953125\n",
      "The representation loss after processing this batch is:  0.00017875432968139648\n",
      "The classification loss after processing this batch is:  34134.13671875\n",
      "The representation loss after processing this batch is:  0.00017608515918254852\n",
      "The classification loss after processing this batch is:  34651.63671875\n",
      "The representation loss after processing this batch is:  0.0001590251922607422\n",
      "The classification loss after processing this batch is:  34271.71875\n",
      "The representation loss after processing this batch is:  0.00019449181854724884\n",
      "The classification loss after processing this batch is:  35852.234375\n",
      "The representation loss after processing this batch is:  0.00019739754498004913\n",
      "The classification loss after processing this batch is:  38182.1484375\n",
      "The representation loss after processing this batch is:  0.0002055913209915161\n",
      "The classification loss after processing this batch is:  33406.83984375\n",
      "The representation loss after processing this batch is:  0.0001495741307735443\n",
      "The classification loss after processing this batch is:  33798.82421875\n",
      "The representation loss after processing this batch is:  0.0001669079065322876\n",
      "The classification loss after processing this batch is:  34406.65625\n",
      "The representation loss after processing this batch is:  0.0001665055751800537\n",
      "The classification loss after processing this batch is:  34200.1484375\n",
      "The representation loss after processing this batch is:  0.0001636296510696411\n",
      "The classification loss after processing this batch is:  33166.734375\n",
      "The representation loss after processing this batch is:  0.00016298703849315643\n",
      "The classification loss after processing this batch is:  33194.9765625\n",
      "The representation loss after processing this batch is:  0.0001933220773935318\n",
      "The classification loss after processing this batch is:  32784.9296875\n",
      "The representation loss after processing this batch is:  0.0001600552350282669\n",
      "The classification loss after processing this batch is:  31641.353515625\n",
      "The representation loss after processing this batch is:  0.0001685265451669693\n",
      "The classification loss after processing this batch is:  32169.77734375\n",
      "The representation loss after processing this batch is:  0.00015885382890701294\n",
      "The classification loss after processing this batch is:  33717.1953125\n",
      "The representation loss after processing this batch is:  0.0001633334904909134\n",
      "The classification loss after processing this batch is:  32541.453125\n",
      "The representation loss after processing this batch is:  0.0001460593193769455\n",
      "The classification loss after processing this batch is:  32117.38671875\n",
      "The representation loss after processing this batch is:  0.00018612854182720184\n",
      "The classification loss after processing this batch is:  32031.810546875\n",
      "The representation loss after processing this batch is:  0.00016241520643234253\n",
      "The classification loss after processing this batch is:  30744.01171875\n",
      "The representation loss after processing this batch is:  0.00015997514128684998\n",
      "The classification loss after processing this batch is:  30704.71484375\n",
      "The representation loss after processing this batch is:  0.00017754919826984406\n",
      "The classification loss after processing this batch is:  30891.99609375\n",
      "The representation loss after processing this batch is:  0.00015965383499860764\n",
      "The classification loss after processing this batch is:  31321.458984375\n",
      "The representation loss after processing this batch is:  0.0001581590622663498\n",
      "The classification loss after processing this batch is:  30913.701171875\n",
      "The representation loss after processing this batch is:  0.00019082799553871155\n",
      "The classification loss after processing this batch is:  32546.345703125\n",
      "The representation loss after processing this batch is:  0.00020522624254226685\n",
      "The classification loss after processing this batch is:  30687.10546875\n",
      "The representation loss after processing this batch is:  0.00019286386668682098\n",
      "The classification loss after processing this batch is:  30073.025390625\n",
      "The representation loss after processing this batch is:  0.00018868036568164825\n",
      "The classification loss after processing this batch is:  31004.1796875\n",
      "The representation loss after processing this batch is:  0.00017198361456394196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  31946.39453125\n",
      "The representation loss after processing this batch is:  0.00018418394029140472\n",
      "The classification loss after processing this batch is:  33366.078125\n",
      "The representation loss after processing this batch is:  0.00015495624393224716\n",
      "The classification loss after processing this batch is:  32492.912109375\n",
      "The representation loss after processing this batch is:  0.00013692863285541534\n",
      "The classification loss after processing this batch is:  30312.935546875\n",
      "The representation loss after processing this batch is:  0.0001552775502204895\n",
      "The classification loss after processing this batch is:  31085.63671875\n",
      "The representation loss after processing this batch is:  0.00016319192945957184\n",
      "The classification loss after processing this batch is:  30929.7421875\n",
      "The representation loss after processing this batch is:  0.00013973936438560486\n",
      "The classification loss after processing this batch is:  31975.994140625\n",
      "The representation loss after processing this batch is:  0.00016230344772338867\n",
      "The classification loss after processing this batch is:  32443.494140625\n",
      "The representation loss after processing this batch is:  0.0001549050211906433\n",
      "The classification loss after processing this batch is:  30604.5625\n",
      "The representation loss after processing this batch is:  0.00015096738934516907\n",
      "The classification loss after processing this batch is:  30470.87890625\n",
      "The representation loss after processing this batch is:  0.00016408227384090424\n",
      "The classification loss after processing this batch is:  30587.62890625\n",
      "The representation loss after processing this batch is:  0.00014906376600265503\n",
      "The classification loss after processing this batch is:  30567.25390625\n",
      "The representation loss after processing this batch is:  0.00016955286264419556\n",
      "The classification loss after processing this batch is:  29420.0546875\n",
      "The representation loss after processing this batch is:  0.00016260705888271332\n",
      "The classification loss after processing this batch is:  32549.146484375\n",
      "The representation loss after processing this batch is:  0.00014341995120048523\n",
      "The classification loss after processing this batch is:  32399.30078125\n",
      "The representation loss after processing this batch is:  0.00014372169971466064\n",
      "The classification loss after processing this batch is:  32008.873046875\n",
      "The representation loss after processing this batch is:  0.0001664813607931137\n",
      "The classification loss after processing this batch is:  31293.099609375\n",
      "The representation loss after processing this batch is:  0.00013615190982818604\n",
      "The classification loss after processing this batch is:  31114.490234375\n",
      "The representation loss after processing this batch is:  0.0001659821718931198\n",
      "The classification loss after processing this batch is:  30818.986328125\n",
      "The representation loss after processing this batch is:  0.00014242902398109436\n",
      "The classification loss after processing this batch is:  31076.138671875\n",
      "The representation loss after processing this batch is:  0.00014098547399044037\n",
      "The classification loss after processing this batch is:  31024.8515625\n",
      "The representation loss after processing this batch is:  0.00014786049723625183\n",
      "The classification loss after processing this batch is:  30808.79296875\n",
      "The representation loss after processing this batch is:  0.00019256584346294403\n",
      "The classification loss after processing this batch is:  30128.091796875\n",
      "The representation loss after processing this batch is:  0.00013662688434123993\n",
      "The classification loss after processing this batch is:  30480.296875\n",
      "The representation loss after processing this batch is:  0.0001642610877752304\n",
      "The classification loss after processing this batch is:  29216.423828125\n",
      "The representation loss after processing this batch is:  0.0001362152397632599\n",
      "The classification loss after processing this batch is:  29254.5078125\n",
      "The representation loss after processing this batch is:  0.00013816356658935547\n",
      "The classification loss after processing this batch is:  30080.52734375\n",
      "The representation loss after processing this batch is:  0.00015475787222385406\n",
      "The classification loss after processing this batch is:  29214.92578125\n",
      "The representation loss after processing this batch is:  0.00013324059545993805\n",
      "The classification loss after processing this batch is:  28835.9453125\n",
      "The representation loss after processing this batch is:  0.00015505962073802948\n",
      "The classification loss after processing this batch is:  29125.228515625\n",
      "The representation loss after processing this batch is:  0.00015475042164325714\n",
      "The classification loss after processing this batch is:  29724.3125\n",
      "The representation loss after processing this batch is:  0.00014324486255645752\n",
      "The classification loss after processing this batch is:  29061.4921875\n",
      "The representation loss after processing this batch is:  0.00016630254685878754\n",
      "The classification loss after processing this batch is:  29256.171875\n",
      "The representation loss after processing this batch is:  0.00014477595686912537\n",
      "The classification loss after processing this batch is:  28805.328125\n",
      "The representation loss after processing this batch is:  0.00014272145926952362\n",
      "The classification loss after processing this batch is:  28601.953125\n",
      "The representation loss after processing this batch is:  0.00013995543122291565\n",
      "The classification loss after processing this batch is:  30133.71484375\n",
      "The representation loss after processing this batch is:  0.00013489369302988052\n",
      "The classification loss after processing this batch is:  30088.880859375\n",
      "The representation loss after processing this batch is:  0.0001565590500831604\n",
      "The classification loss after processing this batch is:  30580.572265625\n",
      "The representation loss after processing this batch is:  0.000144127756357193\n",
      "The classification loss after processing this batch is:  30943.4375\n",
      "The representation loss after processing this batch is:  0.00014453940093517303\n",
      "The classification loss after processing this batch is:  31252.296875\n",
      "The representation loss after processing this batch is:  0.00015666894614696503\n",
      "The classification loss after processing this batch is:  30475.6171875\n",
      "The representation loss after processing this batch is:  0.00014075078070163727\n",
      "The classification loss after processing this batch is:  30532.8515625\n",
      "The representation loss after processing this batch is:  0.00015237368643283844\n",
      "The classification loss after processing this batch is:  30328.34375\n",
      "The representation loss after processing this batch is:  0.00016856007277965546\n",
      "The classification loss after processing this batch is:  30118.712890625\n",
      "The representation loss after processing this batch is:  0.00014150328934192657\n",
      "The classification loss after processing this batch is:  29330.98828125\n",
      "The representation loss after processing this batch is:  0.0001458302140235901\n",
      "The classification loss after processing this batch is:  29171.2578125\n",
      "The representation loss after processing this batch is:  0.00013939663767814636\n",
      "The classification loss after processing this batch is:  29555.12109375\n",
      "The representation loss after processing this batch is:  0.00013226084411144257\n",
      "The classification loss after processing this batch is:  28855.251953125\n",
      "The representation loss after processing this batch is:  0.000157160684466362\n",
      "The classification loss after processing this batch is:  29494.84765625\n",
      "The representation loss after processing this batch is:  0.0001413244754076004\n",
      "The classification loss after processing this batch is:  30288.2109375\n",
      "The representation loss after processing this batch is:  0.00014451518654823303\n",
      "The classification loss after processing this batch is:  33895.4375\n",
      "The representation loss after processing this batch is:  0.00013781525194644928\n",
      "The classification loss after processing this batch is:  30378.89453125\n",
      "The representation loss after processing this batch is:  0.00013324245810508728\n",
      "The classification loss after processing this batch is:  29290.421875\n",
      "The representation loss after processing this batch is:  0.00014104880392551422\n",
      "The classification loss after processing this batch is:  29496.58203125\n",
      "The representation loss after processing this batch is:  0.0001452416181564331\n",
      "The classification loss after processing this batch is:  31918.15234375\n",
      "The representation loss after processing this batch is:  0.00016329996287822723\n",
      "The classification loss after processing this batch is:  32075.94921875\n",
      "The representation loss after processing this batch is:  0.00017856992781162262\n",
      "The classification loss after processing this batch is:  29316.01953125\n",
      "The representation loss after processing this batch is:  0.00014419667422771454\n",
      "The classification loss after processing this batch is:  29303.474609375\n",
      "The representation loss after processing this batch is:  0.0001544170081615448\n",
      "The classification loss after processing this batch is:  29720.783203125\n",
      "The representation loss after processing this batch is:  0.00014770962297916412\n",
      "The classification loss after processing this batch is:  30468.30078125\n",
      "The representation loss after processing this batch is:  0.0001617036759853363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  30024.47265625\n",
      "The representation loss after processing this batch is:  0.0001408196985721588\n",
      "The classification loss after processing this batch is:  29521.6875\n",
      "The representation loss after processing this batch is:  0.0001398082822561264\n",
      "The classification loss after processing this batch is:  30483.78125\n",
      "The representation loss after processing this batch is:  0.00013331416994333267\n",
      "The classification loss after processing this batch is:  30958.04296875\n",
      "The representation loss after processing this batch is:  0.0001642182469367981\n",
      "The classification loss after processing this batch is:  28851.4140625\n",
      "The representation loss after processing this batch is:  0.00015493668615818024\n",
      "The classification loss after processing this batch is:  29625.2890625\n",
      "The representation loss after processing this batch is:  0.0001511741429567337\n",
      "The classification loss after processing this batch is:  28839.29296875\n",
      "The representation loss after processing this batch is:  0.00014693662524223328\n",
      "The classification loss after processing this batch is:  30165.962890625\n",
      "The representation loss after processing this batch is:  0.00016145594418048859\n",
      "The classification loss after processing this batch is:  28936.408203125\n",
      "The representation loss after processing this batch is:  0.00017757155001163483\n",
      "The classification loss after processing this batch is:  31161.4453125\n",
      "The representation loss after processing this batch is:  0.0001810118556022644\n",
      "The classification loss after processing this batch is:  29714.9921875\n",
      "The representation loss after processing this batch is:  0.0001417268067598343\n",
      "The classification loss after processing this batch is:  30969.1015625\n",
      "The representation loss after processing this batch is:  0.0001720283180475235\n",
      "The classification loss after processing this batch is:  28526.90234375\n",
      "The representation loss after processing this batch is:  0.00016517378389835358\n",
      "The classification loss after processing this batch is:  28524.130859375\n",
      "The representation loss after processing this batch is:  0.00013527274131774902\n",
      "The classification loss after processing this batch is:  31380.548828125\n",
      "The representation loss after processing this batch is:  0.0001497305929660797\n",
      "The classification loss after processing this batch is:  30246.44140625\n",
      "The representation loss after processing this batch is:  0.0001472514122724533\n",
      "The classification loss after processing this batch is:  29339.810546875\n",
      "The representation loss after processing this batch is:  0.00014674849808216095\n",
      "The classification loss after processing this batch is:  30464.208984375\n",
      "The representation loss after processing this batch is:  0.00015800446271896362\n",
      "The classification loss after processing this batch is:  29004.43359375\n",
      "The representation loss after processing this batch is:  0.00013958290219306946\n",
      "The classification loss after processing this batch is:  29491.2265625\n",
      "The representation loss after processing this batch is:  0.00018090754747390747\n",
      "The classification loss after processing this batch is:  28562.875\n",
      "The representation loss after processing this batch is:  0.00013074278831481934\n",
      "The classification loss after processing this batch is:  28042.630859375\n",
      "The representation loss after processing this batch is:  0.00012744776904582977\n",
      "The classification loss after processing this batch is:  27822.02734375\n",
      "The representation loss after processing this batch is:  0.0001507159322500229\n",
      "The classification loss after processing this batch is:  27919.453125\n",
      "The representation loss after processing this batch is:  0.00016945227980613708\n",
      "The classification loss after processing this batch is:  28596.630859375\n",
      "The representation loss after processing this batch is:  0.0001683402806520462\n",
      "The classification loss after processing this batch is:  31755.6796875\n",
      "The representation loss after processing this batch is:  0.0001406446099281311\n",
      "The classification loss after processing this batch is:  29207.193359375\n",
      "The representation loss after processing this batch is:  0.00015434995293617249\n",
      "The classification loss after processing this batch is:  29559.3359375\n",
      "The representation loss after processing this batch is:  0.00014659017324447632\n",
      "The classification loss after processing this batch is:  29976.77734375\n",
      "The representation loss after processing this batch is:  0.00014040805399417877\n",
      "The classification loss after processing this batch is:  29130.501953125\n",
      "The representation loss after processing this batch is:  0.00013452768325805664\n",
      "The classification loss after processing this batch is:  29755.33203125\n",
      "The representation loss after processing this batch is:  0.00016206316649913788\n",
      "The classification loss after processing this batch is:  29860.349609375\n",
      "The representation loss after processing this batch is:  0.00014124251902103424\n",
      "The classification loss after processing this batch is:  29973.3671875\n",
      "The representation loss after processing this batch is:  0.00015343911945819855\n",
      "The classification loss after processing this batch is:  28071.173828125\n",
      "The representation loss after processing this batch is:  0.00013768300414085388\n",
      "The classification loss after processing this batch is:  29335.72265625\n",
      "The representation loss after processing this batch is:  0.0001299288123846054\n",
      "The classification loss after processing this batch is:  32647.814453125\n",
      "The representation loss after processing this batch is:  0.00014164112508296967\n",
      "The classification loss after processing this batch is:  33096.15234375\n",
      "The representation loss after processing this batch is:  0.00015419349074363708\n",
      "The classification loss after processing this batch is:  29675.375\n",
      "The representation loss after processing this batch is:  0.00012183934450149536\n",
      "The classification loss after processing this batch is:  29423.55078125\n",
      "The representation loss after processing this batch is:  0.00014336593449115753\n",
      "The classification loss after processing this batch is:  28952.802734375\n",
      "The representation loss after processing this batch is:  0.00012995116412639618\n",
      "The classification loss after processing this batch is:  29941.89453125\n",
      "The representation loss after processing this batch is:  0.00014663860201835632\n",
      "The classification loss after processing this batch is:  28596.759765625\n",
      "The representation loss after processing this batch is:  0.00014336220920085907\n",
      "The classification loss after processing this batch is:  28604.7734375\n",
      "The representation loss after processing this batch is:  0.0001428760588169098\n",
      "The classification loss after processing this batch is:  30659.861328125\n",
      "The representation loss after processing this batch is:  0.00012271106243133545\n",
      "The classification loss after processing this batch is:  27497.6484375\n",
      "The representation loss after processing this batch is:  0.0001424066722393036\n",
      "The classification loss after processing this batch is:  28472.708984375\n",
      "The representation loss after processing this batch is:  0.00013033859431743622\n",
      "The classification loss after processing this batch is:  31166.94140625\n",
      "The representation loss after processing this batch is:  0.0001572202891111374\n",
      "The classification loss after processing this batch is:  29817.03515625\n",
      "The representation loss after processing this batch is:  0.0001463480293750763\n",
      "The classification loss after processing this batch is:  28412.416015625\n",
      "The representation loss after processing this batch is:  0.0001478828489780426\n",
      "The classification loss after processing this batch is:  27688.619140625\n",
      "The representation loss after processing this batch is:  0.0001452900469303131\n",
      "The classification loss after processing this batch is:  29652.158203125\n",
      "The representation loss after processing this batch is:  0.00014420226216316223\n",
      "The classification loss after processing this batch is:  29379.599609375\n",
      "The representation loss after processing this batch is:  0.0001802649348974228\n",
      "The classification loss after processing this batch is:  34726.3515625\n",
      "The representation loss after processing this batch is:  0.00016509927809238434\n",
      "The classification loss after processing this batch is:  30276.73046875\n",
      "The representation loss after processing this batch is:  0.00014284439384937286\n",
      "The classification loss after processing this batch is:  29296.177734375\n",
      "The representation loss after processing this batch is:  0.00014913268387317657\n",
      "The classification loss after processing this batch is:  30880.826171875\n",
      "The representation loss after processing this batch is:  0.00015097949653863907\n",
      "The classification loss after processing this batch is:  32071.1640625\n",
      "The representation loss after processing this batch is:  0.00016630440950393677\n",
      "The classification loss after processing this batch is:  31207.501953125\n",
      "The representation loss after processing this batch is:  0.00015690084546804428\n",
      "The classification loss after processing this batch is:  30170.33203125\n",
      "The representation loss after processing this batch is:  0.0001450125128030777\n",
      "The classification loss after processing this batch is:  30093.125\n",
      "The representation loss after processing this batch is:  0.00013062730431556702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  30049.98828125\n",
      "The representation loss after processing this batch is:  0.0001404210925102234\n",
      "The classification loss after processing this batch is:  28426.41796875\n",
      "The representation loss after processing this batch is:  0.00013721920549869537\n",
      "The classification loss after processing this batch is:  29662.64453125\n",
      "The representation loss after processing this batch is:  0.00016104988753795624\n",
      "The classification loss after processing this batch is:  29308.634765625\n",
      "The representation loss after processing this batch is:  0.00015440769493579865\n",
      "The classification loss after processing this batch is:  29883.845703125\n",
      "The representation loss after processing this batch is:  0.00015140697360038757\n",
      "The classification loss after processing this batch is:  30579.9921875\n",
      "The representation loss after processing this batch is:  0.00013405457139015198\n",
      "The classification loss after processing this batch is:  30553.732421875\n",
      "The representation loss after processing this batch is:  0.00014589354395866394\n",
      "The classification loss after processing this batch is:  28461.494140625\n",
      "The representation loss after processing this batch is:  0.00014687702059745789\n",
      "The classification loss after processing this batch is:  27701.599609375\n",
      "The representation loss after processing this batch is:  0.00017082318663597107\n",
      "The classification loss after processing this batch is:  28959.9765625\n",
      "The representation loss after processing this batch is:  0.00013984739780426025\n",
      "The classification loss after processing this batch is:  28762.71484375\n",
      "The representation loss after processing this batch is:  0.000131288543343544\n",
      "The classification loss after processing this batch is:  30403.16015625\n",
      "The representation loss after processing this batch is:  0.00013259798288345337\n",
      "The classification loss after processing this batch is:  29599.2890625\n",
      "The representation loss after processing this batch is:  0.00013624131679534912\n",
      "The classification loss after processing this batch is:  28479.353515625\n",
      "The representation loss after processing this batch is:  0.00014787539839744568\n",
      "The classification loss after processing this batch is:  27822.77734375\n",
      "The representation loss after processing this batch is:  0.00014584511518478394\n",
      "The classification loss after processing this batch is:  28019.68359375\n",
      "The representation loss after processing this batch is:  0.000141805037856102\n",
      "The classification loss after processing this batch is:  29480.28125\n",
      "The representation loss after processing this batch is:  0.00013924576342105865\n",
      "The classification loss after processing this batch is:  30345.009765625\n",
      "The representation loss after processing this batch is:  0.0001294948160648346\n",
      "The classification loss after processing this batch is:  29883.228515625\n",
      "The representation loss after processing this batch is:  0.00016576983034610748\n",
      "The classification loss after processing this batch is:  28141.1328125\n",
      "The representation loss after processing this batch is:  0.0001315530389547348\n",
      "The classification loss after processing this batch is:  29167.037109375\n",
      "The representation loss after processing this batch is:  0.0001520104706287384\n",
      "The classification loss after processing this batch is:  28123.095703125\n",
      "The representation loss after processing this batch is:  0.00016629137098789215\n",
      "The classification loss after processing this batch is:  28249.65625\n",
      "The representation loss after processing this batch is:  0.00017495639622211456\n",
      "The classification loss after processing this batch is:  27959.9296875\n",
      "The representation loss after processing this batch is:  0.00013945065438747406\n",
      "The classification loss after processing this batch is:  28078.2578125\n",
      "The representation loss after processing this batch is:  0.00014740228652954102\n",
      "The classification loss after processing this batch is:  28361.869140625\n",
      "The representation loss after processing this batch is:  0.00013026781380176544\n",
      "The classification loss after processing this batch is:  28693.01953125\n",
      "The representation loss after processing this batch is:  0.00013864971697330475\n",
      "The classification loss after processing this batch is:  28859.060546875\n",
      "The representation loss after processing this batch is:  0.00016812793910503387\n",
      "The classification loss after processing this batch is:  29268.421875\n",
      "The representation loss after processing this batch is:  0.0001383768394589424\n",
      "The classification loss after processing this batch is:  28441.63671875\n",
      "The representation loss after processing this batch is:  0.0001652240753173828\n",
      "The classification loss after processing this batch is:  28205.2265625\n",
      "The representation loss after processing this batch is:  0.00013926252722740173\n",
      "The classification loss after processing this batch is:  29865.98828125\n",
      "The representation loss after processing this batch is:  0.00015143118798732758\n",
      "The classification loss after processing this batch is:  30926.859375\n",
      "The representation loss after processing this batch is:  0.00019341520965099335\n",
      "The classification loss after processing this batch is:  30302.025390625\n",
      "The representation loss after processing this batch is:  0.00015763193368911743\n",
      "The classification loss after processing this batch is:  30638.203125\n",
      "The representation loss after processing this batch is:  0.0001496579498052597\n",
      "The classification loss after processing this batch is:  29236.296875\n",
      "The representation loss after processing this batch is:  0.00011651404201984406\n",
      "The classification loss after processing this batch is:  29440.828125\n",
      "The representation loss after processing this batch is:  0.00012819841504096985\n",
      "The classification loss after processing this batch is:  30232.453125\n",
      "The representation loss after processing this batch is:  0.00014147348701953888\n",
      "The classification loss after processing this batch is:  28942.1015625\n",
      "The representation loss after processing this batch is:  0.00016361288726329803\n",
      "The classification loss after processing this batch is:  28754.78125\n",
      "The representation loss after processing this batch is:  0.00011659041047096252\n",
      "The classification loss after processing this batch is:  29765.787109375\n",
      "The representation loss after processing this batch is:  0.00012809596955776215\n",
      "The classification loss after processing this batch is:  29235.16015625\n",
      "The representation loss after processing this batch is:  0.00012680143117904663\n",
      "The classification loss after processing this batch is:  29211.38671875\n",
      "The representation loss after processing this batch is:  0.00013718381524085999\n",
      "The classification loss after processing this batch is:  28406.763671875\n",
      "The representation loss after processing this batch is:  0.00012915953993797302\n",
      "The classification loss after processing this batch is:  29658.21875\n",
      "The representation loss after processing this batch is:  0.0001421608030796051\n",
      "The classification loss after processing this batch is:  30056.05078125\n",
      "The representation loss after processing this batch is:  0.00015477091073989868\n",
      "The classification loss after processing this batch is:  30471.3046875\n",
      "The representation loss after processing this batch is:  0.00012882240116596222\n",
      "The classification loss after processing this batch is:  30117.6875\n",
      "The representation loss after processing this batch is:  0.000143405981361866\n",
      "The classification loss after processing this batch is:  29111.91015625\n",
      "The representation loss after processing this batch is:  0.00012925826013088226\n",
      "The classification loss after processing this batch is:  28538.83984375\n",
      "The representation loss after processing this batch is:  0.00014314986765384674\n",
      "The classification loss after processing this batch is:  28997.736328125\n",
      "The representation loss after processing this batch is:  0.00015438906848430634\n",
      "The classification loss after processing this batch is:  28226.228515625\n",
      "The representation loss after processing this batch is:  0.00013242103159427643\n",
      "The classification loss after processing this batch is:  27893.609375\n",
      "The representation loss after processing this batch is:  0.0001533040776848793\n",
      "The classification loss after processing this batch is:  27568.390625\n",
      "The representation loss after processing this batch is:  0.00013374537229537964\n",
      "The classification loss after processing this batch is:  28582.5\n",
      "The representation loss after processing this batch is:  0.00013623572885990143\n",
      "The classification loss after processing this batch is:  28971.486328125\n",
      "The representation loss after processing this batch is:  0.00016318075358867645\n",
      "The classification loss after processing this batch is:  32110.830078125\n",
      "The representation loss after processing this batch is:  0.00017482973635196686\n",
      "The classification loss after processing this batch is:  30854.66796875\n",
      "The representation loss after processing this batch is:  0.00013524480164051056\n",
      "The classification loss after processing this batch is:  28784.408203125\n",
      "The representation loss after processing this batch is:  0.00016309786587953568\n",
      "The classification loss after processing this batch is:  27902.63671875\n",
      "The representation loss after processing this batch is:  0.00013365596532821655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  27981.361328125\n",
      "The representation loss after processing this batch is:  0.0001258552074432373\n",
      "The classification loss after processing this batch is:  28297.904296875\n",
      "The representation loss after processing this batch is:  0.00018123909831047058\n",
      "The classification loss after processing this batch is:  28259.353515625\n",
      "The representation loss after processing this batch is:  0.00016522593796253204\n",
      "The classification loss after processing this batch is:  28665.3203125\n",
      "The representation loss after processing this batch is:  0.000137966126203537\n",
      "The classification loss after processing this batch is:  29454.83203125\n",
      "The representation loss after processing this batch is:  0.0001443270593881607\n",
      "The classification loss after processing this batch is:  28267.78515625\n",
      "The representation loss after processing this batch is:  0.00012027472257614136\n",
      "The classification loss after processing this batch is:  27822.4375\n",
      "The representation loss after processing this batch is:  0.00014832057058811188\n",
      "The classification loss after processing this batch is:  28923.884765625\n",
      "The representation loss after processing this batch is:  0.00013852864503860474\n",
      "The classification loss after processing this batch is:  29705.380859375\n",
      "The representation loss after processing this batch is:  0.00015548057854175568\n",
      "The classification loss after processing this batch is:  28515.76171875\n",
      "The representation loss after processing this batch is:  0.0001372452825307846\n",
      "The classification loss after processing this batch is:  29583.80859375\n",
      "The representation loss after processing this batch is:  0.00014870427548885345\n",
      "The classification loss after processing this batch is:  30822.5859375\n",
      "The representation loss after processing this batch is:  0.0001528654247522354\n",
      "The classification loss after processing this batch is:  29327.13671875\n",
      "The representation loss after processing this batch is:  0.00014888867735862732\n",
      "The classification loss after processing this batch is:  30348.0703125\n",
      "The representation loss after processing this batch is:  0.00012990832328796387\n",
      "The classification loss after processing this batch is:  29417.955078125\n",
      "The representation loss after processing this batch is:  0.00013887137174606323\n",
      "The classification loss after processing this batch is:  30477.046875\n",
      "The representation loss after processing this batch is:  0.00018929317593574524\n",
      "The classification loss after processing this batch is:  29113.0\n",
      "The representation loss after processing this batch is:  0.00013875775039196014\n",
      "The classification loss after processing this batch is:  29381.048828125\n",
      "The representation loss after processing this batch is:  0.00012734904885292053\n",
      "The classification loss after processing this batch is:  28508.822265625\n",
      "The representation loss after processing this batch is:  0.00014384090900421143\n",
      "The classification loss after processing this batch is:  28404.447265625\n",
      "The representation loss after processing this batch is:  0.00014699064195156097\n",
      "The classification loss after processing this batch is:  28787.12109375\n",
      "The representation loss after processing this batch is:  0.0001265406608581543\n",
      "The classification loss after processing this batch is:  27457.60546875\n",
      "The representation loss after processing this batch is:  0.00011785142123699188\n",
      "The classification loss after processing this batch is:  27915.65234375\n",
      "The representation loss after processing this batch is:  0.00014460086822509766\n",
      "The classification loss after processing this batch is:  27932.33984375\n",
      "The representation loss after processing this batch is:  0.00012318231165409088\n",
      "The classification loss after processing this batch is:  28226.16796875\n",
      "The representation loss after processing this batch is:  0.0001338385045528412\n",
      "The classification loss after processing this batch is:  27524.6171875\n",
      "The representation loss after processing this batch is:  0.00013393908739089966\n",
      "The classification loss after processing this batch is:  29169.4609375\n",
      "The representation loss after processing this batch is:  0.00014736689627170563\n",
      "The classification loss after processing this batch is:  28306.25390625\n",
      "The representation loss after processing this batch is:  0.000151805579662323\n",
      "The classification loss after processing this batch is:  28534.015625\n",
      "The representation loss after processing this batch is:  0.00016257353127002716\n",
      "The classification loss after processing this batch is:  29192.73828125\n",
      "The representation loss after processing this batch is:  0.00012265145778656006\n",
      "The classification loss after processing this batch is:  28473.94140625\n",
      "The representation loss after processing this batch is:  0.00013502128422260284\n",
      "The classification loss after processing this batch is:  29176.990234375\n",
      "The representation loss after processing this batch is:  0.00012739188969135284\n",
      "The classification loss after processing this batch is:  29232.4140625\n",
      "The representation loss after processing this batch is:  0.00014315545558929443\n",
      "The classification loss after processing this batch is:  28286.21484375\n",
      "The representation loss after processing this batch is:  0.00013923831284046173\n",
      "The classification loss after processing this batch is:  29083.0546875\n",
      "The representation loss after processing this batch is:  0.00014241505414247513\n",
      "The classification loss after processing this batch is:  28525.8828125\n",
      "The representation loss after processing this batch is:  0.0001316424459218979\n",
      "The classification loss after processing this batch is:  28216.515625\n",
      "The representation loss after processing this batch is:  0.00012963637709617615\n",
      "The classification loss after processing this batch is:  28987.58984375\n",
      "The representation loss after processing this batch is:  0.00012498535215854645\n",
      "The classification loss after processing this batch is:  28474.46484375\n",
      "The representation loss after processing this batch is:  0.00012845173478126526\n",
      "The classification loss after processing this batch is:  30646.361328125\n",
      "The representation loss after processing this batch is:  0.000147942453622818\n",
      "The classification loss after processing this batch is:  30591.015625\n",
      "The representation loss after processing this batch is:  0.00014749914407730103\n",
      "The classification loss after processing this batch is:  28207.1953125\n",
      "The representation loss after processing this batch is:  0.00015923939645290375\n",
      "The classification loss after processing this batch is:  32378.6875\n",
      "The representation loss after processing this batch is:  0.00013114698231220245\n",
      "The classification loss after processing this batch is:  31905.98828125\n",
      "The representation loss after processing this batch is:  0.00013916008174419403\n",
      "The classification loss after processing this batch is:  28599.140625\n",
      "The representation loss after processing this batch is:  0.00012348778545856476\n",
      "The classification loss after processing this batch is:  29147.7109375\n",
      "The representation loss after processing this batch is:  0.00012747850269079208\n",
      "The classification loss after processing this batch is:  29841.82421875\n",
      "The representation loss after processing this batch is:  0.00016293302178382874\n",
      "The classification loss after processing this batch is:  29151.916015625\n",
      "The representation loss after processing this batch is:  0.0001251455396413803\n",
      "The classification loss after processing this batch is:  29467.97265625\n",
      "The representation loss after processing this batch is:  0.00013989955186843872\n",
      "The classification loss after processing this batch is:  29247.2578125\n",
      "The representation loss after processing this batch is:  0.00013967417180538177\n",
      "The classification loss after processing this batch is:  29349.337890625\n",
      "The representation loss after processing this batch is:  0.0001587606966495514\n",
      "The classification loss after processing this batch is:  30609.763671875\n",
      "The representation loss after processing this batch is:  0.00013369787484407425\n",
      "The classification loss after processing this batch is:  29447.029296875\n",
      "The representation loss after processing this batch is:  0.00012325868010520935\n",
      "The classification loss after processing this batch is:  30505.4453125\n",
      "The representation loss after processing this batch is:  0.0001617278903722763\n",
      "The classification loss after processing this batch is:  30027.54296875\n",
      "The representation loss after processing this batch is:  0.0001502949744462967\n",
      "The classification loss after processing this batch is:  31126.55859375\n",
      "The representation loss after processing this batch is:  0.00012635160237550735\n",
      "The classification loss after processing this batch is:  28208.76171875\n",
      "The representation loss after processing this batch is:  0.0001367153599858284\n",
      "The classification loss after processing this batch is:  28608.658203125\n",
      "The representation loss after processing this batch is:  0.00012868642807006836\n",
      "The classification loss after processing this batch is:  29496.34765625\n",
      "The representation loss after processing this batch is:  0.00013243593275547028\n",
      "The classification loss after processing this batch is:  28649.771484375\n",
      "The representation loss after processing this batch is:  0.00017229467630386353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  27523.91015625\n",
      "The representation loss after processing this batch is:  0.00014930590987205505\n",
      "The classification loss after processing this batch is:  29329.3671875\n",
      "The representation loss after processing this batch is:  0.00012329407036304474\n",
      "The classification loss after processing this batch is:  27857.203125\n",
      "The representation loss after processing this batch is:  0.00014020316302776337\n",
      "The classification loss after processing this batch is:  28620.953125\n",
      "The representation loss after processing this batch is:  0.0001337137073278427\n",
      "The classification loss after processing this batch is:  27606.18359375\n",
      "The representation loss after processing this batch is:  0.00014461949467658997\n",
      "The classification loss after processing this batch is:  28100.919921875\n",
      "The representation loss after processing this batch is:  0.00014852546155452728\n",
      "The classification loss after processing this batch is:  27298.990234375\n",
      "The representation loss after processing this batch is:  0.00012378022074699402\n",
      "The classification loss after processing this batch is:  28421.3515625\n",
      "The representation loss after processing this batch is:  0.00012784823775291443\n",
      "The classification loss after processing this batch is:  28333.40625\n",
      "The representation loss after processing this batch is:  0.000128280371427536\n",
      "The classification loss after processing this batch is:  27470.189453125\n",
      "The representation loss after processing this batch is:  0.00011806190013885498\n",
      "The classification loss after processing this batch is:  29127.0546875\n",
      "The representation loss after processing this batch is:  0.00011347979307174683\n",
      "The classification loss after processing this batch is:  29522.12109375\n",
      "The representation loss after processing this batch is:  0.00012528710067272186\n",
      "The classification loss after processing this batch is:  27585.939453125\n",
      "The representation loss after processing this batch is:  0.00014395453035831451\n",
      "The classification loss after processing this batch is:  28082.37109375\n",
      "The representation loss after processing this batch is:  0.00017109885811805725\n",
      "The classification loss after processing this batch is:  27814.671875\n",
      "The representation loss after processing this batch is:  0.0001383405178785324\n",
      "The classification loss after processing this batch is:  28181.208984375\n",
      "The representation loss after processing this batch is:  0.0001311078667640686\n",
      "The classification loss after processing this batch is:  29521.265625\n",
      "The representation loss after processing this batch is:  0.00012544915080070496\n",
      "The classification loss after processing this batch is:  28050.12109375\n",
      "The representation loss after processing this batch is:  0.00011121947318315506\n",
      "The classification loss after processing this batch is:  27486.517578125\n",
      "The representation loss after processing this batch is:  0.00012753158807754517\n",
      "The classification loss after processing this batch is:  28642.091796875\n",
      "The representation loss after processing this batch is:  0.0001284368336200714\n",
      "The classification loss after processing this batch is:  30835.306640625\n",
      "The representation loss after processing this batch is:  0.00014672614634037018\n",
      "The classification loss after processing this batch is:  28258.3359375\n",
      "The representation loss after processing this batch is:  0.0001232502982020378\n",
      "The classification loss after processing this batch is:  29101.44140625\n",
      "The representation loss after processing this batch is:  0.0001253020018339157\n",
      "The classification loss after processing this batch is:  30350.435546875\n",
      "The representation loss after processing this batch is:  0.0001413421705365181\n",
      "The classification loss after processing this batch is:  28464.12890625\n",
      "The representation loss after processing this batch is:  0.0001420155167579651\n",
      "The classification loss after processing this batch is:  27303.87890625\n",
      "The representation loss after processing this batch is:  0.00011765491217374802\n",
      "The classification loss after processing this batch is:  27418.80078125\n",
      "The representation loss after processing this batch is:  0.00011282600462436676\n",
      "The classification loss after processing this batch is:  28067.61328125\n",
      "The representation loss after processing this batch is:  0.00012332946062088013\n",
      "The classification loss after processing this batch is:  28481.29296875\n",
      "The representation loss after processing this batch is:  0.0001345379278063774\n",
      "The classification loss after processing this batch is:  27653.5859375\n",
      "The representation loss after processing this batch is:  0.00015693716704845428\n",
      "The classification loss after processing this batch is:  28748.71484375\n",
      "The representation loss after processing this batch is:  0.0001226775348186493\n",
      "The classification loss after processing this batch is:  31702.3828125\n",
      "The representation loss after processing this batch is:  0.0001304037868976593\n",
      "The classification loss after processing this batch is:  29662.5\n",
      "The representation loss after processing this batch is:  0.00014329701662063599\n",
      "The classification loss after processing this batch is:  28440.740234375\n",
      "The representation loss after processing this batch is:  0.0001485198736190796\n",
      "The classification loss after processing this batch is:  27812.53125\n",
      "The representation loss after processing this batch is:  0.00013092905282974243\n",
      "The classification loss after processing this batch is:  28677.8125\n",
      "The representation loss after processing this batch is:  0.000139748677611351\n",
      "The classification loss after processing this batch is:  28389.62890625\n",
      "The representation loss after processing this batch is:  0.0001645199954509735\n",
      "The classification loss after processing this batch is:  28554.05859375\n",
      "The representation loss after processing this batch is:  0.0001339055597782135\n",
      "The classification loss after processing this batch is:  27703.8671875\n",
      "The representation loss after processing this batch is:  0.0001344587653875351\n",
      "The classification loss after processing this batch is:  28360.888671875\n",
      "The representation loss after processing this batch is:  0.0001242421567440033\n",
      "The classification loss after processing this batch is:  27683.84765625\n",
      "The representation loss after processing this batch is:  0.00010811630636453629\n",
      "The classification loss after processing this batch is:  27003.501953125\n",
      "The representation loss after processing this batch is:  0.00014210771769285202\n",
      "The classification loss after processing this batch is:  27813.74609375\n",
      "The representation loss after processing this batch is:  0.00013196375221014023\n",
      "The classification loss after processing this batch is:  26378.025390625\n",
      "The representation loss after processing this batch is:  0.0001272018998861313\n",
      "The classification loss after processing this batch is:  28841.234375\n",
      "The representation loss after processing this batch is:  0.00015690550208091736\n",
      "The classification loss after processing this batch is:  28663.2890625\n",
      "The representation loss after processing this batch is:  0.00012060906738042831\n",
      "The classification loss after processing this batch is:  27499.080078125\n",
      "The representation loss after processing this batch is:  0.00011217966675758362\n",
      "The classification loss after processing this batch is:  28518.99609375\n",
      "The representation loss after processing this batch is:  0.00014006905257701874\n",
      "The classification loss after processing this batch is:  28749.3515625\n",
      "The representation loss after processing this batch is:  0.0001330757513642311\n",
      "The classification loss after processing this batch is:  29817.5078125\n",
      "The representation loss after processing this batch is:  0.00013225339353084564\n",
      "The classification loss after processing this batch is:  29326.71875\n",
      "The representation loss after processing this batch is:  0.00013574864715337753\n",
      "The classification loss after processing this batch is:  27878.5625\n",
      "The representation loss after processing this batch is:  0.0001270342618227005\n",
      "The classification loss after processing this batch is:  28093.15234375\n",
      "The representation loss after processing this batch is:  0.00010627508163452148\n",
      "The classification loss after processing this batch is:  29625.345703125\n",
      "The representation loss after processing this batch is:  0.00015074759721755981\n",
      "The classification loss after processing this batch is:  27547.95703125\n",
      "The representation loss after processing this batch is:  0.00012496206909418106\n",
      "The classification loss after processing this batch is:  28429.48828125\n",
      "The representation loss after processing this batch is:  0.00013109110295772552\n",
      "The classification loss after processing this batch is:  27937.12109375\n",
      "The representation loss after processing this batch is:  0.00017125345766544342\n",
      "The classification loss after processing this batch is:  28690.640625\n",
      "The representation loss after processing this batch is:  0.0001546330749988556\n",
      "The classification loss after processing this batch is:  29472.849609375\n",
      "The representation loss after processing this batch is:  0.00014109909534454346\n",
      "The classification loss after processing this batch is:  29687.193359375\n",
      "The representation loss after processing this batch is:  0.00015335436910390854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  28000.765625\n",
      "The representation loss after processing this batch is:  0.00017409026622772217\n",
      "The classification loss after processing this batch is:  29095.078125\n",
      "The representation loss after processing this batch is:  0.00012858398258686066\n",
      "The classification loss after processing this batch is:  29356.4921875\n",
      "The representation loss after processing this batch is:  0.0001212097704410553\n",
      "The classification loss after processing this batch is:  27925.4140625\n",
      "The representation loss after processing this batch is:  0.0001384355127811432\n",
      "The classification loss after processing this batch is:  29118.009765625\n",
      "The representation loss after processing this batch is:  0.00012758001685142517\n",
      "The classification loss after processing this batch is:  28460.25\n",
      "The representation loss after processing this batch is:  0.0001417640596628189\n",
      "The classification loss after processing this batch is:  27773.5390625\n",
      "The representation loss after processing this batch is:  0.00013475120067596436\n",
      "The classification loss after processing this batch is:  27674.609375\n",
      "The representation loss after processing this batch is:  0.00012137368321418762\n",
      "The classification loss after processing this batch is:  27931.8203125\n",
      "The representation loss after processing this batch is:  0.00013486109673976898\n",
      "The classification loss after processing this batch is:  27680.76953125\n",
      "The representation loss after processing this batch is:  0.0001275511458516121\n",
      "The classification loss after processing this batch is:  29291.771484375\n",
      "The representation loss after processing this batch is:  0.00013794004917144775\n",
      "The classification loss after processing this batch is:  29014.47265625\n",
      "The representation loss after processing this batch is:  0.0001149279996752739\n",
      "The classification loss after processing this batch is:  30749.091796875\n",
      "The representation loss after processing this batch is:  0.00013891607522964478\n",
      "The classification loss after processing this batch is:  27243.3828125\n",
      "The representation loss after processing this batch is:  0.0001283213496208191\n",
      "The classification loss after processing this batch is:  27323.25390625\n",
      "The representation loss after processing this batch is:  0.00015721842646598816\n",
      "The classification loss after processing this batch is:  28052.40625\n",
      "The representation loss after processing this batch is:  0.00016388855874538422\n",
      "The classification loss after processing this batch is:  28026.994140625\n",
      "The representation loss after processing this batch is:  0.00012800469994544983\n",
      "The classification loss after processing this batch is:  29262.666015625\n",
      "The representation loss after processing this batch is:  0.0001392792910337448\n",
      "The classification loss after processing this batch is:  28337.703125\n",
      "The representation loss after processing this batch is:  0.0001291334629058838\n",
      "The classification loss after processing this batch is:  28647.740234375\n",
      "The representation loss after processing this batch is:  0.00013299565762281418\n",
      "The classification loss after processing this batch is:  28291.375\n",
      "The representation loss after processing this batch is:  0.0001219557598233223\n",
      "The classification loss after processing this batch is:  27584.037109375\n",
      "The representation loss after processing this batch is:  0.00013194512575864792\n",
      "The classification loss after processing this batch is:  29513.888671875\n",
      "The representation loss after processing this batch is:  0.00020421110093593597\n",
      "The classification loss after processing this batch is:  29880.70703125\n",
      "The representation loss after processing this batch is:  0.000130457803606987\n",
      "The classification loss after processing this batch is:  29185.322265625\n",
      "The representation loss after processing this batch is:  0.00013023242354393005\n",
      "The classification loss after processing this batch is:  27305.10546875\n",
      "The representation loss after processing this batch is:  0.0001505482941865921\n",
      "The classification loss after processing this batch is:  29953.501953125\n",
      "The representation loss after processing this batch is:  0.00013098586350679398\n",
      "The classification loss after processing this batch is:  29538.474609375\n",
      "The representation loss after processing this batch is:  0.00012871436774730682\n",
      "The classification loss after processing this batch is:  27981.671875\n",
      "The representation loss after processing this batch is:  0.0001307707279920578\n",
      "The classification loss after processing this batch is:  30065.9140625\n",
      "The representation loss after processing this batch is:  0.00015022419393062592\n",
      "The classification loss after processing this batch is:  29599.91015625\n",
      "The representation loss after processing this batch is:  0.00015156157314777374\n",
      "The classification loss after processing this batch is:  27171.48046875\n",
      "The representation loss after processing this batch is:  0.00012716278433799744\n",
      "The classification loss after processing this batch is:  28023.669921875\n",
      "The representation loss after processing this batch is:  0.0001552235335111618\n",
      "The classification loss after processing this batch is:  28805.94921875\n",
      "The representation loss after processing this batch is:  0.00017171353101730347\n",
      "The classification loss after processing this batch is:  28342.767578125\n",
      "The representation loss after processing this batch is:  0.0001300908625125885\n",
      "The classification loss after processing this batch is:  28850.74609375\n",
      "The representation loss after processing this batch is:  0.00013783574104309082\n",
      "The classification loss after processing this batch is:  28948.859375\n",
      "The representation loss after processing this batch is:  0.0001645740121603012\n",
      "The classification loss after processing this batch is:  27086.828125\n",
      "The representation loss after processing this batch is:  0.00015373341739177704\n",
      "The classification loss after processing this batch is:  27100.107421875\n",
      "The representation loss after processing this batch is:  0.00015696510672569275\n",
      "The classification loss after processing this batch is:  28758.513671875\n",
      "The representation loss after processing this batch is:  0.00013577379286289215\n",
      "The classification loss after processing this batch is:  30073.775390625\n",
      "The representation loss after processing this batch is:  0.00013295933604240417\n",
      "The classification loss after processing this batch is:  28156.419921875\n",
      "The representation loss after processing this batch is:  0.00012765079736709595\n",
      "The classification loss after processing this batch is:  28555.728515625\n",
      "The representation loss after processing this batch is:  0.00014964863657951355\n",
      "The classification loss after processing this batch is:  28273.3125\n",
      "The representation loss after processing this batch is:  0.00011813361197710037\n",
      "The classification loss after processing this batch is:  28465.26953125\n",
      "The representation loss after processing this batch is:  0.0001218114048242569\n",
      "The classification loss after processing this batch is:  27639.052734375\n",
      "The representation loss after processing this batch is:  0.00014391541481018066\n",
      "The classification loss after processing this batch is:  27584.724609375\n",
      "The representation loss after processing this batch is:  0.0001314319670200348\n",
      "The classification loss after processing this batch is:  28713.83984375\n",
      "The representation loss after processing this batch is:  0.0001344531774520874\n",
      "The classification loss after processing this batch is:  26767.34765625\n",
      "The representation loss after processing this batch is:  0.0001297052949666977\n",
      "The classification loss after processing this batch is:  27607.23046875\n",
      "The representation loss after processing this batch is:  0.0001243390142917633\n",
      "The classification loss after processing this batch is:  27590.3046875\n",
      "The representation loss after processing this batch is:  0.0001295916736125946\n",
      "The classification loss after processing this batch is:  26799.390625\n",
      "The representation loss after processing this batch is:  0.00013507157564163208\n",
      "The classification loss after processing this batch is:  27017.81640625\n",
      "The representation loss after processing this batch is:  0.00013878289610147476\n",
      "The classification loss after processing this batch is:  28210.396484375\n",
      "The representation loss after processing this batch is:  0.00011749193072319031\n",
      "The classification loss after processing this batch is:  28107.546875\n",
      "The representation loss after processing this batch is:  0.000126522034406662\n",
      "The classification loss after processing this batch is:  27002.96875\n",
      "The representation loss after processing this batch is:  0.00013160333037376404\n",
      "The classification loss after processing this batch is:  27603.939453125\n",
      "The representation loss after processing this batch is:  0.00012047495692968369\n",
      "The classification loss after processing this batch is:  27307.837890625\n",
      "The representation loss after processing this batch is:  0.00012842658907175064\n",
      "The classification loss after processing this batch is:  27653.814453125\n",
      "The representation loss after processing this batch is:  0.00012946780771017075\n",
      "The classification loss after processing this batch is:  27933.73046875\n",
      "The representation loss after processing this batch is:  0.00011552777141332626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  26918.8046875\n",
      "The representation loss after processing this batch is:  0.00014601461589336395\n",
      "The classification loss after processing this batch is:  29626.25390625\n",
      "The representation loss after processing this batch is:  0.00013767648488283157\n",
      "The classification loss after processing this batch is:  27720.13671875\n",
      "The representation loss after processing this batch is:  0.00011343881487846375\n",
      "The classification loss after processing this batch is:  27082.86328125\n",
      "The representation loss after processing this batch is:  0.00014109443873167038\n",
      "The classification loss after processing this batch is:  27914.783203125\n",
      "The representation loss after processing this batch is:  0.00014569144695997238\n",
      "The classification loss after processing this batch is:  28500.125\n",
      "The representation loss after processing this batch is:  0.0001430027186870575\n",
      "The classification loss after processing this batch is:  27736.501953125\n",
      "The representation loss after processing this batch is:  0.0001399880275130272\n",
      "The classification loss after processing this batch is:  26996.38671875\n",
      "The representation loss after processing this batch is:  0.00016114488244056702\n",
      "The classification loss after processing this batch is:  28166.80078125\n",
      "The representation loss after processing this batch is:  0.00012622587382793427\n",
      "The classification loss after processing this batch is:  29777.955078125\n",
      "The representation loss after processing this batch is:  0.00012125447392463684\n",
      "The classification loss after processing this batch is:  27012.015625\n",
      "The representation loss after processing this batch is:  0.0001315716654062271\n",
      "The classification loss after processing this batch is:  27692.0546875\n",
      "The representation loss after processing this batch is:  0.0001167096197605133\n",
      "The classification loss after processing this batch is:  26474.4140625\n",
      "The representation loss after processing this batch is:  0.0001530628651380539\n",
      "The classification loss after processing this batch is:  27640.00390625\n",
      "The representation loss after processing this batch is:  0.0001247413456439972\n",
      "The classification loss after processing this batch is:  27971.6796875\n",
      "The representation loss after processing this batch is:  0.00013484060764312744\n",
      "The classification loss after processing this batch is:  27919.11328125\n",
      "The representation loss after processing this batch is:  0.00014082714915275574\n",
      "The classification loss after processing this batch is:  27379.662109375\n",
      "The representation loss after processing this batch is:  0.00013518519699573517\n",
      "The classification loss after processing this batch is:  26837.78125\n",
      "The representation loss after processing this batch is:  0.00013994984328746796\n",
      "The classification loss after processing this batch is:  27042.63671875\n",
      "The representation loss after processing this batch is:  0.00011665374040603638\n",
      "The classification loss after processing this batch is:  27519.447265625\n",
      "The representation loss after processing this batch is:  0.0001432318240404129\n",
      "The classification loss after processing this batch is:  26604.49609375\n",
      "The representation loss after processing this batch is:  0.00014128349721431732\n",
      "The classification loss after processing this batch is:  30779.158203125\n",
      "The representation loss after processing this batch is:  0.00013433769345283508\n",
      "The classification loss after processing this batch is:  29260.62109375\n",
      "The representation loss after processing this batch is:  0.00013094954192638397\n",
      "The classification loss after processing this batch is:  28289.486328125\n",
      "The representation loss after processing this batch is:  0.00013459287583827972\n",
      "The classification loss after processing this batch is:  27492.2734375\n",
      "The representation loss after processing this batch is:  0.0001350194215774536\n",
      "The classification loss after processing this batch is:  27586.158203125\n",
      "The representation loss after processing this batch is:  0.00013603828847408295\n",
      "The classification loss after processing this batch is:  28309.3125\n",
      "The representation loss after processing this batch is:  0.00012750737369060516\n",
      "The classification loss after processing this batch is:  28958.626953125\n",
      "The representation loss after processing this batch is:  0.00014440715312957764\n",
      "The classification loss after processing this batch is:  28300.923828125\n",
      "The representation loss after processing this batch is:  0.00011455267667770386\n",
      "The classification loss after processing this batch is:  29894.619140625\n",
      "The representation loss after processing this batch is:  0.00014997739344835281\n",
      "The classification loss after processing this batch is:  27913.673828125\n",
      "The representation loss after processing this batch is:  0.00012198463082313538\n",
      "The classification loss after processing this batch is:  26989.609375\n",
      "The representation loss after processing this batch is:  0.00013411976397037506\n",
      "The classification loss after processing this batch is:  28695.185546875\n",
      "The representation loss after processing this batch is:  0.00013457238674163818\n",
      "The classification loss after processing this batch is:  27065.478515625\n",
      "The representation loss after processing this batch is:  0.00012676138430833817\n",
      "The classification loss after processing this batch is:  27365.078125\n",
      "The representation loss after processing this batch is:  0.00013026967644691467\n",
      "The classification loss after processing this batch is:  30710.998046875\n",
      "The representation loss after processing this batch is:  0.00014102645218372345\n",
      "The classification loss after processing this batch is:  29201.302734375\n",
      "The representation loss after processing this batch is:  0.00014847330749034882\n",
      "The classification loss after processing this batch is:  26568.9453125\n",
      "The representation loss after processing this batch is:  0.00015902332961559296\n",
      "The classification loss after processing this batch is:  26805.251953125\n",
      "The representation loss after processing this batch is:  0.0002461429685354233\n",
      "The classification loss after processing this batch is:  29815.06640625\n",
      "The representation loss after processing this batch is:  0.00013675540685653687\n",
      "The classification loss after processing this batch is:  27290.357421875\n",
      "The representation loss after processing this batch is:  0.0001405850052833557\n",
      "The classification loss after processing this batch is:  26746.859375\n",
      "The representation loss after processing this batch is:  0.00014463067054748535\n",
      "The classification loss after processing this batch is:  26832.716796875\n",
      "The representation loss after processing this batch is:  0.0001432672142982483\n",
      "The classification loss after processing this batch is:  31833.99609375\n",
      "The representation loss after processing this batch is:  0.00015712715685367584\n",
      "The classification loss after processing this batch is:  35226.6484375\n",
      "The representation loss after processing this batch is:  0.00015275180339813232\n",
      "The classification loss after processing this batch is:  27358.876953125\n",
      "The representation loss after processing this batch is:  0.00013897567987442017\n",
      "The classification loss after processing this batch is:  29060.73828125\n",
      "The representation loss after processing this batch is:  0.0001368839293718338\n",
      "The classification loss after processing this batch is:  28376.923828125\n",
      "The representation loss after processing this batch is:  0.00016989000141620636\n",
      "The classification loss after processing this batch is:  24938.123046875\n",
      "The representation loss after processing this batch is:  0.00012721121311187744\n",
      "The classification loss after processing this batch is:  28413.25\n",
      "The representation loss after processing this batch is:  0.00014939531683921814\n",
      "The classification loss after processing this batch is:  28094.59765625\n",
      "The representation loss after processing this batch is:  0.00015556253492832184\n",
      "The classification loss after processing this batch is:  26909.3828125\n",
      "The representation loss after processing this batch is:  0.000145668163895607\n",
      "The classification loss after processing this batch is:  27488.251953125\n",
      "The representation loss after processing this batch is:  0.00013554468750953674\n",
      "The classification loss after processing this batch is:  28151.552734375\n",
      "The representation loss after processing this batch is:  0.00018259882926940918\n",
      "The classification loss after processing this batch is:  28903.35546875\n",
      "The representation loss after processing this batch is:  0.000159531831741333\n",
      "The classification loss after processing this batch is:  28730.2421875\n",
      "The representation loss after processing this batch is:  0.0001439955085515976\n",
      "The classification loss after processing this batch is:  27842.85546875\n",
      "The representation loss after processing this batch is:  0.00013650581240653992\n",
      "The classification loss after processing this batch is:  27696.72265625\n",
      "The representation loss after processing this batch is:  0.00014830008149147034\n",
      "The classification loss after processing this batch is:  30064.796875\n",
      "The representation loss after processing this batch is:  0.00016468577086925507\n",
      "The classification loss after processing this batch is:  28919.1015625\n",
      "The representation loss after processing this batch is:  0.00013920292258262634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  28321.056640625\n",
      "The representation loss after processing this batch is:  0.00014263764023780823\n",
      "The classification loss after processing this batch is:  28661.017578125\n",
      "The representation loss after processing this batch is:  0.0001393388956785202\n",
      "The classification loss after processing this batch is:  28193.412109375\n",
      "The representation loss after processing this batch is:  0.00013585202395915985\n",
      "The classification loss after processing this batch is:  27994.318359375\n",
      "The representation loss after processing this batch is:  0.00014787539839744568\n",
      "The classification loss after processing this batch is:  27898.74609375\n",
      "The representation loss after processing this batch is:  0.00013992004096508026\n",
      "The classification loss after processing this batch is:  27294.314453125\n",
      "The representation loss after processing this batch is:  0.00013406574726104736\n",
      "The classification loss after processing this batch is:  28740.30078125\n",
      "The representation loss after processing this batch is:  0.00016739964485168457\n",
      "The classification loss after processing this batch is:  28416.42578125\n",
      "The representation loss after processing this batch is:  0.00014491938054561615\n",
      "The classification loss after processing this batch is:  29061.75\n",
      "The representation loss after processing this batch is:  0.00015434809029102325\n",
      "The classification loss after processing this batch is:  28531.9453125\n",
      "The representation loss after processing this batch is:  0.0001704692840576172\n",
      "The classification loss after processing this batch is:  27807.53125\n",
      "The representation loss after processing this batch is:  0.00013191811740398407\n",
      "The classification loss after processing this batch is:  28301.396484375\n",
      "The representation loss after processing this batch is:  0.00013370998203754425\n",
      "The classification loss after processing this batch is:  27603.513671875\n",
      "The representation loss after processing this batch is:  0.00014687888324260712\n",
      "The classification loss after processing this batch is:  27128.703125\n",
      "The representation loss after processing this batch is:  0.0001456979662179947\n",
      "The classification loss after processing this batch is:  26541.80859375\n",
      "The representation loss after processing this batch is:  0.00017475523054599762\n",
      "The classification loss after processing this batch is:  26870.53125\n",
      "The representation loss after processing this batch is:  0.00014884769916534424\n",
      "The classification loss after processing this batch is:  26775.369140625\n",
      "The representation loss after processing this batch is:  0.0001353975385427475\n",
      "The classification loss after processing this batch is:  30265.814453125\n",
      "The representation loss after processing this batch is:  0.00014263764023780823\n",
      "The classification loss after processing this batch is:  28632.212890625\n",
      "The representation loss after processing this batch is:  0.0001218356192111969\n",
      "The classification loss after processing this batch is:  27031.3828125\n",
      "The representation loss after processing this batch is:  0.00014257244765758514\n",
      "The classification loss after processing this batch is:  27489.89453125\n",
      "The representation loss after processing this batch is:  0.00012566708028316498\n",
      "The classification loss after processing this batch is:  26603.71484375\n",
      "The representation loss after processing this batch is:  0.00012823008000850677\n",
      "The classification loss after processing this batch is:  27070.861328125\n",
      "The representation loss after processing this batch is:  0.00013981759548187256\n",
      "The classification loss after processing this batch is:  27581.05078125\n",
      "The representation loss after processing this batch is:  0.0001293569803237915\n",
      "The classification loss after processing this batch is:  27905.919921875\n",
      "The representation loss after processing this batch is:  0.00014695897698402405\n",
      "The classification loss after processing this batch is:  29328.474609375\n",
      "The representation loss after processing this batch is:  0.00014335662126541138\n",
      "The classification loss after processing this batch is:  32760.3203125\n",
      "The representation loss after processing this batch is:  0.00018082000315189362\n",
      "The classification loss after processing this batch is:  27636.9609375\n",
      "The representation loss after processing this batch is:  0.00013895146548748016\n",
      "The classification loss after processing this batch is:  28378.80078125\n",
      "The representation loss after processing this batch is:  0.00014906004071235657\n",
      "The classification loss after processing this batch is:  28617.12109375\n",
      "The representation loss after processing this batch is:  0.0001320876181125641\n",
      "The classification loss after processing this batch is:  28685.01171875\n",
      "The representation loss after processing this batch is:  0.00013126805424690247\n",
      "The classification loss after processing this batch is:  28223.94140625\n",
      "The representation loss after processing this batch is:  0.00014018826186656952\n",
      "The classification loss after processing this batch is:  28491.05859375\n",
      "The representation loss after processing this batch is:  0.00014757178723812103\n",
      "The classification loss after processing this batch is:  27969.806640625\n",
      "The representation loss after processing this batch is:  0.00013582035899162292\n",
      "The classification loss after processing this batch is:  27470.095703125\n",
      "The representation loss after processing this batch is:  0.0001463070511817932\n",
      "The classification loss after processing this batch is:  27431.71484375\n",
      "The representation loss after processing this batch is:  0.00014383811503648758\n",
      "The classification loss after processing this batch is:  27913.23828125\n",
      "The representation loss after processing this batch is:  0.00014384090900421143\n",
      "The classification loss after processing this batch is:  27516.75\n",
      "The representation loss after processing this batch is:  0.00013959407806396484\n",
      "The classification loss after processing this batch is:  27429.853515625\n",
      "The representation loss after processing this batch is:  0.00015706010162830353\n",
      "The classification loss after processing this batch is:  27473.1875\n",
      "The representation loss after processing this batch is:  0.0001350492238998413\n",
      "The classification loss after processing this batch is:  26394.162109375\n",
      "The representation loss after processing this batch is:  0.0001328699290752411\n",
      "The classification loss after processing this batch is:  26994.734375\n",
      "The representation loss after processing this batch is:  0.00015296414494514465\n",
      "The classification loss after processing this batch is:  27351.4140625\n",
      "The representation loss after processing this batch is:  0.00015268102288246155\n",
      "The classification loss after processing this batch is:  27331.669921875\n",
      "The representation loss after processing this batch is:  0.00014393404126167297\n",
      "The classification loss after processing this batch is:  26951.09765625\n",
      "The representation loss after processing this batch is:  0.00014580972492694855\n",
      "The classification loss after processing this batch is:  28056.84765625\n",
      "The representation loss after processing this batch is:  0.00015142187476158142\n",
      "The classification loss after processing this batch is:  27018.892578125\n",
      "The representation loss after processing this batch is:  0.00017448235303163528\n",
      "The classification loss after processing this batch is:  27350.4140625\n",
      "The representation loss after processing this batch is:  0.0001626238226890564\n",
      "The classification loss after processing this batch is:  28044.423828125\n",
      "The representation loss after processing this batch is:  0.0001405235379934311\n",
      "The classification loss after processing this batch is:  29191.474609375\n",
      "The representation loss after processing this batch is:  0.00013856589794158936\n",
      "The classification loss after processing this batch is:  29744.37890625\n",
      "The representation loss after processing this batch is:  0.00012916140258312225\n",
      "The classification loss after processing this batch is:  28867.9140625\n",
      "The representation loss after processing this batch is:  0.00013565458357334137\n",
      "The classification loss after processing this batch is:  26803.001953125\n",
      "The representation loss after processing this batch is:  0.0001668483018875122\n",
      "The classification loss after processing this batch is:  28227.234375\n",
      "The representation loss after processing this batch is:  0.00014168769121170044\n",
      "The classification loss after processing this batch is:  28173.978515625\n",
      "The representation loss after processing this batch is:  0.0001397784799337387\n",
      "The classification loss after processing this batch is:  28072.099609375\n",
      "The representation loss after processing this batch is:  0.00015338696539402008\n",
      "The classification loss after processing this batch is:  28772.50390625\n",
      "The representation loss after processing this batch is:  0.00014873594045639038\n",
      "The classification loss after processing this batch is:  27793.08203125\n",
      "The representation loss after processing this batch is:  0.0001268777996301651\n",
      "The classification loss after processing this batch is:  27861.76171875\n",
      "The representation loss after processing this batch is:  0.00014221109449863434\n",
      "The classification loss after processing this batch is:  27809.30859375\n",
      "The representation loss after processing this batch is:  0.0001402590423822403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  28011.86328125\n",
      "The representation loss after processing this batch is:  0.00016632117331027985\n",
      "The classification loss after processing this batch is:  26664.85546875\n",
      "The representation loss after processing this batch is:  0.00014430657029151917\n",
      "The classification loss after processing this batch is:  29070.359375\n",
      "The representation loss after processing this batch is:  0.0001462157815694809\n",
      "The classification loss after processing this batch is:  29044.587890625\n",
      "The representation loss after processing this batch is:  0.00013233907520771027\n",
      "The classification loss after processing this batch is:  29404.0234375\n",
      "The representation loss after processing this batch is:  0.00014921091496944427\n",
      "The classification loss after processing this batch is:  28263.73046875\n",
      "The representation loss after processing this batch is:  0.00013422593474388123\n",
      "The classification loss after processing this batch is:  27896.095703125\n",
      "The representation loss after processing this batch is:  0.00014648586511611938\n",
      "The classification loss after processing this batch is:  27927.265625\n",
      "The representation loss after processing this batch is:  0.00012708641588687897\n",
      "The classification loss after processing this batch is:  28426.39453125\n",
      "The representation loss after processing this batch is:  0.00013730116188526154\n",
      "The classification loss after processing this batch is:  28613.81640625\n",
      "The representation loss after processing this batch is:  0.00014403462409973145\n",
      "The classification loss after processing this batch is:  27705.853515625\n",
      "The representation loss after processing this batch is:  0.0001558307558298111\n",
      "The classification loss after processing this batch is:  27559.125\n",
      "The representation loss after processing this batch is:  0.00012876838445663452\n",
      "The classification loss after processing this batch is:  28176.041015625\n",
      "The representation loss after processing this batch is:  0.0001479554921388626\n",
      "The classification loss after processing this batch is:  27028.32421875\n",
      "The representation loss after processing this batch is:  0.00014377757906913757\n",
      "The classification loss after processing this batch is:  27058.587890625\n",
      "The representation loss after processing this batch is:  0.00015824846923351288\n",
      "The classification loss after processing this batch is:  27241.1484375\n",
      "The representation loss after processing this batch is:  0.00014376826584339142\n",
      "The classification loss after processing this batch is:  26673.048828125\n",
      "The representation loss after processing this batch is:  0.00012763962149620056\n",
      "The classification loss after processing this batch is:  26386.69921875\n",
      "The representation loss after processing this batch is:  0.00013456493616104126\n",
      "The classification loss after processing this batch is:  26538.99609375\n",
      "The representation loss after processing this batch is:  0.00013741850852966309\n",
      "The classification loss after processing this batch is:  26775.6015625\n",
      "The representation loss after processing this batch is:  0.00014165043830871582\n",
      "The classification loss after processing this batch is:  26430.40625\n",
      "The representation loss after processing this batch is:  0.0001325514167547226\n",
      "The classification loss after processing this batch is:  26949.47265625\n",
      "The representation loss after processing this batch is:  0.00014002248644828796\n",
      "The classification loss after processing this batch is:  26939.859375\n",
      "The representation loss after processing this batch is:  0.00012240465730428696\n",
      "The classification loss after processing this batch is:  26324.740234375\n",
      "The representation loss after processing this batch is:  0.00012850947678089142\n",
      "The classification loss after processing this batch is:  28052.8671875\n",
      "The representation loss after processing this batch is:  0.00012449827045202255\n",
      "The classification loss after processing this batch is:  28083.615234375\n",
      "The representation loss after processing this batch is:  0.00013148970901966095\n",
      "The classification loss after processing this batch is:  28410.990234375\n",
      "The representation loss after processing this batch is:  0.00015314389020204544\n",
      "The classification loss after processing this batch is:  28703.09765625\n",
      "The representation loss after processing this batch is:  0.0001514814794063568\n",
      "The classification loss after processing this batch is:  28948.578125\n",
      "The representation loss after processing this batch is:  0.00013666227459907532\n",
      "The classification loss after processing this batch is:  28579.435546875\n",
      "The representation loss after processing this batch is:  0.0001504756510257721\n",
      "The classification loss after processing this batch is:  28174.703125\n",
      "The representation loss after processing this batch is:  0.00015268661081790924\n",
      "The classification loss after processing this batch is:  27904.64453125\n",
      "The representation loss after processing this batch is:  0.0001404043287038803\n",
      "The classification loss after processing this batch is:  27846.0234375\n",
      "The representation loss after processing this batch is:  0.00012266449630260468\n",
      "The classification loss after processing this batch is:  27454.162109375\n",
      "The representation loss after processing this batch is:  0.00014162808656692505\n",
      "The classification loss after processing this batch is:  27114.65625\n",
      "The representation loss after processing this batch is:  0.00013585388660430908\n",
      "The classification loss after processing this batch is:  27493.287109375\n",
      "The representation loss after processing this batch is:  0.00013796985149383545\n",
      "The classification loss after processing this batch is:  26757.453125\n",
      "The representation loss after processing this batch is:  0.00014482811093330383\n",
      "The classification loss after processing this batch is:  27480.29296875\n",
      "The representation loss after processing this batch is:  0.0001331176608800888\n",
      "The classification loss after processing this batch is:  28461.86328125\n",
      "The representation loss after processing this batch is:  0.00014642998576164246\n",
      "The classification loss after processing this batch is:  32147.138671875\n",
      "The representation loss after processing this batch is:  0.00016012974083423615\n",
      "The classification loss after processing this batch is:  28660.251953125\n",
      "The representation loss after processing this batch is:  0.00013734959065914154\n",
      "The classification loss after processing this batch is:  27101.58984375\n",
      "The representation loss after processing this batch is:  0.00013460498303174973\n",
      "The classification loss after processing this batch is:  27283.9375\n",
      "The representation loss after processing this batch is:  0.0001511014997959137\n",
      "The classification loss after processing this batch is:  30786.76171875\n",
      "The representation loss after processing this batch is:  0.0001411978155374527\n",
      "The classification loss after processing this batch is:  30831.8515625\n",
      "The representation loss after processing this batch is:  0.0001606624573469162\n",
      "The classification loss after processing this batch is:  27201.712890625\n",
      "The representation loss after processing this batch is:  0.00014282390475273132\n",
      "The classification loss after processing this batch is:  27393.05078125\n",
      "The representation loss after processing this batch is:  0.00013461709022521973\n",
      "The classification loss after processing this batch is:  27755.81640625\n",
      "The representation loss after processing this batch is:  0.00013799965381622314\n",
      "The classification loss after processing this batch is:  28546.98828125\n",
      "The representation loss after processing this batch is:  0.00014023110270500183\n",
      "The classification loss after processing this batch is:  28225.380859375\n",
      "The representation loss after processing this batch is:  0.00012233108282089233\n",
      "The classification loss after processing this batch is:  27662.640625\n",
      "The representation loss after processing this batch is:  0.00013713166117668152\n",
      "The classification loss after processing this batch is:  28727.53125\n",
      "The representation loss after processing this batch is:  0.0001264447346329689\n",
      "The classification loss after processing this batch is:  29269.296875\n",
      "The representation loss after processing this batch is:  0.00014527514576911926\n",
      "The classification loss after processing this batch is:  26905.294921875\n",
      "The representation loss after processing this batch is:  0.00013272464275360107\n",
      "The classification loss after processing this batch is:  27797.1171875\n",
      "The representation loss after processing this batch is:  0.00014224182814359665\n",
      "The classification loss after processing this batch is:  26758.306640625\n",
      "The representation loss after processing this batch is:  0.00013471953570842743\n",
      "The classification loss after processing this batch is:  27567.56640625\n",
      "The representation loss after processing this batch is:  0.00014495849609375\n",
      "The classification loss after processing this batch is:  26395.4375\n",
      "The representation loss after processing this batch is:  0.00013957545161247253\n",
      "The classification loss after processing this batch is:  28397.31640625\n",
      "The representation loss after processing this batch is:  0.00014832429587841034\n",
      "The classification loss after processing this batch is:  27751.232421875\n",
      "The representation loss after processing this batch is:  0.00014075450599193573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  29440.6796875\n",
      "The representation loss after processing this batch is:  0.00013716146349906921\n",
      "The classification loss after processing this batch is:  27316.958984375\n",
      "The representation loss after processing this batch is:  0.00016581080853939056\n",
      "The classification loss after processing this batch is:  27237.28515625\n",
      "The representation loss after processing this batch is:  0.00013258680701255798\n",
      "The classification loss after processing this batch is:  28854.171875\n",
      "The representation loss after processing this batch is:  0.00015360116958618164\n",
      "The classification loss after processing this batch is:  28223.92578125\n",
      "The representation loss after processing this batch is:  0.00013762153685092926\n",
      "The classification loss after processing this batch is:  27433.69140625\n",
      "The representation loss after processing this batch is:  0.00014822930097579956\n",
      "The classification loss after processing this batch is:  28845.078125\n",
      "The representation loss after processing this batch is:  0.00014347396790981293\n",
      "The classification loss after processing this batch is:  27480.41796875\n",
      "The representation loss after processing this batch is:  0.00014782138168811798\n",
      "The classification loss after processing this batch is:  28435.583984375\n",
      "The representation loss after processing this batch is:  0.0001425575464963913\n",
      "The classification loss after processing this batch is:  27112.296875\n",
      "The representation loss after processing this batch is:  0.00012573041021823883\n",
      "The classification loss after processing this batch is:  27071.82421875\n",
      "The representation loss after processing this batch is:  0.00011357292532920837\n",
      "The classification loss after processing this batch is:  26628.0859375\n",
      "The representation loss after processing this batch is:  0.00014367885887622833\n",
      "The classification loss after processing this batch is:  26549.1640625\n",
      "The representation loss after processing this batch is:  0.00015143491327762604\n",
      "The classification loss after processing this batch is:  26640.78515625\n",
      "The representation loss after processing this batch is:  0.000145643949508667\n",
      "The classification loss after processing this batch is:  29584.296875\n",
      "The representation loss after processing this batch is:  0.00014088861644268036\n",
      "The classification loss after processing this batch is:  27395.71484375\n",
      "The representation loss after processing this batch is:  0.0001355241984128952\n",
      "The classification loss after processing this batch is:  28183.17578125\n",
      "The representation loss after processing this batch is:  0.00013427995145320892\n",
      "The classification loss after processing this batch is:  28900.11328125\n",
      "The representation loss after processing this batch is:  0.00014043226838111877\n",
      "The classification loss after processing this batch is:  27770.759765625\n",
      "The representation loss after processing this batch is:  0.00012728199362754822\n",
      "The classification loss after processing this batch is:  28132.431640625\n",
      "The representation loss after processing this batch is:  0.00013518333435058594\n",
      "The classification loss after processing this batch is:  27909.69140625\n",
      "The representation loss after processing this batch is:  0.00012427568435668945\n",
      "The classification loss after processing this batch is:  27684.81640625\n",
      "The representation loss after processing this batch is:  0.00014090165495872498\n",
      "The classification loss after processing this batch is:  26399.6953125\n",
      "The representation loss after processing this batch is:  0.000132780522108078\n",
      "The classification loss after processing this batch is:  27863.673828125\n",
      "The representation loss after processing this batch is:  0.00014494545757770538\n",
      "The classification loss after processing this batch is:  30562.5390625\n",
      "The representation loss after processing this batch is:  0.00012109801173210144\n",
      "The classification loss after processing this batch is:  31122.021484375\n",
      "The representation loss after processing this batch is:  0.000154176726937294\n",
      "The classification loss after processing this batch is:  27853.3359375\n",
      "The representation loss after processing this batch is:  0.00012012384831905365\n",
      "The classification loss after processing this batch is:  27521.548828125\n",
      "The representation loss after processing this batch is:  0.00012814998626708984\n",
      "The classification loss after processing this batch is:  27317.658203125\n",
      "The representation loss after processing this batch is:  0.00013561733067035675\n",
      "The classification loss after processing this batch is:  28198.39453125\n",
      "The representation loss after processing this batch is:  0.00015604868531227112\n",
      "The classification loss after processing this batch is:  26933.650390625\n",
      "The representation loss after processing this batch is:  0.0001245439052581787\n",
      "The classification loss after processing this batch is:  27128.783203125\n",
      "The representation loss after processing this batch is:  0.00013203546404838562\n",
      "The classification loss after processing this batch is:  28727.025390625\n",
      "The representation loss after processing this batch is:  0.0001286640763282776\n",
      "The classification loss after processing this batch is:  26001.32421875\n",
      "The representation loss after processing this batch is:  0.00012644566595554352\n",
      "The classification loss after processing this batch is:  26740.75390625\n",
      "The representation loss after processing this batch is:  0.00013268925249576569\n",
      "The classification loss after processing this batch is:  29618.36328125\n",
      "The representation loss after processing this batch is:  0.00014327839016914368\n",
      "The classification loss after processing this batch is:  28081.037109375\n",
      "The representation loss after processing this batch is:  0.00014211982488632202\n",
      "The classification loss after processing this batch is:  26927.84765625\n",
      "The representation loss after processing this batch is:  0.00014662928879261017\n",
      "The classification loss after processing this batch is:  25714.25\n",
      "The representation loss after processing this batch is:  0.0001389719545841217\n",
      "The classification loss after processing this batch is:  28124.154296875\n",
      "The representation loss after processing this batch is:  0.00015726499259471893\n",
      "The classification loss after processing this batch is:  27780.3671875\n",
      "The representation loss after processing this batch is:  0.00015844590961933136\n",
      "The classification loss after processing this batch is:  32288.916015625\n",
      "The representation loss after processing this batch is:  0.0001415535807609558\n",
      "The classification loss after processing this batch is:  28450.763671875\n",
      "The representation loss after processing this batch is:  0.0001327265053987503\n",
      "The classification loss after processing this batch is:  27368.2578125\n",
      "The representation loss after processing this batch is:  0.00014123693108558655\n",
      "The classification loss after processing this batch is:  29150.4609375\n",
      "The representation loss after processing this batch is:  0.0001443680375814438\n",
      "The classification loss after processing this batch is:  29956.14453125\n",
      "The representation loss after processing this batch is:  0.0001579541712999344\n",
      "The classification loss after processing this batch is:  28700.88671875\n",
      "The representation loss after processing this batch is:  0.00013031251728534698\n",
      "The classification loss after processing this batch is:  28027.693359375\n",
      "The representation loss after processing this batch is:  0.00013938359916210175\n",
      "The classification loss after processing this batch is:  27959.40625\n",
      "The representation loss after processing this batch is:  0.00012519024312496185\n",
      "The classification loss after processing this batch is:  27849.966796875\n",
      "The representation loss after processing this batch is:  0.00011800974607467651\n",
      "The classification loss after processing this batch is:  26283.181640625\n",
      "The representation loss after processing this batch is:  0.00013632327318191528\n",
      "The classification loss after processing this batch is:  27605.630859375\n",
      "The representation loss after processing this batch is:  0.00012713484466075897\n",
      "The classification loss after processing this batch is:  27185.08203125\n",
      "The representation loss after processing this batch is:  0.0001484658569097519\n",
      "The classification loss after processing this batch is:  27524.998046875\n",
      "The representation loss after processing this batch is:  0.00013616867363452911\n",
      "The classification loss after processing this batch is:  27816.044921875\n",
      "The representation loss after processing this batch is:  0.00011813640594482422\n",
      "The classification loss after processing this batch is:  28080.134765625\n",
      "The representation loss after processing this batch is:  0.0001301337033510208\n",
      "The classification loss after processing this batch is:  26047.884765625\n",
      "The representation loss after processing this batch is:  0.0001493506133556366\n",
      "The classification loss after processing this batch is:  25626.326171875\n",
      "The representation loss after processing this batch is:  0.0001403801143169403\n",
      "The classification loss after processing this batch is:  26700.69140625\n",
      "The representation loss after processing this batch is:  0.00011592172086238861\n",
      "The classification loss after processing this batch is:  26484.01171875\n",
      "The representation loss after processing this batch is:  0.00012245401740074158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  28435.2421875\n",
      "The representation loss after processing this batch is:  0.0001276303082704544\n",
      "The classification loss after processing this batch is:  27705.509765625\n",
      "The representation loss after processing this batch is:  0.00013573560863733292\n",
      "The classification loss after processing this batch is:  26635.419921875\n",
      "The representation loss after processing this batch is:  0.00015486963093280792\n",
      "The classification loss after processing this batch is:  25590.484375\n",
      "The representation loss after processing this batch is:  0.00015526451170444489\n",
      "The classification loss after processing this batch is:  25673.4140625\n",
      "The representation loss after processing this batch is:  0.00012945756316184998\n",
      "The classification loss after processing this batch is:  27331.2421875\n",
      "The representation loss after processing this batch is:  0.00013496167957782745\n",
      "The classification loss after processing this batch is:  28359.5546875\n",
      "The representation loss after processing this batch is:  0.00012541189789772034\n",
      "The classification loss after processing this batch is:  28232.29296875\n",
      "The representation loss after processing this batch is:  0.0001644343137741089\n",
      "The classification loss after processing this batch is:  26306.06640625\n",
      "The representation loss after processing this batch is:  0.00014528818428516388\n",
      "The classification loss after processing this batch is:  27300.328125\n",
      "The representation loss after processing this batch is:  0.00015209242701530457\n",
      "The classification loss after processing this batch is:  26268.646484375\n",
      "The representation loss after processing this batch is:  0.0001490674912929535\n",
      "The classification loss after processing this batch is:  26683.0703125\n",
      "The representation loss after processing this batch is:  0.00016158819198608398\n",
      "The classification loss after processing this batch is:  25896.79296875\n",
      "The representation loss after processing this batch is:  0.00013485737144947052\n",
      "The classification loss after processing this batch is:  26046.513671875\n",
      "The representation loss after processing this batch is:  0.00015035085380077362\n",
      "The classification loss after processing this batch is:  26555.794921875\n",
      "The representation loss after processing this batch is:  0.00012695789337158203\n",
      "The classification loss after processing this batch is:  26894.720703125\n",
      "The representation loss after processing this batch is:  0.00014360062777996063\n",
      "The classification loss after processing this batch is:  26927.30078125\n",
      "The representation loss after processing this batch is:  0.00014341995120048523\n",
      "The classification loss after processing this batch is:  27470.02734375\n",
      "The representation loss after processing this batch is:  0.00013609044253826141\n",
      "The classification loss after processing this batch is:  26678.73828125\n",
      "The representation loss after processing this batch is:  0.00014159828424453735\n",
      "The classification loss after processing this batch is:  26519.57421875\n",
      "The representation loss after processing this batch is:  0.00012782961130142212\n",
      "The classification loss after processing this batch is:  28180.21875\n",
      "The representation loss after processing this batch is:  0.00014775991439819336\n",
      "The classification loss after processing this batch is:  29045.96875\n",
      "The representation loss after processing this batch is:  0.00014264695346355438\n",
      "The classification loss after processing this batch is:  27985.392578125\n",
      "The representation loss after processing this batch is:  0.0001460108906030655\n",
      "The classification loss after processing this batch is:  28179.298828125\n",
      "The representation loss after processing this batch is:  0.00015058740973472595\n",
      "The classification loss after processing this batch is:  26756.54296875\n",
      "The representation loss after processing this batch is:  0.0001303497701883316\n",
      "The classification loss after processing this batch is:  27173.0\n",
      "The representation loss after processing this batch is:  0.00012507103383541107\n",
      "The classification loss after processing this batch is:  28025.521484375\n",
      "The representation loss after processing this batch is:  0.00014839321374893188\n",
      "The classification loss after processing this batch is:  26436.447265625\n",
      "The representation loss after processing this batch is:  0.00015777908265590668\n",
      "The classification loss after processing this batch is:  26256.5859375\n",
      "The representation loss after processing this batch is:  0.00013421662151813507\n",
      "The classification loss after processing this batch is:  27481.37109375\n",
      "The representation loss after processing this batch is:  0.00013701245188713074\n",
      "The classification loss after processing this batch is:  27118.841796875\n",
      "The representation loss after processing this batch is:  0.00013507157564163208\n",
      "The classification loss after processing this batch is:  27259.369140625\n",
      "The representation loss after processing this batch is:  0.000132756307721138\n",
      "The classification loss after processing this batch is:  26362.96875\n",
      "The representation loss after processing this batch is:  0.0001260414719581604\n",
      "The classification loss after processing this batch is:  27604.68359375\n",
      "The representation loss after processing this batch is:  0.00015590526163578033\n",
      "The classification loss after processing this batch is:  27872.9375\n",
      "The representation loss after processing this batch is:  0.00012934580445289612\n",
      "The classification loss after processing this batch is:  28555.58203125\n",
      "The representation loss after processing this batch is:  0.00014138594269752502\n",
      "The classification loss after processing this batch is:  28249.859375\n",
      "The representation loss after processing this batch is:  0.00014495663344860077\n",
      "The classification loss after processing this batch is:  27211.07421875\n",
      "The representation loss after processing this batch is:  0.00013741478323936462\n",
      "The classification loss after processing this batch is:  26510.0546875\n",
      "The representation loss after processing this batch is:  0.00014259107410907745\n",
      "The classification loss after processing this batch is:  26698.3359375\n",
      "The representation loss after processing this batch is:  0.00014329887926578522\n",
      "The classification loss after processing this batch is:  26392.3046875\n",
      "The representation loss after processing this batch is:  0.00014992058277130127\n",
      "The classification loss after processing this batch is:  26078.6328125\n",
      "The representation loss after processing this batch is:  0.0001441407948732376\n",
      "The classification loss after processing this batch is:  25944.583984375\n",
      "The representation loss after processing this batch is:  0.00013832375407218933\n",
      "The classification loss after processing this batch is:  26824.017578125\n",
      "The representation loss after processing this batch is:  0.00012363307178020477\n",
      "The classification loss after processing this batch is:  26943.365234375\n",
      "The representation loss after processing this batch is:  0.00014092028141021729\n",
      "The classification loss after processing this batch is:  31061.3671875\n",
      "The representation loss after processing this batch is:  0.00015653669834136963\n",
      "The classification loss after processing this batch is:  29800.9765625\n",
      "The representation loss after processing this batch is:  0.00014906562864780426\n",
      "The classification loss after processing this batch is:  27072.7734375\n",
      "The representation loss after processing this batch is:  0.0001289602369070053\n",
      "The classification loss after processing this batch is:  25931.5234375\n",
      "The representation loss after processing this batch is:  0.00014680251479148865\n",
      "The classification loss after processing this batch is:  26272.287109375\n",
      "The representation loss after processing this batch is:  0.00013456866145133972\n",
      "The classification loss after processing this batch is:  26548.44140625\n",
      "The representation loss after processing this batch is:  0.00017446652054786682\n",
      "The classification loss after processing this batch is:  26519.68359375\n",
      "The representation loss after processing this batch is:  0.00013552606105804443\n",
      "The classification loss after processing this batch is:  26923.265625\n",
      "The representation loss after processing this batch is:  0.00012770295143127441\n",
      "The classification loss after processing this batch is:  27705.73828125\n",
      "The representation loss after processing this batch is:  0.0001408662647008896\n",
      "The classification loss after processing this batch is:  26582.33984375\n",
      "The representation loss after processing this batch is:  0.0001240912824869156\n",
      "The classification loss after processing this batch is:  26074.580078125\n",
      "The representation loss after processing this batch is:  0.0001404639333486557\n",
      "The classification loss after processing this batch is:  27144.55078125\n",
      "The representation loss after processing this batch is:  0.00013994798064231873\n",
      "The classification loss after processing this batch is:  27550.82421875\n",
      "The representation loss after processing this batch is:  0.0001646038144826889\n",
      "The classification loss after processing this batch is:  26604.2734375\n",
      "The representation loss after processing this batch is:  0.00013397261500358582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  27842.677734375\n",
      "The representation loss after processing this batch is:  0.0001373235136270523\n",
      "The classification loss after processing this batch is:  29452.7734375\n",
      "The representation loss after processing this batch is:  0.00013915449380874634\n",
      "The classification loss after processing this batch is:  27782.556640625\n",
      "The representation loss after processing this batch is:  0.00013648904860019684\n",
      "The classification loss after processing this batch is:  28841.216796875\n",
      "The representation loss after processing this batch is:  0.00013392604887485504\n",
      "The classification loss after processing this batch is:  27290.41796875\n",
      "The representation loss after processing this batch is:  0.0001408848911523819\n",
      "The classification loss after processing this batch is:  28525.24609375\n",
      "The representation loss after processing this batch is:  0.0001588147133588791\n",
      "The classification loss after processing this batch is:  27248.1953125\n",
      "The representation loss after processing this batch is:  0.0001570768654346466\n",
      "The classification loss after processing this batch is:  27680.34765625\n",
      "The representation loss after processing this batch is:  0.00014326535165309906\n",
      "The classification loss after processing this batch is:  26800.65234375\n",
      "The representation loss after processing this batch is:  0.0001338385045528412\n",
      "The classification loss after processing this batch is:  26625.8125\n",
      "The representation loss after processing this batch is:  0.00012130476534366608\n",
      "The classification loss after processing this batch is:  27106.49609375\n",
      "The representation loss after processing this batch is:  0.00013493560254573822\n",
      "The classification loss after processing this batch is:  26132.9765625\n",
      "The representation loss after processing this batch is:  0.00013095326721668243\n",
      "The classification loss after processing this batch is:  26289.94921875\n",
      "The representation loss after processing this batch is:  0.0001311562955379486\n",
      "The classification loss after processing this batch is:  26048.3359375\n",
      "The representation loss after processing this batch is:  0.00014733150601387024\n",
      "The classification loss after processing this batch is:  26368.38671875\n",
      "The representation loss after processing this batch is:  0.00015818513929843903\n",
      "The classification loss after processing this batch is:  25862.17578125\n",
      "The representation loss after processing this batch is:  0.0001350007951259613\n",
      "The classification loss after processing this batch is:  27479.076171875\n",
      "The representation loss after processing this batch is:  0.00014019012451171875\n",
      "The classification loss after processing this batch is:  26785.953125\n",
      "The representation loss after processing this batch is:  0.00015036016702651978\n",
      "The classification loss after processing this batch is:  27115.3515625\n",
      "The representation loss after processing this batch is:  0.00014122948050498962\n",
      "The classification loss after processing this batch is:  27631.921875\n",
      "The representation loss after processing this batch is:  0.0001360839232802391\n",
      "The classification loss after processing this batch is:  26935.43359375\n",
      "The representation loss after processing this batch is:  0.00012563075870275497\n",
      "The classification loss after processing this batch is:  27872.935546875\n",
      "The representation loss after processing this batch is:  0.0001368485391139984\n",
      "The classification loss after processing this batch is:  27757.6796875\n",
      "The representation loss after processing this batch is:  0.00015764683485031128\n",
      "The classification loss after processing this batch is:  26518.4765625\n",
      "The representation loss after processing this batch is:  0.00013049878180027008\n",
      "The classification loss after processing this batch is:  27760.673828125\n",
      "The representation loss after processing this batch is:  0.00014089792966842651\n",
      "The classification loss after processing this batch is:  27285.587890625\n",
      "The representation loss after processing this batch is:  0.00014363043010234833\n",
      "The classification loss after processing this batch is:  26672.87109375\n",
      "The representation loss after processing this batch is:  0.0001280028373003006\n",
      "The classification loss after processing this batch is:  27428.4609375\n",
      "The representation loss after processing this batch is:  0.00014314614236354828\n",
      "The classification loss after processing this batch is:  26939.4296875\n",
      "The representation loss after processing this batch is:  0.00013889186084270477\n",
      "The classification loss after processing this batch is:  29282.982421875\n",
      "The representation loss after processing this batch is:  0.00015379488468170166\n",
      "The classification loss after processing this batch is:  29128.291015625\n",
      "The representation loss after processing this batch is:  0.00011926703155040741\n",
      "The classification loss after processing this batch is:  26856.72265625\n",
      "The representation loss after processing this batch is:  0.0001670699566602707\n",
      "The classification loss after processing this batch is:  30769.84765625\n",
      "The representation loss after processing this batch is:  0.0001293811947107315\n",
      "The classification loss after processing this batch is:  30254.712890625\n",
      "The representation loss after processing this batch is:  0.00012866221368312836\n",
      "The classification loss after processing this batch is:  26860.796875\n",
      "The representation loss after processing this batch is:  0.0001255366951227188\n",
      "The classification loss after processing this batch is:  27503.900390625\n",
      "The representation loss after processing this batch is:  0.00013472232967615128\n",
      "The classification loss after processing this batch is:  27943.4296875\n",
      "The representation loss after processing this batch is:  0.0001370515674352646\n",
      "The classification loss after processing this batch is:  27248.943359375\n",
      "The representation loss after processing this batch is:  0.00013669300824403763\n",
      "The classification loss after processing this batch is:  27704.1796875\n",
      "The representation loss after processing this batch is:  0.00015847012400627136\n",
      "The classification loss after processing this batch is:  27343.46484375\n",
      "The representation loss after processing this batch is:  0.00012997165322303772\n",
      "The classification loss after processing this batch is:  27349.802734375\n",
      "The representation loss after processing this batch is:  0.00012328475713729858\n",
      "The classification loss after processing this batch is:  28363.4765625\n",
      "The representation loss after processing this batch is:  0.0001342538744211197\n",
      "The classification loss after processing this batch is:  27763.5546875\n",
      "The representation loss after processing this batch is:  0.00013162009418010712\n",
      "The classification loss after processing this batch is:  28755.33984375\n",
      "The representation loss after processing this batch is:  0.00016808882355690002\n",
      "The classification loss after processing this batch is:  28232.642578125\n",
      "The representation loss after processing this batch is:  0.00013434886932373047\n",
      "The classification loss after processing this batch is:  28994.41015625\n",
      "The representation loss after processing this batch is:  0.00013082846999168396\n",
      "The classification loss after processing this batch is:  26366.78125\n",
      "The representation loss after processing this batch is:  0.00012915581464767456\n",
      "The classification loss after processing this batch is:  26950.34375\n",
      "The representation loss after processing this batch is:  0.00012934580445289612\n",
      "The classification loss after processing this batch is:  28071.513671875\n",
      "The representation loss after processing this batch is:  0.00013335607945919037\n",
      "The classification loss after processing this batch is:  27017.40625\n",
      "The representation loss after processing this batch is:  0.00014469213783740997\n",
      "The classification loss after processing this batch is:  25869.84375\n",
      "The representation loss after processing this batch is:  0.0001338385045528412\n",
      "The classification loss after processing this batch is:  27915.912109375\n",
      "The representation loss after processing this batch is:  0.00011540018022060394\n",
      "The classification loss after processing this batch is:  26320.6328125\n",
      "The representation loss after processing this batch is:  0.0001340564340353012\n",
      "The classification loss after processing this batch is:  27030.421875\n",
      "The representation loss after processing this batch is:  0.0001242849975824356\n",
      "The classification loss after processing this batch is:  26398.796875\n",
      "The representation loss after processing this batch is:  0.00012913905084133148\n",
      "The classification loss after processing this batch is:  27101.455078125\n",
      "The representation loss after processing this batch is:  0.00013803504407405853\n",
      "The classification loss after processing this batch is:  26172.201171875\n",
      "The representation loss after processing this batch is:  0.00013542361557483673\n",
      "The classification loss after processing this batch is:  27268.4140625\n",
      "The representation loss after processing this batch is:  0.0001233164221048355\n",
      "The classification loss after processing this batch is:  27153.921875\n",
      "The representation loss after processing this batch is:  0.00013801828026771545\n",
      "The classification loss after processing this batch is:  26398.03125\n",
      "The representation loss after processing this batch is:  0.00014656223356723785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  27827.181640625\n",
      "The representation loss after processing this batch is:  0.00015005655586719513\n",
      "The classification loss after processing this batch is:  28212.17578125\n",
      "The representation loss after processing this batch is:  0.00012876465916633606\n",
      "The classification loss after processing this batch is:  26391.32421875\n",
      "The representation loss after processing this batch is:  0.0001395139843225479\n",
      "The classification loss after processing this batch is:  26809.830078125\n",
      "The representation loss after processing this batch is:  0.0001491699367761612\n",
      "The classification loss after processing this batch is:  26694.80078125\n",
      "The representation loss after processing this batch is:  0.00012111291289329529\n",
      "The classification loss after processing this batch is:  27086.71875\n",
      "The representation loss after processing this batch is:  0.00011983327567577362\n",
      "The classification loss after processing this batch is:  28464.28125\n",
      "The representation loss after processing this batch is:  0.00013235583901405334\n",
      "The classification loss after processing this batch is:  26542.19921875\n",
      "The representation loss after processing this batch is:  0.00012189708650112152\n",
      "The classification loss after processing this batch is:  25955.56640625\n",
      "The representation loss after processing this batch is:  0.00012916140258312225\n",
      "The classification loss after processing this batch is:  27246.046875\n",
      "The representation loss after processing this batch is:  0.00012758933007717133\n",
      "The classification loss after processing this batch is:  29211.724609375\n",
      "The representation loss after processing this batch is:  0.00013989396393299103\n",
      "The classification loss after processing this batch is:  26810.5859375\n",
      "The representation loss after processing this batch is:  0.00013311021029949188\n",
      "The classification loss after processing this batch is:  27423.03515625\n",
      "The representation loss after processing this batch is:  0.00013247597962617874\n",
      "The classification loss after processing this batch is:  28633.666015625\n",
      "The representation loss after processing this batch is:  0.00013000331819057465\n",
      "The classification loss after processing this batch is:  27174.890625\n",
      "The representation loss after processing this batch is:  0.00013534165918827057\n",
      "The classification loss after processing this batch is:  25992.28515625\n",
      "The representation loss after processing this batch is:  0.00014064274728298187\n",
      "The classification loss after processing this batch is:  25948.95703125\n",
      "The representation loss after processing this batch is:  0.00014891847968101501\n",
      "The classification loss after processing this batch is:  26150.93359375\n",
      "The representation loss after processing this batch is:  0.00011832453310489655\n",
      "The classification loss after processing this batch is:  26673.79296875\n",
      "The representation loss after processing this batch is:  0.00012109614908695221\n",
      "The classification loss after processing this batch is:  25980.52734375\n",
      "The representation loss after processing this batch is:  0.0001305602490901947\n",
      "The classification loss after processing this batch is:  27080.2734375\n",
      "The representation loss after processing this batch is:  0.000125151127576828\n",
      "The classification loss after processing this batch is:  30245.484375\n",
      "The representation loss after processing this batch is:  0.00014994479715824127\n",
      "The classification loss after processing this batch is:  28316.8984375\n",
      "The representation loss after processing this batch is:  0.00012694858014583588\n",
      "The classification loss after processing this batch is:  27095.95703125\n",
      "The representation loss after processing this batch is:  0.00012401863932609558\n",
      "The classification loss after processing this batch is:  26336.84375\n",
      "The representation loss after processing this batch is:  0.00014136917889118195\n",
      "The classification loss after processing this batch is:  27062.140625\n",
      "The representation loss after processing this batch is:  0.00013649649918079376\n",
      "The classification loss after processing this batch is:  26706.982421875\n",
      "The representation loss after processing this batch is:  0.00017613545060157776\n",
      "The classification loss after processing this batch is:  26765.73828125\n",
      "The representation loss after processing this batch is:  0.0001247003674507141\n",
      "The classification loss after processing this batch is:  26077.978515625\n",
      "The representation loss after processing this batch is:  0.00012963823974132538\n",
      "The classification loss after processing this batch is:  26508.90234375\n",
      "The representation loss after processing this batch is:  0.00013075396418571472\n",
      "The classification loss after processing this batch is:  26238.1328125\n",
      "The representation loss after processing this batch is:  0.00012167729437351227\n",
      "The classification loss after processing this batch is:  25615.427734375\n",
      "The representation loss after processing this batch is:  0.0001412276178598404\n",
      "The classification loss after processing this batch is:  26581.125\n",
      "The representation loss after processing this batch is:  0.00013997219502925873\n",
      "The classification loss after processing this batch is:  25277.34375\n",
      "The representation loss after processing this batch is:  0.00013032928109169006\n",
      "The classification loss after processing this batch is:  27811.64453125\n",
      "The representation loss after processing this batch is:  0.00013056211173534393\n",
      "The classification loss after processing this batch is:  27771.1015625\n",
      "The representation loss after processing this batch is:  0.0001263488084077835\n",
      "The classification loss after processing this batch is:  26551.1640625\n",
      "The representation loss after processing this batch is:  0.00013703666627407074\n",
      "The classification loss after processing this batch is:  26983.748046875\n",
      "The representation loss after processing this batch is:  0.00012019462883472443\n",
      "The classification loss after processing this batch is:  26953.978515625\n",
      "The representation loss after processing this batch is:  0.00014201737940311432\n",
      "The classification loss after processing this batch is:  28143.33203125\n",
      "The representation loss after processing this batch is:  0.00013940781354904175\n",
      "The classification loss after processing this batch is:  27627.361328125\n",
      "The representation loss after processing this batch is:  0.00012612156569957733\n",
      "The classification loss after processing this batch is:  26610.19921875\n",
      "The representation loss after processing this batch is:  0.0001481659710407257\n",
      "The classification loss after processing this batch is:  26915.80078125\n",
      "The representation loss after processing this batch is:  0.00013275258243083954\n",
      "The classification loss after processing this batch is:  28394.322265625\n",
      "The representation loss after processing this batch is:  0.00014013610780239105\n",
      "The classification loss after processing this batch is:  26055.890625\n",
      "The representation loss after processing this batch is:  0.00012442655861377716\n",
      "The classification loss after processing this batch is:  26824.322265625\n",
      "The representation loss after processing this batch is:  0.00011864583939313889\n",
      "The classification loss after processing this batch is:  26291.498046875\n",
      "The representation loss after processing this batch is:  0.00015166960656642914\n",
      "The classification loss after processing this batch is:  26697.224609375\n",
      "The representation loss after processing this batch is:  0.00013564061373472214\n",
      "The classification loss after processing this batch is:  27336.85546875\n",
      "The representation loss after processing this batch is:  0.00012955814599990845\n",
      "The classification loss after processing this batch is:  27816.46484375\n",
      "The representation loss after processing this batch is:  0.00015044864267110825\n",
      "The classification loss after processing this batch is:  26356.27734375\n",
      "The representation loss after processing this batch is:  0.00015348941087722778\n",
      "The classification loss after processing this batch is:  27566.724609375\n",
      "The representation loss after processing this batch is:  0.00012945104390382767\n",
      "The classification loss after processing this batch is:  28025.01953125\n",
      "The representation loss after processing this batch is:  0.000131889246404171\n",
      "The classification loss after processing this batch is:  26405.4609375\n",
      "The representation loss after processing this batch is:  0.0001485142856836319\n",
      "The classification loss after processing this batch is:  27438.06640625\n",
      "The representation loss after processing this batch is:  0.00012353621423244476\n",
      "The classification loss after processing this batch is:  26780.9453125\n",
      "The representation loss after processing this batch is:  0.0001410171389579773\n",
      "The classification loss after processing this batch is:  25990.958984375\n",
      "The representation loss after processing this batch is:  0.00014026835560798645\n",
      "The classification loss after processing this batch is:  26122.771484375\n",
      "The representation loss after processing this batch is:  0.00011176243424415588\n",
      "The classification loss after processing this batch is:  26458.818359375\n",
      "The representation loss after processing this batch is:  0.00012924708425998688\n",
      "The classification loss after processing this batch is:  26326.48828125\n",
      "The representation loss after processing this batch is:  0.00014910567551851273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  27633.974609375\n",
      "The representation loss after processing this batch is:  0.00012970715761184692\n",
      "The classification loss after processing this batch is:  27597.009765625\n",
      "The representation loss after processing this batch is:  0.000131094828248024\n",
      "The classification loss after processing this batch is:  28617.54296875\n",
      "The representation loss after processing this batch is:  0.00013831444084644318\n",
      "The classification loss after processing this batch is:  25494.64453125\n",
      "The representation loss after processing this batch is:  0.00012644007802009583\n",
      "The classification loss after processing this batch is:  25648.21484375\n",
      "The representation loss after processing this batch is:  0.00013959035277366638\n",
      "The classification loss after processing this batch is:  26382.828125\n",
      "The representation loss after processing this batch is:  0.0001717880368232727\n",
      "The classification loss after processing this batch is:  26384.705078125\n",
      "The representation loss after processing this batch is:  0.00012374669313430786\n",
      "The classification loss after processing this batch is:  27737.58203125\n",
      "The representation loss after processing this batch is:  0.0001440085470676422\n",
      "The classification loss after processing this batch is:  26626.66015625\n",
      "The representation loss after processing this batch is:  0.00013823248445987701\n",
      "The classification loss after processing this batch is:  26836.13671875\n",
      "The representation loss after processing this batch is:  0.00013226084411144257\n",
      "The classification loss after processing this batch is:  26791.125\n",
      "The representation loss after processing this batch is:  0.00012576580047607422\n",
      "The classification loss after processing this batch is:  26227.724609375\n",
      "The representation loss after processing this batch is:  0.00013359449803829193\n",
      "The classification loss after processing this batch is:  28040.70703125\n",
      "The representation loss after processing this batch is:  0.00013234280049800873\n",
      "The classification loss after processing this batch is:  28100.15234375\n",
      "The representation loss after processing this batch is:  0.00012138299643993378\n",
      "The classification loss after processing this batch is:  27453.69921875\n",
      "The representation loss after processing this batch is:  0.00012711435556411743\n",
      "The classification loss after processing this batch is:  25663.060546875\n",
      "The representation loss after processing this batch is:  0.00013393908739089966\n",
      "The classification loss after processing this batch is:  27921.75390625\n",
      "The representation loss after processing this batch is:  0.00014162249863147736\n",
      "The classification loss after processing this batch is:  27661.537109375\n",
      "The representation loss after processing this batch is:  0.00012074783444404602\n",
      "The classification loss after processing this batch is:  26364.673828125\n",
      "The representation loss after processing this batch is:  0.00012420490384101868\n",
      "The classification loss after processing this batch is:  28724.53515625\n",
      "The representation loss after processing this batch is:  0.00013372115790843964\n",
      "The classification loss after processing this batch is:  28260.673828125\n",
      "The representation loss after processing this batch is:  0.00014314055442810059\n",
      "The classification loss after processing this batch is:  25737.50390625\n",
      "The representation loss after processing this batch is:  0.00012812763452529907\n",
      "The classification loss after processing this batch is:  26424.021484375\n",
      "The representation loss after processing this batch is:  0.00013686716556549072\n",
      "The classification loss after processing this batch is:  27305.29296875\n",
      "The representation loss after processing this batch is:  0.00012800376862287521\n",
      "The classification loss after processing this batch is:  26815.849609375\n",
      "The representation loss after processing this batch is:  0.00014244578778743744\n",
      "The classification loss after processing this batch is:  27457.927734375\n",
      "The representation loss after processing this batch is:  0.0001277495175600052\n",
      "The classification loss after processing this batch is:  27749.439453125\n",
      "The representation loss after processing this batch is:  0.0001492537558078766\n",
      "The classification loss after processing this batch is:  25868.69921875\n",
      "The representation loss after processing this batch is:  0.00015439651906490326\n",
      "The classification loss after processing this batch is:  25968.9609375\n",
      "The representation loss after processing this batch is:  0.00014554522931575775\n",
      "The classification loss after processing this batch is:  27521.869140625\n",
      "The representation loss after processing this batch is:  0.00011281203478574753\n",
      "The classification loss after processing this batch is:  28867.583984375\n",
      "The representation loss after processing this batch is:  0.00013186968863010406\n",
      "The classification loss after processing this batch is:  27265.51953125\n",
      "The representation loss after processing this batch is:  0.00011854618787765503\n",
      "The classification loss after processing this batch is:  27442.86328125\n",
      "The representation loss after processing this batch is:  0.00012837164103984833\n",
      "The classification loss after processing this batch is:  27287.49609375\n",
      "The representation loss after processing this batch is:  0.00011279061436653137\n",
      "The classification loss after processing this batch is:  27466.14453125\n",
      "The representation loss after processing this batch is:  0.00011456944048404694\n",
      "The classification loss after processing this batch is:  26561.640625\n",
      "The representation loss after processing this batch is:  0.00013629719614982605\n",
      "The classification loss after processing this batch is:  26547.0625\n",
      "The representation loss after processing this batch is:  0.0001256559044122696\n",
      "The classification loss after processing this batch is:  27791.568359375\n",
      "The representation loss after processing this batch is:  0.0001281891018152237\n",
      "The classification loss after processing this batch is:  25765.634765625\n",
      "The representation loss after processing this batch is:  0.0001402115449309349\n",
      "The classification loss after processing this batch is:  26486.12109375\n",
      "The representation loss after processing this batch is:  0.0001217573881149292\n",
      "The classification loss after processing this batch is:  26286.890625\n",
      "The representation loss after processing this batch is:  0.00012845918536186218\n",
      "The classification loss after processing this batch is:  25750.015625\n",
      "The representation loss after processing this batch is:  0.00012232549488544464\n",
      "The classification loss after processing this batch is:  26016.375\n",
      "The representation loss after processing this batch is:  0.00011874549090862274\n",
      "The classification loss after processing this batch is:  27353.53125\n",
      "The representation loss after processing this batch is:  0.00013972818851470947\n",
      "The classification loss after processing this batch is:  26900.875\n",
      "The representation loss after processing this batch is:  0.00012274086475372314\n",
      "The classification loss after processing this batch is:  25717.62109375\n",
      "The representation loss after processing this batch is:  0.0001271069049835205\n",
      "The classification loss after processing this batch is:  26168.26171875\n",
      "The representation loss after processing this batch is:  0.0001316312700510025\n",
      "The classification loss after processing this batch is:  26143.72265625\n",
      "The representation loss after processing this batch is:  0.00013101939111948013\n",
      "The classification loss after processing this batch is:  26657.5078125\n",
      "The representation loss after processing this batch is:  0.0001402590423822403\n",
      "The classification loss after processing this batch is:  26789.30078125\n",
      "The representation loss after processing this batch is:  0.00014393404126167297\n",
      "The classification loss after processing this batch is:  25738.396484375\n",
      "The representation loss after processing this batch is:  0.00012728385627269745\n",
      "The classification loss after processing this batch is:  28251.171875\n",
      "The representation loss after processing this batch is:  0.00013531185686588287\n",
      "The classification loss after processing this batch is:  26172.779296875\n",
      "The representation loss after processing this batch is:  0.00012610573321580887\n",
      "The classification loss after processing this batch is:  25544.3125\n",
      "The representation loss after processing this batch is:  0.00012733973562717438\n",
      "The classification loss after processing this batch is:  26274.4921875\n",
      "The representation loss after processing this batch is:  0.00013234466314315796\n",
      "The classification loss after processing this batch is:  27189.794921875\n",
      "The representation loss after processing this batch is:  0.0001396220177412033\n",
      "The classification loss after processing this batch is:  26506.76953125\n",
      "The representation loss after processing this batch is:  0.00014385394752025604\n",
      "The classification loss after processing this batch is:  25796.078125\n",
      "The representation loss after processing this batch is:  0.00013847090303897858\n",
      "The classification loss after processing this batch is:  26786.8203125\n",
      "The representation loss after processing this batch is:  0.00011984072625637054\n",
      "The classification loss after processing this batch is:  28177.802734375\n",
      "The representation loss after processing this batch is:  0.0001279190182685852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  25529.283203125\n",
      "The representation loss after processing this batch is:  0.0001281537115573883\n",
      "The classification loss after processing this batch is:  26153.40234375\n",
      "The representation loss after processing this batch is:  0.00012520141899585724\n",
      "The classification loss after processing this batch is:  25109.37890625\n",
      "The representation loss after processing this batch is:  0.000131191685795784\n",
      "The classification loss after processing this batch is:  26311.123046875\n",
      "The representation loss after processing this batch is:  0.0001272512599825859\n",
      "The classification loss after processing this batch is:  26510.46875\n",
      "The representation loss after processing this batch is:  0.00012103281915187836\n",
      "The classification loss after processing this batch is:  26108.046875\n",
      "The representation loss after processing this batch is:  0.0001208726316690445\n",
      "The classification loss after processing this batch is:  25789.0625\n",
      "The representation loss after processing this batch is:  0.0001394767314195633\n",
      "The classification loss after processing this batch is:  25360.478515625\n",
      "The representation loss after processing this batch is:  0.00012931600213050842\n",
      "The classification loss after processing this batch is:  25763.69921875\n",
      "The representation loss after processing this batch is:  0.00013045966625213623\n",
      "The classification loss after processing this batch is:  26063.017578125\n",
      "The representation loss after processing this batch is:  0.00012467801570892334\n",
      "The classification loss after processing this batch is:  25268.984375\n",
      "The representation loss after processing this batch is:  0.00013793818652629852\n",
      "The classification loss after processing this batch is:  29718.12109375\n",
      "The representation loss after processing this batch is:  0.00012947432696819305\n",
      "The classification loss after processing this batch is:  28041.697265625\n",
      "The representation loss after processing this batch is:  0.0001222621649503708\n",
      "The classification loss after processing this batch is:  27172.5859375\n",
      "The representation loss after processing this batch is:  0.00012837164103984833\n",
      "The classification loss after processing this batch is:  26060.609375\n",
      "The representation loss after processing this batch is:  0.00013411417603492737\n",
      "The classification loss after processing this batch is:  25392.51953125\n",
      "The representation loss after processing this batch is:  0.00015669874846935272\n",
      "The classification loss after processing this batch is:  26465.08984375\n",
      "The representation loss after processing this batch is:  0.00012465380132198334\n",
      "The classification loss after processing this batch is:  26943.955078125\n",
      "The representation loss after processing this batch is:  0.00013235583901405334\n",
      "The classification loss after processing this batch is:  26367.814453125\n",
      "The representation loss after processing this batch is:  0.00012142211198806763\n",
      "The classification loss after processing this batch is:  28504.24609375\n",
      "The representation loss after processing this batch is:  0.0001282375305891037\n",
      "The classification loss after processing this batch is:  26650.798828125\n",
      "The representation loss after processing this batch is:  0.00013572163879871368\n",
      "The classification loss after processing this batch is:  25617.36328125\n",
      "The representation loss after processing this batch is:  0.00013840943574905396\n",
      "The classification loss after processing this batch is:  27326.0\n",
      "The representation loss after processing this batch is:  0.0001375339925289154\n",
      "The classification loss after processing this batch is:  25844.05859375\n",
      "The representation loss after processing this batch is:  0.00012548081576824188\n",
      "The classification loss after processing this batch is:  26245.990234375\n",
      "The representation loss after processing this batch is:  0.00012142769992351532\n",
      "The classification loss after processing this batch is:  29712.09375\n",
      "The representation loss after processing this batch is:  0.0001429375261068344\n",
      "The classification loss after processing this batch is:  28179.74609375\n",
      "The representation loss after processing this batch is:  0.00016116350889205933\n",
      "The classification loss after processing this batch is:  25647.00390625\n",
      "The representation loss after processing this batch is:  0.0001492537558078766\n",
      "The classification loss after processing this batch is:  25538.65625\n",
      "The representation loss after processing this batch is:  0.00027061067521572113\n",
      "The classification loss after processing this batch is:  28515.359375\n",
      "The representation loss after processing this batch is:  0.00015433691442012787\n",
      "The classification loss after processing this batch is:  25961.44140625\n",
      "The representation loss after processing this batch is:  0.00013822689652442932\n",
      "The classification loss after processing this batch is:  25571.1875\n",
      "The representation loss after processing this batch is:  0.00015223585069179535\n",
      "The classification loss after processing this batch is:  25823.369140625\n",
      "The representation loss after processing this batch is:  0.00016023404896259308\n",
      "The classification loss after processing this batch is:  30814.189453125\n",
      "The representation loss after processing this batch is:  0.00016496889293193817\n",
      "The classification loss after processing this batch is:  34091.09375\n",
      "The representation loss after processing this batch is:  0.00015306100249290466\n",
      "The classification loss after processing this batch is:  26141.86328125\n",
      "The representation loss after processing this batch is:  0.0001345425844192505\n",
      "The classification loss after processing this batch is:  27454.466796875\n",
      "The representation loss after processing this batch is:  0.00013835355639457703\n",
      "The classification loss after processing this batch is:  26854.044921875\n",
      "The representation loss after processing this batch is:  0.00015634484589099884\n",
      "The classification loss after processing this batch is:  24063.92578125\n",
      "The representation loss after processing this batch is:  0.0001409444957971573\n",
      "The classification loss after processing this batch is:  26929.96484375\n",
      "The representation loss after processing this batch is:  9.652413427829742e-05\n",
      "The classification loss after processing this batch is:  26836.63671875\n",
      "The representation loss after processing this batch is:  9.148009121417999e-05\n",
      "The classification loss after processing this batch is:  25447.80859375\n",
      "The representation loss after processing this batch is:  9.872205555438995e-05\n",
      "The classification loss after processing this batch is:  25927.546875\n",
      "The representation loss after processing this batch is:  9.401887655258179e-05\n",
      "The classification loss after processing this batch is:  26461.287109375\n",
      "The representation loss after processing this batch is:  8.440297096967697e-05\n",
      "The classification loss after processing this batch is:  27068.646484375\n",
      "The representation loss after processing this batch is:  8.10595229268074e-05\n",
      "The classification loss after processing this batch is:  27139.404296875\n",
      "The representation loss after processing this batch is:  9.780190885066986e-05\n",
      "The classification loss after processing this batch is:  26314.61328125\n",
      "The representation loss after processing this batch is:  8.032843470573425e-05\n",
      "The classification loss after processing this batch is:  25907.05859375\n",
      "The representation loss after processing this batch is:  7.79367983341217e-05\n",
      "The classification loss after processing this batch is:  29006.12109375\n",
      "The representation loss after processing this batch is:  8.326862007379532e-05\n",
      "The classification loss after processing this batch is:  27770.83203125\n",
      "The representation loss after processing this batch is:  7.342174649238586e-05\n",
      "The classification loss after processing this batch is:  26170.513671875\n",
      "The representation loss after processing this batch is:  7.449835538864136e-05\n",
      "The classification loss after processing this batch is:  26499.640625\n",
      "The representation loss after processing this batch is:  7.0938840508461e-05\n",
      "The classification loss after processing this batch is:  26284.5625\n",
      "The representation loss after processing this batch is:  8.096173405647278e-05\n",
      "The classification loss after processing this batch is:  26664.443359375\n",
      "The representation loss after processing this batch is:  6.903056055307388e-05\n",
      "The classification loss after processing this batch is:  26732.9296875\n",
      "The representation loss after processing this batch is:  6.536021828651428e-05\n",
      "The classification loss after processing this batch is:  26394.3203125\n",
      "The representation loss after processing this batch is:  6.94524496793747e-05\n",
      "The classification loss after processing this batch is:  27972.357421875\n",
      "The representation loss after processing this batch is:  7.401220500469208e-05\n",
      "The classification loss after processing this batch is:  26870.96875\n",
      "The representation loss after processing this batch is:  7.284898310899734e-05\n",
      "The classification loss after processing this batch is:  27168.109375\n",
      "The representation loss after processing this batch is:  7.29905441403389e-05\n",
      "The classification loss after processing this batch is:  27077.140625\n",
      "The representation loss after processing this batch is:  7.664132863283157e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  26876.9765625\n",
      "The representation loss after processing this batch is:  6.790552288293839e-05\n",
      "The classification loss after processing this batch is:  27332.546875\n",
      "The representation loss after processing this batch is:  7.339846342802048e-05\n",
      "The classification loss after processing this batch is:  26721.81640625\n",
      "The representation loss after processing this batch is:  6.371550261974335e-05\n",
      "The classification loss after processing this batch is:  26338.2578125\n",
      "The representation loss after processing this batch is:  7.071718573570251e-05\n",
      "The classification loss after processing this batch is:  25529.58203125\n",
      "The representation loss after processing this batch is:  7.026176899671555e-05\n",
      "The classification loss after processing this batch is:  25986.015625\n",
      "The representation loss after processing this batch is:  6.471574306488037e-05\n",
      "The classification loss after processing this batch is:  26061.63671875\n",
      "The representation loss after processing this batch is:  5.764700472354889e-05\n",
      "The classification loss after processing this batch is:  28764.873046875\n",
      "The representation loss after processing this batch is:  6.258208304643631e-05\n",
      "The classification loss after processing this batch is:  27217.951171875\n",
      "The representation loss after processing this batch is:  6.522331386804581e-05\n",
      "The classification loss after processing this batch is:  26009.93359375\n",
      "The representation loss after processing this batch is:  6.138626486063004e-05\n",
      "The classification loss after processing this batch is:  26575.017578125\n",
      "The representation loss after processing this batch is:  5.4790638387203217e-05\n",
      "The classification loss after processing this batch is:  25822.994140625\n",
      "The representation loss after processing this batch is:  6.673112511634827e-05\n",
      "The classification loss after processing this batch is:  26326.8125\n",
      "The representation loss after processing this batch is:  6.553251296281815e-05\n",
      "The classification loss after processing this batch is:  26681.0859375\n",
      "The representation loss after processing this batch is:  6.45313411951065e-05\n",
      "The classification loss after processing this batch is:  26837.189453125\n",
      "The representation loss after processing this batch is:  7.260311394929886e-05\n",
      "The classification loss after processing this batch is:  28217.0703125\n",
      "The representation loss after processing this batch is:  6.259791553020477e-05\n",
      "The classification loss after processing this batch is:  31767.787109375\n",
      "The representation loss after processing this batch is:  7.51083716750145e-05\n",
      "The classification loss after processing this batch is:  26490.19140625\n",
      "The representation loss after processing this batch is:  7.4789859354496e-05\n",
      "The classification loss after processing this batch is:  26601.9609375\n",
      "The representation loss after processing this batch is:  5.93261793255806e-05\n",
      "The classification loss after processing this batch is:  26666.0078125\n",
      "The representation loss after processing this batch is:  6.72023743391037e-05\n",
      "The classification loss after processing this batch is:  27107.595703125\n",
      "The representation loss after processing this batch is:  6.488151848316193e-05\n",
      "The classification loss after processing this batch is:  26612.07421875\n",
      "The representation loss after processing this batch is:  6.234273314476013e-05\n",
      "The classification loss after processing this batch is:  26713.83984375\n",
      "The representation loss after processing this batch is:  6.31231814622879e-05\n",
      "The classification loss after processing this batch is:  26677.55859375\n",
      "The representation loss after processing this batch is:  5.690939724445343e-05\n",
      "The classification loss after processing this batch is:  26398.78515625\n",
      "The representation loss after processing this batch is:  6.623007357120514e-05\n",
      "The classification loss after processing this batch is:  26408.318359375\n",
      "The representation loss after processing this batch is:  5.6196004152297974e-05\n",
      "The classification loss after processing this batch is:  26445.08984375\n",
      "The representation loss after processing this batch is:  6.4874067902565e-05\n",
      "The classification loss after processing this batch is:  26157.76953125\n",
      "The representation loss after processing this batch is:  6.309524178504944e-05\n",
      "The classification loss after processing this batch is:  25991.1640625\n",
      "The representation loss after processing this batch is:  6.345566362142563e-05\n",
      "The classification loss after processing this batch is:  25988.26171875\n",
      "The representation loss after processing this batch is:  5.7285651564598083e-05\n",
      "The classification loss after processing this batch is:  24798.52734375\n",
      "The representation loss after processing this batch is:  6.529223173856735e-05\n",
      "The classification loss after processing this batch is:  25566.859375\n",
      "The representation loss after processing this batch is:  7.246527820825577e-05\n",
      "The classification loss after processing this batch is:  25881.29296875\n",
      "The representation loss after processing this batch is:  5.837809294462204e-05\n",
      "The classification loss after processing this batch is:  25850.49609375\n",
      "The representation loss after processing this batch is:  6.154365837574005e-05\n",
      "The classification loss after processing this batch is:  25349.59375\n",
      "The representation loss after processing this batch is:  7.17630609869957e-05\n",
      "The classification loss after processing this batch is:  26834.828125\n",
      "The representation loss after processing this batch is:  6.389059126377106e-05\n",
      "The classification loss after processing this batch is:  25588.671875\n",
      "The representation loss after processing this batch is:  7.452676072716713e-05\n",
      "The classification loss after processing this batch is:  25458.40625\n",
      "The representation loss after processing this batch is:  6.941333413124084e-05\n",
      "The classification loss after processing this batch is:  26184.80078125\n",
      "The representation loss after processing this batch is:  6.692856550216675e-05\n",
      "The classification loss after processing this batch is:  27356.705078125\n",
      "The representation loss after processing this batch is:  6.399489939212799e-05\n",
      "The classification loss after processing this batch is:  28108.359375\n",
      "The representation loss after processing this batch is:  5.710497498512268e-05\n",
      "The classification loss after processing this batch is:  27378.267578125\n",
      "The representation loss after processing this batch is:  6.620585918426514e-05\n",
      "The classification loss after processing this batch is:  24596.15625\n",
      "The representation loss after processing this batch is:  6.462167948484421e-05\n",
      "The classification loss after processing this batch is:  26245.23046875\n",
      "The representation loss after processing this batch is:  5.872268229722977e-05\n",
      "The classification loss after processing this batch is:  25881.42578125\n",
      "The representation loss after processing this batch is:  5.645863711833954e-05\n",
      "The classification loss after processing this batch is:  26343.953125\n",
      "The representation loss after processing this batch is:  6.724148988723755e-05\n",
      "The classification loss after processing this batch is:  26783.625\n",
      "The representation loss after processing this batch is:  6.307940930128098e-05\n",
      "The classification loss after processing this batch is:  25510.4609375\n",
      "The representation loss after processing this batch is:  6.397627294063568e-05\n",
      "The classification loss after processing this batch is:  25728.77734375\n",
      "The representation loss after processing this batch is:  6.745941936969757e-05\n",
      "The classification loss after processing this batch is:  25575.875\n",
      "The representation loss after processing this batch is:  6.451364606618881e-05\n",
      "The classification loss after processing this batch is:  26164.4453125\n",
      "The representation loss after processing this batch is:  7.514655590057373e-05\n",
      "The classification loss after processing this batch is:  25008.73046875\n",
      "The representation loss after processing this batch is:  7.665436714887619e-05\n",
      "The classification loss after processing this batch is:  26492.46484375\n",
      "The representation loss after processing this batch is:  5.5680051445961e-05\n",
      "The classification loss after processing this batch is:  27140.19921875\n",
      "The representation loss after processing this batch is:  6.395205855369568e-05\n",
      "The classification loss after processing this batch is:  27745.603515625\n",
      "The representation loss after processing this batch is:  7.253885269165039e-05\n",
      "The classification loss after processing this batch is:  25388.11328125\n",
      "The representation loss after processing this batch is:  6.611179560422897e-05\n",
      "The classification loss after processing this batch is:  25140.88671875\n",
      "The representation loss after processing this batch is:  6.317533552646637e-05\n",
      "The classification loss after processing this batch is:  25224.66015625\n",
      "The representation loss after processing this batch is:  6.346218287944794e-05\n",
      "The classification loss after processing this batch is:  25996.0\n",
      "The representation loss after processing this batch is:  5.474220961332321e-05\n",
      "The classification loss after processing this batch is:  26963.859375\n",
      "The representation loss after processing this batch is:  5.942583084106445e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  25566.466796875\n",
      "The representation loss after processing this batch is:  6.641633808612823e-05\n",
      "The classification loss after processing this batch is:  24976.716796875\n",
      "The representation loss after processing this batch is:  5.802139639854431e-05\n",
      "The classification loss after processing this batch is:  25633.951171875\n",
      "The representation loss after processing this batch is:  6.669200956821442e-05\n",
      "The classification loss after processing this batch is:  24707.30859375\n",
      "The representation loss after processing this batch is:  5.793105810880661e-05\n",
      "The classification loss after processing this batch is:  25177.38671875\n",
      "The representation loss after processing this batch is:  5.805399268865585e-05\n",
      "The classification loss after processing this batch is:  24991.7265625\n",
      "The representation loss after processing this batch is:  6.538350135087967e-05\n",
      "The classification loss after processing this batch is:  24734.96875\n",
      "The representation loss after processing this batch is:  6.127357482910156e-05\n",
      "The classification loss after processing this batch is:  24386.5078125\n",
      "The representation loss after processing this batch is:  6.193574517965317e-05\n",
      "The classification loss after processing this batch is:  24258.8046875\n",
      "The representation loss after processing this batch is:  6.272923201322556e-05\n",
      "The classification loss after processing this batch is:  24554.40234375\n",
      "The representation loss after processing this batch is:  5.507655441761017e-05\n",
      "The classification loss after processing this batch is:  24200.90625\n",
      "The representation loss after processing this batch is:  6.439629942178726e-05\n",
      "The classification loss after processing this batch is:  24599.56640625\n",
      "The representation loss after processing this batch is:  6.247218698263168e-05\n",
      "The classification loss after processing this batch is:  24961.6015625\n",
      "The representation loss after processing this batch is:  5.691498517990112e-05\n",
      "The classification loss after processing this batch is:  24292.330078125\n",
      "The representation loss after processing this batch is:  5.838368088006973e-05\n",
      "The classification loss after processing this batch is:  26345.896484375\n",
      "The representation loss after processing this batch is:  5.4026953876018524e-05\n",
      "The classification loss after processing this batch is:  25793.56640625\n",
      "The representation loss after processing this batch is:  5.738064646720886e-05\n",
      "The classification loss after processing this batch is:  26661.576171875\n",
      "The representation loss after processing this batch is:  6.144214421510696e-05\n",
      "The classification loss after processing this batch is:  27009.6171875\n",
      "The representation loss after processing this batch is:  6.640423089265823e-05\n",
      "The classification loss after processing this batch is:  27063.9140625\n",
      "The representation loss after processing this batch is:  6.066169589757919e-05\n",
      "The classification loss after processing this batch is:  26207.26953125\n",
      "The representation loss after processing this batch is:  6.514601409435272e-05\n",
      "The classification loss after processing this batch is:  25754.79296875\n",
      "The representation loss after processing this batch is:  6.647687405347824e-05\n",
      "The classification loss after processing this batch is:  25395.025390625\n",
      "The representation loss after processing this batch is:  5.9281475841999054e-05\n",
      "The classification loss after processing this batch is:  25995.333984375\n",
      "The representation loss after processing this batch is:  6.792135536670685e-05\n",
      "The classification loss after processing this batch is:  25148.30859375\n",
      "The representation loss after processing this batch is:  5.494058132171631e-05\n",
      "The classification loss after processing this batch is:  24920.90234375\n",
      "The representation loss after processing this batch is:  5.675759166479111e-05\n",
      "The classification loss after processing this batch is:  25523.634765625\n",
      "The representation loss after processing this batch is:  5.7505443692207336e-05\n",
      "The classification loss after processing this batch is:  25056.869140625\n",
      "The representation loss after processing this batch is:  6.923452019691467e-05\n",
      "The classification loss after processing this batch is:  25117.173828125\n",
      "The representation loss after processing this batch is:  6.367452442646027e-05\n",
      "The classification loss after processing this batch is:  26363.35546875\n",
      "The representation loss after processing this batch is:  5.5138953030109406e-05\n",
      "The classification loss after processing this batch is:  29513.33984375\n",
      "The representation loss after processing this batch is:  6.817188113927841e-05\n",
      "The classification loss after processing this batch is:  26830.955078125\n",
      "The representation loss after processing this batch is:  6.891041994094849e-05\n",
      "The classification loss after processing this batch is:  24940.392578125\n",
      "The representation loss after processing this batch is:  5.250750109553337e-05\n",
      "The classification loss after processing this batch is:  25091.734375\n",
      "The representation loss after processing this batch is:  6.378628313541412e-05\n",
      "The classification loss after processing this batch is:  28838.82421875\n",
      "The representation loss after processing this batch is:  6.270408630371094e-05\n",
      "The classification loss after processing this batch is:  29061.82421875\n",
      "The representation loss after processing this batch is:  7.21486285328865e-05\n",
      "The classification loss after processing this batch is:  24583.671875\n",
      "The representation loss after processing this batch is:  6.127171218395233e-05\n",
      "The classification loss after processing this batch is:  24594.859375\n",
      "The representation loss after processing this batch is:  6.458070129156113e-05\n",
      "The classification loss after processing this batch is:  25199.61328125\n",
      "The representation loss after processing this batch is:  6.574857980012894e-05\n",
      "The classification loss after processing this batch is:  25706.384765625\n",
      "The representation loss after processing this batch is:  6.278511136770248e-05\n",
      "The classification loss after processing this batch is:  25745.787109375\n",
      "The representation loss after processing this batch is:  5.798693746328354e-05\n",
      "The classification loss after processing this batch is:  25295.6171875\n",
      "The representation loss after processing this batch is:  6.098579615354538e-05\n",
      "The classification loss after processing this batch is:  26352.984375\n",
      "The representation loss after processing this batch is:  5.59748150408268e-05\n",
      "The classification loss after processing this batch is:  27270.15234375\n",
      "The representation loss after processing this batch is:  7.025245577096939e-05\n",
      "The classification loss after processing this batch is:  25198.330078125\n",
      "The representation loss after processing this batch is:  6.512831896543503e-05\n",
      "The classification loss after processing this batch is:  25901.828125\n",
      "The representation loss after processing this batch is:  6.354087963700294e-05\n",
      "The classification loss after processing this batch is:  24741.509765625\n",
      "The representation loss after processing this batch is:  5.6792981922626495e-05\n",
      "The classification loss after processing this batch is:  24952.59765625\n",
      "The representation loss after processing this batch is:  6.817560642957687e-05\n",
      "The classification loss after processing this batch is:  24088.30078125\n",
      "The representation loss after processing this batch is:  6.049126386642456e-05\n",
      "The classification loss after processing this batch is:  25436.15234375\n",
      "The representation loss after processing this batch is:  8.263718336820602e-05\n",
      "The classification loss after processing this batch is:  24900.453125\n",
      "The representation loss after processing this batch is:  5.919206887483597e-05\n",
      "The classification loss after processing this batch is:  27248.779296875\n",
      "The representation loss after processing this batch is:  6.546452641487122e-05\n",
      "The classification loss after processing this batch is:  25003.9140625\n",
      "The representation loss after processing this batch is:  6.427150219678879e-05\n",
      "The classification loss after processing this batch is:  25027.7109375\n",
      "The representation loss after processing this batch is:  5.238410085439682e-05\n",
      "The classification loss after processing this batch is:  26771.6875\n",
      "The representation loss after processing this batch is:  6.550457328557968e-05\n",
      "The classification loss after processing this batch is:  26182.591796875\n",
      "The representation loss after processing this batch is:  6.164517253637314e-05\n",
      "The classification loss after processing this batch is:  25600.02734375\n",
      "The representation loss after processing this batch is:  6.038695573806763e-05\n",
      "The classification loss after processing this batch is:  27195.818359375\n",
      "The representation loss after processing this batch is:  6.597302854061127e-05\n",
      "The classification loss after processing this batch is:  25176.3984375\n",
      "The representation loss after processing this batch is:  5.8494508266448975e-05\n",
      "The classification loss after processing this batch is:  25760.310546875\n",
      "The representation loss after processing this batch is:  6.239116191864014e-05\n",
      "The classification loss after processing this batch is:  24463.71875\n",
      "The representation loss after processing this batch is:  6.140675395727158e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24468.93359375\n",
      "The representation loss after processing this batch is:  6.002001464366913e-05\n",
      "The classification loss after processing this batch is:  24514.904296875\n",
      "The representation loss after processing this batch is:  6.543286144733429e-05\n",
      "The classification loss after processing this batch is:  24415.056640625\n",
      "The representation loss after processing this batch is:  6.337743252515793e-05\n",
      "The classification loss after processing this batch is:  24551.720703125\n",
      "The representation loss after processing this batch is:  6.169546395540237e-05\n",
      "The classification loss after processing this batch is:  27106.314453125\n",
      "The representation loss after processing this batch is:  6.43804669380188e-05\n",
      "The classification loss after processing this batch is:  24806.59765625\n",
      "The representation loss after processing this batch is:  5.9409067034721375e-05\n",
      "The classification loss after processing this batch is:  24981.23828125\n",
      "The representation loss after processing this batch is:  5.811452865600586e-05\n",
      "The classification loss after processing this batch is:  25637.2734375\n",
      "The representation loss after processing this batch is:  5.7821162045001984e-05\n",
      "The classification loss after processing this batch is:  24993.453125\n",
      "The representation loss after processing this batch is:  5.788635462522507e-05\n",
      "The classification loss after processing this batch is:  25778.6953125\n",
      "The representation loss after processing this batch is:  6.77742063999176e-05\n",
      "The classification loss after processing this batch is:  25699.95703125\n",
      "The representation loss after processing this batch is:  5.924142897129059e-05\n",
      "The classification loss after processing this batch is:  25382.125\n",
      "The representation loss after processing this batch is:  7.062777876853943e-05\n",
      "The classification loss after processing this batch is:  24050.2109375\n",
      "The representation loss after processing this batch is:  5.9670768678188324e-05\n",
      "The classification loss after processing this batch is:  25500.6875\n",
      "The representation loss after processing this batch is:  7.055699825286865e-05\n",
      "The classification loss after processing this batch is:  27897.318359375\n",
      "The representation loss after processing this batch is:  6.240140646696091e-05\n",
      "The classification loss after processing this batch is:  28402.703125\n",
      "The representation loss after processing this batch is:  7.18291848897934e-05\n",
      "The classification loss after processing this batch is:  25351.474609375\n",
      "The representation loss after processing this batch is:  5.445070564746857e-05\n",
      "The classification loss after processing this batch is:  25217.640625\n",
      "The representation loss after processing this batch is:  5.974993109703064e-05\n",
      "The classification loss after processing this batch is:  25172.390625\n",
      "The representation loss after processing this batch is:  5.491077899932861e-05\n",
      "The classification loss after processing this batch is:  25869.796875\n",
      "The representation loss after processing this batch is:  6.031990051269531e-05\n",
      "The classification loss after processing this batch is:  24863.51953125\n",
      "The representation loss after processing this batch is:  6.480887532234192e-05\n",
      "The classification loss after processing this batch is:  25133.67578125\n",
      "The representation loss after processing this batch is:  5.3188763558864594e-05\n",
      "The classification loss after processing this batch is:  26599.7265625\n",
      "The representation loss after processing this batch is:  5.93867152929306e-05\n",
      "The classification loss after processing this batch is:  23868.62109375\n",
      "The representation loss after processing this batch is:  5.759391933679581e-05\n",
      "The classification loss after processing this batch is:  24476.6953125\n",
      "The representation loss after processing this batch is:  5.9773214161396027e-05\n",
      "The classification loss after processing this batch is:  26855.001953125\n",
      "The representation loss after processing this batch is:  6.660912185907364e-05\n",
      "The classification loss after processing this batch is:  25555.068359375\n",
      "The representation loss after processing this batch is:  6.981007754802704e-05\n",
      "The classification loss after processing this batch is:  24695.71484375\n",
      "The representation loss after processing this batch is:  6.446521729230881e-05\n",
      "The classification loss after processing this batch is:  23596.5546875\n",
      "The representation loss after processing this batch is:  5.697272717952728e-05\n",
      "The classification loss after processing this batch is:  26153.650390625\n",
      "The representation loss after processing this batch is:  6.598234176635742e-05\n",
      "The classification loss after processing this batch is:  25907.42578125\n",
      "The representation loss after processing this batch is:  6.809830665588379e-05\n",
      "The classification loss after processing this batch is:  30403.921875\n",
      "The representation loss after processing this batch is:  6.355810910463333e-05\n",
      "The classification loss after processing this batch is:  26504.43359375\n",
      "The representation loss after processing this batch is:  6.079860031604767e-05\n",
      "The classification loss after processing this batch is:  25012.619140625\n",
      "The representation loss after processing this batch is:  6.365682929754257e-05\n",
      "The classification loss after processing this batch is:  26600.94921875\n",
      "The representation loss after processing this batch is:  5.3085386753082275e-05\n",
      "The classification loss after processing this batch is:  27480.83984375\n",
      "The representation loss after processing this batch is:  5.97657635807991e-05\n",
      "The classification loss after processing this batch is:  26610.08984375\n",
      "The representation loss after processing this batch is:  5.7149212807416916e-05\n",
      "The classification loss after processing this batch is:  25938.333984375\n",
      "The representation loss after processing this batch is:  5.834270268678665e-05\n",
      "The classification loss after processing this batch is:  25892.263671875\n",
      "The representation loss after processing this batch is:  6.17094337940216e-05\n",
      "The classification loss after processing this batch is:  25770.86328125\n",
      "The representation loss after processing this batch is:  5.495501682162285e-05\n",
      "The classification loss after processing this batch is:  24404.97265625\n",
      "The representation loss after processing this batch is:  6.18593767285347e-05\n",
      "The classification loss after processing this batch is:  25462.296875\n",
      "The representation loss after processing this batch is:  5.9830956161022186e-05\n",
      "The classification loss after processing this batch is:  25213.1640625\n",
      "The representation loss after processing this batch is:  5.6061893701553345e-05\n",
      "The classification loss after processing this batch is:  26019.23046875\n",
      "The representation loss after processing this batch is:  6.274227052927017e-05\n",
      "The classification loss after processing this batch is:  26029.6796875\n",
      "The representation loss after processing this batch is:  6.272364407777786e-05\n",
      "The classification loss after processing this batch is:  26352.080078125\n",
      "The representation loss after processing this batch is:  6.198976188898087e-05\n",
      "The classification loss after processing this batch is:  24554.94921875\n",
      "The representation loss after processing this batch is:  5.5225566029548645e-05\n",
      "The classification loss after processing this batch is:  24016.359375\n",
      "The representation loss after processing this batch is:  6.553437560796738e-05\n",
      "The classification loss after processing this batch is:  24738.71484375\n",
      "The representation loss after processing this batch is:  5.542021244764328e-05\n",
      "The classification loss after processing this batch is:  24305.333984375\n",
      "The representation loss after processing this batch is:  6.019417196512222e-05\n",
      "The classification loss after processing this batch is:  25685.955078125\n",
      "The representation loss after processing this batch is:  6.497371941804886e-05\n",
      "The classification loss after processing this batch is:  25405.494140625\n",
      "The representation loss after processing this batch is:  5.532940849661827e-05\n",
      "The classification loss after processing this batch is:  24625.734375\n",
      "The representation loss after processing this batch is:  6.268639117479324e-05\n",
      "The classification loss after processing this batch is:  23779.5546875\n",
      "The representation loss after processing this batch is:  6.0774385929107666e-05\n",
      "The classification loss after processing this batch is:  23746.828125\n",
      "The representation loss after processing this batch is:  5.607865750789642e-05\n",
      "The classification loss after processing this batch is:  25357.796875\n",
      "The representation loss after processing this batch is:  5.621183663606644e-05\n",
      "The classification loss after processing this batch is:  26467.5859375\n",
      "The representation loss after processing this batch is:  5.341600626707077e-05\n",
      "The classification loss after processing this batch is:  26406.67578125\n",
      "The representation loss after processing this batch is:  7.047504186630249e-05\n",
      "The classification loss after processing this batch is:  24373.640625\n",
      "The representation loss after processing this batch is:  6.194505840539932e-05\n",
      "The classification loss after processing this batch is:  25403.759765625\n",
      "The representation loss after processing this batch is:  5.794968456029892e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24409.546875\n",
      "The representation loss after processing this batch is:  6.349757313728333e-05\n",
      "The classification loss after processing this batch is:  24685.564453125\n",
      "The representation loss after processing this batch is:  7.528159767389297e-05\n",
      "The classification loss after processing this batch is:  24141.791015625\n",
      "The representation loss after processing this batch is:  5.623605102300644e-05\n",
      "The classification loss after processing this batch is:  23835.51171875\n",
      "The representation loss after processing this batch is:  6.308872252702713e-05\n",
      "The classification loss after processing this batch is:  23783.5234375\n",
      "The representation loss after processing this batch is:  6.363168358802795e-05\n",
      "The classification loss after processing this batch is:  24464.2265625\n",
      "The representation loss after processing this batch is:  6.485078483819962e-05\n",
      "The classification loss after processing this batch is:  24742.189453125\n",
      "The representation loss after processing this batch is:  6.654299795627594e-05\n",
      "The classification loss after processing this batch is:  25000.31640625\n",
      "The representation loss after processing this batch is:  5.779135972261429e-05\n",
      "The classification loss after processing this batch is:  24463.2890625\n",
      "The representation loss after processing this batch is:  6.217882037162781e-05\n",
      "The classification loss after processing this batch is:  24282.5078125\n",
      "The representation loss after processing this batch is:  5.520135164260864e-05\n",
      "The classification loss after processing this batch is:  26009.0625\n",
      "The representation loss after processing this batch is:  5.83818182349205e-05\n",
      "The classification loss after processing this batch is:  27074.24609375\n",
      "The representation loss after processing this batch is:  7.178075611591339e-05\n",
      "The classification loss after processing this batch is:  25954.04296875\n",
      "The representation loss after processing this batch is:  6.969179958105087e-05\n",
      "The classification loss after processing this batch is:  26064.341796875\n",
      "The representation loss after processing this batch is:  6.119906902313232e-05\n",
      "The classification loss after processing this batch is:  24707.5\n",
      "The representation loss after processing this batch is:  5.848705768585205e-05\n",
      "The classification loss after processing this batch is:  25150.48046875\n",
      "The representation loss after processing this batch is:  5.652010440826416e-05\n",
      "The classification loss after processing this batch is:  26188.791015625\n",
      "The representation loss after processing this batch is:  6.571412086486816e-05\n",
      "The classification loss after processing this batch is:  24380.978515625\n",
      "The representation loss after processing this batch is:  6.746407598257065e-05\n",
      "The classification loss after processing this batch is:  24296.185546875\n",
      "The representation loss after processing this batch is:  5.3797848522663116e-05\n",
      "The classification loss after processing this batch is:  25471.064453125\n",
      "The representation loss after processing this batch is:  5.62998466193676e-05\n",
      "The classification loss after processing this batch is:  25234.966796875\n",
      "The representation loss after processing this batch is:  5.389004945755005e-05\n",
      "The classification loss after processing this batch is:  25238.3515625\n",
      "The representation loss after processing this batch is:  5.603255704045296e-05\n",
      "The classification loss after processing this batch is:  24447.017578125\n",
      "The representation loss after processing this batch is:  6.0354359447956085e-05\n",
      "The classification loss after processing this batch is:  26016.21484375\n",
      "The representation loss after processing this batch is:  6.749574095010757e-05\n",
      "The classification loss after processing this batch is:  26147.5\n",
      "The representation loss after processing this batch is:  6.253831088542938e-05\n",
      "The classification loss after processing this batch is:  26795.708984375\n",
      "The representation loss after processing this batch is:  5.8828387409448624e-05\n",
      "The classification loss after processing this batch is:  26609.140625\n",
      "The representation loss after processing this batch is:  7.455656304955482e-05\n",
      "The classification loss after processing this batch is:  25482.84375\n",
      "The representation loss after processing this batch is:  5.381088703870773e-05\n",
      "The classification loss after processing this batch is:  24673.8671875\n",
      "The representation loss after processing this batch is:  5.66607341170311e-05\n",
      "The classification loss after processing this batch is:  24657.3046875\n",
      "The representation loss after processing this batch is:  6.237346678972244e-05\n",
      "The classification loss after processing this batch is:  24509.41015625\n",
      "The representation loss after processing this batch is:  5.1680952310562134e-05\n",
      "The classification loss after processing this batch is:  24406.197265625\n",
      "The representation loss after processing this batch is:  5.777226760983467e-05\n",
      "The classification loss after processing this batch is:  24127.408203125\n",
      "The representation loss after processing this batch is:  5.403673276305199e-05\n",
      "The classification loss after processing this batch is:  24860.65234375\n",
      "The representation loss after processing this batch is:  6.228219717741013e-05\n",
      "The classification loss after processing this batch is:  25062.912109375\n",
      "The representation loss after processing this batch is:  6.199348717927933e-05\n",
      "The classification loss after processing this batch is:  28342.322265625\n",
      "The representation loss after processing this batch is:  6.739981472492218e-05\n",
      "The classification loss after processing this batch is:  27510.744140625\n",
      "The representation loss after processing this batch is:  5.4836273193359375e-05\n",
      "The classification loss after processing this batch is:  25151.4921875\n",
      "The representation loss after processing this batch is:  5.408283323049545e-05\n",
      "The classification loss after processing this batch is:  23816.625\n",
      "The representation loss after processing this batch is:  7.305573672056198e-05\n",
      "The classification loss after processing this batch is:  23991.244140625\n",
      "The representation loss after processing this batch is:  6.775651127099991e-05\n",
      "The classification loss after processing this batch is:  25016.47265625\n",
      "The representation loss after processing this batch is:  6.765592843294144e-05\n",
      "The classification loss after processing this batch is:  24591.69921875\n",
      "The representation loss after processing this batch is:  7.420871406793594e-05\n",
      "The classification loss after processing this batch is:  24980.87890625\n",
      "The representation loss after processing this batch is:  6.423238664865494e-05\n",
      "The classification loss after processing this batch is:  25032.69140625\n",
      "The representation loss after processing this batch is:  5.648285150527954e-05\n",
      "The classification loss after processing this batch is:  24265.806640625\n",
      "The representation loss after processing this batch is:  5.0533097237348557e-05\n",
      "The classification loss after processing this batch is:  23946.39453125\n",
      "The representation loss after processing this batch is:  5.993340164422989e-05\n",
      "The classification loss after processing this batch is:  25378.005859375\n",
      "The representation loss after processing this batch is:  6.128661334514618e-05\n",
      "The classification loss after processing this batch is:  26041.4375\n",
      "The representation loss after processing this batch is:  6.202142685651779e-05\n",
      "The classification loss after processing this batch is:  24790.37109375\n",
      "The representation loss after processing this batch is:  6.219744682312012e-05\n",
      "The classification loss after processing this batch is:  25635.705078125\n",
      "The representation loss after processing this batch is:  5.340389907360077e-05\n",
      "The classification loss after processing this batch is:  27122.0078125\n",
      "The representation loss after processing this batch is:  6.453227251768112e-05\n",
      "The classification loss after processing this batch is:  25858.73046875\n",
      "The representation loss after processing this batch is:  5.550682544708252e-05\n",
      "The classification loss after processing this batch is:  27301.42578125\n",
      "The representation loss after processing this batch is:  5.731359124183655e-05\n",
      "The classification loss after processing this batch is:  25085.07421875\n",
      "The representation loss after processing this batch is:  6.124656647443771e-05\n",
      "The classification loss after processing this batch is:  26278.244140625\n",
      "The representation loss after processing this batch is:  7.33938068151474e-05\n",
      "The classification loss after processing this batch is:  24788.39453125\n",
      "The representation loss after processing this batch is:  6.164610385894775e-05\n",
      "The classification loss after processing this batch is:  25402.65625\n",
      "The representation loss after processing this batch is:  6.48079439997673e-05\n",
      "The classification loss after processing this batch is:  25168.7890625\n",
      "The representation loss after processing this batch is:  6.030779331922531e-05\n",
      "The classification loss after processing this batch is:  24834.51171875\n",
      "The representation loss after processing this batch is:  6.687454879283905e-05\n",
      "The classification loss after processing this batch is:  25469.83984375\n",
      "The representation loss after processing this batch is:  5.9917569160461426e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24100.125\n",
      "The representation loss after processing this batch is:  6.053503602743149e-05\n",
      "The classification loss after processing this batch is:  24346.697265625\n",
      "The representation loss after processing this batch is:  6.473995745182037e-05\n",
      "The classification loss after processing this batch is:  23782.646484375\n",
      "The representation loss after processing this batch is:  5.8241188526153564e-05\n",
      "The classification loss after processing this batch is:  24105.646484375\n",
      "The representation loss after processing this batch is:  6.682984530925751e-05\n",
      "The classification loss after processing this batch is:  23829.1875\n",
      "The representation loss after processing this batch is:  5.803350359201431e-05\n",
      "The classification loss after processing this batch is:  25274.55078125\n",
      "The representation loss after processing this batch is:  6.514880806207657e-05\n",
      "The classification loss after processing this batch is:  24869.693359375\n",
      "The representation loss after processing this batch is:  6.208103150129318e-05\n",
      "The classification loss after processing this batch is:  25197.443359375\n",
      "The representation loss after processing this batch is:  6.07585534453392e-05\n",
      "The classification loss after processing this batch is:  25392.5078125\n",
      "The representation loss after processing this batch is:  5.45671209692955e-05\n",
      "The classification loss after processing this batch is:  24327.03125\n",
      "The representation loss after processing this batch is:  5.657179281115532e-05\n",
      "The classification loss after processing this batch is:  25287.921875\n",
      "The representation loss after processing this batch is:  6.025843322277069e-05\n",
      "The classification loss after processing this batch is:  25025.591796875\n",
      "The representation loss after processing this batch is:  6.025098264217377e-05\n",
      "The classification loss after processing this batch is:  24025.291015625\n",
      "The representation loss after processing this batch is:  6.170663982629776e-05\n",
      "The classification loss after processing this batch is:  25284.615234375\n",
      "The representation loss after processing this batch is:  5.84898516535759e-05\n",
      "The classification loss after processing this batch is:  24813.982421875\n",
      "The representation loss after processing this batch is:  6.04577362537384e-05\n",
      "The classification loss after processing this batch is:  24063.2109375\n",
      "The representation loss after processing this batch is:  5.7392753660678864e-05\n",
      "The classification loss after processing this batch is:  25027.642578125\n",
      "The representation loss after processing this batch is:  5.971081554889679e-05\n",
      "The classification loss after processing this batch is:  24531.255859375\n",
      "The representation loss after processing this batch is:  6.404891610145569e-05\n",
      "The classification loss after processing this batch is:  25786.5078125\n",
      "The representation loss after processing this batch is:  6.586220115423203e-05\n",
      "The classification loss after processing this batch is:  26018.376953125\n",
      "The representation loss after processing this batch is:  5.3369440138339996e-05\n",
      "The classification loss after processing this batch is:  24292.673828125\n",
      "The representation loss after processing this batch is:  6.738398224115372e-05\n",
      "The classification loss after processing this batch is:  27753.267578125\n",
      "The representation loss after processing this batch is:  5.377922207117081e-05\n",
      "The classification loss after processing this batch is:  27718.685546875\n",
      "The representation loss after processing this batch is:  6.22449442744255e-05\n",
      "The classification loss after processing this batch is:  24304.16796875\n",
      "The representation loss after processing this batch is:  5.823653191328049e-05\n",
      "The classification loss after processing this batch is:  25133.515625\n",
      "The representation loss after processing this batch is:  5.773594602942467e-05\n",
      "The classification loss after processing this batch is:  25846.431640625\n",
      "The representation loss after processing this batch is:  6.682984530925751e-05\n",
      "The classification loss after processing this batch is:  24738.99609375\n",
      "The representation loss after processing this batch is:  5.3505413234233856e-05\n",
      "The classification loss after processing this batch is:  25266.638671875\n",
      "The representation loss after processing this batch is:  6.126333028078079e-05\n",
      "The classification loss after processing this batch is:  25070.392578125\n",
      "The representation loss after processing this batch is:  5.667470395565033e-05\n",
      "The classification loss after processing this batch is:  25066.8203125\n",
      "The representation loss after processing this batch is:  5.816575139760971e-05\n",
      "The classification loss after processing this batch is:  26213.38671875\n",
      "The representation loss after processing this batch is:  5.7320110499858856e-05\n",
      "The classification loss after processing this batch is:  25810.96484375\n",
      "The representation loss after processing this batch is:  5.4632313549518585e-05\n",
      "The classification loss after processing this batch is:  27427.98828125\n",
      "The representation loss after processing this batch is:  6.570294499397278e-05\n",
      "The classification loss after processing this batch is:  26184.966796875\n",
      "The representation loss after processing this batch is:  6.406009197235107e-05\n",
      "The classification loss after processing this batch is:  26406.046875\n",
      "The representation loss after processing this batch is:  5.750264972448349e-05\n",
      "The classification loss after processing this batch is:  24132.74609375\n",
      "The representation loss after processing this batch is:  5.927402526140213e-05\n",
      "The classification loss after processing this batch is:  24676.34375\n",
      "The representation loss after processing this batch is:  5.389656871557236e-05\n",
      "The classification loss after processing this batch is:  25900.38671875\n",
      "The representation loss after processing this batch is:  5.725771188735962e-05\n",
      "The classification loss after processing this batch is:  24541.20703125\n",
      "The representation loss after processing this batch is:  5.2333809435367584e-05\n",
      "The classification loss after processing this batch is:  23589.91015625\n",
      "The representation loss after processing this batch is:  7.084943354129791e-05\n",
      "The classification loss after processing this batch is:  26136.6171875\n",
      "The representation loss after processing this batch is:  5.49880787730217e-05\n",
      "The classification loss after processing this batch is:  23956.89453125\n",
      "The representation loss after processing this batch is:  6.175879389047623e-05\n",
      "The classification loss after processing this batch is:  24363.0078125\n",
      "The representation loss after processing this batch is:  5.558319389820099e-05\n",
      "The classification loss after processing this batch is:  23657.916015625\n",
      "The representation loss after processing this batch is:  5.731731653213501e-05\n",
      "The classification loss after processing this batch is:  24234.517578125\n",
      "The representation loss after processing this batch is:  6.437022238969803e-05\n",
      "The classification loss after processing this batch is:  23509.43359375\n",
      "The representation loss after processing this batch is:  5.817785859107971e-05\n",
      "The classification loss after processing this batch is:  24887.83203125\n",
      "The representation loss after processing this batch is:  5.758041515946388e-05\n",
      "The classification loss after processing this batch is:  24719.20703125\n",
      "The representation loss after processing this batch is:  5.0235074013471603e-05\n",
      "The classification loss after processing this batch is:  24105.1171875\n",
      "The representation loss after processing this batch is:  5.5351294577121735e-05\n",
      "The classification loss after processing this batch is:  25612.328125\n",
      "The representation loss after processing this batch is:  5.774758756160736e-05\n",
      "The classification loss after processing this batch is:  25728.203125\n",
      "The representation loss after processing this batch is:  5.702301859855652e-05\n",
      "The classification loss after processing this batch is:  23776.6484375\n",
      "The representation loss after processing this batch is:  6.0793012380599976e-05\n",
      "The classification loss after processing this batch is:  24031.6640625\n",
      "The representation loss after processing this batch is:  6.18956983089447e-05\n",
      "The classification loss after processing this batch is:  24354.36328125\n",
      "The representation loss after processing this batch is:  5.807261914014816e-05\n",
      "The classification loss after processing this batch is:  24666.015625\n",
      "The representation loss after processing this batch is:  5.736202001571655e-05\n",
      "The classification loss after processing this batch is:  26272.75\n",
      "The representation loss after processing this batch is:  5.410797894001007e-05\n",
      "The classification loss after processing this batch is:  24374.61328125\n",
      "The representation loss after processing this batch is:  5.0273723900318146e-05\n",
      "The classification loss after processing this batch is:  23503.12109375\n",
      "The representation loss after processing this batch is:  5.91278076171875e-05\n",
      "The classification loss after processing this batch is:  24851.1328125\n",
      "The representation loss after processing this batch is:  5.8477744460105896e-05\n",
      "The classification loss after processing this batch is:  27286.53125\n",
      "The representation loss after processing this batch is:  6.882008165121078e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24457.21484375\n",
      "The representation loss after processing this batch is:  5.279015749692917e-05\n",
      "The classification loss after processing this batch is:  25129.22265625\n",
      "The representation loss after processing this batch is:  5.261832848191261e-05\n",
      "The classification loss after processing this batch is:  26743.75\n",
      "The representation loss after processing this batch is:  5.5691227316856384e-05\n",
      "The classification loss after processing this batch is:  25107.79296875\n",
      "The representation loss after processing this batch is:  5.579274147748947e-05\n",
      "The classification loss after processing this batch is:  24132.61328125\n",
      "The representation loss after processing this batch is:  5.77862374484539e-05\n",
      "The classification loss after processing this batch is:  24415.6796875\n",
      "The representation loss after processing this batch is:  6.96033239364624e-05\n",
      "The classification loss after processing this batch is:  24273.5859375\n",
      "The representation loss after processing this batch is:  5.8094970881938934e-05\n",
      "The classification loss after processing this batch is:  24520.78515625\n",
      "The representation loss after processing this batch is:  5.224347114562988e-05\n",
      "The classification loss after processing this batch is:  24264.82421875\n",
      "The representation loss after processing this batch is:  5.932990461587906e-05\n",
      "The classification loss after processing this batch is:  25033.380859375\n",
      "The representation loss after processing this batch is:  5.579739809036255e-05\n",
      "The classification loss after processing this batch is:  27762.138671875\n",
      "The representation loss after processing this batch is:  7.50487670302391e-05\n",
      "The classification loss after processing this batch is:  26178.80078125\n",
      "The representation loss after processing this batch is:  6.216298788785934e-05\n",
      "The classification loss after processing this batch is:  25277.177734375\n",
      "The representation loss after processing this batch is:  5.3070951253175735e-05\n",
      "The classification loss after processing this batch is:  24320.84765625\n",
      "The representation loss after processing this batch is:  5.402509123086929e-05\n",
      "The classification loss after processing this batch is:  24859.701171875\n",
      "The representation loss after processing this batch is:  6.201490759849548e-05\n",
      "The classification loss after processing this batch is:  24604.7578125\n",
      "The representation loss after processing this batch is:  6.782729178667068e-05\n",
      "The classification loss after processing this batch is:  24595.369140625\n",
      "The representation loss after processing this batch is:  5.4785050451755524e-05\n",
      "The classification loss after processing this batch is:  23938.64453125\n",
      "The representation loss after processing this batch is:  5.693826824426651e-05\n",
      "The classification loss after processing this batch is:  24471.5703125\n",
      "The representation loss after processing this batch is:  5.877390503883362e-05\n",
      "The classification loss after processing this batch is:  24246.90234375\n",
      "The representation loss after processing this batch is:  5.8640725910663605e-05\n",
      "The classification loss after processing this batch is:  23669.92578125\n",
      "The representation loss after processing this batch is:  5.485396832227707e-05\n",
      "The classification loss after processing this batch is:  24674.66796875\n",
      "The representation loss after processing this batch is:  6.162934005260468e-05\n",
      "The classification loss after processing this batch is:  23502.30078125\n",
      "The representation loss after processing this batch is:  6.21303915977478e-05\n",
      "The classification loss after processing this batch is:  25817.78515625\n",
      "The representation loss after processing this batch is:  6.507989019155502e-05\n",
      "The classification loss after processing this batch is:  25705.98046875\n",
      "The representation loss after processing this batch is:  5.643162876367569e-05\n",
      "The classification loss after processing this batch is:  24658.890625\n",
      "The representation loss after processing this batch is:  5.467422306537628e-05\n",
      "The classification loss after processing this batch is:  24667.74609375\n",
      "The representation loss after processing this batch is:  5.717482417821884e-05\n",
      "The classification loss after processing this batch is:  24663.6640625\n",
      "The representation loss after processing this batch is:  5.859788507223129e-05\n",
      "The classification loss after processing this batch is:  25999.654296875\n",
      "The representation loss after processing this batch is:  5.614105612039566e-05\n",
      "The classification loss after processing this batch is:  25545.30859375\n",
      "The representation loss after processing this batch is:  6.107054650783539e-05\n",
      "The classification loss after processing this batch is:  24554.50390625\n",
      "The representation loss after processing this batch is:  5.529262125492096e-05\n",
      "The classification loss after processing this batch is:  24791.12890625\n",
      "The representation loss after processing this batch is:  5.370844155550003e-05\n",
      "The classification loss after processing this batch is:  26576.52734375\n",
      "The representation loss after processing this batch is:  6.910227239131927e-05\n",
      "The classification loss after processing this batch is:  24112.162109375\n",
      "The representation loss after processing this batch is:  5.3948722779750824e-05\n",
      "The classification loss after processing this batch is:  24867.498046875\n",
      "The representation loss after processing this batch is:  5.4372940212488174e-05\n",
      "The classification loss after processing this batch is:  24734.453125\n",
      "The representation loss after processing this batch is:  6.189383566379547e-05\n",
      "The classification loss after processing this batch is:  24576.876953125\n",
      "The representation loss after processing this batch is:  5.8387406170368195e-05\n",
      "The classification loss after processing this batch is:  25258.40625\n",
      "The representation loss after processing this batch is:  6.27618283033371e-05\n",
      "The classification loss after processing this batch is:  25742.03125\n",
      "The representation loss after processing this batch is:  6.675068289041519e-05\n",
      "The classification loss after processing this batch is:  24488.763671875\n",
      "The representation loss after processing this batch is:  7.847324013710022e-05\n",
      "The classification loss after processing this batch is:  25503.953125\n",
      "The representation loss after processing this batch is:  5.5736396461725235e-05\n",
      "The classification loss after processing this batch is:  26053.93359375\n",
      "The representation loss after processing this batch is:  5.525955930352211e-05\n",
      "The classification loss after processing this batch is:  24493.611328125\n",
      "The representation loss after processing this batch is:  6.230920553207397e-05\n",
      "The classification loss after processing this batch is:  25468.892578125\n",
      "The representation loss after processing this batch is:  5.4856762290000916e-05\n",
      "The classification loss after processing this batch is:  25011.18359375\n",
      "The representation loss after processing this batch is:  5.930662155151367e-05\n",
      "The classification loss after processing this batch is:  23997.546875\n",
      "The representation loss after processing this batch is:  5.827751010656357e-05\n",
      "The classification loss after processing this batch is:  24250.1171875\n",
      "The representation loss after processing this batch is:  6.105192005634308e-05\n",
      "The classification loss after processing this batch is:  24369.701171875\n",
      "The representation loss after processing this batch is:  6.0170888900756836e-05\n",
      "The classification loss after processing this batch is:  24291.294921875\n",
      "The representation loss after processing this batch is:  6.888434290885925e-05\n",
      "The classification loss after processing this batch is:  25945.37109375\n",
      "The representation loss after processing this batch is:  6.331130862236023e-05\n",
      "The classification loss after processing this batch is:  25689.146484375\n",
      "The representation loss after processing this batch is:  5.5460259318351746e-05\n",
      "The classification loss after processing this batch is:  26411.86328125\n",
      "The representation loss after processing this batch is:  6.762892007827759e-05\n",
      "The classification loss after processing this batch is:  23458.01171875\n",
      "The representation loss after processing this batch is:  7.970444858074188e-05\n",
      "The classification loss after processing this batch is:  23729.77734375\n",
      "The representation loss after processing this batch is:  6.911344826221466e-05\n",
      "The classification loss after processing this batch is:  24301.40625\n",
      "The representation loss after processing this batch is:  6.141047924757004e-05\n",
      "The classification loss after processing this batch is:  24125.662109375\n",
      "The representation loss after processing this batch is:  5.776993930339813e-05\n",
      "The classification loss after processing this batch is:  25772.888671875\n",
      "The representation loss after processing this batch is:  6.01084902882576e-05\n",
      "The classification loss after processing this batch is:  24620.478515625\n",
      "The representation loss after processing this batch is:  5.653686821460724e-05\n",
      "The classification loss after processing this batch is:  24884.35546875\n",
      "The representation loss after processing this batch is:  6.046053022146225e-05\n",
      "The classification loss after processing this batch is:  24906.955078125\n",
      "The representation loss after processing this batch is:  5.673058331012726e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24239.2734375\n",
      "The representation loss after processing this batch is:  5.5806711316108704e-05\n",
      "The classification loss after processing this batch is:  25930.744140625\n",
      "The representation loss after processing this batch is:  5.721673369407654e-05\n",
      "The classification loss after processing this batch is:  26195.58203125\n",
      "The representation loss after processing this batch is:  5.745794624090195e-05\n",
      "The classification loss after processing this batch is:  25508.77734375\n",
      "The representation loss after processing this batch is:  5.8760866522789e-05\n",
      "The classification loss after processing this batch is:  23618.421875\n",
      "The representation loss after processing this batch is:  6.0488469898700714e-05\n",
      "The classification loss after processing this batch is:  25923.25\n",
      "The representation loss after processing this batch is:  5.751568824052811e-05\n",
      "The classification loss after processing this batch is:  25674.076171875\n",
      "The representation loss after processing this batch is:  5.181320011615753e-05\n",
      "The classification loss after processing this batch is:  24325.158203125\n",
      "The representation loss after processing this batch is:  6.188498809933662e-05\n",
      "The classification loss after processing this batch is:  26369.755859375\n",
      "The representation loss after processing this batch is:  5.8103352785110474e-05\n",
      "The classification loss after processing this batch is:  26079.73828125\n",
      "The representation loss after processing this batch is:  6.27739354968071e-05\n",
      "The classification loss after processing this batch is:  23674.30078125\n",
      "The representation loss after processing this batch is:  5.581974983215332e-05\n",
      "The classification loss after processing this batch is:  24216.8828125\n",
      "The representation loss after processing this batch is:  5.818437784910202e-05\n",
      "The classification loss after processing this batch is:  24969.18359375\n",
      "The representation loss after processing this batch is:  6.917538121342659e-05\n",
      "The classification loss after processing this batch is:  24554.7109375\n",
      "The representation loss after processing this batch is:  5.8669596910476685e-05\n",
      "The classification loss after processing this batch is:  25050.388671875\n",
      "The representation loss after processing this batch is:  6.69742003083229e-05\n",
      "The classification loss after processing this batch is:  25632.044921875\n",
      "The representation loss after processing this batch is:  6.411690264940262e-05\n",
      "The classification loss after processing this batch is:  23628.556640625\n",
      "The representation loss after processing this batch is:  6.200838834047318e-05\n",
      "The classification loss after processing this batch is:  23316.00390625\n",
      "The representation loss after processing this batch is:  6.388220936059952e-05\n",
      "The classification loss after processing this batch is:  24775.30859375\n",
      "The representation loss after processing this batch is:  5.282554775476456e-05\n",
      "The classification loss after processing this batch is:  25973.697265625\n",
      "The representation loss after processing this batch is:  5.684420466423035e-05\n",
      "The classification loss after processing this batch is:  24549.44140625\n",
      "The representation loss after processing this batch is:  5.861837416887283e-05\n",
      "The classification loss after processing this batch is:  25088.2265625\n",
      "The representation loss after processing this batch is:  6.41997903585434e-05\n",
      "The classification loss after processing this batch is:  24840.08984375\n",
      "The representation loss after processing this batch is:  5.4331496357917786e-05\n",
      "The classification loss after processing this batch is:  24997.056640625\n",
      "The representation loss after processing this batch is:  5.9689395129680634e-05\n",
      "The classification loss after processing this batch is:  24048.6015625\n",
      "The representation loss after processing this batch is:  6.576906889677048e-05\n",
      "The classification loss after processing this batch is:  24277.30859375\n",
      "The representation loss after processing this batch is:  6.262492388486862e-05\n",
      "The classification loss after processing this batch is:  25683.83203125\n",
      "The representation loss after processing this batch is:  5.5565498769283295e-05\n",
      "The classification loss after processing this batch is:  23468.4375\n",
      "The representation loss after processing this batch is:  5.179643630981445e-05\n",
      "The classification loss after processing this batch is:  23744.490234375\n",
      "The representation loss after processing this batch is:  5.469471216201782e-05\n",
      "The classification loss after processing this batch is:  23562.12890625\n",
      "The representation loss after processing this batch is:  5.552265793085098e-05\n",
      "The classification loss after processing this batch is:  23454.90234375\n",
      "The representation loss after processing this batch is:  5.8881938457489014e-05\n",
      "The classification loss after processing this batch is:  23773.81640625\n",
      "The representation loss after processing this batch is:  5.792733281850815e-05\n",
      "The classification loss after processing this batch is:  24962.31640625\n",
      "The representation loss after processing this batch is:  5.8778561651706696e-05\n",
      "The classification loss after processing this batch is:  24840.66796875\n",
      "The representation loss after processing this batch is:  5.408376455307007e-05\n",
      "The classification loss after processing this batch is:  23505.69140625\n",
      "The representation loss after processing this batch is:  6.005074828863144e-05\n",
      "The classification loss after processing this batch is:  23676.091796875\n",
      "The representation loss after processing this batch is:  5.297549068927765e-05\n",
      "The classification loss after processing this batch is:  23754.595703125\n",
      "The representation loss after processing this batch is:  5.38569875061512e-05\n",
      "The classification loss after processing this batch is:  24381.91015625\n",
      "The representation loss after processing this batch is:  6.44586980342865e-05\n",
      "The classification loss after processing this batch is:  24606.498046875\n",
      "The representation loss after processing this batch is:  5.850568413734436e-05\n",
      "The classification loss after processing this batch is:  23638.359375\n",
      "The representation loss after processing this batch is:  6.172619760036469e-05\n",
      "The classification loss after processing this batch is:  26136.82421875\n",
      "The representation loss after processing this batch is:  6.241397932171822e-05\n",
      "The classification loss after processing this batch is:  24163.4296875\n",
      "The representation loss after processing this batch is:  5.124043673276901e-05\n",
      "The classification loss after processing this batch is:  23672.876953125\n",
      "The representation loss after processing this batch is:  6.416905671358109e-05\n",
      "The classification loss after processing this batch is:  24477.50390625\n",
      "The representation loss after processing this batch is:  5.444325506687164e-05\n",
      "The classification loss after processing this batch is:  25328.0078125\n",
      "The representation loss after processing this batch is:  6.057322025299072e-05\n",
      "The classification loss after processing this batch is:  24803.236328125\n",
      "The representation loss after processing this batch is:  5.0381291657686234e-05\n",
      "The classification loss after processing this batch is:  23893.3515625\n",
      "The representation loss after processing this batch is:  5.8902427554130554e-05\n",
      "The classification loss after processing this batch is:  24640.03125\n",
      "The representation loss after processing this batch is:  5.447119474411011e-05\n",
      "The classification loss after processing this batch is:  26047.125\n",
      "The representation loss after processing this batch is:  5.496479570865631e-05\n",
      "The classification loss after processing this batch is:  23418.97265625\n",
      "The representation loss after processing this batch is:  6.305426359176636e-05\n",
      "The classification loss after processing this batch is:  24025.265625\n",
      "The representation loss after processing this batch is:  5.4768286645412445e-05\n",
      "The classification loss after processing this batch is:  22979.21484375\n",
      "The representation loss after processing this batch is:  5.742441862821579e-05\n",
      "The classification loss after processing this batch is:  24431.583984375\n",
      "The representation loss after processing this batch is:  5.6286342442035675e-05\n",
      "The classification loss after processing this batch is:  24615.26171875\n",
      "The representation loss after processing this batch is:  6.145238876342773e-05\n",
      "The classification loss after processing this batch is:  24122.34765625\n",
      "The representation loss after processing this batch is:  5.687866359949112e-05\n",
      "The classification loss after processing this batch is:  24007.66796875\n",
      "The representation loss after processing this batch is:  6.617046892642975e-05\n",
      "The classification loss after processing this batch is:  23478.5390625\n",
      "The representation loss after processing this batch is:  5.411822348833084e-05\n",
      "The classification loss after processing this batch is:  24209.734375\n",
      "The representation loss after processing this batch is:  5.1157549023628235e-05\n",
      "The classification loss after processing this batch is:  24098.8046875\n",
      "The representation loss after processing this batch is:  5.535781383514404e-05\n",
      "The classification loss after processing this batch is:  23329.08203125\n",
      "The representation loss after processing this batch is:  6.061233580112457e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  27488.759765625\n",
      "The representation loss after processing this batch is:  6.65402039885521e-05\n",
      "The classification loss after processing this batch is:  25881.4765625\n",
      "The representation loss after processing this batch is:  5.572289228439331e-05\n",
      "The classification loss after processing this batch is:  25284.91015625\n",
      "The representation loss after processing this batch is:  5.977228283882141e-05\n",
      "The classification loss after processing this batch is:  24349.74609375\n",
      "The representation loss after processing this batch is:  6.348919123411179e-05\n",
      "The classification loss after processing this batch is:  23563.404296875\n",
      "The representation loss after processing this batch is:  6.006099283695221e-05\n",
      "The classification loss after processing this batch is:  24287.00390625\n",
      "The representation loss after processing this batch is:  5.80810010433197e-05\n",
      "The classification loss after processing this batch is:  25033.9140625\n",
      "The representation loss after processing this batch is:  6.326008588075638e-05\n",
      "The classification loss after processing this batch is:  24272.06640625\n",
      "The representation loss after processing this batch is:  5.1221344619989395e-05\n",
      "The classification loss after processing this batch is:  26460.23828125\n",
      "The representation loss after processing this batch is:  5.506537854671478e-05\n",
      "The classification loss after processing this batch is:  24653.515625\n",
      "The representation loss after processing this batch is:  5.4958276450634e-05\n",
      "The classification loss after processing this batch is:  23547.564453125\n",
      "The representation loss after processing this batch is:  5.864724516868591e-05\n",
      "The classification loss after processing this batch is:  25367.93359375\n",
      "The representation loss after processing this batch is:  6.02109357714653e-05\n",
      "The classification loss after processing this batch is:  23686.00390625\n",
      "The representation loss after processing this batch is:  6.0020945966243744e-05\n",
      "The classification loss after processing this batch is:  24050.318359375\n",
      "The representation loss after processing this batch is:  6.502121686935425e-05\n",
      "The classification loss after processing this batch is:  27868.6640625\n",
      "The representation loss after processing this batch is:  6.695929914712906e-05\n",
      "The classification loss after processing this batch is:  25685.62109375\n",
      "The representation loss after processing this batch is:  7.352512329816818e-05\n",
      "The classification loss after processing this batch is:  23655.169921875\n",
      "The representation loss after processing this batch is:  6.7918561398983e-05\n",
      "The classification loss after processing this batch is:  23643.16015625\n",
      "The representation loss after processing this batch is:  9.684544056653976e-05\n",
      "The classification loss after processing this batch is:  26308.314453125\n",
      "The representation loss after processing this batch is:  6.286147981882095e-05\n",
      "The classification loss after processing this batch is:  23655.5234375\n",
      "The representation loss after processing this batch is:  7.442478090524673e-05\n",
      "The classification loss after processing this batch is:  23807.421875\n",
      "The representation loss after processing this batch is:  7.229950278997421e-05\n",
      "The classification loss after processing this batch is:  24254.724609375\n",
      "The representation loss after processing this batch is:  8.131563663482666e-05\n",
      "The classification loss after processing this batch is:  28846.826171875\n",
      "The representation loss after processing this batch is:  6.640143692493439e-05\n",
      "The classification loss after processing this batch is:  31179.296875\n",
      "The representation loss after processing this batch is:  6.498116999864578e-05\n",
      "The classification loss after processing this batch is:  23781.9453125\n",
      "The representation loss after processing this batch is:  7.06324353814125e-05\n",
      "The classification loss after processing this batch is:  25213.19921875\n",
      "The representation loss after processing this batch is:  6.137322634458542e-05\n",
      "The classification loss after processing this batch is:  24944.775390625\n",
      "The representation loss after processing this batch is:  6.657559424638748e-05\n",
      "The classification loss after processing this batch is:  22471.140625\n",
      "The representation loss after processing this batch is:  6.297696381807327e-05\n",
      "The classification loss after processing this batch is:  24998.30078125\n",
      "The representation loss after processing this batch is:  4.863739013671875e-05\n",
      "The classification loss after processing this batch is:  25170.61328125\n",
      "The representation loss after processing this batch is:  5.4496340453624725e-05\n",
      "The classification loss after processing this batch is:  23956.7890625\n",
      "The representation loss after processing this batch is:  4.710536450147629e-05\n",
      "The classification loss after processing this batch is:  24240.6953125\n",
      "The representation loss after processing this batch is:  5.1110051572322845e-05\n",
      "The classification loss after processing this batch is:  24580.32421875\n",
      "The representation loss after processing this batch is:  4.5530498027801514e-05\n",
      "The classification loss after processing this batch is:  24883.388671875\n",
      "The representation loss after processing this batch is:  4.084082320332527e-05\n",
      "The classification loss after processing this batch is:  25198.302734375\n",
      "The representation loss after processing this batch is:  5.109328776597977e-05\n",
      "The classification loss after processing this batch is:  24782.078125\n",
      "The representation loss after processing this batch is:  4.530604928731918e-05\n",
      "The classification loss after processing this batch is:  24326.099609375\n",
      "The representation loss after processing this batch is:  4.952354356646538e-05\n",
      "The classification loss after processing this batch is:  27923.0546875\n",
      "The representation loss after processing this batch is:  6.094807758927345e-05\n",
      "The classification loss after processing this batch is:  26680.171875\n",
      "The representation loss after processing this batch is:  3.8866885006427765e-05\n",
      "The classification loss after processing this batch is:  24418.4609375\n",
      "The representation loss after processing this batch is:  4.118680953979492e-05\n",
      "The classification loss after processing this batch is:  24575.97265625\n",
      "The representation loss after processing this batch is:  3.98796983063221e-05\n",
      "The classification loss after processing this batch is:  24287.626953125\n",
      "The representation loss after processing this batch is:  4.723109304904938e-05\n",
      "The classification loss after processing this batch is:  24618.8515625\n",
      "The representation loss after processing this batch is:  4.878221079707146e-05\n",
      "The classification loss after processing this batch is:  24996.849609375\n",
      "The representation loss after processing this batch is:  5.05116768181324e-05\n",
      "The classification loss after processing this batch is:  24603.771484375\n",
      "The representation loss after processing this batch is:  3.8106925785541534e-05\n",
      "The classification loss after processing this batch is:  26265.431640625\n",
      "The representation loss after processing this batch is:  4.199938848614693e-05\n",
      "The classification loss after processing this batch is:  25049.8359375\n",
      "The representation loss after processing this batch is:  4.551280289888382e-05\n",
      "The classification loss after processing this batch is:  25097.33203125\n",
      "The representation loss after processing this batch is:  4.2838044464588165e-05\n",
      "The classification loss after processing this batch is:  24722.58984375\n",
      "The representation loss after processing this batch is:  4.476308822631836e-05\n",
      "The classification loss after processing this batch is:  24715.25\n",
      "The representation loss after processing this batch is:  3.9307866245508194e-05\n",
      "The classification loss after processing this batch is:  24686.064453125\n",
      "The representation loss after processing this batch is:  4.2228493839502335e-05\n",
      "The classification loss after processing this batch is:  24192.3828125\n",
      "The representation loss after processing this batch is:  3.8329046219587326e-05\n",
      "The classification loss after processing this batch is:  24000.5625\n",
      "The representation loss after processing this batch is:  3.6714132875204086e-05\n",
      "The classification loss after processing this batch is:  23270.240234375\n",
      "The representation loss after processing this batch is:  4.5964960008859634e-05\n",
      "The classification loss after processing this batch is:  23659.626953125\n",
      "The representation loss after processing this batch is:  3.79364937543869e-05\n",
      "The classification loss after processing this batch is:  23641.13671875\n",
      "The representation loss after processing this batch is:  3.652134910225868e-05\n",
      "The classification loss after processing this batch is:  26347.021484375\n",
      "The representation loss after processing this batch is:  3.954721614718437e-05\n",
      "The classification loss after processing this batch is:  24726.44921875\n",
      "The representation loss after processing this batch is:  3.7023331969976425e-05\n",
      "The classification loss after processing this batch is:  23614.95703125\n",
      "The representation loss after processing this batch is:  3.900239244103432e-05\n",
      "The classification loss after processing this batch is:  24235.447265625\n",
      "The representation loss after processing this batch is:  3.763660788536072e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  23218.75\n",
      "The representation loss after processing this batch is:  4.159286618232727e-05\n",
      "The classification loss after processing this batch is:  23887.11328125\n",
      "The representation loss after processing this batch is:  3.7029851227998734e-05\n",
      "The classification loss after processing this batch is:  24195.04296875\n",
      "The representation loss after processing this batch is:  4.0183309465646744e-05\n",
      "The classification loss after processing this batch is:  23975.201171875\n",
      "The representation loss after processing this batch is:  4.3253879994153976e-05\n",
      "The classification loss after processing this batch is:  25180.736328125\n",
      "The representation loss after processing this batch is:  3.478396683931351e-05\n",
      "The classification loss after processing this batch is:  29178.798828125\n",
      "The representation loss after processing this batch is:  4.8658810555934906e-05\n",
      "The classification loss after processing this batch is:  24099.392578125\n",
      "The representation loss after processing this batch is:  4.065921530127525e-05\n",
      "The classification loss after processing this batch is:  24271.796875\n",
      "The representation loss after processing this batch is:  3.7247780710458755e-05\n",
      "The classification loss after processing this batch is:  24282.375\n",
      "The representation loss after processing this batch is:  4.774285480380058e-05\n",
      "The classification loss after processing this batch is:  24669.9296875\n",
      "The representation loss after processing this batch is:  4.937034100294113e-05\n",
      "The classification loss after processing this batch is:  24104.75390625\n",
      "The representation loss after processing this batch is:  3.648502752184868e-05\n",
      "The classification loss after processing this batch is:  24256.71875\n",
      "The representation loss after processing this batch is:  3.9503443986177444e-05\n",
      "The classification loss after processing this batch is:  24225.08984375\n",
      "The representation loss after processing this batch is:  3.91937792301178e-05\n",
      "The classification loss after processing this batch is:  24190.193359375\n",
      "The representation loss after processing this batch is:  4.129204899072647e-05\n",
      "The classification loss after processing this batch is:  23931.4765625\n",
      "The representation loss after processing this batch is:  3.644824028015137e-05\n",
      "The classification loss after processing this batch is:  24098.517578125\n",
      "The representation loss after processing this batch is:  3.857957199215889e-05\n",
      "The classification loss after processing this batch is:  23874.33984375\n",
      "The representation loss after processing this batch is:  3.609387204051018e-05\n",
      "The classification loss after processing this batch is:  23868.39453125\n",
      "The representation loss after processing this batch is:  4.3507665395736694e-05\n",
      "The classification loss after processing this batch is:  23660.08984375\n",
      "The representation loss after processing this batch is:  4.819221794605255e-05\n",
      "The classification loss after processing this batch is:  22717.515625\n",
      "The representation loss after processing this batch is:  4.1569117456674576e-05\n",
      "The classification loss after processing this batch is:  23673.37890625\n",
      "The representation loss after processing this batch is:  4.293583333492279e-05\n",
      "The classification loss after processing this batch is:  24022.9609375\n",
      "The representation loss after processing this batch is:  3.665732219815254e-05\n",
      "The classification loss after processing this batch is:  24082.8046875\n",
      "The representation loss after processing this batch is:  3.8324855268001556e-05\n",
      "The classification loss after processing this batch is:  23503.875\n",
      "The representation loss after processing this batch is:  3.942567855119705e-05\n",
      "The classification loss after processing this batch is:  25040.783203125\n",
      "The representation loss after processing this batch is:  4.8936810344457626e-05\n",
      "The classification loss after processing this batch is:  23839.82421875\n",
      "The representation loss after processing this batch is:  5.115009844303131e-05\n",
      "The classification loss after processing this batch is:  23876.37890625\n",
      "The representation loss after processing this batch is:  4.2560044676065445e-05\n",
      "The classification loss after processing this batch is:  24618.853515625\n",
      "The representation loss after processing this batch is:  3.8611236959695816e-05\n",
      "The classification loss after processing this batch is:  25663.767578125\n",
      "The representation loss after processing this batch is:  3.666011616587639e-05\n",
      "The classification loss after processing this batch is:  26477.310546875\n",
      "The representation loss after processing this batch is:  3.391411155462265e-05\n",
      "The classification loss after processing this batch is:  25816.2734375\n",
      "The representation loss after processing this batch is:  3.6990270018577576e-05\n",
      "The classification loss after processing this batch is:  22965.291015625\n",
      "The representation loss after processing this batch is:  4.113558679819107e-05\n",
      "The classification loss after processing this batch is:  24730.93359375\n",
      "The representation loss after processing this batch is:  3.614462912082672e-05\n",
      "The classification loss after processing this batch is:  24291.7578125\n",
      "The representation loss after processing this batch is:  3.508245572447777e-05\n",
      "The classification loss after processing this batch is:  24925.51171875\n",
      "The representation loss after processing this batch is:  3.843801096081734e-05\n",
      "The classification loss after processing this batch is:  25350.08984375\n",
      "The representation loss after processing this batch is:  3.4939032047986984e-05\n",
      "The classification loss after processing this batch is:  24398.693359375\n",
      "The representation loss after processing this batch is:  3.566872328519821e-05\n",
      "The classification loss after processing this batch is:  24487.58984375\n",
      "The representation loss after processing this batch is:  3.7414953112602234e-05\n",
      "The classification loss after processing this batch is:  24192.234375\n",
      "The representation loss after processing this batch is:  3.708433359861374e-05\n",
      "The classification loss after processing this batch is:  24903.66015625\n",
      "The representation loss after processing this batch is:  4.002731293439865e-05\n",
      "The classification loss after processing this batch is:  23752.498046875\n",
      "The representation loss after processing this batch is:  4.393141716718674e-05\n",
      "The classification loss after processing this batch is:  25149.697265625\n",
      "The representation loss after processing this batch is:  3.267219290137291e-05\n",
      "The classification loss after processing this batch is:  25776.724609375\n",
      "The representation loss after processing this batch is:  3.692787140607834e-05\n",
      "The classification loss after processing this batch is:  26267.76171875\n",
      "The representation loss after processing this batch is:  4.58424910902977e-05\n",
      "The classification loss after processing this batch is:  23879.90625\n",
      "The representation loss after processing this batch is:  4.009949043393135e-05\n",
      "The classification loss after processing this batch is:  23709.4140625\n",
      "The representation loss after processing this batch is:  4.0498096495866776e-05\n",
      "The classification loss after processing this batch is:  23750.7734375\n",
      "The representation loss after processing this batch is:  3.528594970703125e-05\n",
      "The classification loss after processing this batch is:  24772.591796875\n",
      "The representation loss after processing this batch is:  3.309408202767372e-05\n",
      "The classification loss after processing this batch is:  25699.40234375\n",
      "The representation loss after processing this batch is:  3.742752596735954e-05\n",
      "The classification loss after processing this batch is:  24092.49609375\n",
      "The representation loss after processing this batch is:  4.039565101265907e-05\n",
      "The classification loss after processing this batch is:  23397.95703125\n",
      "The representation loss after processing this batch is:  3.3800024539232254e-05\n",
      "The classification loss after processing this batch is:  24050.953125\n",
      "The representation loss after processing this batch is:  3.7013087421655655e-05\n",
      "The classification loss after processing this batch is:  23202.92578125\n",
      "The representation loss after processing this batch is:  3.4427735954523087e-05\n",
      "The classification loss after processing this batch is:  23582.42578125\n",
      "The representation loss after processing this batch is:  3.815721720457077e-05\n",
      "The classification loss after processing this batch is:  23455.341796875\n",
      "The representation loss after processing this batch is:  3.848923370242119e-05\n",
      "The classification loss after processing this batch is:  23338.1796875\n",
      "The representation loss after processing this batch is:  3.6683399230241776e-05\n",
      "The classification loss after processing this batch is:  22975.1484375\n",
      "The representation loss after processing this batch is:  3.420701250433922e-05\n",
      "The classification loss after processing this batch is:  22849.861328125\n",
      "The representation loss after processing this batch is:  3.627408295869827e-05\n",
      "The classification loss after processing this batch is:  23345.06640625\n",
      "The representation loss after processing this batch is:  3.327801823616028e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22891.9296875\n",
      "The representation loss after processing this batch is:  3.8994476199150085e-05\n",
      "The classification loss after processing this batch is:  23077.615234375\n",
      "The representation loss after processing this batch is:  3.7025660276412964e-05\n",
      "The classification loss after processing this batch is:  23542.0859375\n",
      "The representation loss after processing this batch is:  3.503262996673584e-05\n",
      "The classification loss after processing this batch is:  22799.060546875\n",
      "The representation loss after processing this batch is:  3.4121330827474594e-05\n",
      "The classification loss after processing this batch is:  24891.3359375\n",
      "The representation loss after processing this batch is:  3.242632374167442e-05\n",
      "The classification loss after processing this batch is:  24499.66015625\n",
      "The representation loss after processing this batch is:  3.359932452440262e-05\n",
      "The classification loss after processing this batch is:  25141.849609375\n",
      "The representation loss after processing this batch is:  3.321561962366104e-05\n",
      "The classification loss after processing this batch is:  25506.45703125\n",
      "The representation loss after processing this batch is:  3.5848468542099e-05\n",
      "The classification loss after processing this batch is:  25367.994140625\n",
      "The representation loss after processing this batch is:  4.336889833211899e-05\n",
      "The classification loss after processing this batch is:  24573.0546875\n",
      "The representation loss after processing this batch is:  3.701774403452873e-05\n",
      "The classification loss after processing this batch is:  24420.712890625\n",
      "The representation loss after processing this batch is:  3.867177292704582e-05\n",
      "The classification loss after processing this batch is:  23996.49609375\n",
      "The representation loss after processing this batch is:  3.616977483034134e-05\n",
      "The classification loss after processing this batch is:  24634.9765625\n",
      "The representation loss after processing this batch is:  3.760494291782379e-05\n",
      "The classification loss after processing this batch is:  23783.1171875\n",
      "The representation loss after processing this batch is:  3.1717587262392044e-05\n",
      "The classification loss after processing this batch is:  23536.001953125\n",
      "The representation loss after processing this batch is:  3.647850826382637e-05\n",
      "The classification loss after processing this batch is:  24442.49609375\n",
      "The representation loss after processing this batch is:  3.412272781133652e-05\n",
      "The classification loss after processing this batch is:  24098.419921875\n",
      "The representation loss after processing this batch is:  4.03854064643383e-05\n",
      "The classification loss after processing this batch is:  23875.345703125\n",
      "The representation loss after processing this batch is:  3.887573257088661e-05\n",
      "The classification loss after processing this batch is:  25278.72265625\n",
      "The representation loss after processing this batch is:  3.93143855035305e-05\n",
      "The classification loss after processing this batch is:  28112.84375\n",
      "The representation loss after processing this batch is:  3.9894599467515945e-05\n",
      "The classification loss after processing this batch is:  25640.40625\n",
      "The representation loss after processing this batch is:  3.376416862010956e-05\n",
      "The classification loss after processing this batch is:  23876.337890625\n",
      "The representation loss after processing this batch is:  3.3235177397727966e-05\n",
      "The classification loss after processing this batch is:  23976.052734375\n",
      "The representation loss after processing this batch is:  4.0030572563409805e-05\n",
      "The classification loss after processing this batch is:  28139.5078125\n",
      "The representation loss after processing this batch is:  4.158914089202881e-05\n",
      "The classification loss after processing this batch is:  28351.66796875\n",
      "The representation loss after processing this batch is:  4.4063664972782135e-05\n",
      "The classification loss after processing this batch is:  23508.66015625\n",
      "The representation loss after processing this batch is:  3.7540215998888016e-05\n",
      "The classification loss after processing this batch is:  23385.390625\n",
      "The representation loss after processing this batch is:  3.6358367651700974e-05\n",
      "The classification loss after processing this batch is:  23970.240234375\n",
      "The representation loss after processing this batch is:  3.895629197359085e-05\n",
      "The classification loss after processing this batch is:  24302.052734375\n",
      "The representation loss after processing this batch is:  3.39411199092865e-05\n",
      "The classification loss after processing this batch is:  24334.501953125\n",
      "The representation loss after processing this batch is:  3.4294091165065765e-05\n",
      "The classification loss after processing this batch is:  23894.71875\n",
      "The representation loss after processing this batch is:  3.9472244679927826e-05\n",
      "The classification loss after processing this batch is:  25166.9921875\n",
      "The representation loss after processing this batch is:  3.913929685950279e-05\n",
      "The classification loss after processing this batch is:  26196.275390625\n",
      "The representation loss after processing this batch is:  3.656139597296715e-05\n",
      "The classification loss after processing this batch is:  24131.7265625\n",
      "The representation loss after processing this batch is:  3.738515079021454e-05\n",
      "The classification loss after processing this batch is:  24851.5625\n",
      "The representation loss after processing this batch is:  3.5262200981378555e-05\n",
      "The classification loss after processing this batch is:  23575.13671875\n",
      "The representation loss after processing this batch is:  3.192387521266937e-05\n",
      "The classification loss after processing this batch is:  23724.08203125\n",
      "The representation loss after processing this batch is:  3.825174644589424e-05\n",
      "The classification loss after processing this batch is:  22935.6953125\n",
      "The representation loss after processing this batch is:  3.637978807091713e-05\n",
      "The classification loss after processing this batch is:  24217.623046875\n",
      "The representation loss after processing this batch is:  4.140520468354225e-05\n",
      "The classification loss after processing this batch is:  23816.93359375\n",
      "The representation loss after processing this batch is:  3.42661514878273e-05\n",
      "The classification loss after processing this batch is:  26356.099609375\n",
      "The representation loss after processing this batch is:  3.6288052797317505e-05\n",
      "The classification loss after processing this batch is:  23805.224609375\n",
      "The representation loss after processing this batch is:  3.8026366382837296e-05\n",
      "The classification loss after processing this batch is:  24032.53515625\n",
      "The representation loss after processing this batch is:  3.431644290685654e-05\n",
      "The classification loss after processing this batch is:  25684.0078125\n",
      "The representation loss after processing this batch is:  3.9774924516677856e-05\n",
      "The classification loss after processing this batch is:  25140.33984375\n",
      "The representation loss after processing this batch is:  3.225961700081825e-05\n",
      "The classification loss after processing this batch is:  24468.517578125\n",
      "The representation loss after processing this batch is:  3.4862663596868515e-05\n",
      "The classification loss after processing this batch is:  26002.75390625\n",
      "The representation loss after processing this batch is:  4.89591620862484e-05\n",
      "The classification loss after processing this batch is:  24065.3515625\n",
      "The representation loss after processing this batch is:  3.439607098698616e-05\n",
      "The classification loss after processing this batch is:  24616.267578125\n",
      "The representation loss after processing this batch is:  3.9315782487392426e-05\n",
      "The classification loss after processing this batch is:  23340.07421875\n",
      "The representation loss after processing this batch is:  3.481283783912659e-05\n",
      "The classification loss after processing this batch is:  23398.140625\n",
      "The representation loss after processing this batch is:  3.796350210905075e-05\n",
      "The classification loss after processing this batch is:  23539.380859375\n",
      "The representation loss after processing this batch is:  3.5274308174848557e-05\n",
      "The classification loss after processing this batch is:  23429.447265625\n",
      "The representation loss after processing this batch is:  3.807432949542999e-05\n",
      "The classification loss after processing this batch is:  23387.376953125\n",
      "The representation loss after processing this batch is:  3.877142444252968e-05\n",
      "The classification loss after processing this batch is:  25990.404296875\n",
      "The representation loss after processing this batch is:  3.4152064472436905e-05\n",
      "The classification loss after processing this batch is:  23530.876953125\n",
      "The representation loss after processing this batch is:  3.360491245985031e-05\n",
      "The classification loss after processing this batch is:  23747.271484375\n",
      "The representation loss after processing this batch is:  3.349548205733299e-05\n",
      "The classification loss after processing this batch is:  24451.310546875\n",
      "The representation loss after processing this batch is:  3.483006730675697e-05\n",
      "The classification loss after processing this batch is:  23768.0625\n",
      "The representation loss after processing this batch is:  3.347080200910568e-05\n",
      "The classification loss after processing this batch is:  24556.40234375\n",
      "The representation loss after processing this batch is:  3.375997766852379e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24356.6015625\n",
      "The representation loss after processing this batch is:  3.201467916369438e-05\n",
      "The classification loss after processing this batch is:  24070.59765625\n",
      "The representation loss after processing this batch is:  3.3603981137275696e-05\n",
      "The classification loss after processing this batch is:  22770.119140625\n",
      "The representation loss after processing this batch is:  3.1910836696624756e-05\n",
      "The classification loss after processing this batch is:  24317.986328125\n",
      "The representation loss after processing this batch is:  3.753136843442917e-05\n",
      "The classification loss after processing this batch is:  26540.578125\n",
      "The representation loss after processing this batch is:  3.34717333316803e-05\n",
      "The classification loss after processing this batch is:  27386.40625\n",
      "The representation loss after processing this batch is:  3.806455060839653e-05\n",
      "The classification loss after processing this batch is:  24166.525390625\n",
      "The representation loss after processing this batch is:  3.3082906156778336e-05\n",
      "The classification loss after processing this batch is:  24006.98828125\n",
      "The representation loss after processing this batch is:  3.305915743112564e-05\n",
      "The classification loss after processing this batch is:  23680.822265625\n",
      "The representation loss after processing this batch is:  3.306334838271141e-05\n",
      "The classification loss after processing this batch is:  24617.314453125\n",
      "The representation loss after processing this batch is:  3.262609243392944e-05\n",
      "The classification loss after processing this batch is:  23522.24609375\n",
      "The representation loss after processing this batch is:  3.284774720668793e-05\n",
      "The classification loss after processing this batch is:  23821.541015625\n",
      "The representation loss after processing this batch is:  3.1064730137586594e-05\n",
      "The classification loss after processing this batch is:  25402.41015625\n",
      "The representation loss after processing this batch is:  3.412691876292229e-05\n",
      "The classification loss after processing this batch is:  22608.572265625\n",
      "The representation loss after processing this batch is:  3.41217964887619e-05\n",
      "The classification loss after processing this batch is:  23149.443359375\n",
      "The representation loss after processing this batch is:  3.560073673725128e-05\n",
      "The classification loss after processing this batch is:  25193.35546875\n",
      "The representation loss after processing this batch is:  3.7859659641981125e-05\n",
      "The classification loss after processing this batch is:  24117.23828125\n",
      "The representation loss after processing this batch is:  3.9224978536367416e-05\n",
      "The classification loss after processing this batch is:  23371.5703125\n",
      "The representation loss after processing this batch is:  3.676069900393486e-05\n",
      "The classification loss after processing this batch is:  22271.4453125\n",
      "The representation loss after processing this batch is:  3.348430618643761e-05\n",
      "The classification loss after processing this batch is:  24841.05859375\n",
      "The representation loss after processing this batch is:  3.6383047699928284e-05\n",
      "The classification loss after processing this batch is:  24455.35546875\n",
      "The representation loss after processing this batch is:  3.67211177945137e-05\n",
      "The classification loss after processing this batch is:  28935.771484375\n",
      "The representation loss after processing this batch is:  3.62996943295002e-05\n",
      "The classification loss after processing this batch is:  25242.20703125\n",
      "The representation loss after processing this batch is:  3.467267379164696e-05\n",
      "The classification loss after processing this batch is:  23607.88671875\n",
      "The representation loss after processing this batch is:  3.571296110749245e-05\n",
      "The classification loss after processing this batch is:  25112.77734375\n",
      "The representation loss after processing this batch is:  3.6605168133974075e-05\n",
      "The classification loss after processing this batch is:  25991.22265625\n",
      "The representation loss after processing this batch is:  3.5803765058517456e-05\n",
      "The classification loss after processing this batch is:  25052.529296875\n",
      "The representation loss after processing this batch is:  3.286171704530716e-05\n",
      "The classification loss after processing this batch is:  24376.1015625\n",
      "The representation loss after processing this batch is:  3.4329015761613846e-05\n",
      "The classification loss after processing this batch is:  24463.126953125\n",
      "The representation loss after processing this batch is:  3.107963129878044e-05\n",
      "The classification loss after processing this batch is:  24287.1875\n",
      "The representation loss after processing this batch is:  3.0308030545711517e-05\n",
      "The classification loss after processing this batch is:  23113.36328125\n",
      "The representation loss after processing this batch is:  3.447476774454117e-05\n",
      "The classification loss after processing this batch is:  24223.896484375\n",
      "The representation loss after processing this batch is:  3.381352871656418e-05\n",
      "The classification loss after processing this batch is:  23953.794921875\n",
      "The representation loss after processing this batch is:  3.235088661313057e-05\n",
      "The classification loss after processing this batch is:  24498.279296875\n",
      "The representation loss after processing this batch is:  3.684544935822487e-05\n",
      "The classification loss after processing this batch is:  24577.341796875\n",
      "The representation loss after processing this batch is:  3.3099669963121414e-05\n",
      "The classification loss after processing this batch is:  24857.38671875\n",
      "The representation loss after processing this batch is:  3.366032615303993e-05\n",
      "The classification loss after processing this batch is:  23284.859375\n",
      "The representation loss after processing this batch is:  3.113970160484314e-05\n",
      "The classification loss after processing this batch is:  22663.162109375\n",
      "The representation loss after processing this batch is:  3.6500394344329834e-05\n",
      "The classification loss after processing this batch is:  23469.2578125\n",
      "The representation loss after processing this batch is:  3.0284281820058823e-05\n",
      "The classification loss after processing this batch is:  23124.96484375\n",
      "The representation loss after processing this batch is:  3.221258521080017e-05\n",
      "The classification loss after processing this batch is:  24323.216796875\n",
      "The representation loss after processing this batch is:  3.3239368349313736e-05\n",
      "The classification loss after processing this batch is:  24149.80078125\n",
      "The representation loss after processing this batch is:  3.293715417385101e-05\n",
      "The classification loss after processing this batch is:  23324.22265625\n",
      "The representation loss after processing this batch is:  3.686361014842987e-05\n",
      "The classification loss after processing this batch is:  22475.634765625\n",
      "The representation loss after processing this batch is:  3.69856134057045e-05\n",
      "The classification loss after processing this batch is:  22400.8515625\n",
      "The representation loss after processing this batch is:  3.148149698972702e-05\n",
      "The classification loss after processing this batch is:  23962.189453125\n",
      "The representation loss after processing this batch is:  3.211619332432747e-05\n",
      "The classification loss after processing this batch is:  25005.447265625\n",
      "The representation loss after processing this batch is:  3.0030962079763412e-05\n",
      "The classification loss after processing this batch is:  24930.29296875\n",
      "The representation loss after processing this batch is:  4.223501309752464e-05\n",
      "The classification loss after processing this batch is:  23171.90234375\n",
      "The representation loss after processing this batch is:  3.217114135622978e-05\n",
      "The classification loss after processing this batch is:  24080.03515625\n",
      "The representation loss after processing this batch is:  3.623170778155327e-05\n",
      "The classification loss after processing this batch is:  23139.775390625\n",
      "The representation loss after processing this batch is:  3.90857458114624e-05\n",
      "The classification loss after processing this batch is:  23568.654296875\n",
      "The representation loss after processing this batch is:  4.442315548658371e-05\n",
      "The classification loss after processing this batch is:  23039.68359375\n",
      "The representation loss after processing this batch is:  3.1624455004930496e-05\n",
      "The classification loss after processing this batch is:  22687.6015625\n",
      "The representation loss after processing this batch is:  3.471551463007927e-05\n",
      "The classification loss after processing this batch is:  22596.537109375\n",
      "The representation loss after processing this batch is:  3.76235693693161e-05\n",
      "The classification loss after processing this batch is:  23209.388671875\n",
      "The representation loss after processing this batch is:  3.639142960309982e-05\n",
      "The classification loss after processing this batch is:  23490.947265625\n",
      "The representation loss after processing this batch is:  3.6253128200769424e-05\n",
      "The classification loss after processing this batch is:  23971.25390625\n",
      "The representation loss after processing this batch is:  3.426242619752884e-05\n",
      "The classification loss after processing this batch is:  23621.763671875\n",
      "The representation loss after processing this batch is:  3.496883437037468e-05\n",
      "The classification loss after processing this batch is:  23150.34765625\n",
      "The representation loss after processing this batch is:  3.214040771126747e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  25125.06640625\n",
      "The representation loss after processing this batch is:  3.144005313515663e-05\n",
      "The classification loss after processing this batch is:  26395.6171875\n",
      "The representation loss after processing this batch is:  3.843149170279503e-05\n",
      "The classification loss after processing this batch is:  25207.68359375\n",
      "The representation loss after processing this batch is:  4.428531974554062e-05\n",
      "The classification loss after processing this batch is:  25201.23046875\n",
      "The representation loss after processing this batch is:  3.741122782230377e-05\n",
      "The classification loss after processing this batch is:  23523.416015625\n",
      "The representation loss after processing this batch is:  3.303075209259987e-05\n",
      "The classification loss after processing this batch is:  24008.38671875\n",
      "The representation loss after processing this batch is:  3.169802948832512e-05\n",
      "The classification loss after processing this batch is:  25276.990234375\n",
      "The representation loss after processing this batch is:  3.980286419391632e-05\n",
      "The classification loss after processing this batch is:  23286.412109375\n",
      "The representation loss after processing this batch is:  3.858096897602081e-05\n",
      "The classification loss after processing this batch is:  23329.24609375\n",
      "The representation loss after processing this batch is:  3.5589560866355896e-05\n",
      "The classification loss after processing this batch is:  24455.8359375\n",
      "The representation loss after processing this batch is:  3.0932947993278503e-05\n",
      "The classification loss after processing this batch is:  24264.037109375\n",
      "The representation loss after processing this batch is:  3.127614036202431e-05\n",
      "The classification loss after processing this batch is:  24026.201171875\n",
      "The representation loss after processing this batch is:  3.0125025659799576e-05\n",
      "The classification loss after processing this batch is:  23601.47265625\n",
      "The representation loss after processing this batch is:  3.6363955587148666e-05\n",
      "The classification loss after processing this batch is:  25116.359375\n",
      "The representation loss after processing this batch is:  3.4149736166000366e-05\n",
      "The classification loss after processing this batch is:  25008.1796875\n",
      "The representation loss after processing this batch is:  3.74368391931057e-05\n",
      "The classification loss after processing this batch is:  25668.25390625\n",
      "The representation loss after processing this batch is:  2.9709655791521072e-05\n",
      "The classification loss after processing this batch is:  25555.7109375\n",
      "The representation loss after processing this batch is:  3.695022314786911e-05\n",
      "The classification loss after processing this batch is:  24295.91796875\n",
      "The representation loss after processing this batch is:  3.229966387152672e-05\n",
      "The classification loss after processing this batch is:  23553.25390625\n",
      "The representation loss after processing this batch is:  3.371434286236763e-05\n",
      "The classification loss after processing this batch is:  23374.982421875\n",
      "The representation loss after processing this batch is:  3.3389776945114136e-05\n",
      "The classification loss after processing this batch is:  23333.888671875\n",
      "The representation loss after processing this batch is:  3.3173710107803345e-05\n",
      "The classification loss after processing this batch is:  23531.66796875\n",
      "The representation loss after processing this batch is:  3.464892506599426e-05\n",
      "The classification loss after processing this batch is:  23307.005859375\n",
      "The representation loss after processing this batch is:  3.5439152270555496e-05\n",
      "The classification loss after processing this batch is:  23965.86328125\n",
      "The representation loss after processing this batch is:  3.137066960334778e-05\n",
      "The classification loss after processing this batch is:  23984.14453125\n",
      "The representation loss after processing this batch is:  3.855954855680466e-05\n",
      "The classification loss after processing this batch is:  26694.24609375\n",
      "The representation loss after processing this batch is:  4.015117883682251e-05\n",
      "The classification loss after processing this batch is:  25945.40625\n",
      "The representation loss after processing this batch is:  3.210781142115593e-05\n",
      "The classification loss after processing this batch is:  23988.921875\n",
      "The representation loss after processing this batch is:  3.2162293791770935e-05\n",
      "The classification loss after processing this batch is:  22821.21875\n",
      "The representation loss after processing this batch is:  3.836303949356079e-05\n",
      "The classification loss after processing this batch is:  22857.51171875\n",
      "The representation loss after processing this batch is:  3.690086305141449e-05\n",
      "The classification loss after processing this batch is:  23770.552734375\n",
      "The representation loss after processing this batch is:  3.930274397134781e-05\n",
      "The classification loss after processing this batch is:  23363.4375\n",
      "The representation loss after processing this batch is:  3.4980010241270065e-05\n",
      "The classification loss after processing this batch is:  23910.357421875\n",
      "The representation loss after processing this batch is:  3.442680463194847e-05\n",
      "The classification loss after processing this batch is:  23636.142578125\n",
      "The representation loss after processing this batch is:  3.482401371002197e-05\n",
      "The classification loss after processing this batch is:  22998.42578125\n",
      "The representation loss after processing this batch is:  2.927146852016449e-05\n",
      "The classification loss after processing this batch is:  22682.037109375\n",
      "The representation loss after processing this batch is:  3.4924596548080444e-05\n",
      "The classification loss after processing this batch is:  24285.22265625\n",
      "The representation loss after processing this batch is:  3.4079886972904205e-05\n",
      "The classification loss after processing this batch is:  25162.595703125\n",
      "The representation loss after processing this batch is:  3.8671307265758514e-05\n",
      "The classification loss after processing this batch is:  23694.1640625\n",
      "The representation loss after processing this batch is:  3.8378406316041946e-05\n",
      "The classification loss after processing this batch is:  24238.21484375\n",
      "The representation loss after processing this batch is:  3.357278183102608e-05\n",
      "The classification loss after processing this batch is:  25646.306640625\n",
      "The representation loss after processing this batch is:  3.71481291949749e-05\n",
      "The classification loss after processing this batch is:  24538.26953125\n",
      "The representation loss after processing this batch is:  3.3023301512002945e-05\n",
      "The classification loss after processing this batch is:  25745.21484375\n",
      "The representation loss after processing this batch is:  3.3282674849033356e-05\n",
      "The classification loss after processing this batch is:  23896.951171875\n",
      "The representation loss after processing this batch is:  3.443518653512001e-05\n",
      "The classification loss after processing this batch is:  24963.90625\n",
      "The representation loss after processing this batch is:  3.816932439804077e-05\n",
      "The classification loss after processing this batch is:  23626.37890625\n",
      "The representation loss after processing this batch is:  3.448221832513809e-05\n",
      "The classification loss after processing this batch is:  24232.40234375\n",
      "The representation loss after processing this batch is:  3.0790455639362335e-05\n",
      "The classification loss after processing this batch is:  23866.421875\n",
      "The representation loss after processing this batch is:  3.396999090909958e-05\n",
      "The classification loss after processing this batch is:  23695.751953125\n",
      "The representation loss after processing this batch is:  3.30023467540741e-05\n",
      "The classification loss after processing this batch is:  24334.224609375\n",
      "The representation loss after processing this batch is:  3.401562571525574e-05\n",
      "The classification loss after processing this batch is:  22982.828125\n",
      "The representation loss after processing this batch is:  3.5303644835948944e-05\n",
      "The classification loss after processing this batch is:  23306.8828125\n",
      "The representation loss after processing this batch is:  3.531668335199356e-05\n",
      "The classification loss after processing this batch is:  22551.162109375\n",
      "The representation loss after processing this batch is:  3.189966082572937e-05\n",
      "The classification loss after processing this batch is:  22925.650390625\n",
      "The representation loss after processing this batch is:  4.082405939698219e-05\n",
      "The classification loss after processing this batch is:  22689.052734375\n",
      "The representation loss after processing this batch is:  3.2224226742982864e-05\n",
      "The classification loss after processing this batch is:  24273.791015625\n",
      "The representation loss after processing this batch is:  3.515603020787239e-05\n",
      "The classification loss after processing this batch is:  23598.25\n",
      "The representation loss after processing this batch is:  3.48496250808239e-05\n",
      "The classification loss after processing this batch is:  24139.970703125\n",
      "The representation loss after processing this batch is:  3.23224812746048e-05\n",
      "The classification loss after processing this batch is:  24147.28515625\n",
      "The representation loss after processing this batch is:  3.078952431678772e-05\n",
      "The classification loss after processing this batch is:  23099.44921875\n",
      "The representation loss after processing this batch is:  3.280350938439369e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24103.0859375\n",
      "The representation loss after processing this batch is:  3.5591889172792435e-05\n",
      "The classification loss after processing this batch is:  23900.8125\n",
      "The representation loss after processing this batch is:  3.672763705253601e-05\n",
      "The classification loss after processing this batch is:  22842.05859375\n",
      "The representation loss after processing this batch is:  3.294646739959717e-05\n",
      "The classification loss after processing this batch is:  24106.06640625\n",
      "The representation loss after processing this batch is:  3.3511314541101456e-05\n",
      "The classification loss after processing this batch is:  23723.265625\n",
      "The representation loss after processing this batch is:  3.378652036190033e-05\n",
      "The classification loss after processing this batch is:  23073.19140625\n",
      "The representation loss after processing this batch is:  3.285380080342293e-05\n",
      "The classification loss after processing this batch is:  23908.314453125\n",
      "The representation loss after processing this batch is:  3.401143476366997e-05\n",
      "The classification loss after processing this batch is:  23460.1953125\n",
      "The representation loss after processing this batch is:  3.491947427392006e-05\n",
      "The classification loss after processing this batch is:  24386.724609375\n",
      "The representation loss after processing this batch is:  3.682682290673256e-05\n",
      "The classification loss after processing this batch is:  24733.572265625\n",
      "The representation loss after processing this batch is:  3.403192386031151e-05\n",
      "The classification loss after processing this batch is:  23210.2734375\n",
      "The representation loss after processing this batch is:  4.083104431629181e-05\n",
      "The classification loss after processing this batch is:  26442.78515625\n",
      "The representation loss after processing this batch is:  3.145262598991394e-05\n",
      "The classification loss after processing this batch is:  26595.361328125\n",
      "The representation loss after processing this batch is:  3.307964652776718e-05\n",
      "The classification loss after processing this batch is:  23375.6015625\n",
      "The representation loss after processing this batch is:  3.323471173644066e-05\n",
      "The classification loss after processing this batch is:  24111.7265625\n",
      "The representation loss after processing this batch is:  3.16365621984005e-05\n",
      "The classification loss after processing this batch is:  24825.953125\n",
      "The representation loss after processing this batch is:  3.415672108530998e-05\n",
      "The classification loss after processing this batch is:  23547.2578125\n",
      "The representation loss after processing this batch is:  2.941768616437912e-05\n",
      "The classification loss after processing this batch is:  23931.990234375\n",
      "The representation loss after processing this batch is:  3.30987386405468e-05\n",
      "The classification loss after processing this batch is:  23691.267578125\n",
      "The representation loss after processing this batch is:  3.129476681351662e-05\n",
      "The classification loss after processing this batch is:  23972.5859375\n",
      "The representation loss after processing this batch is:  3.309827297925949e-05\n",
      "The classification loss after processing this batch is:  25118.3671875\n",
      "The representation loss after processing this batch is:  3.1360890716314316e-05\n",
      "The classification loss after processing this batch is:  24838.6640625\n",
      "The representation loss after processing this batch is:  3.4096185117959976e-05\n",
      "The classification loss after processing this batch is:  26445.63671875\n",
      "The representation loss after processing this batch is:  3.5101547837257385e-05\n",
      "The classification loss after processing this batch is:  24912.6328125\n",
      "The representation loss after processing this batch is:  3.6265235394239426e-05\n",
      "The classification loss after processing this batch is:  24883.03125\n",
      "The representation loss after processing this batch is:  3.0404888093471527e-05\n",
      "The classification loss after processing this batch is:  22976.80859375\n",
      "The representation loss after processing this batch is:  3.067636862397194e-05\n",
      "The classification loss after processing this batch is:  23368.76171875\n",
      "The representation loss after processing this batch is:  2.993270754814148e-05\n",
      "The classification loss after processing this batch is:  24618.53515625\n",
      "The representation loss after processing this batch is:  3.129569813609123e-05\n",
      "The classification loss after processing this batch is:  23349.525390625\n",
      "The representation loss after processing this batch is:  3.5810284316539764e-05\n",
      "The classification loss after processing this batch is:  22532.93359375\n",
      "The representation loss after processing this batch is:  3.7822872400283813e-05\n",
      "The classification loss after processing this batch is:  25178.2421875\n",
      "The representation loss after processing this batch is:  3.2411422580480576e-05\n",
      "The classification loss after processing this batch is:  22971.26953125\n",
      "The representation loss after processing this batch is:  3.064516931772232e-05\n",
      "The classification loss after processing this batch is:  23177.34765625\n",
      "The representation loss after processing this batch is:  3.17692756652832e-05\n",
      "The classification loss after processing this batch is:  22427.359375\n",
      "The representation loss after processing this batch is:  3.4110620617866516e-05\n",
      "The classification loss after processing this batch is:  22963.83984375\n",
      "The representation loss after processing this batch is:  3.1579285860061646e-05\n",
      "The classification loss after processing this batch is:  22388.1640625\n",
      "The representation loss after processing this batch is:  3.17632220685482e-05\n",
      "The classification loss after processing this batch is:  23749.33984375\n",
      "The representation loss after processing this batch is:  3.425450995564461e-05\n",
      "The classification loss after processing this batch is:  23436.8671875\n",
      "The representation loss after processing this batch is:  3.278395161032677e-05\n",
      "The classification loss after processing this batch is:  22992.1328125\n",
      "The representation loss after processing this batch is:  3.2188836485147476e-05\n",
      "The classification loss after processing this batch is:  24679.859375\n",
      "The representation loss after processing this batch is:  3.453763201832771e-05\n",
      "The classification loss after processing this batch is:  24778.541015625\n",
      "The representation loss after processing this batch is:  3.305543214082718e-05\n",
      "The classification loss after processing this batch is:  22674.92578125\n",
      "The representation loss after processing this batch is:  3.323191776871681e-05\n",
      "The classification loss after processing this batch is:  22987.095703125\n",
      "The representation loss after processing this batch is:  3.609387204051018e-05\n",
      "The classification loss after processing this batch is:  23278.009765625\n",
      "The representation loss after processing this batch is:  3.293761983513832e-05\n",
      "The classification loss after processing this batch is:  23393.76171875\n",
      "The representation loss after processing this batch is:  3.204401582479477e-05\n",
      "The classification loss after processing this batch is:  25074.453125\n",
      "The representation loss after processing this batch is:  3.147125244140625e-05\n",
      "The classification loss after processing this batch is:  23286.26953125\n",
      "The representation loss after processing this batch is:  3.231223672628403e-05\n",
      "The classification loss after processing this batch is:  22398.134765625\n",
      "The representation loss after processing this batch is:  3.439048305153847e-05\n",
      "The classification loss after processing this batch is:  23345.142578125\n",
      "The representation loss after processing this batch is:  3.5293400287628174e-05\n",
      "The classification loss after processing this batch is:  25690.935546875\n",
      "The representation loss after processing this batch is:  3.766268491744995e-05\n",
      "The classification loss after processing this batch is:  23153.251953125\n",
      "The representation loss after processing this batch is:  3.1804200261831284e-05\n",
      "The classification loss after processing this batch is:  23874.3828125\n",
      "The representation loss after processing this batch is:  3.096228465437889e-05\n",
      "The classification loss after processing this batch is:  25661.806640625\n",
      "The representation loss after processing this batch is:  3.2582785934209824e-05\n",
      "The classification loss after processing this batch is:  23612.291015625\n",
      "The representation loss after processing this batch is:  3.378186374902725e-05\n",
      "The classification loss after processing this batch is:  22799.5859375\n",
      "The representation loss after processing this batch is:  3.443891182541847e-05\n",
      "The classification loss after processing this batch is:  23038.599609375\n",
      "The representation loss after processing this batch is:  3.503076732158661e-05\n",
      "The classification loss after processing this batch is:  22801.35546875\n",
      "The representation loss after processing this batch is:  3.154156729578972e-05\n",
      "The classification loss after processing this batch is:  23204.66015625\n",
      "The representation loss after processing this batch is:  2.91517935693264e-05\n",
      "The classification loss after processing this batch is:  23067.6015625\n",
      "The representation loss after processing this batch is:  3.594253212213516e-05\n",
      "The classification loss after processing this batch is:  23579.55078125\n",
      "The representation loss after processing this batch is:  3.264052793383598e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  26555.4765625\n",
      "The representation loss after processing this batch is:  3.370782360434532e-05\n",
      "The classification loss after processing this batch is:  24797.6484375\n",
      "The representation loss after processing this batch is:  2.917693927884102e-05\n",
      "The classification loss after processing this batch is:  24081.18359375\n",
      "The representation loss after processing this batch is:  3.178371116518974e-05\n",
      "The classification loss after processing this batch is:  22950.5078125\n",
      "The representation loss after processing this batch is:  3.167521208524704e-05\n",
      "The classification loss after processing this batch is:  23504.064453125\n",
      "The representation loss after processing this batch is:  3.499351441860199e-05\n",
      "The classification loss after processing this batch is:  23154.171875\n",
      "The representation loss after processing this batch is:  3.935350105166435e-05\n",
      "The classification loss after processing this batch is:  23114.90625\n",
      "The representation loss after processing this batch is:  3.273226320743561e-05\n",
      "The classification loss after processing this batch is:  22363.1640625\n",
      "The representation loss after processing this batch is:  3.194715827703476e-05\n",
      "The classification loss after processing this batch is:  23015.337890625\n",
      "The representation loss after processing this batch is:  3.335438668727875e-05\n",
      "The classification loss after processing this batch is:  22865.724609375\n",
      "The representation loss after processing this batch is:  3.046216443181038e-05\n",
      "The classification loss after processing this batch is:  22234.4453125\n",
      "The representation loss after processing this batch is:  3.2646581530570984e-05\n",
      "The classification loss after processing this batch is:  23464.046875\n",
      "The representation loss after processing this batch is:  3.263493999838829e-05\n",
      "The classification loss after processing this batch is:  22402.30078125\n",
      "The representation loss after processing this batch is:  3.316672518849373e-05\n",
      "The classification loss after processing this batch is:  24748.853515625\n",
      "The representation loss after processing this batch is:  3.459397703409195e-05\n",
      "The classification loss after processing this batch is:  24432.802734375\n",
      "The representation loss after processing this batch is:  3.153085708618164e-05\n",
      "The classification loss after processing this batch is:  23542.884765625\n",
      "The representation loss after processing this batch is:  3.231409937143326e-05\n",
      "The classification loss after processing this batch is:  23234.072265625\n",
      "The representation loss after processing this batch is:  3.144098445773125e-05\n",
      "The classification loss after processing this batch is:  23189.29296875\n",
      "The representation loss after processing this batch is:  3.169430419802666e-05\n",
      "The classification loss after processing this batch is:  24630.248046875\n",
      "The representation loss after processing this batch is:  3.317883238196373e-05\n",
      "The classification loss after processing this batch is:  24288.796875\n",
      "The representation loss after processing this batch is:  3.288593143224716e-05\n",
      "The classification loss after processing this batch is:  23361.515625\n",
      "The representation loss after processing this batch is:  3.095436841249466e-05\n",
      "The classification loss after processing this batch is:  23812.857421875\n",
      "The representation loss after processing this batch is:  2.9752962291240692e-05\n",
      "The classification loss after processing this batch is:  25612.40625\n",
      "The representation loss after processing this batch is:  3.787688910961151e-05\n",
      "The classification loss after processing this batch is:  23006.19140625\n",
      "The representation loss after processing this batch is:  3.0049588531255722e-05\n",
      "The classification loss after processing this batch is:  23868.564453125\n",
      "The representation loss after processing this batch is:  3.1237490475177765e-05\n",
      "The classification loss after processing this batch is:  23854.2109375\n",
      "The representation loss after processing this batch is:  3.8300175219774246e-05\n",
      "The classification loss after processing this batch is:  23459.958984375\n",
      "The representation loss after processing this batch is:  3.3084768801927567e-05\n",
      "The classification loss after processing this batch is:  23998.857421875\n",
      "The representation loss after processing this batch is:  3.890460357069969e-05\n",
      "The classification loss after processing this batch is:  24593.98046875\n",
      "The representation loss after processing this batch is:  3.836723044514656e-05\n",
      "The classification loss after processing this batch is:  23315.19921875\n",
      "The representation loss after processing this batch is:  3.815907984972e-05\n",
      "The classification loss after processing this batch is:  24346.169921875\n",
      "The representation loss after processing this batch is:  2.9793474823236465e-05\n",
      "The classification loss after processing this batch is:  24848.2578125\n",
      "The representation loss after processing this batch is:  2.985401079058647e-05\n",
      "The classification loss after processing this batch is:  23468.46484375\n",
      "The representation loss after processing this batch is:  3.4510623663663864e-05\n",
      "The classification loss after processing this batch is:  24524.791015625\n",
      "The representation loss after processing this batch is:  3.140326589345932e-05\n",
      "The classification loss after processing this batch is:  24083.244140625\n",
      "The representation loss after processing this batch is:  3.112340345978737e-05\n",
      "The classification loss after processing this batch is:  22881.517578125\n",
      "The representation loss after processing this batch is:  3.435090184211731e-05\n",
      "The classification loss after processing this batch is:  23250.318359375\n",
      "The representation loss after processing this batch is:  3.2901763916015625e-05\n",
      "The classification loss after processing this batch is:  23239.958984375\n",
      "The representation loss after processing this batch is:  3.5499222576618195e-05\n",
      "The classification loss after processing this batch is:  23246.798828125\n",
      "The representation loss after processing this batch is:  3.777630627155304e-05\n",
      "The classification loss after processing this batch is:  24790.79296875\n",
      "The representation loss after processing this batch is:  3.308989107608795e-05\n",
      "The classification loss after processing this batch is:  24617.7734375\n",
      "The representation loss after processing this batch is:  3.096461296081543e-05\n",
      "The classification loss after processing this batch is:  25245.259765625\n",
      "The representation loss after processing this batch is:  3.315787762403488e-05\n",
      "The classification loss after processing this batch is:  22340.16015625\n",
      "The representation loss after processing this batch is:  3.488268703222275e-05\n",
      "The classification loss after processing this batch is:  22800.095703125\n",
      "The representation loss after processing this batch is:  3.472156822681427e-05\n",
      "The classification loss after processing this batch is:  23112.21484375\n",
      "The representation loss after processing this batch is:  3.352854400873184e-05\n",
      "The classification loss after processing this batch is:  22983.32421875\n",
      "The representation loss after processing this batch is:  2.9966700822114944e-05\n",
      "The classification loss after processing this batch is:  24409.703125\n",
      "The representation loss after processing this batch is:  3.197649493813515e-05\n",
      "The classification loss after processing this batch is:  23388.611328125\n",
      "The representation loss after processing this batch is:  3.121607005596161e-05\n",
      "The classification loss after processing this batch is:  23972.990234375\n",
      "The representation loss after processing this batch is:  3.0466821044683456e-05\n",
      "The classification loss after processing this batch is:  23820.82421875\n",
      "The representation loss after processing this batch is:  3.26232984662056e-05\n",
      "The classification loss after processing this batch is:  23031.96484375\n",
      "The representation loss after processing this batch is:  3.277091309428215e-05\n",
      "The classification loss after processing this batch is:  24866.21875\n",
      "The representation loss after processing this batch is:  3.9443373680114746e-05\n",
      "The classification loss after processing this batch is:  25099.068359375\n",
      "The representation loss after processing this batch is:  3.38507816195488e-05\n",
      "The classification loss after processing this batch is:  24391.283203125\n",
      "The representation loss after processing this batch is:  3.147125244140625e-05\n",
      "The classification loss after processing this batch is:  22562.775390625\n",
      "The representation loss after processing this batch is:  3.484915941953659e-05\n",
      "The classification loss after processing this batch is:  24885.76171875\n",
      "The representation loss after processing this batch is:  3.285519778728485e-05\n",
      "The classification loss after processing this batch is:  24646.3671875\n",
      "The representation loss after processing this batch is:  3.156345337629318e-05\n",
      "The classification loss after processing this batch is:  23157.091796875\n",
      "The representation loss after processing this batch is:  3.077462315559387e-05\n",
      "The classification loss after processing this batch is:  25155.08984375\n",
      "The representation loss after processing this batch is:  3.306381404399872e-05\n",
      "The classification loss after processing this batch is:  25079.0546875\n",
      "The representation loss after processing this batch is:  3.441004082560539e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22651.046875\n",
      "The representation loss after processing this batch is:  3.101164475083351e-05\n",
      "The classification loss after processing this batch is:  23152.6875\n",
      "The representation loss after processing this batch is:  3.244355320930481e-05\n",
      "The classification loss after processing this batch is:  24040.61328125\n",
      "The representation loss after processing this batch is:  3.3350661396980286e-05\n",
      "The classification loss after processing this batch is:  23509.158203125\n",
      "The representation loss after processing this batch is:  3.2329000532627106e-05\n",
      "The classification loss after processing this batch is:  24280.3046875\n",
      "The representation loss after processing this batch is:  3.7099700421094894e-05\n",
      "The classification loss after processing this batch is:  24921.28125\n",
      "The representation loss after processing this batch is:  3.62093560397625e-05\n",
      "The classification loss after processing this batch is:  22820.90625\n",
      "The representation loss after processing this batch is:  3.3522024750709534e-05\n",
      "The classification loss after processing this batch is:  22306.86328125\n",
      "The representation loss after processing this batch is:  3.519095480442047e-05\n",
      "The classification loss after processing this batch is:  23861.2265625\n",
      "The representation loss after processing this batch is:  3.090454265475273e-05\n",
      "The classification loss after processing this batch is:  24783.822265625\n",
      "The representation loss after processing this batch is:  3.1649135053157806e-05\n",
      "The classification loss after processing this batch is:  23487.630859375\n",
      "The representation loss after processing this batch is:  3.174319863319397e-05\n",
      "The classification loss after processing this batch is:  24127.912109375\n",
      "The representation loss after processing this batch is:  4.0294136852025986e-05\n",
      "The classification loss after processing this batch is:  23864.05859375\n",
      "The representation loss after processing this batch is:  3.035040572285652e-05\n",
      "The classification loss after processing this batch is:  23810.66015625\n",
      "The representation loss after processing this batch is:  3.2885000109672546e-05\n",
      "The classification loss after processing this batch is:  23072.341796875\n",
      "The representation loss after processing this batch is:  3.1301286071538925e-05\n",
      "The classification loss after processing this batch is:  23314.0078125\n",
      "The representation loss after processing this batch is:  3.7449877709150314e-05\n",
      "The classification loss after processing this batch is:  24794.541015625\n",
      "The representation loss after processing this batch is:  3.56622040271759e-05\n",
      "The classification loss after processing this batch is:  22421.205078125\n",
      "The representation loss after processing this batch is:  3.2568350434303284e-05\n",
      "The classification loss after processing this batch is:  22532.791015625\n",
      "The representation loss after processing this batch is:  3.132550045847893e-05\n",
      "The classification loss after processing this batch is:  22393.390625\n",
      "The representation loss after processing this batch is:  3.0111055821180344e-05\n",
      "The classification loss after processing this batch is:  22601.2421875\n",
      "The representation loss after processing this batch is:  3.1774863600730896e-05\n",
      "The classification loss after processing this batch is:  22997.6484375\n",
      "The representation loss after processing this batch is:  3.163795918226242e-05\n",
      "The classification loss after processing this batch is:  24101.447265625\n",
      "The representation loss after processing this batch is:  3.08486633002758e-05\n",
      "The classification loss after processing this batch is:  24008.1171875\n",
      "The representation loss after processing this batch is:  3.098463639616966e-05\n",
      "The classification loss after processing this batch is:  22805.14453125\n",
      "The representation loss after processing this batch is:  3.2139942049980164e-05\n",
      "The classification loss after processing this batch is:  22486.994140625\n",
      "The representation loss after processing this batch is:  2.8100330382585526e-05\n",
      "The classification loss after processing this batch is:  22721.78515625\n",
      "The representation loss after processing this batch is:  3.111129626631737e-05\n",
      "The classification loss after processing this batch is:  23311.921875\n",
      "The representation loss after processing this batch is:  3.368314355611801e-05\n",
      "The classification loss after processing this batch is:  23554.455078125\n",
      "The representation loss after processing this batch is:  3.335950896143913e-05\n",
      "The classification loss after processing this batch is:  22587.873046875\n",
      "The representation loss after processing this batch is:  3.475230187177658e-05\n",
      "The classification loss after processing this batch is:  24940.671875\n",
      "The representation loss after processing this batch is:  3.114528954029083e-05\n",
      "The classification loss after processing this batch is:  23012.6015625\n",
      "The representation loss after processing this batch is:  3.1727366149425507e-05\n",
      "The classification loss after processing this batch is:  22510.294921875\n",
      "The representation loss after processing this batch is:  3.216182813048363e-05\n",
      "The classification loss after processing this batch is:  23178.578125\n",
      "The representation loss after processing this batch is:  3.257486969232559e-05\n",
      "The classification loss after processing this batch is:  24122.390625\n",
      "The representation loss after processing this batch is:  3.046635538339615e-05\n",
      "The classification loss after processing this batch is:  23664.41796875\n",
      "The representation loss after processing this batch is:  2.905493602156639e-05\n",
      "The classification loss after processing this batch is:  22652.03515625\n",
      "The representation loss after processing this batch is:  3.202585503458977e-05\n",
      "The classification loss after processing this batch is:  23466.89453125\n",
      "The representation loss after processing this batch is:  3.1299889087677e-05\n",
      "The classification loss after processing this batch is:  24850.2578125\n",
      "The representation loss after processing this batch is:  3.079976886510849e-05\n",
      "The classification loss after processing this batch is:  22088.26953125\n",
      "The representation loss after processing this batch is:  3.24971042573452e-05\n",
      "The classification loss after processing this batch is:  22703.34375\n",
      "The representation loss after processing this batch is:  3.126077353954315e-05\n",
      "The classification loss after processing this batch is:  21601.98046875\n",
      "The representation loss after processing this batch is:  3.3538322895765305e-05\n",
      "The classification loss after processing this batch is:  23114.09375\n",
      "The representation loss after processing this batch is:  2.8652604669332504e-05\n",
      "The classification loss after processing this batch is:  23406.33984375\n",
      "The representation loss after processing this batch is:  3.0172988772392273e-05\n",
      "The classification loss after processing this batch is:  22756.388671875\n",
      "The representation loss after processing this batch is:  3.2125506550073624e-05\n",
      "The classification loss after processing this batch is:  22672.328125\n",
      "The representation loss after processing this batch is:  3.4642405807971954e-05\n",
      "The classification loss after processing this batch is:  22140.015625\n",
      "The representation loss after processing this batch is:  3.143027424812317e-05\n",
      "The classification loss after processing this batch is:  22993.484375\n",
      "The representation loss after processing this batch is:  2.9886607080698013e-05\n",
      "The classification loss after processing this batch is:  22886.927734375\n",
      "The representation loss after processing this batch is:  3.292132169008255e-05\n",
      "The classification loss after processing this batch is:  22141.828125\n",
      "The representation loss after processing this batch is:  3.136461600661278e-05\n",
      "The classification loss after processing this batch is:  26116.171875\n",
      "The representation loss after processing this batch is:  3.625825047492981e-05\n",
      "The classification loss after processing this batch is:  24766.71875\n",
      "The representation loss after processing this batch is:  3.316439688205719e-05\n",
      "The classification loss after processing this batch is:  23921.896484375\n",
      "The representation loss after processing this batch is:  3.332644701004028e-05\n",
      "The classification loss after processing this batch is:  23168.46875\n",
      "The representation loss after processing this batch is:  3.2877083867788315e-05\n",
      "The classification loss after processing this batch is:  22332.8828125\n",
      "The representation loss after processing this batch is:  3.550015389919281e-05\n",
      "The classification loss after processing this batch is:  22981.12890625\n",
      "The representation loss after processing this batch is:  3.181304782629013e-05\n",
      "The classification loss after processing this batch is:  23910.484375\n",
      "The representation loss after processing this batch is:  3.364449366927147e-05\n",
      "The classification loss after processing this batch is:  23120.775390625\n",
      "The representation loss after processing this batch is:  2.987682819366455e-05\n",
      "The classification loss after processing this batch is:  25241.955078125\n",
      "The representation loss after processing this batch is:  3.199838101863861e-05\n",
      "The classification loss after processing this batch is:  23387.974609375\n",
      "The representation loss after processing this batch is:  3.170548006892204e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22533.564453125\n",
      "The representation loss after processing this batch is:  3.2574404031038284e-05\n",
      "The classification loss after processing this batch is:  24168.755859375\n",
      "The representation loss after processing this batch is:  3.333901986479759e-05\n",
      "The classification loss after processing this batch is:  22656.89453125\n",
      "The representation loss after processing this batch is:  3.151828423142433e-05\n",
      "The classification loss after processing this batch is:  22944.138671875\n",
      "The representation loss after processing this batch is:  3.442727029323578e-05\n",
      "The classification loss after processing this batch is:  26822.525390625\n",
      "The representation loss after processing this batch is:  3.515183925628662e-05\n",
      "The classification loss after processing this batch is:  24361.09375\n",
      "The representation loss after processing this batch is:  3.4253112971782684e-05\n",
      "The classification loss after processing this batch is:  22492.1953125\n",
      "The representation loss after processing this batch is:  3.7000514566898346e-05\n",
      "The classification loss after processing this batch is:  22693.1875\n",
      "The representation loss after processing this batch is:  4.512723535299301e-05\n",
      "The classification loss after processing this batch is:  25028.98828125\n",
      "The representation loss after processing this batch is:  3.520818427205086e-05\n",
      "The classification loss after processing this batch is:  22387.43359375\n",
      "The representation loss after processing this batch is:  3.708992153406143e-05\n",
      "The classification loss after processing this batch is:  22892.0546875\n",
      "The representation loss after processing this batch is:  3.937212750315666e-05\n",
      "The classification loss after processing this batch is:  23616.9453125\n",
      "The representation loss after processing this batch is:  3.969017416238785e-05\n",
      "The classification loss after processing this batch is:  27979.4921875\n",
      "The representation loss after processing this batch is:  3.757886588573456e-05\n",
      "The classification loss after processing this batch is:  30020.7578125\n",
      "The representation loss after processing this batch is:  3.267591819167137e-05\n",
      "The classification loss after processing this batch is:  22563.310546875\n",
      "The representation loss after processing this batch is:  3.4104567021131516e-05\n",
      "The classification loss after processing this batch is:  23979.953125\n",
      "The representation loss after processing this batch is:  3.3643562346696854e-05\n",
      "The classification loss after processing this batch is:  23819.615234375\n",
      "The representation loss after processing this batch is:  3.678072243928909e-05\n",
      "The classification loss after processing this batch is:  21555.0625\n",
      "The representation loss after processing this batch is:  4.13721427321434e-05\n",
      "the loss after processing this epoch is:  0.21922490000724792\n",
      "the loss after processing this epoch is:  0.1779240369796753\n",
      "the loss after processing this epoch is:  0.10089780390262604\n",
      "the loss after processing this epoch is:  0.06340743601322174\n",
      "the loss after processing this epoch is:  0.006732568144798279\n",
      "the loss after processing this epoch is:  0.0010184546699747443\n",
      "the loss after processing this epoch is:  0.0007883509388193488\n",
      "the loss after processing this epoch is:  0.00034862756729125977\n",
      "the loss after processing this epoch is:  0.00015738606452941895\n",
      "the loss after processing this epoch is:  9.646017861086875e-05\n",
      "The classification loss after processing this batch is:  24017.982421875\n",
      "The representation loss after processing this batch is:  0.0016984869726002216\n",
      "The classification loss after processing this batch is:  23062.158203125\n",
      "The representation loss after processing this batch is:  0.001102412585169077\n",
      "The classification loss after processing this batch is:  21880.8046875\n",
      "The representation loss after processing this batch is:  0.0007359161972999573\n",
      "The classification loss after processing this batch is:  23109.689453125\n",
      "The representation loss after processing this batch is:  0.000508422963321209\n",
      "The classification loss after processing this batch is:  24307.04296875\n",
      "The representation loss after processing this batch is:  0.0004549347795546055\n",
      "The classification loss after processing this batch is:  24359.1875\n",
      "The representation loss after processing this batch is:  0.0004078904166817665\n",
      "The classification loss after processing this batch is:  23898.10546875\n",
      "The representation loss after processing this batch is:  0.0003942684270441532\n",
      "The classification loss after processing this batch is:  24155.0234375\n",
      "The representation loss after processing this batch is:  0.00032845884561538696\n",
      "The classification loss after processing this batch is:  24516.58984375\n",
      "The representation loss after processing this batch is:  0.0003307955339550972\n",
      "The classification loss after processing this batch is:  25816.193359375\n",
      "The representation loss after processing this batch is:  0.00039048120379447937\n",
      "The classification loss after processing this batch is:  25006.681640625\n",
      "The representation loss after processing this batch is:  0.0002869758754968643\n",
      "The classification loss after processing this batch is:  25387.9765625\n",
      "The representation loss after processing this batch is:  0.00026841647922992706\n",
      "The classification loss after processing this batch is:  25633.27734375\n",
      "The representation loss after processing this batch is:  0.00021495763212442398\n",
      "The classification loss after processing this batch is:  25170.099609375\n",
      "The representation loss after processing this batch is:  0.00024035107344388962\n",
      "The classification loss after processing this batch is:  25203.119140625\n",
      "The representation loss after processing this batch is:  0.00025553349405527115\n",
      "The classification loss after processing this batch is:  25816.759765625\n",
      "The representation loss after processing this batch is:  0.00022141635417938232\n",
      "The classification loss after processing this batch is:  25653.734375\n",
      "The representation loss after processing this batch is:  0.00019224081188440323\n",
      "The classification loss after processing this batch is:  27195.255859375\n",
      "The representation loss after processing this batch is:  0.0002719154581427574\n",
      "The classification loss after processing this batch is:  26067.388671875\n",
      "The representation loss after processing this batch is:  0.00018813367933034897\n",
      "The classification loss after processing this batch is:  26764.359375\n",
      "The representation loss after processing this batch is:  0.00019043590873479843\n",
      "The classification loss after processing this batch is:  26573.6796875\n",
      "The representation loss after processing this batch is:  0.0001877928152680397\n",
      "The classification loss after processing this batch is:  26904.359375\n",
      "The representation loss after processing this batch is:  0.00016561150550842285\n",
      "The classification loss after processing this batch is:  26987.298828125\n",
      "The representation loss after processing this batch is:  0.00016433652490377426\n",
      "The classification loss after processing this batch is:  26404.9765625\n",
      "The representation loss after processing this batch is:  0.00019646808505058289\n",
      "The classification loss after processing this batch is:  26222.65234375\n",
      "The representation loss after processing this batch is:  0.00019202101975679398\n",
      "The classification loss after processing this batch is:  25621.181640625\n",
      "The representation loss after processing this batch is:  0.0001849345862865448\n",
      "The classification loss after processing this batch is:  26014.83984375\n",
      "The representation loss after processing this batch is:  0.0001828521490097046\n",
      "The classification loss after processing this batch is:  25958.62890625\n",
      "The representation loss after processing this batch is:  0.00015119463205337524\n",
      "The classification loss after processing this batch is:  29243.2265625\n",
      "The representation loss after processing this batch is:  0.00016964413225650787\n",
      "The classification loss after processing this batch is:  27728.1171875\n",
      "The representation loss after processing this batch is:  0.00014940649271011353\n",
      "The classification loss after processing this batch is:  26025.54296875\n",
      "The representation loss after processing this batch is:  0.00018534623086452484\n",
      "The classification loss after processing this batch is:  26503.294921875\n",
      "The representation loss after processing this batch is:  0.00015847943723201752\n",
      "The classification loss after processing this batch is:  25576.5703125\n",
      "The representation loss after processing this batch is:  0.00016660802066326141\n",
      "The classification loss after processing this batch is:  26536.05859375\n",
      "The representation loss after processing this batch is:  0.0001593269407749176\n",
      "The classification loss after processing this batch is:  26689.875\n",
      "The representation loss after processing this batch is:  0.00015393272042274475\n",
      "The classification loss after processing this batch is:  26903.5625\n",
      "The representation loss after processing this batch is:  0.00016554631292819977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  28155.57421875\n",
      "The representation loss after processing this batch is:  0.0001695975661277771\n",
      "The classification loss after processing this batch is:  31335.3515625\n",
      "The representation loss after processing this batch is:  0.0002130270004272461\n",
      "The classification loss after processing this batch is:  26420.67578125\n",
      "The representation loss after processing this batch is:  0.00014791637659072876\n",
      "The classification loss after processing this batch is:  27350.5703125\n",
      "The representation loss after processing this batch is:  0.0001437067985534668\n",
      "The classification loss after processing this batch is:  27697.1640625\n",
      "The representation loss after processing this batch is:  0.00014888495206832886\n",
      "The classification loss after processing this batch is:  27630.166015625\n",
      "The representation loss after processing this batch is:  0.00017384253442287445\n",
      "The classification loss after processing this batch is:  26680.791015625\n",
      "The representation loss after processing this batch is:  0.0001670457422733307\n",
      "The classification loss after processing this batch is:  26892.64453125\n",
      "The representation loss after processing this batch is:  0.00017236173152923584\n",
      "The classification loss after processing this batch is:  26520.814453125\n",
      "The representation loss after processing this batch is:  0.00016801990568637848\n",
      "The classification loss after processing this batch is:  25856.390625\n",
      "The representation loss after processing this batch is:  0.00015677884221076965\n",
      "The classification loss after processing this batch is:  25868.57421875\n",
      "The representation loss after processing this batch is:  0.00014124996960163116\n",
      "The classification loss after processing this batch is:  26664.509765625\n",
      "The representation loss after processing this batch is:  0.00016732141375541687\n",
      "The classification loss after processing this batch is:  26412.615234375\n",
      "The representation loss after processing this batch is:  0.00016026943922042847\n",
      "The classification loss after processing this batch is:  26140.28125\n",
      "The representation loss after processing this batch is:  0.00016516074538230896\n",
      "The classification loss after processing this batch is:  25939.20703125\n",
      "The representation loss after processing this batch is:  0.00013913214206695557\n",
      "The classification loss after processing this batch is:  24731.54296875\n",
      "The representation loss after processing this batch is:  0.00016113929450511932\n",
      "The classification loss after processing this batch is:  25026.5\n",
      "The representation loss after processing this batch is:  0.00015478208661079407\n",
      "The classification loss after processing this batch is:  25201.7890625\n",
      "The representation loss after processing this batch is:  0.00014627259224653244\n",
      "The classification loss after processing this batch is:  25522.9765625\n",
      "The representation loss after processing this batch is:  0.0001285076141357422\n",
      "The classification loss after processing this batch is:  24797.857421875\n",
      "The representation loss after processing this batch is:  0.00016650184988975525\n",
      "The classification loss after processing this batch is:  26661.404296875\n",
      "The representation loss after processing this batch is:  0.00015834905207157135\n",
      "The classification loss after processing this batch is:  25113.49609375\n",
      "The representation loss after processing this batch is:  0.00016602780669927597\n",
      "The classification loss after processing this batch is:  24734.40234375\n",
      "The representation loss after processing this batch is:  0.00018315017223358154\n",
      "The classification loss after processing this batch is:  25662.365234375\n",
      "The representation loss after processing this batch is:  0.00015934929251670837\n",
      "The classification loss after processing this batch is:  27333.4140625\n",
      "The representation loss after processing this batch is:  0.00014266371726989746\n",
      "The classification loss after processing this batch is:  27537.826171875\n",
      "The representation loss after processing this batch is:  0.00012449733912944794\n",
      "The classification loss after processing this batch is:  26526.8671875\n",
      "The representation loss after processing this batch is:  0.0001504514366388321\n",
      "The classification loss after processing this batch is:  24468.896484375\n",
      "The representation loss after processing this batch is:  0.00013119354844093323\n",
      "The classification loss after processing this batch is:  25949.3984375\n",
      "The representation loss after processing this batch is:  0.0001308973878622055\n",
      "The classification loss after processing this batch is:  25124.490234375\n",
      "The representation loss after processing this batch is:  0.00014752428978681564\n",
      "The classification loss after processing this batch is:  25981.7421875\n",
      "The representation loss after processing this batch is:  0.00015418045222759247\n",
      "The classification loss after processing this batch is:  26488.20703125\n",
      "The representation loss after processing this batch is:  0.00015092827379703522\n",
      "The classification loss after processing this batch is:  25461.505859375\n",
      "The representation loss after processing this batch is:  0.00012409407645463943\n",
      "The classification loss after processing this batch is:  25491.44140625\n",
      "The representation loss after processing this batch is:  0.00014354847371578217\n",
      "The classification loss after processing this batch is:  25717.74609375\n",
      "The representation loss after processing this batch is:  0.0001347772777080536\n",
      "The classification loss after processing this batch is:  25957.654296875\n",
      "The representation loss after processing this batch is:  0.000142635777592659\n",
      "The classification loss after processing this batch is:  24526.224609375\n",
      "The representation loss after processing this batch is:  0.00015002675354480743\n",
      "The classification loss after processing this batch is:  26395.86328125\n",
      "The representation loss after processing this batch is:  0.00013529695570468903\n",
      "The classification loss after processing this batch is:  26355.984375\n",
      "The representation loss after processing this batch is:  0.00012243911623954773\n",
      "The classification loss after processing this batch is:  26814.515625\n",
      "The representation loss after processing this batch is:  0.0001599583774805069\n",
      "The classification loss after processing this batch is:  25532.16796875\n",
      "The representation loss after processing this batch is:  0.00011364929378032684\n",
      "The classification loss after processing this batch is:  25363.609375\n",
      "The representation loss after processing this batch is:  0.00013671163469552994\n",
      "The classification loss after processing this batch is:  25071.43359375\n",
      "The representation loss after processing this batch is:  0.00012503750622272491\n",
      "The classification loss after processing this batch is:  25896.412109375\n",
      "The representation loss after processing this batch is:  0.00012577325105667114\n",
      "The classification loss after processing this batch is:  26259.564453125\n",
      "The representation loss after processing this batch is:  0.00012422632426023483\n",
      "The classification loss after processing this batch is:  25179.619140625\n",
      "The representation loss after processing this batch is:  0.00014280527830123901\n",
      "The classification loss after processing this batch is:  24695.564453125\n",
      "The representation loss after processing this batch is:  0.00012798607349395752\n",
      "The classification loss after processing this batch is:  25327.1015625\n",
      "The representation loss after processing this batch is:  0.00013029947876930237\n",
      "The classification loss after processing this batch is:  24222.615234375\n",
      "The representation loss after processing this batch is:  0.0001297546550631523\n",
      "The classification loss after processing this batch is:  24077.771484375\n",
      "The representation loss after processing this batch is:  0.0001384187489748001\n",
      "The classification loss after processing this batch is:  24489.015625\n",
      "The representation loss after processing this batch is:  0.00014147721230983734\n",
      "The classification loss after processing this batch is:  24063.48046875\n",
      "The representation loss after processing this batch is:  0.00014190934598445892\n",
      "The classification loss after processing this batch is:  23573.6484375\n",
      "The representation loss after processing this batch is:  0.00011029187589883804\n",
      "The classification loss after processing this batch is:  23337.88671875\n",
      "The representation loss after processing this batch is:  0.0001608077436685562\n",
      "The classification loss after processing this batch is:  23783.34765625\n",
      "The representation loss after processing this batch is:  0.0001470707356929779\n",
      "The classification loss after processing this batch is:  23610.294921875\n",
      "The representation loss after processing this batch is:  0.00013724155724048615\n",
      "The classification loss after processing this batch is:  23945.86328125\n",
      "The representation loss after processing this batch is:  0.00015296973288059235\n",
      "The classification loss after processing this batch is:  24245.73828125\n",
      "The representation loss after processing this batch is:  0.00013141799718141556\n",
      "The classification loss after processing this batch is:  23325.0703125\n",
      "The representation loss after processing this batch is:  0.0001492537558078766\n",
      "The classification loss after processing this batch is:  25230.490234375\n",
      "The representation loss after processing this batch is:  0.00013661477714776993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24722.494140625\n",
      "The representation loss after processing this batch is:  0.00013408251106739044\n",
      "The classification loss after processing this batch is:  25210.32421875\n",
      "The representation loss after processing this batch is:  0.00014088116586208344\n",
      "The classification loss after processing this batch is:  25373.6875\n",
      "The representation loss after processing this batch is:  0.00014766305685043335\n",
      "The classification loss after processing this batch is:  26044.8984375\n",
      "The representation loss after processing this batch is:  0.00014501623809337616\n",
      "The classification loss after processing this batch is:  25903.166015625\n",
      "The representation loss after processing this batch is:  0.00014061853289604187\n",
      "The classification loss after processing this batch is:  25032.966796875\n",
      "The representation loss after processing this batch is:  0.00015852507203817368\n",
      "The classification loss after processing this batch is:  24913.384765625\n",
      "The representation loss after processing this batch is:  0.00012472085654735565\n",
      "The classification loss after processing this batch is:  25120.265625\n",
      "The representation loss after processing this batch is:  0.00014211423695087433\n",
      "The classification loss after processing this batch is:  24393.95703125\n",
      "The representation loss after processing this batch is:  0.00012738071382045746\n",
      "The classification loss after processing this batch is:  24100.99609375\n",
      "The representation loss after processing this batch is:  0.00011982955038547516\n",
      "The classification loss after processing this batch is:  24674.666015625\n",
      "The representation loss after processing this batch is:  0.00013019144535064697\n",
      "The classification loss after processing this batch is:  24183.95703125\n",
      "The representation loss after processing this batch is:  0.00015016738325357437\n",
      "The classification loss after processing this batch is:  24491.63671875\n",
      "The representation loss after processing this batch is:  0.0001331418752670288\n",
      "The classification loss after processing this batch is:  25679.19921875\n",
      "The representation loss after processing this batch is:  0.00012727826833724976\n",
      "The classification loss after processing this batch is:  29146.685546875\n",
      "The representation loss after processing this batch is:  0.00014810077846050262\n",
      "The classification loss after processing this batch is:  25695.08203125\n",
      "The representation loss after processing this batch is:  0.0001383163034915924\n",
      "The classification loss after processing this batch is:  24331.603515625\n",
      "The representation loss after processing this batch is:  0.0001230929046869278\n",
      "The classification loss after processing this batch is:  24461.220703125\n",
      "The representation loss after processing this batch is:  0.00014993548393249512\n",
      "The classification loss after processing this batch is:  27328.58203125\n",
      "The representation loss after processing this batch is:  0.00013934634625911713\n",
      "The classification loss after processing this batch is:  27614.49609375\n",
      "The representation loss after processing this batch is:  0.0001535452902317047\n",
      "The classification loss after processing this batch is:  24161.97265625\n",
      "The representation loss after processing this batch is:  0.00014580786228179932\n",
      "The classification loss after processing this batch is:  24183.5390625\n",
      "The representation loss after processing this batch is:  0.00012268312275409698\n",
      "The classification loss after processing this batch is:  24705.046875\n",
      "The representation loss after processing this batch is:  0.0001253914088010788\n",
      "The classification loss after processing this batch is:  25414.962890625\n",
      "The representation loss after processing this batch is:  0.00012196041643619537\n",
      "The classification loss after processing this batch is:  25133.046875\n",
      "The representation loss after processing this batch is:  0.0001336410641670227\n",
      "The classification loss after processing this batch is:  24389.59375\n",
      "The representation loss after processing this batch is:  0.0001321118324995041\n",
      "The classification loss after processing this batch is:  25353.76953125\n",
      "The representation loss after processing this batch is:  0.0001171305775642395\n",
      "The classification loss after processing this batch is:  25969.05078125\n",
      "The representation loss after processing this batch is:  0.00013118237257003784\n",
      "The classification loss after processing this batch is:  24018.390625\n",
      "The representation loss after processing this batch is:  0.00014684908092021942\n",
      "The classification loss after processing this batch is:  24922.2109375\n",
      "The representation loss after processing this batch is:  0.00012128148227930069\n",
      "The classification loss after processing this batch is:  23965.109375\n",
      "The representation loss after processing this batch is:  0.00012831669300794601\n",
      "The classification loss after processing this batch is:  24652.9453125\n",
      "The representation loss after processing this batch is:  0.00012069381773471832\n",
      "The classification loss after processing this batch is:  23414.212890625\n",
      "The representation loss after processing this batch is:  0.00012265145778656006\n",
      "The classification loss after processing this batch is:  25041.638671875\n",
      "The representation loss after processing this batch is:  0.00016305409371852875\n",
      "The classification loss after processing this batch is:  24668.5546875\n",
      "The representation loss after processing this batch is:  0.00012150034308433533\n",
      "The classification loss after processing this batch is:  26506.93359375\n",
      "The representation loss after processing this batch is:  0.00013673119246959686\n",
      "The classification loss after processing this batch is:  24153.75\n",
      "The representation loss after processing this batch is:  0.00013835355639457703\n",
      "The classification loss after processing this batch is:  24171.5390625\n",
      "The representation loss after processing this batch is:  0.00013257842510938644\n",
      "The classification loss after processing this batch is:  25705.75390625\n",
      "The representation loss after processing this batch is:  0.00013862736523151398\n",
      "The classification loss after processing this batch is:  25235.810546875\n",
      "The representation loss after processing this batch is:  0.00011574383825063705\n",
      "The classification loss after processing this batch is:  24718.609375\n",
      "The representation loss after processing this batch is:  0.0001345919445157051\n",
      "The classification loss after processing this batch is:  26087.26171875\n",
      "The representation loss after processing this batch is:  0.00013746600598096848\n",
      "The classification loss after processing this batch is:  24231.92578125\n",
      "The representation loss after processing this batch is:  0.00013244524598121643\n",
      "The classification loss after processing this batch is:  25011.310546875\n",
      "The representation loss after processing this batch is:  0.00014100875705480576\n",
      "The classification loss after processing this batch is:  23903.31640625\n",
      "The representation loss after processing this batch is:  0.00011464860290288925\n",
      "The classification loss after processing this batch is:  23765.349609375\n",
      "The representation loss after processing this batch is:  0.00011342484503984451\n",
      "The classification loss after processing this batch is:  23753.5390625\n",
      "The representation loss after processing this batch is:  0.00013066083192825317\n",
      "The classification loss after processing this batch is:  23597.767578125\n",
      "The representation loss after processing this batch is:  0.00013779103755950928\n",
      "The classification loss after processing this batch is:  23538.693359375\n",
      "The representation loss after processing this batch is:  0.00012890156358480453\n",
      "The classification loss after processing this batch is:  26300.2265625\n",
      "The representation loss after processing this batch is:  0.00013043731451034546\n",
      "The classification loss after processing this batch is:  24055.759765625\n",
      "The representation loss after processing this batch is:  0.00012665987014770508\n",
      "The classification loss after processing this batch is:  24541.787109375\n",
      "The representation loss after processing this batch is:  0.00011233054101467133\n",
      "The classification loss after processing this batch is:  25282.421875\n",
      "The representation loss after processing this batch is:  0.0001446213573217392\n",
      "The classification loss after processing this batch is:  24568.4140625\n",
      "The representation loss after processing this batch is:  0.00011364370584487915\n",
      "The classification loss after processing this batch is:  24759.380859375\n",
      "The representation loss after processing this batch is:  0.00012731272727251053\n",
      "The classification loss after processing this batch is:  24612.75\n",
      "The representation loss after processing this batch is:  0.00010838266462087631\n",
      "The classification loss after processing this batch is:  24266.07421875\n",
      "The representation loss after processing this batch is:  0.00013413745909929276\n",
      "The classification loss after processing this batch is:  23144.65625\n",
      "The representation loss after processing this batch is:  0.00011390727013349533\n",
      "The classification loss after processing this batch is:  24550.8046875\n",
      "The representation loss after processing this batch is:  0.00013955775648355484\n",
      "The classification loss after processing this batch is:  27212.169921875\n",
      "The representation loss after processing this batch is:  0.00013269949704408646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  27858.28125\n",
      "The representation loss after processing this batch is:  0.0001243259757757187\n",
      "The classification loss after processing this batch is:  24465.28515625\n",
      "The representation loss after processing this batch is:  0.00012792367488145828\n",
      "The classification loss after processing this batch is:  24260.68359375\n",
      "The representation loss after processing this batch is:  0.00011482276022434235\n",
      "The classification loss after processing this batch is:  24209.888671875\n",
      "The representation loss after processing this batch is:  0.00012224167585372925\n",
      "The classification loss after processing this batch is:  24923.140625\n",
      "The representation loss after processing this batch is:  0.00013362988829612732\n",
      "The classification loss after processing this batch is:  23815.46875\n",
      "The representation loss after processing this batch is:  0.0001285150647163391\n",
      "The classification loss after processing this batch is:  24013.40625\n",
      "The representation loss after processing this batch is:  0.00011761859059333801\n",
      "The classification loss after processing this batch is:  25627.30078125\n",
      "The representation loss after processing this batch is:  0.00011657550930976868\n",
      "The classification loss after processing this batch is:  22818.23046875\n",
      "The representation loss after processing this batch is:  0.00012697838246822357\n",
      "The classification loss after processing this batch is:  23574.123046875\n",
      "The representation loss after processing this batch is:  0.00011020712554454803\n",
      "The classification loss after processing this batch is:  26355.4765625\n",
      "The representation loss after processing this batch is:  0.00014351122081279755\n",
      "The classification loss after processing this batch is:  24837.01953125\n",
      "The representation loss after processing this batch is:  0.00014494732022285461\n",
      "The classification loss after processing this batch is:  23871.744140625\n",
      "The representation loss after processing this batch is:  0.00013824179768562317\n",
      "The classification loss after processing this batch is:  22660.7734375\n",
      "The representation loss after processing this batch is:  0.00013288948684930801\n",
      "The classification loss after processing this batch is:  25380.69921875\n",
      "The representation loss after processing this batch is:  0.00013181380927562714\n",
      "The classification loss after processing this batch is:  25001.4765625\n",
      "The representation loss after processing this batch is:  0.00013804249465465546\n",
      "The classification loss after processing this batch is:  29500.943359375\n",
      "The representation loss after processing this batch is:  0.00012775417417287827\n",
      "The classification loss after processing this batch is:  25590.955078125\n",
      "The representation loss after processing this batch is:  0.00010981690138578415\n",
      "The classification loss after processing this batch is:  24274.44140625\n",
      "The representation loss after processing this batch is:  0.00012901797890663147\n",
      "The classification loss after processing this batch is:  26213.84765625\n",
      "The representation loss after processing this batch is:  0.00011902675032615662\n",
      "The classification loss after processing this batch is:  27155.2890625\n",
      "The representation loss after processing this batch is:  0.00013514887541532516\n",
      "The classification loss after processing this batch is:  25674.43359375\n",
      "The representation loss after processing this batch is:  0.00011666957288980484\n",
      "The classification loss after processing this batch is:  25322.908203125\n",
      "The representation loss after processing this batch is:  0.0001232316717505455\n",
      "The classification loss after processing this batch is:  24945.412109375\n",
      "The representation loss after processing this batch is:  0.0001092962920665741\n",
      "The classification loss after processing this batch is:  24758.4296875\n",
      "The representation loss after processing this batch is:  0.00011243484914302826\n",
      "The classification loss after processing this batch is:  23427.07421875\n",
      "The representation loss after processing this batch is:  0.0001253494992852211\n",
      "The classification loss after processing this batch is:  24454.283203125\n",
      "The representation loss after processing this batch is:  0.0001318594440817833\n",
      "The classification loss after processing this batch is:  24265.3359375\n",
      "The representation loss after processing this batch is:  0.00012004375457763672\n",
      "The classification loss after processing this batch is:  24724.646484375\n",
      "The representation loss after processing this batch is:  0.0001424010843038559\n",
      "The classification loss after processing this batch is:  24867.244140625\n",
      "The representation loss after processing this batch is:  0.00012679211795330048\n",
      "The classification loss after processing this batch is:  25020.767578125\n",
      "The representation loss after processing this batch is:  0.00013421755284070969\n",
      "The classification loss after processing this batch is:  23312.318359375\n",
      "The representation loss after processing this batch is:  0.00011944025754928589\n",
      "The classification loss after processing this batch is:  22664.31640625\n",
      "The representation loss after processing this batch is:  0.00015916675329208374\n",
      "The classification loss after processing this batch is:  23537.16015625\n",
      "The representation loss after processing this batch is:  0.00012749899178743362\n",
      "The classification loss after processing this batch is:  23257.943359375\n",
      "The representation loss after processing this batch is:  0.00011293776333332062\n",
      "The classification loss after processing this batch is:  25180.6484375\n",
      "The representation loss after processing this batch is:  0.00012686941772699356\n",
      "The classification loss after processing this batch is:  24418.48828125\n",
      "The representation loss after processing this batch is:  0.000116666778922081\n",
      "The classification loss after processing this batch is:  23558.125\n",
      "The representation loss after processing this batch is:  0.00014037638902664185\n",
      "The classification loss after processing this batch is:  22739.33203125\n",
      "The representation loss after processing this batch is:  0.0001309029757976532\n",
      "The classification loss after processing this batch is:  22846.009765625\n",
      "The representation loss after processing this batch is:  0.00013056956231594086\n",
      "The classification loss after processing this batch is:  24250.33984375\n",
      "The representation loss after processing this batch is:  0.0001199282705783844\n",
      "The classification loss after processing this batch is:  25440.2890625\n",
      "The representation loss after processing this batch is:  0.0001111738383769989\n",
      "The classification loss after processing this batch is:  25531.349609375\n",
      "The representation loss after processing this batch is:  0.00015059486031532288\n",
      "The classification loss after processing this batch is:  23478.6328125\n",
      "The representation loss after processing this batch is:  0.00012826919555664062\n",
      "The classification loss after processing this batch is:  24455.5\n",
      "The representation loss after processing this batch is:  0.00012820027768611908\n",
      "The classification loss after processing this batch is:  23609.681640625\n",
      "The representation loss after processing this batch is:  0.00013376586139202118\n",
      "The classification loss after processing this batch is:  23891.87109375\n",
      "The representation loss after processing this batch is:  0.0001375097781419754\n",
      "The classification loss after processing this batch is:  23266.7109375\n",
      "The representation loss after processing this batch is:  0.00012679025530815125\n",
      "The classification loss after processing this batch is:  23138.91796875\n",
      "The representation loss after processing this batch is:  0.00014003831893205643\n",
      "The classification loss after processing this batch is:  23417.392578125\n",
      "The representation loss after processing this batch is:  0.00012131687253713608\n",
      "The classification loss after processing this batch is:  24022.994140625\n",
      "The representation loss after processing this batch is:  0.00012230873107910156\n",
      "The classification loss after processing this batch is:  24351.46875\n",
      "The representation loss after processing this batch is:  0.00012789294123649597\n",
      "The classification loss after processing this batch is:  24342.32421875\n",
      "The representation loss after processing this batch is:  0.00012819375842809677\n",
      "The classification loss after processing this batch is:  23708.724609375\n",
      "The representation loss after processing this batch is:  0.00014428235590457916\n",
      "The classification loss after processing this batch is:  23847.4765625\n",
      "The representation loss after processing this batch is:  0.00011830031871795654\n",
      "The classification loss after processing this batch is:  25335.55859375\n",
      "The representation loss after processing this batch is:  0.0001232791692018509\n",
      "The classification loss after processing this batch is:  26292.1328125\n",
      "The representation loss after processing this batch is:  0.00013597309589385986\n",
      "The classification loss after processing this batch is:  25105.701171875\n",
      "The representation loss after processing this batch is:  0.00012774020433425903\n",
      "The classification loss after processing this batch is:  25273.75390625\n",
      "The representation loss after processing this batch is:  0.00015469547361135483\n",
      "The classification loss after processing this batch is:  23871.611328125\n",
      "The representation loss after processing this batch is:  0.00011071190237998962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24400.6953125\n",
      "The representation loss after processing this batch is:  0.00011568516492843628\n",
      "The classification loss after processing this batch is:  25449.455078125\n",
      "The representation loss after processing this batch is:  0.00012161210179328918\n",
      "The classification loss after processing this batch is:  23591.984375\n",
      "The representation loss after processing this batch is:  0.0001473464071750641\n",
      "The classification loss after processing this batch is:  23619.22265625\n",
      "The representation loss after processing this batch is:  0.00012036878615617752\n",
      "The classification loss after processing this batch is:  24379.078125\n",
      "The representation loss after processing this batch is:  0.0001234300434589386\n",
      "The classification loss after processing this batch is:  24417.4140625\n",
      "The representation loss after processing this batch is:  0.00011962279677391052\n",
      "The classification loss after processing this batch is:  24369.03515625\n",
      "The representation loss after processing this batch is:  0.0001270771026611328\n",
      "The classification loss after processing this batch is:  23622.0625\n",
      "The representation loss after processing this batch is:  0.00011407118290662766\n",
      "The classification loss after processing this batch is:  24907.09765625\n",
      "The representation loss after processing this batch is:  0.0001385807991027832\n",
      "The classification loss after processing this batch is:  25175.09375\n",
      "The representation loss after processing this batch is:  0.0001236526295542717\n",
      "The classification loss after processing this batch is:  25835.7265625\n",
      "The representation loss after processing this batch is:  0.00011944863945245743\n",
      "The classification loss after processing this batch is:  25611.56640625\n",
      "The representation loss after processing this batch is:  0.0001227930188179016\n",
      "The classification loss after processing this batch is:  24594.96484375\n",
      "The representation loss after processing this batch is:  0.00012520235031843185\n",
      "The classification loss after processing this batch is:  23798.00390625\n",
      "The representation loss after processing this batch is:  0.00011951103806495667\n",
      "The classification loss after processing this batch is:  23891.21484375\n",
      "The representation loss after processing this batch is:  0.00014113076031208038\n",
      "The classification loss after processing this batch is:  23638.55078125\n",
      "The representation loss after processing this batch is:  0.00012525171041488647\n",
      "The classification loss after processing this batch is:  23800.56640625\n",
      "The representation loss after processing this batch is:  0.00012983009219169617\n",
      "The classification loss after processing this batch is:  23472.515625\n",
      "The representation loss after processing this batch is:  0.00012479163706302643\n",
      "The classification loss after processing this batch is:  24197.123046875\n",
      "The representation loss after processing this batch is:  0.00010988209396600723\n",
      "The classification loss after processing this batch is:  24292.818359375\n",
      "The representation loss after processing this batch is:  0.00012799911201000214\n",
      "The classification loss after processing this batch is:  27503.58203125\n",
      "The representation loss after processing this batch is:  0.00014502182602882385\n",
      "The classification loss after processing this batch is:  26541.15625\n",
      "The representation loss after processing this batch is:  0.00011009909212589264\n",
      "The classification loss after processing this batch is:  24201.775390625\n",
      "The representation loss after processing this batch is:  0.00012859050184488297\n",
      "The classification loss after processing this batch is:  22925.953125\n",
      "The representation loss after processing this batch is:  0.0001323772594332695\n",
      "The classification loss after processing this batch is:  23140.37109375\n",
      "The representation loss after processing this batch is:  0.00013482198119163513\n",
      "The classification loss after processing this batch is:  23912.10546875\n",
      "The representation loss after processing this batch is:  0.00014533847570419312\n",
      "The classification loss after processing this batch is:  23578.142578125\n",
      "The representation loss after processing this batch is:  0.00013140495866537094\n",
      "The classification loss after processing this batch is:  24165.099609375\n",
      "The representation loss after processing this batch is:  0.00012102723121643066\n",
      "The classification loss after processing this batch is:  24427.857421875\n",
      "The representation loss after processing this batch is:  0.00012058950960636139\n",
      "The classification loss after processing this batch is:  23442.03515625\n",
      "The representation loss after processing this batch is:  9.501446038484573e-05\n",
      "The classification loss after processing this batch is:  23115.65625\n",
      "The representation loss after processing this batch is:  0.00012506265193223953\n",
      "The classification loss after processing this batch is:  24409.388671875\n",
      "The representation loss after processing this batch is:  0.00011138617992401123\n",
      "The classification loss after processing this batch is:  24798.30859375\n",
      "The representation loss after processing this batch is:  0.00014084577560424805\n",
      "The classification loss after processing this batch is:  23794.390625\n",
      "The representation loss after processing this batch is:  0.0001328038051724434\n",
      "The classification loss after processing this batch is:  24735.26953125\n",
      "The representation loss after processing this batch is:  0.0001358240842819214\n",
      "The classification loss after processing this batch is:  26605.875\n",
      "The representation loss after processing this batch is:  0.00013312511146068573\n",
      "The classification loss after processing this batch is:  25128.8828125\n",
      "The representation loss after processing this batch is:  0.00011878833174705505\n",
      "The classification loss after processing this batch is:  26263.73046875\n",
      "The representation loss after processing this batch is:  0.00013524014502763748\n",
      "The classification loss after processing this batch is:  24285.1015625\n",
      "The representation loss after processing this batch is:  0.00011100806295871735\n",
      "The classification loss after processing this batch is:  25360.40625\n",
      "The representation loss after processing this batch is:  0.00014411471784114838\n",
      "The classification loss after processing this batch is:  24297.51953125\n",
      "The representation loss after processing this batch is:  0.00012056529521942139\n",
      "The classification loss after processing this batch is:  25019.958984375\n",
      "The representation loss after processing this batch is:  0.00012893322855234146\n",
      "The classification loss after processing this batch is:  24358.703125\n",
      "The representation loss after processing this batch is:  0.00011977460235357285\n",
      "The classification loss after processing this batch is:  24096.6796875\n",
      "The representation loss after processing this batch is:  0.00011960882693529129\n",
      "The classification loss after processing this batch is:  24691.732421875\n",
      "The representation loss after processing this batch is:  0.00010760314762592316\n",
      "The classification loss after processing this batch is:  23672.857421875\n",
      "The representation loss after processing this batch is:  0.00011361762881278992\n",
      "The classification loss after processing this batch is:  23992.703125\n",
      "The representation loss after processing this batch is:  0.0001241881400346756\n",
      "The classification loss after processing this batch is:  23315.5546875\n",
      "The representation loss after processing this batch is:  0.00012359023094177246\n",
      "The classification loss after processing this batch is:  23698.259765625\n",
      "The representation loss after processing this batch is:  0.00013102777302265167\n",
      "The classification loss after processing this batch is:  23265.58984375\n",
      "The representation loss after processing this batch is:  0.0001196032389998436\n",
      "The classification loss after processing this batch is:  24634.125\n",
      "The representation loss after processing this batch is:  0.00012692250311374664\n",
      "The classification loss after processing this batch is:  24116.208984375\n",
      "The representation loss after processing this batch is:  0.00013098306953907013\n",
      "The classification loss after processing this batch is:  24710.83203125\n",
      "The representation loss after processing this batch is:  0.0001330515369772911\n",
      "The classification loss after processing this batch is:  24843.4453125\n",
      "The representation loss after processing this batch is:  0.00010472536087036133\n",
      "The classification loss after processing this batch is:  23603.48046875\n",
      "The representation loss after processing this batch is:  0.00010297168046236038\n",
      "The classification loss after processing this batch is:  24591.6484375\n",
      "The representation loss after processing this batch is:  0.0001093326136469841\n",
      "The classification loss after processing this batch is:  24343.12890625\n",
      "The representation loss after processing this batch is:  0.00013748742640018463\n",
      "The classification loss after processing this batch is:  23275.830078125\n",
      "The representation loss after processing this batch is:  0.00012529827654361725\n",
      "The classification loss after processing this batch is:  24507.978515625\n",
      "The representation loss after processing this batch is:  0.00012402702122926712\n",
      "The classification loss after processing this batch is:  24142.07421875\n",
      "The representation loss after processing this batch is:  0.00012898165732622147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  23426.9921875\n",
      "The representation loss after processing this batch is:  0.00010895542800426483\n",
      "The classification loss after processing this batch is:  24222.625\n",
      "The representation loss after processing this batch is:  0.00011145696043968201\n",
      "The classification loss after processing this batch is:  23707.91796875\n",
      "The representation loss after processing this batch is:  0.00012457743287086487\n",
      "The classification loss after processing this batch is:  25321.083984375\n",
      "The representation loss after processing this batch is:  0.00014419667422771454\n",
      "The classification loss after processing this batch is:  25504.41796875\n",
      "The representation loss after processing this batch is:  0.00013573188334703445\n",
      "The classification loss after processing this batch is:  23556.96484375\n",
      "The representation loss after processing this batch is:  0.0001164805144071579\n",
      "The classification loss after processing this batch is:  27161.29296875\n",
      "The representation loss after processing this batch is:  0.000128977932035923\n",
      "The classification loss after processing this batch is:  27039.458984375\n",
      "The representation loss after processing this batch is:  0.00011353753507137299\n",
      "The classification loss after processing this batch is:  23558.326171875\n",
      "The representation loss after processing this batch is:  0.00013783294707536697\n",
      "The classification loss after processing this batch is:  24301.826171875\n",
      "The representation loss after processing this batch is:  0.00011847354471683502\n",
      "The classification loss after processing this batch is:  25290.69140625\n",
      "The representation loss after processing this batch is:  0.0001466674730181694\n",
      "The classification loss after processing this batch is:  23972.83203125\n",
      "The representation loss after processing this batch is:  0.00012087635695934296\n",
      "The classification loss after processing this batch is:  24325.4140625\n",
      "The representation loss after processing this batch is:  0.0001271301880478859\n",
      "The classification loss after processing this batch is:  24299.052734375\n",
      "The representation loss after processing this batch is:  0.0001145554706454277\n",
      "The classification loss after processing this batch is:  24529.765625\n",
      "The representation loss after processing this batch is:  0.00012828689068555832\n",
      "The classification loss after processing this batch is:  25624.9375\n",
      "The representation loss after processing this batch is:  0.00011204928159713745\n",
      "The classification loss after processing this batch is:  25230.958984375\n",
      "The representation loss after processing this batch is:  0.0001245373860001564\n",
      "The classification loss after processing this batch is:  26496.859375\n",
      "The representation loss after processing this batch is:  0.00014084577560424805\n",
      "The classification loss after processing this batch is:  25447.162109375\n",
      "The representation loss after processing this batch is:  0.00011462438851594925\n",
      "The classification loss after processing this batch is:  25811.90234375\n",
      "The representation loss after processing this batch is:  0.00011321995407342911\n",
      "The classification loss after processing this batch is:  23558.98046875\n",
      "The representation loss after processing this batch is:  0.00011304672807455063\n",
      "The classification loss after processing this batch is:  24226.1484375\n",
      "The representation loss after processing this batch is:  0.00012059696018695831\n",
      "The classification loss after processing this batch is:  25330.99609375\n",
      "The representation loss after processing this batch is:  0.00011472869664430618\n",
      "The classification loss after processing this batch is:  23993.8671875\n",
      "The representation loss after processing this batch is:  0.00010840222239494324\n",
      "The classification loss after processing this batch is:  23104.3671875\n",
      "The representation loss after processing this batch is:  0.0001270342618227005\n",
      "The classification loss after processing this batch is:  25433.703125\n",
      "The representation loss after processing this batch is:  0.0001014387235045433\n",
      "The classification loss after processing this batch is:  23561.109375\n",
      "The representation loss after processing this batch is:  0.0001236172392964363\n",
      "The classification loss after processing this batch is:  24022.822265625\n",
      "The representation loss after processing this batch is:  0.00012544728815555573\n",
      "The classification loss after processing this batch is:  23197.84375\n",
      "The representation loss after processing this batch is:  0.00011430308222770691\n",
      "The classification loss after processing this batch is:  24143.3515625\n",
      "The representation loss after processing this batch is:  0.00010662619024515152\n",
      "The classification loss after processing this batch is:  23259.962890625\n",
      "The representation loss after processing this batch is:  0.00011366326361894608\n",
      "The classification loss after processing this batch is:  24585.8125\n",
      "The representation loss after processing this batch is:  0.00011595245450735092\n",
      "The classification loss after processing this batch is:  24288.974609375\n",
      "The representation loss after processing this batch is:  0.00012420117855072021\n",
      "The classification loss after processing this batch is:  23779.296875\n",
      "The representation loss after processing this batch is:  0.0001172265037894249\n",
      "The classification loss after processing this batch is:  25201.71484375\n",
      "The representation loss after processing this batch is:  0.00011434685438871384\n",
      "The classification loss after processing this batch is:  25460.111328125\n",
      "The representation loss after processing this batch is:  0.00011452753096818924\n",
      "The classification loss after processing this batch is:  23456.90234375\n",
      "The representation loss after processing this batch is:  0.00012583378702402115\n",
      "The classification loss after processing this batch is:  23846.31640625\n",
      "The representation loss after processing this batch is:  0.00012173876166343689\n",
      "The classification loss after processing this batch is:  24072.52734375\n",
      "The representation loss after processing this batch is:  0.00010967627167701721\n",
      "The classification loss after processing this batch is:  24334.54296875\n",
      "The representation loss after processing this batch is:  0.00011637620627880096\n",
      "The classification loss after processing this batch is:  25868.99609375\n",
      "The representation loss after processing this batch is:  0.00011678878217935562\n",
      "The classification loss after processing this batch is:  23927.056640625\n",
      "The representation loss after processing this batch is:  0.0001067817211151123\n",
      "The classification loss after processing this batch is:  23263.154296875\n",
      "The representation loss after processing this batch is:  0.00011543463915586472\n",
      "The classification loss after processing this batch is:  24530.052734375\n",
      "The representation loss after processing this batch is:  0.00012367591261863708\n",
      "The classification loss after processing this batch is:  26623.173828125\n",
      "The representation loss after processing this batch is:  0.0001269206404685974\n",
      "The classification loss after processing this batch is:  23901.62109375\n",
      "The representation loss after processing this batch is:  0.0001105843111872673\n",
      "The classification loss after processing this batch is:  24821.333984375\n",
      "The representation loss after processing this batch is:  0.00011511985212564468\n",
      "The classification loss after processing this batch is:  26244.220703125\n",
      "The representation loss after processing this batch is:  0.00011975225061178207\n",
      "The classification loss after processing this batch is:  24573.56640625\n",
      "The representation loss after processing this batch is:  0.00012783333659172058\n",
      "The classification loss after processing this batch is:  23568.96484375\n",
      "The representation loss after processing this batch is:  0.00010622665286064148\n",
      "The classification loss after processing this batch is:  23817.4921875\n",
      "The representation loss after processing this batch is:  0.00011454988270998001\n",
      "The classification loss after processing this batch is:  23565.787109375\n",
      "The representation loss after processing this batch is:  0.00010728836059570312\n",
      "The classification loss after processing this batch is:  23965.111328125\n",
      "The representation loss after processing this batch is:  0.00010391697287559509\n",
      "The classification loss after processing this batch is:  23427.15234375\n",
      "The representation loss after processing this batch is:  0.00012785103172063828\n",
      "The classification loss after processing this batch is:  24325.880859375\n",
      "The representation loss after processing this batch is:  0.00012461654841899872\n",
      "The classification loss after processing this batch is:  27382.7578125\n",
      "The representation loss after processing this batch is:  0.00013524480164051056\n",
      "The classification loss after processing this batch is:  25531.072265625\n",
      "The representation loss after processing this batch is:  0.00012193340808153152\n",
      "The classification loss after processing this batch is:  24499.080078125\n",
      "The representation loss after processing this batch is:  0.00011407677084207535\n",
      "The classification loss after processing this batch is:  23639.810546875\n",
      "The representation loss after processing this batch is:  0.00012389011681079865\n",
      "The classification loss after processing this batch is:  24229.880859375\n",
      "The representation loss after processing this batch is:  0.0001418180763721466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24018.884765625\n",
      "The representation loss after processing this batch is:  0.00014430470764636993\n",
      "The classification loss after processing this batch is:  23758.94921875\n",
      "The representation loss after processing this batch is:  0.00012033805251121521\n",
      "The classification loss after processing this batch is:  23241.376953125\n",
      "The representation loss after processing this batch is:  0.00010838266462087631\n",
      "The classification loss after processing this batch is:  23771.3671875\n",
      "The representation loss after processing this batch is:  0.00011056289076805115\n",
      "The classification loss after processing this batch is:  23570.515625\n",
      "The representation loss after processing this batch is:  0.00010217074304819107\n",
      "The classification loss after processing this batch is:  22962.82421875\n",
      "The representation loss after processing this batch is:  0.00011501368135213852\n",
      "The classification loss after processing this batch is:  24019.0859375\n",
      "The representation loss after processing this batch is:  0.00011438410729169846\n",
      "The classification loss after processing this batch is:  22924.48046875\n",
      "The representation loss after processing this batch is:  0.0001231953501701355\n",
      "The classification loss after processing this batch is:  25157.31640625\n",
      "The representation loss after processing this batch is:  0.00012904591858386993\n",
      "The classification loss after processing this batch is:  24933.17578125\n",
      "The representation loss after processing this batch is:  0.00011898204684257507\n",
      "The classification loss after processing this batch is:  23953.22265625\n",
      "The representation loss after processing this batch is:  0.0001134723424911499\n",
      "The classification loss after processing this batch is:  24309.0625\n",
      "The representation loss after processing this batch is:  0.00010703131556510925\n",
      "The classification loss after processing this batch is:  24532.4140625\n",
      "The representation loss after processing this batch is:  0.00011138990521430969\n",
      "The classification loss after processing this batch is:  25769.53125\n",
      "The representation loss after processing this batch is:  0.000113743357360363\n",
      "The classification loss after processing this batch is:  25158.466796875\n",
      "The representation loss after processing this batch is:  0.0001069074496626854\n",
      "The classification loss after processing this batch is:  23967.193359375\n",
      "The representation loss after processing this batch is:  0.00011241156607866287\n",
      "The classification loss after processing this batch is:  24395.859375\n",
      "The representation loss after processing this batch is:  0.00010960735380649567\n",
      "The classification loss after processing this batch is:  25942.5\n",
      "The representation loss after processing this batch is:  0.00012461841106414795\n",
      "The classification loss after processing this batch is:  23492.416015625\n",
      "The representation loss after processing this batch is:  0.00011258851736783981\n",
      "The classification loss after processing this batch is:  24407.83203125\n",
      "The representation loss after processing this batch is:  0.00011310726404190063\n",
      "The classification loss after processing this batch is:  24056.328125\n",
      "The representation loss after processing this batch is:  0.00013212114572525024\n",
      "The classification loss after processing this batch is:  24234.80078125\n",
      "The representation loss after processing this batch is:  0.00010787602514028549\n",
      "The classification loss after processing this batch is:  25052.8359375\n",
      "The representation loss after processing this batch is:  0.00012396927922964096\n",
      "The classification loss after processing this batch is:  25768.19921875\n",
      "The representation loss after processing this batch is:  0.00012434273958206177\n",
      "The classification loss after processing this batch is:  24306.087890625\n",
      "The representation loss after processing this batch is:  0.0001352299004793167\n",
      "The classification loss after processing this batch is:  25281.107421875\n",
      "The representation loss after processing this batch is:  0.0001050904393196106\n",
      "The classification loss after processing this batch is:  25799.765625\n",
      "The representation loss after processing this batch is:  9.832996875047684e-05\n",
      "The classification loss after processing this batch is:  23930.392578125\n",
      "The representation loss after processing this batch is:  0.0001233946532011032\n",
      "The classification loss after processing this batch is:  24898.6015625\n",
      "The representation loss after processing this batch is:  0.00010506249964237213\n",
      "The classification loss after processing this batch is:  24468.978515625\n",
      "The representation loss after processing this batch is:  0.00011338386684656143\n",
      "The classification loss after processing this batch is:  23627.904296875\n",
      "The representation loss after processing this batch is:  0.00012125354260206223\n",
      "The classification loss after processing this batch is:  23870.849609375\n",
      "The representation loss after processing this batch is:  0.00011567957699298859\n",
      "The classification loss after processing this batch is:  23852.0\n",
      "The representation loss after processing this batch is:  0.00011324882507324219\n",
      "The classification loss after processing this batch is:  23769.125\n",
      "The representation loss after processing this batch is:  0.00011757761240005493\n",
      "The classification loss after processing this batch is:  25331.08203125\n",
      "The representation loss after processing this batch is:  0.00010851863771677017\n",
      "The classification loss after processing this batch is:  25058.130859375\n",
      "The representation loss after processing this batch is:  9.91215929389e-05\n",
      "The classification loss after processing this batch is:  26243.4765625\n",
      "The representation loss after processing this batch is:  0.0001198919489979744\n",
      "The classification loss after processing this batch is:  23107.421875\n",
      "The representation loss after processing this batch is:  0.00011899042874574661\n",
      "The classification loss after processing this batch is:  23234.255859375\n",
      "The representation loss after processing this batch is:  0.00012859143316745758\n",
      "The classification loss after processing this batch is:  23869.916015625\n",
      "The representation loss after processing this batch is:  0.00012887921184301376\n",
      "The classification loss after processing this batch is:  23748.9765625\n",
      "The representation loss after processing this batch is:  0.00011579133570194244\n",
      "The classification loss after processing this batch is:  25324.42578125\n",
      "The representation loss after processing this batch is:  0.00014152098447084427\n",
      "The classification loss after processing this batch is:  24095.45703125\n",
      "The representation loss after processing this batch is:  0.0001155417412519455\n",
      "The classification loss after processing this batch is:  24304.423828125\n",
      "The representation loss after processing this batch is:  0.00010698754340410233\n",
      "The classification loss after processing this batch is:  24467.0078125\n",
      "The representation loss after processing this batch is:  0.00010542012751102448\n",
      "The classification loss after processing this batch is:  23753.478515625\n",
      "The representation loss after processing this batch is:  0.00012694206088781357\n",
      "The classification loss after processing this batch is:  25684.86328125\n",
      "The representation loss after processing this batch is:  0.00012574344873428345\n",
      "The classification loss after processing this batch is:  25815.59765625\n",
      "The representation loss after processing this batch is:  0.0001132674515247345\n",
      "The classification loss after processing this batch is:  25148.953125\n",
      "The representation loss after processing this batch is:  0.00010709371417760849\n",
      "The classification loss after processing this batch is:  23317.591796875\n",
      "The representation loss after processing this batch is:  0.00014049001038074493\n",
      "The classification loss after processing this batch is:  25510.37109375\n",
      "The representation loss after processing this batch is:  0.0001192484050989151\n",
      "The classification loss after processing this batch is:  25262.640625\n",
      "The representation loss after processing this batch is:  0.00010849256068468094\n",
      "The classification loss after processing this batch is:  23846.4765625\n",
      "The representation loss after processing this batch is:  0.00011466257274150848\n",
      "The classification loss after processing this batch is:  26004.60546875\n",
      "The representation loss after processing this batch is:  0.00012082047760486603\n",
      "The classification loss after processing this batch is:  25819.06640625\n",
      "The representation loss after processing this batch is:  0.00013195723295211792\n",
      "The classification loss after processing this batch is:  23387.02734375\n",
      "The representation loss after processing this batch is:  0.00012370944023132324\n",
      "The classification loss after processing this batch is:  23859.25\n",
      "The representation loss after processing this batch is:  0.00011715944856405258\n",
      "The classification loss after processing this batch is:  24616.380859375\n",
      "The representation loss after processing this batch is:  0.00012472830712795258\n",
      "The classification loss after processing this batch is:  24153.740234375\n",
      "The representation loss after processing this batch is:  0.0001252833753824234\n",
      "The classification loss after processing this batch is:  24776.28125\n",
      "The representation loss after processing this batch is:  0.00012391991913318634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  25243.9140625\n",
      "The representation loss after processing this batch is:  0.00013805460184812546\n",
      "The classification loss after processing this batch is:  23356.859375\n",
      "The representation loss after processing this batch is:  0.00015182793140411377\n",
      "The classification loss after processing this batch is:  23131.00390625\n",
      "The representation loss after processing this batch is:  0.00012824498116970062\n",
      "The classification loss after processing this batch is:  24663.91796875\n",
      "The representation loss after processing this batch is:  0.00011240597814321518\n",
      "The classification loss after processing this batch is:  25726.84375\n",
      "The representation loss after processing this batch is:  0.00011529028415679932\n",
      "The classification loss after processing this batch is:  24117.65625\n",
      "The representation loss after processing this batch is:  0.00011951569467782974\n",
      "The classification loss after processing this batch is:  24657.537109375\n",
      "The representation loss after processing this batch is:  0.0001241695135831833\n",
      "The classification loss after processing this batch is:  24436.6484375\n",
      "The representation loss after processing this batch is:  0.00010721385478973389\n",
      "The classification loss after processing this batch is:  24551.76953125\n",
      "The representation loss after processing this batch is:  0.00010406412184238434\n",
      "The classification loss after processing this batch is:  23701.765625\n",
      "The representation loss after processing this batch is:  0.00011514034122228622\n",
      "The classification loss after processing this batch is:  23935.666015625\n",
      "The representation loss after processing this batch is:  0.00011286977678537369\n",
      "The classification loss after processing this batch is:  25131.31640625\n",
      "The representation loss after processing this batch is:  0.0001071784645318985\n",
      "The classification loss after processing this batch is:  23072.25390625\n",
      "The representation loss after processing this batch is:  0.0001324201002717018\n",
      "The classification loss after processing this batch is:  23388.35546875\n",
      "The representation loss after processing this batch is:  0.00010610464960336685\n",
      "The classification loss after processing this batch is:  23069.345703125\n",
      "The representation loss after processing this batch is:  0.0001174677163362503\n",
      "The classification loss after processing this batch is:  22961.91796875\n",
      "The representation loss after processing this batch is:  0.00010105594992637634\n",
      "The classification loss after processing this batch is:  23445.58203125\n",
      "The representation loss after processing this batch is:  0.00010502990335226059\n",
      "The classification loss after processing this batch is:  24669.759765625\n",
      "The representation loss after processing this batch is:  0.0001244349405169487\n",
      "The classification loss after processing this batch is:  24477.486328125\n",
      "The representation loss after processing this batch is:  0.00012068171054124832\n",
      "The classification loss after processing this batch is:  22996.65234375\n",
      "The representation loss after processing this batch is:  0.00011386815458536148\n",
      "The classification loss after processing this batch is:  23419.75\n",
      "The representation loss after processing this batch is:  0.00010799150913953781\n",
      "The classification loss after processing this batch is:  23492.05859375\n",
      "The representation loss after processing this batch is:  0.0001006321981549263\n",
      "The classification loss after processing this batch is:  24116.37890625\n",
      "The representation loss after processing this batch is:  0.00010536238551139832\n",
      "The classification loss after processing this batch is:  24245.404296875\n",
      "The representation loss after processing this batch is:  0.00012413132935762405\n",
      "The classification loss after processing this batch is:  23342.109375\n",
      "The representation loss after processing this batch is:  0.00011759251356124878\n",
      "The classification loss after processing this batch is:  25789.875\n",
      "The representation loss after processing this batch is:  0.00011160504072904587\n",
      "The classification loss after processing this batch is:  23780.37109375\n",
      "The representation loss after processing this batch is:  0.00010252557694911957\n",
      "The classification loss after processing this batch is:  23173.076171875\n",
      "The representation loss after processing this batch is:  0.00011757016181945801\n",
      "The classification loss after processing this batch is:  23866.31640625\n",
      "The representation loss after processing this batch is:  0.00011357665061950684\n",
      "The classification loss after processing this batch is:  24531.859375\n",
      "The representation loss after processing this batch is:  0.00013948790729045868\n",
      "The classification loss after processing this batch is:  24120.970703125\n",
      "The representation loss after processing this batch is:  0.00010715145617723465\n",
      "The classification loss after processing this batch is:  23589.580078125\n",
      "The representation loss after processing this batch is:  0.0001192782074213028\n",
      "The classification loss after processing this batch is:  24357.07421875\n",
      "The representation loss after processing this batch is:  0.0001319264993071556\n",
      "The classification loss after processing this batch is:  26092.45703125\n",
      "The representation loss after processing this batch is:  0.00010717939585447311\n",
      "The classification loss after processing this batch is:  23241.60546875\n",
      "The representation loss after processing this batch is:  0.00011203158646821976\n",
      "The classification loss after processing this batch is:  24094.71484375\n",
      "The representation loss after processing this batch is:  0.00011700298637151718\n",
      "The classification loss after processing this batch is:  22877.412109375\n",
      "The representation loss after processing this batch is:  0.0001133996993303299\n",
      "The classification loss after processing this batch is:  24286.48046875\n",
      "The representation loss after processing this batch is:  0.00010493025183677673\n",
      "The classification loss after processing this batch is:  24485.046875\n",
      "The representation loss after processing this batch is:  0.00012037716805934906\n",
      "The classification loss after processing this batch is:  23776.37890625\n",
      "The representation loss after processing this batch is:  0.00011432170867919922\n",
      "The classification loss after processing this batch is:  23755.412109375\n",
      "The representation loss after processing this batch is:  0.00012325868010520935\n",
      "The classification loss after processing this batch is:  23138.65234375\n",
      "The representation loss after processing this batch is:  0.00010802596807479858\n",
      "The classification loss after processing this batch is:  23792.796875\n",
      "The representation loss after processing this batch is:  0.00011655688285827637\n",
      "The classification loss after processing this batch is:  23802.298828125\n",
      "The representation loss after processing this batch is:  0.00011852104216814041\n",
      "The classification loss after processing this batch is:  22939.19140625\n",
      "The representation loss after processing this batch is:  0.00011963210999965668\n",
      "The classification loss after processing this batch is:  27283.31640625\n",
      "The representation loss after processing this batch is:  0.00012707337737083435\n",
      "The classification loss after processing this batch is:  25730.62890625\n",
      "The representation loss after processing this batch is:  0.00012384168803691864\n",
      "The classification loss after processing this batch is:  25065.361328125\n",
      "The representation loss after processing this batch is:  0.00012814998626708984\n",
      "The classification loss after processing this batch is:  23927.9765625\n",
      "The representation loss after processing this batch is:  0.0001142183318734169\n",
      "The classification loss after processing this batch is:  23189.119140625\n",
      "The representation loss after processing this batch is:  0.00012633390724658966\n",
      "The classification loss after processing this batch is:  23875.025390625\n",
      "The representation loss after processing this batch is:  0.00010553374886512756\n",
      "The classification loss after processing this batch is:  24717.669921875\n",
      "The representation loss after processing this batch is:  0.00011498946696519852\n",
      "The classification loss after processing this batch is:  23828.060546875\n",
      "The representation loss after processing this batch is:  9.903684258460999e-05\n",
      "The classification loss after processing this batch is:  25835.453125\n",
      "The representation loss after processing this batch is:  0.00014176871627569199\n",
      "The classification loss after processing this batch is:  24048.099609375\n",
      "The representation loss after processing this batch is:  0.00013517867773771286\n",
      "The classification loss after processing this batch is:  23335.294921875\n",
      "The representation loss after processing this batch is:  0.00011249538511037827\n",
      "The classification loss after processing this batch is:  24990.5546875\n",
      "The representation loss after processing this batch is:  0.00011627189815044403\n",
      "The classification loss after processing this batch is:  23288.59765625\n",
      "The representation loss after processing this batch is:  0.00011390913277864456\n",
      "The classification loss after processing this batch is:  23599.41015625\n",
      "The representation loss after processing this batch is:  0.00012679584324359894\n",
      "The classification loss after processing this batch is:  27191.544921875\n",
      "The representation loss after processing this batch is:  0.00012430362403392792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24974.5390625\n",
      "The representation loss after processing this batch is:  0.0001428890973329544\n",
      "The classification loss after processing this batch is:  23199.078125\n",
      "The representation loss after processing this batch is:  0.00014566630125045776\n",
      "The classification loss after processing this batch is:  23221.5625\n",
      "The representation loss after processing this batch is:  0.00017007440328598022\n",
      "The classification loss after processing this batch is:  25908.49609375\n",
      "The representation loss after processing this batch is:  0.00012339837849140167\n",
      "The classification loss after processing this batch is:  23270.71484375\n",
      "The representation loss after processing this batch is:  0.0001279544085264206\n",
      "The classification loss after processing this batch is:  23438.90234375\n",
      "The representation loss after processing this batch is:  0.00015510804951190948\n",
      "The classification loss after processing this batch is:  23947.771484375\n",
      "The representation loss after processing this batch is:  0.00015636160969734192\n",
      "The classification loss after processing this batch is:  28773.29296875\n",
      "The representation loss after processing this batch is:  0.00013589859008789062\n",
      "The classification loss after processing this batch is:  31016.251953125\n",
      "The representation loss after processing this batch is:  0.00012623146176338196\n",
      "The classification loss after processing this batch is:  23152.458984375\n",
      "The representation loss after processing this batch is:  0.0001245252788066864\n",
      "The classification loss after processing this batch is:  24669.8203125\n",
      "The representation loss after processing this batch is:  0.00013100169599056244\n",
      "The classification loss after processing this batch is:  24472.40234375\n",
      "The representation loss after processing this batch is:  0.00014310143887996674\n",
      "The classification loss after processing this batch is:  21858.5703125\n",
      "The representation loss after processing this batch is:  0.00013137422502040863\n",
      "The classification loss after processing this batch is:  24595.66796875\n",
      "The representation loss after processing this batch is:  0.0001357458531856537\n",
      "The classification loss after processing this batch is:  24868.236328125\n",
      "The representation loss after processing this batch is:  0.00015522539615631104\n",
      "The classification loss after processing this batch is:  23745.9375\n",
      "The representation loss after processing this batch is:  0.00015487708151340485\n",
      "The classification loss after processing this batch is:  24205.1015625\n",
      "The representation loss after processing this batch is:  0.00015584006905555725\n",
      "The classification loss after processing this batch is:  24167.453125\n",
      "The representation loss after processing this batch is:  0.00014595501124858856\n",
      "The classification loss after processing this batch is:  24582.8046875\n",
      "The representation loss after processing this batch is:  0.00013564340770244598\n",
      "The classification loss after processing this batch is:  24793.146484375\n",
      "The representation loss after processing this batch is:  0.00013850070536136627\n",
      "The classification loss after processing this batch is:  24576.326171875\n",
      "The representation loss after processing this batch is:  0.00014630891382694244\n",
      "The classification loss after processing this batch is:  24130.51171875\n",
      "The representation loss after processing this batch is:  0.00014879368245601654\n",
      "The classification loss after processing this batch is:  27472.6171875\n",
      "The representation loss after processing this batch is:  0.0001711491495370865\n",
      "The classification loss after processing this batch is:  26179.521484375\n",
      "The representation loss after processing this batch is:  0.00012746639549732208\n",
      "The classification loss after processing this batch is:  24165.17578125\n",
      "The representation loss after processing this batch is:  0.00013289600610733032\n",
      "The classification loss after processing this batch is:  24268.84765625\n",
      "The representation loss after processing this batch is:  0.00012369640171527863\n",
      "The classification loss after processing this batch is:  24033.0546875\n",
      "The representation loss after processing this batch is:  0.0001332554966211319\n",
      "The classification loss after processing this batch is:  24127.43359375\n",
      "The representation loss after processing this batch is:  0.00014921650290489197\n",
      "The classification loss after processing this batch is:  24629.017578125\n",
      "The representation loss after processing this batch is:  0.0001517161726951599\n",
      "The classification loss after processing this batch is:  24118.728515625\n",
      "The representation loss after processing this batch is:  0.0001293271780014038\n",
      "The classification loss after processing this batch is:  25515.630859375\n",
      "The representation loss after processing this batch is:  0.00014832988381385803\n",
      "The classification loss after processing this batch is:  24883.541015625\n",
      "The representation loss after processing this batch is:  0.00012916140258312225\n",
      "The classification loss after processing this batch is:  25156.1015625\n",
      "The representation loss after processing this batch is:  0.0001329369843006134\n",
      "The classification loss after processing this batch is:  24524.0078125\n",
      "The representation loss after processing this batch is:  0.00014120154082775116\n",
      "The classification loss after processing this batch is:  24223.67578125\n",
      "The representation loss after processing this batch is:  0.0001177079975605011\n",
      "The classification loss after processing this batch is:  24622.01953125\n",
      "The representation loss after processing this batch is:  0.00012255273759365082\n",
      "The classification loss after processing this batch is:  24392.662109375\n",
      "The representation loss after processing this batch is:  0.00013208389282226562\n",
      "The classification loss after processing this batch is:  24138.64453125\n",
      "The representation loss after processing this batch is:  0.00013512186706066132\n",
      "The classification loss after processing this batch is:  23339.703125\n",
      "The representation loss after processing this batch is:  0.0001296643167734146\n",
      "The classification loss after processing this batch is:  23501.11328125\n",
      "The representation loss after processing this batch is:  0.00013104267418384552\n",
      "The classification loss after processing this batch is:  23373.49609375\n",
      "The representation loss after processing this batch is:  0.00012672040611505508\n",
      "The classification loss after processing this batch is:  26065.5390625\n",
      "The representation loss after processing this batch is:  0.00013642385601997375\n",
      "The classification loss after processing this batch is:  24702.451171875\n",
      "The representation loss after processing this batch is:  0.00012194551527500153\n",
      "The classification loss after processing this batch is:  23298.833984375\n",
      "The representation loss after processing this batch is:  0.0001288093626499176\n",
      "The classification loss after processing this batch is:  23975.12890625\n",
      "The representation loss after processing this batch is:  0.0001210477203130722\n",
      "The classification loss after processing this batch is:  23007.08984375\n",
      "The representation loss after processing this batch is:  0.0001253196969628334\n",
      "The classification loss after processing this batch is:  23613.9921875\n",
      "The representation loss after processing this batch is:  0.00012806430459022522\n",
      "The classification loss after processing this batch is:  23897.7421875\n",
      "The representation loss after processing this batch is:  0.00012956373393535614\n",
      "The classification loss after processing this batch is:  24345.28125\n",
      "The representation loss after processing this batch is:  0.00012608803808689117\n",
      "The classification loss after processing this batch is:  25490.01953125\n",
      "The representation loss after processing this batch is:  0.00011347886174917221\n",
      "The classification loss after processing this batch is:  29194.6484375\n",
      "The representation loss after processing this batch is:  0.0001587364822626114\n",
      "The classification loss after processing this batch is:  24056.484375\n",
      "The representation loss after processing this batch is:  0.00013525597751140594\n",
      "The classification loss after processing this batch is:  24467.8515625\n",
      "The representation loss after processing this batch is:  0.00012875255197286606\n",
      "The classification loss after processing this batch is:  24737.296875\n",
      "The representation loss after processing this batch is:  0.00012544170022010803\n",
      "The classification loss after processing this batch is:  24973.3515625\n",
      "The representation loss after processing this batch is:  0.000128820538520813\n",
      "The classification loss after processing this batch is:  24401.953125\n",
      "The representation loss after processing this batch is:  0.00011587515473365784\n",
      "The classification loss after processing this batch is:  24674.55859375\n",
      "The representation loss after processing this batch is:  0.0001325942575931549\n",
      "The classification loss after processing this batch is:  24480.56640625\n",
      "The representation loss after processing this batch is:  0.00012356974184513092\n",
      "The classification loss after processing this batch is:  24330.11328125\n",
      "The representation loss after processing this batch is:  0.00013212859630584717\n",
      "The classification loss after processing this batch is:  24167.9140625\n",
      "The representation loss after processing this batch is:  0.00012053456157445908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24108.28125\n",
      "The representation loss after processing this batch is:  0.00012899748980998993\n",
      "The classification loss after processing this batch is:  23747.05078125\n",
      "The representation loss after processing this batch is:  0.0001271311193704605\n",
      "The classification loss after processing this batch is:  23671.67578125\n",
      "The representation loss after processing this batch is:  0.0001388024538755417\n",
      "The classification loss after processing this batch is:  23716.3203125\n",
      "The representation loss after processing this batch is:  0.0001167813315987587\n",
      "The classification loss after processing this batch is:  22499.71484375\n",
      "The representation loss after processing this batch is:  0.00012941472232341766\n",
      "The classification loss after processing this batch is:  23375.0703125\n",
      "The representation loss after processing this batch is:  0.00015570595860481262\n",
      "The classification loss after processing this batch is:  23817.61328125\n",
      "The representation loss after processing this batch is:  0.00014643650501966476\n",
      "The classification loss after processing this batch is:  23877.87890625\n",
      "The representation loss after processing this batch is:  0.00014778226613998413\n",
      "The classification loss after processing this batch is:  23425.34375\n",
      "The representation loss after processing this batch is:  0.00013216957449913025\n",
      "The classification loss after processing this batch is:  24894.29296875\n",
      "The representation loss after processing this batch is:  0.00015058927237987518\n",
      "The classification loss after processing this batch is:  23517.072265625\n",
      "The representation loss after processing this batch is:  0.000143321231007576\n",
      "The classification loss after processing this batch is:  23564.125\n",
      "The representation loss after processing this batch is:  0.00014702416956424713\n",
      "The classification loss after processing this batch is:  24233.421875\n",
      "The representation loss after processing this batch is:  0.00011924281716346741\n",
      "The classification loss after processing this batch is:  25709.326171875\n",
      "The representation loss after processing this batch is:  0.00012602470815181732\n",
      "The classification loss after processing this batch is:  26675.560546875\n",
      "The representation loss after processing this batch is:  0.00012214481830596924\n",
      "The classification loss after processing this batch is:  25871.25\n",
      "The representation loss after processing this batch is:  0.00011859461665153503\n",
      "The classification loss after processing this batch is:  23173.76953125\n",
      "The representation loss after processing this batch is:  0.00014055706560611725\n",
      "The classification loss after processing this batch is:  24841.88671875\n",
      "The representation loss after processing this batch is:  0.00012239627540111542\n",
      "The classification loss after processing this batch is:  24394.416015625\n",
      "The representation loss after processing this batch is:  0.00013427622616291046\n",
      "The classification loss after processing this batch is:  25496.46875\n",
      "The representation loss after processing this batch is:  0.0001368597149848938\n",
      "The classification loss after processing this batch is:  25813.513671875\n",
      "The representation loss after processing this batch is:  0.00013550743460655212\n",
      "The classification loss after processing this batch is:  24546.904296875\n",
      "The representation loss after processing this batch is:  0.00013599824160337448\n",
      "The classification loss after processing this batch is:  24765.21484375\n",
      "The representation loss after processing this batch is:  0.00014281459152698517\n",
      "The classification loss after processing this batch is:  24892.21875\n",
      "The representation loss after processing this batch is:  0.00014107301831245422\n",
      "The classification loss after processing this batch is:  25391.04296875\n",
      "The representation loss after processing this batch is:  0.00014383159577846527\n",
      "The classification loss after processing this batch is:  24078.66015625\n",
      "The representation loss after processing this batch is:  0.00015281885862350464\n",
      "The classification loss after processing this batch is:  25434.29296875\n",
      "The representation loss after processing this batch is:  0.00012786779552698135\n",
      "The classification loss after processing this batch is:  25746.37890625\n",
      "The representation loss after processing this batch is:  0.00014029722660779953\n",
      "The classification loss after processing this batch is:  26612.59375\n",
      "The representation loss after processing this batch is:  0.00014907121658325195\n",
      "The classification loss after processing this batch is:  24818.82421875\n",
      "The representation loss after processing this batch is:  0.00012686476111412048\n",
      "The classification loss after processing this batch is:  24673.501953125\n",
      "The representation loss after processing this batch is:  0.00013164803385734558\n",
      "The classification loss after processing this batch is:  24475.08984375\n",
      "The representation loss after processing this batch is:  0.00012643076479434967\n",
      "The classification loss after processing this batch is:  25538.529296875\n",
      "The representation loss after processing this batch is:  0.0001282617449760437\n",
      "The classification loss after processing this batch is:  26199.22265625\n",
      "The representation loss after processing this batch is:  0.0001276303082704544\n",
      "The classification loss after processing this batch is:  24594.96875\n",
      "The representation loss after processing this batch is:  0.0001465287059545517\n",
      "The classification loss after processing this batch is:  23941.86328125\n",
      "The representation loss after processing this batch is:  0.00011881068348884583\n",
      "The classification loss after processing this batch is:  24569.90625\n",
      "The representation loss after processing this batch is:  0.00012526661157608032\n",
      "The classification loss after processing this batch is:  23899.41796875\n",
      "The representation loss after processing this batch is:  0.00011831149458885193\n",
      "The classification loss after processing this batch is:  24161.95703125\n",
      "The representation loss after processing this batch is:  0.000124368816614151\n",
      "The classification loss after processing this batch is:  24195.86328125\n",
      "The representation loss after processing this batch is:  0.00012748315930366516\n",
      "The classification loss after processing this batch is:  23972.634765625\n",
      "The representation loss after processing this batch is:  0.00013803690671920776\n",
      "The classification loss after processing this batch is:  23599.375\n",
      "The representation loss after processing this batch is:  0.00012174062430858612\n",
      "The classification loss after processing this batch is:  23137.298828125\n",
      "The representation loss after processing this batch is:  0.00011850707232952118\n",
      "The classification loss after processing this batch is:  23285.783203125\n",
      "The representation loss after processing this batch is:  0.00011795386672019958\n",
      "The classification loss after processing this batch is:  22951.75390625\n",
      "The representation loss after processing this batch is:  0.00012874137610197067\n",
      "The classification loss after processing this batch is:  23256.484375\n",
      "The representation loss after processing this batch is:  0.0001351088285446167\n",
      "The classification loss after processing this batch is:  23754.05078125\n",
      "The representation loss after processing this batch is:  0.00013547111302614212\n",
      "The classification loss after processing this batch is:  22892.052734375\n",
      "The representation loss after processing this batch is:  0.00011850893497467041\n",
      "The classification loss after processing this batch is:  25102.62890625\n",
      "The representation loss after processing this batch is:  0.00011071469634771347\n",
      "The classification loss after processing this batch is:  24751.083984375\n",
      "The representation loss after processing this batch is:  0.00012276321649551392\n",
      "The classification loss after processing this batch is:  25360.7109375\n",
      "The representation loss after processing this batch is:  0.00012083910405635834\n",
      "The classification loss after processing this batch is:  25452.1484375\n",
      "The representation loss after processing this batch is:  0.00013478845357894897\n",
      "The classification loss after processing this batch is:  25473.564453125\n",
      "The representation loss after processing this batch is:  0.00013573374599218369\n",
      "The classification loss after processing this batch is:  24793.91796875\n",
      "The representation loss after processing this batch is:  0.00013078004121780396\n",
      "The classification loss after processing this batch is:  24305.015625\n",
      "The representation loss after processing this batch is:  0.00013579148799180984\n",
      "The classification loss after processing this batch is:  24131.6953125\n",
      "The representation loss after processing this batch is:  0.00012569129467010498\n",
      "The classification loss after processing this batch is:  24517.375\n",
      "The representation loss after processing this batch is:  0.00012254714965820312\n",
      "The classification loss after processing this batch is:  23917.953125\n",
      "The representation loss after processing this batch is:  0.0001255776733160019\n",
      "The classification loss after processing this batch is:  23487.482421875\n",
      "The representation loss after processing this batch is:  0.0001329425722360611\n",
      "The classification loss after processing this batch is:  24496.845703125\n",
      "The representation loss after processing this batch is:  0.00013461988419294357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24078.330078125\n",
      "The representation loss after processing this batch is:  0.00013824179768562317\n",
      "The classification loss after processing this batch is:  23606.802734375\n",
      "The representation loss after processing this batch is:  0.00011683255434036255\n",
      "The classification loss after processing this batch is:  24719.423828125\n",
      "The representation loss after processing this batch is:  0.00012229755520820618\n",
      "The classification loss after processing this batch is:  27917.7109375\n",
      "The representation loss after processing this batch is:  0.0001567751169204712\n",
      "The classification loss after processing this batch is:  25112.376953125\n",
      "The representation loss after processing this batch is:  0.00013739056885242462\n",
      "The classification loss after processing this batch is:  23672.22265625\n",
      "The representation loss after processing this batch is:  0.00012553948909044266\n",
      "The classification loss after processing this batch is:  23717.58984375\n",
      "The representation loss after processing this batch is:  0.00013280659914016724\n",
      "The classification loss after processing this batch is:  27159.216796875\n",
      "The representation loss after processing this batch is:  0.00012596137821674347\n",
      "The classification loss after processing this batch is:  27352.767578125\n",
      "The representation loss after processing this batch is:  0.00013961829245090485\n",
      "The classification loss after processing this batch is:  23415.419921875\n",
      "The representation loss after processing this batch is:  0.00011323206126689911\n",
      "The classification loss after processing this batch is:  23249.546875\n",
      "The representation loss after processing this batch is:  0.00013147853314876556\n",
      "The classification loss after processing this batch is:  23880.87109375\n",
      "The representation loss after processing this batch is:  0.00013601034879684448\n",
      "The classification loss after processing this batch is:  24694.033203125\n",
      "The representation loss after processing this batch is:  0.00012050755321979523\n",
      "The classification loss after processing this batch is:  24627.60546875\n",
      "The representation loss after processing this batch is:  0.00011024437844753265\n",
      "The classification loss after processing this batch is:  23990.7265625\n",
      "The representation loss after processing this batch is:  0.00011680088937282562\n",
      "The classification loss after processing this batch is:  25044.2734375\n",
      "The representation loss after processing this batch is:  0.00011449679732322693\n",
      "The classification loss after processing this batch is:  25818.751953125\n",
      "The representation loss after processing this batch is:  0.00014787446707487106\n",
      "The classification loss after processing this batch is:  23667.89453125\n",
      "The representation loss after processing this batch is:  0.00014259293675422668\n",
      "The classification loss after processing this batch is:  24532.845703125\n",
      "The representation loss after processing this batch is:  0.00013779941946268082\n",
      "The classification loss after processing this batch is:  23380.2578125\n",
      "The representation loss after processing this batch is:  0.00013061054050922394\n",
      "The classification loss after processing this batch is:  23896.705078125\n",
      "The representation loss after processing this batch is:  0.00014742836356163025\n",
      "The classification loss after processing this batch is:  22984.484375\n",
      "The representation loss after processing this batch is:  0.0001297779381275177\n",
      "The classification loss after processing this batch is:  24550.736328125\n",
      "The representation loss after processing this batch is:  0.00013593025505542755\n",
      "The classification loss after processing this batch is:  24020.92578125\n",
      "The representation loss after processing this batch is:  0.0001234002411365509\n",
      "The classification loss after processing this batch is:  25743.5625\n",
      "The representation loss after processing this batch is:  0.00011574476957321167\n",
      "The classification loss after processing this batch is:  23811.767578125\n",
      "The representation loss after processing this batch is:  0.00012650713324546814\n",
      "The classification loss after processing this batch is:  23944.751953125\n",
      "The representation loss after processing this batch is:  0.0001316191628575325\n",
      "The classification loss after processing this batch is:  25468.1484375\n",
      "The representation loss after processing this batch is:  0.0001334007829427719\n",
      "The classification loss after processing this batch is:  24920.134765625\n",
      "The representation loss after processing this batch is:  0.00011684373021125793\n",
      "The classification loss after processing this batch is:  24350.60546875\n",
      "The representation loss after processing this batch is:  0.00013185851275920868\n",
      "The classification loss after processing this batch is:  25833.2734375\n",
      "The representation loss after processing this batch is:  0.0001385565847158432\n",
      "The classification loss after processing this batch is:  23941.47265625\n",
      "The representation loss after processing this batch is:  0.0001419857144355774\n",
      "The classification loss after processing this batch is:  24747.623046875\n",
      "The representation loss after processing this batch is:  0.00015150383114814758\n",
      "The classification loss after processing this batch is:  23417.0234375\n",
      "The representation loss after processing this batch is:  0.0001112762838602066\n",
      "The classification loss after processing this batch is:  23474.48046875\n",
      "The representation loss after processing this batch is:  0.00012563541531562805\n",
      "The classification loss after processing this batch is:  23674.98046875\n",
      "The representation loss after processing this batch is:  0.00013263709843158722\n",
      "The classification loss after processing this batch is:  23391.72265625\n",
      "The representation loss after processing this batch is:  0.0001470707356929779\n",
      "The classification loss after processing this batch is:  23348.80078125\n",
      "The representation loss after processing this batch is:  0.00014075636863708496\n",
      "The classification loss after processing this batch is:  26112.23046875\n",
      "The representation loss after processing this batch is:  0.0001247115433216095\n",
      "The classification loss after processing this batch is:  23704.947265625\n",
      "The representation loss after processing this batch is:  0.00012818537652492523\n",
      "The classification loss after processing this batch is:  24270.150390625\n",
      "The representation loss after processing this batch is:  0.00010786019265651703\n",
      "The classification loss after processing this batch is:  25183.2578125\n",
      "The representation loss after processing this batch is:  0.0001208130270242691\n",
      "The classification loss after processing this batch is:  24381.81640625\n",
      "The representation loss after processing this batch is:  0.00011658482253551483\n",
      "The classification loss after processing this batch is:  24796.83203125\n",
      "The representation loss after processing this batch is:  0.0001297779381275177\n",
      "The classification loss after processing this batch is:  24546.91796875\n",
      "The representation loss after processing this batch is:  0.00011740624904632568\n",
      "The classification loss after processing this batch is:  24184.69921875\n",
      "The representation loss after processing this batch is:  0.00013007409870624542\n",
      "The classification loss after processing this batch is:  23049.609375\n",
      "The representation loss after processing this batch is:  0.00012600980699062347\n",
      "The classification loss after processing this batch is:  24508.259765625\n",
      "The representation loss after processing this batch is:  0.00012321770191192627\n",
      "The classification loss after processing this batch is:  27137.49609375\n",
      "The representation loss after processing this batch is:  0.00012484751641750336\n",
      "The classification loss after processing this batch is:  27717.48828125\n",
      "The representation loss after processing this batch is:  0.00013066455721855164\n",
      "The classification loss after processing this batch is:  24461.765625\n",
      "The representation loss after processing this batch is:  0.00010678358376026154\n",
      "The classification loss after processing this batch is:  24147.80859375\n",
      "The representation loss after processing this batch is:  0.00011074356734752655\n",
      "The classification loss after processing this batch is:  24147.62109375\n",
      "The representation loss after processing this batch is:  0.00011351983994245529\n",
      "The classification loss after processing this batch is:  24953.759765625\n",
      "The representation loss after processing this batch is:  0.00012586358934640884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  23770.6171875\n",
      "The representation loss after processing this batch is:  0.00013540871441364288\n",
      "The classification loss after processing this batch is:  24128.07421875\n",
      "The representation loss after processing this batch is:  0.00011500995606184006\n",
      "The classification loss after processing this batch is:  25713.083984375\n",
      "The representation loss after processing this batch is:  0.00013246387243270874\n",
      "The classification loss after processing this batch is:  22636.193359375\n",
      "The representation loss after processing this batch is:  0.00011210143566131592\n",
      "The classification loss after processing this batch is:  23276.626953125\n",
      "The representation loss after processing this batch is:  0.00011099874973297119\n",
      "The classification loss after processing this batch is:  25747.47265625\n",
      "The representation loss after processing this batch is:  0.0001536775380373001\n",
      "The classification loss after processing this batch is:  24552.447265625\n",
      "The representation loss after processing this batch is:  0.00012519769370555878\n",
      "The classification loss after processing this batch is:  23575.927734375\n",
      "The representation loss after processing this batch is:  0.000124368816614151\n",
      "The classification loss after processing this batch is:  22415.626953125\n",
      "The representation loss after processing this batch is:  0.00012785103172063828\n",
      "The classification loss after processing this batch is:  25410.68359375\n",
      "The representation loss after processing this batch is:  0.00013074278831481934\n",
      "The classification loss after processing this batch is:  25068.5859375\n",
      "The representation loss after processing this batch is:  0.00014484301209449768\n",
      "The classification loss after processing this batch is:  29576.7578125\n",
      "The representation loss after processing this batch is:  0.00012790225446224213\n",
      "The classification loss after processing this batch is:  25417.1875\n",
      "The representation loss after processing this batch is:  0.00011855363845825195\n",
      "The classification loss after processing this batch is:  23788.734375\n",
      "The representation loss after processing this batch is:  0.00013886205852031708\n",
      "The classification loss after processing this batch is:  25353.029296875\n",
      "The representation loss after processing this batch is:  0.00011704117059707642\n",
      "The classification loss after processing this batch is:  26324.423828125\n",
      "The representation loss after processing this batch is:  0.00014290492981672287\n",
      "The classification loss after processing this batch is:  25403.619140625\n",
      "The representation loss after processing this batch is:  0.00012259464710950851\n",
      "The classification loss after processing this batch is:  24934.5625\n",
      "The representation loss after processing this batch is:  0.00012329407036304474\n",
      "The classification loss after processing this batch is:  24716.76953125\n",
      "The representation loss after processing this batch is:  0.00010914541780948639\n",
      "The classification loss after processing this batch is:  24766.416015625\n",
      "The representation loss after processing this batch is:  0.0001217331737279892\n",
      "The classification loss after processing this batch is:  23680.17578125\n",
      "The representation loss after processing this batch is:  0.00011814385652542114\n",
      "The classification loss after processing this batch is:  24774.765625\n",
      "The representation loss after processing this batch is:  0.00012763962149620056\n",
      "The classification loss after processing this batch is:  24380.869140625\n",
      "The representation loss after processing this batch is:  0.00012161023914813995\n",
      "The classification loss after processing this batch is:  24748.109375\n",
      "The representation loss after processing this batch is:  0.00012573041021823883\n",
      "The classification loss after processing this batch is:  24872.515625\n",
      "The representation loss after processing this batch is:  0.00011370331048965454\n",
      "The classification loss after processing this batch is:  25059.3515625\n",
      "The representation loss after processing this batch is:  0.00012250803411006927\n",
      "The classification loss after processing this batch is:  23411.49609375\n",
      "The representation loss after processing this batch is:  0.00012468360364437103\n",
      "The classification loss after processing this batch is:  22958.361328125\n",
      "The representation loss after processing this batch is:  0.00013989023864269257\n",
      "The classification loss after processing this batch is:  23548.86328125\n",
      "The representation loss after processing this batch is:  0.00011999532580375671\n",
      "The classification loss after processing this batch is:  23292.275390625\n",
      "The representation loss after processing this batch is:  0.00010196585208177567\n",
      "The classification loss after processing this batch is:  24972.638671875\n",
      "The representation loss after processing this batch is:  0.0001226477324962616\n",
      "The classification loss after processing this batch is:  24391.5390625\n",
      "The representation loss after processing this batch is:  0.0001096697524189949\n",
      "The classification loss after processing this batch is:  23465.16796875\n",
      "The representation loss after processing this batch is:  0.00014883093535900116\n",
      "The classification loss after processing this batch is:  22581.080078125\n",
      "The representation loss after processing this batch is:  0.0001302771270275116\n",
      "The classification loss after processing this batch is:  22713.412109375\n",
      "The representation loss after processing this batch is:  0.00012713391333818436\n",
      "The classification loss after processing this batch is:  24236.34375\n",
      "The representation loss after processing this batch is:  0.00011797528713941574\n",
      "The classification loss after processing this batch is:  25250.73828125\n",
      "The representation loss after processing this batch is:  0.00011265743523836136\n",
      "The classification loss after processing this batch is:  25376.45703125\n",
      "The representation loss after processing this batch is:  0.00016548298299312592\n",
      "The classification loss after processing this batch is:  23264.58203125\n",
      "The representation loss after processing this batch is:  0.00012293830513954163\n",
      "The classification loss after processing this batch is:  24410.03515625\n",
      "The representation loss after processing this batch is:  0.00012534484267234802\n",
      "The classification loss after processing this batch is:  23534.0\n",
      "The representation loss after processing this batch is:  0.00013496167957782745\n",
      "The classification loss after processing this batch is:  23910.1328125\n",
      "The representation loss after processing this batch is:  0.00014808587729930878\n",
      "The classification loss after processing this batch is:  23314.11328125\n",
      "The representation loss after processing this batch is:  0.0001268181949853897\n",
      "The classification loss after processing this batch is:  23104.314453125\n",
      "The representation loss after processing this batch is:  0.00012446753680706024\n",
      "The classification loss after processing this batch is:  23155.265625\n",
      "The representation loss after processing this batch is:  0.00012371037155389786\n",
      "The classification loss after processing this batch is:  23843.447265625\n",
      "The representation loss after processing this batch is:  0.0001269988715648651\n",
      "The classification loss after processing this batch is:  23927.26953125\n",
      "The representation loss after processing this batch is:  0.000140506774187088\n",
      "The classification loss after processing this batch is:  24304.0390625\n",
      "The representation loss after processing this batch is:  0.0001371130347251892\n",
      "The classification loss after processing this batch is:  23874.82421875\n",
      "The representation loss after processing this batch is:  0.0001443084329366684\n",
      "The classification loss after processing this batch is:  23651.64453125\n",
      "The representation loss after processing this batch is:  0.000124368816614151\n",
      "The classification loss after processing this batch is:  25176.9609375\n",
      "The representation loss after processing this batch is:  0.00012651830911636353\n",
      "The classification loss after processing this batch is:  26282.68359375\n",
      "The representation loss after processing this batch is:  0.0001529734581708908\n",
      "The classification loss after processing this batch is:  25040.107421875\n",
      "The representation loss after processing this batch is:  0.00012713484466075897\n",
      "The classification loss after processing this batch is:  25087.57421875\n",
      "The representation loss after processing this batch is:  0.00013159401714801788\n",
      "The classification loss after processing this batch is:  23587.9296875\n",
      "The representation loss after processing this batch is:  0.000129014253616333\n",
      "The classification loss after processing this batch is:  23980.359375\n",
      "The representation loss after processing this batch is:  0.0001213783398270607\n",
      "The classification loss after processing this batch is:  25136.0859375\n",
      "The representation loss after processing this batch is:  0.00012957863509655\n",
      "The classification loss after processing this batch is:  23489.4140625\n",
      "The representation loss after processing this batch is:  0.0001406390219926834\n",
      "The classification loss after processing this batch is:  23407.806640625\n",
      "The representation loss after processing this batch is:  0.0001252293586730957\n",
      "The classification loss after processing this batch is:  24268.20703125\n",
      "The representation loss after processing this batch is:  0.00012559816241264343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24350.515625\n",
      "The representation loss after processing this batch is:  0.0001295618712902069\n",
      "The classification loss after processing this batch is:  24344.125\n",
      "The representation loss after processing this batch is:  0.00012278463691473007\n",
      "The classification loss after processing this batch is:  23659.3671875\n",
      "The representation loss after processing this batch is:  0.00012780353426933289\n",
      "The classification loss after processing this batch is:  24897.31640625\n",
      "The representation loss after processing this batch is:  0.0001351926475763321\n",
      "The classification loss after processing this batch is:  25064.193359375\n",
      "The representation loss after processing this batch is:  0.0001275148242712021\n",
      "The classification loss after processing this batch is:  25598.29296875\n",
      "The representation loss after processing this batch is:  0.0001255366951227188\n",
      "The classification loss after processing this batch is:  25376.802734375\n",
      "The representation loss after processing this batch is:  0.000142587348818779\n",
      "The classification loss after processing this batch is:  24473.9921875\n",
      "The representation loss after processing this batch is:  0.00012182537466287613\n",
      "The classification loss after processing this batch is:  23898.4296875\n",
      "The representation loss after processing this batch is:  0.00013023242354393005\n",
      "The classification loss after processing this batch is:  23966.203125\n",
      "The representation loss after processing this batch is:  0.00012570247054100037\n",
      "The classification loss after processing this batch is:  23662.6484375\n",
      "The representation loss after processing this batch is:  0.00011503323912620544\n",
      "The classification loss after processing this batch is:  23724.16015625\n",
      "The representation loss after processing this batch is:  0.00013031065464019775\n",
      "The classification loss after processing this batch is:  23359.73828125\n",
      "The representation loss after processing this batch is:  0.00013459473848342896\n",
      "The classification loss after processing this batch is:  24345.123046875\n",
      "The representation loss after processing this batch is:  0.00013602618128061295\n",
      "The classification loss after processing this batch is:  24030.43359375\n",
      "The representation loss after processing this batch is:  0.00013114511966705322\n",
      "The classification loss after processing this batch is:  27586.396484375\n",
      "The representation loss after processing this batch is:  0.00014229118824005127\n",
      "The classification loss after processing this batch is:  26519.546875\n",
      "The representation loss after processing this batch is:  0.00012011639773845673\n",
      "The classification loss after processing this batch is:  24207.03515625\n",
      "The representation loss after processing this batch is:  0.00012640003114938736\n",
      "The classification loss after processing this batch is:  22783.390625\n",
      "The representation loss after processing this batch is:  0.0001234970986843109\n",
      "The classification loss after processing this batch is:  23079.35546875\n",
      "The representation loss after processing this batch is:  0.00011780764907598495\n",
      "The classification loss after processing this batch is:  23771.923828125\n",
      "The representation loss after processing this batch is:  0.00014213845133781433\n",
      "The classification loss after processing this batch is:  23583.96484375\n",
      "The representation loss after processing this batch is:  0.00016480311751365662\n",
      "The classification loss after processing this batch is:  24287.80859375\n",
      "The representation loss after processing this batch is:  0.00011560320854187012\n",
      "The classification loss after processing this batch is:  24374.904296875\n",
      "The representation loss after processing this batch is:  0.00012285634875297546\n",
      "The classification loss after processing this batch is:  23612.96484375\n",
      "The representation loss after processing this batch is:  0.00011518597602844238\n",
      "The classification loss after processing this batch is:  23400.765625\n",
      "The representation loss after processing this batch is:  0.00011773128062486649\n",
      "The classification loss after processing this batch is:  24717.228515625\n",
      "The representation loss after processing this batch is:  0.0001194346696138382\n",
      "The classification loss after processing this batch is:  24981.1484375\n",
      "The representation loss after processing this batch is:  0.0001346040517091751\n",
      "The classification loss after processing this batch is:  23920.0625\n",
      "The representation loss after processing this batch is:  0.00012422073632478714\n",
      "The classification loss after processing this batch is:  25113.81640625\n",
      "The representation loss after processing this batch is:  0.0001432439312338829\n",
      "The classification loss after processing this batch is:  26755.12109375\n",
      "The representation loss after processing this batch is:  0.00013245455920696259\n",
      "The classification loss after processing this batch is:  25661.271484375\n",
      "The representation loss after processing this batch is:  0.0001363717019557953\n",
      "The classification loss after processing this batch is:  26753.30859375\n",
      "The representation loss after processing this batch is:  0.00013277307152748108\n",
      "The classification loss after processing this batch is:  24539.30859375\n",
      "The representation loss after processing this batch is:  0.00012669526040554047\n",
      "The classification loss after processing this batch is:  25580.30859375\n",
      "The representation loss after processing this batch is:  0.0001537613570690155\n",
      "The classification loss after processing this batch is:  24462.306640625\n",
      "The representation loss after processing this batch is:  0.0001420527696609497\n",
      "The classification loss after processing this batch is:  25236.953125\n",
      "The representation loss after processing this batch is:  0.00011999160051345825\n",
      "The classification loss after processing this batch is:  24550.4375\n",
      "The representation loss after processing this batch is:  0.00013035722076892853\n",
      "The classification loss after processing this batch is:  24210.1953125\n",
      "The representation loss after processing this batch is:  0.00012023374438285828\n",
      "The classification loss after processing this batch is:  24796.806640625\n",
      "The representation loss after processing this batch is:  0.0001164563000202179\n",
      "The classification loss after processing this batch is:  23897.533203125\n",
      "The representation loss after processing this batch is:  0.00012126006186008453\n",
      "The classification loss after processing this batch is:  24128.828125\n",
      "The representation loss after processing this batch is:  0.00011574476957321167\n",
      "The classification loss after processing this batch is:  23533.70703125\n",
      "The representation loss after processing this batch is:  0.00013131648302078247\n",
      "The classification loss after processing this batch is:  23630.064453125\n",
      "The representation loss after processing this batch is:  0.00011969730257987976\n",
      "The classification loss after processing this batch is:  23274.95703125\n",
      "The representation loss after processing this batch is:  0.000122731551527977\n",
      "The classification loss after processing this batch is:  24679.23046875\n",
      "The representation loss after processing this batch is:  0.00012951716780662537\n",
      "The classification loss after processing this batch is:  23969.037109375\n",
      "The representation loss after processing this batch is:  0.00014740414917469025\n",
      "The classification loss after processing this batch is:  24692.603515625\n",
      "The representation loss after processing this batch is:  0.00014172866940498352\n",
      "The classification loss after processing this batch is:  24707.26953125\n",
      "The representation loss after processing this batch is:  0.00011139828711748123\n",
      "The classification loss after processing this batch is:  23505.826171875\n",
      "The representation loss after processing this batch is:  0.00011415034532546997\n",
      "The classification loss after processing this batch is:  24450.681640625\n",
      "The representation loss after processing this batch is:  0.00011730194091796875\n",
      "The classification loss after processing this batch is:  24273.328125\n",
      "The representation loss after processing this batch is:  0.0001444350928068161\n",
      "The classification loss after processing this batch is:  23250.3671875\n",
      "The representation loss after processing this batch is:  0.00011320225894451141\n",
      "The classification loss after processing this batch is:  24467.7890625\n",
      "The representation loss after processing this batch is:  0.00012057740241289139\n",
      "The classification loss after processing this batch is:  24210.203125\n",
      "The representation loss after processing this batch is:  0.00013025570660829544\n",
      "The classification loss after processing this batch is:  23426.7734375\n",
      "The representation loss after processing this batch is:  0.00011661741882562637\n",
      "The classification loss after processing this batch is:  24351.970703125\n",
      "The representation loss after processing this batch is:  0.00011995621025562286\n",
      "The classification loss after processing this batch is:  23738.234375\n",
      "The representation loss after processing this batch is:  0.00012824125587940216\n",
      "The classification loss after processing this batch is:  25214.736328125\n",
      "The representation loss after processing this batch is:  0.00013994798064231873\n",
      "The classification loss after processing this batch is:  25634.58203125\n",
      "The representation loss after processing this batch is:  0.00011836830526590347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  23717.14453125\n",
      "The representation loss after processing this batch is:  0.0001416550949215889\n",
      "The classification loss after processing this batch is:  27111.3984375\n",
      "The representation loss after processing this batch is:  0.0001225639134645462\n",
      "The classification loss after processing this batch is:  27151.33203125\n",
      "The representation loss after processing this batch is:  0.00012979656457901\n",
      "The classification loss after processing this batch is:  23670.26953125\n",
      "The representation loss after processing this batch is:  0.00012790225446224213\n",
      "The classification loss after processing this batch is:  24586.53515625\n",
      "The representation loss after processing this batch is:  0.000125005841255188\n",
      "The classification loss after processing this batch is:  25831.57421875\n",
      "The representation loss after processing this batch is:  0.00013103708624839783\n",
      "The classification loss after processing this batch is:  24241.37109375\n",
      "The representation loss after processing this batch is:  0.00011968519538640976\n",
      "The classification loss after processing this batch is:  24448.01171875\n",
      "The representation loss after processing this batch is:  0.00014235638082027435\n",
      "The classification loss after processing this batch is:  24455.46484375\n",
      "The representation loss after processing this batch is:  0.00012292712926864624\n",
      "The classification loss after processing this batch is:  24659.28125\n",
      "The representation loss after processing this batch is:  0.00013973936438560486\n",
      "The classification loss after processing this batch is:  25587.541015625\n",
      "The representation loss after processing this batch is:  0.00011617224663496017\n",
      "The classification loss after processing this batch is:  25319.99609375\n",
      "The representation loss after processing this batch is:  0.00012890063226222992\n",
      "The classification loss after processing this batch is:  26735.146484375\n",
      "The representation loss after processing this batch is:  0.00012768618762493134\n",
      "The classification loss after processing this batch is:  25710.859375\n",
      "The representation loss after processing this batch is:  0.0001200549304485321\n",
      "The classification loss after processing this batch is:  25773.203125\n",
      "The representation loss after processing this batch is:  0.00011742021888494492\n",
      "The classification loss after processing this batch is:  23552.54296875\n",
      "The representation loss after processing this batch is:  0.00011867377907037735\n",
      "The classification loss after processing this batch is:  24095.0\n",
      "The representation loss after processing this batch is:  0.00012078508734703064\n",
      "The classification loss after processing this batch is:  25169.515625\n",
      "The representation loss after processing this batch is:  0.0001107044517993927\n",
      "The classification loss after processing this batch is:  23958.740234375\n",
      "The representation loss after processing this batch is:  0.00012918934226036072\n",
      "The classification loss after processing this batch is:  22747.607421875\n",
      "The representation loss after processing this batch is:  0.0001301877200603485\n",
      "The classification loss after processing this batch is:  25495.5078125\n",
      "The representation loss after processing this batch is:  0.00011976994574069977\n",
      "The classification loss after processing this batch is:  23433.07421875\n",
      "The representation loss after processing this batch is:  0.00011728797107934952\n",
      "The classification loss after processing this batch is:  23924.888671875\n",
      "The representation loss after processing this batch is:  0.00011969730257987976\n",
      "The classification loss after processing this batch is:  22997.30859375\n",
      "The representation loss after processing this batch is:  0.00011696480214595795\n",
      "The classification loss after processing this batch is:  24103.412109375\n",
      "The representation loss after processing this batch is:  0.00012087076902389526\n",
      "The classification loss after processing this batch is:  23093.6796875\n",
      "The representation loss after processing this batch is:  0.00013158656656742096\n",
      "The classification loss after processing this batch is:  24449.482421875\n",
      "The representation loss after processing this batch is:  0.0001463852822780609\n",
      "The classification loss after processing this batch is:  24154.232421875\n",
      "The representation loss after processing this batch is:  0.00010849442332983017\n",
      "The classification loss after processing this batch is:  23612.82421875\n",
      "The representation loss after processing this batch is:  0.00011754874140024185\n",
      "The classification loss after processing this batch is:  24982.30859375\n",
      "The representation loss after processing this batch is:  0.00013494398444890976\n",
      "The classification loss after processing this batch is:  25247.28125\n",
      "The representation loss after processing this batch is:  0.0001355540007352829\n",
      "The classification loss after processing this batch is:  23340.431640625\n",
      "The representation loss after processing this batch is:  0.00012051872909069061\n",
      "The classification loss after processing this batch is:  23590.455078125\n",
      "The representation loss after processing this batch is:  0.00012507662177085876\n",
      "The classification loss after processing this batch is:  24013.154296875\n",
      "The representation loss after processing this batch is:  0.00010644830763339996\n",
      "The classification loss after processing this batch is:  24097.650390625\n",
      "The representation loss after processing this batch is:  0.00011243484914302826\n",
      "The classification loss after processing this batch is:  25552.486328125\n",
      "The representation loss after processing this batch is:  0.00011851824820041656\n",
      "The classification loss after processing this batch is:  23927.2265625\n",
      "The representation loss after processing this batch is:  0.00010982155799865723\n",
      "The classification loss after processing this batch is:  23078.2109375\n",
      "The representation loss after processing this batch is:  0.00011939741671085358\n",
      "The classification loss after processing this batch is:  24084.015625\n",
      "The representation loss after processing this batch is:  0.00012666918337345123\n",
      "The classification loss after processing this batch is:  26082.328125\n",
      "The representation loss after processing this batch is:  0.000151781365275383\n",
      "The classification loss after processing this batch is:  23703.25\n",
      "The representation loss after processing this batch is:  0.00011193007230758667\n",
      "The classification loss after processing this batch is:  24550.115234375\n",
      "The representation loss after processing this batch is:  0.00012371409684419632\n",
      "The classification loss after processing this batch is:  26146.37890625\n",
      "The representation loss after processing this batch is:  0.00013790186494588852\n",
      "The classification loss after processing this batch is:  24089.216796875\n",
      "The representation loss after processing this batch is:  0.0001162337139248848\n",
      "The classification loss after processing this batch is:  23166.859375\n",
      "The representation loss after processing this batch is:  0.0001270221546292305\n",
      "The classification loss after processing this batch is:  23412.771484375\n",
      "The representation loss after processing this batch is:  0.00010860059410333633\n",
      "The classification loss after processing this batch is:  23356.02734375\n",
      "The representation loss after processing this batch is:  0.00010911654680967331\n",
      "The classification loss after processing this batch is:  23658.93359375\n",
      "The representation loss after processing this batch is:  0.000115981325507164\n",
      "The classification loss after processing this batch is:  23275.328125\n",
      "The representation loss after processing this batch is:  0.00013512186706066132\n",
      "The classification loss after processing this batch is:  23990.3828125\n",
      "The representation loss after processing this batch is:  0.00011845864355564117\n",
      "The classification loss after processing this batch is:  26820.75\n",
      "The representation loss after processing this batch is:  0.00012673437595367432\n",
      "The classification loss after processing this batch is:  25173.56640625\n",
      "The representation loss after processing this batch is:  0.00011644139885902405\n",
      "The classification loss after processing this batch is:  24298.89453125\n",
      "The representation loss after processing this batch is:  0.00011004786938428879\n",
      "The classification loss after processing this batch is:  23526.17578125\n",
      "The representation loss after processing this batch is:  0.00011575035750865936\n",
      "The classification loss after processing this batch is:  23912.80859375\n",
      "The representation loss after processing this batch is:  0.00014707259833812714\n",
      "The classification loss after processing this batch is:  23679.08203125\n",
      "The representation loss after processing this batch is:  0.00014413148164749146\n",
      "The classification loss after processing this batch is:  23483.98828125\n",
      "The representation loss after processing this batch is:  0.00011567864567041397\n",
      "The classification loss after processing this batch is:  22943.087890625\n",
      "The representation loss after processing this batch is:  0.00012115202844142914\n",
      "The classification loss after processing this batch is:  23617.044921875\n",
      "The representation loss after processing this batch is:  0.0001149103045463562\n",
      "The classification loss after processing this batch is:  23486.0703125\n",
      "The representation loss after processing this batch is:  0.00011218618601560593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22773.9921875\n",
      "The representation loss after processing this batch is:  0.00011894013732671738\n",
      "The classification loss after processing this batch is:  23804.3984375\n",
      "The representation loss after processing this batch is:  0.0001250719651579857\n",
      "The classification loss after processing this batch is:  22779.24609375\n",
      "The representation loss after processing this batch is:  0.00011952593922615051\n",
      "The classification loss after processing this batch is:  25049.3203125\n",
      "The representation loss after processing this batch is:  0.00011832825839519501\n",
      "The classification loss after processing this batch is:  24731.96875\n",
      "The representation loss after processing this batch is:  0.0001145433634519577\n",
      "The classification loss after processing this batch is:  23723.671875\n",
      "The representation loss after processing this batch is:  0.00010584387928247452\n",
      "The classification loss after processing this batch is:  23961.3515625\n",
      "The representation loss after processing this batch is:  0.00011515989899635315\n",
      "The classification loss after processing this batch is:  24155.6640625\n",
      "The representation loss after processing this batch is:  0.000123695470392704\n",
      "The classification loss after processing this batch is:  25649.921875\n",
      "The representation loss after processing this batch is:  0.00011775828897953033\n",
      "The classification loss after processing this batch is:  25130.828125\n",
      "The representation loss after processing this batch is:  0.00013437867164611816\n",
      "The classification loss after processing this batch is:  24090.66796875\n",
      "The representation loss after processing this batch is:  0.00012804009020328522\n",
      "The classification loss after processing this batch is:  24447.94921875\n",
      "The representation loss after processing this batch is:  0.00012398883700370789\n",
      "The classification loss after processing this batch is:  26018.69921875\n",
      "The representation loss after processing this batch is:  0.0001373477280139923\n",
      "The classification loss after processing this batch is:  23550.5625\n",
      "The representation loss after processing this batch is:  0.00012387428432703018\n",
      "The classification loss after processing this batch is:  24565.552734375\n",
      "The representation loss after processing this batch is:  0.00011874176561832428\n",
      "The classification loss after processing this batch is:  24421.125\n",
      "The representation loss after processing this batch is:  0.0001376364380121231\n",
      "The classification loss after processing this batch is:  24269.197265625\n",
      "The representation loss after processing this batch is:  0.00013106130063533783\n",
      "The classification loss after processing this batch is:  24970.21484375\n",
      "The representation loss after processing this batch is:  0.00014100037515163422\n",
      "The classification loss after processing this batch is:  25701.3984375\n",
      "The representation loss after processing this batch is:  0.00015954859554767609\n",
      "The classification loss after processing this batch is:  24255.8671875\n",
      "The representation loss after processing this batch is:  0.00014590099453926086\n",
      "The classification loss after processing this batch is:  25129.3125\n",
      "The representation loss after processing this batch is:  0.00013118889182806015\n",
      "The classification loss after processing this batch is:  25703.00390625\n",
      "The representation loss after processing this batch is:  0.00011659413576126099\n",
      "The classification loss after processing this batch is:  24035.60546875\n",
      "The representation loss after processing this batch is:  0.00013303570449352264\n",
      "The classification loss after processing this batch is:  25140.66796875\n",
      "The representation loss after processing this batch is:  0.0001176055520772934\n",
      "The classification loss after processing this batch is:  24559.17578125\n",
      "The representation loss after processing this batch is:  0.0001324377954006195\n",
      "The classification loss after processing this batch is:  23600.990234375\n",
      "The representation loss after processing this batch is:  0.0001263190060853958\n",
      "The classification loss after processing this batch is:  23858.30078125\n",
      "The representation loss after processing this batch is:  0.0001329127699136734\n",
      "The classification loss after processing this batch is:  23909.662109375\n",
      "The representation loss after processing this batch is:  0.00011500157415866852\n",
      "The classification loss after processing this batch is:  23823.6484375\n",
      "The representation loss after processing this batch is:  0.00012663472443819046\n",
      "The classification loss after processing this batch is:  25284.255859375\n",
      "The representation loss after processing this batch is:  0.00012074597179889679\n",
      "The classification loss after processing this batch is:  24918.28125\n",
      "The representation loss after processing this batch is:  0.00011464208364486694\n",
      "The classification loss after processing this batch is:  26331.86328125\n",
      "The representation loss after processing this batch is:  0.00013882294297218323\n",
      "The classification loss after processing this batch is:  23020.51953125\n",
      "The representation loss after processing this batch is:  0.00011297687888145447\n",
      "The classification loss after processing this batch is:  23222.13671875\n",
      "The representation loss after processing this batch is:  0.0001423414796590805\n",
      "The classification loss after processing this batch is:  23863.478515625\n",
      "The representation loss after processing this batch is:  0.0001529902219772339\n",
      "The classification loss after processing this batch is:  23676.83203125\n",
      "The representation loss after processing this batch is:  0.00011720694601535797\n",
      "The classification loss after processing this batch is:  25212.515625\n",
      "The representation loss after processing this batch is:  0.0001415703445672989\n",
      "The classification loss after processing this batch is:  24087.201171875\n",
      "The representation loss after processing this batch is:  0.00012049265205860138\n",
      "The classification loss after processing this batch is:  24306.4296875\n",
      "The representation loss after processing this batch is:  0.00011253543198108673\n",
      "The classification loss after processing this batch is:  24447.302734375\n",
      "The representation loss after processing this batch is:  0.0001214686781167984\n",
      "The classification loss after processing this batch is:  23654.734375\n",
      "The representation loss after processing this batch is:  0.0001281537115573883\n",
      "The classification loss after processing this batch is:  25251.84765625\n",
      "The representation loss after processing this batch is:  0.00015821214765310287\n",
      "The classification loss after processing this batch is:  25733.0625\n",
      "The representation loss after processing this batch is:  0.0001201871782541275\n",
      "The classification loss after processing this batch is:  25034.216796875\n",
      "The representation loss after processing this batch is:  0.0001172749325633049\n",
      "The classification loss after processing this batch is:  23289.3125\n",
      "The representation loss after processing this batch is:  0.0001175273209810257\n",
      "The classification loss after processing this batch is:  25396.451171875\n",
      "The representation loss after processing this batch is:  0.00012061744928359985\n",
      "The classification loss after processing this batch is:  25154.0625\n",
      "The representation loss after processing this batch is:  0.00011604093015193939\n",
      "The classification loss after processing this batch is:  23879.203125\n",
      "The representation loss after processing this batch is:  0.00011162087321281433\n",
      "The classification loss after processing this batch is:  26039.5546875\n",
      "The representation loss after processing this batch is:  0.00013342313468456268\n",
      "The classification loss after processing this batch is:  25831.3828125\n",
      "The representation loss after processing this batch is:  0.00014191865921020508\n",
      "The classification loss after processing this batch is:  23526.326171875\n",
      "The representation loss after processing this batch is:  0.00011526141315698624\n",
      "The classification loss after processing this batch is:  24084.318359375\n",
      "The representation loss after processing this batch is:  0.00011944212019443512\n",
      "The classification loss after processing this batch is:  24696.7578125\n",
      "The representation loss after processing this batch is:  0.00013852212578058243\n",
      "The classification loss after processing this batch is:  24295.4453125\n",
      "The representation loss after processing this batch is:  0.0001500248908996582\n",
      "The classification loss after processing this batch is:  24804.806640625\n",
      "The representation loss after processing this batch is:  0.00013496913015842438\n",
      "The classification loss after processing this batch is:  25462.169921875\n",
      "The representation loss after processing this batch is:  0.000160999596118927\n",
      "The classification loss after processing this batch is:  23432.439453125\n",
      "The representation loss after processing this batch is:  0.00013267993927001953\n",
      "The classification loss after processing this batch is:  23163.82421875\n",
      "The representation loss after processing this batch is:  0.00012869946658611298\n",
      "The classification loss after processing this batch is:  24609.322265625\n",
      "The representation loss after processing this batch is:  0.00010860525071620941\n",
      "The classification loss after processing this batch is:  25842.59765625\n",
      "The representation loss after processing this batch is:  0.00012012198567390442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24202.51953125\n",
      "The representation loss after processing this batch is:  0.00011691637337207794\n",
      "The classification loss after processing this batch is:  24709.15625\n",
      "The representation loss after processing this batch is:  0.00014104880392551422\n",
      "The classification loss after processing this batch is:  24545.1328125\n",
      "The representation loss after processing this batch is:  0.00010858196765184402\n",
      "The classification loss after processing this batch is:  24742.39453125\n",
      "The representation loss after processing this batch is:  0.00011534057557582855\n",
      "The classification loss after processing this batch is:  23731.431640625\n",
      "The representation loss after processing this batch is:  0.00013260077685117722\n",
      "The classification loss after processing this batch is:  23991.2578125\n",
      "The representation loss after processing this batch is:  0.00011609122157096863\n",
      "The classification loss after processing this batch is:  25196.8359375\n",
      "The representation loss after processing this batch is:  0.00011536106467247009\n",
      "The classification loss after processing this batch is:  22736.6953125\n",
      "The representation loss after processing this batch is:  0.00012743566185235977\n",
      "The classification loss after processing this batch is:  23138.46484375\n",
      "The representation loss after processing this batch is:  0.0001183096319437027\n",
      "The classification loss after processing this batch is:  22845.8671875\n",
      "The representation loss after processing this batch is:  0.00011921115219593048\n",
      "The classification loss after processing this batch is:  22831.02734375\n",
      "The representation loss after processing this batch is:  0.00012344028800725937\n",
      "The classification loss after processing this batch is:  23285.85546875\n",
      "The representation loss after processing this batch is:  0.00011918880045413971\n",
      "The classification loss after processing this batch is:  24668.4609375\n",
      "The representation loss after processing this batch is:  0.0001329546794295311\n",
      "The classification loss after processing this batch is:  24541.583984375\n",
      "The representation loss after processing this batch is:  0.00011880230158567429\n",
      "The classification loss after processing this batch is:  23069.41015625\n",
      "The representation loss after processing this batch is:  0.00012286938726902008\n",
      "The classification loss after processing this batch is:  23232.8359375\n",
      "The representation loss after processing this batch is:  0.000119796022772789\n",
      "The classification loss after processing this batch is:  23575.236328125\n",
      "The representation loss after processing this batch is:  0.00011327676475048065\n",
      "The classification loss after processing this batch is:  24044.802734375\n",
      "The representation loss after processing this batch is:  0.00013000145554542542\n",
      "The classification loss after processing this batch is:  24173.76171875\n",
      "The representation loss after processing this batch is:  0.00013091042637825012\n",
      "The classification loss after processing this batch is:  23349.52734375\n",
      "The representation loss after processing this batch is:  0.00013017840683460236\n",
      "The classification loss after processing this batch is:  25986.330078125\n",
      "The representation loss after processing this batch is:  0.00011049024760723114\n",
      "The classification loss after processing this batch is:  23650.91015625\n",
      "The representation loss after processing this batch is:  0.00011517200618982315\n",
      "The classification loss after processing this batch is:  23422.291015625\n",
      "The representation loss after processing this batch is:  0.00011214148253202438\n",
      "The classification loss after processing this batch is:  24028.376953125\n",
      "The representation loss after processing this batch is:  0.0001376662403345108\n",
      "The classification loss after processing this batch is:  24638.09765625\n",
      "The representation loss after processing this batch is:  0.00014182832092046738\n",
      "The classification loss after processing this batch is:  24173.0390625\n",
      "The representation loss after processing this batch is:  0.00011411681771278381\n",
      "The classification loss after processing this batch is:  23488.08203125\n",
      "The representation loss after processing this batch is:  0.00013847462832927704\n",
      "The classification loss after processing this batch is:  24371.25390625\n",
      "The representation loss after processing this batch is:  0.0001214146614074707\n",
      "The classification loss after processing this batch is:  25995.1484375\n",
      "The representation loss after processing this batch is:  0.00011825188994407654\n",
      "The classification loss after processing this batch is:  23092.84375\n",
      "The representation loss after processing this batch is:  0.00011448748409748077\n",
      "The classification loss after processing this batch is:  23900.359375\n",
      "The representation loss after processing this batch is:  0.00011135358363389969\n",
      "The classification loss after processing this batch is:  22511.6796875\n",
      "The representation loss after processing this batch is:  0.00013148225843906403\n",
      "The classification loss after processing this batch is:  23911.458984375\n",
      "The representation loss after processing this batch is:  0.0001153256744146347\n",
      "The classification loss after processing this batch is:  24053.609375\n",
      "The representation loss after processing this batch is:  0.00012545473873615265\n",
      "The classification loss after processing this batch is:  23513.01953125\n",
      "The representation loss after processing this batch is:  0.00012462399899959564\n",
      "The classification loss after processing this batch is:  23370.03125\n",
      "The representation loss after processing this batch is:  0.0001425705850124359\n",
      "The classification loss after processing this batch is:  22890.140625\n",
      "The representation loss after processing this batch is:  0.00010844320058822632\n",
      "The classification loss after processing this batch is:  23677.537109375\n",
      "The representation loss after processing this batch is:  0.00010798778384923935\n",
      "The classification loss after processing this batch is:  23379.189453125\n",
      "The representation loss after processing this batch is:  0.00013137701898813248\n",
      "The classification loss after processing this batch is:  22778.560546875\n",
      "The representation loss after processing this batch is:  0.00012194178998470306\n",
      "The classification loss after processing this batch is:  26864.810546875\n",
      "The representation loss after processing this batch is:  0.00011672452092170715\n",
      "The classification loss after processing this batch is:  25188.56640625\n",
      "The representation loss after processing this batch is:  0.0001217275857925415\n",
      "The classification loss after processing this batch is:  24569.029296875\n",
      "The representation loss after processing this batch is:  0.00013021379709243774\n",
      "The classification loss after processing this batch is:  23595.66015625\n",
      "The representation loss after processing this batch is:  0.00011943653225898743\n",
      "The classification loss after processing this batch is:  23066.6015625\n",
      "The representation loss after processing this batch is:  0.00013969838619232178\n",
      "The classification loss after processing this batch is:  23917.09765625\n",
      "The representation loss after processing this batch is:  0.0001253727823495865\n",
      "The classification loss after processing this batch is:  24673.37890625\n",
      "The representation loss after processing this batch is:  0.00013273581862449646\n",
      "The classification loss after processing this batch is:  23740.478515625\n",
      "The representation loss after processing this batch is:  0.00010860618203878403\n",
      "The classification loss after processing this batch is:  25832.33203125\n",
      "The representation loss after processing this batch is:  0.00012801773846149445\n",
      "The classification loss after processing this batch is:  23948.125\n",
      "The representation loss after processing this batch is:  0.00013193581253290176\n",
      "The classification loss after processing this batch is:  23153.4765625\n",
      "The representation loss after processing this batch is:  0.00012285634875297546\n",
      "The classification loss after processing this batch is:  24988.33984375\n",
      "The representation loss after processing this batch is:  0.00011756271123886108\n",
      "The classification loss after processing this batch is:  23310.072265625\n",
      "The representation loss after processing this batch is:  0.00011586956679821014\n",
      "The classification loss after processing this batch is:  23643.52734375\n",
      "The representation loss after processing this batch is:  0.00012475252151489258\n",
      "The classification loss after processing this batch is:  26901.921875\n",
      "The representation loss after processing this batch is:  0.00012650154531002045\n",
      "The classification loss after processing this batch is:  24711.37109375\n",
      "The representation loss after processing this batch is:  0.00014310888946056366\n",
      "The classification loss after processing this batch is:  23070.8125\n",
      "The representation loss after processing this batch is:  0.00014368072152137756\n",
      "The classification loss after processing this batch is:  22972.8828125\n",
      "The representation loss after processing this batch is:  0.00018310919404029846\n",
      "The classification loss after processing this batch is:  25784.775390625\n",
      "The representation loss after processing this batch is:  0.0001279246062040329\n",
      "The classification loss after processing this batch is:  23168.810546875\n",
      "The representation loss after processing this batch is:  0.00014546513557434082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  23134.78515625\n",
      "The representation loss after processing this batch is:  0.00015594996511936188\n",
      "The classification loss after processing this batch is:  23536.015625\n",
      "The representation loss after processing this batch is:  0.00015348754823207855\n",
      "The classification loss after processing this batch is:  28470.625\n",
      "The representation loss after processing this batch is:  0.00013796985149383545\n",
      "The classification loss after processing this batch is:  31318.4296875\n",
      "The representation loss after processing this batch is:  0.00013517215847969055\n",
      "The classification loss after processing this batch is:  22815.71875\n",
      "The representation loss after processing this batch is:  0.0001377798616886139\n",
      "The classification loss after processing this batch is:  24337.2890625\n",
      "The representation loss after processing this batch is:  0.0001360718160867691\n",
      "The classification loss after processing this batch is:  24104.17578125\n",
      "The representation loss after processing this batch is:  0.0001452285796403885\n",
      "The classification loss after processing this batch is:  21847.4765625\n",
      "The representation loss after processing this batch is:  0.00011971127241849899\n",
      "The classification loss after processing this batch is:  24183.94921875\n",
      "The representation loss after processing this batch is:  8.788704872131348e-05\n",
      "The classification loss after processing this batch is:  24438.3671875\n",
      "The representation loss after processing this batch is:  8.19014385342598e-05\n",
      "The classification loss after processing this batch is:  23309.13671875\n",
      "The representation loss after processing this batch is:  8.55717808008194e-05\n",
      "The classification loss after processing this batch is:  23675.84375\n",
      "The representation loss after processing this batch is:  8.410029113292694e-05\n",
      "The classification loss after processing this batch is:  23648.63671875\n",
      "The representation loss after processing this batch is:  8.224323391914368e-05\n",
      "The classification loss after processing this batch is:  23460.287109375\n",
      "The representation loss after processing this batch is:  7.502268999814987e-05\n",
      "The classification loss after processing this batch is:  23722.259765625\n",
      "The representation loss after processing this batch is:  9.571854025125504e-05\n",
      "The classification loss after processing this batch is:  23801.552734375\n",
      "The representation loss after processing this batch is:  7.393304258584976e-05\n",
      "The classification loss after processing this batch is:  23488.4453125\n",
      "The representation loss after processing this batch is:  7.705297321081161e-05\n",
      "The classification loss after processing this batch is:  27187.62109375\n",
      "The representation loss after processing this batch is:  7.582549005746841e-05\n",
      "The classification loss after processing this batch is:  25953.44140625\n",
      "The representation loss after processing this batch is:  6.971228867769241e-05\n",
      "The classification loss after processing this batch is:  23435.5859375\n",
      "The representation loss after processing this batch is:  7.614493370056152e-05\n",
      "The classification loss after processing this batch is:  23441.37109375\n",
      "The representation loss after processing this batch is:  6.804242730140686e-05\n",
      "The classification loss after processing this batch is:  23122.9296875\n",
      "The representation loss after processing this batch is:  7.625017315149307e-05\n",
      "The classification loss after processing this batch is:  23480.244140625\n",
      "The representation loss after processing this batch is:  7.522664964199066e-05\n",
      "The classification loss after processing this batch is:  24358.8046875\n",
      "The representation loss after processing this batch is:  7.718801498413086e-05\n",
      "The classification loss after processing this batch is:  23837.3671875\n",
      "The representation loss after processing this batch is:  6.812438368797302e-05\n",
      "The classification loss after processing this batch is:  25684.91015625\n",
      "The representation loss after processing this batch is:  7.547996938228607e-05\n",
      "The classification loss after processing this batch is:  24351.2109375\n",
      "The representation loss after processing this batch is:  6.823427975177765e-05\n",
      "The classification loss after processing this batch is:  24520.361328125\n",
      "The representation loss after processing this batch is:  7.532071322202682e-05\n",
      "The classification loss after processing this batch is:  24282.87890625\n",
      "The representation loss after processing this batch is:  6.80023804306984e-05\n",
      "The classification loss after processing this batch is:  24375.87109375\n",
      "The representation loss after processing this batch is:  6.975140422582626e-05\n",
      "The classification loss after processing this batch is:  24529.328125\n",
      "The representation loss after processing this batch is:  6.98678195476532e-05\n",
      "The classification loss after processing this batch is:  24190.876953125\n",
      "The representation loss after processing this batch is:  6.153061985969543e-05\n",
      "The classification loss after processing this batch is:  24103.24609375\n",
      "The representation loss after processing this batch is:  6.318837404251099e-05\n",
      "The classification loss after processing this batch is:  23326.71875\n",
      "The representation loss after processing this batch is:  6.677210330963135e-05\n",
      "The classification loss after processing this batch is:  23739.234375\n",
      "The representation loss after processing this batch is:  6.328988820314407e-05\n",
      "The classification loss after processing this batch is:  23671.06640625\n",
      "The representation loss after processing this batch is:  6.260257214307785e-05\n",
      "The classification loss after processing this batch is:  26200.06640625\n",
      "The representation loss after processing this batch is:  7.35986977815628e-05\n",
      "The classification loss after processing this batch is:  24613.873046875\n",
      "The representation loss after processing this batch is:  6.0558319091796875e-05\n",
      "The classification loss after processing this batch is:  23485.88671875\n",
      "The representation loss after processing this batch is:  6.2515027821064e-05\n",
      "The classification loss after processing this batch is:  24073.025390625\n",
      "The representation loss after processing this batch is:  6.158743053674698e-05\n",
      "The classification loss after processing this batch is:  23143.67578125\n",
      "The representation loss after processing this batch is:  6.53248280286789e-05\n",
      "The classification loss after processing this batch is:  23746.529296875\n",
      "The representation loss after processing this batch is:  6.636977195739746e-05\n",
      "The classification loss after processing this batch is:  23980.662109375\n",
      "The representation loss after processing this batch is:  6.325263530015945e-05\n",
      "The classification loss after processing this batch is:  23946.29296875\n",
      "The representation loss after processing this batch is:  7.260218262672424e-05\n",
      "The classification loss after processing this batch is:  25089.794921875\n",
      "The representation loss after processing this batch is:  6.223656237125397e-05\n",
      "The classification loss after processing this batch is:  28695.06640625\n",
      "The representation loss after processing this batch is:  7.95312225818634e-05\n",
      "The classification loss after processing this batch is:  23804.1328125\n",
      "The representation loss after processing this batch is:  6.321165710687637e-05\n",
      "The classification loss after processing this batch is:  24177.912109375\n",
      "The representation loss after processing this batch is:  5.948822945356369e-05\n",
      "The classification loss after processing this batch is:  24147.30859375\n",
      "The representation loss after processing this batch is:  6.888341158628464e-05\n",
      "The classification loss after processing this batch is:  24389.94140625\n",
      "The representation loss after processing this batch is:  7.483083754777908e-05\n",
      "The classification loss after processing this batch is:  23823.54296875\n",
      "The representation loss after processing this batch is:  6.0381367802619934e-05\n",
      "The classification loss after processing this batch is:  24288.35546875\n",
      "The representation loss after processing this batch is:  6.780214607715607e-05\n",
      "The classification loss after processing this batch is:  23979.171875\n",
      "The representation loss after processing this batch is:  6.411410868167877e-05\n",
      "The classification loss after processing this batch is:  23835.23046875\n",
      "The representation loss after processing this batch is:  6.80265948176384e-05\n",
      "The classification loss after processing this batch is:  23689.81640625\n",
      "The representation loss after processing this batch is:  6.199441850185394e-05\n",
      "The classification loss after processing this batch is:  23946.421875\n",
      "The representation loss after processing this batch is:  6.847456097602844e-05\n",
      "The classification loss after processing this batch is:  23539.849609375\n",
      "The representation loss after processing this batch is:  7.407553493976593e-05\n",
      "The classification loss after processing this batch is:  23467.216796875\n",
      "The representation loss after processing this batch is:  6.330758333206177e-05\n",
      "The classification loss after processing this batch is:  23270.947265625\n",
      "The representation loss after processing this batch is:  6.872881203889847e-05\n",
      "The classification loss after processing this batch is:  22150.41796875\n",
      "The representation loss after processing this batch is:  6.452854722738266e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  23183.42578125\n",
      "The representation loss after processing this batch is:  6.74491748213768e-05\n",
      "The classification loss after processing this batch is:  23465.3125\n",
      "The representation loss after processing this batch is:  6.849691271781921e-05\n",
      "The classification loss after processing this batch is:  23352.1328125\n",
      "The representation loss after processing this batch is:  5.7697296142578125e-05\n",
      "The classification loss after processing this batch is:  22953.72265625\n",
      "The representation loss after processing this batch is:  7.515493780374527e-05\n",
      "The classification loss after processing this batch is:  24520.45703125\n",
      "The representation loss after processing this batch is:  5.7416968047618866e-05\n",
      "The classification loss after processing this batch is:  23302.81640625\n",
      "The representation loss after processing this batch is:  6.037391722202301e-05\n",
      "The classification loss after processing this batch is:  22995.359375\n",
      "The representation loss after processing this batch is:  6.859377026557922e-05\n",
      "The classification loss after processing this batch is:  23677.62890625\n",
      "The representation loss after processing this batch is:  6.117019802331924e-05\n",
      "The classification loss after processing this batch is:  24918.23046875\n",
      "The representation loss after processing this batch is:  6.299745291471481e-05\n",
      "The classification loss after processing this batch is:  25832.041015625\n",
      "The representation loss after processing this batch is:  5.793571472167969e-05\n",
      "The classification loss after processing this batch is:  25307.64453125\n",
      "The representation loss after processing this batch is:  5.7957135140895844e-05\n",
      "The classification loss after processing this batch is:  22291.9609375\n",
      "The representation loss after processing this batch is:  6.179232150316238e-05\n",
      "The classification loss after processing this batch is:  24101.8046875\n",
      "The representation loss after processing this batch is:  5.613919347524643e-05\n",
      "The classification loss after processing this batch is:  23353.90625\n",
      "The representation loss after processing this batch is:  5.746539682149887e-05\n",
      "The classification loss after processing this batch is:  24358.8046875\n",
      "The representation loss after processing this batch is:  6.717443466186523e-05\n",
      "The classification loss after processing this batch is:  24690.53515625\n",
      "The representation loss after processing this batch is:  5.905516445636749e-05\n",
      "The classification loss after processing this batch is:  23453.16796875\n",
      "The representation loss after processing this batch is:  5.454476922750473e-05\n",
      "The classification loss after processing this batch is:  23612.29296875\n",
      "The representation loss after processing this batch is:  6.118696182966232e-05\n",
      "The classification loss after processing this batch is:  23847.83984375\n",
      "The representation loss after processing this batch is:  6.091594696044922e-05\n",
      "The classification loss after processing this batch is:  24522.06640625\n",
      "The representation loss after processing this batch is:  6.63483515381813e-05\n",
      "The classification loss after processing this batch is:  23458.50390625\n",
      "The representation loss after processing this batch is:  6.316415965557098e-05\n",
      "The classification loss after processing this batch is:  24320.953125\n",
      "The representation loss after processing this batch is:  6.659980863332748e-05\n",
      "The classification loss after processing this batch is:  24940.0390625\n",
      "The representation loss after processing this batch is:  5.991104990243912e-05\n",
      "The classification loss after processing this batch is:  25688.75390625\n",
      "The representation loss after processing this batch is:  8.077919483184814e-05\n",
      "The classification loss after processing this batch is:  23220.36328125\n",
      "The representation loss after processing this batch is:  6.469432264566422e-05\n",
      "The classification loss after processing this batch is:  23010.84765625\n",
      "The representation loss after processing this batch is:  6.463658064603806e-05\n",
      "The classification loss after processing this batch is:  23044.603515625\n",
      "The representation loss after processing this batch is:  5.946308374404907e-05\n",
      "The classification loss after processing this batch is:  24331.689453125\n",
      "The representation loss after processing this batch is:  5.607260391116142e-05\n",
      "The classification loss after processing this batch is:  25578.9453125\n",
      "The representation loss after processing this batch is:  5.718600004911423e-05\n",
      "The classification loss after processing this batch is:  23690.818359375\n",
      "The representation loss after processing this batch is:  6.701238453388214e-05\n",
      "The classification loss after processing this batch is:  22795.08984375\n",
      "The representation loss after processing this batch is:  6.052199751138687e-05\n",
      "The classification loss after processing this batch is:  23185.65234375\n",
      "The representation loss after processing this batch is:  6.284844130277634e-05\n",
      "The classification loss after processing this batch is:  22413.431640625\n",
      "The representation loss after processing this batch is:  5.584303289651871e-05\n",
      "The classification loss after processing this batch is:  22807.681640625\n",
      "The representation loss after processing this batch is:  5.805119872093201e-05\n",
      "The classification loss after processing this batch is:  22884.68359375\n",
      "The representation loss after processing this batch is:  6.084982305765152e-05\n",
      "The classification loss after processing this batch is:  22713.3125\n",
      "The representation loss after processing this batch is:  5.6224875152111053e-05\n",
      "The classification loss after processing this batch is:  22456.111328125\n",
      "The representation loss after processing this batch is:  5.810149013996124e-05\n",
      "The classification loss after processing this batch is:  22328.5390625\n",
      "The representation loss after processing this batch is:  6.311945617198944e-05\n",
      "The classification loss after processing this batch is:  22795.30078125\n",
      "The representation loss after processing this batch is:  5.582626909017563e-05\n",
      "The classification loss after processing this batch is:  22411.775390625\n",
      "The representation loss after processing this batch is:  5.7044439017772675e-05\n",
      "The classification loss after processing this batch is:  22419.6171875\n",
      "The representation loss after processing this batch is:  5.915481597185135e-05\n",
      "The classification loss after processing this batch is:  22552.5625\n",
      "The representation loss after processing this batch is:  6.183236837387085e-05\n",
      "The classification loss after processing this batch is:  21972.091796875\n",
      "The representation loss after processing this batch is:  6.387103348970413e-05\n",
      "The classification loss after processing this batch is:  23966.5234375\n",
      "The representation loss after processing this batch is:  5.4366886615753174e-05\n",
      "The classification loss after processing this batch is:  23686.828125\n",
      "The representation loss after processing this batch is:  5.6403689086437225e-05\n",
      "The classification loss after processing this batch is:  24667.97265625\n",
      "The representation loss after processing this batch is:  5.641672760248184e-05\n",
      "The classification loss after processing this batch is:  25107.515625\n",
      "The representation loss after processing this batch is:  6.991904228925705e-05\n",
      "The classification loss after processing this batch is:  24702.55078125\n",
      "The representation loss after processing this batch is:  6.37667253613472e-05\n",
      "The classification loss after processing this batch is:  23718.38671875\n",
      "The representation loss after processing this batch is:  6.507150828838348e-05\n",
      "The classification loss after processing this batch is:  23770.654296875\n",
      "The representation loss after processing this batch is:  6.271433085203171e-05\n",
      "The classification loss after processing this batch is:  23281.90234375\n",
      "The representation loss after processing this batch is:  6.407313048839569e-05\n",
      "The classification loss after processing this batch is:  23805.0078125\n",
      "The representation loss after processing this batch is:  6.154552102088928e-05\n",
      "The classification loss after processing this batch is:  22980.4296875\n",
      "The representation loss after processing this batch is:  5.6741759181022644e-05\n",
      "The classification loss after processing this batch is:  22814.9453125\n",
      "The representation loss after processing this batch is:  6.235670298337936e-05\n",
      "The classification loss after processing this batch is:  23856.59765625\n",
      "The representation loss after processing this batch is:  5.605444312095642e-05\n",
      "The classification loss after processing this batch is:  23508.3984375\n",
      "The representation loss after processing this batch is:  6.580818444490433e-05\n",
      "The classification loss after processing this batch is:  23073.05078125\n",
      "The representation loss after processing this batch is:  5.786307156085968e-05\n",
      "The classification loss after processing this batch is:  24214.439453125\n",
      "The representation loss after processing this batch is:  6.24312087893486e-05\n",
      "The classification loss after processing this batch is:  27071.615234375\n",
      "The representation loss after processing this batch is:  6.325449794530869e-05\n",
      "The classification loss after processing this batch is:  24702.0234375\n",
      "The representation loss after processing this batch is:  6.986968219280243e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  23038.28125\n",
      "The representation loss after processing this batch is:  5.3291674703359604e-05\n",
      "The classification loss after processing this batch is:  23320.46875\n",
      "The representation loss after processing this batch is:  6.287358701229095e-05\n",
      "The classification loss after processing this batch is:  27234.142578125\n",
      "The representation loss after processing this batch is:  6.607268005609512e-05\n",
      "The classification loss after processing this batch is:  27499.05078125\n",
      "The representation loss after processing this batch is:  7.937196642160416e-05\n",
      "The classification loss after processing this batch is:  22725.31640625\n",
      "The representation loss after processing this batch is:  6.246846169233322e-05\n",
      "The classification loss after processing this batch is:  22456.0703125\n",
      "The representation loss after processing this batch is:  6.30505383014679e-05\n",
      "The classification loss after processing this batch is:  22965.8671875\n",
      "The representation loss after processing this batch is:  6.0078687965869904e-05\n",
      "The classification loss after processing this batch is:  23458.83984375\n",
      "The representation loss after processing this batch is:  6.059184670448303e-05\n",
      "The classification loss after processing this batch is:  23472.9765625\n",
      "The representation loss after processing this batch is:  5.730427801609039e-05\n",
      "The classification loss after processing this batch is:  23268.556640625\n",
      "The representation loss after processing this batch is:  5.979742854833603e-05\n",
      "The classification loss after processing this batch is:  24465.75\n",
      "The representation loss after processing this batch is:  5.504675209522247e-05\n",
      "The classification loss after processing this batch is:  25500.056640625\n",
      "The representation loss after processing this batch is:  6.518885493278503e-05\n",
      "The classification loss after processing this batch is:  23112.107421875\n",
      "The representation loss after processing this batch is:  6.930343806743622e-05\n",
      "The classification loss after processing this batch is:  23735.576171875\n",
      "The representation loss after processing this batch is:  5.809031426906586e-05\n",
      "The classification loss after processing this batch is:  22535.34765625\n",
      "The representation loss after processing this batch is:  5.329865962266922e-05\n",
      "The classification loss after processing this batch is:  22585.822265625\n",
      "The representation loss after processing this batch is:  6.043631583452225e-05\n",
      "The classification loss after processing this batch is:  21971.755859375\n",
      "The representation loss after processing this batch is:  5.978252738714218e-05\n",
      "The classification loss after processing this batch is:  23285.361328125\n",
      "The representation loss after processing this batch is:  7.925089448690414e-05\n",
      "The classification loss after processing this batch is:  22826.654296875\n",
      "The representation loss after processing this batch is:  5.866494029760361e-05\n",
      "The classification loss after processing this batch is:  25423.890625\n",
      "The representation loss after processing this batch is:  6.271060556173325e-05\n",
      "The classification loss after processing this batch is:  23219.015625\n",
      "The representation loss after processing this batch is:  6.12996518611908e-05\n",
      "The classification loss after processing this batch is:  23235.66015625\n",
      "The representation loss after processing this batch is:  5.670823156833649e-05\n",
      "The classification loss after processing this batch is:  24706.88671875\n",
      "The representation loss after processing this batch is:  6.534531712532043e-05\n",
      "The classification loss after processing this batch is:  24377.36328125\n",
      "The representation loss after processing this batch is:  5.9341080486774445e-05\n",
      "The classification loss after processing this batch is:  23806.505859375\n",
      "The representation loss after processing this batch is:  6.358418613672256e-05\n",
      "The classification loss after processing this batch is:  25054.6015625\n",
      "The representation loss after processing this batch is:  6.0399994254112244e-05\n",
      "The classification loss after processing this batch is:  23258.556640625\n",
      "The representation loss after processing this batch is:  5.511101335287094e-05\n",
      "The classification loss after processing this batch is:  23978.4140625\n",
      "The representation loss after processing this batch is:  6.068497896194458e-05\n",
      "The classification loss after processing this batch is:  22518.466796875\n",
      "The representation loss after processing this batch is:  5.581602454185486e-05\n",
      "The classification loss after processing this batch is:  22503.673828125\n",
      "The representation loss after processing this batch is:  6.0002319514751434e-05\n",
      "The classification loss after processing this batch is:  22827.025390625\n",
      "The representation loss after processing this batch is:  6.217416375875473e-05\n",
      "The classification loss after processing this batch is:  22764.12109375\n",
      "The representation loss after processing this batch is:  6.735138595104218e-05\n",
      "The classification loss after processing this batch is:  22677.591796875\n",
      "The representation loss after processing this batch is:  6.476789712905884e-05\n",
      "The classification loss after processing this batch is:  25134.099609375\n",
      "The representation loss after processing this batch is:  6.38747587800026e-05\n",
      "The classification loss after processing this batch is:  22609.33984375\n",
      "The representation loss after processing this batch is:  6.175599992275238e-05\n",
      "The classification loss after processing this batch is:  22893.15625\n",
      "The representation loss after processing this batch is:  5.565956234931946e-05\n",
      "The classification loss after processing this batch is:  23609.34765625\n",
      "The representation loss after processing this batch is:  5.62518835067749e-05\n",
      "The classification loss after processing this batch is:  22928.1484375\n",
      "The representation loss after processing this batch is:  5.842279642820358e-05\n",
      "The classification loss after processing this batch is:  23736.66015625\n",
      "The representation loss after processing this batch is:  6.771460175514221e-05\n",
      "The classification loss after processing this batch is:  23591.67578125\n",
      "The representation loss after processing this batch is:  5.914270877838135e-05\n",
      "The classification loss after processing this batch is:  23332.765625\n",
      "The representation loss after processing this batch is:  6.638374179601669e-05\n",
      "The classification loss after processing this batch is:  21956.294921875\n",
      "The representation loss after processing this batch is:  5.556829273700714e-05\n",
      "The classification loss after processing this batch is:  23527.875\n",
      "The representation loss after processing this batch is:  6.0558319091796875e-05\n",
      "The classification loss after processing this batch is:  26093.5078125\n",
      "The representation loss after processing this batch is:  6.459001451730728e-05\n",
      "The classification loss after processing this batch is:  26598.34765625\n",
      "The representation loss after processing this batch is:  6.825476884841919e-05\n",
      "The classification loss after processing this batch is:  23356.330078125\n",
      "The representation loss after processing this batch is:  5.816854536533356e-05\n",
      "The classification loss after processing this batch is:  23294.279296875\n",
      "The representation loss after processing this batch is:  5.212519317865372e-05\n",
      "The classification loss after processing this batch is:  23046.66796875\n",
      "The representation loss after processing this batch is:  5.445070564746857e-05\n",
      "The classification loss after processing this batch is:  23827.3046875\n",
      "The representation loss after processing this batch is:  6.35385513305664e-05\n",
      "The classification loss after processing this batch is:  22900.65625\n",
      "The representation loss after processing this batch is:  6.299186497926712e-05\n",
      "The classification loss after processing this batch is:  23248.078125\n",
      "The representation loss after processing this batch is:  5.313195288181305e-05\n",
      "The classification loss after processing this batch is:  24790.5546875\n",
      "The representation loss after processing this batch is:  6.31650909781456e-05\n",
      "The classification loss after processing this batch is:  21965.69921875\n",
      "The representation loss after processing this batch is:  5.465373396873474e-05\n",
      "The classification loss after processing this batch is:  22448.34375\n",
      "The representation loss after processing this batch is:  6.311200559139252e-05\n",
      "The classification loss after processing this batch is:  24467.15234375\n",
      "The representation loss after processing this batch is:  7.438007742166519e-05\n",
      "The classification loss after processing this batch is:  23413.162109375\n",
      "The representation loss after processing this batch is:  6.984826177358627e-05\n",
      "The classification loss after processing this batch is:  22755.98046875\n",
      "The representation loss after processing this batch is:  6.279163062572479e-05\n",
      "The classification loss after processing this batch is:  21564.095703125\n",
      "The representation loss after processing this batch is:  5.507003515958786e-05\n",
      "The classification loss after processing this batch is:  24503.572265625\n",
      "The representation loss after processing this batch is:  6.636511534452438e-05\n",
      "The classification loss after processing this batch is:  24046.8125\n",
      "The representation loss after processing this batch is:  7.856078445911407e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  28431.6328125\n",
      "The representation loss after processing this batch is:  6.569549441337585e-05\n",
      "The classification loss after processing this batch is:  24529.919921875\n",
      "The representation loss after processing this batch is:  5.929917097091675e-05\n",
      "The classification loss after processing this batch is:  22822.353515625\n",
      "The representation loss after processing this batch is:  5.913805216550827e-05\n",
      "The classification loss after processing this batch is:  24325.56640625\n",
      "The representation loss after processing this batch is:  5.2372924983501434e-05\n",
      "The classification loss after processing this batch is:  25380.162109375\n",
      "The representation loss after processing this batch is:  5.8778561651706696e-05\n",
      "The classification loss after processing this batch is:  24539.86328125\n",
      "The representation loss after processing this batch is:  5.787983536720276e-05\n",
      "The classification loss after processing this batch is:  23868.599609375\n",
      "The representation loss after processing this batch is:  5.724374204874039e-05\n",
      "The classification loss after processing this batch is:  23767.91015625\n",
      "The representation loss after processing this batch is:  5.892757326364517e-05\n",
      "The classification loss after processing this batch is:  23768.4921875\n",
      "The representation loss after processing this batch is:  6.052432581782341e-05\n",
      "The classification loss after processing this batch is:  22627.328125\n",
      "The representation loss after processing this batch is:  6.039813160896301e-05\n",
      "The classification loss after processing this batch is:  23819.7890625\n",
      "The representation loss after processing this batch is:  6.815232336521149e-05\n",
      "The classification loss after processing this batch is:  23559.89453125\n",
      "The representation loss after processing this batch is:  5.535408854484558e-05\n",
      "The classification loss after processing this batch is:  24122.453125\n",
      "The representation loss after processing this batch is:  6.474275141954422e-05\n",
      "The classification loss after processing this batch is:  24190.2578125\n",
      "The representation loss after processing this batch is:  5.672965198755264e-05\n",
      "The classification loss after processing this batch is:  24365.8671875\n",
      "The representation loss after processing this batch is:  6.558187305927277e-05\n",
      "The classification loss after processing this batch is:  22849.05859375\n",
      "The representation loss after processing this batch is:  5.805399268865585e-05\n",
      "The classification loss after processing this batch is:  22350.7578125\n",
      "The representation loss after processing this batch is:  6.497930735349655e-05\n",
      "The classification loss after processing this batch is:  22984.529296875\n",
      "The representation loss after processing this batch is:  5.73405995965004e-05\n",
      "The classification loss after processing this batch is:  22565.447265625\n",
      "The representation loss after processing this batch is:  5.5324286222457886e-05\n",
      "The classification loss after processing this batch is:  24074.7734375\n",
      "The representation loss after processing this batch is:  5.9703364968299866e-05\n",
      "The classification loss after processing this batch is:  23659.66015625\n",
      "The representation loss after processing this batch is:  5.560833960771561e-05\n",
      "The classification loss after processing this batch is:  22906.44921875\n",
      "The representation loss after processing this batch is:  6.115343421697617e-05\n",
      "The classification loss after processing this batch is:  21873.736328125\n",
      "The representation loss after processing this batch is:  6.0197897255420685e-05\n",
      "The classification loss after processing this batch is:  21972.166015625\n",
      "The representation loss after processing this batch is:  5.534198135137558e-05\n",
      "The classification loss after processing this batch is:  23527.328125\n",
      "The representation loss after processing this batch is:  5.814991891384125e-05\n",
      "The classification loss after processing this batch is:  24499.515625\n",
      "The representation loss after processing this batch is:  5.532987415790558e-05\n",
      "The classification loss after processing this batch is:  24575.796875\n",
      "The representation loss after processing this batch is:  8.009187877178192e-05\n",
      "The classification loss after processing this batch is:  22525.71875\n",
      "The representation loss after processing this batch is:  5.497317761182785e-05\n",
      "The classification loss after processing this batch is:  23436.2421875\n",
      "The representation loss after processing this batch is:  6.2575563788414e-05\n",
      "The classification loss after processing this batch is:  22671.890625\n",
      "The representation loss after processing this batch is:  6.455648690462112e-05\n",
      "The classification loss after processing this batch is:  23005.46484375\n",
      "The representation loss after processing this batch is:  6.626080721616745e-05\n",
      "The classification loss after processing this batch is:  22429.96484375\n",
      "The representation loss after processing this batch is:  5.6755729019641876e-05\n",
      "The classification loss after processing this batch is:  22021.328125\n",
      "The representation loss after processing this batch is:  5.884002894163132e-05\n",
      "The classification loss after processing this batch is:  21848.55078125\n",
      "The representation loss after processing this batch is:  5.782581865787506e-05\n",
      "The classification loss after processing this batch is:  22696.66796875\n",
      "The representation loss after processing this batch is:  6.701704114675522e-05\n",
      "The classification loss after processing this batch is:  22839.591796875\n",
      "The representation loss after processing this batch is:  6.238743662834167e-05\n",
      "The classification loss after processing this batch is:  23152.275390625\n",
      "The representation loss after processing this batch is:  5.922466516494751e-05\n",
      "The classification loss after processing this batch is:  22841.46484375\n",
      "The representation loss after processing this batch is:  6.425846368074417e-05\n",
      "The classification loss after processing this batch is:  22402.71484375\n",
      "The representation loss after processing this batch is:  5.379971116781235e-05\n",
      "The classification loss after processing this batch is:  24080.5234375\n",
      "The representation loss after processing this batch is:  5.971826612949371e-05\n",
      "The classification loss after processing this batch is:  25264.1875\n",
      "The representation loss after processing this batch is:  7.360056042671204e-05\n",
      "The classification loss after processing this batch is:  24138.515625\n",
      "The representation loss after processing this batch is:  6.703753024339676e-05\n",
      "The classification loss after processing this batch is:  24124.658203125\n",
      "The representation loss after processing this batch is:  7.143989205360413e-05\n",
      "The classification loss after processing this batch is:  22466.6328125\n",
      "The representation loss after processing this batch is:  6.380584090948105e-05\n",
      "The classification loss after processing this batch is:  22947.15625\n",
      "The representation loss after processing this batch is:  5.3826719522476196e-05\n",
      "The classification loss after processing this batch is:  24163.287109375\n",
      "The representation loss after processing this batch is:  7.016584277153015e-05\n",
      "The classification loss after processing this batch is:  22253.20703125\n",
      "The representation loss after processing this batch is:  6.754137575626373e-05\n",
      "The classification loss after processing this batch is:  22303.673828125\n",
      "The representation loss after processing this batch is:  6.1032362282276154e-05\n",
      "The classification loss after processing this batch is:  23331.611328125\n",
      "The representation loss after processing this batch is:  5.6383199989795685e-05\n",
      "The classification loss after processing this batch is:  23236.5625\n",
      "The representation loss after processing this batch is:  5.4255127906799316e-05\n",
      "The classification loss after processing this batch is:  23113.541015625\n",
      "The representation loss after processing this batch is:  5.332473665475845e-05\n",
      "The classification loss after processing this batch is:  22607.58203125\n",
      "The representation loss after processing this batch is:  6.555765867233276e-05\n",
      "The classification loss after processing this batch is:  23984.5\n",
      "The representation loss after processing this batch is:  6.804242730140686e-05\n",
      "The classification loss after processing this batch is:  24107.427734375\n",
      "The representation loss after processing this batch is:  6.102956831455231e-05\n",
      "The classification loss after processing this batch is:  24510.5234375\n",
      "The representation loss after processing this batch is:  5.086371675133705e-05\n",
      "The classification loss after processing this batch is:  24709.2890625\n",
      "The representation loss after processing this batch is:  5.9316400438547134e-05\n",
      "The classification loss after processing this batch is:  23527.1171875\n",
      "The representation loss after processing this batch is:  5.9720128774642944e-05\n",
      "The classification loss after processing this batch is:  22692.640625\n",
      "The representation loss after processing this batch is:  6.82435929775238e-05\n",
      "The classification loss after processing this batch is:  22554.013671875\n",
      "The representation loss after processing this batch is:  6.210338324308395e-05\n",
      "The classification loss after processing this batch is:  22504.48828125\n",
      "The representation loss after processing this batch is:  5.386676639318466e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22906.03125\n",
      "The representation loss after processing this batch is:  5.9219542890787125e-05\n",
      "The classification loss after processing this batch is:  22367.51953125\n",
      "The representation loss after processing this batch is:  5.2751973271369934e-05\n",
      "The classification loss after processing this batch is:  23233.46875\n",
      "The representation loss after processing this batch is:  5.602836608886719e-05\n",
      "The classification loss after processing this batch is:  23054.234375\n",
      "The representation loss after processing this batch is:  6.0634687542915344e-05\n",
      "The classification loss after processing this batch is:  25903.421875\n",
      "The representation loss after processing this batch is:  7.221288979053497e-05\n",
      "The classification loss after processing this batch is:  25093.84765625\n",
      "The representation loss after processing this batch is:  6.008800119161606e-05\n",
      "The classification loss after processing this batch is:  23046.50390625\n",
      "The representation loss after processing this batch is:  6.0284044593572617e-05\n",
      "The classification loss after processing this batch is:  21821.625\n",
      "The representation loss after processing this batch is:  6.474647670984268e-05\n",
      "The classification loss after processing this batch is:  22098.29296875\n",
      "The representation loss after processing this batch is:  6.154179573059082e-05\n",
      "The classification loss after processing this batch is:  23056.515625\n",
      "The representation loss after processing this batch is:  6.858166307210922e-05\n",
      "The classification loss after processing this batch is:  22654.46484375\n",
      "The representation loss after processing this batch is:  6.286613643169403e-05\n",
      "The classification loss after processing this batch is:  23357.61328125\n",
      "The representation loss after processing this batch is:  6.289500743150711e-05\n",
      "The classification loss after processing this batch is:  22878.140625\n",
      "The representation loss after processing this batch is:  5.58728352189064e-05\n",
      "The classification loss after processing this batch is:  22193.09765625\n",
      "The representation loss after processing this batch is:  4.761572927236557e-05\n",
      "The classification loss after processing this batch is:  21950.423828125\n",
      "The representation loss after processing this batch is:  5.252379924058914e-05\n",
      "The classification loss after processing this batch is:  23580.921875\n",
      "The representation loss after processing this batch is:  5.4039061069488525e-05\n",
      "The classification loss after processing this batch is:  24228.20703125\n",
      "The representation loss after processing this batch is:  6.89169391989708e-05\n",
      "The classification loss after processing this batch is:  22677.4609375\n",
      "The representation loss after processing this batch is:  7.489509880542755e-05\n",
      "The classification loss after processing this batch is:  23361.74609375\n",
      "The representation loss after processing this batch is:  6.003770977258682e-05\n",
      "The classification loss after processing this batch is:  24827.751953125\n",
      "The representation loss after processing this batch is:  6.316788494586945e-05\n",
      "The classification loss after processing this batch is:  23731.724609375\n",
      "The representation loss after processing this batch is:  5.705747753381729e-05\n",
      "The classification loss after processing this batch is:  25189.703125\n",
      "The representation loss after processing this batch is:  6.173178553581238e-05\n",
      "The classification loss after processing this batch is:  22887.86328125\n",
      "The representation loss after processing this batch is:  5.605071783065796e-05\n",
      "The classification loss after processing this batch is:  24019.26953125\n",
      "The representation loss after processing this batch is:  7.879827171564102e-05\n",
      "The classification loss after processing this batch is:  22806.634765625\n",
      "The representation loss after processing this batch is:  6.192456930875778e-05\n",
      "The classification loss after processing this batch is:  23570.685546875\n",
      "The representation loss after processing this batch is:  5.632452666759491e-05\n",
      "The classification loss after processing this batch is:  23237.33984375\n",
      "The representation loss after processing this batch is:  5.893968045711517e-05\n",
      "The classification loss after processing this batch is:  23041.525390625\n",
      "The representation loss after processing this batch is:  6.26416876912117e-05\n",
      "The classification loss after processing this batch is:  23642.953125\n",
      "The representation loss after processing this batch is:  5.7299621403217316e-05\n",
      "The classification loss after processing this batch is:  22550.291015625\n",
      "The representation loss after processing this batch is:  6.109569221735e-05\n",
      "The classification loss after processing this batch is:  22817.8046875\n",
      "The representation loss after processing this batch is:  6.365496665239334e-05\n",
      "The classification loss after processing this batch is:  21970.525390625\n",
      "The representation loss after processing this batch is:  5.7666562497615814e-05\n",
      "The classification loss after processing this batch is:  22116.7734375\n",
      "The representation loss after processing this batch is:  6.768573075532913e-05\n",
      "The classification loss after processing this batch is:  21939.123046875\n",
      "The representation loss after processing this batch is:  5.699042230844498e-05\n",
      "The classification loss after processing this batch is:  23481.900390625\n",
      "The representation loss after processing this batch is:  6.0644932091236115e-05\n",
      "The classification loss after processing this batch is:  22860.244140625\n",
      "The representation loss after processing this batch is:  6.220489740371704e-05\n",
      "The classification loss after processing this batch is:  23497.94921875\n",
      "The representation loss after processing this batch is:  5.939323455095291e-05\n",
      "The classification loss after processing this batch is:  23636.4296875\n",
      "The representation loss after processing this batch is:  5.6125689297914505e-05\n",
      "The classification loss after processing this batch is:  22285.431640625\n",
      "The representation loss after processing this batch is:  5.466863512992859e-05\n",
      "The classification loss after processing this batch is:  23340.140625\n",
      "The representation loss after processing this batch is:  6.489735096693039e-05\n",
      "The classification loss after processing this batch is:  23058.591796875\n",
      "The representation loss after processing this batch is:  7.239263504743576e-05\n",
      "The classification loss after processing this batch is:  22078.470703125\n",
      "The representation loss after processing this batch is:  5.9734098613262177e-05\n",
      "The classification loss after processing this batch is:  23245.6484375\n",
      "The representation loss after processing this batch is:  5.5450014770030975e-05\n",
      "The classification loss after processing this batch is:  23011.71484375\n",
      "The representation loss after processing this batch is:  6.0653313994407654e-05\n",
      "The classification loss after processing this batch is:  22318.146484375\n",
      "The representation loss after processing this batch is:  5.9975311160087585e-05\n",
      "The classification loss after processing this batch is:  23135.5859375\n",
      "The representation loss after processing this batch is:  5.901604890823364e-05\n",
      "The classification loss after processing this batch is:  22589.5703125\n",
      "The representation loss after processing this batch is:  6.0918740928173065e-05\n",
      "The classification loss after processing this batch is:  23714.89453125\n",
      "The representation loss after processing this batch is:  6.357301026582718e-05\n",
      "The classification loss after processing this batch is:  24362.3125\n",
      "The representation loss after processing this batch is:  5.3688883781433105e-05\n",
      "The classification loss after processing this batch is:  22719.37109375\n",
      "The representation loss after processing this batch is:  6.769690662622452e-05\n",
      "The classification loss after processing this batch is:  25590.60546875\n",
      "The representation loss after processing this batch is:  5.4922886192798615e-05\n",
      "The classification loss after processing this batch is:  25697.41015625\n",
      "The representation loss after processing this batch is:  6.246846169233322e-05\n",
      "The classification loss after processing this batch is:  22515.638671875\n",
      "The representation loss after processing this batch is:  5.765073001384735e-05\n",
      "The classification loss after processing this batch is:  23336.61328125\n",
      "The representation loss after processing this batch is:  5.61736524105072e-05\n",
      "The classification loss after processing this batch is:  24415.265625\n",
      "The representation loss after processing this batch is:  7.089506834745407e-05\n",
      "The classification loss after processing this batch is:  22920.98828125\n",
      "The representation loss after processing this batch is:  5.536014214158058e-05\n",
      "The classification loss after processing this batch is:  23097.697265625\n",
      "The representation loss after processing this batch is:  5.962885916233063e-05\n",
      "The classification loss after processing this batch is:  22996.52734375\n",
      "The representation loss after processing this batch is:  5.721580237150192e-05\n",
      "The classification loss after processing this batch is:  23173.26953125\n",
      "The representation loss after processing this batch is:  6.117112934589386e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24111.41796875\n",
      "The representation loss after processing this batch is:  5.330424755811691e-05\n",
      "The classification loss after processing this batch is:  23917.75\n",
      "The representation loss after processing this batch is:  5.88027760386467e-05\n",
      "The classification loss after processing this batch is:  25773.890625\n",
      "The representation loss after processing this batch is:  6.359070539474487e-05\n",
      "The classification loss after processing this batch is:  24340.876953125\n",
      "The representation loss after processing this batch is:  5.737878382205963e-05\n",
      "The classification loss after processing this batch is:  24183.546875\n",
      "The representation loss after processing this batch is:  5.308911204338074e-05\n",
      "The classification loss after processing this batch is:  22277.62109375\n",
      "The representation loss after processing this batch is:  5.2026472985744476e-05\n",
      "The classification loss after processing this batch is:  22745.26953125\n",
      "The representation loss after processing this batch is:  5.175638943910599e-05\n",
      "The classification loss after processing this batch is:  23825.21484375\n",
      "The representation loss after processing this batch is:  5.360133945941925e-05\n",
      "The classification loss after processing this batch is:  22564.3984375\n",
      "The representation loss after processing this batch is:  5.3524039685726166e-05\n",
      "The classification loss after processing this batch is:  21568.7421875\n",
      "The representation loss after processing this batch is:  6.300769746303558e-05\n",
      "The classification loss after processing this batch is:  24398.078125\n",
      "The representation loss after processing this batch is:  5.3911469876766205e-05\n",
      "The classification loss after processing this batch is:  22276.44921875\n",
      "The representation loss after processing this batch is:  5.5355019867420197e-05\n",
      "The classification loss after processing this batch is:  22448.306640625\n",
      "The representation loss after processing this batch is:  5.756039172410965e-05\n",
      "The classification loss after processing this batch is:  21599.615234375\n",
      "The representation loss after processing this batch is:  5.741417407989502e-05\n",
      "The classification loss after processing this batch is:  22384.0546875\n",
      "The representation loss after processing this batch is:  5.9738755226135254e-05\n",
      "The classification loss after processing this batch is:  21653.17578125\n",
      "The representation loss after processing this batch is:  5.6898221373558044e-05\n",
      "The classification loss after processing this batch is:  23134.45703125\n",
      "The representation loss after processing this batch is:  5.228491500020027e-05\n",
      "The classification loss after processing this batch is:  22690.53125\n",
      "The representation loss after processing this batch is:  4.9466732889413834e-05\n",
      "The classification loss after processing this batch is:  22252.55078125\n",
      "The representation loss after processing this batch is:  5.759112536907196e-05\n",
      "The classification loss after processing this batch is:  23516.94921875\n",
      "The representation loss after processing this batch is:  5.8103352785110474e-05\n",
      "The classification loss after processing this batch is:  23631.693359375\n",
      "The representation loss after processing this batch is:  5.86826354265213e-05\n",
      "The classification loss after processing this batch is:  21759.623046875\n",
      "The representation loss after processing this batch is:  6.287172436714172e-05\n",
      "The classification loss after processing this batch is:  22075.201171875\n",
      "The representation loss after processing this batch is:  6.303191184997559e-05\n",
      "The classification loss after processing this batch is:  22358.85546875\n",
      "The representation loss after processing this batch is:  5.2634626626968384e-05\n",
      "The classification loss after processing this batch is:  22428.78515625\n",
      "The representation loss after processing this batch is:  5.886144936084747e-05\n",
      "The classification loss after processing this batch is:  23652.703125\n",
      "The representation loss after processing this batch is:  5.491357296705246e-05\n",
      "The classification loss after processing this batch is:  22165.39453125\n",
      "The representation loss after processing this batch is:  5.660718306899071e-05\n",
      "The classification loss after processing this batch is:  21591.1484375\n",
      "The representation loss after processing this batch is:  6.024818867444992e-05\n",
      "The classification loss after processing this batch is:  22629.6640625\n",
      "The representation loss after processing this batch is:  6.018020212650299e-05\n",
      "The classification loss after processing this batch is:  24794.7890625\n",
      "The representation loss after processing this batch is:  6.201211363077164e-05\n",
      "The classification loss after processing this batch is:  22200.72265625\n",
      "The representation loss after processing this batch is:  5.5777840316295624e-05\n",
      "The classification loss after processing this batch is:  23051.5859375\n",
      "The representation loss after processing this batch is:  5.822628736495972e-05\n",
      "The classification loss after processing this batch is:  24858.205078125\n",
      "The representation loss after processing this batch is:  5.848146975040436e-05\n",
      "The classification loss after processing this batch is:  22618.17578125\n",
      "The representation loss after processing this batch is:  5.306396633386612e-05\n",
      "The classification loss after processing this batch is:  21814.44921875\n",
      "The representation loss after processing this batch is:  5.949661135673523e-05\n",
      "The classification loss after processing this batch is:  22051.73046875\n",
      "The representation loss after processing this batch is:  5.760136991739273e-05\n",
      "The classification loss after processing this batch is:  21967.65625\n",
      "The representation loss after processing this batch is:  5.3573399782180786e-05\n",
      "The classification loss after processing this batch is:  22484.3984375\n",
      "The representation loss after processing this batch is:  5.35864382982254e-05\n",
      "The classification loss after processing this batch is:  22130.8671875\n",
      "The representation loss after processing this batch is:  6.0041435062885284e-05\n",
      "The classification loss after processing this batch is:  22774.935546875\n",
      "The representation loss after processing this batch is:  5.7013705372810364e-05\n",
      "The classification loss after processing this batch is:  25688.658203125\n",
      "The representation loss after processing this batch is:  7.22743570804596e-05\n",
      "The classification loss after processing this batch is:  24020.166015625\n",
      "The representation loss after processing this batch is:  5.9126876294612885e-05\n",
      "The classification loss after processing this batch is:  23243.26953125\n",
      "The representation loss after processing this batch is:  5.891593173146248e-05\n",
      "The classification loss after processing this batch is:  22163.951171875\n",
      "The representation loss after processing this batch is:  6.448104977607727e-05\n",
      "The classification loss after processing this batch is:  22700.298828125\n",
      "The representation loss after processing this batch is:  6.526429206132889e-05\n",
      "The classification loss after processing this batch is:  22597.4140625\n",
      "The representation loss after processing this batch is:  6.370805203914642e-05\n",
      "The classification loss after processing this batch is:  22269.294921875\n",
      "The representation loss after processing this batch is:  5.5072829127311707e-05\n",
      "The classification loss after processing this batch is:  21696.87109375\n",
      "The representation loss after processing this batch is:  6.020441651344299e-05\n",
      "The classification loss after processing this batch is:  22431.9140625\n",
      "The representation loss after processing this batch is:  5.612429231405258e-05\n",
      "The classification loss after processing this batch is:  22305.48046875\n",
      "The representation loss after processing this batch is:  5.781091749668121e-05\n",
      "The classification loss after processing this batch is:  21605.046875\n",
      "The representation loss after processing this batch is:  5.580112338066101e-05\n",
      "The classification loss after processing this batch is:  22797.26171875\n",
      "The representation loss after processing this batch is:  5.960743874311447e-05\n",
      "The classification loss after processing this batch is:  21719.88671875\n",
      "The representation loss after processing this batch is:  5.613919347524643e-05\n",
      "The classification loss after processing this batch is:  24231.015625\n",
      "The representation loss after processing this batch is:  6.223376840353012e-05\n",
      "The classification loss after processing this batch is:  23901.6484375\n",
      "The representation loss after processing this batch is:  5.344860255718231e-05\n",
      "The classification loss after processing this batch is:  22768.916015625\n",
      "The representation loss after processing this batch is:  5.396828055381775e-05\n",
      "The classification loss after processing this batch is:  22553.255859375\n",
      "The representation loss after processing this batch is:  5.143601447343826e-05\n",
      "The classification loss after processing this batch is:  22476.275390625\n",
      "The representation loss after processing this batch is:  5.488470196723938e-05\n",
      "The classification loss after processing this batch is:  24093.75390625\n",
      "The representation loss after processing this batch is:  5.455967038869858e-05\n",
      "The classification loss after processing this batch is:  23594.41015625\n",
      "The representation loss after processing this batch is:  5.5371783673763275e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22678.412109375\n",
      "The representation loss after processing this batch is:  6.168242543935776e-05\n",
      "The classification loss after processing this batch is:  23080.1796875\n",
      "The representation loss after processing this batch is:  5.1451846957206726e-05\n",
      "The classification loss after processing this batch is:  24903.232421875\n",
      "The representation loss after processing this batch is:  6.825663149356842e-05\n",
      "The classification loss after processing this batch is:  22279.806640625\n",
      "The representation loss after processing this batch is:  5.82253560423851e-05\n",
      "The classification loss after processing this batch is:  23124.28515625\n",
      "The representation loss after processing this batch is:  5.603395402431488e-05\n",
      "The classification loss after processing this batch is:  23125.892578125\n",
      "The representation loss after processing this batch is:  6.762612611055374e-05\n",
      "The classification loss after processing this batch is:  22864.185546875\n",
      "The representation loss after processing this batch is:  5.326932296156883e-05\n",
      "The classification loss after processing this batch is:  23536.89453125\n",
      "The representation loss after processing this batch is:  6.916746497154236e-05\n",
      "The classification loss after processing this batch is:  23985.8125\n",
      "The representation loss after processing this batch is:  6.117112934589386e-05\n",
      "The classification loss after processing this batch is:  22667.44921875\n",
      "The representation loss after processing this batch is:  6.496813148260117e-05\n",
      "The classification loss after processing this batch is:  23503.3515625\n",
      "The representation loss after processing this batch is:  5.4333359003067017e-05\n",
      "The classification loss after processing this batch is:  24081.07421875\n",
      "The representation loss after processing this batch is:  5.2036717534065247e-05\n",
      "The classification loss after processing this batch is:  22591.9921875\n",
      "The representation loss after processing this batch is:  6.332807242870331e-05\n",
      "The classification loss after processing this batch is:  23655.8984375\n",
      "The representation loss after processing this batch is:  5.477108061313629e-05\n",
      "The classification loss after processing this batch is:  23231.7421875\n",
      "The representation loss after processing this batch is:  5.6150369346141815e-05\n",
      "The classification loss after processing this batch is:  22125.40625\n",
      "The representation loss after processing this batch is:  6.419513374567032e-05\n",
      "The classification loss after processing this batch is:  22415.833984375\n",
      "The representation loss after processing this batch is:  5.6852586567401886e-05\n",
      "The classification loss after processing this batch is:  22378.23046875\n",
      "The representation loss after processing this batch is:  6.488151848316193e-05\n",
      "The classification loss after processing this batch is:  22162.91796875\n",
      "The representation loss after processing this batch is:  5.5009499192237854e-05\n",
      "The classification loss after processing this batch is:  23984.2109375\n",
      "The representation loss after processing this batch is:  5.607306957244873e-05\n",
      "The classification loss after processing this batch is:  23512.01953125\n",
      "The representation loss after processing this batch is:  5.254056304693222e-05\n",
      "The classification loss after processing this batch is:  24596.76953125\n",
      "The representation loss after processing this batch is:  6.585102528333664e-05\n",
      "The classification loss after processing this batch is:  21612.234375\n",
      "The representation loss after processing this batch is:  6.315484642982483e-05\n",
      "The classification loss after processing this batch is:  21880.4296875\n",
      "The representation loss after processing this batch is:  6.428360939025879e-05\n",
      "The classification loss after processing this batch is:  22408.7421875\n",
      "The representation loss after processing this batch is:  6.266497075557709e-05\n",
      "The classification loss after processing this batch is:  22090.56640625\n",
      "The representation loss after processing this batch is:  5.434360355138779e-05\n",
      "The classification loss after processing this batch is:  23533.353515625\n",
      "The representation loss after processing this batch is:  6.354507058858871e-05\n",
      "The classification loss after processing this batch is:  22507.140625\n",
      "The representation loss after processing this batch is:  5.442742258310318e-05\n",
      "The classification loss after processing this batch is:  22938.99609375\n",
      "The representation loss after processing this batch is:  5.5573880672454834e-05\n",
      "The classification loss after processing this batch is:  23042.15625\n",
      "The representation loss after processing this batch is:  5.6721270084381104e-05\n",
      "The classification loss after processing this batch is:  22221.7265625\n",
      "The representation loss after processing this batch is:  5.562417209148407e-05\n",
      "The classification loss after processing this batch is:  24129.607421875\n",
      "The representation loss after processing this batch is:  5.7880766689777374e-05\n",
      "The classification loss after processing this batch is:  24348.0078125\n",
      "The representation loss after processing this batch is:  5.291495472192764e-05\n",
      "The classification loss after processing this batch is:  23530.11328125\n",
      "The representation loss after processing this batch is:  6.0325488448143005e-05\n",
      "The classification loss after processing this batch is:  21822.447265625\n",
      "The representation loss after processing this batch is:  6.129872053861618e-05\n",
      "The classification loss after processing this batch is:  23969.28515625\n",
      "The representation loss after processing this batch is:  5.615595728158951e-05\n",
      "The classification loss after processing this batch is:  23714.90625\n",
      "The representation loss after processing this batch is:  5.059875547885895e-05\n",
      "The classification loss after processing this batch is:  22277.07421875\n",
      "The representation loss after processing this batch is:  5.665561184287071e-05\n",
      "The classification loss after processing this batch is:  24535.447265625\n",
      "The representation loss after processing this batch is:  6.171595305204391e-05\n",
      "The classification loss after processing this batch is:  24312.380859375\n",
      "The representation loss after processing this batch is:  6.85080885887146e-05\n",
      "The classification loss after processing this batch is:  21955.50390625\n",
      "The representation loss after processing this batch is:  5.433056503534317e-05\n",
      "The classification loss after processing this batch is:  22535.603515625\n",
      "The representation loss after processing this batch is:  6.135273724794388e-05\n",
      "The classification loss after processing this batch is:  23173.73046875\n",
      "The representation loss after processing this batch is:  6.124656647443771e-05\n",
      "The classification loss after processing this batch is:  22717.1484375\n",
      "The representation loss after processing this batch is:  6.065424531698227e-05\n",
      "The classification loss after processing this batch is:  23458.58984375\n",
      "The representation loss after processing this batch is:  7.403269410133362e-05\n",
      "The classification loss after processing this batch is:  24129.361328125\n",
      "The representation loss after processing this batch is:  5.9738755226135254e-05\n",
      "The classification loss after processing this batch is:  22115.20703125\n",
      "The representation loss after processing this batch is:  6.31231814622879e-05\n",
      "The classification loss after processing this batch is:  21641.80859375\n",
      "The representation loss after processing this batch is:  6.023980677127838e-05\n",
      "The classification loss after processing this batch is:  23133.0\n",
      "The representation loss after processing this batch is:  5.310727283358574e-05\n",
      "The classification loss after processing this batch is:  24151.419921875\n",
      "The representation loss after processing this batch is:  7.182452827692032e-05\n",
      "The classification loss after processing this batch is:  22772.103515625\n",
      "The representation loss after processing this batch is:  5.8795325458049774e-05\n",
      "The classification loss after processing this batch is:  23531.5\n",
      "The representation loss after processing this batch is:  6.702076643705368e-05\n",
      "The classification loss after processing this batch is:  23201.37109375\n",
      "The representation loss after processing this batch is:  5.466677248477936e-05\n",
      "The classification loss after processing this batch is:  23424.626953125\n",
      "The representation loss after processing this batch is:  6.0274265706539154e-05\n",
      "The classification loss after processing this batch is:  22472.8125\n",
      "The representation loss after processing this batch is:  6.143096834421158e-05\n",
      "The classification loss after processing this batch is:  22875.544921875\n",
      "The representation loss after processing this batch is:  6.445683538913727e-05\n",
      "The classification loss after processing this batch is:  24152.65625\n",
      "The representation loss after processing this batch is:  5.397666245698929e-05\n",
      "The classification loss after processing this batch is:  21689.83984375\n",
      "The representation loss after processing this batch is:  5.199480801820755e-05\n",
      "The classification loss after processing this batch is:  21719.541015625\n",
      "The representation loss after processing this batch is:  5.5215321481227875e-05\n",
      "The classification loss after processing this batch is:  21506.46484375\n",
      "The representation loss after processing this batch is:  5.440693348646164e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21671.68359375\n",
      "The representation loss after processing this batch is:  5.542673170566559e-05\n",
      "The classification loss after processing this batch is:  22077.701171875\n",
      "The representation loss after processing this batch is:  5.6782737374305725e-05\n",
      "The classification loss after processing this batch is:  23344.02734375\n",
      "The representation loss after processing this batch is:  5.7124532759189606e-05\n",
      "The classification loss after processing this batch is:  23391.04296875\n",
      "The representation loss after processing this batch is:  5.7291239500045776e-05\n",
      "The classification loss after processing this batch is:  21942.04296875\n",
      "The representation loss after processing this batch is:  6.089266389608383e-05\n",
      "The classification loss after processing this batch is:  21550.37890625\n",
      "The representation loss after processing this batch is:  5.549658089876175e-05\n",
      "The classification loss after processing this batch is:  21942.4375\n",
      "The representation loss after processing this batch is:  4.983646795153618e-05\n",
      "The classification loss after processing this batch is:  22582.11328125\n",
      "The representation loss after processing this batch is:  5.611404776573181e-05\n",
      "The classification loss after processing this batch is:  22650.056640625\n",
      "The representation loss after processing this batch is:  5.478784441947937e-05\n",
      "The classification loss after processing this batch is:  21792.271484375\n",
      "The representation loss after processing this batch is:  5.945097655057907e-05\n",
      "The classification loss after processing this batch is:  24209.853515625\n",
      "The representation loss after processing this batch is:  5.310727283358574e-05\n",
      "The classification loss after processing this batch is:  22254.62890625\n",
      "The representation loss after processing this batch is:  5.152914673089981e-05\n",
      "The classification loss after processing this batch is:  21905.412109375\n",
      "The representation loss after processing this batch is:  6.5571628510952e-05\n",
      "The classification loss after processing this batch is:  22548.552734375\n",
      "The representation loss after processing this batch is:  6.353482604026794e-05\n",
      "The classification loss after processing this batch is:  23213.5390625\n",
      "The representation loss after processing this batch is:  6.373133510351181e-05\n",
      "The classification loss after processing this batch is:  22640.921875\n",
      "The representation loss after processing this batch is:  5.655083805322647e-05\n",
      "The classification loss after processing this batch is:  21923.353515625\n",
      "The representation loss after processing this batch is:  5.942583084106445e-05\n",
      "The classification loss after processing this batch is:  22659.453125\n",
      "The representation loss after processing this batch is:  5.193985998630524e-05\n",
      "The classification loss after processing this batch is:  24116.34375\n",
      "The representation loss after processing this batch is:  5.565118044614792e-05\n",
      "The classification loss after processing this batch is:  21356.65234375\n",
      "The representation loss after processing this batch is:  6.241444498300552e-05\n",
      "The classification loss after processing this batch is:  22168.7109375\n",
      "The representation loss after processing this batch is:  6.1015598475933075e-05\n",
      "The classification loss after processing this batch is:  20910.17578125\n",
      "The representation loss after processing this batch is:  5.889497697353363e-05\n",
      "The classification loss after processing this batch is:  22393.8515625\n",
      "The representation loss after processing this batch is:  4.845764487981796e-05\n",
      "The classification loss after processing this batch is:  22664.130859375\n",
      "The representation loss after processing this batch is:  5.4434873163700104e-05\n",
      "The classification loss after processing this batch is:  22105.078125\n",
      "The representation loss after processing this batch is:  6.070826202630997e-05\n",
      "The classification loss after processing this batch is:  21845.185546875\n",
      "The representation loss after processing this batch is:  6.175972521305084e-05\n",
      "The classification loss after processing this batch is:  21377.568359375\n",
      "The representation loss after processing this batch is:  6.075948476791382e-05\n",
      "The classification loss after processing this batch is:  22437.54296875\n",
      "The representation loss after processing this batch is:  5.5101700127124786e-05\n",
      "The classification loss after processing this batch is:  22095.880859375\n",
      "The representation loss after processing this batch is:  5.778251215815544e-05\n",
      "The classification loss after processing this batch is:  21421.220703125\n",
      "The representation loss after processing this batch is:  5.8943405747413635e-05\n",
      "The classification loss after processing this batch is:  25505.05859375\n",
      "The representation loss after processing this batch is:  6.612110882997513e-05\n",
      "The classification loss after processing this batch is:  23997.4609375\n",
      "The representation loss after processing this batch is:  5.8910809457302094e-05\n",
      "The classification loss after processing this batch is:  23117.259765625\n",
      "The representation loss after processing this batch is:  6.355158984661102e-05\n",
      "The classification loss after processing this batch is:  22304.7734375\n",
      "The representation loss after processing this batch is:  6.629899144172668e-05\n",
      "The classification loss after processing this batch is:  21458.20703125\n",
      "The representation loss after processing this batch is:  6.097275763750076e-05\n",
      "The classification loss after processing this batch is:  22193.96875\n",
      "The representation loss after processing this batch is:  6.639771163463593e-05\n",
      "The classification loss after processing this batch is:  23043.583984375\n",
      "The representation loss after processing this batch is:  5.9437938034534454e-05\n",
      "The classification loss after processing this batch is:  22070.125\n",
      "The representation loss after processing this batch is:  5.4210424423217773e-05\n",
      "The classification loss after processing this batch is:  24245.671875\n",
      "The representation loss after processing this batch is:  5.7579949498176575e-05\n",
      "The classification loss after processing this batch is:  22378.08203125\n",
      "The representation loss after processing this batch is:  5.971547216176987e-05\n",
      "The classification loss after processing this batch is:  21753.3359375\n",
      "The representation loss after processing this batch is:  5.5565498769283295e-05\n",
      "The classification loss after processing this batch is:  23554.078125\n",
      "The representation loss after processing this batch is:  6.566569209098816e-05\n",
      "The classification loss after processing this batch is:  21885.89453125\n",
      "The representation loss after processing this batch is:  5.432404577732086e-05\n",
      "The classification loss after processing this batch is:  22132.31640625\n",
      "The representation loss after processing this batch is:  6.551668047904968e-05\n",
      "The classification loss after processing this batch is:  25799.7578125\n",
      "The representation loss after processing this batch is:  6.752833724021912e-05\n",
      "The classification loss after processing this batch is:  23285.19921875\n",
      "The representation loss after processing this batch is:  7.53616914153099e-05\n",
      "The classification loss after processing this batch is:  21888.818359375\n",
      "The representation loss after processing this batch is:  6.720423698425293e-05\n",
      "The classification loss after processing this batch is:  21812.86328125\n",
      "The representation loss after processing this batch is:  8.573010563850403e-05\n",
      "The classification loss after processing this batch is:  24436.16796875\n",
      "The representation loss after processing this batch is:  6.66007399559021e-05\n",
      "The classification loss after processing this batch is:  21658.837890625\n",
      "The representation loss after processing this batch is:  7.008947432041168e-05\n",
      "The classification loss after processing this batch is:  22183.82421875\n",
      "The representation loss after processing this batch is:  8.193217217922211e-05\n",
      "The classification loss after processing this batch is:  22886.109375\n",
      "The representation loss after processing this batch is:  8.71485099196434e-05\n",
      "The classification loss after processing this batch is:  27133.28515625\n",
      "The representation loss after processing this batch is:  7.481314241886139e-05\n",
      "The classification loss after processing this batch is:  29469.568359375\n",
      "The representation loss after processing this batch is:  6.576348096132278e-05\n",
      "The classification loss after processing this batch is:  21714.333984375\n",
      "The representation loss after processing this batch is:  6.41094520688057e-05\n",
      "The classification loss after processing this batch is:  23226.60546875\n",
      "The representation loss after processing this batch is:  6.448011845350266e-05\n",
      "The classification loss after processing this batch is:  23165.98046875\n",
      "The representation loss after processing this batch is:  7.125549018383026e-05\n",
      "The classification loss after processing this batch is:  21006.78125\n",
      "The representation loss after processing this batch is:  6.189709529280663e-05\n",
      "The classification loss after processing this batch is:  23141.2109375\n",
      "The representation loss after processing this batch is:  4.8201531171798706e-05\n",
      "The classification loss after processing this batch is:  23416.00390625\n",
      "The representation loss after processing this batch is:  5.067046731710434e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22398.19921875\n",
      "The representation loss after processing this batch is:  5.477108061313629e-05\n",
      "The classification loss after processing this batch is:  22722.455078125\n",
      "The representation loss after processing this batch is:  5.053915083408356e-05\n",
      "The classification loss after processing this batch is:  22630.7265625\n",
      "The representation loss after processing this batch is:  4.534795880317688e-05\n",
      "The classification loss after processing this batch is:  22479.3359375\n",
      "The representation loss after processing this batch is:  4.514632746577263e-05\n",
      "The classification loss after processing this batch is:  22779.20703125\n",
      "The representation loss after processing this batch is:  5.953758955001831e-05\n",
      "The classification loss after processing this batch is:  22652.8828125\n",
      "The representation loss after processing this batch is:  5.161017179489136e-05\n",
      "The classification loss after processing this batch is:  22411.4296875\n",
      "The representation loss after processing this batch is:  5.162786692380905e-05\n",
      "The classification loss after processing this batch is:  26102.470703125\n",
      "The representation loss after processing this batch is:  5.1771290600299835e-05\n",
      "The classification loss after processing this batch is:  24974.83203125\n",
      "The representation loss after processing this batch is:  4.1202642023563385e-05\n",
      "The classification loss after processing this batch is:  22304.2890625\n",
      "The representation loss after processing this batch is:  4.236679524183273e-05\n",
      "The classification loss after processing this batch is:  22273.197265625\n",
      "The representation loss after processing this batch is:  3.9482954889535904e-05\n",
      "The classification loss after processing this batch is:  21994.95703125\n",
      "The representation loss after processing this batch is:  4.495028406381607e-05\n",
      "The classification loss after processing this batch is:  22271.48828125\n",
      "The representation loss after processing this batch is:  4.6113040298223495e-05\n",
      "The classification loss after processing this batch is:  23030.013671875\n",
      "The representation loss after processing this batch is:  4.396634176373482e-05\n",
      "The classification loss after processing this batch is:  22439.6484375\n",
      "The representation loss after processing this batch is:  4.229135811328888e-05\n",
      "The classification loss after processing this batch is:  24284.91796875\n",
      "The representation loss after processing this batch is:  5.498761311173439e-05\n",
      "The classification loss after processing this batch is:  22819.271484375\n",
      "The representation loss after processing this batch is:  4.7429464757442474e-05\n",
      "The classification loss after processing this batch is:  22893.916015625\n",
      "The representation loss after processing this batch is:  4.856474697589874e-05\n",
      "The classification loss after processing this batch is:  22549.3046875\n",
      "The representation loss after processing this batch is:  5.3839292377233505e-05\n",
      "The classification loss after processing this batch is:  22641.40234375\n",
      "The representation loss after processing this batch is:  4.711048677563667e-05\n",
      "The classification loss after processing this batch is:  22607.306640625\n",
      "The representation loss after processing this batch is:  5.1295384764671326e-05\n",
      "The classification loss after processing this batch is:  22189.810546875\n",
      "The representation loss after processing this batch is:  3.9041973650455475e-05\n",
      "The classification loss after processing this batch is:  22103.91015625\n",
      "The representation loss after processing this batch is:  4.239380359649658e-05\n",
      "The classification loss after processing this batch is:  21444.01953125\n",
      "The representation loss after processing this batch is:  4.9386173486709595e-05\n",
      "The classification loss after processing this batch is:  21773.71875\n",
      "The representation loss after processing this batch is:  4.211580380797386e-05\n",
      "The classification loss after processing this batch is:  21753.890625\n",
      "The representation loss after processing this batch is:  3.9944425225257874e-05\n",
      "The classification loss after processing this batch is:  24253.40625\n",
      "The representation loss after processing this batch is:  4.794122651219368e-05\n",
      "The classification loss after processing this batch is:  22794.09375\n",
      "The representation loss after processing this batch is:  4.130695015192032e-05\n",
      "The classification loss after processing this batch is:  21635.861328125\n",
      "The representation loss after processing this batch is:  4.3519772589206696e-05\n",
      "The classification loss after processing this batch is:  22187.078125\n",
      "The representation loss after processing this batch is:  4.301220178604126e-05\n",
      "The classification loss after processing this batch is:  21346.2734375\n",
      "The representation loss after processing this batch is:  4.343688488006592e-05\n",
      "The classification loss after processing this batch is:  21854.228515625\n",
      "The representation loss after processing this batch is:  4.169531166553497e-05\n",
      "The classification loss after processing this batch is:  22082.71484375\n",
      "The representation loss after processing this batch is:  4.176143556833267e-05\n",
      "The classification loss after processing this batch is:  22067.72265625\n",
      "The representation loss after processing this batch is:  4.2823608964681625e-05\n",
      "The classification loss after processing this batch is:  23350.0234375\n",
      "The representation loss after processing this batch is:  4.0907878428697586e-05\n",
      "The classification loss after processing this batch is:  27254.27734375\n",
      "The representation loss after processing this batch is:  5.525350570678711e-05\n",
      "The classification loss after processing this batch is:  22325.84375\n",
      "The representation loss after processing this batch is:  4.364410415291786e-05\n",
      "The classification loss after processing this batch is:  22379.8671875\n",
      "The representation loss after processing this batch is:  3.904709592461586e-05\n",
      "The classification loss after processing this batch is:  22486.85546875\n",
      "The representation loss after processing this batch is:  4.476960748434067e-05\n",
      "The classification loss after processing this batch is:  22712.310546875\n",
      "The representation loss after processing this batch is:  5.1200855523347855e-05\n",
      "The classification loss after processing this batch is:  22140.884765625\n",
      "The representation loss after processing this batch is:  4.849117249250412e-05\n",
      "The classification loss after processing this batch is:  22637.20703125\n",
      "The representation loss after processing this batch is:  4.285946488380432e-05\n",
      "The classification loss after processing this batch is:  22363.794921875\n",
      "The representation loss after processing this batch is:  3.8732774555683136e-05\n",
      "The classification loss after processing this batch is:  22279.6953125\n",
      "The representation loss after processing this batch is:  4.792492836713791e-05\n",
      "The classification loss after processing this batch is:  22142.64453125\n",
      "The representation loss after processing this batch is:  3.848830237984657e-05\n",
      "The classification loss after processing this batch is:  22324.9453125\n",
      "The representation loss after processing this batch is:  4.353281110525131e-05\n",
      "The classification loss after processing this batch is:  22095.56640625\n",
      "The representation loss after processing this batch is:  4.369625821709633e-05\n",
      "The classification loss after processing this batch is:  22120.57421875\n",
      "The representation loss after processing this batch is:  4.1419174522161484e-05\n",
      "The classification loss after processing this batch is:  21821.466796875\n",
      "The representation loss after processing this batch is:  4.646275192499161e-05\n",
      "The classification loss after processing this batch is:  20836.931640625\n",
      "The representation loss after processing this batch is:  4.334188997745514e-05\n",
      "The classification loss after processing this batch is:  21934.017578125\n",
      "The representation loss after processing this batch is:  4.45307232439518e-05\n",
      "The classification loss after processing this batch is:  22302.751953125\n",
      "The representation loss after processing this batch is:  4.636775702238083e-05\n",
      "The classification loss after processing this batch is:  22064.16015625\n",
      "The representation loss after processing this batch is:  4.63360920548439e-05\n",
      "The classification loss after processing this batch is:  21734.08203125\n",
      "The representation loss after processing this batch is:  4.716217517852783e-05\n",
      "The classification loss after processing this batch is:  23357.2734375\n",
      "The representation loss after processing this batch is:  4.575401544570923e-05\n",
      "The classification loss after processing this batch is:  22105.904296875\n",
      "The representation loss after processing this batch is:  4.3750274926424026e-05\n",
      "The classification loss after processing this batch is:  21889.4765625\n",
      "The representation loss after processing this batch is:  4.2350031435489655e-05\n",
      "The classification loss after processing this batch is:  22666.1953125\n",
      "The representation loss after processing this batch is:  4.415493458509445e-05\n",
      "The classification loss after processing this batch is:  23986.259765625\n",
      "The representation loss after processing this batch is:  3.9182137697935104e-05\n",
      "The classification loss after processing this batch is:  24745.15625\n",
      "The representation loss after processing this batch is:  3.923196345567703e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24252.279296875\n",
      "The representation loss after processing this batch is:  3.91518697142601e-05\n",
      "The classification loss after processing this batch is:  21243.86328125\n",
      "The representation loss after processing this batch is:  5.110306665301323e-05\n",
      "The classification loss after processing this batch is:  23108.53125\n",
      "The representation loss after processing this batch is:  3.889249637722969e-05\n",
      "The classification loss after processing this batch is:  22346.41015625\n",
      "The representation loss after processing this batch is:  3.746245056390762e-05\n",
      "The classification loss after processing this batch is:  23437.203125\n",
      "The representation loss after processing this batch is:  4.269741475582123e-05\n",
      "The classification loss after processing this batch is:  23742.91796875\n",
      "The representation loss after processing this batch is:  3.7476420402526855e-05\n",
      "The classification loss after processing this batch is:  22538.921875\n",
      "The representation loss after processing this batch is:  3.7686433643102646e-05\n",
      "The classification loss after processing this batch is:  22633.822265625\n",
      "The representation loss after processing this batch is:  4.016607999801636e-05\n",
      "The classification loss after processing this batch is:  22755.5078125\n",
      "The representation loss after processing this batch is:  3.9719510823488235e-05\n",
      "The classification loss after processing this batch is:  23546.9375\n",
      "The representation loss after processing this batch is:  4.820339381694794e-05\n",
      "The classification loss after processing this batch is:  22530.71484375\n",
      "The representation loss after processing this batch is:  7.164059206843376e-05\n",
      "The classification loss after processing this batch is:  23355.4453125\n",
      "The representation loss after processing this batch is:  4.000263288617134e-05\n",
      "The classification loss after processing this batch is:  24158.26171875\n",
      "The representation loss after processing this batch is:  3.896886482834816e-05\n",
      "The classification loss after processing this batch is:  24673.921875\n",
      "The representation loss after processing this batch is:  5.035568028688431e-05\n",
      "The classification loss after processing this batch is:  22135.203125\n",
      "The representation loss after processing this batch is:  4.425784572958946e-05\n",
      "The classification loss after processing this batch is:  21955.43359375\n",
      "The representation loss after processing this batch is:  4.008971154689789e-05\n",
      "The classification loss after processing this batch is:  22048.828125\n",
      "The representation loss after processing this batch is:  3.8658734411001205e-05\n",
      "The classification loss after processing this batch is:  23371.765625\n",
      "The representation loss after processing this batch is:  3.528967499732971e-05\n",
      "The classification loss after processing this batch is:  24473.556640625\n",
      "The representation loss after processing this batch is:  3.834487870335579e-05\n",
      "The classification loss after processing this batch is:  22707.8984375\n",
      "The representation loss after processing this batch is:  4.425039514899254e-05\n",
      "The classification loss after processing this batch is:  21769.171875\n",
      "The representation loss after processing this batch is:  3.8479920476675034e-05\n",
      "The classification loss after processing this batch is:  22231.07421875\n",
      "The representation loss after processing this batch is:  4.091719165444374e-05\n",
      "The classification loss after processing this batch is:  21407.748046875\n",
      "The representation loss after processing this batch is:  4.518171772360802e-05\n",
      "The classification loss after processing this batch is:  21960.36328125\n",
      "The representation loss after processing this batch is:  3.781262785196304e-05\n",
      "The classification loss after processing this batch is:  21950.0078125\n",
      "The representation loss after processing this batch is:  4.0644314140081406e-05\n",
      "The classification loss after processing this batch is:  21806.8359375\n",
      "The representation loss after processing this batch is:  3.8458965718746185e-05\n",
      "The classification loss after processing this batch is:  21544.029296875\n",
      "The representation loss after processing this batch is:  3.710482269525528e-05\n",
      "The classification loss after processing this batch is:  21472.005859375\n",
      "The representation loss after processing this batch is:  4.162127152085304e-05\n",
      "The classification loss after processing this batch is:  21961.05078125\n",
      "The representation loss after processing this batch is:  4.1052233427762985e-05\n",
      "The classification loss after processing this batch is:  21530.1015625\n",
      "The representation loss after processing this batch is:  4.011578857898712e-05\n",
      "The classification loss after processing this batch is:  21529.169921875\n",
      "The representation loss after processing this batch is:  4.096655175089836e-05\n",
      "The classification loss after processing this batch is:  21653.150390625\n",
      "The representation loss after processing this batch is:  3.8650352507829666e-05\n",
      "The classification loss after processing this batch is:  21123.271484375\n",
      "The representation loss after processing this batch is:  3.8578640669584274e-05\n",
      "The classification loss after processing this batch is:  23063.701171875\n",
      "The representation loss after processing this batch is:  3.408314660191536e-05\n",
      "The classification loss after processing this batch is:  22932.173828125\n",
      "The representation loss after processing this batch is:  3.784801810979843e-05\n",
      "The classification loss after processing this batch is:  23543.9921875\n",
      "The representation loss after processing this batch is:  3.841286525130272e-05\n",
      "The classification loss after processing this batch is:  24152.55859375\n",
      "The representation loss after processing this batch is:  3.9360951632261276e-05\n",
      "The classification loss after processing this batch is:  23800.69921875\n",
      "The representation loss after processing this batch is:  3.6946963518857956e-05\n",
      "The classification loss after processing this batch is:  22817.5546875\n",
      "The representation loss after processing this batch is:  4.752166569232941e-05\n",
      "The classification loss after processing this batch is:  22796.6171875\n",
      "The representation loss after processing this batch is:  4.592491313815117e-05\n",
      "The classification loss after processing this batch is:  22447.6015625\n",
      "The representation loss after processing this batch is:  3.896327689290047e-05\n",
      "The classification loss after processing this batch is:  22893.13671875\n",
      "The representation loss after processing this batch is:  3.79122793674469e-05\n",
      "The classification loss after processing this batch is:  22128.953125\n",
      "The representation loss after processing this batch is:  3.434624522924423e-05\n",
      "The classification loss after processing this batch is:  21963.513671875\n",
      "The representation loss after processing this batch is:  4.202313721179962e-05\n",
      "The classification loss after processing this batch is:  23161.767578125\n",
      "The representation loss after processing this batch is:  3.680400550365448e-05\n",
      "The classification loss after processing this batch is:  22860.03125\n",
      "The representation loss after processing this batch is:  3.841891884803772e-05\n",
      "The classification loss after processing this batch is:  22233.482421875\n",
      "The representation loss after processing this batch is:  3.8193073123693466e-05\n",
      "The classification loss after processing this batch is:  23422.107421875\n",
      "The representation loss after processing this batch is:  3.8137659430503845e-05\n",
      "The classification loss after processing this batch is:  25994.88671875\n",
      "The representation loss after processing this batch is:  4.231557250022888e-05\n",
      "The classification loss after processing this batch is:  23796.30859375\n",
      "The representation loss after processing this batch is:  4.346948117017746e-05\n",
      "The classification loss after processing this batch is:  22052.4921875\n",
      "The representation loss after processing this batch is:  3.669736906886101e-05\n",
      "The classification loss after processing this batch is:  22351.283203125\n",
      "The representation loss after processing this batch is:  4.729069769382477e-05\n",
      "The classification loss after processing this batch is:  26466.7109375\n",
      "The representation loss after processing this batch is:  4.5258551836013794e-05\n",
      "The classification loss after processing this batch is:  26705.2109375\n",
      "The representation loss after processing this batch is:  5.189981311559677e-05\n",
      "The classification loss after processing this batch is:  21748.810546875\n",
      "The representation loss after processing this batch is:  4.9831345677375793e-05\n",
      "The classification loss after processing this batch is:  21460.96484375\n",
      "The representation loss after processing this batch is:  4.028854891657829e-05\n",
      "The classification loss after processing this batch is:  22010.404296875\n",
      "The representation loss after processing this batch is:  4.451721906661987e-05\n",
      "The classification loss after processing this batch is:  22322.55859375\n",
      "The representation loss after processing this batch is:  4.0974002331495285e-05\n",
      "The classification loss after processing this batch is:  22248.9921875\n",
      "The representation loss after processing this batch is:  3.9221253246068954e-05\n",
      "The classification loss after processing this batch is:  22094.017578125\n",
      "The representation loss after processing this batch is:  4.452746361494064e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  23421.87109375\n",
      "The representation loss after processing this batch is:  4.466623067855835e-05\n",
      "The classification loss after processing this batch is:  24398.169921875\n",
      "The representation loss after processing this batch is:  4.087621346116066e-05\n",
      "The classification loss after processing this batch is:  21975.806640625\n",
      "The representation loss after processing this batch is:  4.236679524183273e-05\n",
      "The classification loss after processing this batch is:  22840.09765625\n",
      "The representation loss after processing this batch is:  3.989972174167633e-05\n",
      "The classification loss after processing this batch is:  21516.705078125\n",
      "The representation loss after processing this batch is:  3.5717152059078217e-05\n",
      "The classification loss after processing this batch is:  21639.791015625\n",
      "The representation loss after processing this batch is:  4.159845411777496e-05\n",
      "The classification loss after processing this batch is:  20925.98828125\n",
      "The representation loss after processing this batch is:  3.956584259867668e-05\n",
      "The classification loss after processing this batch is:  22301.138671875\n",
      "The representation loss after processing this batch is:  5.050515756011009e-05\n",
      "The classification loss after processing this batch is:  21925.96484375\n",
      "The representation loss after processing this batch is:  3.976002335548401e-05\n",
      "The classification loss after processing this batch is:  24559.228515625\n",
      "The representation loss after processing this batch is:  4.0844082832336426e-05\n",
      "The classification loss after processing this batch is:  22108.00390625\n",
      "The representation loss after processing this batch is:  4.431745037436485e-05\n",
      "The classification loss after processing this batch is:  22347.9296875\n",
      "The representation loss after processing this batch is:  3.9243604987859726e-05\n",
      "The classification loss after processing this batch is:  23793.7734375\n",
      "The representation loss after processing this batch is:  4.039239138364792e-05\n",
      "The classification loss after processing this batch is:  23452.86328125\n",
      "The representation loss after processing this batch is:  3.441702574491501e-05\n",
      "The classification loss after processing this batch is:  22654.451171875\n",
      "The representation loss after processing this batch is:  3.9292965084314346e-05\n",
      "The classification loss after processing this batch is:  24076.74609375\n",
      "The representation loss after processing this batch is:  4.365528002381325e-05\n",
      "The classification loss after processing this batch is:  22259.3125\n",
      "The representation loss after processing this batch is:  3.8625672459602356e-05\n",
      "The classification loss after processing this batch is:  22765.556640625\n",
      "The representation loss after processing this batch is:  4.033651202917099e-05\n",
      "The classification loss after processing this batch is:  21580.666015625\n",
      "The representation loss after processing this batch is:  3.529805690050125e-05\n",
      "The classification loss after processing this batch is:  21596.212890625\n",
      "The representation loss after processing this batch is:  3.595137968659401e-05\n",
      "The classification loss after processing this batch is:  21863.689453125\n",
      "The representation loss after processing this batch is:  3.7678051739931107e-05\n",
      "The classification loss after processing this batch is:  21803.791015625\n",
      "The representation loss after processing this batch is:  4.16426919400692e-05\n",
      "The classification loss after processing this batch is:  21851.943359375\n",
      "The representation loss after processing this batch is:  3.925338387489319e-05\n",
      "The classification loss after processing this batch is:  24397.04296875\n",
      "The representation loss after processing this batch is:  3.681192174553871e-05\n",
      "The classification loss after processing this batch is:  21741.857421875\n",
      "The representation loss after processing this batch is:  4.2218249291181564e-05\n",
      "The classification loss after processing this batch is:  21942.197265625\n",
      "The representation loss after processing this batch is:  3.438396379351616e-05\n",
      "The classification loss after processing this batch is:  22746.140625\n",
      "The representation loss after processing this batch is:  3.659212961792946e-05\n",
      "The classification loss after processing this batch is:  22221.822265625\n",
      "The representation loss after processing this batch is:  3.627408295869827e-05\n",
      "The classification loss after processing this batch is:  22884.798828125\n",
      "The representation loss after processing this batch is:  3.768177703022957e-05\n",
      "The classification loss after processing this batch is:  22729.2578125\n",
      "The representation loss after processing this batch is:  3.4901779145002365e-05\n",
      "The classification loss after processing this batch is:  22315.02734375\n",
      "The representation loss after processing this batch is:  3.958027809858322e-05\n",
      "The classification loss after processing this batch is:  21136.693359375\n",
      "The representation loss after processing this batch is:  3.5614706575870514e-05\n",
      "The classification loss after processing this batch is:  22784.705078125\n",
      "The representation loss after processing this batch is:  3.7396326661109924e-05\n",
      "The classification loss after processing this batch is:  25167.83203125\n",
      "The representation loss after processing this batch is:  3.8695987313985825e-05\n",
      "The classification loss after processing this batch is:  26001.14453125\n",
      "The representation loss after processing this batch is:  4.3274834752082825e-05\n",
      "The classification loss after processing this batch is:  22632.30078125\n",
      "The representation loss after processing this batch is:  3.5832636058330536e-05\n",
      "The classification loss after processing this batch is:  22495.37890625\n",
      "The representation loss after processing this batch is:  3.5305507481098175e-05\n",
      "The classification loss after processing this batch is:  22056.693359375\n",
      "The representation loss after processing this batch is:  3.7585385143756866e-05\n",
      "The classification loss after processing this batch is:  23036.857421875\n",
      "The representation loss after processing this batch is:  3.800122067332268e-05\n",
      "The classification loss after processing this batch is:  22027.142578125\n",
      "The representation loss after processing this batch is:  3.795372322201729e-05\n",
      "The classification loss after processing this batch is:  22392.1875\n",
      "The representation loss after processing this batch is:  3.5424716770648956e-05\n",
      "The classification loss after processing this batch is:  24129.8984375\n",
      "The representation loss after processing this batch is:  3.807852044701576e-05\n",
      "The classification loss after processing this batch is:  21199.083984375\n",
      "The representation loss after processing this batch is:  3.675464540719986e-05\n",
      "The classification loss after processing this batch is:  21676.080078125\n",
      "The representation loss after processing this batch is:  3.811344504356384e-05\n",
      "The classification loss after processing this batch is:  23673.73828125\n",
      "The representation loss after processing this batch is:  4.438543692231178e-05\n",
      "The classification loss after processing this batch is:  22466.14453125\n",
      "The representation loss after processing this batch is:  4.0599144995212555e-05\n",
      "The classification loss after processing this batch is:  21860.03515625\n",
      "The representation loss after processing this batch is:  3.835093230009079e-05\n",
      "The classification loss after processing this batch is:  20812.470703125\n",
      "The representation loss after processing this batch is:  3.5532284528017044e-05\n",
      "The classification loss after processing this batch is:  23383.453125\n",
      "The representation loss after processing this batch is:  4.091532900929451e-05\n",
      "The classification loss after processing this batch is:  22952.68359375\n",
      "The representation loss after processing this batch is:  4.2566098272800446e-05\n",
      "The classification loss after processing this batch is:  27475.4140625\n",
      "The representation loss after processing this batch is:  4.3981242924928665e-05\n",
      "The classification loss after processing this batch is:  23732.34765625\n",
      "The representation loss after processing this batch is:  3.996631130576134e-05\n",
      "The classification loss after processing this batch is:  22124.01953125\n",
      "The representation loss after processing this batch is:  3.7564896047115326e-05\n",
      "The classification loss after processing this batch is:  23409.02734375\n",
      "The representation loss after processing this batch is:  3.6044977605342865e-05\n",
      "The classification loss after processing this batch is:  24430.32421875\n",
      "The representation loss after processing this batch is:  4.031555727124214e-05\n",
      "The classification loss after processing this batch is:  23573.921875\n",
      "The representation loss after processing this batch is:  4.261871799826622e-05\n",
      "The classification loss after processing this batch is:  22918.9765625\n",
      "The representation loss after processing this batch is:  3.573764115571976e-05\n",
      "The classification loss after processing this batch is:  22858.533203125\n",
      "The representation loss after processing this batch is:  3.4899916499853134e-05\n",
      "The classification loss after processing this batch is:  22704.376953125\n",
      "The representation loss after processing this batch is:  3.534415736794472e-05\n",
      "The classification loss after processing this batch is:  21654.1875\n",
      "The representation loss after processing this batch is:  3.7215184420347214e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22723.33984375\n",
      "The representation loss after processing this batch is:  3.875419497489929e-05\n",
      "The classification loss after processing this batch is:  22404.576171875\n",
      "The representation loss after processing this batch is:  3.93143855035305e-05\n",
      "The classification loss after processing this batch is:  23081.3828125\n",
      "The representation loss after processing this batch is:  3.9756763726472855e-05\n",
      "The classification loss after processing this batch is:  23077.11328125\n",
      "The representation loss after processing this batch is:  3.574090078473091e-05\n",
      "The classification loss after processing this batch is:  23046.37109375\n",
      "The representation loss after processing this batch is:  3.8397032767534256e-05\n",
      "The classification loss after processing this batch is:  21845.078125\n",
      "The representation loss after processing this batch is:  3.582332283258438e-05\n",
      "The classification loss after processing this batch is:  21266.64453125\n",
      "The representation loss after processing this batch is:  4.082266241312027e-05\n",
      "The classification loss after processing this batch is:  21890.7421875\n",
      "The representation loss after processing this batch is:  3.640912473201752e-05\n",
      "The classification loss after processing this batch is:  21698.439453125\n",
      "The representation loss after processing this batch is:  3.423495218157768e-05\n",
      "The classification loss after processing this batch is:  22959.810546875\n",
      "The representation loss after processing this batch is:  3.628246486186981e-05\n",
      "The classification loss after processing this batch is:  22618.0703125\n",
      "The representation loss after processing this batch is:  3.4578610211610794e-05\n",
      "The classification loss after processing this batch is:  22017.486328125\n",
      "The representation loss after processing this batch is:  4.0891580283641815e-05\n",
      "The classification loss after processing this batch is:  21017.96875\n",
      "The representation loss after processing this batch is:  4.101451486349106e-05\n",
      "The classification loss after processing this batch is:  20966.021484375\n",
      "The representation loss after processing this batch is:  3.458932042121887e-05\n",
      "The classification loss after processing this batch is:  22490.35546875\n",
      "The representation loss after processing this batch is:  3.5375356674194336e-05\n",
      "The classification loss after processing this batch is:  23529.08984375\n",
      "The representation loss after processing this batch is:  3.458559513092041e-05\n",
      "The classification loss after processing this batch is:  23573.7890625\n",
      "The representation loss after processing this batch is:  4.612654447555542e-05\n",
      "The classification loss after processing this batch is:  21606.26953125\n",
      "The representation loss after processing this batch is:  3.753742203116417e-05\n",
      "The classification loss after processing this batch is:  22627.52734375\n",
      "The representation loss after processing this batch is:  3.562774509191513e-05\n",
      "The classification loss after processing this batch is:  21819.373046875\n",
      "The representation loss after processing this batch is:  4.076119512319565e-05\n",
      "The classification loss after processing this batch is:  22359.35546875\n",
      "The representation loss after processing this batch is:  4.666624590754509e-05\n",
      "The classification loss after processing this batch is:  21636.9296875\n",
      "The representation loss after processing this batch is:  3.48496250808239e-05\n",
      "The classification loss after processing this batch is:  21157.67578125\n",
      "The representation loss after processing this batch is:  4.2593106627464294e-05\n",
      "The classification loss after processing this batch is:  20969.5625\n",
      "The representation loss after processing this batch is:  3.6329030990600586e-05\n",
      "The classification loss after processing this batch is:  21909.76953125\n",
      "The representation loss after processing this batch is:  4.422478377819061e-05\n",
      "The classification loss after processing this batch is:  22140.59375\n",
      "The representation loss after processing this batch is:  4.350906237959862e-05\n",
      "The classification loss after processing this batch is:  22350.2578125\n",
      "The representation loss after processing this batch is:  3.4823548048734665e-05\n",
      "The classification loss after processing this batch is:  22221.859375\n",
      "The representation loss after processing this batch is:  3.897910937666893e-05\n",
      "The classification loss after processing this batch is:  21567.1796875\n",
      "The representation loss after processing this batch is:  3.355508670210838e-05\n",
      "The classification loss after processing this batch is:  23442.869140625\n",
      "The representation loss after processing this batch is:  3.796396777033806e-05\n",
      "The classification loss after processing this batch is:  24798.892578125\n",
      "The representation loss after processing this batch is:  4.899222403764725e-05\n",
      "The classification loss after processing this batch is:  23683.79296875\n",
      "The representation loss after processing this batch is:  4.086783155798912e-05\n",
      "The classification loss after processing this batch is:  23585.755859375\n",
      "The representation loss after processing this batch is:  4.234863445162773e-05\n",
      "The classification loss after processing this batch is:  21765.560546875\n",
      "The representation loss after processing this batch is:  3.596208989620209e-05\n",
      "The classification loss after processing this batch is:  22202.86328125\n",
      "The representation loss after processing this batch is:  3.3556949347257614e-05\n",
      "The classification loss after processing this batch is:  23420.609375\n",
      "The representation loss after processing this batch is:  3.905082121491432e-05\n",
      "The classification loss after processing this batch is:  21607.98046875\n",
      "The representation loss after processing this batch is:  4.127714782953262e-05\n",
      "The classification loss after processing this batch is:  21760.9609375\n",
      "The representation loss after processing this batch is:  3.636116161942482e-05\n",
      "The classification loss after processing this batch is:  22627.25\n",
      "The representation loss after processing this batch is:  3.697723150253296e-05\n",
      "The classification loss after processing this batch is:  22403.1875\n",
      "The representation loss after processing this batch is:  3.436999395489693e-05\n",
      "The classification loss after processing this batch is:  22310.359375\n",
      "The representation loss after processing this batch is:  3.5608187317848206e-05\n",
      "The classification loss after processing this batch is:  21975.9453125\n",
      "The representation loss after processing this batch is:  3.6164186894893646e-05\n",
      "The classification loss after processing this batch is:  23374.064453125\n",
      "The representation loss after processing this batch is:  4.350068047642708e-05\n",
      "The classification loss after processing this batch is:  23123.53125\n",
      "The representation loss after processing this batch is:  3.854231908917427e-05\n",
      "The classification loss after processing this batch is:  23711.677734375\n",
      "The representation loss after processing this batch is:  3.8300640881061554e-05\n",
      "The classification loss after processing this batch is:  23886.02734375\n",
      "The representation loss after processing this batch is:  4.308158531785011e-05\n",
      "The classification loss after processing this batch is:  22696.365234375\n",
      "The representation loss after processing this batch is:  3.491155803203583e-05\n",
      "The classification loss after processing this batch is:  21873.763671875\n",
      "The representation loss after processing this batch is:  3.462424501776695e-05\n",
      "The classification loss after processing this batch is:  21562.18359375\n",
      "The representation loss after processing this batch is:  3.641052171587944e-05\n",
      "The classification loss after processing this batch is:  21688.169921875\n",
      "The representation loss after processing this batch is:  3.4864526242017746e-05\n",
      "The classification loss after processing this batch is:  22127.921875\n",
      "The representation loss after processing this batch is:  3.760587424039841e-05\n",
      "The classification loss after processing this batch is:  21850.8515625\n",
      "The representation loss after processing this batch is:  3.450969234108925e-05\n",
      "The classification loss after processing this batch is:  22513.81640625\n",
      "The representation loss after processing this batch is:  3.662938252091408e-05\n",
      "The classification loss after processing this batch is:  22351.5390625\n",
      "The representation loss after processing this batch is:  4.097307100892067e-05\n",
      "The classification loss after processing this batch is:  25107.873046875\n",
      "The representation loss after processing this batch is:  4.429975524544716e-05\n",
      "The classification loss after processing this batch is:  24265.12109375\n",
      "The representation loss after processing this batch is:  3.6393292248249054e-05\n",
      "The classification loss after processing this batch is:  22236.375\n",
      "The representation loss after processing this batch is:  3.590993583202362e-05\n",
      "The classification loss after processing this batch is:  21239.63671875\n",
      "The representation loss after processing this batch is:  3.991229459643364e-05\n",
      "The classification loss after processing this batch is:  21410.24609375\n",
      "The representation loss after processing this batch is:  3.724545240402222e-05\n",
      "The classification loss after processing this batch is:  22453.619140625\n",
      "The representation loss after processing this batch is:  4.276540130376816e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22101.27734375\n",
      "The representation loss after processing this batch is:  3.9186328649520874e-05\n",
      "The classification loss after processing this batch is:  22562.640625\n",
      "The representation loss after processing this batch is:  3.668665885925293e-05\n",
      "The classification loss after processing this batch is:  21993.7109375\n",
      "The representation loss after processing this batch is:  3.797607496380806e-05\n",
      "The classification loss after processing this batch is:  21505.92578125\n",
      "The representation loss after processing this batch is:  3.1293835490942e-05\n",
      "The classification loss after processing this batch is:  21228.3984375\n",
      "The representation loss after processing this batch is:  3.3818650990724564e-05\n",
      "The classification loss after processing this batch is:  22900.171875\n",
      "The representation loss after processing this batch is:  3.579864278435707e-05\n",
      "The classification loss after processing this batch is:  23843.95703125\n",
      "The representation loss after processing this batch is:  4.246411845088005e-05\n",
      "The classification loss after processing this batch is:  22145.53125\n",
      "The representation loss after processing this batch is:  4.1371677070856094e-05\n",
      "The classification loss after processing this batch is:  22727.259765625\n",
      "The representation loss after processing this batch is:  3.512902185320854e-05\n",
      "The classification loss after processing this batch is:  23924.58203125\n",
      "The representation loss after processing this batch is:  3.9958860725164413e-05\n",
      "The classification loss after processing this batch is:  23040.705078125\n",
      "The representation loss after processing this batch is:  3.6854296922683716e-05\n",
      "The classification loss after processing this batch is:  24311.861328125\n",
      "The representation loss after processing this batch is:  3.642542287707329e-05\n",
      "The classification loss after processing this batch is:  22094.609375\n",
      "The representation loss after processing this batch is:  4.202406853437424e-05\n",
      "The classification loss after processing this batch is:  23222.97265625\n",
      "The representation loss after processing this batch is:  4.479847848415375e-05\n",
      "The classification loss after processing this batch is:  22025.76953125\n",
      "The representation loss after processing this batch is:  3.522634506225586e-05\n",
      "The classification loss after processing this batch is:  22773.671875\n",
      "The representation loss after processing this batch is:  3.203703090548515e-05\n",
      "The classification loss after processing this batch is:  22332.947265625\n",
      "The representation loss after processing this batch is:  3.7550460547208786e-05\n",
      "The classification loss after processing this batch is:  22255.056640625\n",
      "The representation loss after processing this batch is:  3.856467083096504e-05\n",
      "The classification loss after processing this batch is:  22780.4296875\n",
      "The representation loss after processing this batch is:  3.299955278635025e-05\n",
      "The classification loss after processing this batch is:  21688.421875\n",
      "The representation loss after processing this batch is:  3.7231482565402985e-05\n",
      "The classification loss after processing this batch is:  22039.939453125\n",
      "The representation loss after processing this batch is:  3.877375274896622e-05\n",
      "The classification loss after processing this batch is:  21196.0625\n",
      "The representation loss after processing this batch is:  3.792205825448036e-05\n",
      "The classification loss after processing this batch is:  21365.248046875\n",
      "The representation loss after processing this batch is:  4.8022717237472534e-05\n",
      "The classification loss after processing this batch is:  21208.869140625\n",
      "The representation loss after processing this batch is:  3.6078039556741714e-05\n",
      "The classification loss after processing this batch is:  22860.7265625\n",
      "The representation loss after processing this batch is:  3.967108204960823e-05\n",
      "The classification loss after processing this batch is:  21939.59375\n",
      "The representation loss after processing this batch is:  3.863312304019928e-05\n",
      "The classification loss after processing this batch is:  22792.796875\n",
      "The representation loss after processing this batch is:  3.648316487669945e-05\n",
      "The classification loss after processing this batch is:  22938.8515625\n",
      "The representation loss after processing this batch is:  3.3670105040073395e-05\n",
      "The classification loss after processing this batch is:  21691.54296875\n",
      "The representation loss after processing this batch is:  3.267871215939522e-05\n",
      "The classification loss after processing this batch is:  22872.234375\n",
      "The representation loss after processing this batch is:  4.261406138539314e-05\n",
      "The classification loss after processing this batch is:  22461.4921875\n",
      "The representation loss after processing this batch is:  3.726594150066376e-05\n",
      "The classification loss after processing this batch is:  21558.4609375\n",
      "The representation loss after processing this batch is:  3.571389243006706e-05\n",
      "The classification loss after processing this batch is:  22591.921875\n",
      "The representation loss after processing this batch is:  3.5523902624845505e-05\n",
      "The classification loss after processing this batch is:  22233.21484375\n",
      "The representation loss after processing this batch is:  3.569107502698898e-05\n",
      "The classification loss after processing this batch is:  21804.84765625\n",
      "The representation loss after processing this batch is:  3.483844920992851e-05\n",
      "The classification loss after processing this batch is:  22492.4453125\n",
      "The representation loss after processing this batch is:  3.573251888155937e-05\n",
      "The classification loss after processing this batch is:  22026.796875\n",
      "The representation loss after processing this batch is:  3.880588337779045e-05\n",
      "The classification loss after processing this batch is:  22922.36328125\n",
      "The representation loss after processing this batch is:  4.3144915252923965e-05\n",
      "The classification loss after processing this batch is:  23565.5859375\n",
      "The representation loss after processing this batch is:  3.681238740682602e-05\n",
      "The classification loss after processing this batch is:  22080.359375\n",
      "The representation loss after processing this batch is:  4.117889329791069e-05\n",
      "The classification loss after processing this batch is:  24532.40234375\n",
      "The representation loss after processing this batch is:  3.709224984049797e-05\n",
      "The classification loss after processing this batch is:  24939.87109375\n",
      "The representation loss after processing this batch is:  3.839796409010887e-05\n",
      "The classification loss after processing this batch is:  22162.708984375\n",
      "The representation loss after processing this batch is:  3.726547583937645e-05\n",
      "The classification loss after processing this batch is:  22883.892578125\n",
      "The representation loss after processing this batch is:  3.325473517179489e-05\n",
      "The classification loss after processing this batch is:  23746.33984375\n",
      "The representation loss after processing this batch is:  4.0378887206315994e-05\n",
      "The classification loss after processing this batch is:  22327.703125\n",
      "The representation loss after processing this batch is:  3.277882933616638e-05\n",
      "The classification loss after processing this batch is:  22364.37890625\n",
      "The representation loss after processing this batch is:  3.608036786317825e-05\n",
      "The classification loss after processing this batch is:  22201.23046875\n",
      "The representation loss after processing this batch is:  3.457069396972656e-05\n",
      "The classification loss after processing this batch is:  22544.62109375\n",
      "The representation loss after processing this batch is:  3.525521606206894e-05\n",
      "The classification loss after processing this batch is:  23377.72265625\n",
      "The representation loss after processing this batch is:  3.2729003578424454e-05\n",
      "The classification loss after processing this batch is:  23160.369140625\n",
      "The representation loss after processing this batch is:  3.803428262472153e-05\n",
      "The classification loss after processing this batch is:  25118.25390625\n",
      "The representation loss after processing this batch is:  4.169950261712074e-05\n",
      "The classification loss after processing this batch is:  23512.498046875\n",
      "The representation loss after processing this batch is:  3.421539440751076e-05\n",
      "The classification loss after processing this batch is:  23301.55859375\n",
      "The representation loss after processing this batch is:  3.414042294025421e-05\n",
      "The classification loss after processing this batch is:  21573.505859375\n",
      "The representation loss after processing this batch is:  3.279605880379677e-05\n",
      "The classification loss after processing this batch is:  21957.52734375\n",
      "The representation loss after processing this batch is:  3.3812131732702255e-05\n",
      "The classification loss after processing this batch is:  23167.2734375\n",
      "The representation loss after processing this batch is:  3.357976675033569e-05\n",
      "The classification loss after processing this batch is:  21894.609375\n",
      "The representation loss after processing this batch is:  3.773020580410957e-05\n",
      "The classification loss after processing this batch is:  20889.6875\n",
      "The representation loss after processing this batch is:  3.9150938391685486e-05\n",
      "The classification loss after processing this batch is:  23755.5546875\n",
      "The representation loss after processing this batch is:  3.40556725859642e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21631.85546875\n",
      "The representation loss after processing this batch is:  3.398023545742035e-05\n",
      "The classification loss after processing this batch is:  21719.37890625\n",
      "The representation loss after processing this batch is:  3.3260323107242584e-05\n",
      "The classification loss after processing this batch is:  20934.08984375\n",
      "The representation loss after processing this batch is:  3.9262231439352036e-05\n",
      "The classification loss after processing this batch is:  21556.66796875\n",
      "The representation loss after processing this batch is:  3.5952311009168625e-05\n",
      "The classification loss after processing this batch is:  21084.5625\n",
      "The representation loss after processing this batch is:  3.406265750527382e-05\n",
      "The classification loss after processing this batch is:  22344.3515625\n",
      "The representation loss after processing this batch is:  3.565894439816475e-05\n",
      "The classification loss after processing this batch is:  21960.2109375\n",
      "The representation loss after processing this batch is:  3.3546704798936844e-05\n",
      "The classification loss after processing this batch is:  21458.66015625\n",
      "The representation loss after processing this batch is:  3.367476165294647e-05\n",
      "The classification loss after processing this batch is:  22965.19140625\n",
      "The representation loss after processing this batch is:  3.493437543511391e-05\n",
      "The classification loss after processing this batch is:  23255.82421875\n",
      "The representation loss after processing this batch is:  3.686826676130295e-05\n",
      "The classification loss after processing this batch is:  21119.546875\n",
      "The representation loss after processing this batch is:  3.551924601197243e-05\n",
      "The classification loss after processing this batch is:  21463.296875\n",
      "The representation loss after processing this batch is:  3.9797741919755936e-05\n",
      "The classification loss after processing this batch is:  21823.513671875\n",
      "The representation loss after processing this batch is:  3.5923440009355545e-05\n",
      "The classification loss after processing this batch is:  21699.41796875\n",
      "The representation loss after processing this batch is:  3.533903509378433e-05\n",
      "The classification loss after processing this batch is:  23017.990234375\n",
      "The representation loss after processing this batch is:  3.6664772778749466e-05\n",
      "The classification loss after processing this batch is:  21631.966796875\n",
      "The representation loss after processing this batch is:  3.417115658521652e-05\n",
      "The classification loss after processing this batch is:  20988.388671875\n",
      "The representation loss after processing this batch is:  3.8514845073223114e-05\n",
      "The classification loss after processing this batch is:  22015.875\n",
      "The representation loss after processing this batch is:  4.107039421796799e-05\n",
      "The classification loss after processing this batch is:  24070.0546875\n",
      "The representation loss after processing this batch is:  4.0576327592134476e-05\n",
      "The classification loss after processing this batch is:  21627.43359375\n",
      "The representation loss after processing this batch is:  3.345450386404991e-05\n",
      "The classification loss after processing this batch is:  22592.908203125\n",
      "The representation loss after processing this batch is:  3.482680767774582e-05\n",
      "The classification loss after processing this batch is:  24373.015625\n",
      "The representation loss after processing this batch is:  3.6049168556928635e-05\n",
      "The classification loss after processing this batch is:  22089.24609375\n",
      "The representation loss after processing this batch is:  3.7344638258218765e-05\n",
      "The classification loss after processing this batch is:  21293.21484375\n",
      "The representation loss after processing this batch is:  3.604171797633171e-05\n",
      "The classification loss after processing this batch is:  21568.79296875\n",
      "The representation loss after processing this batch is:  3.78158874809742e-05\n",
      "The classification loss after processing this batch is:  21310.86328125\n",
      "The representation loss after processing this batch is:  3.463122993707657e-05\n",
      "The classification loss after processing this batch is:  21904.083984375\n",
      "The representation loss after processing this batch is:  3.3499207347631454e-05\n",
      "The classification loss after processing this batch is:  21490.87109375\n",
      "The representation loss after processing this batch is:  3.984151408076286e-05\n",
      "The classification loss after processing this batch is:  22113.60546875\n",
      "The representation loss after processing this batch is:  3.6162324249744415e-05\n",
      "The classification loss after processing this batch is:  25005.609375\n",
      "The representation loss after processing this batch is:  3.992626443505287e-05\n",
      "The classification loss after processing this batch is:  23294.55078125\n",
      "The representation loss after processing this batch is:  3.2720621675252914e-05\n",
      "The classification loss after processing this batch is:  22751.986328125\n",
      "The representation loss after processing this batch is:  3.418838605284691e-05\n",
      "The classification loss after processing this batch is:  21621.89453125\n",
      "The representation loss after processing this batch is:  3.378419205546379e-05\n",
      "The classification loss after processing this batch is:  22009.49609375\n",
      "The representation loss after processing this batch is:  4.016375169157982e-05\n",
      "The classification loss after processing this batch is:  21969.75\n",
      "The representation loss after processing this batch is:  3.8945116102695465e-05\n",
      "The classification loss after processing this batch is:  21640.8515625\n",
      "The representation loss after processing this batch is:  3.3307820558547974e-05\n",
      "The classification loss after processing this batch is:  20941.9453125\n",
      "The representation loss after processing this batch is:  3.460794687271118e-05\n",
      "The classification loss after processing this batch is:  21612.0234375\n",
      "The representation loss after processing this batch is:  3.300141543149948e-05\n",
      "The classification loss after processing this batch is:  21542.77734375\n",
      "The representation loss after processing this batch is:  3.329571336507797e-05\n",
      "The classification loss after processing this batch is:  20839.3515625\n",
      "The representation loss after processing this batch is:  3.4049153327941895e-05\n",
      "The classification loss after processing this batch is:  21921.298828125\n",
      "The representation loss after processing this batch is:  3.3884309232234955e-05\n",
      "The classification loss after processing this batch is:  21051.05859375\n",
      "The representation loss after processing this batch is:  3.587501123547554e-05\n",
      "The classification loss after processing this batch is:  23380.837890625\n",
      "The representation loss after processing this batch is:  3.8669444620609283e-05\n",
      "The classification loss after processing this batch is:  23132.361328125\n",
      "The representation loss after processing this batch is:  3.375997766852379e-05\n",
      "The classification loss after processing this batch is:  22075.021484375\n",
      "The representation loss after processing this batch is:  3.303820267319679e-05\n",
      "The classification loss after processing this batch is:  21805.578125\n",
      "The representation loss after processing this batch is:  3.192480653524399e-05\n",
      "The classification loss after processing this batch is:  21603.1484375\n",
      "The representation loss after processing this batch is:  3.282260149717331e-05\n",
      "The classification loss after processing this batch is:  23096.181640625\n",
      "The representation loss after processing this batch is:  3.659212961792946e-05\n",
      "The classification loss after processing this batch is:  22707.486328125\n",
      "The representation loss after processing this batch is:  3.526313230395317e-05\n",
      "The classification loss after processing this batch is:  21932.4453125\n",
      "The representation loss after processing this batch is:  3.325287252664566e-05\n",
      "The classification loss after processing this batch is:  22266.24609375\n",
      "The representation loss after processing this batch is:  3.1833071261644363e-05\n",
      "The classification loss after processing this batch is:  24158.65234375\n",
      "The representation loss after processing this batch is:  3.897910937666893e-05\n",
      "The classification loss after processing this batch is:  21533.515625\n",
      "The representation loss after processing this batch is:  3.455905243754387e-05\n",
      "The classification loss after processing this batch is:  22372.783203125\n",
      "The representation loss after processing this batch is:  3.4578144550323486e-05\n",
      "The classification loss after processing this batch is:  22539.96484375\n",
      "The representation loss after processing this batch is:  4.083290696144104e-05\n",
      "The classification loss after processing this batch is:  22037.982421875\n",
      "The representation loss after processing this batch is:  3.3581629395484924e-05\n",
      "The classification loss after processing this batch is:  22678.841796875\n",
      "The representation loss after processing this batch is:  4.0698330849409103e-05\n",
      "The classification loss after processing this batch is:  23170.34375\n",
      "The representation loss after processing this batch is:  4.024384543299675e-05\n",
      "The classification loss after processing this batch is:  21924.66796875\n",
      "The representation loss after processing this batch is:  4.593236371874809e-05\n",
      "The classification loss after processing this batch is:  22700.52734375\n",
      "The representation loss after processing this batch is:  3.232574090361595e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  23135.640625\n",
      "The representation loss after processing this batch is:  3.260653465986252e-05\n",
      "The classification loss after processing this batch is:  21822.90234375\n",
      "The representation loss after processing this batch is:  4.36403788626194e-05\n",
      "The classification loss after processing this batch is:  22897.04296875\n",
      "The representation loss after processing this batch is:  3.562634810805321e-05\n",
      "The classification loss after processing this batch is:  22527.296875\n",
      "The representation loss after processing this batch is:  3.213062882423401e-05\n",
      "The classification loss after processing this batch is:  21388.9921875\n",
      "The representation loss after processing this batch is:  3.75392846763134e-05\n",
      "The classification loss after processing this batch is:  21774.833984375\n",
      "The representation loss after processing this batch is:  3.644172102212906e-05\n",
      "The classification loss after processing this batch is:  21583.169921875\n",
      "The representation loss after processing this batch is:  3.890739753842354e-05\n",
      "The classification loss after processing this batch is:  21608.52734375\n",
      "The representation loss after processing this batch is:  3.432808443903923e-05\n",
      "The classification loss after processing this batch is:  23483.80859375\n",
      "The representation loss after processing this batch is:  3.6302488297224045e-05\n",
      "The classification loss after processing this batch is:  22990.681640625\n",
      "The representation loss after processing this batch is:  3.2644253224134445e-05\n",
      "The classification loss after processing this batch is:  23848.71484375\n",
      "The representation loss after processing this batch is:  3.7060119211673737e-05\n",
      "The classification loss after processing this batch is:  20874.421875\n",
      "The representation loss after processing this batch is:  3.7740450352430344e-05\n",
      "The classification loss after processing this batch is:  21399.455078125\n",
      "The representation loss after processing this batch is:  3.880215808749199e-05\n",
      "The classification loss after processing this batch is:  21732.361328125\n",
      "The representation loss after processing this batch is:  3.735534846782684e-05\n",
      "The classification loss after processing this batch is:  21422.50390625\n",
      "The representation loss after processing this batch is:  3.225775435566902e-05\n",
      "The classification loss after processing this batch is:  22730.736328125\n",
      "The representation loss after processing this batch is:  3.885757178068161e-05\n",
      "The classification loss after processing this batch is:  21688.365234375\n",
      "The representation loss after processing this batch is:  3.154529258608818e-05\n",
      "The classification loss after processing this batch is:  22349.59375\n",
      "The representation loss after processing this batch is:  3.3663585782051086e-05\n",
      "The classification loss after processing this batch is:  22396.46875\n",
      "The representation loss after processing this batch is:  3.6321114748716354e-05\n",
      "The classification loss after processing this batch is:  21469.75\n",
      "The representation loss after processing this batch is:  3.609387204051018e-05\n",
      "The classification loss after processing this batch is:  23482.48828125\n",
      "The representation loss after processing this batch is:  4.068436101078987e-05\n",
      "The classification loss after processing this batch is:  23657.474609375\n",
      "The representation loss after processing this batch is:  3.4411437809467316e-05\n",
      "The classification loss after processing this batch is:  22846.99609375\n",
      "The representation loss after processing this batch is:  3.486312925815582e-05\n",
      "The classification loss after processing this batch is:  21144.0078125\n",
      "The representation loss after processing this batch is:  3.8100406527519226e-05\n",
      "The classification loss after processing this batch is:  23258.349609375\n",
      "The representation loss after processing this batch is:  3.4357886761426926e-05\n",
      "The classification loss after processing this batch is:  23106.5859375\n",
      "The representation loss after processing this batch is:  3.398861736059189e-05\n",
      "The classification loss after processing this batch is:  21513.33984375\n",
      "The representation loss after processing this batch is:  3.391038626432419e-05\n",
      "The classification loss after processing this batch is:  23632.939453125\n",
      "The representation loss after processing this batch is:  3.793090581893921e-05\n",
      "The classification loss after processing this batch is:  23505.392578125\n",
      "The representation loss after processing this batch is:  3.822473809123039e-05\n",
      "The classification loss after processing this batch is:  21185.98828125\n",
      "The representation loss after processing this batch is:  3.253156319260597e-05\n",
      "The classification loss after processing this batch is:  21768.384765625\n",
      "The representation loss after processing this batch is:  3.317836672067642e-05\n",
      "The classification loss after processing this batch is:  22465.3984375\n",
      "The representation loss after processing this batch is:  4.275655373930931e-05\n",
      "The classification loss after processing this batch is:  21935.20703125\n",
      "The representation loss after processing this batch is:  3.607012331485748e-05\n",
      "The classification loss after processing this batch is:  22881.2890625\n",
      "The representation loss after processing this batch is:  4.2972154915332794e-05\n",
      "The classification loss after processing this batch is:  23421.25390625\n",
      "The representation loss after processing this batch is:  3.685196861624718e-05\n",
      "The classification loss after processing this batch is:  21410.2109375\n",
      "The representation loss after processing this batch is:  3.927526995539665e-05\n",
      "The classification loss after processing this batch is:  20852.87890625\n",
      "The representation loss after processing this batch is:  3.542238846421242e-05\n",
      "The classification loss after processing this batch is:  22276.662109375\n",
      "The representation loss after processing this batch is:  3.393320366740227e-05\n",
      "The classification loss after processing this batch is:  23354.875\n",
      "The representation loss after processing this batch is:  3.733718767762184e-05\n",
      "The classification loss after processing this batch is:  21859.6953125\n",
      "The representation loss after processing this batch is:  3.37488017976284e-05\n",
      "The classification loss after processing this batch is:  22664.748046875\n",
      "The representation loss after processing this batch is:  3.7774909287691116e-05\n",
      "The classification loss after processing this batch is:  22234.142578125\n",
      "The representation loss after processing this batch is:  3.197556361556053e-05\n",
      "The classification loss after processing this batch is:  22356.787109375\n",
      "The representation loss after processing this batch is:  3.63900326192379e-05\n",
      "The classification loss after processing this batch is:  21665.650390625\n",
      "The representation loss after processing this batch is:  3.5789329558610916e-05\n",
      "The classification loss after processing this batch is:  22075.40234375\n",
      "The representation loss after processing this batch is:  3.62638384103775e-05\n",
      "The classification loss after processing this batch is:  23400.33984375\n",
      "The representation loss after processing this batch is:  3.653205931186676e-05\n",
      "The classification loss after processing this batch is:  20999.06640625\n",
      "The representation loss after processing this batch is:  3.4994445741176605e-05\n",
      "The classification loss after processing this batch is:  20946.0546875\n",
      "The representation loss after processing this batch is:  3.437185660004616e-05\n",
      "The classification loss after processing this batch is:  20762.353515625\n",
      "The representation loss after processing this batch is:  3.405660390853882e-05\n",
      "The classification loss after processing this batch is:  20961.302734375\n",
      "The representation loss after processing this batch is:  3.435974940657616e-05\n",
      "The classification loss after processing this batch is:  21356.53125\n",
      "The representation loss after processing this batch is:  3.256881609559059e-05\n",
      "The classification loss after processing this batch is:  22621.873046875\n",
      "The representation loss after processing this batch is:  3.454042598605156e-05\n",
      "The classification loss after processing this batch is:  22645.73046875\n",
      "The representation loss after processing this batch is:  3.464799374341965e-05\n",
      "The classification loss after processing this batch is:  21287.359375\n",
      "The representation loss after processing this batch is:  3.5482924431562424e-05\n",
      "The classification loss after processing this batch is:  20793.3984375\n",
      "The representation loss after processing this batch is:  3.179861232638359e-05\n",
      "The classification loss after processing this batch is:  21132.68359375\n",
      "The representation loss after processing this batch is:  3.297673538327217e-05\n",
      "The classification loss after processing this batch is:  21720.638671875\n",
      "The representation loss after processing this batch is:  3.603799268603325e-05\n",
      "The classification loss after processing this batch is:  21882.9375\n",
      "The representation loss after processing this batch is:  3.3678486943244934e-05\n",
      "The classification loss after processing this batch is:  21025.93359375\n",
      "The representation loss after processing this batch is:  3.6076176911592484e-05\n",
      "The classification loss after processing this batch is:  23407.08984375\n",
      "The representation loss after processing this batch is:  3.2553914934396744e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21509.025390625\n",
      "The representation loss after processing this batch is:  3.357045352458954e-05\n",
      "The classification loss after processing this batch is:  21129.58203125\n",
      "The representation loss after processing this batch is:  3.5050325095653534e-05\n",
      "The classification loss after processing this batch is:  21676.19140625\n",
      "The representation loss after processing this batch is:  3.577256575226784e-05\n",
      "The classification loss after processing this batch is:  22474.7734375\n",
      "The representation loss after processing this batch is:  3.654230386018753e-05\n",
      "The classification loss after processing this batch is:  22030.09375\n",
      "The representation loss after processing this batch is:  3.325054422020912e-05\n",
      "The classification loss after processing this batch is:  21184.025390625\n",
      "The representation loss after processing this batch is:  3.932509571313858e-05\n",
      "The classification loss after processing this batch is:  21908.96875\n",
      "The representation loss after processing this batch is:  3.477977588772774e-05\n",
      "The classification loss after processing this batch is:  23304.185546875\n",
      "The representation loss after processing this batch is:  3.42479906976223e-05\n",
      "The classification loss after processing this batch is:  20601.28125\n",
      "The representation loss after processing this batch is:  3.379024565219879e-05\n",
      "The classification loss after processing this batch is:  21340.708984375\n",
      "The representation loss after processing this batch is:  3.544706851243973e-05\n",
      "The classification loss after processing this batch is:  20184.326171875\n",
      "The representation loss after processing this batch is:  3.462517634034157e-05\n",
      "The classification loss after processing this batch is:  21750.484375\n",
      "The representation loss after processing this batch is:  3.187265247106552e-05\n",
      "The classification loss after processing this batch is:  22037.140625\n",
      "The representation loss after processing this batch is:  3.27499583363533e-05\n",
      "The classification loss after processing this batch is:  21442.193359375\n",
      "The representation loss after processing this batch is:  3.3037737011909485e-05\n",
      "The classification loss after processing this batch is:  21210.517578125\n",
      "The representation loss after processing this batch is:  3.6932993680238724e-05\n",
      "The classification loss after processing this batch is:  20745.9765625\n",
      "The representation loss after processing this batch is:  3.4631695598363876e-05\n",
      "The classification loss after processing this batch is:  21742.46875\n",
      "The representation loss after processing this batch is:  3.1340401619672775e-05\n",
      "The classification loss after processing this batch is:  21449.5\n",
      "The representation loss after processing this batch is:  3.477931022644043e-05\n",
      "The classification loss after processing this batch is:  20793.388671875\n",
      "The representation loss after processing this batch is:  3.652134910225868e-05\n",
      "The classification loss after processing this batch is:  24869.984375\n",
      "The representation loss after processing this batch is:  3.976654261350632e-05\n",
      "The classification loss after processing this batch is:  23276.6640625\n",
      "The representation loss after processing this batch is:  3.766454756259918e-05\n",
      "The classification loss after processing this batch is:  22366.53125\n",
      "The representation loss after processing this batch is:  3.4677330404520035e-05\n",
      "The classification loss after processing this batch is:  21588.33984375\n",
      "The representation loss after processing this batch is:  3.640586510300636e-05\n",
      "The classification loss after processing this batch is:  20897.69140625\n",
      "The representation loss after processing this batch is:  3.661401569843292e-05\n",
      "The classification loss after processing this batch is:  21628.177734375\n",
      "The representation loss after processing this batch is:  3.443937748670578e-05\n",
      "The classification loss after processing this batch is:  22620.341796875\n",
      "The representation loss after processing this batch is:  3.6246608942747116e-05\n",
      "The classification loss after processing this batch is:  21695.5703125\n",
      "The representation loss after processing this batch is:  3.200024366378784e-05\n",
      "The classification loss after processing this batch is:  23580.69140625\n",
      "The representation loss after processing this batch is:  3.356439992785454e-05\n",
      "The classification loss after processing this batch is:  21811.693359375\n",
      "The representation loss after processing this batch is:  3.5843346267938614e-05\n",
      "The classification loss after processing this batch is:  21051.2578125\n",
      "The representation loss after processing this batch is:  3.482401371002197e-05\n",
      "The classification loss after processing this batch is:  22644.62890625\n",
      "The representation loss after processing this batch is:  3.5176053643226624e-05\n",
      "The classification loss after processing this batch is:  21210.08203125\n",
      "The representation loss after processing this batch is:  3.536045551300049e-05\n",
      "The classification loss after processing this batch is:  21461.546875\n",
      "The representation loss after processing this batch is:  3.722822293639183e-05\n",
      "The classification loss after processing this batch is:  25210.810546875\n",
      "The representation loss after processing this batch is:  4.097912460565567e-05\n",
      "The classification loss after processing this batch is:  22529.9296875\n",
      "The representation loss after processing this batch is:  3.75933013856411e-05\n",
      "The classification loss after processing this batch is:  21185.0390625\n",
      "The representation loss after processing this batch is:  3.910250961780548e-05\n",
      "The classification loss after processing this batch is:  21311.162109375\n",
      "The representation loss after processing this batch is:  4.900852218270302e-05\n",
      "The classification loss after processing this batch is:  23586.53125\n",
      "The representation loss after processing this batch is:  3.768084570765495e-05\n",
      "The classification loss after processing this batch is:  20769.7265625\n",
      "The representation loss after processing this batch is:  3.820424899458885e-05\n",
      "The classification loss after processing this batch is:  21647.24609375\n",
      "The representation loss after processing this batch is:  4.167528823018074e-05\n",
      "The classification loss after processing this batch is:  22630.462890625\n",
      "The representation loss after processing this batch is:  4.437519237399101e-05\n",
      "The classification loss after processing this batch is:  26394.25390625\n",
      "The representation loss after processing this batch is:  4.0168873965740204e-05\n",
      "The classification loss after processing this batch is:  28634.951171875\n",
      "The representation loss after processing this batch is:  3.578187897801399e-05\n",
      "The classification loss after processing this batch is:  20965.197265625\n",
      "The representation loss after processing this batch is:  3.6634039133787155e-05\n",
      "The classification loss after processing this batch is:  22420.630859375\n",
      "The representation loss after processing this batch is:  3.902893513441086e-05\n",
      "The classification loss after processing this batch is:  22459.640625\n",
      "The representation loss after processing this batch is:  3.896420821547508e-05\n",
      "The classification loss after processing this batch is:  20481.30078125\n",
      "The representation loss after processing this batch is:  3.51686030626297e-05\n",
      "the loss after processing this epoch is:  0.1075374111533165\n",
      "the loss after processing this epoch is:  0.1184273362159729\n",
      "the loss after processing this epoch is:  0.025251328945159912\n",
      "the loss after processing this epoch is:  0.00283350539393723\n",
      "the loss after processing this epoch is:  0.001389066455885768\n",
      "the loss after processing this epoch is:  0.0005130817298777401\n",
      "the loss after processing this epoch is:  0.00047440826892852783\n",
      "the loss after processing this epoch is:  0.00033790868474170566\n",
      "the loss after processing this epoch is:  0.00014304120850283653\n",
      "the loss after processing this epoch is:  6.50187284918502e-05\n",
      "The classification loss after processing this batch is:  22198.3515625\n",
      "The representation loss after processing this batch is:  0.0013788724318146706\n",
      "The classification loss after processing this batch is:  21687.41015625\n",
      "The representation loss after processing this batch is:  0.0006445129401981831\n",
      "The classification loss after processing this batch is:  20643.5546875\n",
      "The representation loss after processing this batch is:  0.0005135419778525829\n",
      "The classification loss after processing this batch is:  21625.6875\n",
      "The representation loss after processing this batch is:  0.0005006366409361362\n",
      "The classification loss after processing this batch is:  22651.048828125\n",
      "The representation loss after processing this batch is:  0.0004494674503803253\n",
      "The classification loss after processing this batch is:  22974.740234375\n",
      "The representation loss after processing this batch is:  0.00038153864443302155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22511.8125\n",
      "The representation loss after processing this batch is:  0.00035136379301548004\n",
      "The classification loss after processing this batch is:  22897.91015625\n",
      "The representation loss after processing this batch is:  0.00030672457069158554\n",
      "The classification loss after processing this batch is:  22975.330078125\n",
      "The representation loss after processing this batch is:  0.0002947193570435047\n",
      "The classification loss after processing this batch is:  24337.244140625\n",
      "The representation loss after processing this batch is:  0.000321198720484972\n",
      "The classification loss after processing this batch is:  23505.255859375\n",
      "The representation loss after processing this batch is:  0.00032012490555644035\n",
      "The classification loss after processing this batch is:  23613.482421875\n",
      "The representation loss after processing this batch is:  0.0002417340874671936\n",
      "The classification loss after processing this batch is:  23943.48828125\n",
      "The representation loss after processing this batch is:  0.00018519069999456406\n",
      "The classification loss after processing this batch is:  23690.05859375\n",
      "The representation loss after processing this batch is:  0.00021807663142681122\n",
      "The classification loss after processing this batch is:  23824.6171875\n",
      "The representation loss after processing this batch is:  0.00021443422883749008\n",
      "The classification loss after processing this batch is:  24277.224609375\n",
      "The representation loss after processing this batch is:  0.00021439045667648315\n",
      "The classification loss after processing this batch is:  23916.654296875\n",
      "The representation loss after processing this batch is:  0.00017970893532037735\n",
      "The classification loss after processing this batch is:  25581.091796875\n",
      "The representation loss after processing this batch is:  0.0002207653596997261\n",
      "The classification loss after processing this batch is:  24368.6171875\n",
      "The representation loss after processing this batch is:  0.00017277710139751434\n",
      "The classification loss after processing this batch is:  24890.91796875\n",
      "The representation loss after processing this batch is:  0.00016925297677516937\n",
      "The classification loss after processing this batch is:  24752.455078125\n",
      "The representation loss after processing this batch is:  0.00016925018280744553\n",
      "The classification loss after processing this batch is:  24970.6875\n",
      "The representation loss after processing this batch is:  0.00016590021550655365\n",
      "The classification loss after processing this batch is:  25119.12109375\n",
      "The representation loss after processing this batch is:  0.00016049295663833618\n",
      "The classification loss after processing this batch is:  24433.84765625\n",
      "The representation loss after processing this batch is:  0.0001645796000957489\n",
      "The classification loss after processing this batch is:  24266.302734375\n",
      "The representation loss after processing this batch is:  0.00018451549112796783\n",
      "The classification loss after processing this batch is:  23444.671875\n",
      "The representation loss after processing this batch is:  0.00018015317618846893\n",
      "The classification loss after processing this batch is:  24101.046875\n",
      "The representation loss after processing this batch is:  0.00014876015484333038\n",
      "The classification loss after processing this batch is:  23993.19921875\n",
      "The representation loss after processing this batch is:  0.00015808269381523132\n",
      "The classification loss after processing this batch is:  27236.556640625\n",
      "The representation loss after processing this batch is:  0.00017070770263671875\n",
      "The classification loss after processing this batch is:  25468.763671875\n",
      "The representation loss after processing this batch is:  0.00014275871217250824\n",
      "The classification loss after processing this batch is:  23908.9375\n",
      "The representation loss after processing this batch is:  0.00014171376824378967\n",
      "The classification loss after processing this batch is:  24398.20703125\n",
      "The representation loss after processing this batch is:  0.00012738816440105438\n",
      "The classification loss after processing this batch is:  23368.05078125\n",
      "The representation loss after processing this batch is:  0.0001634545624256134\n",
      "The classification loss after processing this batch is:  24123.01953125\n",
      "The representation loss after processing this batch is:  0.00015602260828018188\n",
      "The classification loss after processing this batch is:  24366.806640625\n",
      "The representation loss after processing this batch is:  0.00015419162809848785\n",
      "The classification loss after processing this batch is:  24900.26171875\n",
      "The representation loss after processing this batch is:  0.00014450587332248688\n",
      "The classification loss after processing this batch is:  26025.03515625\n",
      "The representation loss after processing this batch is:  0.00014782510697841644\n",
      "The classification loss after processing this batch is:  29241.8359375\n",
      "The representation loss after processing this batch is:  0.00021696463227272034\n",
      "The classification loss after processing this batch is:  24057.9453125\n",
      "The representation loss after processing this batch is:  0.00014405883848667145\n",
      "The classification loss after processing this batch is:  24928.998046875\n",
      "The representation loss after processing this batch is:  0.00013723038136959076\n",
      "The classification loss after processing this batch is:  25159.201171875\n",
      "The representation loss after processing this batch is:  0.00015670433640480042\n",
      "The classification loss after processing this batch is:  25054.111328125\n",
      "The representation loss after processing this batch is:  0.00014649704098701477\n",
      "The classification loss after processing this batch is:  24395.26953125\n",
      "The representation loss after processing this batch is:  0.00015067122876644135\n",
      "The classification loss after processing this batch is:  24543.68359375\n",
      "The representation loss after processing this batch is:  0.00015750713646411896\n",
      "The classification loss after processing this batch is:  24320.65625\n",
      "The representation loss after processing this batch is:  0.00015646032989025116\n",
      "The classification loss after processing this batch is:  23990.6953125\n",
      "The representation loss after processing this batch is:  0.00014077872037887573\n",
      "The classification loss after processing this batch is:  23680.0\n",
      "The representation loss after processing this batch is:  0.00014345906674861908\n",
      "The classification loss after processing this batch is:  24079.85546875\n",
      "The representation loss after processing this batch is:  0.0001390501856803894\n",
      "The classification loss after processing this batch is:  23802.576171875\n",
      "The representation loss after processing this batch is:  0.00012843124568462372\n",
      "The classification loss after processing this batch is:  23840.6484375\n",
      "The representation loss after processing this batch is:  0.00016082078218460083\n",
      "The classification loss after processing this batch is:  23664.685546875\n",
      "The representation loss after processing this batch is:  0.00015606917440891266\n",
      "The classification loss after processing this batch is:  22393.82421875\n",
      "The representation loss after processing this batch is:  0.00012844614684581757\n",
      "The classification loss after processing this batch is:  23085.826171875\n",
      "The representation loss after processing this batch is:  0.0001545492559671402\n",
      "The classification loss after processing this batch is:  23299.57421875\n",
      "The representation loss after processing this batch is:  0.00016974005848169327\n",
      "The classification loss after processing this batch is:  23529.22265625\n",
      "The representation loss after processing this batch is:  0.00014471262693405151\n",
      "The classification loss after processing this batch is:  22870.2734375\n",
      "The representation loss after processing this batch is:  0.00013208389282226562\n",
      "The classification loss after processing this batch is:  24334.435546875\n",
      "The representation loss after processing this batch is:  0.00013399124145507812\n",
      "The classification loss after processing this batch is:  23059.447265625\n",
      "The representation loss after processing this batch is:  0.00015026330947875977\n",
      "The classification loss after processing this batch is:  22817.6796875\n",
      "The representation loss after processing this batch is:  0.00016460567712783813\n",
      "The classification loss after processing this batch is:  23541.640625\n",
      "The representation loss after processing this batch is:  0.00013767369091510773\n",
      "The classification loss after processing this batch is:  25080.369140625\n",
      "The representation loss after processing this batch is:  0.00013985112309455872\n",
      "The classification loss after processing this batch is:  25706.255859375\n",
      "The representation loss after processing this batch is:  0.00012333132326602936\n",
      "The classification loss after processing this batch is:  24882.869140625\n",
      "The representation loss after processing this batch is:  0.00011931173503398895\n",
      "The classification loss after processing this batch is:  22551.6640625\n",
      "The representation loss after processing this batch is:  0.00013105198740959167\n",
      "The classification loss after processing this batch is:  24006.322265625\n",
      "The representation loss after processing this batch is:  0.00013235211372375488\n",
      "The classification loss after processing this batch is:  23295.8984375\n",
      "The representation loss after processing this batch is:  0.00012935232371091843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24257.87109375\n",
      "The representation loss after processing this batch is:  0.0001485925167798996\n",
      "The classification loss after processing this batch is:  24665.36328125\n",
      "The representation loss after processing this batch is:  0.00014005787670612335\n",
      "The classification loss after processing this batch is:  23503.357421875\n",
      "The representation loss after processing this batch is:  0.00012246426194906235\n",
      "The classification loss after processing this batch is:  23641.50390625\n",
      "The representation loss after processing this batch is:  0.00013089366257190704\n",
      "The classification loss after processing this batch is:  24009.32421875\n",
      "The representation loss after processing this batch is:  0.00012970715761184692\n",
      "The classification loss after processing this batch is:  24457.833984375\n",
      "The representation loss after processing this batch is:  0.00012127682566642761\n",
      "The classification loss after processing this batch is:  22937.904296875\n",
      "The representation loss after processing this batch is:  0.00014496967196464539\n",
      "The classification loss after processing this batch is:  24381.94140625\n",
      "The representation loss after processing this batch is:  0.00012731458991765976\n",
      "The classification loss after processing this batch is:  24568.75\n",
      "The representation loss after processing this batch is:  0.00012944824993610382\n",
      "The classification loss after processing this batch is:  25024.98046875\n",
      "The representation loss after processing this batch is:  0.00016168877482414246\n",
      "The classification loss after processing this batch is:  23933.5546875\n",
      "The representation loss after processing this batch is:  0.00011380854994058609\n",
      "The classification loss after processing this batch is:  23651.9765625\n",
      "The representation loss after processing this batch is:  0.00012317951768636703\n",
      "The classification loss after processing this batch is:  23417.7109375\n",
      "The representation loss after processing this batch is:  0.00012417510151863098\n",
      "The classification loss after processing this batch is:  24407.818359375\n",
      "The representation loss after processing this batch is:  0.00012468546628952026\n",
      "The classification loss after processing this batch is:  24881.56640625\n",
      "The representation loss after processing this batch is:  0.00013025663793087006\n",
      "The classification loss after processing this batch is:  23347.70703125\n",
      "The representation loss after processing this batch is:  0.00013816915452480316\n",
      "The classification loss after processing this batch is:  22601.876953125\n",
      "The representation loss after processing this batch is:  0.0001288093626499176\n",
      "The classification loss after processing this batch is:  23244.60546875\n",
      "The representation loss after processing this batch is:  0.0001281946897506714\n",
      "The classification loss after processing this batch is:  22454.8046875\n",
      "The representation loss after processing this batch is:  0.00011734478175640106\n",
      "The classification loss after processing this batch is:  22730.158203125\n",
      "The representation loss after processing this batch is:  0.0001127263531088829\n",
      "The classification loss after processing this batch is:  22915.27734375\n",
      "The representation loss after processing this batch is:  0.00013768672943115234\n",
      "The classification loss after processing this batch is:  22861.77734375\n",
      "The representation loss after processing this batch is:  0.00012793764472007751\n",
      "The classification loss after processing this batch is:  22467.130859375\n",
      "The representation loss after processing this batch is:  0.00011301971971988678\n",
      "The classification loss after processing this batch is:  22006.6328125\n",
      "The representation loss after processing this batch is:  0.0001275334507226944\n",
      "The classification loss after processing this batch is:  22378.96875\n",
      "The representation loss after processing this batch is:  0.00012671295553445816\n",
      "The classification loss after processing this batch is:  21945.046875\n",
      "The representation loss after processing this batch is:  0.0001450190320611\n",
      "The classification loss after processing this batch is:  22210.40625\n",
      "The representation loss after processing this batch is:  0.00012066960334777832\n",
      "The classification loss after processing this batch is:  22562.220703125\n",
      "The representation loss after processing this batch is:  0.0001269914209842682\n",
      "The classification loss after processing this batch is:  21792.078125\n",
      "The representation loss after processing this batch is:  0.00014369655400514603\n",
      "The classification loss after processing this batch is:  24119.853515625\n",
      "The representation loss after processing this batch is:  0.00012009590864181519\n",
      "The classification loss after processing this batch is:  23671.265625\n",
      "The representation loss after processing this batch is:  0.00012141559273004532\n",
      "The classification loss after processing this batch is:  24333.75390625\n",
      "The representation loss after processing this batch is:  0.0001356983557343483\n",
      "The classification loss after processing this batch is:  24621.4921875\n",
      "The representation loss after processing this batch is:  0.0001302044838666916\n",
      "The classification loss after processing this batch is:  24223.5390625\n",
      "The representation loss after processing this batch is:  0.00012164842337369919\n",
      "The classification loss after processing this batch is:  23749.90625\n",
      "The representation loss after processing this batch is:  0.00012078136205673218\n",
      "The classification loss after processing this batch is:  23509.30078125\n",
      "The representation loss after processing this batch is:  0.00013122893869876862\n",
      "The classification loss after processing this batch is:  23287.3125\n",
      "The representation loss after processing this batch is:  0.00011953990906476974\n",
      "The classification loss after processing this batch is:  23502.5078125\n",
      "The representation loss after processing this batch is:  0.00012477301061153412\n",
      "The classification loss after processing this batch is:  23082.64453125\n",
      "The representation loss after processing this batch is:  0.00012492947280406952\n",
      "The classification loss after processing this batch is:  22553.10546875\n",
      "The representation loss after processing this batch is:  0.00012073852121829987\n",
      "The classification loss after processing this batch is:  23593.0078125\n",
      "The representation loss after processing this batch is:  0.0001129787415266037\n",
      "The classification loss after processing this batch is:  23330.513671875\n",
      "The representation loss after processing this batch is:  0.00013564713299274445\n",
      "The classification loss after processing this batch is:  22987.71484375\n",
      "The representation loss after processing this batch is:  0.0001329667866230011\n",
      "The classification loss after processing this batch is:  23732.4140625\n",
      "The representation loss after processing this batch is:  0.00011786911636590958\n",
      "The classification loss after processing this batch is:  26391.17578125\n",
      "The representation loss after processing this batch is:  0.00014843977987766266\n",
      "The classification loss after processing this batch is:  23866.298828125\n",
      "The representation loss after processing this batch is:  0.00011084042489528656\n",
      "The classification loss after processing this batch is:  22554.34765625\n",
      "The representation loss after processing this batch is:  0.00010190904140472412\n",
      "The classification loss after processing this batch is:  22741.921875\n",
      "The representation loss after processing this batch is:  0.000141974538564682\n",
      "The classification loss after processing this batch is:  26210.30078125\n",
      "The representation loss after processing this batch is:  0.00013711676001548767\n",
      "The classification loss after processing this batch is:  26342.51171875\n",
      "The representation loss after processing this batch is:  0.00014481507241725922\n",
      "The classification loss after processing this batch is:  22477.658203125\n",
      "The representation loss after processing this batch is:  0.00013199076056480408\n",
      "The classification loss after processing this batch is:  22316.29296875\n",
      "The representation loss after processing this batch is:  0.00012612901628017426\n",
      "The classification loss after processing this batch is:  22798.79296875\n",
      "The representation loss after processing this batch is:  0.00012247636914253235\n",
      "The classification loss after processing this batch is:  23631.2421875\n",
      "The representation loss after processing this batch is:  0.00012509245425462723\n",
      "The classification loss after processing this batch is:  23527.083984375\n",
      "The representation loss after processing this batch is:  0.00012438371777534485\n",
      "The classification loss after processing this batch is:  22969.830078125\n",
      "The representation loss after processing this batch is:  0.00011749006807804108\n",
      "The classification loss after processing this batch is:  24114.537109375\n",
      "The representation loss after processing this batch is:  0.00011144299060106277\n",
      "The classification loss after processing this batch is:  24934.5078125\n",
      "The representation loss after processing this batch is:  0.0001311013475060463\n",
      "The classification loss after processing this batch is:  22685.625\n",
      "The representation loss after processing this batch is:  0.00012681633234024048\n",
      "The classification loss after processing this batch is:  23536.5625\n",
      "The representation loss after processing this batch is:  0.00012330524623394012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22487.23828125\n",
      "The representation loss after processing this batch is:  0.00012077484279870987\n",
      "The classification loss after processing this batch is:  22980.03125\n",
      "The representation loss after processing this batch is:  0.00012269243597984314\n",
      "The classification loss after processing this batch is:  22172.8359375\n",
      "The representation loss after processing this batch is:  0.00012826640158891678\n",
      "The classification loss after processing this batch is:  23649.552734375\n",
      "The representation loss after processing this batch is:  0.0001305844634771347\n",
      "The classification loss after processing this batch is:  23150.494140625\n",
      "The representation loss after processing this batch is:  0.00012051872909069061\n",
      "The classification loss after processing this batch is:  24973.2109375\n",
      "The representation loss after processing this batch is:  0.00012214761227369308\n",
      "The classification loss after processing this batch is:  22725.66796875\n",
      "The representation loss after processing this batch is:  0.0001346813514828682\n",
      "The classification loss after processing this batch is:  22790.6328125\n",
      "The representation loss after processing this batch is:  0.0001162700355052948\n",
      "The classification loss after processing this batch is:  24364.314453125\n",
      "The representation loss after processing this batch is:  0.00013947580009698868\n",
      "The classification loss after processing this batch is:  23807.8125\n",
      "The representation loss after processing this batch is:  0.00012291688472032547\n",
      "The classification loss after processing this batch is:  23150.103515625\n",
      "The representation loss after processing this batch is:  0.00012040790170431137\n",
      "The classification loss after processing this batch is:  24548.49609375\n",
      "The representation loss after processing this batch is:  0.00012588966637849808\n",
      "The classification loss after processing this batch is:  22649.19921875\n",
      "The representation loss after processing this batch is:  0.00013322103768587112\n",
      "The classification loss after processing this batch is:  23410.5546875\n",
      "The representation loss after processing this batch is:  0.00015150010585784912\n",
      "The classification loss after processing this batch is:  22120.400390625\n",
      "The representation loss after processing this batch is:  0.0001188330352306366\n",
      "The classification loss after processing this batch is:  22129.65234375\n",
      "The representation loss after processing this batch is:  0.0001250430941581726\n",
      "The classification loss after processing this batch is:  22175.876953125\n",
      "The representation loss after processing this batch is:  0.00013258866965770721\n",
      "The classification loss after processing this batch is:  21964.81640625\n",
      "The representation loss after processing this batch is:  0.00014595966786146164\n",
      "The classification loss after processing this batch is:  21778.29296875\n",
      "The representation loss after processing this batch is:  0.0001415833830833435\n",
      "The classification loss after processing this batch is:  24685.478515625\n",
      "The representation loss after processing this batch is:  0.00012643076479434967\n",
      "The classification loss after processing this batch is:  22268.3046875\n",
      "The representation loss after processing this batch is:  0.0001412704586982727\n",
      "The classification loss after processing this batch is:  22846.22265625\n",
      "The representation loss after processing this batch is:  0.00010921154171228409\n",
      "The classification loss after processing this batch is:  23773.30859375\n",
      "The representation loss after processing this batch is:  0.00012079533189535141\n",
      "The classification loss after processing this batch is:  22897.5234375\n",
      "The representation loss after processing this batch is:  0.00010550767183303833\n",
      "The classification loss after processing this batch is:  23202.11328125\n",
      "The representation loss after processing this batch is:  0.00011642836034297943\n",
      "The classification loss after processing this batch is:  23110.28125\n",
      "The representation loss after processing this batch is:  0.00011295173317193985\n",
      "The classification loss after processing this batch is:  22452.890625\n",
      "The representation loss after processing this batch is:  0.00012729689478874207\n",
      "The classification loss after processing this batch is:  21382.935546875\n",
      "The representation loss after processing this batch is:  0.00011724978685379028\n",
      "The classification loss after processing this batch is:  23030.90625\n",
      "The representation loss after processing this batch is:  0.00012774765491485596\n",
      "The classification loss after processing this batch is:  25614.0234375\n",
      "The representation loss after processing this batch is:  0.00011377781629562378\n",
      "The classification loss after processing this batch is:  26155.01953125\n",
      "The representation loss after processing this batch is:  0.00012537464499473572\n",
      "The classification loss after processing this batch is:  22821.892578125\n",
      "The representation loss after processing this batch is:  0.00011495780199766159\n",
      "The classification loss after processing this batch is:  22723.677734375\n",
      "The representation loss after processing this batch is:  0.00011484604328870773\n",
      "The classification loss after processing this batch is:  22550.421875\n",
      "The representation loss after processing this batch is:  0.00010687019675970078\n",
      "The classification loss after processing this batch is:  23505.435546875\n",
      "The representation loss after processing this batch is:  0.00011758413165807724\n",
      "The classification loss after processing this batch is:  22350.94921875\n",
      "The representation loss after processing this batch is:  0.00012199580669403076\n",
      "The classification loss after processing this batch is:  22599.224609375\n",
      "The representation loss after processing this batch is:  9.871087968349457e-05\n",
      "The classification loss after processing this batch is:  24142.6171875\n",
      "The representation loss after processing this batch is:  0.00011910498142242432\n",
      "The classification loss after processing this batch is:  21361.33203125\n",
      "The representation loss after processing this batch is:  0.0001067332923412323\n",
      "The classification loss after processing this batch is:  21900.2890625\n",
      "The representation loss after processing this batch is:  0.0001153675839304924\n",
      "The classification loss after processing this batch is:  24742.7890625\n",
      "The representation loss after processing this batch is:  0.00012648478150367737\n",
      "The classification loss after processing this batch is:  23295.07421875\n",
      "The representation loss after processing this batch is:  0.00013111159205436707\n",
      "The classification loss after processing this batch is:  22147.251953125\n",
      "The representation loss after processing this batch is:  0.00013557448983192444\n",
      "The classification loss after processing this batch is:  20974.6171875\n",
      "The representation loss after processing this batch is:  0.00012870598584413528\n",
      "The classification loss after processing this batch is:  23789.2734375\n",
      "The representation loss after processing this batch is:  0.00013669580221176147\n",
      "The classification loss after processing this batch is:  23378.64453125\n",
      "The representation loss after processing this batch is:  0.00017600320279598236\n",
      "The classification loss after processing this batch is:  27686.2421875\n",
      "The representation loss after processing this batch is:  0.00012557115405797958\n",
      "The classification loss after processing this batch is:  23776.96875\n",
      "The representation loss after processing this batch is:  0.00011672358959913254\n",
      "The classification loss after processing this batch is:  22508.666015625\n",
      "The representation loss after processing this batch is:  0.0001406138762831688\n",
      "The classification loss after processing this batch is:  24119.05859375\n",
      "The representation loss after processing this batch is:  0.00011545047163963318\n",
      "The classification loss after processing this batch is:  25316.765625\n",
      "The representation loss after processing this batch is:  0.0001356620341539383\n",
      "The classification loss after processing this batch is:  23887.42578125\n",
      "The representation loss after processing this batch is:  0.00011574570089578629\n",
      "The classification loss after processing this batch is:  23580.12890625\n",
      "The representation loss after processing this batch is:  0.00011480413377285004\n",
      "The classification loss after processing this batch is:  23324.361328125\n",
      "The representation loss after processing this batch is:  0.00010434817522764206\n",
      "The classification loss after processing this batch is:  23337.078125\n",
      "The representation loss after processing this batch is:  0.00010184571146965027\n",
      "The classification loss after processing this batch is:  22164.1015625\n",
      "The representation loss after processing this batch is:  0.00012461375445127487\n",
      "The classification loss after processing this batch is:  23262.25390625\n",
      "The representation loss after processing this batch is:  0.00013083592057228088\n",
      "The classification loss after processing this batch is:  22917.9296875\n",
      "The representation loss after processing this batch is:  0.00011473521590232849\n",
      "The classification loss after processing this batch is:  23452.5\n",
      "The representation loss after processing this batch is:  0.00010823830962181091\n",
      "The classification loss after processing this batch is:  23579.826171875\n",
      "The representation loss after processing this batch is:  0.00010443385690450668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  23725.6171875\n",
      "The representation loss after processing this batch is:  0.00011967215687036514\n",
      "The classification loss after processing this batch is:  22076.3046875\n",
      "The representation loss after processing this batch is:  0.00012141279876232147\n",
      "The classification loss after processing this batch is:  21543.578125\n",
      "The representation loss after processing this batch is:  0.0001446995884180069\n",
      "The classification loss after processing this batch is:  22268.94921875\n",
      "The representation loss after processing this batch is:  0.00010596774518489838\n",
      "The classification loss after processing this batch is:  22056.208984375\n",
      "The representation loss after processing this batch is:  9.644404053688049e-05\n",
      "The classification loss after processing this batch is:  23752.046875\n",
      "The representation loss after processing this batch is:  0.0001066848635673523\n",
      "The classification loss after processing this batch is:  23261.423828125\n",
      "The representation loss after processing this batch is:  0.00012583844363689423\n",
      "The classification loss after processing this batch is:  22395.287109375\n",
      "The representation loss after processing this batch is:  0.0001260843127965927\n",
      "The classification loss after processing this batch is:  21502.60546875\n",
      "The representation loss after processing this batch is:  0.00012544170022010803\n",
      "The classification loss after processing this batch is:  21468.203125\n",
      "The representation loss after processing this batch is:  0.00011368561536073685\n",
      "The classification loss after processing this batch is:  23169.634765625\n",
      "The representation loss after processing this batch is:  0.00010889023542404175\n",
      "The classification loss after processing this batch is:  24051.09765625\n",
      "The representation loss after processing this batch is:  0.00012013595551252365\n",
      "The classification loss after processing this batch is:  24258.87890625\n",
      "The representation loss after processing this batch is:  0.0001559387892484665\n",
      "The classification loss after processing this batch is:  21962.830078125\n",
      "The representation loss after processing this batch is:  0.0001218840479850769\n",
      "The classification loss after processing this batch is:  22995.0078125\n",
      "The representation loss after processing this batch is:  0.00010568276047706604\n",
      "The classification loss after processing this batch is:  22393.3515625\n",
      "The representation loss after processing this batch is:  0.00012403540313243866\n",
      "The classification loss after processing this batch is:  22770.34765625\n",
      "The representation loss after processing this batch is:  0.00013147294521331787\n",
      "The classification loss after processing this batch is:  21987.875\n",
      "The representation loss after processing this batch is:  0.00012066401541233063\n",
      "The classification loss after processing this batch is:  21725.06640625\n",
      "The representation loss after processing this batch is:  0.00012079160660505295\n",
      "The classification loss after processing this batch is:  21995.455078125\n",
      "The representation loss after processing this batch is:  0.00011367816478013992\n",
      "The classification loss after processing this batch is:  22717.4921875\n",
      "The representation loss after processing this batch is:  0.00011711008846759796\n",
      "The classification loss after processing this batch is:  22984.1953125\n",
      "The representation loss after processing this batch is:  0.000131215900182724\n",
      "The classification loss after processing this batch is:  22882.61328125\n",
      "The representation loss after processing this batch is:  0.00012746546417474747\n",
      "The classification loss after processing this batch is:  22475.10546875\n",
      "The representation loss after processing this batch is:  0.00013464875519275665\n",
      "The classification loss after processing this batch is:  22519.689453125\n",
      "The representation loss after processing this batch is:  0.0001272382214665413\n",
      "The classification loss after processing this batch is:  24026.65234375\n",
      "The representation loss after processing this batch is:  0.00011798087507486343\n",
      "The classification loss after processing this batch is:  25184.2578125\n",
      "The representation loss after processing this batch is:  0.00013421103358268738\n",
      "The classification loss after processing this batch is:  23943.787109375\n",
      "The representation loss after processing this batch is:  0.00012679584324359894\n",
      "The classification loss after processing this batch is:  24063.640625\n",
      "The representation loss after processing this batch is:  0.00012069568037986755\n",
      "The classification loss after processing this batch is:  22295.669921875\n",
      "The representation loss after processing this batch is:  0.00010183453559875488\n",
      "The classification loss after processing this batch is:  22687.689453125\n",
      "The representation loss after processing this batch is:  0.00010679103434085846\n",
      "The classification loss after processing this batch is:  23868.138671875\n",
      "The representation loss after processing this batch is:  0.00011320970952510834\n",
      "The classification loss after processing this batch is:  22220.078125\n",
      "The representation loss after processing this batch is:  0.00013436004519462585\n",
      "The classification loss after processing this batch is:  22376.853515625\n",
      "The representation loss after processing this batch is:  0.00011654943227767944\n",
      "The classification loss after processing this batch is:  23258.43359375\n",
      "The representation loss after processing this batch is:  0.00011670216917991638\n",
      "The classification loss after processing this batch is:  23023.189453125\n",
      "The representation loss after processing this batch is:  0.00010825693607330322\n",
      "The classification loss after processing this batch is:  23015.51171875\n",
      "The representation loss after processing this batch is:  0.0001140618696808815\n",
      "The classification loss after processing this batch is:  22348.44140625\n",
      "The representation loss after processing this batch is:  0.00011299643665552139\n",
      "The classification loss after processing this batch is:  23515.7265625\n",
      "The representation loss after processing this batch is:  0.00012350548058748245\n",
      "The classification loss after processing this batch is:  23509.091796875\n",
      "The representation loss after processing this batch is:  0.00011409353464841843\n",
      "The classification loss after processing this batch is:  23975.1171875\n",
      "The representation loss after processing this batch is:  0.00010288041085004807\n",
      "The classification loss after processing this batch is:  24209.71875\n",
      "The representation loss after processing this batch is:  0.00012298859655857086\n",
      "The classification loss after processing this batch is:  23098.2421875\n",
      "The representation loss after processing this batch is:  0.00010083615779876709\n",
      "The classification loss after processing this batch is:  22332.841796875\n",
      "The representation loss after processing this batch is:  0.0001112939789891243\n",
      "The classification loss after processing this batch is:  22523.94921875\n",
      "The representation loss after processing this batch is:  0.00012853741645812988\n",
      "The classification loss after processing this batch is:  22078.7578125\n",
      "The representation loss after processing this batch is:  0.0001173168420791626\n",
      "The classification loss after processing this batch is:  22431.044921875\n",
      "The representation loss after processing this batch is:  0.00012142490595579147\n",
      "The classification loss after processing this batch is:  21980.333984375\n",
      "The representation loss after processing this batch is:  0.00012325216084718704\n",
      "The classification loss after processing this batch is:  22741.55859375\n",
      "The representation loss after processing this batch is:  0.00010878685861825943\n",
      "The classification loss after processing this batch is:  22594.7890625\n",
      "The representation loss after processing this batch is:  0.00012751668691635132\n",
      "The classification loss after processing this batch is:  25818.3671875\n",
      "The representation loss after processing this batch is:  0.00014050118625164032\n",
      "The classification loss after processing this batch is:  24682.81640625\n",
      "The representation loss after processing this batch is:  0.00011648330837488174\n",
      "The classification loss after processing this batch is:  22514.30078125\n",
      "The representation loss after processing this batch is:  0.00012302212417125702\n",
      "The classification loss after processing this batch is:  21347.75\n",
      "The representation loss after processing this batch is:  0.00012041721493005753\n",
      "The classification loss after processing this batch is:  21498.9375\n",
      "The representation loss after processing this batch is:  0.000110565684735775\n",
      "The classification loss after processing this batch is:  22540.748046875\n",
      "The representation loss after processing this batch is:  0.00012711714953184128\n",
      "The classification loss after processing this batch is:  22151.80859375\n",
      "The representation loss after processing this batch is:  0.0001289229840040207\n",
      "The classification loss after processing this batch is:  22747.2734375\n",
      "The representation loss after processing this batch is:  0.0001076776534318924\n",
      "The classification loss after processing this batch is:  22595.595703125\n",
      "The representation loss after processing this batch is:  0.00010869186371564865\n",
      "The classification loss after processing this batch is:  21926.7109375\n",
      "The representation loss after processing this batch is:  0.0001025637611746788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21592.85546875\n",
      "The representation loss after processing this batch is:  0.00010643433779478073\n",
      "The classification loss after processing this batch is:  22968.70703125\n",
      "The representation loss after processing this batch is:  0.00011576618999242783\n",
      "The classification loss after processing this batch is:  23576.693359375\n",
      "The representation loss after processing this batch is:  0.00014748424291610718\n",
      "The classification loss after processing this batch is:  22199.525390625\n",
      "The representation loss after processing this batch is:  0.00011901743710041046\n",
      "The classification loss after processing this batch is:  23288.859375\n",
      "The representation loss after processing this batch is:  0.00010812375694513321\n",
      "The classification loss after processing this batch is:  25119.720703125\n",
      "The representation loss after processing this batch is:  0.00011580251157283783\n",
      "The classification loss after processing this batch is:  23717.58984375\n",
      "The representation loss after processing this batch is:  0.00011489540338516235\n",
      "The classification loss after processing this batch is:  25082.73828125\n",
      "The representation loss after processing this batch is:  0.00012391898781061172\n",
      "The classification loss after processing this batch is:  22592.94140625\n",
      "The representation loss after processing this batch is:  0.00011378154158592224\n",
      "The classification loss after processing this batch is:  23548.32421875\n",
      "The representation loss after processing this batch is:  0.0001298198476433754\n",
      "The classification loss after processing this batch is:  22580.287109375\n",
      "The representation loss after processing this batch is:  0.00012025516480207443\n",
      "The classification loss after processing this batch is:  23255.11328125\n",
      "The representation loss after processing this batch is:  0.00010687392204999924\n",
      "The classification loss after processing this batch is:  22723.201171875\n",
      "The representation loss after processing this batch is:  0.00012380070984363556\n",
      "The classification loss after processing this batch is:  22513.298828125\n",
      "The representation loss after processing this batch is:  0.00010784808546304703\n",
      "The classification loss after processing this batch is:  22885.4765625\n",
      "The representation loss after processing this batch is:  0.00010569673031568527\n",
      "The classification loss after processing this batch is:  22091.82421875\n",
      "The representation loss after processing this batch is:  0.00012206751853227615\n",
      "The classification loss after processing this batch is:  22438.36328125\n",
      "The representation loss after processing this batch is:  0.00011374242603778839\n",
      "The classification loss after processing this batch is:  21628.796875\n",
      "The representation loss after processing this batch is:  0.00011820346117019653\n",
      "The classification loss after processing this batch is:  21992.01953125\n",
      "The representation loss after processing this batch is:  0.00011426303535699844\n",
      "The classification loss after processing this batch is:  21471.826171875\n",
      "The representation loss after processing this batch is:  0.00010562408715486526\n",
      "The classification loss after processing this batch is:  23128.39453125\n",
      "The representation loss after processing this batch is:  0.00012484844774007797\n",
      "The classification loss after processing this batch is:  22208.99609375\n",
      "The representation loss after processing this batch is:  0.00011499971151351929\n",
      "The classification loss after processing this batch is:  23007.109375\n",
      "The representation loss after processing this batch is:  0.00013018958270549774\n",
      "The classification loss after processing this batch is:  23179.57421875\n",
      "The representation loss after processing this batch is:  0.00010992120951414108\n",
      "The classification loss after processing this batch is:  21823.91015625\n",
      "The representation loss after processing this batch is:  9.70698893070221e-05\n",
      "The classification loss after processing this batch is:  22929.43359375\n",
      "The representation loss after processing this batch is:  0.0001092962920665741\n",
      "The classification loss after processing this batch is:  22566.87109375\n",
      "The representation loss after processing this batch is:  0.00011650938540697098\n",
      "The classification loss after processing this batch is:  21550.3359375\n",
      "The representation loss after processing this batch is:  0.00011489354074001312\n",
      "The classification loss after processing this batch is:  22795.15234375\n",
      "The representation loss after processing this batch is:  0.00010686181485652924\n",
      "The classification loss after processing this batch is:  22403.541015625\n",
      "The representation loss after processing this batch is:  0.00010878406465053558\n",
      "The classification loss after processing this batch is:  21835.244140625\n",
      "The representation loss after processing this batch is:  0.0001072445884346962\n",
      "The classification loss after processing this batch is:  22646.0546875\n",
      "The representation loss after processing this batch is:  0.0001012459397315979\n",
      "The classification loss after processing this batch is:  22130.615234375\n",
      "The representation loss after processing this batch is:  0.0001193024218082428\n",
      "The classification loss after processing this batch is:  23440.169921875\n",
      "The representation loss after processing this batch is:  0.00012198463082313538\n",
      "The classification loss after processing this batch is:  24003.15234375\n",
      "The representation loss after processing this batch is:  0.00011216290295124054\n",
      "The classification loss after processing this batch is:  22443.984375\n",
      "The representation loss after processing this batch is:  0.00010932702571153641\n",
      "The classification loss after processing this batch is:  25217.671875\n",
      "The representation loss after processing this batch is:  0.00010875985026359558\n",
      "The classification loss after processing this batch is:  25389.48828125\n",
      "The representation loss after processing this batch is:  0.00011695828288793564\n",
      "The classification loss after processing this batch is:  22479.6875\n",
      "The representation loss after processing this batch is:  0.00010641384869813919\n",
      "The classification loss after processing this batch is:  23372.33984375\n",
      "The representation loss after processing this batch is:  0.00011028256267309189\n",
      "The classification loss after processing this batch is:  24261.7890625\n",
      "The representation loss after processing this batch is:  0.00011967308819293976\n",
      "The classification loss after processing this batch is:  22823.22265625\n",
      "The representation loss after processing this batch is:  0.00011220015585422516\n",
      "The classification loss after processing this batch is:  22941.73828125\n",
      "The representation loss after processing this batch is:  0.00011952966451644897\n",
      "The classification loss after processing this batch is:  22998.564453125\n",
      "The representation loss after processing this batch is:  0.00012207310646772385\n",
      "The classification loss after processing this batch is:  23277.734375\n",
      "The representation loss after processing this batch is:  0.00011146161705255508\n",
      "The classification loss after processing this batch is:  24147.47265625\n",
      "The representation loss after processing this batch is:  0.00010969117283821106\n",
      "The classification loss after processing this batch is:  23885.53125\n",
      "The representation loss after processing this batch is:  0.00010357610881328583\n",
      "The classification loss after processing this batch is:  25096.16015625\n",
      "The representation loss after processing this batch is:  0.00012133456766605377\n",
      "The classification loss after processing this batch is:  24082.4921875\n",
      "The representation loss after processing this batch is:  9.907782077789307e-05\n",
      "The classification loss after processing this batch is:  24354.287109375\n",
      "The representation loss after processing this batch is:  0.00010231323540210724\n",
      "The classification loss after processing this batch is:  22203.849609375\n",
      "The representation loss after processing this batch is:  0.00010833051055669785\n",
      "The classification loss after processing this batch is:  22692.26953125\n",
      "The representation loss after processing this batch is:  0.00011582579463720322\n",
      "The classification loss after processing this batch is:  23950.892578125\n",
      "The representation loss after processing this batch is:  0.00010891817510128021\n",
      "The classification loss after processing this batch is:  22299.98828125\n",
      "The representation loss after processing this batch is:  0.00011354964226484299\n",
      "The classification loss after processing this batch is:  21419.4375\n",
      "The representation loss after processing this batch is:  0.00011903699487447739\n",
      "The classification loss after processing this batch is:  23927.23828125\n",
      "The representation loss after processing this batch is:  0.00011958740651607513\n",
      "The classification loss after processing this batch is:  22024.80078125\n",
      "The representation loss after processing this batch is:  0.00011929869651794434\n",
      "The classification loss after processing this batch is:  22452.802734375\n",
      "The representation loss after processing this batch is:  0.00011599529534578323\n",
      "The classification loss after processing this batch is:  21496.86328125\n",
      "The representation loss after processing this batch is:  0.00011766701936721802\n",
      "The classification loss after processing this batch is:  22490.6484375\n",
      "The representation loss after processing this batch is:  0.00010819081217050552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21570.041015625\n",
      "The representation loss after processing this batch is:  0.0001154216006398201\n",
      "The classification loss after processing this batch is:  22794.458984375\n",
      "The representation loss after processing this batch is:  0.00010361894965171814\n",
      "The classification loss after processing this batch is:  22367.251953125\n",
      "The representation loss after processing this batch is:  0.00010570045560598373\n",
      "The classification loss after processing this batch is:  22006.90625\n",
      "The representation loss after processing this batch is:  0.00011566746979951859\n",
      "The classification loss after processing this batch is:  23179.697265625\n",
      "The representation loss after processing this batch is:  0.00010051019489765167\n",
      "The classification loss after processing this batch is:  23624.9609375\n",
      "The representation loss after processing this batch is:  0.00011189375072717667\n",
      "The classification loss after processing this batch is:  21586.005859375\n",
      "The representation loss after processing this batch is:  0.0001202654093503952\n",
      "The classification loss after processing this batch is:  21891.4453125\n",
      "The representation loss after processing this batch is:  0.00011858157813549042\n",
      "The classification loss after processing this batch is:  22087.07421875\n",
      "The representation loss after processing this batch is:  0.00011466536670923233\n",
      "The classification loss after processing this batch is:  21972.71875\n",
      "The representation loss after processing this batch is:  0.00010526832193136215\n",
      "The classification loss after processing this batch is:  23375.103515625\n",
      "The representation loss after processing this batch is:  0.00010350719094276428\n",
      "The classification loss after processing this batch is:  21818.900390625\n",
      "The representation loss after processing this batch is:  9.833090007305145e-05\n",
      "The classification loss after processing this batch is:  21255.580078125\n",
      "The representation loss after processing this batch is:  0.00010690279304981232\n",
      "The classification loss after processing this batch is:  22308.484375\n",
      "The representation loss after processing this batch is:  0.00010923296213150024\n",
      "The classification loss after processing this batch is:  24268.4140625\n",
      "The representation loss after processing this batch is:  0.00013075396418571472\n",
      "The classification loss after processing this batch is:  22008.83203125\n",
      "The representation loss after processing this batch is:  0.0001134062185883522\n",
      "The classification loss after processing this batch is:  23135.64453125\n",
      "The representation loss after processing this batch is:  9.883381426334381e-05\n",
      "The classification loss after processing this batch is:  24694.625\n",
      "The representation loss after processing this batch is:  0.00011719949543476105\n",
      "The classification loss after processing this batch is:  22787.751953125\n",
      "The representation loss after processing this batch is:  0.00010812561959028244\n",
      "The classification loss after processing this batch is:  21625.814453125\n",
      "The representation loss after processing this batch is:  0.00010434165596961975\n",
      "The classification loss after processing this batch is:  22005.96484375\n",
      "The representation loss after processing this batch is:  0.00010625738650560379\n",
      "The classification loss after processing this batch is:  21930.076171875\n",
      "The representation loss after processing this batch is:  0.000104476697742939\n",
      "The classification loss after processing this batch is:  22420.951171875\n",
      "The representation loss after processing this batch is:  0.00010758452117443085\n",
      "The classification loss after processing this batch is:  21890.32421875\n",
      "The representation loss after processing this batch is:  0.00012889225035905838\n",
      "The classification loss after processing this batch is:  22525.046875\n",
      "The representation loss after processing this batch is:  0.00011579319834709167\n",
      "The classification loss after processing this batch is:  25423.41796875\n",
      "The representation loss after processing this batch is:  0.0001203017309308052\n",
      "The classification loss after processing this batch is:  23752.5390625\n",
      "The representation loss after processing this batch is:  0.00011008977890014648\n",
      "The classification loss after processing this batch is:  22947.41015625\n",
      "The representation loss after processing this batch is:  0.00011004973202943802\n",
      "The classification loss after processing this batch is:  22249.69921875\n",
      "The representation loss after processing this batch is:  0.0001128707081079483\n",
      "The classification loss after processing this batch is:  22647.1953125\n",
      "The representation loss after processing this batch is:  0.00012883450835943222\n",
      "The classification loss after processing this batch is:  22533.9609375\n",
      "The representation loss after processing this batch is:  0.00013063475489616394\n",
      "The classification loss after processing this batch is:  22029.38671875\n",
      "The representation loss after processing this batch is:  0.00012613087892532349\n",
      "The classification loss after processing this batch is:  21586.1015625\n",
      "The representation loss after processing this batch is:  0.0001118415966629982\n",
      "The classification loss after processing this batch is:  22249.44140625\n",
      "The representation loss after processing this batch is:  0.0001043686643242836\n",
      "The classification loss after processing this batch is:  22097.134765625\n",
      "The representation loss after processing this batch is:  0.00010207854211330414\n",
      "The classification loss after processing this batch is:  21465.896484375\n",
      "The representation loss after processing this batch is:  0.0001238388940691948\n",
      "The classification loss after processing this batch is:  22476.98828125\n",
      "The representation loss after processing this batch is:  0.00011817645281553268\n",
      "The classification loss after processing this batch is:  21521.111328125\n",
      "The representation loss after processing this batch is:  0.00010558310896158218\n",
      "The classification loss after processing this batch is:  23659.3046875\n",
      "The representation loss after processing this batch is:  0.00010334048420190811\n",
      "The classification loss after processing this batch is:  23444.8203125\n",
      "The representation loss after processing this batch is:  0.0001061558723449707\n",
      "The classification loss after processing this batch is:  22433.3046875\n",
      "The representation loss after processing this batch is:  9.898003190755844e-05\n",
      "The classification loss after processing this batch is:  22598.103515625\n",
      "The representation loss after processing this batch is:  0.00011211540549993515\n",
      "The classification loss after processing this batch is:  22852.779296875\n",
      "The representation loss after processing this batch is:  0.00010434072464704514\n",
      "The classification loss after processing this batch is:  24220.228515625\n",
      "The representation loss after processing this batch is:  0.00011368095874786377\n",
      "The classification loss after processing this batch is:  23660.62890625\n",
      "The representation loss after processing this batch is:  0.00012045074254274368\n",
      "The classification loss after processing this batch is:  22735.3125\n",
      "The representation loss after processing this batch is:  0.00010489113628864288\n",
      "The classification loss after processing this batch is:  22979.546875\n",
      "The representation loss after processing this batch is:  9.509921073913574e-05\n",
      "The classification loss after processing this batch is:  24578.0390625\n",
      "The representation loss after processing this batch is:  0.0001246873289346695\n",
      "The classification loss after processing this batch is:  22104.900390625\n",
      "The representation loss after processing this batch is:  0.0001082615926861763\n",
      "The classification loss after processing this batch is:  23132.134765625\n",
      "The representation loss after processing this batch is:  0.00010264478623867035\n",
      "The classification loss after processing this batch is:  22965.3203125\n",
      "The representation loss after processing this batch is:  0.00012609641999006271\n",
      "The classification loss after processing this batch is:  22996.32421875\n",
      "The representation loss after processing this batch is:  0.00010786950588226318\n",
      "The classification loss after processing this batch is:  23812.04296875\n",
      "The representation loss after processing this batch is:  0.0001230929046869278\n",
      "The classification loss after processing this batch is:  24493.701171875\n",
      "The representation loss after processing this batch is:  0.00012074224650859833\n",
      "The classification loss after processing this batch is:  22867.6796875\n",
      "The representation loss after processing this batch is:  0.00012010056525468826\n",
      "The classification loss after processing this batch is:  23930.73046875\n",
      "The representation loss after processing this batch is:  0.00011033006012439728\n",
      "The classification loss after processing this batch is:  24445.669921875\n",
      "The representation loss after processing this batch is:  0.00011648889631032944\n",
      "The classification loss after processing this batch is:  22529.935546875\n",
      "The representation loss after processing this batch is:  0.0001244284212589264\n",
      "The classification loss after processing this batch is:  23598.9453125\n",
      "The representation loss after processing this batch is:  0.00010408926755189896\n",
      "The classification loss after processing this batch is:  23267.58203125\n",
      "The representation loss after processing this batch is:  0.00011462438851594925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22444.40625\n",
      "The representation loss after processing this batch is:  0.00011883489787578583\n",
      "The classification loss after processing this batch is:  22716.537109375\n",
      "The representation loss after processing this batch is:  9.947549551725388e-05\n",
      "The classification loss after processing this batch is:  22579.736328125\n",
      "The representation loss after processing this batch is:  0.00011010374873876572\n",
      "The classification loss after processing this batch is:  22368.984375\n",
      "The representation loss after processing this batch is:  0.0001009088009595871\n",
      "The classification loss after processing this batch is:  24101.15625\n",
      "The representation loss after processing this batch is:  0.00010512396693229675\n",
      "The classification loss after processing this batch is:  23730.302734375\n",
      "The representation loss after processing this batch is:  9.944010525941849e-05\n",
      "The classification loss after processing this batch is:  24696.44140625\n",
      "The representation loss after processing this batch is:  0.00013427995145320892\n",
      "The classification loss after processing this batch is:  21804.296875\n",
      "The representation loss after processing this batch is:  0.00010397844016551971\n",
      "The classification loss after processing this batch is:  22046.29296875\n",
      "The representation loss after processing this batch is:  0.0001156739890575409\n",
      "The classification loss after processing this batch is:  22681.224609375\n",
      "The representation loss after processing this batch is:  0.00010912492871284485\n",
      "The classification loss after processing this batch is:  22201.7890625\n",
      "The representation loss after processing this batch is:  0.00011163949966430664\n",
      "The classification loss after processing this batch is:  23567.1640625\n",
      "The representation loss after processing this batch is:  0.00010452046990394592\n",
      "The classification loss after processing this batch is:  22635.927734375\n",
      "The representation loss after processing this batch is:  9.818002581596375e-05\n",
      "The classification loss after processing this batch is:  22834.978515625\n",
      "The representation loss after processing this batch is:  0.00010652188211679459\n",
      "The classification loss after processing this batch is:  22956.203125\n",
      "The representation loss after processing this batch is:  0.00010187365114688873\n",
      "The classification loss after processing this batch is:  22081.919921875\n",
      "The representation loss after processing this batch is:  0.0001233881339430809\n",
      "The classification loss after processing this batch is:  23982.0234375\n",
      "The representation loss after processing this batch is:  0.0001172451302409172\n",
      "The classification loss after processing this batch is:  24308.99609375\n",
      "The representation loss after processing this batch is:  0.00011890288442373276\n",
      "The classification loss after processing this batch is:  23500.453125\n",
      "The representation loss after processing this batch is:  0.00010841898620128632\n",
      "The classification loss after processing this batch is:  21634.56640625\n",
      "The representation loss after processing this batch is:  0.00011877249926328659\n",
      "The classification loss after processing this batch is:  23949.2265625\n",
      "The representation loss after processing this batch is:  0.00010425969958305359\n",
      "The classification loss after processing this batch is:  23509.951171875\n",
      "The representation loss after processing this batch is:  0.00010564550757408142\n",
      "The classification loss after processing this batch is:  22126.091796875\n",
      "The representation loss after processing this batch is:  9.980052709579468e-05\n",
      "The classification loss after processing this batch is:  24219.25\n",
      "The representation loss after processing this batch is:  0.00012074783444404602\n",
      "The classification loss after processing this batch is:  24048.59765625\n",
      "The representation loss after processing this batch is:  0.00013075117021799088\n",
      "The classification loss after processing this batch is:  21926.4765625\n",
      "The representation loss after processing this batch is:  0.00011267140507698059\n",
      "The classification loss after processing this batch is:  22289.06640625\n",
      "The representation loss after processing this batch is:  0.00011695362627506256\n",
      "The classification loss after processing this batch is:  23128.6015625\n",
      "The representation loss after processing this batch is:  0.00011655595153570175\n",
      "The classification loss after processing this batch is:  22705.73046875\n",
      "The representation loss after processing this batch is:  0.000117449089884758\n",
      "The classification loss after processing this batch is:  23218.17578125\n",
      "The representation loss after processing this batch is:  0.0001424495130777359\n",
      "The classification loss after processing this batch is:  23862.990234375\n",
      "The representation loss after processing this batch is:  0.00013931002467870712\n",
      "The classification loss after processing this batch is:  21783.19140625\n",
      "The representation loss after processing this batch is:  0.00012332387268543243\n",
      "The classification loss after processing this batch is:  21540.578125\n",
      "The representation loss after processing this batch is:  0.00012628547847270966\n",
      "The classification loss after processing this batch is:  23024.603515625\n",
      "The representation loss after processing this batch is:  0.0001176241785287857\n",
      "The classification loss after processing this batch is:  24347.373046875\n",
      "The representation loss after processing this batch is:  0.00012742355465888977\n",
      "The classification loss after processing this batch is:  22725.02734375\n",
      "The representation loss after processing this batch is:  0.00010327808558940887\n",
      "The classification loss after processing this batch is:  23481.666015625\n",
      "The representation loss after processing this batch is:  0.00011196359992027283\n",
      "The classification loss after processing this batch is:  23173.029296875\n",
      "The representation loss after processing this batch is:  9.902101010084152e-05\n",
      "The classification loss after processing this batch is:  23481.818359375\n",
      "The representation loss after processing this batch is:  0.00010043196380138397\n",
      "The classification loss after processing this batch is:  22705.96484375\n",
      "The representation loss after processing this batch is:  0.00011995527893304825\n",
      "The classification loss after processing this batch is:  22896.07421875\n",
      "The representation loss after processing this batch is:  0.00011490099132061005\n",
      "The classification loss after processing this batch is:  24022.796875\n",
      "The representation loss after processing this batch is:  0.00011082924902439117\n",
      "The classification loss after processing this batch is:  21960.17578125\n",
      "The representation loss after processing this batch is:  0.00011863000690937042\n",
      "The classification loss after processing this batch is:  21986.04296875\n",
      "The representation loss after processing this batch is:  0.00010529253631830215\n",
      "The classification loss after processing this batch is:  21793.921875\n",
      "The representation loss after processing this batch is:  0.00011677294969558716\n",
      "The classification loss after processing this batch is:  21870.7890625\n",
      "The representation loss after processing this batch is:  0.00010216422379016876\n",
      "The classification loss after processing this batch is:  22247.6640625\n",
      "The representation loss after processing this batch is:  0.00011532381176948547\n",
      "The classification loss after processing this batch is:  23468.79296875\n",
      "The representation loss after processing this batch is:  0.00011066906154155731\n",
      "The classification loss after processing this batch is:  23522.611328125\n",
      "The representation loss after processing this batch is:  0.00010423548519611359\n",
      "The classification loss after processing this batch is:  22065.06640625\n",
      "The representation loss after processing this batch is:  0.00010848045349121094\n",
      "The classification loss after processing this batch is:  21942.833984375\n",
      "The representation loss after processing this batch is:  9.748991578817368e-05\n",
      "The classification loss after processing this batch is:  22194.26953125\n",
      "The representation loss after processing this batch is:  9.972881525754929e-05\n",
      "The classification loss after processing this batch is:  22789.12109375\n",
      "The representation loss after processing this batch is:  0.0001001572236418724\n",
      "The classification loss after processing this batch is:  22665.876953125\n",
      "The representation loss after processing this batch is:  0.00010974891483783722\n",
      "The classification loss after processing this batch is:  21977.919921875\n",
      "The representation loss after processing this batch is:  0.00011145137250423431\n",
      "The classification loss after processing this batch is:  24462.103515625\n",
      "The representation loss after processing this batch is:  0.00011457037180662155\n",
      "The classification loss after processing this batch is:  22501.51171875\n",
      "The representation loss after processing this batch is:  0.00010563898831605911\n",
      "The classification loss after processing this batch is:  21939.40625\n",
      "The representation loss after processing this batch is:  0.00010418891906738281\n",
      "The classification loss after processing this batch is:  22424.927734375\n",
      "The representation loss after processing this batch is:  0.0001072026789188385\n",
      "The classification loss after processing this batch is:  22984.6640625\n",
      "The representation loss after processing this batch is:  0.00012339837849140167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22542.189453125\n",
      "The representation loss after processing this batch is:  9.973347187042236e-05\n",
      "The classification loss after processing this batch is:  21988.919921875\n",
      "The representation loss after processing this batch is:  0.00011416617780923843\n",
      "The classification loss after processing this batch is:  22732.541015625\n",
      "The representation loss after processing this batch is:  0.0001230509951710701\n",
      "The classification loss after processing this batch is:  24292.181640625\n",
      "The representation loss after processing this batch is:  0.00011422857642173767\n",
      "The classification loss after processing this batch is:  21563.6015625\n",
      "The representation loss after processing this batch is:  0.00010225735604763031\n",
      "The classification loss after processing this batch is:  22263.849609375\n",
      "The representation loss after processing this batch is:  0.00010019727051258087\n",
      "The classification loss after processing this batch is:  21004.24609375\n",
      "The representation loss after processing this batch is:  0.00012275949120521545\n",
      "The classification loss after processing this batch is:  22417.943359375\n",
      "The representation loss after processing this batch is:  0.00010089017450809479\n",
      "The classification loss after processing this batch is:  22750.17578125\n",
      "The representation loss after processing this batch is:  0.00010519474744796753\n",
      "The classification loss after processing this batch is:  22068.03125\n",
      "The representation loss after processing this batch is:  0.00012168101966381073\n",
      "The classification loss after processing this batch is:  21832.857421875\n",
      "The representation loss after processing this batch is:  0.00012730713933706284\n",
      "The classification loss after processing this batch is:  21351.61328125\n",
      "The representation loss after processing this batch is:  0.00010904576629400253\n",
      "The classification loss after processing this batch is:  22385.6015625\n",
      "The representation loss after processing this batch is:  0.00010511651635169983\n",
      "The classification loss after processing this batch is:  22017.91796875\n",
      "The representation loss after processing this batch is:  0.00011219549924135208\n",
      "The classification loss after processing this batch is:  21414.140625\n",
      "The representation loss after processing this batch is:  0.00012404751032590866\n",
      "The classification loss after processing this batch is:  25635.677734375\n",
      "The representation loss after processing this batch is:  0.00011625885963439941\n",
      "The classification loss after processing this batch is:  24037.89453125\n",
      "The representation loss after processing this batch is:  0.00011977739632129669\n",
      "The classification loss after processing this batch is:  23220.79296875\n",
      "The representation loss after processing this batch is:  0.0001103673130273819\n",
      "The classification loss after processing this batch is:  22519.98046875\n",
      "The representation loss after processing this batch is:  0.00010606646537780762\n",
      "The classification loss after processing this batch is:  21788.509765625\n",
      "The representation loss after processing this batch is:  0.0001093568280339241\n",
      "The classification loss after processing this batch is:  22440.798828125\n",
      "The representation loss after processing this batch is:  0.00010628253221511841\n",
      "The classification loss after processing this batch is:  23324.54296875\n",
      "The representation loss after processing this batch is:  0.00011076591908931732\n",
      "The classification loss after processing this batch is:  22443.4765625\n",
      "The representation loss after processing this batch is:  9.655021131038666e-05\n",
      "The classification loss after processing this batch is:  24316.92578125\n",
      "The representation loss after processing this batch is:  0.00011583790183067322\n",
      "The classification loss after processing this batch is:  22535.5234375\n",
      "The representation loss after processing this batch is:  0.00010684784501791\n",
      "The classification loss after processing this batch is:  21726.0546875\n",
      "The representation loss after processing this batch is:  0.00011376570910215378\n",
      "The classification loss after processing this batch is:  23478.91015625\n",
      "The representation loss after processing this batch is:  0.0001181596890091896\n",
      "The classification loss after processing this batch is:  21728.365234375\n",
      "The representation loss after processing this batch is:  0.00010462198406457901\n",
      "The classification loss after processing this batch is:  22195.177734375\n",
      "The representation loss after processing this batch is:  0.00011056102812290192\n",
      "The classification loss after processing this batch is:  25527.015625\n",
      "The representation loss after processing this batch is:  0.00012213364243507385\n",
      "The classification loss after processing this batch is:  23221.533203125\n",
      "The representation loss after processing this batch is:  0.00014239922165870667\n",
      "The classification loss after processing this batch is:  21943.345703125\n",
      "The representation loss after processing this batch is:  0.00013150274753570557\n",
      "The classification loss after processing this batch is:  21809.43359375\n",
      "The representation loss after processing this batch is:  0.0001670103520154953\n",
      "The classification loss after processing this batch is:  24237.447265625\n",
      "The representation loss after processing this batch is:  0.00011537130922079086\n",
      "The classification loss after processing this batch is:  21583.28125\n",
      "The representation loss after processing this batch is:  0.00012783333659172058\n",
      "The classification loss after processing this batch is:  22009.26171875\n",
      "The representation loss after processing this batch is:  0.00012663379311561584\n",
      "The classification loss after processing this batch is:  22723.26953125\n",
      "The representation loss after processing this batch is:  0.00014511682093143463\n",
      "The classification loss after processing this batch is:  27419.7421875\n",
      "The representation loss after processing this batch is:  0.00013183429837226868\n",
      "The classification loss after processing this batch is:  29818.34375\n",
      "The representation loss after processing this batch is:  0.00012813881039619446\n",
      "The classification loss after processing this batch is:  21625.296875\n",
      "The representation loss after processing this batch is:  0.0001268237829208374\n",
      "The classification loss after processing this batch is:  22971.796875\n",
      "The representation loss after processing this batch is:  0.00011912640184164047\n",
      "The classification loss after processing this batch is:  23014.2734375\n",
      "The representation loss after processing this batch is:  0.000134320929646492\n",
      "The classification loss after processing this batch is:  20914.005859375\n",
      "The representation loss after processing this batch is:  9.953230619430542e-05\n",
      "The classification loss after processing this batch is:  22998.037109375\n",
      "The representation loss after processing this batch is:  0.00012354739010334015\n",
      "The classification loss after processing this batch is:  23342.01953125\n",
      "The representation loss after processing this batch is:  0.00013582874089479446\n",
      "The classification loss after processing this batch is:  22474.7734375\n",
      "The representation loss after processing this batch is:  0.0001474916934967041\n",
      "The classification loss after processing this batch is:  22826.701171875\n",
      "The representation loss after processing this batch is:  0.0001362459734082222\n",
      "The classification loss after processing this batch is:  22742.171875\n",
      "The representation loss after processing this batch is:  0.00012253038585186005\n",
      "The classification loss after processing this batch is:  22700.298828125\n",
      "The representation loss after processing this batch is:  0.0001170225441455841\n",
      "The classification loss after processing this batch is:  22799.814453125\n",
      "The representation loss after processing this batch is:  0.0001354403793811798\n",
      "The classification loss after processing this batch is:  22978.05859375\n",
      "The representation loss after processing this batch is:  0.0001255124807357788\n",
      "The classification loss after processing this batch is:  22757.7734375\n",
      "The representation loss after processing this batch is:  0.00012877676635980606\n",
      "The classification loss after processing this batch is:  26271.3203125\n",
      "The representation loss after processing this batch is:  0.00014117266982793808\n",
      "The classification loss after processing this batch is:  24982.53125\n",
      "The representation loss after processing this batch is:  0.00012424495071172714\n",
      "The classification loss after processing this batch is:  22752.458984375\n",
      "The representation loss after processing this batch is:  0.00011679716408252716\n",
      "The classification loss after processing this batch is:  22669.234375\n",
      "The representation loss after processing this batch is:  0.00011254101991653442\n",
      "The classification loss after processing this batch is:  22536.8359375\n",
      "The representation loss after processing this batch is:  0.00012329034507274628\n",
      "The classification loss after processing this batch is:  22533.33203125\n",
      "The representation loss after processing this batch is:  0.00011461041867733002\n",
      "The classification loss after processing this batch is:  23442.078125\n",
      "The representation loss after processing this batch is:  0.00013158097863197327\n",
      "The classification loss after processing this batch is:  22704.94921875\n",
      "The representation loss after processing this batch is:  0.00011757202446460724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24177.91015625\n",
      "The representation loss after processing this batch is:  0.00014303810894489288\n",
      "The classification loss after processing this batch is:  23543.8046875\n",
      "The representation loss after processing this batch is:  0.00011452287435531616\n",
      "The classification loss after processing this batch is:  23882.984375\n",
      "The representation loss after processing this batch is:  0.00012778863310813904\n",
      "The classification loss after processing this batch is:  23190.05078125\n",
      "The representation loss after processing this batch is:  0.00011787004768848419\n",
      "The classification loss after processing this batch is:  22921.80859375\n",
      "The representation loss after processing this batch is:  0.0001093745231628418\n",
      "The classification loss after processing this batch is:  23073.31640625\n",
      "The representation loss after processing this batch is:  0.00012464262545108795\n",
      "The classification loss after processing this batch is:  23135.302734375\n",
      "The representation loss after processing this batch is:  0.00012511108070611954\n",
      "The classification loss after processing this batch is:  23083.484375\n",
      "The representation loss after processing this batch is:  0.00012607406824827194\n",
      "The classification loss after processing this batch is:  22025.12890625\n",
      "The representation loss after processing this batch is:  0.00013290531933307648\n",
      "The classification loss after processing this batch is:  22360.353515625\n",
      "The representation loss after processing this batch is:  0.00011704862117767334\n",
      "The classification loss after processing this batch is:  22346.021484375\n",
      "The representation loss after processing this batch is:  0.0001184605062007904\n",
      "The classification loss after processing this batch is:  24968.76953125\n",
      "The representation loss after processing this batch is:  0.0001162998378276825\n",
      "The classification loss after processing this batch is:  23543.61328125\n",
      "The representation loss after processing this batch is:  0.00011325161904096603\n",
      "The classification loss after processing this batch is:  22295.146484375\n",
      "The representation loss after processing this batch is:  0.0001280456781387329\n",
      "The classification loss after processing this batch is:  22788.134765625\n",
      "The representation loss after processing this batch is:  0.0001132674515247345\n",
      "The classification loss after processing this batch is:  21912.36328125\n",
      "The representation loss after processing this batch is:  0.00011938158422708511\n",
      "The classification loss after processing this batch is:  22513.48046875\n",
      "The representation loss after processing this batch is:  0.00012103654444217682\n",
      "The classification loss after processing this batch is:  22626.048828125\n",
      "The representation loss after processing this batch is:  0.00011585745960474014\n",
      "The classification loss after processing this batch is:  22836.5625\n",
      "The representation loss after processing this batch is:  0.00011797621846199036\n",
      "The classification loss after processing this batch is:  23983.83203125\n",
      "The representation loss after processing this batch is:  0.0001266850158572197\n",
      "The classification loss after processing this batch is:  27620.263671875\n",
      "The representation loss after processing this batch is:  0.00014409050345420837\n",
      "The classification loss after processing this batch is:  22672.98828125\n",
      "The representation loss after processing this batch is:  0.0001262333244085312\n",
      "The classification loss after processing this batch is:  23232.82421875\n",
      "The representation loss after processing this batch is:  0.00012504030019044876\n",
      "The classification loss after processing this batch is:  23273.0234375\n",
      "The representation loss after processing this batch is:  0.00011952035129070282\n",
      "The classification loss after processing this batch is:  23334.39453125\n",
      "The representation loss after processing this batch is:  0.0001141279935836792\n",
      "The classification loss after processing this batch is:  22948.9609375\n",
      "The representation loss after processing this batch is:  0.00012073572725057602\n",
      "The classification loss after processing this batch is:  23115.3046875\n",
      "The representation loss after processing this batch is:  0.00011647772043943405\n",
      "The classification loss after processing this batch is:  22925.75390625\n",
      "The representation loss after processing this batch is:  0.00011027511209249496\n",
      "The classification loss after processing this batch is:  22838.185546875\n",
      "The representation loss after processing this batch is:  0.00013731233775615692\n",
      "The classification loss after processing this batch is:  22739.892578125\n",
      "The representation loss after processing this batch is:  0.0001204581931233406\n",
      "The classification loss after processing this batch is:  22885.08203125\n",
      "The representation loss after processing this batch is:  0.00011722370982170105\n",
      "The classification loss after processing this batch is:  22458.3046875\n",
      "The representation loss after processing this batch is:  0.000131215900182724\n",
      "The classification loss after processing this batch is:  22309.19140625\n",
      "The representation loss after processing this batch is:  0.00013190880417823792\n",
      "The classification loss after processing this batch is:  22349.3125\n",
      "The representation loss after processing this batch is:  0.00010663922876119614\n",
      "The classification loss after processing this batch is:  21290.55078125\n",
      "The representation loss after processing this batch is:  0.00012015178799629211\n",
      "The classification loss after processing this batch is:  22093.2265625\n",
      "The representation loss after processing this batch is:  0.00013885274529457092\n",
      "The classification loss after processing this batch is:  22579.859375\n",
      "The representation loss after processing this batch is:  0.00012447871267795563\n",
      "The classification loss after processing this batch is:  22710.716796875\n",
      "The representation loss after processing this batch is:  0.00012244470417499542\n",
      "The classification loss after processing this batch is:  22299.36328125\n",
      "The representation loss after processing this batch is:  0.0001280456781387329\n",
      "The classification loss after processing this batch is:  23752.75\n",
      "The representation loss after processing this batch is:  0.00013486016541719437\n",
      "The classification loss after processing this batch is:  22360.59765625\n",
      "The representation loss after processing this batch is:  0.0001665297895669937\n",
      "The classification loss after processing this batch is:  22340.806640625\n",
      "The representation loss after processing this batch is:  0.00013062544167041779\n",
      "The classification loss after processing this batch is:  22775.32421875\n",
      "The representation loss after processing this batch is:  0.00011875666677951813\n",
      "The classification loss after processing this batch is:  24237.80859375\n",
      "The representation loss after processing this batch is:  0.0001290012151002884\n",
      "The classification loss after processing this batch is:  24968.720703125\n",
      "The representation loss after processing this batch is:  0.0001138029620051384\n",
      "The classification loss after processing this batch is:  24461.4453125\n",
      "The representation loss after processing this batch is:  0.00011915713548660278\n",
      "The classification loss after processing this batch is:  21851.9765625\n",
      "The representation loss after processing this batch is:  0.0001397170126438141\n",
      "The classification loss after processing this batch is:  23361.28515625\n",
      "The representation loss after processing this batch is:  0.00011759810149669647\n",
      "The classification loss after processing this batch is:  22706.6484375\n",
      "The representation loss after processing this batch is:  0.00011811591684818268\n",
      "The classification loss after processing this batch is:  23892.67578125\n",
      "The representation loss after processing this batch is:  0.00013440661132335663\n",
      "The classification loss after processing this batch is:  24017.41015625\n",
      "The representation loss after processing this batch is:  0.00013194605708122253\n",
      "The classification loss after processing this batch is:  23027.44921875\n",
      "The representation loss after processing this batch is:  0.00013270042836666107\n",
      "The classification loss after processing this batch is:  23022.73828125\n",
      "The representation loss after processing this batch is:  0.0001243259757757187\n",
      "The classification loss after processing this batch is:  23266.365234375\n",
      "The representation loss after processing this batch is:  0.00011883676052093506\n",
      "The classification loss after processing this batch is:  23923.625\n",
      "The representation loss after processing this batch is:  0.0001377314329147339\n",
      "The classification loss after processing this batch is:  22683.416015625\n",
      "The representation loss after processing this batch is:  0.00012998469173908234\n",
      "The classification loss after processing this batch is:  23766.8515625\n",
      "The representation loss after processing this batch is:  0.0001082252711057663\n",
      "The classification loss after processing this batch is:  23769.82421875\n",
      "The representation loss after processing this batch is:  0.00012064632028341293\n",
      "The classification loss after processing this batch is:  24362.71875\n",
      "The representation loss after processing this batch is:  0.00013730302453041077\n",
      "The classification loss after processing this batch is:  22977.248046875\n",
      "The representation loss after processing this batch is:  0.00010755285620689392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22920.076171875\n",
      "The representation loss after processing this batch is:  0.00010984763503074646\n",
      "The classification loss after processing this batch is:  22677.392578125\n",
      "The representation loss after processing this batch is:  0.0001164264976978302\n",
      "The classification loss after processing this batch is:  24142.142578125\n",
      "The representation loss after processing this batch is:  0.00011798087507486343\n",
      "The classification loss after processing this batch is:  24752.173828125\n",
      "The representation loss after processing this batch is:  0.00011650845408439636\n",
      "The classification loss after processing this batch is:  22862.486328125\n",
      "The representation loss after processing this batch is:  0.00012231618165969849\n",
      "The classification loss after processing this batch is:  22016.216796875\n",
      "The representation loss after processing this batch is:  0.00012533925473690033\n",
      "The classification loss after processing this batch is:  22383.125\n",
      "The representation loss after processing this batch is:  0.00012348592281341553\n",
      "The classification loss after processing this batch is:  21643.66015625\n",
      "The representation loss after processing this batch is:  0.0001148683950304985\n",
      "The classification loss after processing this batch is:  22034.197265625\n",
      "The representation loss after processing this batch is:  0.00011571962386369705\n",
      "The classification loss after processing this batch is:  22192.365234375\n",
      "The representation loss after processing this batch is:  0.00013601500540971756\n",
      "The classification loss after processing this batch is:  22204.90234375\n",
      "The representation loss after processing this batch is:  0.00011667422950267792\n",
      "The classification loss after processing this batch is:  21922.33984375\n",
      "The representation loss after processing this batch is:  0.00011835992336273193\n",
      "The classification loss after processing this batch is:  21730.935546875\n",
      "The representation loss after processing this batch is:  0.00011710450053215027\n",
      "The classification loss after processing this batch is:  21850.39453125\n",
      "The representation loss after processing this batch is:  0.00011422112584114075\n",
      "The classification loss after processing this batch is:  21513.26171875\n",
      "The representation loss after processing this batch is:  0.00013121869415044785\n",
      "The classification loss after processing this batch is:  21890.32421875\n",
      "The representation loss after processing this batch is:  0.00013327505439519882\n",
      "The classification loss after processing this batch is:  22028.4765625\n",
      "The representation loss after processing this batch is:  0.00012704450637102127\n",
      "The classification loss after processing this batch is:  21491.875\n",
      "The representation loss after processing this batch is:  0.00012360885739326477\n",
      "The classification loss after processing this batch is:  23812.1875\n",
      "The representation loss after processing this batch is:  0.00010322127491235733\n",
      "The classification loss after processing this batch is:  23736.171875\n",
      "The representation loss after processing this batch is:  0.00013839825987815857\n",
      "The classification loss after processing this batch is:  24349.546875\n",
      "The representation loss after processing this batch is:  0.00010060891509056091\n",
      "The classification loss after processing this batch is:  24750.9375\n",
      "The representation loss after processing this batch is:  0.00011561065912246704\n",
      "The classification loss after processing this batch is:  24310.279296875\n",
      "The representation loss after processing this batch is:  0.00011869333684444427\n",
      "The classification loss after processing this batch is:  23526.333984375\n",
      "The representation loss after processing this batch is:  0.000125247985124588\n",
      "The classification loss after processing this batch is:  23463.8125\n",
      "The representation loss after processing this batch is:  0.00012335088104009628\n",
      "The classification loss after processing this batch is:  23255.5078125\n",
      "The representation loss after processing this batch is:  0.00011589657515287399\n",
      "The classification loss after processing this batch is:  23377.0546875\n",
      "The representation loss after processing this batch is:  0.00011933594942092896\n",
      "The classification loss after processing this batch is:  22940.69140625\n",
      "The representation loss after processing this batch is:  0.00011975690722465515\n",
      "The classification loss after processing this batch is:  22584.146484375\n",
      "The representation loss after processing this batch is:  0.00011740997433662415\n",
      "The classification loss after processing this batch is:  23774.615234375\n",
      "The representation loss after processing this batch is:  0.00011563021689653397\n",
      "The classification loss after processing this batch is:  23440.478515625\n",
      "The representation loss after processing this batch is:  0.00011966843158006668\n",
      "The classification loss after processing this batch is:  22907.765625\n",
      "The representation loss after processing this batch is:  0.00011488981544971466\n",
      "The classification loss after processing this batch is:  23848.55859375\n",
      "The representation loss after processing this batch is:  0.00011197850108146667\n",
      "The classification loss after processing this batch is:  26492.45703125\n",
      "The representation loss after processing this batch is:  0.00014413706958293915\n",
      "The classification loss after processing this batch is:  24162.125\n",
      "The representation loss after processing this batch is:  0.00011782720685005188\n",
      "The classification loss after processing this batch is:  22485.83203125\n",
      "The representation loss after processing this batch is:  0.00011299829930067062\n",
      "The classification loss after processing this batch is:  22757.0703125\n",
      "The representation loss after processing this batch is:  0.00014331471174955368\n",
      "The classification loss after processing this batch is:  26456.109375\n",
      "The representation loss after processing this batch is:  0.00013966113328933716\n",
      "The classification loss after processing this batch is:  26534.70703125\n",
      "The representation loss after processing this batch is:  0.00012806802988052368\n",
      "The classification loss after processing this batch is:  22458.779296875\n",
      "The representation loss after processing this batch is:  0.00012112781405448914\n",
      "The classification loss after processing this batch is:  21935.44140625\n",
      "The representation loss after processing this batch is:  0.00012486055493354797\n",
      "The classification loss after processing this batch is:  22531.796875\n",
      "The representation loss after processing this batch is:  0.00012298859655857086\n",
      "The classification loss after processing this batch is:  23286.6640625\n",
      "The representation loss after processing this batch is:  0.00013588089495897293\n",
      "The classification loss after processing this batch is:  23073.984375\n",
      "The representation loss after processing this batch is:  0.0001126239076256752\n",
      "The classification loss after processing this batch is:  22914.359375\n",
      "The representation loss after processing this batch is:  0.00011549331247806549\n",
      "The classification loss after processing this batch is:  23932.03125\n",
      "The representation loss after processing this batch is:  0.00010659545660018921\n",
      "The classification loss after processing this batch is:  24665.587890625\n",
      "The representation loss after processing this batch is:  0.00013946089893579483\n",
      "The classification loss after processing this batch is:  22447.609375\n",
      "The representation loss after processing this batch is:  0.00012689456343650818\n",
      "The classification loss after processing this batch is:  23254.29296875\n",
      "The representation loss after processing this batch is:  0.000128207728266716\n",
      "The classification loss after processing this batch is:  22136.345703125\n",
      "The representation loss after processing this batch is:  0.000119050033390522\n",
      "The classification loss after processing this batch is:  22388.6171875\n",
      "The representation loss after processing this batch is:  0.00012040138244628906\n",
      "The classification loss after processing this batch is:  21653.625\n",
      "The representation loss after processing this batch is:  0.00014031492173671722\n",
      "The classification loss after processing this batch is:  23181.353515625\n",
      "The representation loss after processing this batch is:  0.00013727881014347076\n",
      "The classification loss after processing this batch is:  22881.23046875\n",
      "The representation loss after processing this batch is:  0.0001130327582359314\n",
      "The classification loss after processing this batch is:  24710.8359375\n",
      "The representation loss after processing this batch is:  0.0001268051564693451\n",
      "The classification loss after processing this batch is:  22691.982421875\n",
      "The representation loss after processing this batch is:  0.00012668035924434662\n",
      "The classification loss after processing this batch is:  22908.03125\n",
      "The representation loss after processing this batch is:  0.00011990126222372055\n",
      "The classification loss after processing this batch is:  24169.56640625\n",
      "The representation loss after processing this batch is:  0.00012980960309505463\n",
      "The classification loss after processing this batch is:  23774.41015625\n",
      "The representation loss after processing this batch is:  0.00011243857443332672\n",
      "The classification loss after processing this batch is:  22995.23828125\n",
      "The representation loss after processing this batch is:  0.00012062862515449524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24377.29296875\n",
      "The representation loss after processing this batch is:  0.0001299697905778885\n",
      "The classification loss after processing this batch is:  22766.20703125\n",
      "The representation loss after processing this batch is:  0.00013419333845376968\n",
      "The classification loss after processing this batch is:  23513.00390625\n",
      "The representation loss after processing this batch is:  0.00014514848589897156\n",
      "The classification loss after processing this batch is:  22192.71875\n",
      "The representation loss after processing this batch is:  0.00011119246482849121\n",
      "The classification loss after processing this batch is:  22160.064453125\n",
      "The representation loss after processing this batch is:  0.00011448934674263\n",
      "The classification loss after processing this batch is:  22127.984375\n",
      "The representation loss after processing this batch is:  0.00012979283928871155\n",
      "The classification loss after processing this batch is:  22052.125\n",
      "The representation loss after processing this batch is:  0.00012721866369247437\n",
      "The classification loss after processing this batch is:  21921.08203125\n",
      "The representation loss after processing this batch is:  0.00011683069169521332\n",
      "The classification loss after processing this batch is:  24657.875\n",
      "The representation loss after processing this batch is:  0.00012000836431980133\n",
      "The classification loss after processing this batch is:  22200.5078125\n",
      "The representation loss after processing this batch is:  0.00010534003376960754\n",
      "The classification loss after processing this batch is:  22820.09765625\n",
      "The representation loss after processing this batch is:  0.00011241808533668518\n",
      "The classification loss after processing this batch is:  23529.35546875\n",
      "The representation loss after processing this batch is:  0.00011144764721393585\n",
      "The classification loss after processing this batch is:  22853.1953125\n",
      "The representation loss after processing this batch is:  0.00010687019675970078\n",
      "The classification loss after processing this batch is:  23432.572265625\n",
      "The representation loss after processing this batch is:  0.00012656021863222122\n",
      "The classification loss after processing this batch is:  23206.015625\n",
      "The representation loss after processing this batch is:  0.00011081062257289886\n",
      "The classification loss after processing this batch is:  22880.7734375\n",
      "The representation loss after processing this batch is:  0.00013270508497953415\n",
      "The classification loss after processing this batch is:  21670.7734375\n",
      "The representation loss after processing this batch is:  0.00011872220784425735\n",
      "The classification loss after processing this batch is:  23202.796875\n",
      "The representation loss after processing this batch is:  0.0001255245879292488\n",
      "The classification loss after processing this batch is:  25925.044921875\n",
      "The representation loss after processing this batch is:  0.00011933594942092896\n",
      "The classification loss after processing this batch is:  26540.341796875\n",
      "The representation loss after processing this batch is:  0.00013399310410022736\n",
      "The classification loss after processing this batch is:  23163.8984375\n",
      "The representation loss after processing this batch is:  0.00010930001735687256\n",
      "The classification loss after processing this batch is:  23118.00390625\n",
      "The representation loss after processing this batch is:  0.00011839345097541809\n",
      "The classification loss after processing this batch is:  22872.96875\n",
      "The representation loss after processing this batch is:  0.00012094713747501373\n",
      "The classification loss after processing this batch is:  23757.451171875\n",
      "The representation loss after processing this batch is:  0.00013229437172412872\n",
      "The classification loss after processing this batch is:  22714.64453125\n",
      "The representation loss after processing this batch is:  0.00012714602053165436\n",
      "The classification loss after processing this batch is:  23058.453125\n",
      "The representation loss after processing this batch is:  0.00010895449668169022\n",
      "The classification loss after processing this batch is:  24497.205078125\n",
      "The representation loss after processing this batch is:  0.00012447312474250793\n",
      "The classification loss after processing this batch is:  21854.12890625\n",
      "The representation loss after processing this batch is:  0.00010514911264181137\n",
      "The classification loss after processing this batch is:  22515.345703125\n",
      "The representation loss after processing this batch is:  0.00011011958122253418\n",
      "The classification loss after processing this batch is:  25048.40234375\n",
      "The representation loss after processing this batch is:  0.0001265835016965866\n",
      "The classification loss after processing this batch is:  23814.2578125\n",
      "The representation loss after processing this batch is:  0.00012198090553283691\n",
      "The classification loss after processing this batch is:  22810.8828125\n",
      "The representation loss after processing this batch is:  0.0001264512538909912\n",
      "The classification loss after processing this batch is:  21677.78125\n",
      "The representation loss after processing this batch is:  0.00010709278285503387\n",
      "The classification loss after processing this batch is:  24730.099609375\n",
      "The representation loss after processing this batch is:  0.00012898258864879608\n",
      "The classification loss after processing this batch is:  24129.01171875\n",
      "The representation loss after processing this batch is:  0.000135885551571846\n",
      "The classification loss after processing this batch is:  28376.05859375\n",
      "The representation loss after processing this batch is:  0.00011945143342018127\n",
      "The classification loss after processing this batch is:  24147.37109375\n",
      "The representation loss after processing this batch is:  0.00010820385068655014\n",
      "The classification loss after processing this batch is:  22969.55078125\n",
      "The representation loss after processing this batch is:  0.0001305956393480301\n",
      "The classification loss after processing this batch is:  24493.171875\n",
      "The representation loss after processing this batch is:  0.00013148970901966095\n",
      "The classification loss after processing this batch is:  25591.087890625\n",
      "The representation loss after processing this batch is:  0.0001309448853135109\n",
      "The classification loss after processing this batch is:  24298.583984375\n",
      "The representation loss after processing this batch is:  0.0001268954947590828\n",
      "The classification loss after processing this batch is:  23927.625\n",
      "The representation loss after processing this batch is:  0.00011988077312707901\n",
      "The classification loss after processing this batch is:  23604.2265625\n",
      "The representation loss after processing this batch is:  0.00010345783084630966\n",
      "The classification loss after processing this batch is:  23524.3203125\n",
      "The representation loss after processing this batch is:  0.00011879298835992813\n",
      "The classification loss after processing this batch is:  22372.484375\n",
      "The representation loss after processing this batch is:  0.0001198500394821167\n",
      "The classification loss after processing this batch is:  23287.2890625\n",
      "The representation loss after processing this batch is:  0.00012523215264081955\n",
      "The classification loss after processing this batch is:  22965.94140625\n",
      "The representation loss after processing this batch is:  0.00011466443538665771\n",
      "The classification loss after processing this batch is:  23671.79296875\n",
      "The representation loss after processing this batch is:  0.00011592917144298553\n",
      "The classification loss after processing this batch is:  23653.32421875\n",
      "The representation loss after processing this batch is:  0.00010201334953308105\n",
      "The classification loss after processing this batch is:  23732.6171875\n",
      "The representation loss after processing this batch is:  0.00012777931988239288\n",
      "The classification loss after processing this batch is:  22085.279296875\n",
      "The representation loss after processing this batch is:  0.00012495089322328568\n",
      "The classification loss after processing this batch is:  21587.09765625\n",
      "The representation loss after processing this batch is:  0.00014030560851097107\n",
      "The classification loss after processing this batch is:  22173.4296875\n",
      "The representation loss after processing this batch is:  0.00011048652231693268\n",
      "The classification loss after processing this batch is:  21973.2578125\n",
      "The representation loss after processing this batch is:  0.00010580569505691528\n",
      "The classification loss after processing this batch is:  23646.62109375\n",
      "The representation loss after processing this batch is:  0.00010983366519212723\n",
      "The classification loss after processing this batch is:  23298.19140625\n",
      "The representation loss after processing this batch is:  0.0001100907102227211\n",
      "The classification loss after processing this batch is:  22308.798828125\n",
      "The representation loss after processing this batch is:  0.00014851242303848267\n",
      "The classification loss after processing this batch is:  21183.591796875\n",
      "The representation loss after processing this batch is:  0.00011765211820602417\n",
      "The classification loss after processing this batch is:  21348.171875\n",
      "The representation loss after processing this batch is:  0.00010620243847370148\n",
      "The classification loss after processing this batch is:  22901.4140625\n",
      "The representation loss after processing this batch is:  0.00011981744319200516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  23665.673828125\n",
      "The representation loss after processing this batch is:  0.00011473800987005234\n",
      "The classification loss after processing this batch is:  23622.251953125\n",
      "The representation loss after processing this batch is:  0.0001528766006231308\n",
      "The classification loss after processing this batch is:  21681.794921875\n",
      "The representation loss after processing this batch is:  0.00012359581887722015\n",
      "The classification loss after processing this batch is:  22653.671875\n",
      "The representation loss after processing this batch is:  0.00011721998453140259\n",
      "The classification loss after processing this batch is:  22226.8984375\n",
      "The representation loss after processing this batch is:  0.00013284757733345032\n",
      "The classification loss after processing this batch is:  22553.759765625\n",
      "The representation loss after processing this batch is:  0.00016550719738006592\n",
      "The classification loss after processing this batch is:  21666.849609375\n",
      "The representation loss after processing this batch is:  0.00011631473898887634\n",
      "The classification loss after processing this batch is:  21556.94140625\n",
      "The representation loss after processing this batch is:  0.00012812018394470215\n",
      "The classification loss after processing this batch is:  21615.57421875\n",
      "The representation loss after processing this batch is:  0.00013266876339912415\n",
      "The classification loss after processing this batch is:  22548.197265625\n",
      "The representation loss after processing this batch is:  0.000131094828248024\n",
      "The classification loss after processing this batch is:  22783.64453125\n",
      "The representation loss after processing this batch is:  0.0001291763037443161\n",
      "The classification loss after processing this batch is:  22737.59375\n",
      "The representation loss after processing this batch is:  0.00013393722474575043\n",
      "The classification loss after processing this batch is:  22282.078125\n",
      "The representation loss after processing this batch is:  0.00013214163482189178\n",
      "The classification loss after processing this batch is:  22219.98046875\n",
      "The representation loss after processing this batch is:  0.00011829286813735962\n",
      "The classification loss after processing this batch is:  23658.109375\n",
      "The representation loss after processing this batch is:  0.00013580918312072754\n",
      "The classification loss after processing this batch is:  24991.615234375\n",
      "The representation loss after processing this batch is:  0.00015172362327575684\n",
      "The classification loss after processing this batch is:  23990.453125\n",
      "The representation loss after processing this batch is:  0.0001169741153717041\n",
      "The classification loss after processing this batch is:  23859.85546875\n",
      "The representation loss after processing this batch is:  0.0001419205218553543\n",
      "The classification loss after processing this batch is:  22096.044921875\n",
      "The representation loss after processing this batch is:  0.00010678544640541077\n",
      "The classification loss after processing this batch is:  22406.380859375\n",
      "The representation loss after processing this batch is:  0.000109928660094738\n",
      "The classification loss after processing this batch is:  23712.3203125\n",
      "The representation loss after processing this batch is:  0.0001265108585357666\n",
      "The classification loss after processing this batch is:  22298.9296875\n",
      "The representation loss after processing this batch is:  0.0001294165849685669\n",
      "The classification loss after processing this batch is:  22426.435546875\n",
      "The representation loss after processing this batch is:  0.00012163352221250534\n",
      "The classification loss after processing this batch is:  23323.001953125\n",
      "The representation loss after processing this batch is:  0.00012509431689977646\n",
      "The classification loss after processing this batch is:  23195.30859375\n",
      "The representation loss after processing this batch is:  0.00011524558067321777\n",
      "The classification loss after processing this batch is:  23136.5859375\n",
      "The representation loss after processing this batch is:  0.00012049823999404907\n",
      "The classification loss after processing this batch is:  22633.53125\n",
      "The representation loss after processing this batch is:  0.0001139417290687561\n",
      "The classification loss after processing this batch is:  23918.873046875\n",
      "The representation loss after processing this batch is:  0.00013884902000427246\n",
      "The classification loss after processing this batch is:  23661.9140625\n",
      "The representation loss after processing this batch is:  0.00012562796473503113\n",
      "The classification loss after processing this batch is:  24103.5078125\n",
      "The representation loss after processing this batch is:  0.00010563712567090988\n",
      "The classification loss after processing this batch is:  24406.072265625\n",
      "The representation loss after processing this batch is:  0.00013557448983192444\n",
      "The classification loss after processing this batch is:  23299.18359375\n",
      "The representation loss after processing this batch is:  0.00011320412158966064\n",
      "The classification loss after processing this batch is:  22519.1484375\n",
      "The representation loss after processing this batch is:  0.00012650713324546814\n",
      "The classification loss after processing this batch is:  22604.65625\n",
      "The representation loss after processing this batch is:  0.0001129545271396637\n",
      "The classification loss after processing this batch is:  22452.7421875\n",
      "The representation loss after processing this batch is:  0.00011391844600439072\n",
      "The classification loss after processing this batch is:  22656.984375\n",
      "The representation loss after processing this batch is:  0.00013487227261066437\n",
      "The classification loss after processing this batch is:  22178.48046875\n",
      "The representation loss after processing this batch is:  0.00011765304952859879\n",
      "The classification loss after processing this batch is:  23001.80078125\n",
      "The representation loss after processing this batch is:  0.00011493917554616928\n",
      "The classification loss after processing this batch is:  22766.94921875\n",
      "The representation loss after processing this batch is:  0.00012367404997348785\n",
      "The classification loss after processing this batch is:  25973.611328125\n",
      "The representation loss after processing this batch is:  0.00012333691120147705\n",
      "The classification loss after processing this batch is:  25018.15234375\n",
      "The representation loss after processing this batch is:  0.00011621508747339249\n",
      "The classification loss after processing this batch is:  22849.572265625\n",
      "The representation loss after processing this batch is:  0.00011381693184375763\n",
      "The classification loss after processing this batch is:  21582.373046875\n",
      "The representation loss after processing this batch is:  0.00012809503823518753\n",
      "The classification loss after processing this batch is:  21941.2265625\n",
      "The representation loss after processing this batch is:  0.00013603270053863525\n",
      "The classification loss after processing this batch is:  22930.3046875\n",
      "The representation loss after processing this batch is:  0.00013136304914951324\n",
      "The classification loss after processing this batch is:  22376.736328125\n",
      "The representation loss after processing this batch is:  0.0001289350911974907\n",
      "The classification loss after processing this batch is:  23071.83203125\n",
      "The representation loss after processing this batch is:  0.00011970289051532745\n",
      "The classification loss after processing this batch is:  22852.712890625\n",
      "The representation loss after processing this batch is:  0.00012185517698526382\n",
      "The classification loss after processing this batch is:  22129.65234375\n",
      "The representation loss after processing this batch is:  0.00011767540127038956\n",
      "The classification loss after processing this batch is:  21779.484375\n",
      "The representation loss after processing this batch is:  0.0001225518062710762\n",
      "The classification loss after processing this batch is:  23194.07421875\n",
      "The representation loss after processing this batch is:  0.00011417455971240997\n",
      "The classification loss after processing this batch is:  23644.53515625\n",
      "The representation loss after processing this batch is:  0.000131949782371521\n",
      "The classification loss after processing this batch is:  22304.318359375\n",
      "The representation loss after processing this batch is:  0.00011429190635681152\n",
      "The classification loss after processing this batch is:  23158.66796875\n",
      "The representation loss after processing this batch is:  0.00013035256415605545\n",
      "The classification loss after processing this batch is:  24810.16015625\n",
      "The representation loss after processing this batch is:  0.00012244470417499542\n",
      "The classification loss after processing this batch is:  23782.31640625\n",
      "The representation loss after processing this batch is:  0.0001214984804391861\n",
      "The classification loss after processing this batch is:  25130.314453125\n",
      "The representation loss after processing this batch is:  0.00013612210750579834\n",
      "The classification loss after processing this batch is:  22558.62890625\n",
      "The representation loss after processing this batch is:  0.00011357665061950684\n",
      "The classification loss after processing this batch is:  23424.748046875\n",
      "The representation loss after processing this batch is:  0.00015062279999256134\n",
      "The classification loss after processing this batch is:  22495.31640625\n",
      "The representation loss after processing this batch is:  0.00012801960110664368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  23279.890625\n",
      "The representation loss after processing this batch is:  0.00011006742715835571\n",
      "The classification loss after processing this batch is:  22876.09765625\n",
      "The representation loss after processing this batch is:  0.00011919252574443817\n",
      "The classification loss after processing this batch is:  22782.0859375\n",
      "The representation loss after processing this batch is:  0.0001079123467206955\n",
      "The classification loss after processing this batch is:  23138.2734375\n",
      "The representation loss after processing this batch is:  0.00011383555829524994\n",
      "The classification loss after processing this batch is:  22278.69140625\n",
      "The representation loss after processing this batch is:  0.00011666864156723022\n",
      "The classification loss after processing this batch is:  22629.556640625\n",
      "The representation loss after processing this batch is:  0.00011964701116085052\n",
      "The classification loss after processing this batch is:  21894.578125\n",
      "The representation loss after processing this batch is:  0.0001231897622346878\n",
      "The classification loss after processing this batch is:  22101.27734375\n",
      "The representation loss after processing this batch is:  0.00012277066707611084\n",
      "The classification loss after processing this batch is:  21736.46875\n",
      "The representation loss after processing this batch is:  0.00012928806245326996\n",
      "The classification loss after processing this batch is:  23293.318359375\n",
      "The representation loss after processing this batch is:  0.00012343190610408783\n",
      "The classification loss after processing this batch is:  22470.328125\n",
      "The representation loss after processing this batch is:  0.0001217275857925415\n",
      "The classification loss after processing this batch is:  23204.470703125\n",
      "The representation loss after processing this batch is:  0.00013656262308359146\n",
      "The classification loss after processing this batch is:  23522.21484375\n",
      "The representation loss after processing this batch is:  0.00011747237294912338\n",
      "The classification loss after processing this batch is:  22129.0625\n",
      "The representation loss after processing this batch is:  0.00010532140731811523\n",
      "The classification loss after processing this batch is:  23224.83203125\n",
      "The representation loss after processing this batch is:  0.00012306775897741318\n",
      "The classification loss after processing this batch is:  22862.1171875\n",
      "The representation loss after processing this batch is:  0.00013466831296682358\n",
      "The classification loss after processing this batch is:  21781.75\n",
      "The representation loss after processing this batch is:  0.00012039020657539368\n",
      "The classification loss after processing this batch is:  22880.634765625\n",
      "The representation loss after processing this batch is:  0.00011489354074001312\n",
      "The classification loss after processing this batch is:  22662.58203125\n",
      "The representation loss after processing this batch is:  0.00012394506484270096\n",
      "The classification loss after processing this batch is:  22033.1015625\n",
      "The representation loss after processing this batch is:  0.00011011213064193726\n",
      "The classification loss after processing this batch is:  22884.79296875\n",
      "The representation loss after processing this batch is:  0.00011426862329244614\n",
      "The classification loss after processing this batch is:  22375.84375\n",
      "The representation loss after processing this batch is:  0.00011633895337581635\n",
      "The classification loss after processing this batch is:  23614.326171875\n",
      "The representation loss after processing this batch is:  0.00012927129864692688\n",
      "The classification loss after processing this batch is:  24263.17578125\n",
      "The representation loss after processing this batch is:  0.00011663325130939484\n",
      "The classification loss after processing this batch is:  22515.458984375\n",
      "The representation loss after processing this batch is:  0.00013520848006010056\n",
      "The classification loss after processing this batch is:  25121.98046875\n",
      "The representation loss after processing this batch is:  0.00012181326746940613\n",
      "The classification loss after processing this batch is:  25149.1328125\n",
      "The representation loss after processing this batch is:  0.00012401770800352097\n",
      "The classification loss after processing this batch is:  22309.212890625\n",
      "The representation loss after processing this batch is:  0.00011834781616926193\n",
      "The classification loss after processing this batch is:  23020.8984375\n",
      "The representation loss after processing this batch is:  0.00010920967906713486\n",
      "The classification loss after processing this batch is:  24095.4609375\n",
      "The representation loss after processing this batch is:  0.0001487499102950096\n",
      "The classification loss after processing this batch is:  22753.13671875\n",
      "The representation loss after processing this batch is:  0.0001385984942317009\n",
      "The classification loss after processing this batch is:  22731.71875\n",
      "The representation loss after processing this batch is:  0.00014283135533332825\n",
      "The classification loss after processing this batch is:  22777.904296875\n",
      "The representation loss after processing this batch is:  0.0001258915290236473\n",
      "The classification loss after processing this batch is:  23014.98828125\n",
      "The representation loss after processing this batch is:  0.00013247132301330566\n",
      "The classification loss after processing this batch is:  23964.4453125\n",
      "The representation loss after processing this batch is:  0.00011254288256168365\n",
      "The classification loss after processing this batch is:  23599.333984375\n",
      "The representation loss after processing this batch is:  0.00011972896754741669\n",
      "The classification loss after processing this batch is:  25195.83203125\n",
      "The representation loss after processing this batch is:  0.00012456439435482025\n",
      "The classification loss after processing this batch is:  24239.06640625\n",
      "The representation loss after processing this batch is:  0.00011384766548871994\n",
      "The classification loss after processing this batch is:  24355.353515625\n",
      "The representation loss after processing this batch is:  0.00010936055332422256\n",
      "The classification loss after processing this batch is:  22330.376953125\n",
      "The representation loss after processing this batch is:  0.00011859741061925888\n",
      "The classification loss after processing this batch is:  22851.69140625\n",
      "The representation loss after processing this batch is:  0.00011478178203105927\n",
      "The classification loss after processing this batch is:  23838.873046875\n",
      "The representation loss after processing this batch is:  0.00010839477181434631\n",
      "The classification loss after processing this batch is:  22504.30859375\n",
      "The representation loss after processing this batch is:  0.00010980106890201569\n",
      "The classification loss after processing this batch is:  21661.044921875\n",
      "The representation loss after processing this batch is:  0.0001222454011440277\n",
      "The classification loss after processing this batch is:  23980.021484375\n",
      "The representation loss after processing this batch is:  0.00010446179658174515\n",
      "The classification loss after processing this batch is:  22308.154296875\n",
      "The representation loss after processing this batch is:  0.00011982396245002747\n",
      "The classification loss after processing this batch is:  22784.1640625\n",
      "The representation loss after processing this batch is:  0.00010852143168449402\n",
      "The classification loss after processing this batch is:  21934.373046875\n",
      "The representation loss after processing this batch is:  0.00011216290295124054\n",
      "The classification loss after processing this batch is:  22845.271484375\n",
      "The representation loss after processing this batch is:  0.00011963490396738052\n",
      "The classification loss after processing this batch is:  21955.59375\n",
      "The representation loss after processing this batch is:  0.00010993797332048416\n",
      "The classification loss after processing this batch is:  23207.68359375\n",
      "The representation loss after processing this batch is:  0.00012503471225500107\n",
      "The classification loss after processing this batch is:  22797.81640625\n",
      "The representation loss after processing this batch is:  0.00011078547686338425\n",
      "The classification loss after processing this batch is:  22400.16796875\n",
      "The representation loss after processing this batch is:  0.00012008193880319595\n",
      "The classification loss after processing this batch is:  23457.47265625\n",
      "The representation loss after processing this batch is:  0.00014155078679323196\n",
      "The classification loss after processing this batch is:  24015.23046875\n",
      "The representation loss after processing this batch is:  0.00010613910853862762\n",
      "The classification loss after processing this batch is:  22113.6484375\n",
      "The representation loss after processing this batch is:  0.00013370811939239502\n",
      "The classification loss after processing this batch is:  22454.189453125\n",
      "The representation loss after processing this batch is:  0.00012014433741569519\n",
      "The classification loss after processing this batch is:  22900.423828125\n",
      "The representation loss after processing this batch is:  0.0001191822811961174\n",
      "The classification loss after processing this batch is:  22960.916015625\n",
      "The representation loss after processing this batch is:  0.00010820291936397552\n",
      "The classification loss after processing this batch is:  24157.662109375\n",
      "The representation loss after processing this batch is:  0.00011364370584487915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22638.88671875\n",
      "The representation loss after processing this batch is:  0.00011916551738977432\n",
      "The classification loss after processing this batch is:  22060.2578125\n",
      "The representation loss after processing this batch is:  0.0001156926155090332\n",
      "The classification loss after processing this batch is:  22892.0703125\n",
      "The representation loss after processing this batch is:  0.0001290552318096161\n",
      "The classification loss after processing this batch is:  24843.177734375\n",
      "The representation loss after processing this batch is:  0.00014091841876506805\n",
      "The classification loss after processing this batch is:  22675.275390625\n",
      "The representation loss after processing this batch is:  0.00011097732931375504\n",
      "The classification loss after processing this batch is:  23556.52734375\n",
      "The representation loss after processing this batch is:  0.00010687205940485\n",
      "The classification loss after processing this batch is:  25364.232421875\n",
      "The representation loss after processing this batch is:  0.00011971127241849899\n",
      "The classification loss after processing this batch is:  23181.990234375\n",
      "The representation loss after processing this batch is:  0.0001227017492055893\n",
      "The classification loss after processing this batch is:  22200.0390625\n",
      "The representation loss after processing this batch is:  0.00012073945254087448\n",
      "The classification loss after processing this batch is:  22525.328125\n",
      "The representation loss after processing this batch is:  0.00012842193245887756\n",
      "The classification loss after processing this batch is:  22593.85546875\n",
      "The representation loss after processing this batch is:  0.00010096188634634018\n",
      "The classification loss after processing this batch is:  22973.5234375\n",
      "The representation loss after processing this batch is:  0.00011629052460193634\n",
      "The classification loss after processing this batch is:  22484.724609375\n",
      "The representation loss after processing this batch is:  0.00011816993355751038\n",
      "The classification loss after processing this batch is:  23033.720703125\n",
      "The representation loss after processing this batch is:  0.00011556316167116165\n",
      "The classification loss after processing this batch is:  25502.232421875\n",
      "The representation loss after processing this batch is:  0.0001400299370288849\n",
      "The classification loss after processing this batch is:  24057.76171875\n",
      "The representation loss after processing this batch is:  0.0001050364226102829\n",
      "The classification loss after processing this batch is:  23304.30078125\n",
      "The representation loss after processing this batch is:  0.00012366939336061478\n",
      "The classification loss after processing this batch is:  22424.66796875\n",
      "The representation loss after processing this batch is:  0.00011826027184724808\n",
      "The classification loss after processing this batch is:  22874.046875\n",
      "The representation loss after processing this batch is:  0.00014381855726242065\n",
      "The classification loss after processing this batch is:  22694.30859375\n",
      "The representation loss after processing this batch is:  0.0001446641981601715\n",
      "The classification loss after processing this batch is:  22357.216796875\n",
      "The representation loss after processing this batch is:  0.00011901184916496277\n",
      "The classification loss after processing this batch is:  21941.462890625\n",
      "The representation loss after processing this batch is:  0.00010997429490089417\n",
      "The classification loss after processing this batch is:  22628.962890625\n",
      "The representation loss after processing this batch is:  0.00011383555829524994\n",
      "The classification loss after processing this batch is:  22448.72265625\n",
      "The representation loss after processing this batch is:  0.00010344386100769043\n",
      "The classification loss after processing this batch is:  21516.90234375\n",
      "The representation loss after processing this batch is:  0.0001185685396194458\n",
      "The classification loss after processing this batch is:  22576.986328125\n",
      "The representation loss after processing this batch is:  0.00012828875333070755\n",
      "The classification loss after processing this batch is:  21602.97265625\n",
      "The representation loss after processing this batch is:  0.0001262463629245758\n",
      "The classification loss after processing this batch is:  23917.16796875\n",
      "The representation loss after processing this batch is:  0.00012273713946342468\n",
      "The classification loss after processing this batch is:  23627.59765625\n",
      "The representation loss after processing this batch is:  0.00010267365723848343\n",
      "The classification loss after processing this batch is:  22453.623046875\n",
      "The representation loss after processing this batch is:  0.0001051025465130806\n",
      "The classification loss after processing this batch is:  22487.5546875\n",
      "The representation loss after processing this batch is:  0.0001029185950756073\n",
      "The classification loss after processing this batch is:  22451.3046875\n",
      "The representation loss after processing this batch is:  0.00011926423758268356\n",
      "The classification loss after processing this batch is:  24053.60546875\n",
      "The representation loss after processing this batch is:  0.00012138672173023224\n",
      "The classification loss after processing this batch is:  23401.001953125\n",
      "The representation loss after processing this batch is:  0.0001194830983877182\n",
      "The classification loss after processing this batch is:  22742.693359375\n",
      "The representation loss after processing this batch is:  0.00011480320245027542\n",
      "The classification loss after processing this batch is:  22986.46484375\n",
      "The representation loss after processing this batch is:  0.0001070946455001831\n",
      "The classification loss after processing this batch is:  24434.611328125\n",
      "The representation loss after processing this batch is:  0.00012467429041862488\n",
      "The classification loss after processing this batch is:  21994.3359375\n",
      "The representation loss after processing this batch is:  0.00010480359196662903\n",
      "The classification loss after processing this batch is:  23051.93359375\n",
      "The representation loss after processing this batch is:  0.00011085160076618195\n",
      "The classification loss after processing this batch is:  22750.95703125\n",
      "The representation loss after processing this batch is:  0.00013815239071846008\n",
      "The classification loss after processing this batch is:  22727.712890625\n",
      "The representation loss after processing this batch is:  0.00011256895959377289\n",
      "The classification loss after processing this batch is:  23468.5234375\n",
      "The representation loss after processing this batch is:  0.00013939570635557175\n",
      "The classification loss after processing this batch is:  24140.29296875\n",
      "The representation loss after processing this batch is:  0.00012786313891410828\n",
      "The classification loss after processing this batch is:  22722.66015625\n",
      "The representation loss after processing this batch is:  0.00014640484005212784\n",
      "The classification loss after processing this batch is:  23548.3984375\n",
      "The representation loss after processing this batch is:  0.00010595563799142838\n",
      "The classification loss after processing this batch is:  24064.650390625\n",
      "The representation loss after processing this batch is:  0.00010581407696008682\n",
      "The classification loss after processing this batch is:  22347.244140625\n",
      "The representation loss after processing this batch is:  0.0001189354807138443\n",
      "The classification loss after processing this batch is:  23572.4921875\n",
      "The representation loss after processing this batch is:  0.00012248847633600235\n",
      "The classification loss after processing this batch is:  23091.4375\n",
      "The representation loss after processing this batch is:  0.00011791102588176727\n",
      "The classification loss after processing this batch is:  22323.7734375\n",
      "The representation loss after processing this batch is:  0.0001165047287940979\n",
      "The classification loss after processing this batch is:  22538.857421875\n",
      "The representation loss after processing this batch is:  0.00011189654469490051\n",
      "The classification loss after processing this batch is:  22424.931640625\n",
      "The representation loss after processing this batch is:  0.00011043623089790344\n",
      "The classification loss after processing this batch is:  22106.2734375\n",
      "The representation loss after processing this batch is:  0.0001272205263376236\n",
      "The classification loss after processing this batch is:  23901.43359375\n",
      "The representation loss after processing this batch is:  0.00012006796896457672\n",
      "The classification loss after processing this batch is:  23473.3359375\n",
      "The representation loss after processing this batch is:  0.00011849310249090195\n",
      "The classification loss after processing this batch is:  24684.22265625\n",
      "The representation loss after processing this batch is:  0.00012310780584812164\n",
      "The classification loss after processing this batch is:  21657.3671875\n",
      "The representation loss after processing this batch is:  0.0001172628253698349\n",
      "The classification loss after processing this batch is:  21900.52734375\n",
      "The representation loss after processing this batch is:  0.0001232735812664032\n",
      "The classification loss after processing this batch is:  22637.0859375\n",
      "The representation loss after processing this batch is:  0.0001282263547182083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22182.462890625\n",
      "The representation loss after processing this batch is:  0.00012028217315673828\n",
      "The classification loss after processing this batch is:  23498.25\n",
      "The representation loss after processing this batch is:  0.00012522749602794647\n",
      "The classification loss after processing this batch is:  22517.39453125\n",
      "The representation loss after processing this batch is:  0.00011668726801872253\n",
      "The classification loss after processing this batch is:  22859.359375\n",
      "The representation loss after processing this batch is:  0.00011025462299585342\n",
      "The classification loss after processing this batch is:  22944.87890625\n",
      "The representation loss after processing this batch is:  0.00010677799582481384\n",
      "The classification loss after processing this batch is:  22173.83984375\n",
      "The representation loss after processing this batch is:  0.00010979361832141876\n",
      "The classification loss after processing this batch is:  24026.978515625\n",
      "The representation loss after processing this batch is:  0.0001313546672463417\n",
      "The classification loss after processing this batch is:  24310.349609375\n",
      "The representation loss after processing this batch is:  0.00011456292122602463\n",
      "The classification loss after processing this batch is:  23473.255859375\n",
      "The representation loss after processing this batch is:  0.00011970940977334976\n",
      "The classification loss after processing this batch is:  21568.375\n",
      "The representation loss after processing this batch is:  0.0001183878630399704\n",
      "The classification loss after processing this batch is:  23812.6875\n",
      "The representation loss after processing this batch is:  0.00013165641576051712\n",
      "The classification loss after processing this batch is:  23434.423828125\n",
      "The representation loss after processing this batch is:  0.00011727772653102875\n",
      "The classification loss after processing this batch is:  22028.22265625\n",
      "The representation loss after processing this batch is:  0.00011020153760910034\n",
      "The classification loss after processing this batch is:  24368.25390625\n",
      "The representation loss after processing this batch is:  0.00013487692922353745\n",
      "The classification loss after processing this batch is:  24186.345703125\n",
      "The representation loss after processing this batch is:  0.00011793524026870728\n",
      "The classification loss after processing this batch is:  21851.53515625\n",
      "The representation loss after processing this batch is:  0.0001219082623720169\n",
      "The classification loss after processing this batch is:  22391.234375\n",
      "The representation loss after processing this batch is:  0.00013080891221761703\n",
      "The classification loss after processing this batch is:  22822.35546875\n",
      "The representation loss after processing this batch is:  0.00012025050818920135\n",
      "The classification loss after processing this batch is:  22614.53515625\n",
      "The representation loss after processing this batch is:  0.00012696720659732819\n",
      "The classification loss after processing this batch is:  23084.55078125\n",
      "The representation loss after processing this batch is:  0.00012337416410446167\n",
      "The classification loss after processing this batch is:  23899.404296875\n",
      "The representation loss after processing this batch is:  0.00012916699051856995\n",
      "The classification loss after processing this batch is:  21770.19140625\n",
      "The representation loss after processing this batch is:  0.0001242905855178833\n",
      "The classification loss after processing this batch is:  21595.826171875\n",
      "The representation loss after processing this batch is:  0.0001294352114200592\n",
      "The classification loss after processing this batch is:  23129.478515625\n",
      "The representation loss after processing this batch is:  0.00010934006422758102\n",
      "The classification loss after processing this batch is:  24353.12890625\n",
      "The representation loss after processing this batch is:  0.0001301746815443039\n",
      "The classification loss after processing this batch is:  22623.66015625\n",
      "The representation loss after processing this batch is:  0.00010269880294799805\n",
      "The classification loss after processing this batch is:  23170.80859375\n",
      "The representation loss after processing this batch is:  0.00012707337737083435\n",
      "The classification loss after processing this batch is:  22954.220703125\n",
      "The representation loss after processing this batch is:  0.00011009164154529572\n",
      "The classification loss after processing this batch is:  23333.466796875\n",
      "The representation loss after processing this batch is:  0.00010721106082201004\n",
      "The classification loss after processing this batch is:  22576.25\n",
      "The representation loss after processing this batch is:  0.00012547429651021957\n",
      "The classification loss after processing this batch is:  22928.220703125\n",
      "The representation loss after processing this batch is:  0.0001126537099480629\n",
      "The classification loss after processing this batch is:  23883.75\n",
      "The representation loss after processing this batch is:  0.00012147985398769379\n",
      "The classification loss after processing this batch is:  21771.638671875\n",
      "The representation loss after processing this batch is:  0.00012399256229400635\n",
      "The classification loss after processing this batch is:  21895.427734375\n",
      "The representation loss after processing this batch is:  0.00011414662003517151\n",
      "The classification loss after processing this batch is:  21529.607421875\n",
      "The representation loss after processing this batch is:  0.00011257641017436981\n",
      "The classification loss after processing this batch is:  21638.138671875\n",
      "The representation loss after processing this batch is:  0.00010791700333356857\n",
      "The classification loss after processing this batch is:  22050.0078125\n",
      "The representation loss after processing this batch is:  0.0001331530511379242\n",
      "The classification loss after processing this batch is:  23445.044921875\n",
      "The representation loss after processing this batch is:  0.00013356562703847885\n",
      "The classification loss after processing this batch is:  23484.203125\n",
      "The representation loss after processing this batch is:  0.00010805577039718628\n",
      "The classification loss after processing this batch is:  21733.423828125\n",
      "The representation loss after processing this batch is:  0.00012347102165222168\n",
      "The classification loss after processing this batch is:  21914.548828125\n",
      "The representation loss after processing this batch is:  0.00011673476547002792\n",
      "The classification loss after processing this batch is:  22077.17578125\n",
      "The representation loss after processing this batch is:  0.00010760687291622162\n",
      "The classification loss after processing this batch is:  22681.427734375\n",
      "The representation loss after processing this batch is:  0.00011401716619729996\n",
      "The classification loss after processing this batch is:  22623.216796875\n",
      "The representation loss after processing this batch is:  0.00013253651559352875\n",
      "The classification loss after processing this batch is:  21838.94921875\n",
      "The representation loss after processing this batch is:  0.0001195371150970459\n",
      "The classification loss after processing this batch is:  24345.498046875\n",
      "The representation loss after processing this batch is:  0.00011312868446111679\n",
      "The classification loss after processing this batch is:  22353.80859375\n",
      "The representation loss after processing this batch is:  0.00010044313967227936\n",
      "The classification loss after processing this batch is:  21815.328125\n",
      "The representation loss after processing this batch is:  0.0001134723424911499\n",
      "The classification loss after processing this batch is:  22302.39453125\n",
      "The representation loss after processing this batch is:  0.00012138579040765762\n",
      "The classification loss after processing this batch is:  22682.58984375\n",
      "The representation loss after processing this batch is:  0.00012705475091934204\n",
      "The classification loss after processing this batch is:  22228.421875\n",
      "The representation loss after processing this batch is:  0.00011919811367988586\n",
      "The classification loss after processing this batch is:  21943.625\n",
      "The representation loss after processing this batch is:  0.00013452209532260895\n",
      "The classification loss after processing this batch is:  22775.564453125\n",
      "The representation loss after processing this batch is:  0.00012165773659944534\n",
      "The classification loss after processing this batch is:  24380.919921875\n",
      "The representation loss after processing this batch is:  0.00011710170656442642\n",
      "The classification loss after processing this batch is:  21480.15625\n",
      "The representation loss after processing this batch is:  0.00012179277837276459\n",
      "The classification loss after processing this batch is:  22200.93359375\n",
      "The representation loss after processing this batch is:  0.00010494515299797058\n",
      "The classification loss after processing this batch is:  21096.859375\n",
      "The representation loss after processing this batch is:  0.00011861138045787811\n",
      "The classification loss after processing this batch is:  22471.392578125\n",
      "The representation loss after processing this batch is:  0.00010495539754629135\n",
      "The classification loss after processing this batch is:  22773.22265625\n",
      "The representation loss after processing this batch is:  0.0001208968460559845\n",
      "The classification loss after processing this batch is:  22193.88671875\n",
      "The representation loss after processing this batch is:  0.00011797063052654266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21979.3828125\n",
      "The representation loss after processing this batch is:  0.0001369379460811615\n",
      "The classification loss after processing this batch is:  21475.38671875\n",
      "The representation loss after processing this batch is:  0.00012157857418060303\n",
      "The classification loss after processing this batch is:  22353.240234375\n",
      "The representation loss after processing this batch is:  0.00011771917343139648\n",
      "The classification loss after processing this batch is:  22224.6796875\n",
      "The representation loss after processing this batch is:  0.00010792072862386703\n",
      "The classification loss after processing this batch is:  21475.32421875\n",
      "The representation loss after processing this batch is:  0.0001292116940021515\n",
      "The classification loss after processing this batch is:  25678.515625\n",
      "The representation loss after processing this batch is:  0.00012474879622459412\n",
      "The classification loss after processing this batch is:  24216.583984375\n",
      "The representation loss after processing this batch is:  0.00011448562145233154\n",
      "The classification loss after processing this batch is:  23249.51171875\n",
      "The representation loss after processing this batch is:  0.0001282021403312683\n",
      "The classification loss after processing this batch is:  22518.373046875\n",
      "The representation loss after processing this batch is:  0.0001155603677034378\n",
      "The classification loss after processing this batch is:  21904.376953125\n",
      "The representation loss after processing this batch is:  0.00013745855540037155\n",
      "The classification loss after processing this batch is:  22619.677734375\n",
      "The representation loss after processing this batch is:  0.00011431518942117691\n",
      "The classification loss after processing this batch is:  23527.890625\n",
      "The representation loss after processing this batch is:  0.00012129545211791992\n",
      "The classification loss after processing this batch is:  22572.6953125\n",
      "The representation loss after processing this batch is:  0.00010477844625711441\n",
      "The classification loss after processing this batch is:  24728.140625\n",
      "The representation loss after processing this batch is:  0.00012334343045949936\n",
      "The classification loss after processing this batch is:  22664.99609375\n",
      "The representation loss after processing this batch is:  0.00011720042675733566\n",
      "The classification loss after processing this batch is:  21953.47265625\n",
      "The representation loss after processing this batch is:  0.0001234905794262886\n",
      "The classification loss after processing this batch is:  24011.064453125\n",
      "The representation loss after processing this batch is:  0.00012872368097305298\n",
      "The classification loss after processing this batch is:  22042.03515625\n",
      "The representation loss after processing this batch is:  0.00011107604950666428\n",
      "The classification loss after processing this batch is:  22326.271484375\n",
      "The representation loss after processing this batch is:  0.00012190639972686768\n",
      "The classification loss after processing this batch is:  25677.46484375\n",
      "The representation loss after processing this batch is:  0.00012694858014583588\n",
      "The classification loss after processing this batch is:  23466.115234375\n",
      "The representation loss after processing this batch is:  0.00015381351113319397\n",
      "The classification loss after processing this batch is:  22122.19140625\n",
      "The representation loss after processing this batch is:  0.00014453381299972534\n",
      "The classification loss after processing this batch is:  22298.162109375\n",
      "The representation loss after processing this batch is:  0.0002297908067703247\n",
      "The classification loss after processing this batch is:  24484.591796875\n",
      "The representation loss after processing this batch is:  0.00013009272515773773\n",
      "The classification loss after processing this batch is:  21852.42578125\n",
      "The representation loss after processing this batch is:  0.00013184919953346252\n",
      "The classification loss after processing this batch is:  22065.70703125\n",
      "The representation loss after processing this batch is:  0.000148015096783638\n",
      "The classification loss after processing this batch is:  22874.732421875\n",
      "The representation loss after processing this batch is:  0.00015344657003879547\n",
      "The classification loss after processing this batch is:  27565.78125\n",
      "The representation loss after processing this batch is:  0.00013460591435432434\n",
      "The classification loss after processing this batch is:  30327.87109375\n",
      "The representation loss after processing this batch is:  0.00016284920275211334\n",
      "The classification loss after processing this batch is:  21699.671875\n",
      "The representation loss after processing this batch is:  0.0001311860978603363\n",
      "The classification loss after processing this batch is:  23066.43359375\n",
      "The representation loss after processing this batch is:  0.0001171845942735672\n",
      "The classification loss after processing this batch is:  23089.39453125\n",
      "The representation loss after processing this batch is:  0.00014579668641090393\n",
      "The classification loss after processing this batch is:  20768.30859375\n",
      "The representation loss after processing this batch is:  0.00011973828077316284\n",
      "The classification loss after processing this batch is:  22969.666015625\n",
      "The representation loss after processing this batch is:  8.57524573802948e-05\n",
      "The classification loss after processing this batch is:  23465.11328125\n",
      "The representation loss after processing this batch is:  7.854960858821869e-05\n",
      "The classification loss after processing this batch is:  22294.4375\n",
      "The representation loss after processing this batch is:  9.03196632862091e-05\n",
      "The classification loss after processing this batch is:  22577.33203125\n",
      "The representation loss after processing this batch is:  7.638894021511078e-05\n",
      "The classification loss after processing this batch is:  22638.80859375\n",
      "The representation loss after processing this batch is:  7.58543610572815e-05\n",
      "The classification loss after processing this batch is:  22392.2109375\n",
      "The representation loss after processing this batch is:  7.057655602693558e-05\n",
      "The classification loss after processing this batch is:  22422.541015625\n",
      "The representation loss after processing this batch is:  8.045695722103119e-05\n",
      "The classification loss after processing this batch is:  22505.859375\n",
      "The representation loss after processing this batch is:  7.44285061955452e-05\n",
      "The classification loss after processing this batch is:  22520.7421875\n",
      "The representation loss after processing this batch is:  7.530767470598221e-05\n",
      "The classification loss after processing this batch is:  26068.09765625\n",
      "The representation loss after processing this batch is:  7.168017327785492e-05\n",
      "The classification loss after processing this batch is:  25146.4921875\n",
      "The representation loss after processing this batch is:  6.447173655033112e-05\n",
      "The classification loss after processing this batch is:  22306.015625\n",
      "The representation loss after processing this batch is:  6.61015510559082e-05\n",
      "The classification loss after processing this batch is:  22155.5234375\n",
      "The representation loss after processing this batch is:  6.232690066099167e-05\n",
      "The classification loss after processing this batch is:  21785.9609375\n",
      "The representation loss after processing this batch is:  7.100868970155716e-05\n",
      "The classification loss after processing this batch is:  22316.943359375\n",
      "The representation loss after processing this batch is:  6.40377402305603e-05\n",
      "The classification loss after processing this batch is:  23392.36328125\n",
      "The representation loss after processing this batch is:  5.7211145758628845e-05\n",
      "The classification loss after processing this batch is:  22634.1171875\n",
      "The representation loss after processing this batch is:  6.621796637773514e-05\n",
      "The classification loss after processing this batch is:  24480.91015625\n",
      "The representation loss after processing this batch is:  7.349811494350433e-05\n",
      "The classification loss after processing this batch is:  22971.876953125\n",
      "The representation loss after processing this batch is:  6.187334656715393e-05\n",
      "The classification loss after processing this batch is:  23229.732421875\n",
      "The representation loss after processing this batch is:  7.100217044353485e-05\n",
      "The classification loss after processing this batch is:  23064.16015625\n",
      "The representation loss after processing this batch is:  5.966145545244217e-05\n",
      "The classification loss after processing this batch is:  23123.53515625\n",
      "The representation loss after processing this batch is:  6.954651325941086e-05\n",
      "The classification loss after processing this batch is:  23269.51171875\n",
      "The representation loss after processing this batch is:  5.9518031775951385e-05\n",
      "The classification loss after processing this batch is:  22835.64453125\n",
      "The representation loss after processing this batch is:  6.324145942926407e-05\n",
      "The classification loss after processing this batch is:  22807.32421875\n",
      "The representation loss after processing this batch is:  6.607081741094589e-05\n",
      "The classification loss after processing this batch is:  21930.267578125\n",
      "The representation loss after processing this batch is:  6.6414475440979e-05\n",
      "The classification loss after processing this batch is:  22430.5390625\n",
      "The representation loss after processing this batch is:  5.7374127209186554e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22443.91015625\n",
      "The representation loss after processing this batch is:  5.680415779352188e-05\n",
      "The classification loss after processing this batch is:  25021.470703125\n",
      "The representation loss after processing this batch is:  6.293412297964096e-05\n",
      "The classification loss after processing this batch is:  23537.90625\n",
      "The representation loss after processing this batch is:  5.981791764497757e-05\n",
      "The classification loss after processing this batch is:  22257.05078125\n",
      "The representation loss after processing this batch is:  5.973689258098602e-05\n",
      "The classification loss after processing this batch is:  22862.552734375\n",
      "The representation loss after processing this batch is:  5.1427632570266724e-05\n",
      "The classification loss after processing this batch is:  22004.943359375\n",
      "The representation loss after processing this batch is:  5.871988832950592e-05\n",
      "The classification loss after processing this batch is:  22462.208984375\n",
      "The representation loss after processing this batch is:  5.5870041251182556e-05\n",
      "The classification loss after processing this batch is:  22663.98046875\n",
      "The representation loss after processing this batch is:  6.038416177034378e-05\n",
      "The classification loss after processing this batch is:  22642.94921875\n",
      "The representation loss after processing this batch is:  6.32554292678833e-05\n",
      "The classification loss after processing this batch is:  24063.4921875\n",
      "The representation loss after processing this batch is:  5.3882598876953125e-05\n",
      "The classification loss after processing this batch is:  27695.560546875\n",
      "The representation loss after processing this batch is:  7.984507828950882e-05\n",
      "The classification loss after processing this batch is:  22651.05859375\n",
      "The representation loss after processing this batch is:  5.784258246421814e-05\n",
      "The classification loss after processing this batch is:  22961.51171875\n",
      "The representation loss after processing this batch is:  5.703698843717575e-05\n",
      "The classification loss after processing this batch is:  22906.654296875\n",
      "The representation loss after processing this batch is:  5.446653813123703e-05\n",
      "The classification loss after processing this batch is:  23145.439453125\n",
      "The representation loss after processing this batch is:  6.303563714027405e-05\n",
      "The classification loss after processing this batch is:  22677.255859375\n",
      "The representation loss after processing this batch is:  5.6566670536994934e-05\n",
      "The classification loss after processing this batch is:  22941.5078125\n",
      "The representation loss after processing this batch is:  5.957484245300293e-05\n",
      "The classification loss after processing this batch is:  22628.3515625\n",
      "The representation loss after processing this batch is:  5.3285155445337296e-05\n",
      "The classification loss after processing this batch is:  22758.953125\n",
      "The representation loss after processing this batch is:  6.226543337106705e-05\n",
      "The classification loss after processing this batch is:  22524.849609375\n",
      "The representation loss after processing this batch is:  5.612056702375412e-05\n",
      "The classification loss after processing this batch is:  22663.703125\n",
      "The representation loss after processing this batch is:  6.364844739437103e-05\n",
      "The classification loss after processing this batch is:  22395.326171875\n",
      "The representation loss after processing this batch is:  5.6265853345394135e-05\n",
      "The classification loss after processing this batch is:  22117.43359375\n",
      "The representation loss after processing this batch is:  5.8741308748722076e-05\n",
      "The classification loss after processing this batch is:  22090.046875\n",
      "The representation loss after processing this batch is:  6.162375211715698e-05\n",
      "The classification loss after processing this batch is:  20923.783203125\n",
      "The representation loss after processing this batch is:  5.9524551033973694e-05\n",
      "The classification loss after processing this batch is:  21990.603515625\n",
      "The representation loss after processing this batch is:  6.199628114700317e-05\n",
      "The classification loss after processing this batch is:  22253.6484375\n",
      "The representation loss after processing this batch is:  6.166985258460045e-05\n",
      "The classification loss after processing this batch is:  22014.75390625\n",
      "The representation loss after processing this batch is:  5.535222589969635e-05\n",
      "The classification loss after processing this batch is:  21706.626953125\n",
      "The representation loss after processing this batch is:  5.98859041929245e-05\n",
      "The classification loss after processing this batch is:  23165.900390625\n",
      "The representation loss after processing this batch is:  5.753524601459503e-05\n",
      "The classification loss after processing this batch is:  22071.8671875\n",
      "The representation loss after processing this batch is:  6.465986371040344e-05\n",
      "The classification loss after processing this batch is:  21844.19921875\n",
      "The representation loss after processing this batch is:  6.658211350440979e-05\n",
      "The classification loss after processing this batch is:  22311.26953125\n",
      "The representation loss after processing this batch is:  5.8329664170742035e-05\n",
      "The classification loss after processing this batch is:  23415.0390625\n",
      "The representation loss after processing this batch is:  5.940534174442291e-05\n",
      "The classification loss after processing this batch is:  24570.966796875\n",
      "The representation loss after processing this batch is:  5.214475095272064e-05\n",
      "The classification loss after processing this batch is:  24185.154296875\n",
      "The representation loss after processing this batch is:  5.5818818509578705e-05\n",
      "The classification loss after processing this batch is:  21107.484375\n",
      "The representation loss after processing this batch is:  5.941558629274368e-05\n",
      "The classification loss after processing this batch is:  23018.06640625\n",
      "The representation loss after processing this batch is:  5.408376455307007e-05\n",
      "The classification loss after processing this batch is:  21894.1796875\n",
      "The representation loss after processing this batch is:  4.984904080629349e-05\n",
      "The classification loss after processing this batch is:  23258.455078125\n",
      "The representation loss after processing this batch is:  6.115064024925232e-05\n",
      "The classification loss after processing this batch is:  23380.408203125\n",
      "The representation loss after processing this batch is:  5.905609577894211e-05\n",
      "The classification loss after processing this batch is:  22046.0234375\n",
      "The representation loss after processing this batch is:  5.232822149991989e-05\n",
      "The classification loss after processing this batch is:  22296.90625\n",
      "The representation loss after processing this batch is:  5.8659352362155914e-05\n",
      "The classification loss after processing this batch is:  22362.43359375\n",
      "The representation loss after processing this batch is:  6.0721300542354584e-05\n",
      "The classification loss after processing this batch is:  23336.64453125\n",
      "The representation loss after processing this batch is:  6.420165300369263e-05\n",
      "The classification loss after processing this batch is:  22324.671875\n",
      "The representation loss after processing this batch is:  6.537698209285736e-05\n",
      "The classification loss after processing this batch is:  23007.689453125\n",
      "The representation loss after processing this batch is:  5.5052340030670166e-05\n",
      "The classification loss after processing this batch is:  23622.4609375\n",
      "The representation loss after processing this batch is:  5.981326103210449e-05\n",
      "The classification loss after processing this batch is:  24422.3515625\n",
      "The representation loss after processing this batch is:  7.020216435194016e-05\n",
      "The classification loss after processing this batch is:  21806.86328125\n",
      "The representation loss after processing this batch is:  5.5371783673763275e-05\n",
      "The classification loss after processing this batch is:  21624.9375\n",
      "The representation loss after processing this batch is:  5.434360355138779e-05\n",
      "The classification loss after processing this batch is:  21795.328125\n",
      "The representation loss after processing this batch is:  5.54574653506279e-05\n",
      "The classification loss after processing this batch is:  23112.787109375\n",
      "The representation loss after processing this batch is:  5.270494148135185e-05\n",
      "The classification loss after processing this batch is:  24396.3828125\n",
      "The representation loss after processing this batch is:  6.307661533355713e-05\n",
      "The classification loss after processing this batch is:  22397.9296875\n",
      "The representation loss after processing this batch is:  6.225518882274628e-05\n",
      "The classification loss after processing this batch is:  21320.94921875\n",
      "The representation loss after processing this batch is:  5.666911602020264e-05\n",
      "The classification loss after processing this batch is:  21675.13671875\n",
      "The representation loss after processing this batch is:  6.29248097538948e-05\n",
      "The classification loss after processing this batch is:  21025.41796875\n",
      "The representation loss after processing this batch is:  5.668867379426956e-05\n",
      "The classification loss after processing this batch is:  21477.162109375\n",
      "The representation loss after processing this batch is:  5.5147334933280945e-05\n",
      "The classification loss after processing this batch is:  21493.572265625\n",
      "The representation loss after processing this batch is:  5.362462252378464e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21464.25390625\n",
      "The representation loss after processing this batch is:  5.7567842304706573e-05\n",
      "The classification loss after processing this batch is:  21157.734375\n",
      "The representation loss after processing this batch is:  5.249492824077606e-05\n",
      "The classification loss after processing this batch is:  21164.25\n",
      "The representation loss after processing this batch is:  5.9153884649276733e-05\n",
      "The classification loss after processing this batch is:  21704.9921875\n",
      "The representation loss after processing this batch is:  5.3495168685913086e-05\n",
      "The classification loss after processing this batch is:  21201.6796875\n",
      "The representation loss after processing this batch is:  5.385838449001312e-05\n",
      "The classification loss after processing this batch is:  21240.61328125\n",
      "The representation loss after processing this batch is:  5.643349140882492e-05\n",
      "The classification loss after processing this batch is:  21190.4453125\n",
      "The representation loss after processing this batch is:  5.1011331379413605e-05\n",
      "The classification loss after processing this batch is:  20673.328125\n",
      "The representation loss after processing this batch is:  5.309842526912689e-05\n",
      "The classification loss after processing this batch is:  22640.841796875\n",
      "The representation loss after processing this batch is:  5.242135375738144e-05\n",
      "The classification loss after processing this batch is:  22483.02734375\n",
      "The representation loss after processing this batch is:  5.30807301402092e-05\n",
      "The classification loss after processing this batch is:  23266.49609375\n",
      "The representation loss after processing this batch is:  6.60349614918232e-05\n",
      "The classification loss after processing this batch is:  23795.44140625\n",
      "The representation loss after processing this batch is:  6.074924021959305e-05\n",
      "The classification loss after processing this batch is:  23322.0703125\n",
      "The representation loss after processing this batch is:  5.948822945356369e-05\n",
      "The classification loss after processing this batch is:  22312.578125\n",
      "The representation loss after processing this batch is:  6.035994738340378e-05\n",
      "The classification loss after processing this batch is:  22708.9453125\n",
      "The representation loss after processing this batch is:  5.663558840751648e-05\n",
      "The classification loss after processing this batch is:  22188.97265625\n",
      "The representation loss after processing this batch is:  5.4958276450634e-05\n",
      "The classification loss after processing this batch is:  22566.0234375\n",
      "The representation loss after processing this batch is:  5.652196705341339e-05\n",
      "The classification loss after processing this batch is:  21772.677734375\n",
      "The representation loss after processing this batch is:  5.401298403739929e-05\n",
      "The classification loss after processing this batch is:  21625.25390625\n",
      "The representation loss after processing this batch is:  6.103888154029846e-05\n",
      "The classification loss after processing this batch is:  22696.142578125\n",
      "The representation loss after processing this batch is:  5.4201576858758926e-05\n",
      "The classification loss after processing this batch is:  22504.833984375\n",
      "The representation loss after processing this batch is:  5.899369716644287e-05\n",
      "The classification loss after processing this batch is:  21884.603515625\n",
      "The representation loss after processing this batch is:  5.1898881793022156e-05\n",
      "The classification loss after processing this batch is:  23106.701171875\n",
      "The representation loss after processing this batch is:  5.252659320831299e-05\n",
      "The classification loss after processing this batch is:  25486.265625\n",
      "The representation loss after processing this batch is:  6.241165101528168e-05\n",
      "The classification loss after processing this batch is:  23424.748046875\n",
      "The representation loss after processing this batch is:  5.3753145039081573e-05\n",
      "The classification loss after processing this batch is:  21787.14453125\n",
      "The representation loss after processing this batch is:  4.9952883273363113e-05\n",
      "The classification loss after processing this batch is:  22097.162109375\n",
      "The representation loss after processing this batch is:  5.4477714002132416e-05\n",
      "The classification loss after processing this batch is:  26239.61328125\n",
      "The representation loss after processing this batch is:  5.861558020114899e-05\n",
      "The classification loss after processing this batch is:  26556.73046875\n",
      "The representation loss after processing this batch is:  6.392970681190491e-05\n",
      "The classification loss after processing this batch is:  21594.98046875\n",
      "The representation loss after processing this batch is:  5.7600438594818115e-05\n",
      "The classification loss after processing this batch is:  21171.67578125\n",
      "The representation loss after processing this batch is:  6.50547444820404e-05\n",
      "The classification loss after processing this batch is:  21618.275390625\n",
      "The representation loss after processing this batch is:  5.7472847402095795e-05\n",
      "The classification loss after processing this batch is:  22159.162109375\n",
      "The representation loss after processing this batch is:  5.1528215408325195e-05\n",
      "The classification loss after processing this batch is:  22029.650390625\n",
      "The representation loss after processing this batch is:  5.230400711297989e-05\n",
      "The classification loss after processing this batch is:  21979.3359375\n",
      "The representation loss after processing this batch is:  5.733594298362732e-05\n",
      "The classification loss after processing this batch is:  23153.34765625\n",
      "The representation loss after processing this batch is:  5.064206197857857e-05\n",
      "The classification loss after processing this batch is:  24020.67578125\n",
      "The representation loss after processing this batch is:  6.247498095035553e-05\n",
      "The classification loss after processing this batch is:  21810.96875\n",
      "The representation loss after processing this batch is:  6.226170808076859e-05\n",
      "The classification loss after processing this batch is:  22504.2890625\n",
      "The representation loss after processing this batch is:  4.886649549007416e-05\n",
      "The classification loss after processing this batch is:  21111.0703125\n",
      "The representation loss after processing this batch is:  4.9769412726163864e-05\n",
      "The classification loss after processing this batch is:  21176.517578125\n",
      "The representation loss after processing this batch is:  5.730893462896347e-05\n",
      "The classification loss after processing this batch is:  20682.9296875\n",
      "The representation loss after processing this batch is:  5.6813471019268036e-05\n",
      "The classification loss after processing this batch is:  22007.990234375\n",
      "The representation loss after processing this batch is:  7.512606680393219e-05\n",
      "The classification loss after processing this batch is:  21593.08203125\n",
      "The representation loss after processing this batch is:  6.279535591602325e-05\n",
      "The classification loss after processing this batch is:  24039.294921875\n",
      "The representation loss after processing this batch is:  5.878787487745285e-05\n",
      "The classification loss after processing this batch is:  21748.287109375\n",
      "The representation loss after processing this batch is:  5.757622420787811e-05\n",
      "The classification loss after processing this batch is:  21999.98046875\n",
      "The representation loss after processing this batch is:  5.091400817036629e-05\n",
      "The classification loss after processing this batch is:  23319.873046875\n",
      "The representation loss after processing this batch is:  5.82253560423851e-05\n",
      "The classification loss after processing this batch is:  23007.943359375\n",
      "The representation loss after processing this batch is:  5.051726475358009e-05\n",
      "The classification loss after processing this batch is:  22351.021484375\n",
      "The representation loss after processing this batch is:  5.533173680305481e-05\n",
      "The classification loss after processing this batch is:  23542.265625\n",
      "The representation loss after processing this batch is:  6.023421883583069e-05\n",
      "The classification loss after processing this batch is:  21928.072265625\n",
      "The representation loss after processing this batch is:  5.7441648095846176e-05\n",
      "The classification loss after processing this batch is:  22522.787109375\n",
      "The representation loss after processing this batch is:  6.47837296128273e-05\n",
      "The classification loss after processing this batch is:  21080.583984375\n",
      "The representation loss after processing this batch is:  5.42420893907547e-05\n",
      "The classification loss after processing this batch is:  21015.01171875\n",
      "The representation loss after processing this batch is:  5.6249089539051056e-05\n",
      "The classification loss after processing this batch is:  21437.177734375\n",
      "The representation loss after processing this batch is:  5.7670287787914276e-05\n",
      "The classification loss after processing this batch is:  21304.42578125\n",
      "The representation loss after processing this batch is:  6.211362779140472e-05\n",
      "The classification loss after processing this batch is:  21317.736328125\n",
      "The representation loss after processing this batch is:  6.17029145359993e-05\n",
      "The classification loss after processing this batch is:  23920.3359375\n",
      "The representation loss after processing this batch is:  6.853509694337845e-05\n",
      "The classification loss after processing this batch is:  21109.509765625\n",
      "The representation loss after processing this batch is:  5.721859633922577e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21419.6796875\n",
      "The representation loss after processing this batch is:  5.1664188504219055e-05\n",
      "The classification loss after processing this batch is:  22031.2421875\n",
      "The representation loss after processing this batch is:  5.2002258598804474e-05\n",
      "The classification loss after processing this batch is:  21502.9921875\n",
      "The representation loss after processing this batch is:  5.293358117341995e-05\n",
      "The classification loss after processing this batch is:  22338.12109375\n",
      "The representation loss after processing this batch is:  5.479436367750168e-05\n",
      "The classification loss after processing this batch is:  22275.81640625\n",
      "The representation loss after processing this batch is:  5.585514008998871e-05\n",
      "The classification loss after processing this batch is:  21955.125\n",
      "The representation loss after processing this batch is:  7.51931220293045e-05\n",
      "The classification loss after processing this batch is:  20678.876953125\n",
      "The representation loss after processing this batch is:  5.203206092119217e-05\n",
      "The classification loss after processing this batch is:  22302.30078125\n",
      "The representation loss after processing this batch is:  5.534850060939789e-05\n",
      "The classification loss after processing this batch is:  24973.236328125\n",
      "The representation loss after processing this batch is:  5.856342613697052e-05\n",
      "The classification loss after processing this batch is:  25573.33203125\n",
      "The representation loss after processing this batch is:  6.653834134340286e-05\n",
      "The classification loss after processing this batch is:  22102.775390625\n",
      "The representation loss after processing this batch is:  5.114451050758362e-05\n",
      "The classification loss after processing this batch is:  22170.201171875\n",
      "The representation loss after processing this batch is:  5.205301567912102e-05\n",
      "The classification loss after processing this batch is:  21743.98828125\n",
      "The representation loss after processing this batch is:  5.238223820924759e-05\n",
      "The classification loss after processing this batch is:  22515.623046875\n",
      "The representation loss after processing this batch is:  5.787797272205353e-05\n",
      "The classification loss after processing this batch is:  21568.09375\n",
      "The representation loss after processing this batch is:  5.4790638387203217e-05\n",
      "The classification loss after processing this batch is:  22082.435546875\n",
      "The representation loss after processing this batch is:  5.016103386878967e-05\n",
      "The classification loss after processing this batch is:  23560.421875\n",
      "The representation loss after processing this batch is:  5.571544170379639e-05\n",
      "The classification loss after processing this batch is:  20833.921875\n",
      "The representation loss after processing this batch is:  5.426816642284393e-05\n",
      "The classification loss after processing this batch is:  21258.564453125\n",
      "The representation loss after processing this batch is:  5.694665014743805e-05\n",
      "The classification loss after processing this batch is:  23296.09765625\n",
      "The representation loss after processing this batch is:  7.038749754428864e-05\n",
      "The classification loss after processing this batch is:  21941.349609375\n",
      "The representation loss after processing this batch is:  6.017368286848068e-05\n",
      "The classification loss after processing this batch is:  21465.65625\n",
      "The representation loss after processing this batch is:  6.338488310575485e-05\n",
      "The classification loss after processing this batch is:  20503.87109375\n",
      "The representation loss after processing this batch is:  5.7919882237911224e-05\n",
      "The classification loss after processing this batch is:  23326.619140625\n",
      "The representation loss after processing this batch is:  6.278790533542633e-05\n",
      "The classification loss after processing this batch is:  22664.3203125\n",
      "The representation loss after processing this batch is:  6.722286343574524e-05\n",
      "The classification loss after processing this batch is:  27086.47265625\n",
      "The representation loss after processing this batch is:  6.257090717554092e-05\n",
      "The classification loss after processing this batch is:  23122.578125\n",
      "The representation loss after processing this batch is:  5.418434739112854e-05\n",
      "The classification loss after processing this batch is:  21755.38671875\n",
      "The representation loss after processing this batch is:  5.4881907999515533e-05\n",
      "The classification loss after processing this batch is:  22935.6640625\n",
      "The representation loss after processing this batch is:  5.114777013659477e-05\n",
      "The classification loss after processing this batch is:  23928.578125\n",
      "The representation loss after processing this batch is:  5.532940849661827e-05\n",
      "The classification loss after processing this batch is:  23071.80078125\n",
      "The representation loss after processing this batch is:  5.872175097465515e-05\n",
      "The classification loss after processing this batch is:  22299.982421875\n",
      "The representation loss after processing this batch is:  5.15766441822052e-05\n",
      "The classification loss after processing this batch is:  22373.6953125\n",
      "The representation loss after processing this batch is:  5.497876554727554e-05\n",
      "The classification loss after processing this batch is:  22251.953125\n",
      "The representation loss after processing this batch is:  5.19617460668087e-05\n",
      "The classification loss after processing this batch is:  21239.4453125\n",
      "The representation loss after processing this batch is:  5.989428609609604e-05\n",
      "The classification loss after processing this batch is:  22345.974609375\n",
      "The representation loss after processing this batch is:  5.502626299858093e-05\n",
      "The classification loss after processing this batch is:  21993.73046875\n",
      "The representation loss after processing this batch is:  5.7260505855083466e-05\n",
      "The classification loss after processing this batch is:  22584.486328125\n",
      "The representation loss after processing this batch is:  5.8234669268131256e-05\n",
      "The classification loss after processing this batch is:  22542.4609375\n",
      "The representation loss after processing this batch is:  5.7608820497989655e-05\n",
      "The classification loss after processing this batch is:  22706.560546875\n",
      "The representation loss after processing this batch is:  5.9351325035095215e-05\n",
      "The classification loss after processing this batch is:  21338.6328125\n",
      "The representation loss after processing this batch is:  5.333544686436653e-05\n",
      "The classification loss after processing this batch is:  20808.044921875\n",
      "The representation loss after processing this batch is:  6.033293902873993e-05\n",
      "The classification loss after processing this batch is:  21389.591796875\n",
      "The representation loss after processing this batch is:  5.303137004375458e-05\n",
      "The classification loss after processing this batch is:  21106.76171875\n",
      "The representation loss after processing this batch is:  5.259271711111069e-05\n",
      "The classification loss after processing this batch is:  22449.140625\n",
      "The representation loss after processing this batch is:  5.569681525230408e-05\n",
      "The classification loss after processing this batch is:  22183.392578125\n",
      "The representation loss after processing this batch is:  5.4103322327136993e-05\n",
      "The classification loss after processing this batch is:  21480.15234375\n",
      "The representation loss after processing this batch is:  5.828961730003357e-05\n",
      "The classification loss after processing this batch is:  20388.81640625\n",
      "The representation loss after processing this batch is:  5.7267025113105774e-05\n",
      "The classification loss after processing this batch is:  20450.91015625\n",
      "The representation loss after processing this batch is:  5.458854138851166e-05\n",
      "The classification loss after processing this batch is:  22168.33203125\n",
      "The representation loss after processing this batch is:  5.538947880268097e-05\n",
      "The classification loss after processing this batch is:  22837.70703125\n",
      "The representation loss after processing this batch is:  5.622208118438721e-05\n",
      "The classification loss after processing this batch is:  23117.259765625\n",
      "The representation loss after processing this batch is:  7.518567144870758e-05\n",
      "The classification loss after processing this batch is:  21046.46484375\n",
      "The representation loss after processing this batch is:  5.2842311561107635e-05\n",
      "The classification loss after processing this batch is:  22189.763671875\n",
      "The representation loss after processing this batch is:  5.7394616305828094e-05\n",
      "The classification loss after processing this batch is:  21403.076171875\n",
      "The representation loss after processing this batch is:  6.043538451194763e-05\n",
      "The classification loss after processing this batch is:  21868.64453125\n",
      "The representation loss after processing this batch is:  6.385147571563721e-05\n",
      "The classification loss after processing this batch is:  21195.5234375\n",
      "The representation loss after processing this batch is:  5.6121498346328735e-05\n",
      "The classification loss after processing this batch is:  20750.080078125\n",
      "The representation loss after processing this batch is:  5.401391535997391e-05\n",
      "The classification loss after processing this batch is:  20568.6328125\n",
      "The representation loss after processing this batch is:  5.283486098051071e-05\n",
      "The classification loss after processing this batch is:  21591.55859375\n",
      "The representation loss after processing this batch is:  5.689077079296112e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21751.353515625\n",
      "The representation loss after processing this batch is:  6.423518061637878e-05\n",
      "The classification loss after processing this batch is:  22032.306640625\n",
      "The representation loss after processing this batch is:  5.3748488426208496e-05\n",
      "The classification loss after processing this batch is:  21761.611328125\n",
      "The representation loss after processing this batch is:  5.739089101552963e-05\n",
      "The classification loss after processing this batch is:  21190.880859375\n",
      "The representation loss after processing this batch is:  5.255267024040222e-05\n",
      "The classification loss after processing this batch is:  22883.3671875\n",
      "The representation loss after processing this batch is:  5.642976611852646e-05\n",
      "The classification loss after processing this batch is:  24101.6640625\n",
      "The representation loss after processing this batch is:  5.806516855955124e-05\n",
      "The classification loss after processing this batch is:  23222.314453125\n",
      "The representation loss after processing this batch is:  5.9577636420726776e-05\n",
      "The classification loss after processing this batch is:  23095.119140625\n",
      "The representation loss after processing this batch is:  6.112083792686462e-05\n",
      "The classification loss after processing this batch is:  21423.99609375\n",
      "The representation loss after processing this batch is:  5.555246025323868e-05\n",
      "The classification loss after processing this batch is:  21688.34765625\n",
      "The representation loss after processing this batch is:  5.1575712859630585e-05\n",
      "The classification loss after processing this batch is:  22838.3671875\n",
      "The representation loss after processing this batch is:  6.634090095758438e-05\n",
      "The classification loss after processing this batch is:  21252.228515625\n",
      "The representation loss after processing this batch is:  6.403587758541107e-05\n",
      "The classification loss after processing this batch is:  21322.0625\n",
      "The representation loss after processing this batch is:  5.767121911048889e-05\n",
      "The classification loss after processing this batch is:  22195.951171875\n",
      "The representation loss after processing this batch is:  5.041668191552162e-05\n",
      "The classification loss after processing this batch is:  22057.59765625\n",
      "The representation loss after processing this batch is:  5.392450839281082e-05\n",
      "The classification loss after processing this batch is:  21810.76953125\n",
      "The representation loss after processing this batch is:  5.212845280766487e-05\n",
      "The classification loss after processing this batch is:  21496.23828125\n",
      "The representation loss after processing this batch is:  5.2422285079956055e-05\n",
      "The classification loss after processing this batch is:  22867.771484375\n",
      "The representation loss after processing this batch is:  6.019230931997299e-05\n",
      "The classification loss after processing this batch is:  22793.537109375\n",
      "The representation loss after processing this batch is:  5.944725126028061e-05\n",
      "The classification loss after processing this batch is:  23190.572265625\n",
      "The representation loss after processing this batch is:  5.054892972111702e-05\n",
      "The classification loss after processing this batch is:  23534.79296875\n",
      "The representation loss after processing this batch is:  6.098533049225807e-05\n",
      "The classification loss after processing this batch is:  22473.37109375\n",
      "The representation loss after processing this batch is:  4.9884431064128876e-05\n",
      "The classification loss after processing this batch is:  21555.671875\n",
      "The representation loss after processing this batch is:  5.85382804274559e-05\n",
      "The classification loss after processing this batch is:  21143.517578125\n",
      "The representation loss after processing this batch is:  5.767308175563812e-05\n",
      "The classification loss after processing this batch is:  21205.43359375\n",
      "The representation loss after processing this batch is:  5.099782720208168e-05\n",
      "The classification loss after processing this batch is:  21821.796875\n",
      "The representation loss after processing this batch is:  5.450518801808357e-05\n",
      "The classification loss after processing this batch is:  21250.068359375\n",
      "The representation loss after processing this batch is:  5.228910595178604e-05\n",
      "The classification loss after processing this batch is:  21982.46484375\n",
      "The representation loss after processing this batch is:  5.5262353271245956e-05\n",
      "The classification loss after processing this batch is:  21674.611328125\n",
      "The representation loss after processing this batch is:  5.451124161481857e-05\n",
      "The classification loss after processing this batch is:  24581.36328125\n",
      "The representation loss after processing this batch is:  6.399396806955338e-05\n",
      "The classification loss after processing this batch is:  23837.43359375\n",
      "The representation loss after processing this batch is:  5.656760185956955e-05\n",
      "The classification loss after processing this batch is:  21788.505859375\n",
      "The representation loss after processing this batch is:  4.8522837460041046e-05\n",
      "The classification loss after processing this batch is:  20836.69921875\n",
      "The representation loss after processing this batch is:  5.736667662858963e-05\n",
      "The classification loss after processing this batch is:  21012.609375\n",
      "The representation loss after processing this batch is:  5.5468641221523285e-05\n",
      "The classification loss after processing this batch is:  22073.65625\n",
      "The representation loss after processing this batch is:  6.21723011136055e-05\n",
      "The classification loss after processing this batch is:  21673.111328125\n",
      "The representation loss after processing this batch is:  5.899183452129364e-05\n",
      "The classification loss after processing this batch is:  22291.0390625\n",
      "The representation loss after processing this batch is:  5.554314702749252e-05\n",
      "The classification loss after processing this batch is:  21553.765625\n",
      "The representation loss after processing this batch is:  5.241669714450836e-05\n",
      "The classification loss after processing this batch is:  21066.1328125\n",
      "The representation loss after processing this batch is:  5.231145769357681e-05\n",
      "The classification loss after processing this batch is:  20812.390625\n",
      "The representation loss after processing this batch is:  5.4467469453811646e-05\n",
      "The classification loss after processing this batch is:  22473.517578125\n",
      "The representation loss after processing this batch is:  5.335081368684769e-05\n",
      "The classification loss after processing this batch is:  23404.12890625\n",
      "The representation loss after processing this batch is:  6.142072379589081e-05\n",
      "The classification loss after processing this batch is:  21714.8046875\n",
      "The representation loss after processing this batch is:  6.0039572417736053e-05\n",
      "The classification loss after processing this batch is:  22285.638671875\n",
      "The representation loss after processing this batch is:  5.28399832546711e-05\n",
      "The classification loss after processing this batch is:  23596.29296875\n",
      "The representation loss after processing this batch is:  5.988217890262604e-05\n",
      "The classification loss after processing this batch is:  22581.9296875\n",
      "The representation loss after processing this batch is:  5.1112379878759384e-05\n",
      "The classification loss after processing this batch is:  24027.58984375\n",
      "The representation loss after processing this batch is:  4.908256232738495e-05\n",
      "The classification loss after processing this batch is:  21669.330078125\n",
      "The representation loss after processing this batch is:  5.823839455842972e-05\n",
      "The classification loss after processing this batch is:  22707.966796875\n",
      "The representation loss after processing this batch is:  7.230695337057114e-05\n",
      "The classification loss after processing this batch is:  21605.99609375\n",
      "The representation loss after processing this batch is:  5.679391324520111e-05\n",
      "The classification loss after processing this batch is:  22346.3671875\n",
      "The representation loss after processing this batch is:  5.516316741704941e-05\n",
      "The classification loss after processing this batch is:  21848.091796875\n",
      "The representation loss after processing this batch is:  5.695037543773651e-05\n",
      "The classification loss after processing this batch is:  21816.06640625\n",
      "The representation loss after processing this batch is:  5.4786913096904755e-05\n",
      "The classification loss after processing this batch is:  22427.67578125\n",
      "The representation loss after processing this batch is:  4.89773228764534e-05\n",
      "The classification loss after processing this batch is:  21335.38671875\n",
      "The representation loss after processing this batch is:  5.879160016775131e-05\n",
      "The classification loss after processing this batch is:  21639.81640625\n",
      "The representation loss after processing this batch is:  5.724932998418808e-05\n",
      "The classification loss after processing this batch is:  20785.953125\n",
      "The representation loss after processing this batch is:  5.395524203777313e-05\n",
      "The classification loss after processing this batch is:  21054.19140625\n",
      "The representation loss after processing this batch is:  6.685778498649597e-05\n",
      "The classification loss after processing this batch is:  20799.484375\n",
      "The representation loss after processing this batch is:  5.29605895280838e-05\n",
      "The classification loss after processing this batch is:  22553.669921875\n",
      "The representation loss after processing this batch is:  5.73229044675827e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21607.603515625\n",
      "The representation loss after processing this batch is:  6.053317338228226e-05\n",
      "The classification loss after processing this batch is:  22219.158203125\n",
      "The representation loss after processing this batch is:  5.5788084864616394e-05\n",
      "The classification loss after processing this batch is:  22583.74609375\n",
      "The representation loss after processing this batch is:  5.335034802556038e-05\n",
      "The classification loss after processing this batch is:  21293.60546875\n",
      "The representation loss after processing this batch is:  5.297921597957611e-05\n",
      "The classification loss after processing this batch is:  22280.0703125\n",
      "The representation loss after processing this batch is:  5.024205893278122e-05\n",
      "The classification loss after processing this batch is:  21942.517578125\n",
      "The representation loss after processing this batch is:  5.8348290622234344e-05\n",
      "The classification loss after processing this batch is:  21078.5234375\n",
      "The representation loss after processing this batch is:  5.194172263145447e-05\n",
      "The classification loss after processing this batch is:  22096.494140625\n",
      "The representation loss after processing this batch is:  5.4895877838134766e-05\n",
      "The classification loss after processing this batch is:  21776.21875\n",
      "The representation loss after processing this batch is:  5.158223211765289e-05\n",
      "The classification loss after processing this batch is:  21312.9921875\n",
      "The representation loss after processing this batch is:  4.993472248315811e-05\n",
      "The classification loss after processing this batch is:  22011.9453125\n",
      "The representation loss after processing this batch is:  5.490705370903015e-05\n",
      "The classification loss after processing this batch is:  21470.9609375\n",
      "The representation loss after processing this batch is:  5.88810071349144e-05\n",
      "The classification loss after processing this batch is:  22390.32421875\n",
      "The representation loss after processing this batch is:  6.145425140857697e-05\n",
      "The classification loss after processing this batch is:  23201.93359375\n",
      "The representation loss after processing this batch is:  5.221506580710411e-05\n",
      "The classification loss after processing this batch is:  21771.93359375\n",
      "The representation loss after processing this batch is:  5.997437983751297e-05\n",
      "The classification loss after processing this batch is:  24170.140625\n",
      "The representation loss after processing this batch is:  5.3423922508955e-05\n",
      "The classification loss after processing this batch is:  24277.640625\n",
      "The representation loss after processing this batch is:  5.856901407241821e-05\n",
      "The classification loss after processing this batch is:  21483.296875\n",
      "The representation loss after processing this batch is:  5.773920565843582e-05\n",
      "The classification loss after processing this batch is:  22162.03125\n",
      "The representation loss after processing this batch is:  5.2630435675382614e-05\n",
      "The classification loss after processing this batch is:  23305.138671875\n",
      "The representation loss after processing this batch is:  6.191246211528778e-05\n",
      "The classification loss after processing this batch is:  21854.46875\n",
      "The representation loss after processing this batch is:  5.507469177246094e-05\n",
      "The classification loss after processing this batch is:  21880.939453125\n",
      "The representation loss after processing this batch is:  5.8980658650398254e-05\n",
      "The classification loss after processing this batch is:  21679.51171875\n",
      "The representation loss after processing this batch is:  5.048327147960663e-05\n",
      "The classification loss after processing this batch is:  21966.046875\n",
      "The representation loss after processing this batch is:  5.311146378517151e-05\n",
      "The classification loss after processing this batch is:  22788.658203125\n",
      "The representation loss after processing this batch is:  5.578901618719101e-05\n",
      "The classification loss after processing this batch is:  22613.06640625\n",
      "The representation loss after processing this batch is:  5.213730037212372e-05\n",
      "The classification loss after processing this batch is:  24456.3515625\n",
      "The representation loss after processing this batch is:  6.630364805459976e-05\n",
      "The classification loss after processing this batch is:  23034.216796875\n",
      "The representation loss after processing this batch is:  5.575129762291908e-05\n",
      "The classification loss after processing this batch is:  22611.3203125\n",
      "The representation loss after processing this batch is:  4.793703556060791e-05\n",
      "The classification loss after processing this batch is:  21060.1484375\n",
      "The representation loss after processing this batch is:  5.148584023118019e-05\n",
      "The classification loss after processing this batch is:  21395.134765625\n",
      "The representation loss after processing this batch is:  5.121156573295593e-05\n",
      "The classification loss after processing this batch is:  22490.59375\n",
      "The representation loss after processing this batch is:  5.363300442695618e-05\n",
      "The classification loss after processing this batch is:  21322.43359375\n",
      "The representation loss after processing this batch is:  4.94346022605896e-05\n",
      "The classification loss after processing this batch is:  20292.17578125\n",
      "The representation loss after processing this batch is:  5.8346427977085114e-05\n",
      "The classification loss after processing this batch is:  23038.359375\n",
      "The representation loss after processing this batch is:  4.981504753232002e-05\n",
      "The classification loss after processing this batch is:  21095.50390625\n",
      "The representation loss after processing this batch is:  5.2084214985370636e-05\n",
      "The classification loss after processing this batch is:  21286.19140625\n",
      "The representation loss after processing this batch is:  5.2626244723796844e-05\n",
      "The classification loss after processing this batch is:  20476.11328125\n",
      "The representation loss after processing this batch is:  5.5660493671894073e-05\n",
      "The classification loss after processing this batch is:  21178.830078125\n",
      "The representation loss after processing this batch is:  5.48679381608963e-05\n",
      "The classification loss after processing this batch is:  20661.908203125\n",
      "The representation loss after processing this batch is:  4.8547983169555664e-05\n",
      "The classification loss after processing this batch is:  21889.70703125\n",
      "The representation loss after processing this batch is:  4.9285124987363815e-05\n",
      "The classification loss after processing this batch is:  21521.06640625\n",
      "The representation loss after processing this batch is:  4.930002614855766e-05\n",
      "The classification loss after processing this batch is:  21062.453125\n",
      "The representation loss after processing this batch is:  5.6127551943063736e-05\n",
      "The classification loss after processing this batch is:  22362.5546875\n",
      "The representation loss after processing this batch is:  5.333404988050461e-05\n",
      "The classification loss after processing this batch is:  22799.146484375\n",
      "The representation loss after processing this batch is:  5.2473507821559906e-05\n",
      "The classification loss after processing this batch is:  20825.451171875\n",
      "The representation loss after processing this batch is:  5.674269050359726e-05\n",
      "The classification loss after processing this batch is:  21179.580078125\n",
      "The representation loss after processing this batch is:  5.2908435463905334e-05\n",
      "The classification loss after processing this batch is:  21459.14453125\n",
      "The representation loss after processing this batch is:  5.11612743139267e-05\n",
      "The classification loss after processing this batch is:  21309.41796875\n",
      "The representation loss after processing this batch is:  5.435943603515625e-05\n",
      "The classification loss after processing this batch is:  22457.44921875\n",
      "The representation loss after processing this batch is:  5.627050995826721e-05\n",
      "The classification loss after processing this batch is:  21191.640625\n",
      "The representation loss after processing this batch is:  4.9542635679244995e-05\n",
      "The classification loss after processing this batch is:  20563.560546875\n",
      "The representation loss after processing this batch is:  5.3748488426208496e-05\n",
      "The classification loss after processing this batch is:  21696.3515625\n",
      "The representation loss after processing this batch is:  5.579553544521332e-05\n",
      "The classification loss after processing this batch is:  23730.9453125\n",
      "The representation loss after processing this batch is:  6.144586950540543e-05\n",
      "The classification loss after processing this batch is:  21117.59765625\n",
      "The representation loss after processing this batch is:  4.773354157805443e-05\n",
      "The classification loss after processing this batch is:  22008.509765625\n",
      "The representation loss after processing this batch is:  5.3573865443468094e-05\n",
      "The classification loss after processing this batch is:  23803.12109375\n",
      "The representation loss after processing this batch is:  4.9783848226070404e-05\n",
      "The classification loss after processing this batch is:  21620.294921875\n",
      "The representation loss after processing this batch is:  5.566887557506561e-05\n",
      "The classification loss after processing this batch is:  20740.443359375\n",
      "The representation loss after processing this batch is:  5.109934136271477e-05\n",
      "The classification loss after processing this batch is:  21195.7734375\n",
      "The representation loss after processing this batch is:  5.451217293739319e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21011.416015625\n",
      "The representation loss after processing this batch is:  5.103647708892822e-05\n",
      "The classification loss after processing this batch is:  21599.796875\n",
      "The representation loss after processing this batch is:  5.5719632655382156e-05\n",
      "The classification loss after processing this batch is:  20910.92578125\n",
      "The representation loss after processing this batch is:  5.5652111768722534e-05\n",
      "The classification loss after processing this batch is:  21605.98828125\n",
      "The representation loss after processing this batch is:  5.2012503147125244e-05\n",
      "The classification loss after processing this batch is:  24461.64453125\n",
      "The representation loss after processing this batch is:  5.7865865528583527e-05\n",
      "The classification loss after processing this batch is:  22868.47265625\n",
      "The representation loss after processing this batch is:  4.9915630370378494e-05\n",
      "The classification loss after processing this batch is:  22127.2578125\n",
      "The representation loss after processing this batch is:  4.955194890499115e-05\n",
      "The classification loss after processing this batch is:  21178.39453125\n",
      "The representation loss after processing this batch is:  5.158223211765289e-05\n",
      "The classification loss after processing this batch is:  21724.58984375\n",
      "The representation loss after processing this batch is:  6.040837615728378e-05\n",
      "The classification loss after processing this batch is:  21753.28125\n",
      "The representation loss after processing this batch is:  6.096530705690384e-05\n",
      "The classification loss after processing this batch is:  21085.55859375\n",
      "The representation loss after processing this batch is:  5.2279792726039886e-05\n",
      "The classification loss after processing this batch is:  20544.064453125\n",
      "The representation loss after processing this batch is:  5.6646764278411865e-05\n",
      "The classification loss after processing this batch is:  21192.267578125\n",
      "The representation loss after processing this batch is:  5.285535007715225e-05\n",
      "The classification loss after processing this batch is:  21143.693359375\n",
      "The representation loss after processing this batch is:  5.09447418153286e-05\n",
      "The classification loss after processing this batch is:  20497.826171875\n",
      "The representation loss after processing this batch is:  5.0743576139211655e-05\n",
      "The classification loss after processing this batch is:  21481.6640625\n",
      "The representation loss after processing this batch is:  5.279434844851494e-05\n",
      "The classification loss after processing this batch is:  20517.99609375\n",
      "The representation loss after processing this batch is:  5.381926894187927e-05\n",
      "The classification loss after processing this batch is:  22786.662109375\n",
      "The representation loss after processing this batch is:  5.59929758310318e-05\n",
      "The classification loss after processing this batch is:  22582.873046875\n",
      "The representation loss after processing this batch is:  5.0716567784547806e-05\n",
      "The classification loss after processing this batch is:  21447.45703125\n",
      "The representation loss after processing this batch is:  4.870304837822914e-05\n",
      "The classification loss after processing this batch is:  21313.419921875\n",
      "The representation loss after processing this batch is:  5.4350122809410095e-05\n",
      "The classification loss after processing this batch is:  21113.11328125\n",
      "The representation loss after processing this batch is:  5.372893065214157e-05\n",
      "The classification loss after processing this batch is:  22645.50390625\n",
      "The representation loss after processing this batch is:  5.5711716413497925e-05\n",
      "The classification loss after processing this batch is:  22089.09375\n",
      "The representation loss after processing this batch is:  5.368608981370926e-05\n",
      "The classification loss after processing this batch is:  21374.482421875\n",
      "The representation loss after processing this batch is:  5.1293522119522095e-05\n",
      "The classification loss after processing this batch is:  21788.9375\n",
      "The representation loss after processing this batch is:  4.7058332711458206e-05\n",
      "The classification loss after processing this batch is:  23512.4296875\n",
      "The representation loss after processing this batch is:  6.43385574221611e-05\n",
      "The classification loss after processing this batch is:  21045.08984375\n",
      "The representation loss after processing this batch is:  5.426211282610893e-05\n",
      "The classification loss after processing this batch is:  22008.69921875\n",
      "The representation loss after processing this batch is:  5.3445808589458466e-05\n",
      "The classification loss after processing this batch is:  22100.58984375\n",
      "The representation loss after processing this batch is:  5.878601223230362e-05\n",
      "The classification loss after processing this batch is:  21680.1640625\n",
      "The representation loss after processing this batch is:  5.164416506886482e-05\n",
      "The classification loss after processing this batch is:  22259.64453125\n",
      "The representation loss after processing this batch is:  6.128521636128426e-05\n",
      "The classification loss after processing this batch is:  22985.83203125\n",
      "The representation loss after processing this batch is:  5.94044104218483e-05\n",
      "The classification loss after processing this batch is:  21531.0703125\n",
      "The representation loss after processing this batch is:  5.9232115745544434e-05\n",
      "The classification loss after processing this batch is:  22353.84375\n",
      "The representation loss after processing this batch is:  4.992028698325157e-05\n",
      "The classification loss after processing this batch is:  22694.3125\n",
      "The representation loss after processing this batch is:  4.7528184950351715e-05\n",
      "The classification loss after processing this batch is:  21370.4375\n",
      "The representation loss after processing this batch is:  5.7569704949855804e-05\n",
      "The classification loss after processing this batch is:  22522.259765625\n",
      "The representation loss after processing this batch is:  5.027838051319122e-05\n",
      "The classification loss after processing this batch is:  22165.052734375\n",
      "The representation loss after processing this batch is:  5.479156970977783e-05\n",
      "The classification loss after processing this batch is:  21161.40234375\n",
      "The representation loss after processing this batch is:  5.644839257001877e-05\n",
      "The classification loss after processing this batch is:  21378.443359375\n",
      "The representation loss after processing this batch is:  5.797576159238815e-05\n",
      "The classification loss after processing this batch is:  21225.890625\n",
      "The representation loss after processing this batch is:  5.4284464567899704e-05\n",
      "The classification loss after processing this batch is:  20999.9765625\n",
      "The representation loss after processing this batch is:  5.487864837050438e-05\n",
      "The classification loss after processing this batch is:  22970.1015625\n",
      "The representation loss after processing this batch is:  5.745701491832733e-05\n",
      "The classification loss after processing this batch is:  22363.171875\n",
      "The representation loss after processing this batch is:  5.027884617447853e-05\n",
      "The classification loss after processing this batch is:  23343.130859375\n",
      "The representation loss after processing this batch is:  5.374103784561157e-05\n",
      "The classification loss after processing this batch is:  20524.71875\n",
      "The representation loss after processing this batch is:  5.491822957992554e-05\n",
      "The classification loss after processing this batch is:  20916.255859375\n",
      "The representation loss after processing this batch is:  6.390176713466644e-05\n",
      "The classification loss after processing this batch is:  21330.7265625\n",
      "The representation loss after processing this batch is:  5.253497511148453e-05\n",
      "The classification loss after processing this batch is:  21028.775390625\n",
      "The representation loss after processing this batch is:  5.4492615163326263e-05\n",
      "The classification loss after processing this batch is:  22295.78125\n",
      "The representation loss after processing this batch is:  5.717761814594269e-05\n",
      "The classification loss after processing this batch is:  21278.625\n",
      "The representation loss after processing this batch is:  5.011493340134621e-05\n",
      "The classification loss after processing this batch is:  21709.12890625\n",
      "The representation loss after processing this batch is:  5.308911204338074e-05\n",
      "The classification loss after processing this batch is:  21891.78125\n",
      "The representation loss after processing this batch is:  5.3981319069862366e-05\n",
      "The classification loss after processing this batch is:  21034.18359375\n",
      "The representation loss after processing this batch is:  5.246791988611221e-05\n",
      "The classification loss after processing this batch is:  23170.39453125\n",
      "The representation loss after processing this batch is:  5.883164703845978e-05\n",
      "The classification loss after processing this batch is:  23239.197265625\n",
      "The representation loss after processing this batch is:  5.299318581819534e-05\n",
      "The classification loss after processing this batch is:  22416.189453125\n",
      "The representation loss after processing this batch is:  5.591614171862602e-05\n",
      "The classification loss after processing this batch is:  20731.486328125\n",
      "The representation loss after processing this batch is:  5.4076313972473145e-05\n",
      "The classification loss after processing this batch is:  22957.8125\n",
      "The representation loss after processing this batch is:  5.227932706475258e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22550.0234375\n",
      "The representation loss after processing this batch is:  4.9116089940071106e-05\n",
      "The classification loss after processing this batch is:  21121.640625\n",
      "The representation loss after processing this batch is:  4.824204370379448e-05\n",
      "The classification loss after processing this batch is:  23565.9609375\n",
      "The representation loss after processing this batch is:  5.86044043302536e-05\n",
      "The classification loss after processing this batch is:  23306.13671875\n",
      "The representation loss after processing this batch is:  6.269384175539017e-05\n",
      "The classification loss after processing this batch is:  20916.236328125\n",
      "The representation loss after processing this batch is:  5.081808194518089e-05\n",
      "The classification loss after processing this batch is:  21465.24609375\n",
      "The representation loss after processing this batch is:  5.3155235946178436e-05\n",
      "The classification loss after processing this batch is:  22067.671875\n",
      "The representation loss after processing this batch is:  4.90313395857811e-05\n",
      "The classification loss after processing this batch is:  21706.18359375\n",
      "The representation loss after processing this batch is:  5.5110082030296326e-05\n",
      "The classification loss after processing this batch is:  22477.583984375\n",
      "The representation loss after processing this batch is:  6.821192800998688e-05\n",
      "The classification loss after processing this batch is:  23188.986328125\n",
      "The representation loss after processing this batch is:  5.363393574953079e-05\n",
      "The classification loss after processing this batch is:  21028.3046875\n",
      "The representation loss after processing this batch is:  5.372334271669388e-05\n",
      "The classification loss after processing this batch is:  20505.302734375\n",
      "The representation loss after processing this batch is:  5.4350122809410095e-05\n",
      "The classification loss after processing this batch is:  21897.369140625\n",
      "The representation loss after processing this batch is:  4.705553874373436e-05\n",
      "The classification loss after processing this batch is:  22988.6015625\n",
      "The representation loss after processing this batch is:  5.94286248087883e-05\n",
      "The classification loss after processing this batch is:  21587.791015625\n",
      "The representation loss after processing this batch is:  5.612242966890335e-05\n",
      "The classification loss after processing this batch is:  22281.263671875\n",
      "The representation loss after processing this batch is:  6.100162863731384e-05\n",
      "The classification loss after processing this batch is:  21753.34375\n",
      "The representation loss after processing this batch is:  5.08185476064682e-05\n",
      "The classification loss after processing this batch is:  21979.986328125\n",
      "The representation loss after processing this batch is:  5.40195032954216e-05\n",
      "The classification loss after processing this batch is:  21363.49609375\n",
      "The representation loss after processing this batch is:  6.196321919560432e-05\n",
      "The classification loss after processing this batch is:  21766.89453125\n",
      "The representation loss after processing this batch is:  5.286466330289841e-05\n",
      "The classification loss after processing this batch is:  23061.876953125\n",
      "The representation loss after processing this batch is:  5.553197115659714e-05\n",
      "The classification loss after processing this batch is:  20675.0859375\n",
      "The representation loss after processing this batch is:  5.408609285950661e-05\n",
      "The classification loss after processing this batch is:  20632.296875\n",
      "The representation loss after processing this batch is:  5.4191797971725464e-05\n",
      "The classification loss after processing this batch is:  20379.986328125\n",
      "The representation loss after processing this batch is:  5.334150046110153e-05\n",
      "The classification loss after processing this batch is:  20599.00390625\n",
      "The representation loss after processing this batch is:  5.274452269077301e-05\n",
      "The classification loss after processing this batch is:  21114.439453125\n",
      "The representation loss after processing this batch is:  5.633290857076645e-05\n",
      "The classification loss after processing this batch is:  22152.17578125\n",
      "The representation loss after processing this batch is:  5.091354250907898e-05\n",
      "The classification loss after processing this batch is:  22438.728515625\n",
      "The representation loss after processing this batch is:  4.965439438819885e-05\n",
      "The classification loss after processing this batch is:  20877.0625\n",
      "The representation loss after processing this batch is:  5.734153091907501e-05\n",
      "The classification loss after processing this batch is:  20571.77734375\n",
      "The representation loss after processing this batch is:  5.462346598505974e-05\n",
      "The classification loss after processing this batch is:  20739.93359375\n",
      "The representation loss after processing this batch is:  4.769209772348404e-05\n",
      "The classification loss after processing this batch is:  21416.666015625\n",
      "The representation loss after processing this batch is:  5.579087883234024e-05\n",
      "The classification loss after processing this batch is:  21429.48046875\n",
      "The representation loss after processing this batch is:  5.448702722787857e-05\n",
      "The classification loss after processing this batch is:  20557.34765625\n",
      "The representation loss after processing this batch is:  5.31952828168869e-05\n",
      "The classification loss after processing this batch is:  23155.45703125\n",
      "The representation loss after processing this batch is:  5.063693970441818e-05\n",
      "The classification loss after processing this batch is:  21235.107421875\n",
      "The representation loss after processing this batch is:  5.057407543063164e-05\n",
      "The classification loss after processing this batch is:  20890.1328125\n",
      "The representation loss after processing this batch is:  6.51627779006958e-05\n",
      "The classification loss after processing this batch is:  21327.69140625\n",
      "The representation loss after processing this batch is:  5.263276398181915e-05\n",
      "The classification loss after processing this batch is:  21930.38671875\n",
      "The representation loss after processing this batch is:  5.1089562475681305e-05\n",
      "The classification loss after processing this batch is:  21542.068359375\n",
      "The representation loss after processing this batch is:  5.191424861550331e-05\n",
      "The classification loss after processing this batch is:  20980.19140625\n",
      "The representation loss after processing this batch is:  5.507189780473709e-05\n",
      "The classification loss after processing this batch is:  21572.765625\n",
      "The representation loss after processing this batch is:  5.273008719086647e-05\n",
      "The classification loss after processing this batch is:  22957.099609375\n",
      "The representation loss after processing this batch is:  5.311518907546997e-05\n",
      "The classification loss after processing this batch is:  20333.4296875\n",
      "The representation loss after processing this batch is:  5.554314702749252e-05\n",
      "The classification loss after processing this batch is:  21064.681640625\n",
      "The representation loss after processing this batch is:  5.4142437875270844e-05\n",
      "The classification loss after processing this batch is:  19966.5703125\n",
      "The representation loss after processing this batch is:  5.769822746515274e-05\n",
      "The classification loss after processing this batch is:  21379.34375\n",
      "The representation loss after processing this batch is:  4.9700960516929626e-05\n",
      "The classification loss after processing this batch is:  21848.69140625\n",
      "The representation loss after processing this batch is:  5.045440047979355e-05\n",
      "The classification loss after processing this batch is:  21235.828125\n",
      "The representation loss after processing this batch is:  5.9925951063632965e-05\n",
      "The classification loss after processing this batch is:  20845.037109375\n",
      "The representation loss after processing this batch is:  6.285123527050018e-05\n",
      "The classification loss after processing this batch is:  20423.013671875\n",
      "The representation loss after processing this batch is:  5.0086528062820435e-05\n",
      "The classification loss after processing this batch is:  21456.76953125\n",
      "The representation loss after processing this batch is:  4.953937605023384e-05\n",
      "The classification loss after processing this batch is:  21192.658203125\n",
      "The representation loss after processing this batch is:  5.46812079846859e-05\n",
      "The classification loss after processing this batch is:  20518.001953125\n",
      "The representation loss after processing this batch is:  5.0572678446769714e-05\n",
      "The classification loss after processing this batch is:  24521.6640625\n",
      "The representation loss after processing this batch is:  6.0264021158218384e-05\n",
      "The classification loss after processing this batch is:  23109.24609375\n",
      "The representation loss after processing this batch is:  6.311573088169098e-05\n",
      "The classification loss after processing this batch is:  22116.166015625\n",
      "The representation loss after processing this batch is:  5.770847201347351e-05\n",
      "The classification loss after processing this batch is:  21429.3046875\n",
      "The representation loss after processing this batch is:  5.868542939424515e-05\n",
      "The classification loss after processing this batch is:  20803.69140625\n",
      "The representation loss after processing this batch is:  5.5363401770591736e-05\n",
      "The classification loss after processing this batch is:  21336.19921875\n",
      "The representation loss after processing this batch is:  5.364697426557541e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22142.55859375\n",
      "The representation loss after processing this batch is:  5.4669566452503204e-05\n",
      "The classification loss after processing this batch is:  21303.234375\n",
      "The representation loss after processing this batch is:  5.04152849316597e-05\n",
      "The classification loss after processing this batch is:  23514.982421875\n",
      "The representation loss after processing this batch is:  5.3948257118463516e-05\n",
      "The classification loss after processing this batch is:  21671.70703125\n",
      "The representation loss after processing this batch is:  5.299225449562073e-05\n",
      "The classification loss after processing this batch is:  20768.9296875\n",
      "The representation loss after processing this batch is:  5.590822547674179e-05\n",
      "The classification loss after processing this batch is:  22671.669921875\n",
      "The representation loss after processing this batch is:  5.673710256814957e-05\n",
      "The classification loss after processing this batch is:  20892.982421875\n",
      "The representation loss after processing this batch is:  5.54155558347702e-05\n",
      "The classification loss after processing this batch is:  21227.166015625\n",
      "The representation loss after processing this batch is:  6.115715950727463e-05\n",
      "The classification loss after processing this batch is:  25057.71875\n",
      "The representation loss after processing this batch is:  6.681680679321289e-05\n",
      "The classification loss after processing this batch is:  22408.564453125\n",
      "The representation loss after processing this batch is:  7.13123008608818e-05\n",
      "The classification loss after processing this batch is:  21233.3515625\n",
      "The representation loss after processing this batch is:  6.0947611927986145e-05\n",
      "The classification loss after processing this batch is:  21413.265625\n",
      "The representation loss after processing this batch is:  8.13780352473259e-05\n",
      "The classification loss after processing this batch is:  23378.1640625\n",
      "The representation loss after processing this batch is:  6.330106407403946e-05\n",
      "The classification loss after processing this batch is:  20583.34765625\n",
      "The representation loss after processing this batch is:  6.924476474523544e-05\n",
      "The classification loss after processing this batch is:  21624.97265625\n",
      "The representation loss after processing this batch is:  7.270742207765579e-05\n",
      "The classification loss after processing this batch is:  22470.904296875\n",
      "The representation loss after processing this batch is:  7.516145706176758e-05\n",
      "The classification loss after processing this batch is:  26550.197265625\n",
      "The representation loss after processing this batch is:  6.708875298500061e-05\n",
      "The classification loss after processing this batch is:  28646.173828125\n",
      "The representation loss after processing this batch is:  5.822163075208664e-05\n",
      "The classification loss after processing this batch is:  20909.8046875\n",
      "The representation loss after processing this batch is:  5.8438628911972046e-05\n",
      "The classification loss after processing this batch is:  22175.22265625\n",
      "The representation loss after processing this batch is:  5.705561488866806e-05\n",
      "The classification loss after processing this batch is:  22361.59375\n",
      "The representation loss after processing this batch is:  6.621610373258591e-05\n",
      "The classification loss after processing this batch is:  20466.77734375\n",
      "The representation loss after processing this batch is:  5.3134746849536896e-05\n",
      "The classification loss after processing this batch is:  21892.1953125\n",
      "The representation loss after processing this batch is:  4.13721427321434e-05\n",
      "The classification loss after processing this batch is:  22458.76953125\n",
      "The representation loss after processing this batch is:  4.151277244091034e-05\n",
      "The classification loss after processing this batch is:  21513.57421875\n",
      "The representation loss after processing this batch is:  4.693120718002319e-05\n",
      "The classification loss after processing this batch is:  21709.541015625\n",
      "The representation loss after processing this batch is:  4.433654248714447e-05\n",
      "The classification loss after processing this batch is:  21628.23828125\n",
      "The representation loss after processing this batch is:  4.25572507083416e-05\n",
      "The classification loss after processing this batch is:  21383.87109375\n",
      "The representation loss after processing this batch is:  4.192069172859192e-05\n",
      "The classification loss after processing this batch is:  21592.375\n",
      "The representation loss after processing this batch is:  5.3231604397296906e-05\n",
      "The classification loss after processing this batch is:  21552.25\n",
      "The representation loss after processing this batch is:  4.9863941967487335e-05\n",
      "The classification loss after processing this batch is:  21544.154296875\n",
      "The representation loss after processing this batch is:  4.956778138875961e-05\n",
      "The classification loss after processing this batch is:  24940.83203125\n",
      "The representation loss after processing this batch is:  4.693865776062012e-05\n",
      "The classification loss after processing this batch is:  24175.189453125\n",
      "The representation loss after processing this batch is:  4.162546247243881e-05\n",
      "The classification loss after processing this batch is:  21372.623046875\n",
      "The representation loss after processing this batch is:  3.785407170653343e-05\n",
      "The classification loss after processing this batch is:  21246.158203125\n",
      "The representation loss after processing this batch is:  3.9035454392433167e-05\n",
      "The classification loss after processing this batch is:  21108.166015625\n",
      "The representation loss after processing this batch is:  4.409719258546829e-05\n",
      "The classification loss after processing this batch is:  21345.14453125\n",
      "The representation loss after processing this batch is:  3.818748518824577e-05\n",
      "The classification loss after processing this batch is:  22298.87890625\n",
      "The representation loss after processing this batch is:  3.8242898881435394e-05\n",
      "The classification loss after processing this batch is:  21530.0859375\n",
      "The representation loss after processing this batch is:  3.806082531809807e-05\n",
      "The classification loss after processing this batch is:  23539.4375\n",
      "The representation loss after processing this batch is:  4.5406632125377655e-05\n",
      "The classification loss after processing this batch is:  21586.625\n",
      "The representation loss after processing this batch is:  4.248274490237236e-05\n",
      "The classification loss after processing this batch is:  21630.892578125\n",
      "The representation loss after processing this batch is:  4.416517913341522e-05\n",
      "The classification loss after processing this batch is:  21512.798828125\n",
      "The representation loss after processing this batch is:  3.772694617509842e-05\n",
      "The classification loss after processing this batch is:  21637.70703125\n",
      "The representation loss after processing this batch is:  4.0193554013967514e-05\n",
      "The classification loss after processing this batch is:  21644.64453125\n",
      "The representation loss after processing this batch is:  4.643714055418968e-05\n",
      "The classification loss after processing this batch is:  21317.177734375\n",
      "The representation loss after processing this batch is:  3.5521574318408966e-05\n",
      "The classification loss after processing this batch is:  21458.02734375\n",
      "The representation loss after processing this batch is:  3.8629863411188126e-05\n",
      "The classification loss after processing this batch is:  20506.82421875\n",
      "The representation loss after processing this batch is:  4.266155883669853e-05\n",
      "The classification loss after processing this batch is:  20894.65625\n",
      "The representation loss after processing this batch is:  3.839191049337387e-05\n",
      "The classification loss after processing this batch is:  20842.439453125\n",
      "The representation loss after processing this batch is:  3.8310885429382324e-05\n",
      "The classification loss after processing this batch is:  23085.0078125\n",
      "The representation loss after processing this batch is:  3.7614256143569946e-05\n",
      "The classification loss after processing this batch is:  21896.68359375\n",
      "The representation loss after processing this batch is:  3.570783883333206e-05\n",
      "The classification loss after processing this batch is:  20766.28515625\n",
      "The representation loss after processing this batch is:  3.80566343665123e-05\n",
      "The classification loss after processing this batch is:  21170.234375\n",
      "The representation loss after processing this batch is:  3.334088250994682e-05\n",
      "The classification loss after processing this batch is:  20336.84375\n",
      "The representation loss after processing this batch is:  3.565475344657898e-05\n",
      "The classification loss after processing this batch is:  20811.697265625\n",
      "The representation loss after processing this batch is:  3.665918484330177e-05\n",
      "The classification loss after processing this batch is:  21108.32421875\n",
      "The representation loss after processing this batch is:  3.80747951567173e-05\n",
      "The classification loss after processing this batch is:  21049.6875\n",
      "The representation loss after processing this batch is:  3.9215199649333954e-05\n",
      "The classification loss after processing this batch is:  22494.05078125\n",
      "The representation loss after processing this batch is:  3.1719449907541275e-05\n",
      "The classification loss after processing this batch is:  26508.125\n",
      "The representation loss after processing this batch is:  4.553515464067459e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21227.5859375\n",
      "The representation loss after processing this batch is:  3.8201455026865005e-05\n",
      "The classification loss after processing this batch is:  21437.87890625\n",
      "The representation loss after processing this batch is:  3.3045653253793716e-05\n",
      "The classification loss after processing this batch is:  21358.7578125\n",
      "The representation loss after processing this batch is:  3.7662219256162643e-05\n",
      "The classification loss after processing this batch is:  21649.501953125\n",
      "The representation loss after processing this batch is:  3.628898411989212e-05\n",
      "The classification loss after processing this batch is:  21301.841796875\n",
      "The representation loss after processing this batch is:  3.791972994804382e-05\n",
      "The classification loss after processing this batch is:  21595.931640625\n",
      "The representation loss after processing this batch is:  3.8236845284700394e-05\n",
      "The classification loss after processing this batch is:  21163.94140625\n",
      "The representation loss after processing this batch is:  3.542797639966011e-05\n",
      "The classification loss after processing this batch is:  21516.58984375\n",
      "The representation loss after processing this batch is:  3.864802420139313e-05\n",
      "The classification loss after processing this batch is:  21128.73046875\n",
      "The representation loss after processing this batch is:  3.825873136520386e-05\n",
      "The classification loss after processing this batch is:  21362.2734375\n",
      "The representation loss after processing this batch is:  3.601657226681709e-05\n",
      "The classification loss after processing this batch is:  21133.150390625\n",
      "The representation loss after processing this batch is:  3.699585795402527e-05\n",
      "The classification loss after processing this batch is:  20855.69140625\n",
      "The representation loss after processing this batch is:  3.435974940657616e-05\n",
      "The classification loss after processing this batch is:  20732.828125\n",
      "The representation loss after processing this batch is:  4.446366801857948e-05\n",
      "The classification loss after processing this batch is:  19766.416015625\n",
      "The representation loss after processing this batch is:  3.6714132875204086e-05\n",
      "The classification loss after processing this batch is:  20860.615234375\n",
      "The representation loss after processing this batch is:  4.443200305104256e-05\n",
      "The classification loss after processing this batch is:  21287.564453125\n",
      "The representation loss after processing this batch is:  3.518257290124893e-05\n",
      "The classification loss after processing this batch is:  21094.603515625\n",
      "The representation loss after processing this batch is:  3.7179794162511826e-05\n",
      "The classification loss after processing this batch is:  20662.3984375\n",
      "The representation loss after processing this batch is:  3.75332310795784e-05\n",
      "The classification loss after processing this batch is:  22299.091796875\n",
      "The representation loss after processing this batch is:  3.700796514749527e-05\n",
      "The classification loss after processing this batch is:  21165.41015625\n",
      "The representation loss after processing this batch is:  3.987317904829979e-05\n",
      "The classification loss after processing this batch is:  20911.447265625\n",
      "The representation loss after processing this batch is:  3.806082531809807e-05\n",
      "The classification loss after processing this batch is:  21349.60546875\n",
      "The representation loss after processing this batch is:  3.8129743188619614e-05\n",
      "The classification loss after processing this batch is:  22391.140625\n",
      "The representation loss after processing this batch is:  3.4959521144628525e-05\n",
      "The classification loss after processing this batch is:  23633.7421875\n",
      "The representation loss after processing this batch is:  3.167567774653435e-05\n",
      "The classification loss after processing this batch is:  23197.390625\n",
      "The representation loss after processing this batch is:  3.312760964035988e-05\n",
      "The classification loss after processing this batch is:  20225.25\n",
      "The representation loss after processing this batch is:  3.801984712481499e-05\n",
      "The classification loss after processing this batch is:  22023.09765625\n",
      "The representation loss after processing this batch is:  3.440072759985924e-05\n",
      "The classification loss after processing this batch is:  20958.9453125\n",
      "The representation loss after processing this batch is:  3.114575520157814e-05\n",
      "The classification loss after processing this batch is:  22420.21875\n",
      "The representation loss after processing this batch is:  3.5579316318035126e-05\n",
      "The classification loss after processing this batch is:  22520.3359375\n",
      "The representation loss after processing this batch is:  3.218557685613632e-05\n",
      "The classification loss after processing this batch is:  21262.51953125\n",
      "The representation loss after processing this batch is:  3.370177000761032e-05\n",
      "The classification loss after processing this batch is:  21562.587890625\n",
      "The representation loss after processing this batch is:  3.346335142850876e-05\n",
      "The classification loss after processing this batch is:  21591.212890625\n",
      "The representation loss after processing this batch is:  3.54512594640255e-05\n",
      "The classification loss after processing this batch is:  22611.212890625\n",
      "The representation loss after processing this batch is:  4.0710438042879105e-05\n",
      "The classification loss after processing this batch is:  21561.697265625\n",
      "The representation loss after processing this batch is:  5.0361268222332e-05\n",
      "The classification loss after processing this batch is:  22311.513671875\n",
      "The representation loss after processing this batch is:  3.1878240406513214e-05\n",
      "The classification loss after processing this batch is:  22973.265625\n",
      "The representation loss after processing this batch is:  3.630761057138443e-05\n",
      "The classification loss after processing this batch is:  23598.109375\n",
      "The representation loss after processing this batch is:  4.4086016714572906e-05\n",
      "The classification loss after processing this batch is:  20916.369140625\n",
      "The representation loss after processing this batch is:  3.78219410777092e-05\n",
      "The classification loss after processing this batch is:  20811.42578125\n",
      "The representation loss after processing this batch is:  3.498047590255737e-05\n",
      "The classification loss after processing this batch is:  20917.71484375\n",
      "The representation loss after processing this batch is:  3.757048398256302e-05\n",
      "The classification loss after processing this batch is:  22270.884765625\n",
      "The representation loss after processing this batch is:  3.247847780585289e-05\n",
      "The classification loss after processing this batch is:  23343.06640625\n",
      "The representation loss after processing this batch is:  3.465963527560234e-05\n",
      "The classification loss after processing this batch is:  21715.24609375\n",
      "The representation loss after processing this batch is:  3.706198185682297e-05\n",
      "The classification loss after processing this batch is:  20553.57421875\n",
      "The representation loss after processing this batch is:  3.254413604736328e-05\n",
      "The classification loss after processing this batch is:  21064.88671875\n",
      "The representation loss after processing this batch is:  3.6860350519418716e-05\n",
      "The classification loss after processing this batch is:  20388.984375\n",
      "The representation loss after processing this batch is:  3.454601392149925e-05\n",
      "The classification loss after processing this batch is:  20887.41015625\n",
      "The representation loss after processing this batch is:  3.276905044913292e-05\n",
      "The classification loss after processing this batch is:  20833.33984375\n",
      "The representation loss after processing this batch is:  3.295252099633217e-05\n",
      "The classification loss after processing this batch is:  20760.2265625\n",
      "The representation loss after processing this batch is:  3.6189332604408264e-05\n",
      "The classification loss after processing this batch is:  20526.87890625\n",
      "The representation loss after processing this batch is:  3.328220918774605e-05\n",
      "The classification loss after processing this batch is:  20540.33203125\n",
      "The representation loss after processing this batch is:  3.448920324444771e-05\n",
      "The classification loss after processing this batch is:  21219.359375\n",
      "The representation loss after processing this batch is:  3.41217964887619e-05\n",
      "The classification loss after processing this batch is:  20517.87109375\n",
      "The representation loss after processing this batch is:  3.514392301440239e-05\n",
      "The classification loss after processing this batch is:  20631.716796875\n",
      "The representation loss after processing this batch is:  3.514764830470085e-05\n",
      "The classification loss after processing this batch is:  20404.296875\n",
      "The representation loss after processing this batch is:  3.2454729080200195e-05\n",
      "The classification loss after processing this batch is:  20101.509765625\n",
      "The representation loss after processing this batch is:  3.334786742925644e-05\n",
      "The classification loss after processing this batch is:  21907.3203125\n",
      "The representation loss after processing this batch is:  2.9881484806537628e-05\n",
      "The classification loss after processing this batch is:  21807.546875\n",
      "The representation loss after processing this batch is:  3.230804577469826e-05\n",
      "The classification loss after processing this batch is:  22407.4375\n",
      "The representation loss after processing this batch is:  3.22503037750721e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  23021.560546875\n",
      "The representation loss after processing this batch is:  3.26056033372879e-05\n",
      "The classification loss after processing this batch is:  22628.61328125\n",
      "The representation loss after processing this batch is:  3.475882112979889e-05\n",
      "The classification loss after processing this batch is:  21530.703125\n",
      "The representation loss after processing this batch is:  3.647804260253906e-05\n",
      "The classification loss after processing this batch is:  21903.82421875\n",
      "The representation loss after processing this batch is:  3.522215411067009e-05\n",
      "The classification loss after processing this batch is:  21363.40625\n",
      "The representation loss after processing this batch is:  3.285752609372139e-05\n",
      "The classification loss after processing this batch is:  21793.8046875\n",
      "The representation loss after processing this batch is:  3.533344715833664e-05\n",
      "The classification loss after processing this batch is:  20956.0859375\n",
      "The representation loss after processing this batch is:  3.3618882298469543e-05\n",
      "The classification loss after processing this batch is:  20778.884765625\n",
      "The representation loss after processing this batch is:  3.6735087633132935e-05\n",
      "The classification loss after processing this batch is:  21848.7890625\n",
      "The representation loss after processing this batch is:  3.616185858845711e-05\n",
      "The classification loss after processing this batch is:  21809.462890625\n",
      "The representation loss after processing this batch is:  3.4932512789964676e-05\n",
      "The classification loss after processing this batch is:  21128.8984375\n",
      "The representation loss after processing this batch is:  3.272527828812599e-05\n",
      "The classification loss after processing this batch is:  22358.205078125\n",
      "The representation loss after processing this batch is:  3.4648459404706955e-05\n",
      "The classification loss after processing this batch is:  24687.421875\n",
      "The representation loss after processing this batch is:  3.8897618651390076e-05\n",
      "The classification loss after processing this batch is:  22765.724609375\n",
      "The representation loss after processing this batch is:  3.514764830470085e-05\n",
      "The classification loss after processing this batch is:  21070.38671875\n",
      "The representation loss after processing this batch is:  3.073038533329964e-05\n",
      "The classification loss after processing this batch is:  21196.17578125\n",
      "The representation loss after processing this batch is:  3.7210993468761444e-05\n",
      "The classification loss after processing this batch is:  25640.265625\n",
      "The representation loss after processing this batch is:  3.750994801521301e-05\n",
      "The classification loss after processing this batch is:  26058.12109375\n",
      "The representation loss after processing this batch is:  4.540383815765381e-05\n",
      "The classification loss after processing this batch is:  20939.4453125\n",
      "The representation loss after processing this batch is:  3.71844507753849e-05\n",
      "The classification loss after processing this batch is:  20523.31640625\n",
      "The representation loss after processing this batch is:  3.5945791751146317e-05\n",
      "The classification loss after processing this batch is:  21130.904296875\n",
      "The representation loss after processing this batch is:  3.729201853275299e-05\n",
      "The classification loss after processing this batch is:  21522.62890625\n",
      "The representation loss after processing this batch is:  3.430387005209923e-05\n",
      "The classification loss after processing this batch is:  21442.224609375\n",
      "The representation loss after processing this batch is:  3.3556949347257614e-05\n",
      "The classification loss after processing this batch is:  21155.01953125\n",
      "The representation loss after processing this batch is:  3.363378345966339e-05\n",
      "The classification loss after processing this batch is:  22455.0390625\n",
      "The representation loss after processing this batch is:  3.0627474188804626e-05\n",
      "The classification loss after processing this batch is:  23454.505859375\n",
      "The representation loss after processing this batch is:  3.779632970690727e-05\n",
      "The classification loss after processing this batch is:  21190.92578125\n",
      "The representation loss after processing this batch is:  3.558443859219551e-05\n",
      "The classification loss after processing this batch is:  22026.16796875\n",
      "The representation loss after processing this batch is:  3.2383017241954803e-05\n",
      "The classification loss after processing this batch is:  20602.935546875\n",
      "The representation loss after processing this batch is:  3.5249628126621246e-05\n",
      "The classification loss after processing this batch is:  20696.53125\n",
      "The representation loss after processing this batch is:  3.451202064752579e-05\n",
      "The classification loss after processing this batch is:  20183.8828125\n",
      "The representation loss after processing this batch is:  3.238720819354057e-05\n",
      "The classification loss after processing this batch is:  21525.5078125\n",
      "The representation loss after processing this batch is:  3.827642649412155e-05\n",
      "The classification loss after processing this batch is:  20991.28515625\n",
      "The representation loss after processing this batch is:  3.44286672770977e-05\n",
      "The classification loss after processing this batch is:  23681.24609375\n",
      "The representation loss after processing this batch is:  3.5867560654878616e-05\n",
      "The classification loss after processing this batch is:  21149.869140625\n",
      "The representation loss after processing this batch is:  3.411341458559036e-05\n",
      "The classification loss after processing this batch is:  21455.203125\n",
      "The representation loss after processing this batch is:  3.279978409409523e-05\n",
      "The classification loss after processing this batch is:  22948.140625\n",
      "The representation loss after processing this batch is:  3.6425888538360596e-05\n",
      "The classification loss after processing this batch is:  22425.171875\n",
      "The representation loss after processing this batch is:  2.9922928661108017e-05\n",
      "The classification loss after processing this batch is:  21781.08984375\n",
      "The representation loss after processing this batch is:  3.293529152870178e-05\n",
      "The classification loss after processing this batch is:  23051.35546875\n",
      "The representation loss after processing this batch is:  4.425877705216408e-05\n",
      "The classification loss after processing this batch is:  21293.015625\n",
      "The representation loss after processing this batch is:  3.37124802172184e-05\n",
      "The classification loss after processing this batch is:  21851.9765625\n",
      "The representation loss after processing this batch is:  3.72864305973053e-05\n",
      "The classification loss after processing this batch is:  20480.251953125\n",
      "The representation loss after processing this batch is:  3.057485446333885e-05\n",
      "The classification loss after processing this batch is:  20607.20703125\n",
      "The representation loss after processing this batch is:  3.5264063626527786e-05\n",
      "The classification loss after processing this batch is:  20868.1875\n",
      "The representation loss after processing this batch is:  3.473833203315735e-05\n",
      "The classification loss after processing this batch is:  20868.763671875\n",
      "The representation loss after processing this batch is:  3.537395969033241e-05\n",
      "The classification loss after processing this batch is:  20929.671875\n",
      "The representation loss after processing this batch is:  3.1511299312114716e-05\n",
      "The classification loss after processing this batch is:  23415.705078125\n",
      "The representation loss after processing this batch is:  3.389501944184303e-05\n",
      "The classification loss after processing this batch is:  20630.412109375\n",
      "The representation loss after processing this batch is:  3.203423693776131e-05\n",
      "The classification loss after processing this batch is:  20830.541015625\n",
      "The representation loss after processing this batch is:  3.0909664928913116e-05\n",
      "The classification loss after processing this batch is:  21496.19921875\n",
      "The representation loss after processing this batch is:  3.2189302146434784e-05\n",
      "The classification loss after processing this batch is:  20982.16796875\n",
      "The representation loss after processing this batch is:  3.163982182741165e-05\n",
      "The classification loss after processing this batch is:  21752.826171875\n",
      "The representation loss after processing this batch is:  3.331433981657028e-05\n",
      "The classification loss after processing this batch is:  21616.603515625\n",
      "The representation loss after processing this batch is:  3.034435212612152e-05\n",
      "The classification loss after processing this batch is:  21429.68359375\n",
      "The representation loss after processing this batch is:  3.2603275030851364e-05\n",
      "The classification loss after processing this batch is:  20122.189453125\n",
      "The representation loss after processing this batch is:  2.996576949954033e-05\n",
      "The classification loss after processing this batch is:  21812.70703125\n",
      "The representation loss after processing this batch is:  3.130687400698662e-05\n",
      "The classification loss after processing this batch is:  24277.17578125\n",
      "The representation loss after processing this batch is:  3.483472391963005e-05\n",
      "The classification loss after processing this batch is:  25146.28515625\n",
      "The representation loss after processing this batch is:  3.673136234283447e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21598.078125\n",
      "The representation loss after processing this batch is:  3.224797546863556e-05\n",
      "The classification loss after processing this batch is:  21551.359375\n",
      "The representation loss after processing this batch is:  3.040861338376999e-05\n",
      "The classification loss after processing this batch is:  21056.595703125\n",
      "The representation loss after processing this batch is:  3.362959250807762e-05\n",
      "The classification loss after processing this batch is:  21758.474609375\n",
      "The representation loss after processing this batch is:  3.433087840676308e-05\n",
      "The classification loss after processing this batch is:  20869.880859375\n",
      "The representation loss after processing this batch is:  3.104656934738159e-05\n",
      "The classification loss after processing this batch is:  21345.34375\n",
      "The representation loss after processing this batch is:  3.0615366995334625e-05\n",
      "The classification loss after processing this batch is:  22850.9140625\n",
      "The representation loss after processing this batch is:  3.196811303496361e-05\n",
      "The classification loss after processing this batch is:  20263.927734375\n",
      "The representation loss after processing this batch is:  3.227312117815018e-05\n",
      "The classification loss after processing this batch is:  20622.759765625\n",
      "The representation loss after processing this batch is:  3.3317599445581436e-05\n",
      "The classification loss after processing this batch is:  22642.2109375\n",
      "The representation loss after processing this batch is:  3.5871751606464386e-05\n",
      "The classification loss after processing this batch is:  21308.8203125\n",
      "The representation loss after processing this batch is:  3.302423283457756e-05\n",
      "The classification loss after processing this batch is:  20907.39453125\n",
      "The representation loss after processing this batch is:  3.288360312581062e-05\n",
      "The classification loss after processing this batch is:  19952.087890625\n",
      "The representation loss after processing this batch is:  3.238534554839134e-05\n",
      "The classification loss after processing this batch is:  22836.1875\n",
      "The representation loss after processing this batch is:  3.5740435123443604e-05\n",
      "The classification loss after processing this batch is:  22110.587890625\n",
      "The representation loss after processing this batch is:  3.696465864777565e-05\n",
      "The classification loss after processing this batch is:  26406.056640625\n",
      "The representation loss after processing this batch is:  3.828248009085655e-05\n",
      "The classification loss after processing this batch is:  22486.19921875\n",
      "The representation loss after processing this batch is:  3.126263618469238e-05\n",
      "The classification loss after processing this batch is:  21156.91015625\n",
      "The representation loss after processing this batch is:  3.436161205172539e-05\n",
      "The classification loss after processing this batch is:  22318.60546875\n",
      "The representation loss after processing this batch is:  3.204634413123131e-05\n",
      "The classification loss after processing this batch is:  23360.130859375\n",
      "The representation loss after processing this batch is:  3.546569496393204e-05\n",
      "The classification loss after processing this batch is:  22528.7109375\n",
      "The representation loss after processing this batch is:  3.5210512578487396e-05\n",
      "The classification loss after processing this batch is:  21774.236328125\n",
      "The representation loss after processing this batch is:  3.224611282348633e-05\n",
      "The classification loss after processing this batch is:  21824.03515625\n",
      "The representation loss after processing this batch is:  3.105541691184044e-05\n",
      "The classification loss after processing this batch is:  21696.140625\n",
      "The representation loss after processing this batch is:  2.9461923986673355e-05\n",
      "The classification loss after processing this batch is:  20722.09765625\n",
      "The representation loss after processing this batch is:  3.3597927540540695e-05\n",
      "The classification loss after processing this batch is:  21851.2578125\n",
      "The representation loss after processing this batch is:  3.383122384548187e-05\n",
      "The classification loss after processing this batch is:  21488.72265625\n",
      "The representation loss after processing this batch is:  3.235554322600365e-05\n",
      "The classification loss after processing this batch is:  22036.986328125\n",
      "The representation loss after processing this batch is:  3.395183011889458e-05\n",
      "The classification loss after processing this batch is:  22030.41796875\n",
      "The representation loss after processing this batch is:  3.2372307032346725e-05\n",
      "The classification loss after processing this batch is:  22096.4375\n",
      "The representation loss after processing this batch is:  3.340095281600952e-05\n",
      "The classification loss after processing this batch is:  20756.083984375\n",
      "The representation loss after processing this batch is:  2.9853545129299164e-05\n",
      "The classification loss after processing this batch is:  20260.52734375\n",
      "The representation loss after processing this batch is:  3.7052202969789505e-05\n",
      "The classification loss after processing this batch is:  20828.50390625\n",
      "The representation loss after processing this batch is:  2.995925024151802e-05\n",
      "The classification loss after processing this batch is:  20712.26953125\n",
      "The representation loss after processing this batch is:  3.300793468952179e-05\n",
      "The classification loss after processing this batch is:  22044.4375\n",
      "The representation loss after processing this batch is:  3.307173028588295e-05\n",
      "The classification loss after processing this batch is:  21671.85546875\n",
      "The representation loss after processing this batch is:  3.093807026743889e-05\n",
      "The classification loss after processing this batch is:  21002.095703125\n",
      "The representation loss after processing this batch is:  3.579631447792053e-05\n",
      "The classification loss after processing this batch is:  19888.84375\n",
      "The representation loss after processing this batch is:  3.643985837697983e-05\n",
      "The classification loss after processing this batch is:  19916.736328125\n",
      "The representation loss after processing this batch is:  3.172503784298897e-05\n",
      "The classification loss after processing this batch is:  21644.109375\n",
      "The representation loss after processing this batch is:  3.239838406443596e-05\n",
      "The classification loss after processing this batch is:  22324.98046875\n",
      "The representation loss after processing this batch is:  3.041466698050499e-05\n",
      "The classification loss after processing this batch is:  22531.990234375\n",
      "The representation loss after processing this batch is:  3.692321479320526e-05\n",
      "The classification loss after processing this batch is:  20522.578125\n",
      "The representation loss after processing this batch is:  3.383820876479149e-05\n",
      "The classification loss after processing this batch is:  21742.373046875\n",
      "The representation loss after processing this batch is:  3.270478919148445e-05\n",
      "The classification loss after processing this batch is:  20811.224609375\n",
      "The representation loss after processing this batch is:  3.603333607316017e-05\n",
      "The classification loss after processing this batch is:  21590.755859375\n",
      "The representation loss after processing this batch is:  4.051718860864639e-05\n",
      "The classification loss after processing this batch is:  20619.63671875\n",
      "The representation loss after processing this batch is:  3.051571547985077e-05\n",
      "The classification loss after processing this batch is:  20109.677734375\n",
      "The representation loss after processing this batch is:  3.2738782465457916e-05\n",
      "The classification loss after processing this batch is:  19895.453125\n",
      "The representation loss after processing this batch is:  3.234902396798134e-05\n",
      "The classification loss after processing this batch is:  20895.8984375\n",
      "The representation loss after processing this batch is:  3.646966069936752e-05\n",
      "The classification loss after processing this batch is:  21140.5703125\n",
      "The representation loss after processing this batch is:  3.872113302350044e-05\n",
      "The classification loss after processing this batch is:  21478.98828125\n",
      "The representation loss after processing this batch is:  3.305263817310333e-05\n",
      "The classification loss after processing this batch is:  21391.87109375\n",
      "The representation loss after processing this batch is:  3.61674465239048e-05\n",
      "The classification loss after processing this batch is:  20578.74609375\n",
      "The representation loss after processing this batch is:  3.078766167163849e-05\n",
      "The classification loss after processing this batch is:  22274.783203125\n",
      "The representation loss after processing this batch is:  3.183819353580475e-05\n",
      "The classification loss after processing this batch is:  23811.630859375\n",
      "The representation loss after processing this batch is:  3.5706907510757446e-05\n",
      "The classification loss after processing this batch is:  22960.203125\n",
      "The representation loss after processing this batch is:  3.63299623131752e-05\n",
      "The classification loss after processing this batch is:  22680.01953125\n",
      "The representation loss after processing this batch is:  4.133395850658417e-05\n",
      "The classification loss after processing this batch is:  20849.08984375\n",
      "The representation loss after processing this batch is:  3.032200038433075e-05\n",
      "The classification loss after processing this batch is:  21141.697265625\n",
      "The representation loss after processing this batch is:  3.125704824924469e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22317.150390625\n",
      "The representation loss after processing this batch is:  3.757793456315994e-05\n",
      "The classification loss after processing this batch is:  20616.77734375\n",
      "The representation loss after processing this batch is:  3.729481250047684e-05\n",
      "The classification loss after processing this batch is:  20863.041015625\n",
      "The representation loss after processing this batch is:  3.218371421098709e-05\n",
      "The classification loss after processing this batch is:  21736.263671875\n",
      "The representation loss after processing this batch is:  3.0109193176031113e-05\n",
      "The classification loss after processing this batch is:  21629.625\n",
      "The representation loss after processing this batch is:  2.992665395140648e-05\n",
      "The classification loss after processing this batch is:  21256.142578125\n",
      "The representation loss after processing this batch is:  2.8323382139205933e-05\n",
      "The classification loss after processing this batch is:  21119.34765625\n",
      "The representation loss after processing this batch is:  3.0728522688150406e-05\n",
      "The classification loss after processing this batch is:  22597.9921875\n",
      "The representation loss after processing this batch is:  3.6345794796943665e-05\n",
      "The classification loss after processing this batch is:  22256.361328125\n",
      "The representation loss after processing this batch is:  3.286357969045639e-05\n",
      "The classification loss after processing this batch is:  22785.75390625\n",
      "The representation loss after processing this batch is:  3.158068284392357e-05\n",
      "The classification loss after processing this batch is:  23076.63671875\n",
      "The representation loss after processing this batch is:  3.6174431443214417e-05\n",
      "The classification loss after processing this batch is:  22103.2109375\n",
      "The representation loss after processing this batch is:  3.118952736258507e-05\n",
      "The classification loss after processing this batch is:  21070.5234375\n",
      "The representation loss after processing this batch is:  3.187265247106552e-05\n",
      "The classification loss after processing this batch is:  20585.03515625\n",
      "The representation loss after processing this batch is:  3.306800499558449e-05\n",
      "The classification loss after processing this batch is:  20762.216796875\n",
      "The representation loss after processing this batch is:  3.15224751830101e-05\n",
      "The classification loss after processing this batch is:  21426.66015625\n",
      "The representation loss after processing this batch is:  3.350479528307915e-05\n",
      "The classification loss after processing this batch is:  20982.44140625\n",
      "The representation loss after processing this batch is:  3.299349918961525e-05\n",
      "The classification loss after processing this batch is:  21605.375\n",
      "The representation loss after processing this batch is:  3.138044849038124e-05\n",
      "The classification loss after processing this batch is:  21395.39453125\n",
      "The representation loss after processing this batch is:  3.4129247069358826e-05\n",
      "The classification loss after processing this batch is:  23937.384765625\n",
      "The representation loss after processing this batch is:  3.6199577152729034e-05\n",
      "The classification loss after processing this batch is:  23144.171875\n",
      "The representation loss after processing this batch is:  3.263913094997406e-05\n",
      "The classification loss after processing this batch is:  21249.23046875\n",
      "The representation loss after processing this batch is:  3.0667055398225784e-05\n",
      "The classification loss after processing this batch is:  20356.48046875\n",
      "The representation loss after processing this batch is:  3.5933684557676315e-05\n",
      "The classification loss after processing this batch is:  20546.85546875\n",
      "The representation loss after processing this batch is:  3.279373049736023e-05\n",
      "The classification loss after processing this batch is:  21496.765625\n",
      "The representation loss after processing this batch is:  3.850692883133888e-05\n",
      "The classification loss after processing this batch is:  21153.994140625\n",
      "The representation loss after processing this batch is:  3.6082230508327484e-05\n",
      "The classification loss after processing this batch is:  21710.005859375\n",
      "The representation loss after processing this batch is:  3.437977284193039e-05\n",
      "The classification loss after processing this batch is:  20993.296875\n",
      "The representation loss after processing this batch is:  3.2481271773576736e-05\n",
      "The classification loss after processing this batch is:  20606.751953125\n",
      "The representation loss after processing this batch is:  2.9175542294979095e-05\n",
      "The classification loss after processing this batch is:  20296.9140625\n",
      "The representation loss after processing this batch is:  3.15406359732151e-05\n",
      "The classification loss after processing this batch is:  22029.203125\n",
      "The representation loss after processing this batch is:  3.195926547050476e-05\n",
      "The classification loss after processing this batch is:  23151.654296875\n",
      "The representation loss after processing this batch is:  3.706943243741989e-05\n",
      "The classification loss after processing this batch is:  21301.892578125\n",
      "The representation loss after processing this batch is:  3.291107714176178e-05\n",
      "The classification loss after processing this batch is:  21728.1171875\n",
      "The representation loss after processing this batch is:  3.381166607141495e-05\n",
      "The classification loss after processing this batch is:  22817.0234375\n",
      "The representation loss after processing this batch is:  3.8199592381715775e-05\n",
      "The classification loss after processing this batch is:  21857.900390625\n",
      "The representation loss after processing this batch is:  3.2246578484773636e-05\n",
      "The classification loss after processing this batch is:  23219.080078125\n",
      "The representation loss after processing this batch is:  3.1181611120700836e-05\n",
      "The classification loss after processing this batch is:  21197.943359375\n",
      "The representation loss after processing this batch is:  3.6251265555620193e-05\n",
      "The classification loss after processing this batch is:  22168.201171875\n",
      "The representation loss after processing this batch is:  3.640074282884598e-05\n",
      "The classification loss after processing this batch is:  21074.79296875\n",
      "The representation loss after processing this batch is:  3.307545557618141e-05\n",
      "The classification loss after processing this batch is:  21729.123046875\n",
      "The representation loss after processing this batch is:  2.914993092417717e-05\n",
      "The classification loss after processing this batch is:  21237.07421875\n",
      "The representation loss after processing this batch is:  3.3828895539045334e-05\n",
      "The classification loss after processing this batch is:  21236.25\n",
      "The representation loss after processing this batch is:  3.379443660378456e-05\n",
      "The classification loss after processing this batch is:  21720.1953125\n",
      "The representation loss after processing this batch is:  3.170967102050781e-05\n",
      "The classification loss after processing this batch is:  20704.37109375\n",
      "The representation loss after processing this batch is:  3.4767668694257736e-05\n",
      "The classification loss after processing this batch is:  21134.70703125\n",
      "The representation loss after processing this batch is:  3.334740176796913e-05\n",
      "The classification loss after processing this batch is:  20147.306640625\n",
      "The representation loss after processing this batch is:  3.3286865800619125e-05\n",
      "The classification loss after processing this batch is:  20400.48828125\n",
      "The representation loss after processing this batch is:  3.622472286224365e-05\n",
      "The classification loss after processing this batch is:  20151.3046875\n",
      "The representation loss after processing this batch is:  3.151595592498779e-05\n",
      "The classification loss after processing this batch is:  21903.607421875\n",
      "The representation loss after processing this batch is:  3.704288974404335e-05\n",
      "The classification loss after processing this batch is:  20955.05859375\n",
      "The representation loss after processing this batch is:  3.470899537205696e-05\n",
      "The classification loss after processing this batch is:  21552.21875\n",
      "The representation loss after processing this batch is:  3.255624324083328e-05\n",
      "The classification loss after processing this batch is:  21746.76953125\n",
      "The representation loss after processing this batch is:  2.9549933969974518e-05\n",
      "The classification loss after processing this batch is:  20635.9921875\n",
      "The representation loss after processing this batch is:  3.0324328690767288e-05\n",
      "The classification loss after processing this batch is:  21809.869140625\n",
      "The representation loss after processing this batch is:  3.5804230719804764e-05\n",
      "The classification loss after processing this batch is:  21503.42578125\n",
      "The representation loss after processing this batch is:  3.481423482298851e-05\n",
      "The classification loss after processing this batch is:  20612.19140625\n",
      "The representation loss after processing this batch is:  3.0105002224445343e-05\n",
      "The classification loss after processing this batch is:  21559.03125\n",
      "The representation loss after processing this batch is:  3.242073580622673e-05\n",
      "The classification loss after processing this batch is:  21196.32421875\n",
      "The representation loss after processing this batch is:  3.234390169382095e-05\n",
      "The classification loss after processing this batch is:  20810.267578125\n",
      "The representation loss after processing this batch is:  3.068707883358002e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21421.8671875\n",
      "The representation loss after processing this batch is:  3.223167732357979e-05\n",
      "The classification loss after processing this batch is:  20919.1875\n",
      "The representation loss after processing this batch is:  3.39532271027565e-05\n",
      "The classification loss after processing this batch is:  21685.01171875\n",
      "The representation loss after processing this batch is:  3.6112964153289795e-05\n",
      "The classification loss after processing this batch is:  22475.298828125\n",
      "The representation loss after processing this batch is:  3.471085801720619e-05\n",
      "The classification loss after processing this batch is:  21199.720703125\n",
      "The representation loss after processing this batch is:  3.704754635691643e-05\n",
      "The classification loss after processing this batch is:  23246.177734375\n",
      "The representation loss after processing this batch is:  2.987077459692955e-05\n",
      "The classification loss after processing this batch is:  23646.830078125\n",
      "The representation loss after processing this batch is:  3.1093135476112366e-05\n",
      "The classification loss after processing this batch is:  21005.89453125\n",
      "The representation loss after processing this batch is:  3.1281728297472e-05\n",
      "The classification loss after processing this batch is:  21700.47265625\n",
      "The representation loss after processing this batch is:  3.0543189495801926e-05\n",
      "The classification loss after processing this batch is:  22753.75\n",
      "The representation loss after processing this batch is:  3.511970862746239e-05\n",
      "The classification loss after processing this batch is:  21273.53125\n",
      "The representation loss after processing this batch is:  3.0302908271551132e-05\n",
      "The classification loss after processing this batch is:  21230.26171875\n",
      "The representation loss after processing this batch is:  3.1229108572006226e-05\n",
      "The classification loss after processing this batch is:  20940.85546875\n",
      "The representation loss after processing this batch is:  3.0513852834701538e-05\n",
      "The classification loss after processing this batch is:  21253.23828125\n",
      "The representation loss after processing this batch is:  3.1639356166124344e-05\n",
      "The classification loss after processing this batch is:  22174.94921875\n",
      "The representation loss after processing this batch is:  3.115599974989891e-05\n",
      "The classification loss after processing this batch is:  21983.99609375\n",
      "The representation loss after processing this batch is:  3.4401193261146545e-05\n",
      "The classification loss after processing this batch is:  23959.3984375\n",
      "The representation loss after processing this batch is:  3.779679536819458e-05\n",
      "The classification loss after processing this batch is:  22422.3359375\n",
      "The representation loss after processing this batch is:  3.219069913029671e-05\n",
      "The classification loss after processing this batch is:  21992.197265625\n",
      "The representation loss after processing this batch is:  2.9655173420906067e-05\n",
      "The classification loss after processing this batch is:  20559.62890625\n",
      "The representation loss after processing this batch is:  3.133900463581085e-05\n",
      "The classification loss after processing this batch is:  20839.0546875\n",
      "The representation loss after processing this batch is:  3.117090091109276e-05\n",
      "The classification loss after processing this batch is:  21954.33203125\n",
      "The representation loss after processing this batch is:  3.324821591377258e-05\n",
      "The classification loss after processing this batch is:  20831.421875\n",
      "The representation loss after processing this batch is:  3.2298266887664795e-05\n",
      "The classification loss after processing this batch is:  19900.681640625\n",
      "The representation loss after processing this batch is:  3.50181944668293e-05\n",
      "The classification loss after processing this batch is:  22484.46875\n",
      "The representation loss after processing this batch is:  3.106147050857544e-05\n",
      "The classification loss after processing this batch is:  20597.140625\n",
      "The representation loss after processing this batch is:  3.084680065512657e-05\n",
      "The classification loss after processing this batch is:  20708.8203125\n",
      "The representation loss after processing this batch is:  3.139488399028778e-05\n",
      "The classification loss after processing this batch is:  20000.580078125\n",
      "The representation loss after processing this batch is:  3.257766366004944e-05\n",
      "The classification loss after processing this batch is:  20567.5859375\n",
      "The representation loss after processing this batch is:  3.1760428100824356e-05\n",
      "The classification loss after processing this batch is:  20327.37890625\n",
      "The representation loss after processing this batch is:  2.9719434678554535e-05\n",
      "The classification loss after processing this batch is:  21423.033203125\n",
      "The representation loss after processing this batch is:  3.1136441975831985e-05\n",
      "The classification loss after processing this batch is:  20968.86328125\n",
      "The representation loss after processing this batch is:  2.966262400150299e-05\n",
      "The classification loss after processing this batch is:  20563.140625\n",
      "The representation loss after processing this batch is:  3.041839227080345e-05\n",
      "The classification loss after processing this batch is:  21924.37109375\n",
      "The representation loss after processing this batch is:  3.2106414437294006e-05\n",
      "The classification loss after processing this batch is:  22356.759765625\n",
      "The representation loss after processing this batch is:  3.278953954577446e-05\n",
      "The classification loss after processing this batch is:  20394.771484375\n",
      "The representation loss after processing this batch is:  3.248825669288635e-05\n",
      "The classification loss after processing this batch is:  20740.595703125\n",
      "The representation loss after processing this batch is:  3.156345337629318e-05\n",
      "The classification loss after processing this batch is:  21107.45703125\n",
      "The representation loss after processing this batch is:  3.0112918466329575e-05\n",
      "The classification loss after processing this batch is:  20813.8203125\n",
      "The representation loss after processing this batch is:  3.0541326850652695e-05\n",
      "The classification loss after processing this batch is:  21953.5078125\n",
      "The representation loss after processing this batch is:  3.03550623357296e-05\n",
      "The classification loss after processing this batch is:  20612.4609375\n",
      "The representation loss after processing this batch is:  3.012176603078842e-05\n",
      "The classification loss after processing this batch is:  20122.607421875\n",
      "The representation loss after processing this batch is:  3.2697804272174835e-05\n",
      "The classification loss after processing this batch is:  21124.865234375\n",
      "The representation loss after processing this batch is:  3.323378041386604e-05\n",
      "The classification loss after processing this batch is:  23053.5859375\n",
      "The representation loss after processing this batch is:  3.611575812101364e-05\n",
      "The classification loss after processing this batch is:  20573.79296875\n",
      "The representation loss after processing this batch is:  2.9866117984056473e-05\n",
      "The classification loss after processing this batch is:  21516.19921875\n",
      "The representation loss after processing this batch is:  3.070291131734848e-05\n",
      "The classification loss after processing this batch is:  23305.90234375\n",
      "The representation loss after processing this batch is:  3.344286233186722e-05\n",
      "The classification loss after processing this batch is:  21022.5390625\n",
      "The representation loss after processing this batch is:  3.34419310092926e-05\n",
      "The classification loss after processing this batch is:  20236.630859375\n",
      "The representation loss after processing this batch is:  3.0549243092536926e-05\n",
      "The classification loss after processing this batch is:  20631.591796875\n",
      "The representation loss after processing this batch is:  3.184424713253975e-05\n",
      "The classification loss after processing this batch is:  20376.91796875\n",
      "The representation loss after processing this batch is:  3.017578274011612e-05\n",
      "The classification loss after processing this batch is:  21177.3515625\n",
      "The representation loss after processing this batch is:  3.149546682834625e-05\n",
      "The classification loss after processing this batch is:  20420.4921875\n",
      "The representation loss after processing this batch is:  3.4209806472063065e-05\n",
      "The classification loss after processing this batch is:  21138.763671875\n",
      "The representation loss after processing this batch is:  3.2982323318719864e-05\n",
      "The classification loss after processing this batch is:  24063.1953125\n",
      "The representation loss after processing this batch is:  3.3206772059202194e-05\n",
      "The classification loss after processing this batch is:  22359.1953125\n",
      "The representation loss after processing this batch is:  2.80807726085186e-05\n",
      "The classification loss after processing this batch is:  21645.044921875\n",
      "The representation loss after processing this batch is:  3.125332295894623e-05\n",
      "The classification loss after processing this batch is:  20643.240234375\n",
      "The representation loss after processing this batch is:  3.0390452593564987e-05\n",
      "The classification loss after processing this batch is:  21221.23828125\n",
      "The representation loss after processing this batch is:  3.390945494174957e-05\n",
      "The classification loss after processing this batch is:  21227.0390625\n",
      "The representation loss after processing this batch is:  3.835558891296387e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  20656.76171875\n",
      "The representation loss after processing this batch is:  2.987496554851532e-05\n",
      "The classification loss after processing this batch is:  20000.29296875\n",
      "The representation loss after processing this batch is:  3.166031092405319e-05\n",
      "The classification loss after processing this batch is:  20721.126953125\n",
      "The representation loss after processing this batch is:  3.1670089811086655e-05\n",
      "The classification loss after processing this batch is:  20646.5546875\n",
      "The representation loss after processing this batch is:  2.9502902179956436e-05\n",
      "The classification loss after processing this batch is:  20016.98046875\n",
      "The representation loss after processing this batch is:  3.22503037750721e-05\n",
      "The classification loss after processing this batch is:  20909.83203125\n",
      "The representation loss after processing this batch is:  3.0038412660360336e-05\n",
      "The classification loss after processing this batch is:  20072.34765625\n",
      "The representation loss after processing this batch is:  3.0487775802612305e-05\n",
      "The classification loss after processing this batch is:  22592.71875\n",
      "The representation loss after processing this batch is:  3.3956486731767654e-05\n",
      "The classification loss after processing this batch is:  22333.857421875\n",
      "The representation loss after processing this batch is:  2.8782524168491364e-05\n",
      "The classification loss after processing this batch is:  21304.037109375\n",
      "The representation loss after processing this batch is:  3.084307536482811e-05\n",
      "The classification loss after processing this batch is:  20935.09765625\n",
      "The representation loss after processing this batch is:  3.097299486398697e-05\n",
      "The classification loss after processing this batch is:  20659.87109375\n",
      "The representation loss after processing this batch is:  3.3517833799123764e-05\n",
      "The classification loss after processing this batch is:  22261.623046875\n",
      "The representation loss after processing this batch is:  3.192294389009476e-05\n",
      "The classification loss after processing this batch is:  21723.19140625\n",
      "The representation loss after processing this batch is:  3.113411366939545e-05\n",
      "The classification loss after processing this batch is:  21011.87109375\n",
      "The representation loss after processing this batch is:  3.0322466045618057e-05\n",
      "The classification loss after processing this batch is:  21405.708984375\n",
      "The representation loss after processing this batch is:  3.0224211513996124e-05\n",
      "The classification loss after processing this batch is:  23137.626953125\n",
      "The representation loss after processing this batch is:  3.71723435819149e-05\n",
      "The classification loss after processing this batch is:  20697.90625\n",
      "The representation loss after processing this batch is:  3.0205585062503815e-05\n",
      "The classification loss after processing this batch is:  21650.990234375\n",
      "The representation loss after processing this batch is:  3.0749477446079254e-05\n",
      "The classification loss after processing this batch is:  21641.13671875\n",
      "The representation loss after processing this batch is:  3.8967467844486237e-05\n",
      "The classification loss after processing this batch is:  21271.283203125\n",
      "The representation loss after processing this batch is:  3.1803734600543976e-05\n",
      "The classification loss after processing this batch is:  21807.08203125\n",
      "The representation loss after processing this batch is:  3.355508670210838e-05\n",
      "The classification loss after processing this batch is:  22447.126953125\n",
      "The representation loss after processing this batch is:  3.730179741978645e-05\n",
      "The classification loss after processing this batch is:  21021.994140625\n",
      "The representation loss after processing this batch is:  3.62638384103775e-05\n",
      "The classification loss after processing this batch is:  21695.71484375\n",
      "The representation loss after processing this batch is:  2.9593706130981445e-05\n",
      "The classification loss after processing this batch is:  22075.91015625\n",
      "The representation loss after processing this batch is:  2.9396265745162964e-05\n",
      "The classification loss after processing this batch is:  21016.8359375\n",
      "The representation loss after processing this batch is:  3.381585702300072e-05\n",
      "The classification loss after processing this batch is:  22095.7890625\n",
      "The representation loss after processing this batch is:  2.83755362033844e-05\n",
      "The classification loss after processing this batch is:  21707.79296875\n",
      "The representation loss after processing this batch is:  3.205565735697746e-05\n",
      "The classification loss after processing this batch is:  20607.24609375\n",
      "The representation loss after processing this batch is:  3.255857154726982e-05\n",
      "The classification loss after processing this batch is:  20808.001953125\n",
      "The representation loss after processing this batch is:  3.131059929728508e-05\n",
      "The classification loss after processing this batch is:  20658.984375\n",
      "The representation loss after processing this batch is:  3.369757905602455e-05\n",
      "The classification loss after processing this batch is:  20590.85546875\n",
      "The representation loss after processing this batch is:  3.111502155661583e-05\n",
      "The classification loss after processing this batch is:  22559.65234375\n",
      "The representation loss after processing this batch is:  3.1567178666591644e-05\n",
      "The classification loss after processing this batch is:  21951.15234375\n",
      "The representation loss after processing this batch is:  2.9038172215223312e-05\n",
      "The classification loss after processing this batch is:  22841.642578125\n",
      "The representation loss after processing this batch is:  3.222096711397171e-05\n",
      "The classification loss after processing this batch is:  20071.08203125\n",
      "The representation loss after processing this batch is:  3.190385177731514e-05\n",
      "The classification loss after processing this batch is:  20549.791015625\n",
      "The representation loss after processing this batch is:  3.429083153605461e-05\n",
      "The classification loss after processing this batch is:  20784.146484375\n",
      "The representation loss after processing this batch is:  3.336183726787567e-05\n",
      "The classification loss after processing this batch is:  20570.6484375\n",
      "The representation loss after processing this batch is:  2.998625859618187e-05\n",
      "The classification loss after processing this batch is:  21908.0\n",
      "The representation loss after processing this batch is:  3.145122900605202e-05\n",
      "The classification loss after processing this batch is:  20651.583984375\n",
      "The representation loss after processing this batch is:  2.938089892268181e-05\n",
      "The classification loss after processing this batch is:  21321.2890625\n",
      "The representation loss after processing this batch is:  2.9315706342458725e-05\n",
      "The classification loss after processing this batch is:  21312.79296875\n",
      "The representation loss after processing this batch is:  3.273366019129753e-05\n",
      "The classification loss after processing this batch is:  20561.203125\n",
      "The representation loss after processing this batch is:  3.056460991501808e-05\n",
      "The classification loss after processing this batch is:  22671.357421875\n",
      "The representation loss after processing this batch is:  3.586104139685631e-05\n",
      "The classification loss after processing this batch is:  22629.810546875\n",
      "The representation loss after processing this batch is:  3.0617695301771164e-05\n",
      "The classification loss after processing this batch is:  21772.15234375\n",
      "The representation loss after processing this batch is:  3.308570012450218e-05\n",
      "The classification loss after processing this batch is:  20236.248046875\n",
      "The representation loss after processing this batch is:  3.2572075724601746e-05\n",
      "The classification loss after processing this batch is:  22455.0859375\n",
      "The representation loss after processing this batch is:  3.069499507546425e-05\n",
      "The classification loss after processing this batch is:  22106.41796875\n",
      "The representation loss after processing this batch is:  3.0231662094593048e-05\n",
      "The classification loss after processing this batch is:  20534.19140625\n",
      "The representation loss after processing this batch is:  2.983957529067993e-05\n",
      "The classification loss after processing this batch is:  22770.814453125\n",
      "The representation loss after processing this batch is:  3.351271152496338e-05\n",
      "The classification loss after processing this batch is:  22693.703125\n",
      "The representation loss after processing this batch is:  3.5868026316165924e-05\n",
      "The classification loss after processing this batch is:  20194.8984375\n",
      "The representation loss after processing this batch is:  2.9636546969413757e-05\n",
      "The classification loss after processing this batch is:  20836.7890625\n",
      "The representation loss after processing this batch is:  3.2020267099142075e-05\n",
      "The classification loss after processing this batch is:  21492.609375\n",
      "The representation loss after processing this batch is:  3.181584179401398e-05\n",
      "The classification loss after processing this batch is:  21026.734375\n",
      "The representation loss after processing this batch is:  3.155320882797241e-05\n",
      "The classification loss after processing this batch is:  22006.939453125\n",
      "The representation loss after processing this batch is:  3.690551966428757e-05\n",
      "The classification loss after processing this batch is:  22575.716796875\n",
      "The representation loss after processing this batch is:  3.2753217965364456e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  20405.08203125\n",
      "The representation loss after processing this batch is:  3.499956801533699e-05\n",
      "The classification loss after processing this batch is:  19844.44140625\n",
      "The representation loss after processing this batch is:  3.356672823429108e-05\n",
      "The classification loss after processing this batch is:  21190.87890625\n",
      "The representation loss after processing this batch is:  2.9499642550945282e-05\n",
      "The classification loss after processing this batch is:  22167.12109375\n",
      "The representation loss after processing this batch is:  3.283843398094177e-05\n",
      "The classification loss after processing this batch is:  20940.802734375\n",
      "The representation loss after processing this batch is:  3.119464963674545e-05\n",
      "The classification loss after processing this batch is:  21682.09375\n",
      "The representation loss after processing this batch is:  3.376370295882225e-05\n",
      "The classification loss after processing this batch is:  21213.556640625\n",
      "The representation loss after processing this batch is:  3.0458439141511917e-05\n",
      "The classification loss after processing this batch is:  21290.650390625\n",
      "The representation loss after processing this batch is:  3.212830051779747e-05\n",
      "The classification loss after processing this batch is:  20807.3515625\n",
      "The representation loss after processing this batch is:  3.1732022762298584e-05\n",
      "The classification loss after processing this batch is:  21223.0859375\n",
      "The representation loss after processing this batch is:  3.1898729503154755e-05\n",
      "The classification loss after processing this batch is:  22553.4375\n",
      "The representation loss after processing this batch is:  3.560958430171013e-05\n",
      "The classification loss after processing this batch is:  20297.9453125\n",
      "The representation loss after processing this batch is:  2.9556453227996826e-05\n",
      "The classification loss after processing this batch is:  20101.80859375\n",
      "The representation loss after processing this batch is:  3.0189286917448044e-05\n",
      "The classification loss after processing this batch is:  19875.56640625\n",
      "The representation loss after processing this batch is:  3.2028649002313614e-05\n",
      "The classification loss after processing this batch is:  20149.0546875\n",
      "The representation loss after processing this batch is:  2.94465571641922e-05\n",
      "The classification loss after processing this batch is:  20524.1640625\n",
      "The representation loss after processing this batch is:  3.0472874641418457e-05\n",
      "The classification loss after processing this batch is:  21793.171875\n",
      "The representation loss after processing this batch is:  3.0703842639923096e-05\n",
      "The classification loss after processing this batch is:  21911.43359375\n",
      "The representation loss after processing this batch is:  2.9651448130607605e-05\n",
      "The classification loss after processing this batch is:  20695.8046875\n",
      "The representation loss after processing this batch is:  3.0174851417541504e-05\n",
      "The classification loss after processing this batch is:  20001.03125\n",
      "The representation loss after processing this batch is:  3.0769966542720795e-05\n",
      "The classification loss after processing this batch is:  20114.79296875\n",
      "The representation loss after processing this batch is:  3.029312938451767e-05\n",
      "The classification loss after processing this batch is:  20772.6796875\n",
      "The representation loss after processing this batch is:  3.0710361897945404e-05\n",
      "The classification loss after processing this batch is:  20951.197265625\n",
      "The representation loss after processing this batch is:  3.106705844402313e-05\n",
      "The classification loss after processing this batch is:  20170.2109375\n",
      "The representation loss after processing this batch is:  3.337813541293144e-05\n",
      "The classification loss after processing this batch is:  22531.3515625\n",
      "The representation loss after processing this batch is:  3.062095493078232e-05\n",
      "The classification loss after processing this batch is:  20787.0234375\n",
      "The representation loss after processing this batch is:  3.070849925279617e-05\n",
      "The classification loss after processing this batch is:  20449.2109375\n",
      "The representation loss after processing this batch is:  3.469828516244888e-05\n",
      "The classification loss after processing this batch is:  20862.6640625\n",
      "The representation loss after processing this batch is:  3.0563678592443466e-05\n",
      "The classification loss after processing this batch is:  21578.0859375\n",
      "The representation loss after processing this batch is:  2.9989052563905716e-05\n",
      "The classification loss after processing this batch is:  21221.095703125\n",
      "The representation loss after processing this batch is:  2.9997900128364563e-05\n",
      "The classification loss after processing this batch is:  20357.39453125\n",
      "The representation loss after processing this batch is:  3.0856113880872726e-05\n",
      "The classification loss after processing this batch is:  21020.017578125\n",
      "The representation loss after processing this batch is:  3.0238181352615356e-05\n",
      "The classification loss after processing this batch is:  22461.962890625\n",
      "The representation loss after processing this batch is:  3.1949952244758606e-05\n",
      "The classification loss after processing this batch is:  19826.6171875\n",
      "The representation loss after processing this batch is:  3.232806921005249e-05\n",
      "The classification loss after processing this batch is:  20425.80859375\n",
      "The representation loss after processing this batch is:  2.9119662940502167e-05\n",
      "The classification loss after processing this batch is:  19457.50390625\n",
      "The representation loss after processing this batch is:  3.274856135249138e-05\n",
      "The classification loss after processing this batch is:  20860.873046875\n",
      "The representation loss after processing this batch is:  2.8893817216157913e-05\n",
      "The classification loss after processing this batch is:  21241.859375\n",
      "The representation loss after processing this batch is:  3.07643786072731e-05\n",
      "The classification loss after processing this batch is:  20580.84375\n",
      "The representation loss after processing this batch is:  3.228941932320595e-05\n",
      "The classification loss after processing this batch is:  20325.77734375\n",
      "The representation loss after processing this batch is:  3.4875236451625824e-05\n",
      "The classification loss after processing this batch is:  19896.0\n",
      "The representation loss after processing this batch is:  3.153504803776741e-05\n",
      "The classification loss after processing this batch is:  20977.689453125\n",
      "The representation loss after processing this batch is:  2.8324779123067856e-05\n",
      "The classification loss after processing this batch is:  20654.501953125\n",
      "The representation loss after processing this batch is:  3.0774157494306564e-05\n",
      "The classification loss after processing this batch is:  20105.89453125\n",
      "The representation loss after processing this batch is:  3.118300810456276e-05\n",
      "The classification loss after processing this batch is:  23864.017578125\n",
      "The representation loss after processing this batch is:  3.319326788187027e-05\n",
      "The classification loss after processing this batch is:  22383.71484375\n",
      "The representation loss after processing this batch is:  3.405986353754997e-05\n",
      "The classification loss after processing this batch is:  21404.05859375\n",
      "The representation loss after processing this batch is:  3.098277375102043e-05\n",
      "The classification loss after processing this batch is:  20932.09765625\n",
      "The representation loss after processing this batch is:  3.242306411266327e-05\n",
      "The classification loss after processing this batch is:  20283.9375\n",
      "The representation loss after processing this batch is:  3.41576524078846e-05\n",
      "The classification loss after processing this batch is:  20942.77734375\n",
      "The representation loss after processing this batch is:  3.172038123011589e-05\n",
      "The classification loss after processing this batch is:  21658.51953125\n",
      "The representation loss after processing this batch is:  3.2667070627212524e-05\n",
      "The classification loss after processing this batch is:  20746.537109375\n",
      "The representation loss after processing this batch is:  2.9332470148801804e-05\n",
      "The classification loss after processing this batch is:  22972.9609375\n",
      "The representation loss after processing this batch is:  3.051338717341423e-05\n",
      "The classification loss after processing this batch is:  21067.271484375\n",
      "The representation loss after processing this batch is:  3.16067598760128e-05\n",
      "The classification loss after processing this batch is:  20131.296875\n",
      "The representation loss after processing this batch is:  3.291945904493332e-05\n",
      "The classification loss after processing this batch is:  22011.7109375\n",
      "The representation loss after processing this batch is:  3.294413909316063e-05\n",
      "The classification loss after processing this batch is:  20283.20703125\n",
      "The representation loss after processing this batch is:  3.21660190820694e-05\n",
      "The classification loss after processing this batch is:  20605.55859375\n",
      "The representation loss after processing this batch is:  3.521982580423355e-05\n",
      "The classification loss after processing this batch is:  24453.30859375\n",
      "The representation loss after processing this batch is:  3.6061741411685944e-05\n",
      "The classification loss after processing this batch is:  21755.04296875\n",
      "The representation loss after processing this batch is:  3.66908498108387e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  20465.626953125\n",
      "The representation loss after processing this batch is:  3.790529444813728e-05\n",
      "The classification loss after processing this batch is:  20763.23046875\n",
      "The representation loss after processing this batch is:  4.37004491686821e-05\n",
      "The classification loss after processing this batch is:  22638.0625\n",
      "The representation loss after processing this batch is:  3.448035567998886e-05\n",
      "The classification loss after processing this batch is:  19902.025390625\n",
      "The representation loss after processing this batch is:  3.5373494029045105e-05\n",
      "The classification loss after processing this batch is:  20940.3828125\n",
      "The representation loss after processing this batch is:  3.764638677239418e-05\n",
      "The classification loss after processing this batch is:  21803.8203125\n",
      "The representation loss after processing this batch is:  3.824802115559578e-05\n",
      "The classification loss after processing this batch is:  25543.9453125\n",
      "The representation loss after processing this batch is:  3.8825906813144684e-05\n",
      "The classification loss after processing this batch is:  27551.7421875\n",
      "The representation loss after processing this batch is:  3.286218270659447e-05\n",
      "The classification loss after processing this batch is:  20136.52734375\n",
      "The representation loss after processing this batch is:  3.435928374528885e-05\n",
      "The classification loss after processing this batch is:  21539.25\n",
      "The representation loss after processing this batch is:  3.253389149904251e-05\n",
      "The classification loss after processing this batch is:  21660.130859375\n",
      "The representation loss after processing this batch is:  3.6796554923057556e-05\n",
      "The classification loss after processing this batch is:  19804.888671875\n",
      "The representation loss after processing this batch is:  3.227684646844864e-05\n",
      "the loss after processing this epoch is:  0.08207670599222183\n",
      "the loss after processing this epoch is:  0.028935475274920464\n",
      "the loss after processing this epoch is:  0.0037710368633270264\n",
      "the loss after processing this epoch is:  0.0011717031011357903\n",
      "the loss after processing this epoch is:  0.0006044605979695916\n",
      "the loss after processing this epoch is:  0.00042645138455554843\n",
      "the loss after processing this epoch is:  0.0002853770856745541\n",
      "the loss after processing this epoch is:  0.00011832515156129375\n",
      "the loss after processing this epoch is:  6.647904956480488e-05\n",
      "the loss after processing this epoch is:  3.616015237639658e-05\n",
      "The classification loss after processing this batch is:  21163.71484375\n",
      "The representation loss after processing this batch is:  0.0014455337077379227\n",
      "The classification loss after processing this batch is:  20690.05859375\n",
      "The representation loss after processing this batch is:  0.0007372223772108555\n",
      "The classification loss after processing this batch is:  19612.841796875\n",
      "The representation loss after processing this batch is:  0.0004937397316098213\n",
      "The classification loss after processing this batch is:  20365.29296875\n",
      "The representation loss after processing this batch is:  0.00031851278617978096\n",
      "The classification loss after processing this batch is:  21452.484375\n",
      "The representation loss after processing this batch is:  0.0003738114610314369\n",
      "The classification loss after processing this batch is:  21704.248046875\n",
      "The representation loss after processing this batch is:  0.0003145243972539902\n",
      "The classification loss after processing this batch is:  21501.15234375\n",
      "The representation loss after processing this batch is:  0.00031244056299328804\n",
      "The classification loss after processing this batch is:  21760.845703125\n",
      "The representation loss after processing this batch is:  0.0003070039674639702\n",
      "The classification loss after processing this batch is:  21679.384765625\n",
      "The representation loss after processing this batch is:  0.00027422700077295303\n",
      "The classification loss after processing this batch is:  23305.50390625\n",
      "The representation loss after processing this batch is:  0.00035887863487005234\n",
      "The classification loss after processing this batch is:  22455.71484375\n",
      "The representation loss after processing this batch is:  0.0002394295297563076\n",
      "The classification loss after processing this batch is:  22312.0625\n",
      "The representation loss after processing this batch is:  0.00021571572870016098\n",
      "The classification loss after processing this batch is:  22573.15234375\n",
      "The representation loss after processing this batch is:  0.000193009153008461\n",
      "The classification loss after processing this batch is:  22271.0390625\n",
      "The representation loss after processing this batch is:  0.00019736215472221375\n",
      "The classification loss after processing this batch is:  22488.640625\n",
      "The representation loss after processing this batch is:  0.00021515414118766785\n",
      "The classification loss after processing this batch is:  22944.890625\n",
      "The representation loss after processing this batch is:  0.00021825917065143585\n",
      "The classification loss after processing this batch is:  22703.375\n",
      "The representation loss after processing this batch is:  0.0001871911808848381\n",
      "The classification loss after processing this batch is:  24539.486328125\n",
      "The representation loss after processing this batch is:  0.00020919833332300186\n",
      "The classification loss after processing this batch is:  22933.408203125\n",
      "The representation loss after processing this batch is:  0.00016792304813861847\n",
      "The classification loss after processing this batch is:  23369.912109375\n",
      "The representation loss after processing this batch is:  0.00015732645988464355\n",
      "The classification loss after processing this batch is:  23268.42578125\n",
      "The representation loss after processing this batch is:  0.0001657530665397644\n",
      "The classification loss after processing this batch is:  23557.8828125\n",
      "The representation loss after processing this batch is:  0.00013248343020677567\n",
      "The classification loss after processing this batch is:  23802.58984375\n",
      "The representation loss after processing this batch is:  0.00013321172446012497\n",
      "The classification loss after processing this batch is:  23174.826171875\n",
      "The representation loss after processing this batch is:  0.00015792343765497208\n",
      "The classification loss after processing this batch is:  23151.908203125\n",
      "The representation loss after processing this batch is:  0.00016080588102340698\n",
      "The classification loss after processing this batch is:  22157.15625\n",
      "The representation loss after processing this batch is:  0.00015662983059883118\n",
      "The classification loss after processing this batch is:  22928.103515625\n",
      "The representation loss after processing this batch is:  0.00013806670904159546\n",
      "The classification loss after processing this batch is:  22895.4453125\n",
      "The representation loss after processing this batch is:  0.00014069676399230957\n",
      "The classification loss after processing this batch is:  25838.166015625\n",
      "The representation loss after processing this batch is:  0.00015835091471672058\n",
      "The classification loss after processing this batch is:  24133.6875\n",
      "The representation loss after processing this batch is:  0.00013123080134391785\n",
      "The classification loss after processing this batch is:  22689.55078125\n",
      "The representation loss after processing this batch is:  0.00015975162386894226\n",
      "The classification loss after processing this batch is:  23056.5\n",
      "The representation loss after processing this batch is:  0.00012503191828727722\n",
      "The classification loss after processing this batch is:  22150.75390625\n",
      "The representation loss after processing this batch is:  0.00013474933803081512\n",
      "The classification loss after processing this batch is:  22951.396484375\n",
      "The representation loss after processing this batch is:  0.00015372037887573242\n",
      "The classification loss after processing this batch is:  23355.12890625\n",
      "The representation loss after processing this batch is:  0.00014011748135089874\n",
      "The classification loss after processing this batch is:  23547.697265625\n",
      "The representation loss after processing this batch is:  0.00013747066259384155\n",
      "The classification loss after processing this batch is:  24912.41796875\n",
      "The representation loss after processing this batch is:  0.00014800392091274261\n",
      "The classification loss after processing this batch is:  28431.044921875\n",
      "The representation loss after processing this batch is:  0.00020215846598148346\n",
      "The classification loss after processing this batch is:  23169.5546875\n",
      "The representation loss after processing this batch is:  0.00012717582285404205\n",
      "The classification loss after processing this batch is:  23909.146484375\n",
      "The representation loss after processing this batch is:  0.0001446399837732315\n",
      "The classification loss after processing this batch is:  23834.650390625\n",
      "The representation loss after processing this batch is:  0.00012328475713729858\n",
      "The classification loss after processing this batch is:  23853.076171875\n",
      "The representation loss after processing this batch is:  0.00014284439384937286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  23269.525390625\n",
      "The representation loss after processing this batch is:  0.00013573281466960907\n",
      "The classification loss after processing this batch is:  23573.66015625\n",
      "The representation loss after processing this batch is:  0.00013905391097068787\n",
      "The classification loss after processing this batch is:  23275.923828125\n",
      "The representation loss after processing this batch is:  0.00012569688260555267\n",
      "The classification loss after processing this batch is:  23192.11328125\n",
      "The representation loss after processing this batch is:  0.0001421421766281128\n",
      "The classification loss after processing this batch is:  22828.16796875\n",
      "The representation loss after processing this batch is:  0.000132853165268898\n",
      "The classification loss after processing this batch is:  22904.546875\n",
      "The representation loss after processing this batch is:  0.00012105144560337067\n",
      "The classification loss after processing this batch is:  22488.052734375\n",
      "The representation loss after processing this batch is:  0.00012185703963041306\n",
      "The classification loss after processing this batch is:  22353.435546875\n",
      "The representation loss after processing this batch is:  0.00014874525368213654\n",
      "The classification loss after processing this batch is:  22679.30078125\n",
      "The representation loss after processing this batch is:  0.00012413877993822098\n",
      "The classification loss after processing this batch is:  21452.99609375\n",
      "The representation loss after processing this batch is:  0.00012342818081378937\n",
      "The classification loss after processing this batch is:  22234.46484375\n",
      "The representation loss after processing this batch is:  0.00014869868755340576\n",
      "The classification loss after processing this batch is:  22474.5\n",
      "The representation loss after processing this batch is:  0.0001569679006934166\n",
      "The classification loss after processing this batch is:  22566.5703125\n",
      "The representation loss after processing this batch is:  0.00013402756303548813\n",
      "The classification loss after processing this batch is:  21990.87890625\n",
      "The representation loss after processing this batch is:  0.00013033486902713776\n",
      "The classification loss after processing this batch is:  23413.0\n",
      "The representation loss after processing this batch is:  0.0001295134425163269\n",
      "The classification loss after processing this batch is:  22203.5546875\n",
      "The representation loss after processing this batch is:  0.0001468844711780548\n",
      "The classification loss after processing this batch is:  21892.87890625\n",
      "The representation loss after processing this batch is:  0.0001539122313261032\n",
      "The classification loss after processing this batch is:  22379.6875\n",
      "The representation loss after processing this batch is:  0.000144273042678833\n",
      "The classification loss after processing this batch is:  23976.740234375\n",
      "The representation loss after processing this batch is:  0.0001346217468380928\n",
      "The classification loss after processing this batch is:  24653.71484375\n",
      "The representation loss after processing this batch is:  0.00012333504855632782\n",
      "The classification loss after processing this batch is:  23759.85546875\n",
      "The representation loss after processing this batch is:  0.00012475717812776566\n",
      "The classification loss after processing this batch is:  21379.40234375\n",
      "The representation loss after processing this batch is:  0.00011067837476730347\n",
      "The classification loss after processing this batch is:  23098.69140625\n",
      "The representation loss after processing this batch is:  0.00012118089944124222\n",
      "The classification loss after processing this batch is:  22138.54296875\n",
      "The representation loss after processing this batch is:  0.00011897459626197815\n",
      "The classification loss after processing this batch is:  23326.482421875\n",
      "The representation loss after processing this batch is:  0.0001289956271648407\n",
      "The classification loss after processing this batch is:  23487.5546875\n",
      "The representation loss after processing this batch is:  0.00012366380542516708\n",
      "The classification loss after processing this batch is:  22414.1640625\n",
      "The representation loss after processing this batch is:  0.00011388584971427917\n",
      "The classification loss after processing this batch is:  22583.123046875\n",
      "The representation loss after processing this batch is:  0.0001398855820298195\n",
      "The classification loss after processing this batch is:  22699.46875\n",
      "The representation loss after processing this batch is:  0.00011032167822122574\n",
      "The classification loss after processing this batch is:  23555.3359375\n",
      "The representation loss after processing this batch is:  0.00013641174882650375\n",
      "The classification loss after processing this batch is:  22115.72265625\n",
      "The representation loss after processing this batch is:  0.0001388387754559517\n",
      "The classification loss after processing this batch is:  23160.595703125\n",
      "The representation loss after processing this batch is:  0.00010669324547052383\n",
      "The classification loss after processing this batch is:  23577.193359375\n",
      "The representation loss after processing this batch is:  0.0001292843371629715\n",
      "The classification loss after processing this batch is:  23934.68359375\n",
      "The representation loss after processing this batch is:  0.00013085640966892242\n",
      "The classification loss after processing this batch is:  22455.611328125\n",
      "The representation loss after processing this batch is:  0.00011582951992750168\n",
      "The classification loss after processing this batch is:  22346.037109375\n",
      "The representation loss after processing this batch is:  0.00011310819536447525\n",
      "The classification loss after processing this batch is:  22143.865234375\n",
      "The representation loss after processing this batch is:  0.00011929776519536972\n",
      "The classification loss after processing this batch is:  23469.515625\n",
      "The representation loss after processing this batch is:  0.00011320319026708603\n",
      "The classification loss after processing this batch is:  24055.806640625\n",
      "The representation loss after processing this batch is:  0.00011153426021337509\n",
      "The classification loss after processing this batch is:  22449.625\n",
      "The representation loss after processing this batch is:  0.0001246398314833641\n",
      "The classification loss after processing this batch is:  21461.509765625\n",
      "The representation loss after processing this batch is:  0.00011848937720060349\n",
      "The classification loss after processing this batch is:  21963.71484375\n",
      "The representation loss after processing this batch is:  0.00012678466737270355\n",
      "The classification loss after processing this batch is:  21184.607421875\n",
      "The representation loss after processing this batch is:  0.00011267699301242828\n",
      "The classification loss after processing this batch is:  21636.578125\n",
      "The representation loss after processing this batch is:  0.00011663883924484253\n",
      "The classification loss after processing this batch is:  21612.82421875\n",
      "The representation loss after processing this batch is:  0.000112154521048069\n",
      "The classification loss after processing this batch is:  21659.06640625\n",
      "The representation loss after processing this batch is:  0.00010653957724571228\n",
      "The classification loss after processing this batch is:  21364.18359375\n",
      "The representation loss after processing this batch is:  0.00011410750448703766\n",
      "The classification loss after processing this batch is:  21050.5\n",
      "The representation loss after processing this batch is:  0.00011650193482637405\n",
      "The classification loss after processing this batch is:  21344.25390625\n",
      "The representation loss after processing this batch is:  0.00010728929191827774\n",
      "The classification loss after processing this batch is:  20808.36328125\n",
      "The representation loss after processing this batch is:  0.00011860392987728119\n",
      "The classification loss after processing this batch is:  21100.3203125\n",
      "The representation loss after processing this batch is:  0.00014045462012290955\n",
      "The classification loss after processing this batch is:  21211.25\n",
      "The representation loss after processing this batch is:  0.00010991934686899185\n",
      "The classification loss after processing this batch is:  20509.71484375\n",
      "The representation loss after processing this batch is:  0.00012621749192476273\n",
      "The classification loss after processing this batch is:  22595.568359375\n",
      "The representation loss after processing this batch is:  0.00010062567889690399\n",
      "The classification loss after processing this batch is:  22306.587890625\n",
      "The representation loss after processing this batch is:  0.00011829938739538193\n",
      "The classification loss after processing this batch is:  23297.744140625\n",
      "The representation loss after processing this batch is:  0.00011090468615293503\n",
      "The classification loss after processing this batch is:  23613.00390625\n",
      "The representation loss after processing this batch is:  0.00013526901602745056\n",
      "The classification loss after processing this batch is:  23267.638671875\n",
      "The representation loss after processing this batch is:  0.00012354925274848938\n",
      "The classification loss after processing this batch is:  22332.205078125\n",
      "The representation loss after processing this batch is:  0.00011873617768287659\n",
      "The classification loss after processing this batch is:  22282.021484375\n",
      "The representation loss after processing this batch is:  0.00011483393609523773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21885.60546875\n",
      "The representation loss after processing this batch is:  0.00011169258505105972\n",
      "The classification loss after processing this batch is:  22112.58984375\n",
      "The representation loss after processing this batch is:  0.00011052750051021576\n",
      "The classification loss after processing this batch is:  21670.91796875\n",
      "The representation loss after processing this batch is:  0.00011531263589859009\n",
      "The classification loss after processing this batch is:  21028.15625\n",
      "The representation loss after processing this batch is:  0.00010572094470262527\n",
      "The classification loss after processing this batch is:  22308.845703125\n",
      "The representation loss after processing this batch is:  0.0001034960150718689\n",
      "The classification loss after processing this batch is:  22259.669921875\n",
      "The representation loss after processing this batch is:  0.0001202113926410675\n",
      "The classification loss after processing this batch is:  21549.525390625\n",
      "The representation loss after processing this batch is:  0.0001221913844347\n",
      "The classification loss after processing this batch is:  22750.72265625\n",
      "The representation loss after processing this batch is:  0.00011559110134840012\n",
      "The classification loss after processing this batch is:  24965.5703125\n",
      "The representation loss after processing this batch is:  0.0001255962997674942\n",
      "The classification loss after processing this batch is:  22810.271484375\n",
      "The representation loss after processing this batch is:  0.00011347606778144836\n",
      "The classification loss after processing this batch is:  21406.77734375\n",
      "The representation loss after processing this batch is:  0.00010229833424091339\n",
      "The classification loss after processing this batch is:  21715.291015625\n",
      "The representation loss after processing this batch is:  0.00012031756341457367\n",
      "The classification loss after processing this batch is:  25408.12890625\n",
      "The representation loss after processing this batch is:  0.0001160893589258194\n",
      "The classification loss after processing this batch is:  25516.8203125\n",
      "The representation loss after processing this batch is:  0.00013021565973758698\n",
      "The classification loss after processing this batch is:  21458.275390625\n",
      "The representation loss after processing this batch is:  0.00011144019663333893\n",
      "The classification loss after processing this batch is:  21017.333984375\n",
      "The representation loss after processing this batch is:  0.00010759010910987854\n",
      "The classification loss after processing this batch is:  21552.177734375\n",
      "The representation loss after processing this batch is:  0.00011157151311635971\n",
      "The classification loss after processing this batch is:  22424.89453125\n",
      "The representation loss after processing this batch is:  0.00010566320270299911\n",
      "The classification loss after processing this batch is:  22126.58984375\n",
      "The representation loss after processing this batch is:  9.791459888219833e-05\n",
      "The classification loss after processing this batch is:  21849.3515625\n",
      "The representation loss after processing this batch is:  0.00011843815445899963\n",
      "The classification loss after processing this batch is:  23080.49609375\n",
      "The representation loss after processing this batch is:  0.00010043475776910782\n",
      "The classification loss after processing this batch is:  23789.986328125\n",
      "The representation loss after processing this batch is:  0.00012557301670312881\n",
      "The classification loss after processing this batch is:  21692.5390625\n",
      "The representation loss after processing this batch is:  0.00012277346104383469\n",
      "The classification loss after processing this batch is:  22386.4453125\n",
      "The representation loss after processing this batch is:  0.0001316545531153679\n",
      "The classification loss after processing this batch is:  20995.5234375\n",
      "The representation loss after processing this batch is:  0.00012040510773658752\n",
      "The classification loss after processing this batch is:  21330.51953125\n",
      "The representation loss after processing this batch is:  0.00011750217527151108\n",
      "The classification loss after processing this batch is:  20689.48828125\n",
      "The representation loss after processing this batch is:  0.00012009497731924057\n",
      "The classification loss after processing this batch is:  22319.13671875\n",
      "The representation loss after processing this batch is:  0.0001300303265452385\n",
      "The classification loss after processing this batch is:  21909.298828125\n",
      "The representation loss after processing this batch is:  0.00012458860874176025\n",
      "The classification loss after processing this batch is:  23758.3125\n",
      "The representation loss after processing this batch is:  0.00010510347783565521\n",
      "The classification loss after processing this batch is:  21619.0859375\n",
      "The representation loss after processing this batch is:  0.00011356640607118607\n",
      "The classification loss after processing this batch is:  21780.453125\n",
      "The representation loss after processing this batch is:  0.00010107830166816711\n",
      "The classification loss after processing this batch is:  23154.724609375\n",
      "The representation loss after processing this batch is:  0.00011940672993659973\n",
      "The classification loss after processing this batch is:  22703.35546875\n",
      "The representation loss after processing this batch is:  0.00010900851339101791\n",
      "The classification loss after processing this batch is:  22090.33203125\n",
      "The representation loss after processing this batch is:  0.0001210412010550499\n",
      "The classification loss after processing this batch is:  23453.8125\n",
      "The representation loss after processing this batch is:  0.00012350454926490784\n",
      "The classification loss after processing this batch is:  21845.259765625\n",
      "The representation loss after processing this batch is:  0.00011910311877727509\n",
      "The classification loss after processing this batch is:  22721.33203125\n",
      "The representation loss after processing this batch is:  0.00013960804790258408\n",
      "The classification loss after processing this batch is:  21235.66015625\n",
      "The representation loss after processing this batch is:  0.00010381452739238739\n",
      "The classification loss after processing this batch is:  21383.640625\n",
      "The representation loss after processing this batch is:  0.00011623091995716095\n",
      "The classification loss after processing this batch is:  21434.08984375\n",
      "The representation loss after processing this batch is:  0.00011384114623069763\n",
      "The classification loss after processing this batch is:  21383.6640625\n",
      "The representation loss after processing this batch is:  0.00012809038162231445\n",
      "The classification loss after processing this batch is:  21149.06640625\n",
      "The representation loss after processing this batch is:  0.00012305565178394318\n",
      "The classification loss after processing this batch is:  23805.90234375\n",
      "The representation loss after processing this batch is:  0.00011550169438123703\n",
      "The classification loss after processing this batch is:  21341.4140625\n",
      "The representation loss after processing this batch is:  0.00011287443339824677\n",
      "The classification loss after processing this batch is:  21762.55859375\n",
      "The representation loss after processing this batch is:  0.000100686214864254\n",
      "The classification loss after processing this batch is:  22534.66015625\n",
      "The representation loss after processing this batch is:  0.00010154303163290024\n",
      "The classification loss after processing this batch is:  21791.44921875\n",
      "The representation loss after processing this batch is:  9.733904153108597e-05\n",
      "The classification loss after processing this batch is:  22288.32421875\n",
      "The representation loss after processing this batch is:  0.00011132657527923584\n",
      "The classification loss after processing this batch is:  22199.76171875\n",
      "The representation loss after processing this batch is:  9.871553629636765e-05\n",
      "The classification loss after processing this batch is:  21592.9609375\n",
      "The representation loss after processing this batch is:  0.00010959804058074951\n",
      "The classification loss after processing this batch is:  20530.9453125\n",
      "The representation loss after processing this batch is:  9.609293192625046e-05\n",
      "The classification loss after processing this batch is:  22066.57421875\n",
      "The representation loss after processing this batch is:  0.00012087728828191757\n",
      "The classification loss after processing this batch is:  24586.291015625\n",
      "The representation loss after processing this batch is:  0.00010414700955152512\n",
      "The classification loss after processing this batch is:  24950.55859375\n",
      "The representation loss after processing this batch is:  0.00011616852134466171\n",
      "The classification loss after processing this batch is:  21845.048828125\n",
      "The representation loss after processing this batch is:  0.00010436400771141052\n",
      "The classification loss after processing this batch is:  21933.90625\n",
      "The representation loss after processing this batch is:  0.00010522082448005676\n",
      "The classification loss after processing this batch is:  21936.884765625\n",
      "The representation loss after processing this batch is:  9.820330888032913e-05\n",
      "The classification loss after processing this batch is:  22814.373046875\n",
      "The representation loss after processing this batch is:  0.00011383742094039917\n",
      "The classification loss after processing this batch is:  21632.17578125\n",
      "The representation loss after processing this batch is:  0.0001168297603726387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22088.79296875\n",
      "The representation loss after processing this batch is:  9.355321526527405e-05\n",
      "The classification loss after processing this batch is:  23389.88671875\n",
      "The representation loss after processing this batch is:  0.000100734643638134\n",
      "The classification loss after processing this batch is:  20561.873046875\n",
      "The representation loss after processing this batch is:  9.026378393173218e-05\n",
      "The classification loss after processing this batch is:  21014.765625\n",
      "The representation loss after processing this batch is:  9.328406304121017e-05\n",
      "The classification loss after processing this batch is:  23672.70703125\n",
      "The representation loss after processing this batch is:  0.00012443773448467255\n",
      "The classification loss after processing this batch is:  22178.669921875\n",
      "The representation loss after processing this batch is:  0.00011961348354816437\n",
      "The classification loss after processing this batch is:  21340.744140625\n",
      "The representation loss after processing this batch is:  0.00011861417442560196\n",
      "The classification loss after processing this batch is:  20221.955078125\n",
      "The representation loss after processing this batch is:  0.0001033218577504158\n",
      "The classification loss after processing this batch is:  23221.14453125\n",
      "The representation loss after processing this batch is:  0.00012081768363714218\n",
      "The classification loss after processing this batch is:  22779.439453125\n",
      "The representation loss after processing this batch is:  0.0001301206648349762\n",
      "The classification loss after processing this batch is:  27441.98828125\n",
      "The representation loss after processing this batch is:  0.00011571776121854782\n",
      "The classification loss after processing this batch is:  23109.9296875\n",
      "The representation loss after processing this batch is:  0.00011162925511598587\n",
      "The classification loss after processing this batch is:  21661.65625\n",
      "The representation loss after processing this batch is:  0.0001084357500076294\n",
      "The classification loss after processing this batch is:  23083.75\n",
      "The representation loss after processing this batch is:  0.00010764319449663162\n",
      "The classification loss after processing this batch is:  24151.37109375\n",
      "The representation loss after processing this batch is:  0.00011754501610994339\n",
      "The classification loss after processing this batch is:  22994.0625\n",
      "The representation loss after processing this batch is:  0.00010224618017673492\n",
      "The classification loss after processing this batch is:  22495.41796875\n",
      "The representation loss after processing this batch is:  0.00010242592543363571\n",
      "The classification loss after processing this batch is:  22364.33984375\n",
      "The representation loss after processing this batch is:  9.441375732421875e-05\n",
      "The classification loss after processing this batch is:  22256.61328125\n",
      "The representation loss after processing this batch is:  0.00011458434164524078\n",
      "The classification loss after processing this batch is:  21247.19140625\n",
      "The representation loss after processing this batch is:  0.00010574888437986374\n",
      "The classification loss after processing this batch is:  22301.494140625\n",
      "The representation loss after processing this batch is:  0.00010801386088132858\n",
      "The classification loss after processing this batch is:  22032.716796875\n",
      "The representation loss after processing this batch is:  0.00010044500231742859\n",
      "The classification loss after processing this batch is:  22702.27734375\n",
      "The representation loss after processing this batch is:  0.00011218618601560593\n",
      "The classification loss after processing this batch is:  22554.9609375\n",
      "The representation loss after processing this batch is:  0.00010075140744447708\n",
      "The classification loss after processing this batch is:  22680.16015625\n",
      "The representation loss after processing this batch is:  0.00010721944272518158\n",
      "The classification loss after processing this batch is:  21287.05078125\n",
      "The representation loss after processing this batch is:  0.00011462066322565079\n",
      "The classification loss after processing this batch is:  20730.763671875\n",
      "The representation loss after processing this batch is:  0.00012714136391878128\n",
      "The classification loss after processing this batch is:  21248.3671875\n",
      "The representation loss after processing this batch is:  0.00010982155799865723\n",
      "The classification loss after processing this batch is:  21049.517578125\n",
      "The representation loss after processing this batch is:  0.00010052137076854706\n",
      "The classification loss after processing this batch is:  22815.46875\n",
      "The representation loss after processing this batch is:  9.915139526128769e-05\n",
      "The classification loss after processing this batch is:  22305.1015625\n",
      "The representation loss after processing this batch is:  9.637046605348587e-05\n",
      "The classification loss after processing this batch is:  21282.39453125\n",
      "The representation loss after processing this batch is:  0.0001238808035850525\n",
      "The classification loss after processing this batch is:  20241.44921875\n",
      "The representation loss after processing this batch is:  0.00011129304766654968\n",
      "The classification loss after processing this batch is:  20459.06640625\n",
      "The representation loss after processing this batch is:  0.00011285115033388138\n",
      "The classification loss after processing this batch is:  22212.078125\n",
      "The representation loss after processing this batch is:  0.00010863691568374634\n",
      "The classification loss after processing this batch is:  22946.984375\n",
      "The representation loss after processing this batch is:  0.00010772235691547394\n",
      "The classification loss after processing this batch is:  23163.21875\n",
      "The representation loss after processing this batch is:  0.00012492574751377106\n",
      "The classification loss after processing this batch is:  20983.45703125\n",
      "The representation loss after processing this batch is:  0.00010676588863134384\n",
      "The classification loss after processing this batch is:  21946.634765625\n",
      "The representation loss after processing this batch is:  0.00011565908789634705\n",
      "The classification loss after processing this batch is:  21206.421875\n",
      "The representation loss after processing this batch is:  0.00010912679135799408\n",
      "The classification loss after processing this batch is:  21711.46484375\n",
      "The representation loss after processing this batch is:  0.00012702122330665588\n",
      "The classification loss after processing this batch is:  20901.259765625\n",
      "The representation loss after processing this batch is:  0.0001097414642572403\n",
      "The classification loss after processing this batch is:  20743.474609375\n",
      "The representation loss after processing this batch is:  0.00012120138853788376\n",
      "The classification loss after processing this batch is:  20804.173828125\n",
      "The representation loss after processing this batch is:  0.00010443944483995438\n",
      "The classification loss after processing this batch is:  21651.078125\n",
      "The representation loss after processing this batch is:  0.00011387281119823456\n",
      "The classification loss after processing this batch is:  21835.2578125\n",
      "The representation loss after processing this batch is:  0.0001252898946404457\n",
      "The classification loss after processing this batch is:  21934.283203125\n",
      "The representation loss after processing this batch is:  0.000112876296043396\n",
      "The classification loss after processing this batch is:  21528.06640625\n",
      "The representation loss after processing this batch is:  0.00011452101171016693\n",
      "The classification loss after processing this batch is:  21541.9375\n",
      "The representation loss after processing this batch is:  0.00010959059000015259\n",
      "The classification loss after processing this batch is:  22824.6171875\n",
      "The representation loss after processing this batch is:  9.896419942378998e-05\n",
      "The classification loss after processing this batch is:  24002.943359375\n",
      "The representation loss after processing this batch is:  0.00011930335313081741\n",
      "The classification loss after processing this batch is:  23064.6328125\n",
      "The representation loss after processing this batch is:  0.00011947937309741974\n",
      "The classification loss after processing this batch is:  22961.556640625\n",
      "The representation loss after processing this batch is:  0.00012561678886413574\n",
      "The classification loss after processing this batch is:  21400.5078125\n",
      "The representation loss after processing this batch is:  0.00010746810585260391\n",
      "The classification loss after processing this batch is:  21636.177734375\n",
      "The representation loss after processing this batch is:  9.377487003803253e-05\n",
      "The classification loss after processing this batch is:  22754.1640625\n",
      "The representation loss after processing this batch is:  0.00011040084064006805\n",
      "The classification loss after processing this batch is:  21194.8359375\n",
      "The representation loss after processing this batch is:  0.00012215040624141693\n",
      "The classification loss after processing this batch is:  21369.005859375\n",
      "The representation loss after processing this batch is:  9.753741323947906e-05\n",
      "The classification loss after processing this batch is:  22203.638671875\n",
      "The representation loss after processing this batch is:  0.00011585745960474014\n",
      "The classification loss after processing this batch is:  22131.228515625\n",
      "The representation loss after processing this batch is:  0.00010956451296806335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22016.08203125\n",
      "The representation loss after processing this batch is:  0.00010533444583415985\n",
      "The classification loss after processing this batch is:  21408.603515625\n",
      "The representation loss after processing this batch is:  0.00010248273611068726\n",
      "The classification loss after processing this batch is:  22565.4296875\n",
      "The representation loss after processing this batch is:  0.00012114178389310837\n",
      "The classification loss after processing this batch is:  22546.55078125\n",
      "The representation loss after processing this batch is:  0.00010894797742366791\n",
      "The classification loss after processing this batch is:  22917.7109375\n",
      "The representation loss after processing this batch is:  9.934790432453156e-05\n",
      "The classification loss after processing this batch is:  23152.177734375\n",
      "The representation loss after processing this batch is:  0.00012795347720384598\n",
      "The classification loss after processing this batch is:  22270.4453125\n",
      "The representation loss after processing this batch is:  0.00010251346975564957\n",
      "The classification loss after processing this batch is:  21375.208984375\n",
      "The representation loss after processing this batch is:  0.00011391285806894302\n",
      "The classification loss after processing this batch is:  21386.40234375\n",
      "The representation loss after processing this batch is:  0.00011670030653476715\n",
      "The classification loss after processing this batch is:  21129.8515625\n",
      "The representation loss after processing this batch is:  0.00010126177221536636\n",
      "The classification loss after processing this batch is:  21590.576171875\n",
      "The representation loss after processing this batch is:  0.00011334754526615143\n",
      "The classification loss after processing this batch is:  21077.24609375\n",
      "The representation loss after processing this batch is:  0.00011776573956012726\n",
      "The classification loss after processing this batch is:  21779.599609375\n",
      "The representation loss after processing this batch is:  0.0001009935513138771\n",
      "The classification loss after processing this batch is:  21420.203125\n",
      "The representation loss after processing this batch is:  0.0001035500317811966\n",
      "The classification loss after processing this batch is:  24990.8046875\n",
      "The representation loss after processing this batch is:  0.00012803450226783752\n",
      "The classification loss after processing this batch is:  23972.580078125\n",
      "The representation loss after processing this batch is:  0.00011034682393074036\n",
      "The classification loss after processing this batch is:  21637.587890625\n",
      "The representation loss after processing this batch is:  0.00010485295206308365\n",
      "The classification loss after processing this batch is:  20592.953125\n",
      "The representation loss after processing this batch is:  0.00012181047350168228\n",
      "The classification loss after processing this batch is:  20832.921875\n",
      "The representation loss after processing this batch is:  0.00011823326349258423\n",
      "The classification loss after processing this batch is:  21852.21484375\n",
      "The representation loss after processing this batch is:  0.00011693965643644333\n",
      "The classification loss after processing this batch is:  21350.35546875\n",
      "The representation loss after processing this batch is:  0.00011474359780550003\n",
      "The classification loss after processing this batch is:  22083.416015625\n",
      "The representation loss after processing this batch is:  9.879283607006073e-05\n",
      "The classification loss after processing this batch is:  21827.8828125\n",
      "The representation loss after processing this batch is:  0.00011734385043382645\n",
      "The classification loss after processing this batch is:  21020.765625\n",
      "The representation loss after processing this batch is:  9.909830987453461e-05\n",
      "The classification loss after processing this batch is:  20667.58203125\n",
      "The representation loss after processing this batch is:  0.00010365713387727737\n",
      "The classification loss after processing this batch is:  22016.646484375\n",
      "The representation loss after processing this batch is:  0.00010943971574306488\n",
      "The classification loss after processing this batch is:  22569.41796875\n",
      "The representation loss after processing this batch is:  0.00013187527656555176\n",
      "The classification loss after processing this batch is:  21389.08984375\n",
      "The representation loss after processing this batch is:  0.00010588206350803375\n",
      "The classification loss after processing this batch is:  22391.3125\n",
      "The representation loss after processing this batch is:  0.00011421553790569305\n",
      "The classification loss after processing this batch is:  23843.80078125\n",
      "The representation loss after processing this batch is:  0.00011426303535699844\n",
      "The classification loss after processing this batch is:  22833.84375\n",
      "The representation loss after processing this batch is:  0.0001081954687833786\n",
      "The classification loss after processing this batch is:  24101.787109375\n",
      "The representation loss after processing this batch is:  0.00010641198605298996\n",
      "The classification loss after processing this batch is:  21610.71875\n",
      "The representation loss after processing this batch is:  9.749550372362137e-05\n",
      "The classification loss after processing this batch is:  22546.10546875\n",
      "The representation loss after processing this batch is:  0.00012280046939849854\n",
      "The classification loss after processing this batch is:  21827.44140625\n",
      "The representation loss after processing this batch is:  0.00011065136641263962\n",
      "The classification loss after processing this batch is:  22347.3203125\n",
      "The representation loss after processing this batch is:  0.00010764040052890778\n",
      "The classification loss after processing this batch is:  21733.515625\n",
      "The representation loss after processing this batch is:  9.630434215068817e-05\n",
      "The classification loss after processing this batch is:  21692.884765625\n",
      "The representation loss after processing this batch is:  0.00010692514479160309\n",
      "The classification loss after processing this batch is:  22031.99609375\n",
      "The representation loss after processing this batch is:  0.0001090439036488533\n",
      "The classification loss after processing this batch is:  21361.62109375\n",
      "The representation loss after processing this batch is:  9.785126894712448e-05\n",
      "The classification loss after processing this batch is:  21706.9921875\n",
      "The representation loss after processing this batch is:  0.00011127069592475891\n",
      "The classification loss after processing this batch is:  20831.931640625\n",
      "The representation loss after processing this batch is:  0.00011026207357645035\n",
      "The classification loss after processing this batch is:  21034.470703125\n",
      "The representation loss after processing this batch is:  0.00010477844625711441\n",
      "The classification loss after processing this batch is:  20599.23046875\n",
      "The representation loss after processing this batch is:  9.747873991727829e-05\n",
      "The classification loss after processing this batch is:  22145.2734375\n",
      "The representation loss after processing this batch is:  0.0001072688028216362\n",
      "The classification loss after processing this batch is:  21436.119140625\n",
      "The representation loss after processing this batch is:  0.00011319760233163834\n",
      "The classification loss after processing this batch is:  22144.220703125\n",
      "The representation loss after processing this batch is:  0.00010945834219455719\n",
      "The classification loss after processing this batch is:  22504.86328125\n",
      "The representation loss after processing this batch is:  0.00010399892926216125\n",
      "The classification loss after processing this batch is:  21100.41796875\n",
      "The representation loss after processing this batch is:  8.763652294874191e-05\n",
      "The classification loss after processing this batch is:  22303.078125\n",
      "The representation loss after processing this batch is:  0.00010894611477851868\n",
      "The classification loss after processing this batch is:  21885.30078125\n",
      "The representation loss after processing this batch is:  0.00010795518755912781\n",
      "The classification loss after processing this batch is:  20930.271484375\n",
      "The representation loss after processing this batch is:  0.00010440964251756668\n",
      "The classification loss after processing this batch is:  21998.7421875\n",
      "The representation loss after processing this batch is:  0.00010251812636852264\n",
      "The classification loss after processing this batch is:  21673.3359375\n",
      "The representation loss after processing this batch is:  9.691249579191208e-05\n",
      "The classification loss after processing this batch is:  21105.578125\n",
      "The representation loss after processing this batch is:  9.828153997659683e-05\n",
      "The classification loss after processing this batch is:  21892.478515625\n",
      "The representation loss after processing this batch is:  9.592249989509583e-05\n",
      "The classification loss after processing this batch is:  21377.921875\n",
      "The representation loss after processing this batch is:  0.00011139921844005585\n",
      "The classification loss after processing this batch is:  22559.560546875\n",
      "The representation loss after processing this batch is:  0.0001124190166592598\n",
      "The classification loss after processing this batch is:  23264.6640625\n",
      "The representation loss after processing this batch is:  0.00010712817311286926\n",
      "The classification loss after processing this batch is:  21855.853515625\n",
      "The representation loss after processing this batch is:  0.00011756457388401031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  24151.45703125\n",
      "The representation loss after processing this batch is:  0.00011587142944335938\n",
      "The classification loss after processing this batch is:  24313.337890625\n",
      "The representation loss after processing this batch is:  0.00010284688323736191\n",
      "The classification loss after processing this batch is:  21631.470703125\n",
      "The representation loss after processing this batch is:  0.00010224990546703339\n",
      "The classification loss after processing this batch is:  22191.681640625\n",
      "The representation loss after processing this batch is:  0.00010479148477315903\n",
      "The classification loss after processing this batch is:  23192.12109375\n",
      "The representation loss after processing this batch is:  0.00011367909610271454\n",
      "The classification loss after processing this batch is:  21902.7109375\n",
      "The representation loss after processing this batch is:  0.00010551605373620987\n",
      "The classification loss after processing this batch is:  21747.896484375\n",
      "The representation loss after processing this batch is:  0.00011137127876281738\n",
      "The classification loss after processing this batch is:  21665.455078125\n",
      "The representation loss after processing this batch is:  0.00010612979531288147\n",
      "The classification loss after processing this batch is:  22063.201171875\n",
      "The representation loss after processing this batch is:  0.00012057367712259293\n",
      "The classification loss after processing this batch is:  22762.3203125\n",
      "The representation loss after processing this batch is:  0.00010744668543338776\n",
      "The classification loss after processing this batch is:  22521.87109375\n",
      "The representation loss after processing this batch is:  0.00011067558079957962\n",
      "The classification loss after processing this batch is:  24063.2109375\n",
      "The representation loss after processing this batch is:  0.00011844001710414886\n",
      "The classification loss after processing this batch is:  23051.72265625\n",
      "The representation loss after processing this batch is:  9.801611304283142e-05\n",
      "The classification loss after processing this batch is:  22986.9453125\n",
      "The representation loss after processing this batch is:  9.786523878574371e-05\n",
      "The classification loss after processing this batch is:  21216.65234375\n",
      "The representation loss after processing this batch is:  0.00010464340448379517\n",
      "The classification loss after processing this batch is:  21562.576171875\n",
      "The representation loss after processing this batch is:  9.6125528216362e-05\n",
      "The classification loss after processing this batch is:  22685.51171875\n",
      "The representation loss after processing this batch is:  0.00010962039232254028\n",
      "The classification loss after processing this batch is:  21326.30078125\n",
      "The representation loss after processing this batch is:  0.00010143127292394638\n",
      "The classification loss after processing this batch is:  20399.24609375\n",
      "The representation loss after processing this batch is:  0.00010661128908395767\n",
      "The classification loss after processing this batch is:  22888.578125\n",
      "The representation loss after processing this batch is:  9.615812450647354e-05\n",
      "The classification loss after processing this batch is:  21025.9921875\n",
      "The representation loss after processing this batch is:  9.824056178331375e-05\n",
      "The classification loss after processing this batch is:  21420.03515625\n",
      "The representation loss after processing this batch is:  0.00010863691568374634\n",
      "The classification loss after processing this batch is:  20539.1796875\n",
      "The representation loss after processing this batch is:  9.97418537735939e-05\n",
      "The classification loss after processing this batch is:  21564.4140625\n",
      "The representation loss after processing this batch is:  0.0001001264899969101\n",
      "The classification loss after processing this batch is:  20879.8671875\n",
      "The representation loss after processing this batch is:  9.430944919586182e-05\n",
      "The classification loss after processing this batch is:  22043.23046875\n",
      "The representation loss after processing this batch is:  0.00010793842375278473\n",
      "The classification loss after processing this batch is:  21591.330078125\n",
      "The representation loss after processing this batch is:  0.00010236259549856186\n",
      "The classification loss after processing this batch is:  21298.55859375\n",
      "The representation loss after processing this batch is:  0.0001027919352054596\n",
      "The classification loss after processing this batch is:  22223.84765625\n",
      "The representation loss after processing this batch is:  0.00010809581726789474\n",
      "The classification loss after processing this batch is:  22780.720703125\n",
      "The representation loss after processing this batch is:  0.0001013064756989479\n",
      "The classification loss after processing this batch is:  20900.34765625\n",
      "The representation loss after processing this batch is:  9.470712393522263e-05\n",
      "The classification loss after processing this batch is:  21208.529296875\n",
      "The representation loss after processing this batch is:  0.00010401662439107895\n",
      "The classification loss after processing this batch is:  21586.54296875\n",
      "The representation loss after processing this batch is:  0.0001019677147269249\n",
      "The classification loss after processing this batch is:  21394.146484375\n",
      "The representation loss after processing this batch is:  0.00010598357766866684\n",
      "The classification loss after processing this batch is:  22389.390625\n",
      "The representation loss after processing this batch is:  9.722262620925903e-05\n",
      "The classification loss after processing this batch is:  21124.86328125\n",
      "The representation loss after processing this batch is:  9.253434836864471e-05\n",
      "The classification loss after processing this batch is:  20581.0078125\n",
      "The representation loss after processing this batch is:  0.00011473894119262695\n",
      "The classification loss after processing this batch is:  21627.77734375\n",
      "The representation loss after processing this batch is:  0.00010867975652217865\n",
      "The classification loss after processing this batch is:  23671.1953125\n",
      "The representation loss after processing this batch is:  0.00012995954602956772\n",
      "The classification loss after processing this batch is:  21278.40234375\n",
      "The representation loss after processing this batch is:  8.888170123100281e-05\n",
      "The classification loss after processing this batch is:  22246.39453125\n",
      "The representation loss after processing this batch is:  9.615253657102585e-05\n",
      "The classification loss after processing this batch is:  23920.265625\n",
      "The representation loss after processing this batch is:  0.00010874960571527481\n",
      "The classification loss after processing this batch is:  21960.732421875\n",
      "The representation loss after processing this batch is:  0.00011205952614545822\n",
      "The classification loss after processing this batch is:  20925.77734375\n",
      "The representation loss after processing this batch is:  9.936466813087463e-05\n",
      "The classification loss after processing this batch is:  21373.796875\n",
      "The representation loss after processing this batch is:  0.00010653678327798843\n",
      "The classification loss after processing this batch is:  21276.474609375\n",
      "The representation loss after processing this batch is:  9.165052324533463e-05\n",
      "The classification loss after processing this batch is:  21840.525390625\n",
      "The representation loss after processing this batch is:  9.93870198726654e-05\n",
      "The classification loss after processing this batch is:  21258.220703125\n",
      "The representation loss after processing this batch is:  0.00012524425983428955\n",
      "The classification loss after processing this batch is:  21945.1640625\n",
      "The representation loss after processing this batch is:  9.249337017536163e-05\n",
      "The classification loss after processing this batch is:  24434.720703125\n",
      "The representation loss after processing this batch is:  0.00011977646499872208\n",
      "The classification loss after processing this batch is:  22993.6484375\n",
      "The representation loss after processing this batch is:  0.00010376889258623123\n",
      "The classification loss after processing this batch is:  22194.41796875\n",
      "The representation loss after processing this batch is:  0.00010354910045862198\n",
      "The classification loss after processing this batch is:  21425.12109375\n",
      "The representation loss after processing this batch is:  0.000105319544672966\n",
      "The classification loss after processing this batch is:  21925.67578125\n",
      "The representation loss after processing this batch is:  0.00011303182691335678\n",
      "The classification loss after processing this batch is:  22098.173828125\n",
      "The representation loss after processing this batch is:  0.00012830272316932678\n",
      "The classification loss after processing this batch is:  21476.64453125\n",
      "The representation loss after processing this batch is:  9.237043559551239e-05\n",
      "The classification loss after processing this batch is:  21019.677734375\n",
      "The representation loss after processing this batch is:  0.0001125335693359375\n",
      "The classification loss after processing this batch is:  21603.2890625\n",
      "The representation loss after processing this batch is:  0.00010165013372898102\n",
      "The classification loss after processing this batch is:  21516.34375\n",
      "The representation loss after processing this batch is:  9.94652509689331e-05\n",
      "The classification loss after processing this batch is:  20614.34765625\n",
      "The representation loss after processing this batch is:  0.00011728331446647644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21611.125\n",
      "The representation loss after processing this batch is:  9.894929826259613e-05\n",
      "The classification loss after processing this batch is:  20749.20703125\n",
      "The representation loss after processing this batch is:  0.00010910537093877792\n",
      "The classification loss after processing this batch is:  22960.966796875\n",
      "The representation loss after processing this batch is:  0.0001055477187037468\n",
      "The classification loss after processing this batch is:  22763.86328125\n",
      "The representation loss after processing this batch is:  9.223073720932007e-05\n",
      "The classification loss after processing this batch is:  21479.265625\n",
      "The representation loss after processing this batch is:  9.924732148647308e-05\n",
      "The classification loss after processing this batch is:  21789.830078125\n",
      "The representation loss after processing this batch is:  0.00010052695870399475\n",
      "The classification loss after processing this batch is:  21954.87109375\n",
      "The representation loss after processing this batch is:  9.648967534303665e-05\n",
      "The classification loss after processing this batch is:  23327.48828125\n",
      "The representation loss after processing this batch is:  0.00010340381413698196\n",
      "The classification loss after processing this batch is:  22659.814453125\n",
      "The representation loss after processing this batch is:  0.00010384060442447662\n",
      "The classification loss after processing this batch is:  21841.892578125\n",
      "The representation loss after processing this batch is:  9.489059448242188e-05\n",
      "The classification loss after processing this batch is:  22207.435546875\n",
      "The representation loss after processing this batch is:  0.00010033976286649704\n",
      "The classification loss after processing this batch is:  23639.55859375\n",
      "The representation loss after processing this batch is:  0.00010947324335575104\n",
      "The classification loss after processing this batch is:  21143.16796875\n",
      "The representation loss after processing this batch is:  0.0001004636287689209\n",
      "The classification loss after processing this batch is:  22154.3125\n",
      "The representation loss after processing this batch is:  9.519793093204498e-05\n",
      "The classification loss after processing this batch is:  22158.1640625\n",
      "The representation loss after processing this batch is:  0.00012933369725942612\n",
      "The classification loss after processing this batch is:  21807.72265625\n",
      "The representation loss after processing this batch is:  0.00010000914335250854\n",
      "The classification loss after processing this batch is:  22542.111328125\n",
      "The representation loss after processing this batch is:  0.00010679196566343307\n",
      "The classification loss after processing this batch is:  23126.646484375\n",
      "The representation loss after processing this batch is:  0.00011382065713405609\n",
      "The classification loss after processing this batch is:  21663.75390625\n",
      "The representation loss after processing this batch is:  0.00011583138257265091\n",
      "The classification loss after processing this batch is:  22497.970703125\n",
      "The representation loss after processing this batch is:  0.00010654609650373459\n",
      "The classification loss after processing this batch is:  22829.451171875\n",
      "The representation loss after processing this batch is:  9.51504334807396e-05\n",
      "The classification loss after processing this batch is:  21368.818359375\n",
      "The representation loss after processing this batch is:  0.00010537076741456985\n",
      "The classification loss after processing this batch is:  22470.921875\n",
      "The representation loss after processing this batch is:  0.000100722536444664\n",
      "The classification loss after processing this batch is:  22148.23046875\n",
      "The representation loss after processing this batch is:  0.00010812096297740936\n",
      "The classification loss after processing this batch is:  21238.357421875\n",
      "The representation loss after processing this batch is:  9.654369205236435e-05\n",
      "The classification loss after processing this batch is:  21438.423828125\n",
      "The representation loss after processing this batch is:  9.728502482175827e-05\n",
      "The classification loss after processing this batch is:  21319.931640625\n",
      "The representation loss after processing this batch is:  0.00010596588253974915\n",
      "The classification loss after processing this batch is:  21102.552734375\n",
      "The representation loss after processing this batch is:  0.00010022614151239395\n",
      "The classification loss after processing this batch is:  22902.818359375\n",
      "The representation loss after processing this batch is:  0.00010440684854984283\n",
      "The classification loss after processing this batch is:  22517.79296875\n",
      "The representation loss after processing this batch is:  9.821448475122452e-05\n",
      "The classification loss after processing this batch is:  23554.095703125\n",
      "The representation loss after processing this batch is:  0.00012011080980300903\n",
      "The classification loss after processing this batch is:  20691.396484375\n",
      "The representation loss after processing this batch is:  0.00010356493294239044\n",
      "The classification loss after processing this batch is:  21074.203125\n",
      "The representation loss after processing this batch is:  0.00010948348790407181\n",
      "The classification loss after processing this batch is:  21567.810546875\n",
      "The representation loss after processing this batch is:  0.00011379178613424301\n",
      "The classification loss after processing this batch is:  21263.04296875\n",
      "The representation loss after processing this batch is:  0.00010492466390132904\n",
      "The classification loss after processing this batch is:  22559.318359375\n",
      "The representation loss after processing this batch is:  0.00010336469858884811\n",
      "The classification loss after processing this batch is:  21453.140625\n",
      "The representation loss after processing this batch is:  9.139534085988998e-05\n",
      "The classification loss after processing this batch is:  21995.86328125\n",
      "The representation loss after processing this batch is:  0.00010080821812152863\n",
      "The classification loss after processing this batch is:  22060.84375\n",
      "The representation loss after processing this batch is:  0.00010479055345058441\n",
      "The classification loss after processing this batch is:  21145.9765625\n",
      "The representation loss after processing this batch is:  0.00010692514479160309\n",
      "The classification loss after processing this batch is:  23311.4140625\n",
      "The representation loss after processing this batch is:  0.00010751374065876007\n",
      "The classification loss after processing this batch is:  23418.29296875\n",
      "The representation loss after processing this batch is:  9.463261812925339e-05\n",
      "The classification loss after processing this batch is:  22565.78125\n",
      "The representation loss after processing this batch is:  0.00010248832404613495\n",
      "The classification loss after processing this batch is:  20943.224609375\n",
      "The representation loss after processing this batch is:  0.00011129863560199738\n",
      "The classification loss after processing this batch is:  22952.25\n",
      "The representation loss after processing this batch is:  0.00010665133595466614\n",
      "The classification loss after processing this batch is:  22561.41015625\n",
      "The representation loss after processing this batch is:  0.00010069180279970169\n",
      "The classification loss after processing this batch is:  21111.638671875\n",
      "The representation loss after processing this batch is:  8.493941277265549e-05\n",
      "The classification loss after processing this batch is:  23519.6484375\n",
      "The representation loss after processing this batch is:  0.00010322593152523041\n",
      "The classification loss after processing this batch is:  23312.1875\n",
      "The representation loss after processing this batch is:  0.0001360829919576645\n",
      "The classification loss after processing this batch is:  21074.65625\n",
      "The representation loss after processing this batch is:  9.000301361083984e-05\n",
      "The classification loss after processing this batch is:  21514.9296875\n",
      "The representation loss after processing this batch is:  0.00011079106479883194\n",
      "The classification loss after processing this batch is:  22033.978515625\n",
      "The representation loss after processing this batch is:  0.00011857040226459503\n",
      "The classification loss after processing this batch is:  21888.736328125\n",
      "The representation loss after processing this batch is:  0.00010819360613822937\n",
      "The classification loss after processing this batch is:  22607.62109375\n",
      "The representation loss after processing this batch is:  0.00011435896158218384\n",
      "The classification loss after processing this batch is:  23273.7421875\n",
      "The representation loss after processing this batch is:  0.000116690993309021\n",
      "The classification loss after processing this batch is:  21198.29296875\n",
      "The representation loss after processing this batch is:  0.00011288374662399292\n",
      "The classification loss after processing this batch is:  20768.1875\n",
      "The representation loss after processing this batch is:  0.00010473281145095825\n",
      "The classification loss after processing this batch is:  22167.0390625\n",
      "The representation loss after processing this batch is:  9.670853614807129e-05\n",
      "The classification loss after processing this batch is:  23264.47265625\n",
      "The representation loss after processing this batch is:  0.00011175032705068588\n",
      "The classification loss after processing this batch is:  21699.80078125\n",
      "The representation loss after processing this batch is:  9.382795542478561e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22372.896484375\n",
      "The representation loss after processing this batch is:  0.00010884925723075867\n",
      "The classification loss after processing this batch is:  21996.34375\n",
      "The representation loss after processing this batch is:  9.244587272405624e-05\n",
      "The classification loss after processing this batch is:  22219.708984375\n",
      "The representation loss after processing this batch is:  9.217020124197006e-05\n",
      "The classification loss after processing this batch is:  21801.1484375\n",
      "The representation loss after processing this batch is:  0.00010561477392911911\n",
      "The classification loss after processing this batch is:  21945.49609375\n",
      "The representation loss after processing this batch is:  0.00010971073061227798\n",
      "The classification loss after processing this batch is:  22993.728515625\n",
      "The representation loss after processing this batch is:  9.041279554367065e-05\n",
      "The classification loss after processing this batch is:  20939.587890625\n",
      "The representation loss after processing this batch is:  9.517930448055267e-05\n",
      "The classification loss after processing this batch is:  20821.32421875\n",
      "The representation loss after processing this batch is:  0.00010250229388475418\n",
      "The classification loss after processing this batch is:  20608.85546875\n",
      "The representation loss after processing this batch is:  0.0001065526157617569\n",
      "The classification loss after processing this batch is:  20756.244140625\n",
      "The representation loss after processing this batch is:  0.0001058550551533699\n",
      "The classification loss after processing this batch is:  21069.205078125\n",
      "The representation loss after processing this batch is:  0.00010378938168287277\n",
      "The classification loss after processing this batch is:  22231.76171875\n",
      "The representation loss after processing this batch is:  0.00011385232210159302\n",
      "The classification loss after processing this batch is:  22447.3828125\n",
      "The representation loss after processing this batch is:  0.00010732561349868774\n",
      "The classification loss after processing this batch is:  21014.224609375\n",
      "The representation loss after processing this batch is:  0.00010639708489179611\n",
      "The classification loss after processing this batch is:  20697.40234375\n",
      "The representation loss after processing this batch is:  9.50545072555542e-05\n",
      "The classification loss after processing this batch is:  21024.21484375\n",
      "The representation loss after processing this batch is:  0.00010319799184799194\n",
      "The classification loss after processing this batch is:  21629.08203125\n",
      "The representation loss after processing this batch is:  9.564682841300964e-05\n",
      "The classification loss after processing this batch is:  21673.6015625\n",
      "The representation loss after processing this batch is:  9.355228394269943e-05\n",
      "The classification loss after processing this batch is:  20953.259765625\n",
      "The representation loss after processing this batch is:  0.0001037251204252243\n",
      "The classification loss after processing this batch is:  23294.67578125\n",
      "The representation loss after processing this batch is:  9.048450738191605e-05\n",
      "The classification loss after processing this batch is:  21325.515625\n",
      "The representation loss after processing this batch is:  8.952245116233826e-05\n",
      "The classification loss after processing this batch is:  21008.658203125\n",
      "The representation loss after processing this batch is:  0.0001073768362402916\n",
      "The classification loss after processing this batch is:  21295.8046875\n",
      "The representation loss after processing this batch is:  9.893998503684998e-05\n",
      "The classification loss after processing this batch is:  21946.701171875\n",
      "The representation loss after processing this batch is:  0.00010932143777608871\n",
      "The classification loss after processing this batch is:  21518.4765625\n",
      "The representation loss after processing this batch is:  0.00010121334344148636\n",
      "The classification loss after processing this batch is:  20944.599609375\n",
      "The representation loss after processing this batch is:  0.00011394545435905457\n",
      "The classification loss after processing this batch is:  21656.4296875\n",
      "The representation loss after processing this batch is:  9.891297668218613e-05\n",
      "The classification loss after processing this batch is:  23223.0\n",
      "The representation loss after processing this batch is:  9.754765778779984e-05\n",
      "The classification loss after processing this batch is:  20627.98046875\n",
      "The representation loss after processing this batch is:  0.00010564364492893219\n",
      "The classification loss after processing this batch is:  21263.51171875\n",
      "The representation loss after processing this batch is:  0.00010410230606794357\n",
      "The classification loss after processing this batch is:  20152.119140625\n",
      "The representation loss after processing this batch is:  0.00011471100151538849\n",
      "The classification loss after processing this batch is:  21526.654296875\n",
      "The representation loss after processing this batch is:  9.623635560274124e-05\n",
      "The classification loss after processing this batch is:  21830.166015625\n",
      "The representation loss after processing this batch is:  0.00010298192501068115\n",
      "The classification loss after processing this batch is:  21157.625\n",
      "The representation loss after processing this batch is:  0.00010265037417411804\n",
      "The classification loss after processing this batch is:  20883.8515625\n",
      "The representation loss after processing this batch is:  0.00011925771832466125\n",
      "The classification loss after processing this batch is:  20482.0703125\n",
      "The representation loss after processing this batch is:  0.00010449904948472977\n",
      "The classification loss after processing this batch is:  21740.4140625\n",
      "The representation loss after processing this batch is:  0.00010121334344148636\n",
      "The classification loss after processing this batch is:  21308.09765625\n",
      "The representation loss after processing this batch is:  9.838026016950607e-05\n",
      "The classification loss after processing this batch is:  20640.69921875\n",
      "The representation loss after processing this batch is:  0.0001201629638671875\n",
      "The classification loss after processing this batch is:  24520.927734375\n",
      "The representation loss after processing this batch is:  0.00010293908417224884\n",
      "The classification loss after processing this batch is:  23004.0234375\n",
      "The representation loss after processing this batch is:  0.00010189693421125412\n",
      "The classification loss after processing this batch is:  22068.15625\n",
      "The representation loss after processing this batch is:  0.00010416191071271896\n",
      "The classification loss after processing this batch is:  21598.654296875\n",
      "The representation loss after processing this batch is:  0.00010013580322265625\n",
      "The classification loss after processing this batch is:  20886.01171875\n",
      "The representation loss after processing this batch is:  0.0001253373920917511\n",
      "The classification loss after processing this batch is:  21568.935546875\n",
      "The representation loss after processing this batch is:  9.80747863650322e-05\n",
      "The classification loss after processing this batch is:  22245.9765625\n",
      "The representation loss after processing this batch is:  0.00010152813047170639\n",
      "The classification loss after processing this batch is:  21353.99609375\n",
      "The representation loss after processing this batch is:  9.772740304470062e-05\n",
      "The classification loss after processing this batch is:  23542.275390625\n",
      "The representation loss after processing this batch is:  0.00011990312486886978\n",
      "The classification loss after processing this batch is:  21538.28515625\n",
      "The representation loss after processing this batch is:  0.00011165253818035126\n",
      "The classification loss after processing this batch is:  20871.34375\n",
      "The representation loss after processing this batch is:  0.0001033581793308258\n",
      "The classification loss after processing this batch is:  22910.06640625\n",
      "The representation loss after processing this batch is:  0.00011493079364299774\n",
      "The classification loss after processing this batch is:  20883.09765625\n",
      "The representation loss after processing this batch is:  0.00010300520807504654\n",
      "The classification loss after processing this batch is:  21317.642578125\n",
      "The representation loss after processing this batch is:  0.00010243058204650879\n",
      "The classification loss after processing this batch is:  24760.796875\n",
      "The representation loss after processing this batch is:  0.00011838413774967194\n",
      "The classification loss after processing this batch is:  22575.517578125\n",
      "The representation loss after processing this batch is:  0.00012970343232154846\n",
      "The classification loss after processing this batch is:  21143.443359375\n",
      "The representation loss after processing this batch is:  0.0001214928925037384\n",
      "The classification loss after processing this batch is:  21456.29296875\n",
      "The representation loss after processing this batch is:  0.00016063638031482697\n",
      "The classification loss after processing this batch is:  23504.546875\n",
      "The representation loss after processing this batch is:  0.00011636875569820404\n",
      "The classification loss after processing this batch is:  20801.984375\n",
      "The representation loss after processing this batch is:  0.00011286884546279907\n",
      "The classification loss after processing this batch is:  21345.92578125\n",
      "The representation loss after processing this batch is:  0.00014998018741607666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22230.07421875\n",
      "The representation loss after processing this batch is:  0.00013671629130840302\n",
      "The classification loss after processing this batch is:  26247.41015625\n",
      "The representation loss after processing this batch is:  0.00012495648115873337\n",
      "The classification loss after processing this batch is:  28917.94921875\n",
      "The representation loss after processing this batch is:  0.00012167543172836304\n",
      "The classification loss after processing this batch is:  20868.06640625\n",
      "The representation loss after processing this batch is:  0.00011657271534204483\n",
      "The classification loss after processing this batch is:  22054.330078125\n",
      "The representation loss after processing this batch is:  0.0001284303143620491\n",
      "The classification loss after processing this batch is:  22238.888671875\n",
      "The representation loss after processing this batch is:  0.00011660344898700714\n",
      "The classification loss after processing this batch is:  20313.25\n",
      "The representation loss after processing this batch is:  0.00010739453136920929\n",
      "The classification loss after processing this batch is:  21950.46875\n",
      "The representation loss after processing this batch is:  0.00011931266635656357\n",
      "The classification loss after processing this batch is:  22489.30859375\n",
      "The representation loss after processing this batch is:  0.0001163063570857048\n",
      "The classification loss after processing this batch is:  21481.625\n",
      "The representation loss after processing this batch is:  0.00014848075807094574\n",
      "The classification loss after processing this batch is:  21740.134765625\n",
      "The representation loss after processing this batch is:  0.00013014115393161774\n",
      "The classification loss after processing this batch is:  21608.701171875\n",
      "The representation loss after processing this batch is:  0.00013548322021961212\n",
      "The classification loss after processing this batch is:  21214.81640625\n",
      "The representation loss after processing this batch is:  0.00011805351823568344\n",
      "The classification loss after processing this batch is:  21384.3828125\n",
      "The representation loss after processing this batch is:  0.00012010056525468826\n",
      "The classification loss after processing this batch is:  21613.2109375\n",
      "The representation loss after processing this batch is:  0.00012320280075073242\n",
      "The classification loss after processing this batch is:  21447.298828125\n",
      "The representation loss after processing this batch is:  0.00013912655413150787\n",
      "The classification loss after processing this batch is:  24611.56640625\n",
      "The representation loss after processing this batch is:  0.0001287003979086876\n",
      "The classification loss after processing this batch is:  24040.68359375\n",
      "The representation loss after processing this batch is:  0.00012002512812614441\n",
      "The classification loss after processing this batch is:  21448.36328125\n",
      "The representation loss after processing this batch is:  0.00012514740228652954\n",
      "The classification loss after processing this batch is:  21315.671875\n",
      "The representation loss after processing this batch is:  0.0001262575387954712\n",
      "The classification loss after processing this batch is:  21051.859375\n",
      "The representation loss after processing this batch is:  0.00012784823775291443\n",
      "The classification loss after processing this batch is:  21129.484375\n",
      "The representation loss after processing this batch is:  0.0001206565648317337\n",
      "The classification loss after processing this batch is:  22099.6875\n",
      "The representation loss after processing this batch is:  0.00012182816863059998\n",
      "The classification loss after processing this batch is:  21319.404296875\n",
      "The representation loss after processing this batch is:  0.00011138804256916046\n",
      "The classification loss after processing this batch is:  22968.4609375\n",
      "The representation loss after processing this batch is:  0.0001260600984096527\n",
      "The classification loss after processing this batch is:  21946.826171875\n",
      "The representation loss after processing this batch is:  0.00011819601058959961\n",
      "The classification loss after processing this batch is:  22381.82421875\n",
      "The representation loss after processing this batch is:  0.00012542679905891418\n",
      "The classification loss after processing this batch is:  21799.28515625\n",
      "The representation loss after processing this batch is:  0.00012463610619306564\n",
      "The classification loss after processing this batch is:  21714.90234375\n",
      "The representation loss after processing this batch is:  0.0001180153340101242\n",
      "The classification loss after processing this batch is:  21917.87109375\n",
      "The representation loss after processing this batch is:  0.00012207496911287308\n",
      "The classification loss after processing this batch is:  21737.017578125\n",
      "The representation loss after processing this batch is:  0.0001114988699555397\n",
      "The classification loss after processing this batch is:  21929.08984375\n",
      "The representation loss after processing this batch is:  0.00012077018618583679\n",
      "The classification loss after processing this batch is:  21102.470703125\n",
      "The representation loss after processing this batch is:  0.00014244765043258667\n",
      "The classification loss after processing this batch is:  21294.810546875\n",
      "The representation loss after processing this batch is:  0.00011354498565196991\n",
      "The classification loss after processing this batch is:  21163.900390625\n",
      "The representation loss after processing this batch is:  0.00011904537677764893\n",
      "The classification loss after processing this batch is:  23812.25390625\n",
      "The representation loss after processing this batch is:  0.00011484324932098389\n",
      "The classification loss after processing this batch is:  22583.2578125\n",
      "The representation loss after processing this batch is:  0.00012074876576662064\n",
      "The classification loss after processing this batch is:  21223.22265625\n",
      "The representation loss after processing this batch is:  0.00011303648352622986\n",
      "The classification loss after processing this batch is:  21550.173828125\n",
      "The representation loss after processing this batch is:  0.00011687632650136948\n",
      "The classification loss after processing this batch is:  20752.431640625\n",
      "The representation loss after processing this batch is:  0.00011128466576337814\n",
      "The classification loss after processing this batch is:  21311.44921875\n",
      "The representation loss after processing this batch is:  0.00010255351662635803\n",
      "The classification loss after processing this batch is:  21601.724609375\n",
      "The representation loss after processing this batch is:  0.00010874681174755096\n",
      "The classification loss after processing this batch is:  22111.59765625\n",
      "The representation loss after processing this batch is:  0.00011587236076593399\n",
      "The classification loss after processing this batch is:  23333.341796875\n",
      "The representation loss after processing this batch is:  0.000113731250166893\n",
      "The classification loss after processing this batch is:  26987.625\n",
      "The representation loss after processing this batch is:  0.00014876481145620346\n",
      "The classification loss after processing this batch is:  21883.53125\n",
      "The representation loss after processing this batch is:  0.00012210290879011154\n",
      "The classification loss after processing this batch is:  22336.310546875\n",
      "The representation loss after processing this batch is:  0.00012874417006969452\n",
      "The classification loss after processing this batch is:  22532.5\n",
      "The representation loss after processing this batch is:  0.00012938305735588074\n",
      "The classification loss after processing this batch is:  22698.345703125\n",
      "The representation loss after processing this batch is:  0.00010826531797647476\n",
      "The classification loss after processing this batch is:  22583.44140625\n",
      "The representation loss after processing this batch is:  0.00010970234870910645\n",
      "The classification loss after processing this batch is:  22821.40234375\n",
      "The representation loss after processing this batch is:  0.00013469066470861435\n",
      "The classification loss after processing this batch is:  22465.603515625\n",
      "The representation loss after processing this batch is:  0.00011080782860517502\n",
      "The classification loss after processing this batch is:  22591.591796875\n",
      "The representation loss after processing this batch is:  0.00012021511793136597\n",
      "The classification loss after processing this batch is:  22263.787109375\n",
      "The representation loss after processing this batch is:  0.00011556688696146011\n",
      "The classification loss after processing this batch is:  22198.90234375\n",
      "The representation loss after processing this batch is:  0.00011398456990718842\n",
      "The classification loss after processing this batch is:  21881.4921875\n",
      "The representation loss after processing this batch is:  0.0001134360209107399\n",
      "The classification loss after processing this batch is:  21507.328125\n",
      "The representation loss after processing this batch is:  0.00011952407658100128\n",
      "The classification loss after processing this batch is:  21694.97265625\n",
      "The representation loss after processing this batch is:  0.00010614469647407532\n",
      "The classification loss after processing this batch is:  20671.5078125\n",
      "The representation loss after processing this batch is:  0.0001158732920885086\n",
      "The classification loss after processing this batch is:  21570.533203125\n",
      "The representation loss after processing this batch is:  0.00015510618686676025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22016.57421875\n",
      "The representation loss after processing this batch is:  0.00012046005576848984\n",
      "The classification loss after processing this batch is:  22057.640625\n",
      "The representation loss after processing this batch is:  0.0001202654093503952\n",
      "The classification loss after processing this batch is:  21418.6171875\n",
      "The representation loss after processing this batch is:  0.00011982955038547516\n",
      "The classification loss after processing this batch is:  22909.9453125\n",
      "The representation loss after processing this batch is:  0.00012245401740074158\n",
      "The classification loss after processing this batch is:  21705.12890625\n",
      "The representation loss after processing this batch is:  0.00012891646474599838\n",
      "The classification loss after processing this batch is:  21586.0859375\n",
      "The representation loss after processing this batch is:  0.0001243390142917633\n",
      "The classification loss after processing this batch is:  21873.34765625\n",
      "The representation loss after processing this batch is:  0.0001266486942768097\n",
      "The classification loss after processing this batch is:  23061.234375\n",
      "The representation loss after processing this batch is:  0.00011833198368549347\n",
      "The classification loss after processing this batch is:  23975.36328125\n",
      "The representation loss after processing this batch is:  0.00011870265007019043\n",
      "The classification loss after processing this batch is:  23328.8828125\n",
      "The representation loss after processing this batch is:  0.00011375732719898224\n",
      "The classification loss after processing this batch is:  20814.626953125\n",
      "The representation loss after processing this batch is:  0.00011713244020938873\n",
      "The classification loss after processing this batch is:  22342.0625\n",
      "The representation loss after processing this batch is:  0.00011592917144298553\n",
      "The classification loss after processing this batch is:  21626.0\n",
      "The representation loss after processing this batch is:  0.00011913571506738663\n",
      "The classification loss after processing this batch is:  23182.15625\n",
      "The representation loss after processing this batch is:  0.00013867393136024475\n",
      "The classification loss after processing this batch is:  23181.17578125\n",
      "The representation loss after processing this batch is:  0.00012126192450523376\n",
      "The classification loss after processing this batch is:  21856.5703125\n",
      "The representation loss after processing this batch is:  0.00010708440095186234\n",
      "The classification loss after processing this batch is:  22124.017578125\n",
      "The representation loss after processing this batch is:  0.00011166557669639587\n",
      "The classification loss after processing this batch is:  22381.421875\n",
      "The representation loss after processing this batch is:  0.00011625140905380249\n",
      "The classification loss after processing this batch is:  23179.9453125\n",
      "The representation loss after processing this batch is:  0.00013038888573646545\n",
      "The classification loss after processing this batch is:  21969.630859375\n",
      "The representation loss after processing this batch is:  0.00011815875768661499\n",
      "The classification loss after processing this batch is:  22732.82421875\n",
      "The representation loss after processing this batch is:  0.00011273473501205444\n",
      "The classification loss after processing this batch is:  23114.666015625\n",
      "The representation loss after processing this batch is:  0.00013901200145483017\n",
      "The classification loss after processing this batch is:  23655.3046875\n",
      "The representation loss after processing this batch is:  0.00013549812138080597\n",
      "The classification loss after processing this batch is:  21872.0\n",
      "The representation loss after processing this batch is:  0.00011400505900382996\n",
      "The classification loss after processing this batch is:  21880.787109375\n",
      "The representation loss after processing this batch is:  0.00011405814439058304\n",
      "The classification loss after processing this batch is:  21738.5234375\n",
      "The representation loss after processing this batch is:  0.00010921619832515717\n",
      "The classification loss after processing this batch is:  23374.54296875\n",
      "The representation loss after processing this batch is:  0.00012133084237575531\n",
      "The classification loss after processing this batch is:  23994.7890625\n",
      "The representation loss after processing this batch is:  0.00011963490396738052\n",
      "The classification loss after processing this batch is:  22250.609375\n",
      "The representation loss after processing this batch is:  0.00012353062629699707\n",
      "The classification loss after processing this batch is:  21379.546875\n",
      "The representation loss after processing this batch is:  0.00011431891471147537\n",
      "The classification loss after processing this batch is:  21649.03515625\n",
      "The representation loss after processing this batch is:  0.00012199580669403076\n",
      "The classification loss after processing this batch is:  20944.83203125\n",
      "The representation loss after processing this batch is:  0.00011236220598220825\n",
      "The classification loss after processing this batch is:  21576.2421875\n",
      "The representation loss after processing this batch is:  0.00011037196964025497\n",
      "The classification loss after processing this batch is:  21475.74609375\n",
      "The representation loss after processing this batch is:  0.00011315289884805679\n",
      "The classification loss after processing this batch is:  21527.658203125\n",
      "The representation loss after processing this batch is:  0.00011630542576313019\n",
      "The classification loss after processing this batch is:  21292.66796875\n",
      "The representation loss after processing this batch is:  0.00012000557035207748\n",
      "The classification loss after processing this batch is:  21206.087890625\n",
      "The representation loss after processing this batch is:  0.00011622905731201172\n",
      "The classification loss after processing this batch is:  21322.60546875\n",
      "The representation loss after processing this batch is:  0.0001193629577755928\n",
      "The classification loss after processing this batch is:  20957.751953125\n",
      "The representation loss after processing this batch is:  0.00011457689106464386\n",
      "The classification loss after processing this batch is:  21179.119140625\n",
      "The representation loss after processing this batch is:  0.0001183515414595604\n",
      "The classification loss after processing this batch is:  21370.978515625\n",
      "The representation loss after processing this batch is:  0.00011653918772935867\n",
      "The classification loss after processing this batch is:  20814.98828125\n",
      "The representation loss after processing this batch is:  0.0001185266301035881\n",
      "The classification loss after processing this batch is:  22692.935546875\n",
      "The representation loss after processing this batch is:  0.00010005198419094086\n",
      "The classification loss after processing this batch is:  22587.451171875\n",
      "The representation loss after processing this batch is:  0.00010826531797647476\n",
      "The classification loss after processing this batch is:  23181.08984375\n",
      "The representation loss after processing this batch is:  0.00010845251381397247\n",
      "The classification loss after processing this batch is:  23740.59765625\n",
      "The representation loss after processing this batch is:  0.00011778157204389572\n",
      "The classification loss after processing this batch is:  23509.85546875\n",
      "The representation loss after processing this batch is:  0.00011056941002607346\n",
      "The classification loss after processing this batch is:  22738.90234375\n",
      "The representation loss after processing this batch is:  0.00012220162898302078\n",
      "The classification loss after processing this batch is:  22632.13671875\n",
      "The representation loss after processing this batch is:  0.00012490153312683105\n",
      "The classification loss after processing this batch is:  22275.66015625\n",
      "The representation loss after processing this batch is:  0.00011778995394706726\n",
      "The classification loss after processing this batch is:  22476.501953125\n",
      "The representation loss after processing this batch is:  0.00010944809764623642\n",
      "The classification loss after processing this batch is:  22063.78515625\n",
      "The representation loss after processing this batch is:  0.00011300947517156601\n",
      "The classification loss after processing this batch is:  21568.671875\n",
      "The representation loss after processing this batch is:  0.00011216755956411362\n",
      "The classification loss after processing this batch is:  22819.6640625\n",
      "The representation loss after processing this batch is:  0.00011082645505666733\n",
      "The classification loss after processing this batch is:  22672.359375\n",
      "The representation loss after processing this batch is:  0.00013227574527263641\n",
      "The classification loss after processing this batch is:  21930.30078125\n",
      "The representation loss after processing this batch is:  0.00010925717651844025\n",
      "The classification loss after processing this batch is:  22981.359375\n",
      "The representation loss after processing this batch is:  0.00011886097490787506\n",
      "The classification loss after processing this batch is:  25135.501953125\n",
      "The representation loss after processing this batch is:  0.00013113580644130707\n",
      "The classification loss after processing this batch is:  23282.9609375\n",
      "The representation loss after processing this batch is:  0.00011012330651283264\n",
      "The classification loss after processing this batch is:  21630.33984375\n",
      "The representation loss after processing this batch is:  0.00010331720113754272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22003.380859375\n",
      "The representation loss after processing this batch is:  0.0001313295215368271\n",
      "The classification loss after processing this batch is:  25924.0234375\n",
      "The representation loss after processing this batch is:  0.00011656992137432098\n",
      "The classification loss after processing this batch is:  26000.931640625\n",
      "The representation loss after processing this batch is:  0.00012782588601112366\n",
      "The classification loss after processing this batch is:  21737.48828125\n",
      "The representation loss after processing this batch is:  0.0001213178038597107\n",
      "The classification loss after processing this batch is:  21158.65234375\n",
      "The representation loss after processing this batch is:  0.00012417137622833252\n",
      "The classification loss after processing this batch is:  21787.267578125\n",
      "The representation loss after processing this batch is:  0.00011437200009822845\n",
      "The classification loss after processing this batch is:  22612.51171875\n",
      "The representation loss after processing this batch is:  0.00011142529547214508\n",
      "The classification loss after processing this batch is:  22379.544921875\n",
      "The representation loss after processing this batch is:  0.00010325107723474503\n",
      "The classification loss after processing this batch is:  22232.126953125\n",
      "The representation loss after processing this batch is:  0.00011965818703174591\n",
      "The classification loss after processing this batch is:  23179.607421875\n",
      "The representation loss after processing this batch is:  0.00010134093463420868\n",
      "The classification loss after processing this batch is:  24045.140625\n",
      "The representation loss after processing this batch is:  0.00011296384036540985\n",
      "The classification loss after processing this batch is:  21701.72265625\n",
      "The representation loss after processing this batch is:  0.00012878607958555222\n",
      "The classification loss after processing this batch is:  22477.68359375\n",
      "The representation loss after processing this batch is:  0.00012039393186569214\n",
      "The classification loss after processing this batch is:  21286.43359375\n",
      "The representation loss after processing this batch is:  0.00011443533003330231\n",
      "The classification loss after processing this batch is:  21416.33203125\n",
      "The representation loss after processing this batch is:  0.00013960711658000946\n",
      "The classification loss after processing this batch is:  20746.74609375\n",
      "The representation loss after processing this batch is:  0.00011665001511573792\n",
      "The classification loss after processing this batch is:  22245.802734375\n",
      "The representation loss after processing this batch is:  0.00013165920972824097\n",
      "The classification loss after processing this batch is:  21853.10546875\n",
      "The representation loss after processing this batch is:  0.00011518411338329315\n",
      "The classification loss after processing this batch is:  23657.828125\n",
      "The representation loss after processing this batch is:  0.00011743232607841492\n",
      "The classification loss after processing this batch is:  21690.822265625\n",
      "The representation loss after processing this batch is:  0.00012077111750841141\n",
      "The classification loss after processing this batch is:  21849.33984375\n",
      "The representation loss after processing this batch is:  0.00010989606380462646\n",
      "The classification loss after processing this batch is:  23063.154296875\n",
      "The representation loss after processing this batch is:  0.00012353993952274323\n",
      "The classification loss after processing this batch is:  22691.087890625\n",
      "The representation loss after processing this batch is:  0.00010581966489553452\n",
      "The classification loss after processing this batch is:  21999.322265625\n",
      "The representation loss after processing this batch is:  0.00012301839888095856\n",
      "The classification loss after processing this batch is:  23494.80078125\n",
      "The representation loss after processing this batch is:  0.00011323206126689911\n",
      "The classification loss after processing this batch is:  21878.849609375\n",
      "The representation loss after processing this batch is:  0.0001164022833108902\n",
      "The classification loss after processing this batch is:  22713.544921875\n",
      "The representation loss after processing this batch is:  0.0001305127516388893\n",
      "The classification loss after processing this batch is:  21154.6953125\n",
      "The representation loss after processing this batch is:  9.718630462884903e-05\n",
      "The classification loss after processing this batch is:  21413.0859375\n",
      "The representation loss after processing this batch is:  0.00011817831546068192\n",
      "The classification loss after processing this batch is:  21619.658203125\n",
      "The representation loss after processing this batch is:  0.0001211315393447876\n",
      "The classification loss after processing this batch is:  21366.08203125\n",
      "The representation loss after processing this batch is:  0.00012547243386507034\n",
      "The classification loss after processing this batch is:  21155.1171875\n",
      "The representation loss after processing this batch is:  0.00012496206909418106\n",
      "The classification loss after processing this batch is:  23931.435546875\n",
      "The representation loss after processing this batch is:  0.0001216735690832138\n",
      "The classification loss after processing this batch is:  21373.076171875\n",
      "The representation loss after processing this batch is:  0.00011786259710788727\n",
      "The classification loss after processing this batch is:  21834.2421875\n",
      "The representation loss after processing this batch is:  0.00010460428893566132\n",
      "The classification loss after processing this batch is:  22572.03515625\n",
      "The representation loss after processing this batch is:  0.00012134108692407608\n",
      "The classification loss after processing this batch is:  21904.06640625\n",
      "The representation loss after processing this batch is:  0.00011418573558330536\n",
      "The classification loss after processing this batch is:  22549.044921875\n",
      "The representation loss after processing this batch is:  0.00011226162314414978\n",
      "The classification loss after processing this batch is:  22262.4765625\n",
      "The representation loss after processing this batch is:  0.00010738242417573929\n",
      "The classification loss after processing this batch is:  21822.15234375\n",
      "The representation loss after processing this batch is:  0.00011025462299585342\n",
      "The classification loss after processing this batch is:  20545.94921875\n",
      "The representation loss after processing this batch is:  0.00011097174137830734\n",
      "The classification loss after processing this batch is:  22189.41796875\n",
      "The representation loss after processing this batch is:  0.00011652708053588867\n",
      "The classification loss after processing this batch is:  24665.52734375\n",
      "The representation loss after processing this batch is:  0.0001146513968706131\n",
      "The classification loss after processing this batch is:  25048.76171875\n",
      "The representation loss after processing this batch is:  0.00012075714766979218\n",
      "The classification loss after processing this batch is:  22014.359375\n",
      "The representation loss after processing this batch is:  0.00010358262807130814\n",
      "The classification loss after processing this batch is:  21969.39453125\n",
      "The representation loss after processing this batch is:  0.00011169817298650742\n",
      "The classification loss after processing this batch is:  21873.9765625\n",
      "The representation loss after processing this batch is:  0.00010166782885789871\n",
      "The classification loss after processing this batch is:  22887.30859375\n",
      "The representation loss after processing this batch is:  0.00011603068560361862\n",
      "The classification loss after processing this batch is:  21896.310546875\n",
      "The representation loss after processing this batch is:  0.00012630876153707504\n",
      "The classification loss after processing this batch is:  22304.236328125\n",
      "The representation loss after processing this batch is:  0.00011079106479883194\n",
      "The classification loss after processing this batch is:  23531.76953125\n",
      "The representation loss after processing this batch is:  0.00011785980314016342\n",
      "The classification loss after processing this batch is:  20876.837890625\n",
      "The representation loss after processing this batch is:  0.00010764226317405701\n",
      "The classification loss after processing this batch is:  21333.30859375\n",
      "The representation loss after processing this batch is:  0.00010284222662448883\n",
      "The classification loss after processing this batch is:  23550.171875\n",
      "The representation loss after processing this batch is:  0.00013257376849651337\n",
      "The classification loss after processing this batch is:  22250.943359375\n",
      "The representation loss after processing this batch is:  0.00012374483048915863\n",
      "The classification loss after processing this batch is:  21730.45703125\n",
      "The representation loss after processing this batch is:  0.00011442042887210846\n",
      "The classification loss after processing this batch is:  20725.8984375\n",
      "The representation loss after processing this batch is:  0.00011960510164499283\n",
      "The classification loss after processing this batch is:  23523.009765625\n",
      "The representation loss after processing this batch is:  0.00013831444084644318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22952.015625\n",
      "The representation loss after processing this batch is:  0.00012044049799442291\n",
      "The classification loss after processing this batch is:  27725.7265625\n",
      "The representation loss after processing this batch is:  0.00011382065713405609\n",
      "The classification loss after processing this batch is:  23426.11328125\n",
      "The representation loss after processing this batch is:  0.00010519195348024368\n",
      "The classification loss after processing this batch is:  22062.67578125\n",
      "The representation loss after processing this batch is:  0.00012571737170219421\n",
      "The classification loss after processing this batch is:  23431.25\n",
      "The representation loss after processing this batch is:  0.00011018477380275726\n",
      "The classification loss after processing this batch is:  24596.5234375\n",
      "The representation loss after processing this batch is:  0.00013765040785074234\n",
      "The classification loss after processing this batch is:  23638.935546875\n",
      "The representation loss after processing this batch is:  0.00011968892067670822\n",
      "The classification loss after processing this batch is:  22883.828125\n",
      "The representation loss after processing this batch is:  0.00010933633893728256\n",
      "The classification loss after processing this batch is:  22840.728515625\n",
      "The representation loss after processing this batch is:  9.850598871707916e-05\n",
      "The classification loss after processing this batch is:  22773.765625\n",
      "The representation loss after processing this batch is:  0.00011428631842136383\n",
      "The classification loss after processing this batch is:  21864.755859375\n",
      "The representation loss after processing this batch is:  0.00012332946062088013\n",
      "The classification loss after processing this batch is:  22847.34765625\n",
      "The representation loss after processing this batch is:  0.00011024158447980881\n",
      "The classification loss after processing this batch is:  22647.1328125\n",
      "The representation loss after processing this batch is:  0.00010845623910427094\n",
      "The classification loss after processing this batch is:  22911.52734375\n",
      "The representation loss after processing this batch is:  0.00010985508561134338\n",
      "The classification loss after processing this batch is:  22888.419921875\n",
      "The representation loss after processing this batch is:  0.00010607205331325531\n",
      "The classification loss after processing this batch is:  23227.81640625\n",
      "The representation loss after processing this batch is:  0.00011439993977546692\n",
      "The classification loss after processing this batch is:  21461.623046875\n",
      "The representation loss after processing this batch is:  0.000126582570374012\n",
      "The classification loss after processing this batch is:  21105.609375\n",
      "The representation loss after processing this batch is:  0.00013121776282787323\n",
      "The classification loss after processing this batch is:  21269.7890625\n",
      "The representation loss after processing this batch is:  0.0001149885356426239\n",
      "The classification loss after processing this batch is:  21150.798828125\n",
      "The representation loss after processing this batch is:  0.00010782014578580856\n",
      "The classification loss after processing this batch is:  23022.0234375\n",
      "The representation loss after processing this batch is:  0.00010821130126714706\n",
      "The classification loss after processing this batch is:  22390.92578125\n",
      "The representation loss after processing this batch is:  0.00010564085096120834\n",
      "The classification loss after processing this batch is:  21517.419921875\n",
      "The representation loss after processing this batch is:  0.00013099052011966705\n",
      "The classification loss after processing this batch is:  20301.416015625\n",
      "The representation loss after processing this batch is:  0.00011564604938030243\n",
      "The classification loss after processing this batch is:  20566.134765625\n",
      "The representation loss after processing this batch is:  0.000115223228931427\n",
      "The classification loss after processing this batch is:  22313.55859375\n",
      "The representation loss after processing this batch is:  0.0001055058091878891\n",
      "The classification loss after processing this batch is:  22967.591796875\n",
      "The representation loss after processing this batch is:  0.00010684784501791\n",
      "The classification loss after processing this batch is:  23133.90625\n",
      "The representation loss after processing this batch is:  0.00013768672943115234\n",
      "The classification loss after processing this batch is:  21068.85546875\n",
      "The representation loss after processing this batch is:  0.00012542027980089188\n",
      "The classification loss after processing this batch is:  22059.576171875\n",
      "The representation loss after processing this batch is:  0.00012352783232927322\n",
      "The classification loss after processing this batch is:  21272.28125\n",
      "The representation loss after processing this batch is:  0.00012166053056716919\n",
      "The classification loss after processing this batch is:  21918.32421875\n",
      "The representation loss after processing this batch is:  0.00013568997383117676\n",
      "The classification loss after processing this batch is:  21066.6328125\n",
      "The representation loss after processing this batch is:  0.00010874494910240173\n",
      "The classification loss after processing this batch is:  20793.10546875\n",
      "The representation loss after processing this batch is:  0.00013010669499635696\n",
      "The classification loss after processing this batch is:  20975.5546875\n",
      "The representation loss after processing this batch is:  0.0001227930188179016\n",
      "The classification loss after processing this batch is:  21823.83203125\n",
      "The representation loss after processing this batch is:  0.00012255460023880005\n",
      "The classification loss after processing this batch is:  21992.666015625\n",
      "The representation loss after processing this batch is:  0.00013086572289466858\n",
      "The classification loss after processing this batch is:  22152.76171875\n",
      "The representation loss after processing this batch is:  0.00012659654021263123\n",
      "The classification loss after processing this batch is:  21742.865234375\n",
      "The representation loss after processing this batch is:  0.00012540258467197418\n",
      "The classification loss after processing this batch is:  21791.931640625\n",
      "The representation loss after processing this batch is:  0.00012230128049850464\n",
      "The classification loss after processing this batch is:  23272.4140625\n",
      "The representation loss after processing this batch is:  0.00012965500354766846\n",
      "The classification loss after processing this batch is:  24496.59375\n",
      "The representation loss after processing this batch is:  0.00013619102537631989\n",
      "The classification loss after processing this batch is:  23463.82421875\n",
      "The representation loss after processing this batch is:  0.00012398697435855865\n",
      "The classification loss after processing this batch is:  23444.01171875\n",
      "The representation loss after processing this batch is:  0.00012686289846897125\n",
      "The classification loss after processing this batch is:  21763.306640625\n",
      "The representation loss after processing this batch is:  0.00010653771460056305\n",
      "The classification loss after processing this batch is:  21836.869140625\n",
      "The representation loss after processing this batch is:  0.00011220574378967285\n",
      "The classification loss after processing this batch is:  23015.2734375\n",
      "The representation loss after processing this batch is:  0.00010970607399940491\n",
      "The classification loss after processing this batch is:  21510.220703125\n",
      "The representation loss after processing this batch is:  0.00013677962124347687\n",
      "The classification loss after processing this batch is:  21610.8203125\n",
      "The representation loss after processing this batch is:  0.00010362081229686737\n",
      "The classification loss after processing this batch is:  22556.982421875\n",
      "The representation loss after processing this batch is:  0.00012499932199716568\n",
      "The classification loss after processing this batch is:  22510.67578125\n",
      "The representation loss after processing this batch is:  0.00011026114225387573\n",
      "The classification loss after processing this batch is:  22354.265625\n",
      "The representation loss after processing this batch is:  0.00011619087308645248\n",
      "The classification loss after processing this batch is:  21835.87109375\n",
      "The representation loss after processing this batch is:  0.00010948441922664642\n",
      "The classification loss after processing this batch is:  22941.158203125\n",
      "The representation loss after processing this batch is:  0.00014113355427980423\n",
      "The classification loss after processing this batch is:  22749.501953125\n",
      "The representation loss after processing this batch is:  0.00012197904288768768\n",
      "The classification loss after processing this batch is:  23275.041015625\n",
      "The representation loss after processing this batch is:  0.00010786019265651703\n",
      "The classification loss after processing this batch is:  23384.76953125\n",
      "The representation loss after processing this batch is:  0.00013112369924783707\n",
      "The classification loss after processing this batch is:  22767.6796875\n",
      "The representation loss after processing this batch is:  0.0001152530312538147\n",
      "The classification loss after processing this batch is:  21851.119140625\n",
      "The representation loss after processing this batch is:  0.00011681579053401947\n",
      "The classification loss after processing this batch is:  22000.33984375\n",
      "The representation loss after processing this batch is:  0.00013051554560661316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21736.97265625\n",
      "The representation loss after processing this batch is:  0.0001132618635892868\n",
      "The classification loss after processing this batch is:  21914.087890625\n",
      "The representation loss after processing this batch is:  0.00012839771807193756\n",
      "The classification loss after processing this batch is:  21354.337890625\n",
      "The representation loss after processing this batch is:  0.0001325402408838272\n",
      "The classification loss after processing this batch is:  22189.265625\n",
      "The representation loss after processing this batch is:  0.00011148862540721893\n",
      "The classification loss after processing this batch is:  21913.453125\n",
      "The representation loss after processing this batch is:  0.00011812709271907806\n",
      "The classification loss after processing this batch is:  25385.9375\n",
      "The representation loss after processing this batch is:  0.0001274198293685913\n",
      "The classification loss after processing this batch is:  24422.90625\n",
      "The representation loss after processing this batch is:  0.00011036638170480728\n",
      "The classification loss after processing this batch is:  22212.74609375\n",
      "The representation loss after processing this batch is:  0.000122707337141037\n",
      "The classification loss after processing this batch is:  21102.548828125\n",
      "The representation loss after processing this batch is:  0.00014228187501430511\n",
      "The classification loss after processing this batch is:  21387.1171875\n",
      "The representation loss after processing this batch is:  0.00011745374649763107\n",
      "The classification loss after processing this batch is:  22114.1484375\n",
      "The representation loss after processing this batch is:  0.00013901665806770325\n",
      "The classification loss after processing this batch is:  21731.68359375\n",
      "The representation loss after processing this batch is:  0.00013241078704595566\n",
      "The classification loss after processing this batch is:  22674.78125\n",
      "The representation loss after processing this batch is:  0.00011152401566505432\n",
      "The classification loss after processing this batch is:  22407.30859375\n",
      "The representation loss after processing this batch is:  0.00011235103011131287\n",
      "The classification loss after processing this batch is:  21668.6328125\n",
      "The representation loss after processing this batch is:  0.00011188257485628128\n",
      "The classification loss after processing this batch is:  21128.0546875\n",
      "The representation loss after processing this batch is:  0.00010530836880207062\n",
      "The classification loss after processing this batch is:  22561.4375\n",
      "The representation loss after processing this batch is:  0.00011197105050086975\n",
      "The classification loss after processing this batch is:  23215.84765625\n",
      "The representation loss after processing this batch is:  0.0001357533037662506\n",
      "The classification loss after processing this batch is:  21768.046875\n",
      "The representation loss after processing this batch is:  0.00011806003749370575\n",
      "The classification loss after processing this batch is:  22835.626953125\n",
      "The representation loss after processing this batch is:  0.00012607593089342117\n",
      "The classification loss after processing this batch is:  24224.955078125\n",
      "The representation loss after processing this batch is:  0.00012494996190071106\n",
      "The classification loss after processing this batch is:  23076.35546875\n",
      "The representation loss after processing this batch is:  0.00013579800724983215\n",
      "The classification loss after processing this batch is:  24386.13671875\n",
      "The representation loss after processing this batch is:  0.00012518838047981262\n",
      "The classification loss after processing this batch is:  22026.404296875\n",
      "The representation loss after processing this batch is:  0.0001100543886423111\n",
      "The classification loss after processing this batch is:  22820.30078125\n",
      "The representation loss after processing this batch is:  0.00013078376650810242\n",
      "The classification loss after processing this batch is:  22127.064453125\n",
      "The representation loss after processing this batch is:  0.00011225603520870209\n",
      "The classification loss after processing this batch is:  22629.029296875\n",
      "The representation loss after processing this batch is:  0.00010396074503660202\n",
      "The classification loss after processing this batch is:  21962.533203125\n",
      "The representation loss after processing this batch is:  0.00011847913265228271\n",
      "The classification loss after processing this batch is:  21841.5625\n",
      "The representation loss after processing this batch is:  0.00010561943054199219\n",
      "The classification loss after processing this batch is:  22348.0234375\n",
      "The representation loss after processing this batch is:  0.00011062342673540115\n",
      "The classification loss after processing this batch is:  21487.625\n",
      "The representation loss after processing this batch is:  0.00010451953858137131\n",
      "The classification loss after processing this batch is:  21825.078125\n",
      "The representation loss after processing this batch is:  0.0001092124730348587\n",
      "The classification loss after processing this batch is:  21038.875\n",
      "The representation loss after processing this batch is:  0.00011034496128559113\n",
      "The classification loss after processing this batch is:  21242.4609375\n",
      "The representation loss after processing this batch is:  0.00012231618165969849\n",
      "The classification loss after processing this batch is:  20786.3671875\n",
      "The representation loss after processing this batch is:  0.00010960735380649567\n",
      "The classification loss after processing this batch is:  22343.703125\n",
      "The representation loss after processing this batch is:  0.00011443626135587692\n",
      "The classification loss after processing this batch is:  21630.19921875\n",
      "The representation loss after processing this batch is:  0.00013044849038124084\n",
      "The classification loss after processing this batch is:  22252.521484375\n",
      "The representation loss after processing this batch is:  0.0001438092440366745\n",
      "The classification loss after processing this batch is:  22547.9375\n",
      "The representation loss after processing this batch is:  0.00010387040674686432\n",
      "The classification loss after processing this batch is:  21265.66015625\n",
      "The representation loss after processing this batch is:  9.624473750591278e-05\n",
      "The classification loss after processing this batch is:  22459.35546875\n",
      "The representation loss after processing this batch is:  0.00011102575808763504\n",
      "The classification loss after processing this batch is:  22148.474609375\n",
      "The representation loss after processing this batch is:  0.00012484565377235413\n",
      "The classification loss after processing this batch is:  21165.33203125\n",
      "The representation loss after processing this batch is:  0.00011087022721767426\n",
      "The classification loss after processing this batch is:  22028.560546875\n",
      "The representation loss after processing this batch is:  0.00011636782437562943\n",
      "The classification loss after processing this batch is:  21801.099609375\n",
      "The representation loss after processing this batch is:  0.00010685622692108154\n",
      "The classification loss after processing this batch is:  21301.583984375\n",
      "The representation loss after processing this batch is:  0.00010662339627742767\n",
      "The classification loss after processing this batch is:  22221.609375\n",
      "The representation loss after processing this batch is:  0.00010476447641849518\n",
      "The classification loss after processing this batch is:  21609.421875\n",
      "The representation loss after processing this batch is:  0.00010996311902999878\n",
      "The classification loss after processing this batch is:  22807.146484375\n",
      "The representation loss after processing this batch is:  0.0001292601227760315\n",
      "The classification loss after processing this batch is:  23543.25390625\n",
      "The representation loss after processing this batch is:  0.00012049451470375061\n",
      "The classification loss after processing this batch is:  22041.3203125\n",
      "The representation loss after processing this batch is:  0.00013448763638734818\n",
      "The classification loss after processing this batch is:  24439.75\n",
      "The representation loss after processing this batch is:  0.00011381786316633224\n",
      "The classification loss after processing this batch is:  24393.22265625\n",
      "The representation loss after processing this batch is:  0.00012690294533967972\n",
      "The classification loss after processing this batch is:  21817.42578125\n",
      "The representation loss after processing this batch is:  0.00011157430708408356\n",
      "The classification loss after processing this batch is:  22266.1328125\n",
      "The representation loss after processing this batch is:  0.00011800136417150497\n",
      "The classification loss after processing this batch is:  23493.294921875\n",
      "The representation loss after processing this batch is:  0.00013014394789934158\n",
      "The classification loss after processing this batch is:  22157.44140625\n",
      "The representation loss after processing this batch is:  0.0001162039116024971\n",
      "The classification loss after processing this batch is:  21986.443359375\n",
      "The representation loss after processing this batch is:  0.0001280214637517929\n",
      "The classification loss after processing this batch is:  21954.90625\n",
      "The representation loss after processing this batch is:  0.00011840648949146271\n",
      "The classification loss after processing this batch is:  22169.71875\n",
      "The representation loss after processing this batch is:  0.00012360885739326477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22887.294921875\n",
      "The representation loss after processing this batch is:  0.00011823978275060654\n",
      "The classification loss after processing this batch is:  22538.337890625\n",
      "The representation loss after processing this batch is:  0.00011946354061365128\n",
      "The classification loss after processing this batch is:  24245.1171875\n",
      "The representation loss after processing this batch is:  0.0001331046223640442\n",
      "The classification loss after processing this batch is:  23186.4609375\n",
      "The representation loss after processing this batch is:  0.00010972842574119568\n",
      "The classification loss after processing this batch is:  23258.5078125\n",
      "The representation loss after processing this batch is:  0.00010867230594158173\n",
      "The classification loss after processing this batch is:  21373.35546875\n",
      "The representation loss after processing this batch is:  0.00010936520993709564\n",
      "The classification loss after processing this batch is:  21826.771484375\n",
      "The representation loss after processing this batch is:  0.00010309647768735886\n",
      "The classification loss after processing this batch is:  22685.201171875\n",
      "The representation loss after processing this batch is:  0.00011336710304021835\n",
      "The classification loss after processing this batch is:  21351.27734375\n",
      "The representation loss after processing this batch is:  0.00010381359606981277\n",
      "The classification loss after processing this batch is:  20436.4296875\n",
      "The representation loss after processing this batch is:  0.000127498060464859\n",
      "The classification loss after processing this batch is:  22798.2421875\n",
      "The representation loss after processing this batch is:  0.00011171679943799973\n",
      "The classification loss after processing this batch is:  20988.900390625\n",
      "The representation loss after processing this batch is:  0.0001241760328412056\n",
      "The classification loss after processing this batch is:  21478.84375\n",
      "The representation loss after processing this batch is:  0.00010691583156585693\n",
      "The classification loss after processing this batch is:  20625.173828125\n",
      "The representation loss after processing this batch is:  0.00010391790419816971\n",
      "The classification loss after processing this batch is:  21559.51953125\n",
      "The representation loss after processing this batch is:  0.00011514034122228622\n",
      "The classification loss after processing this batch is:  20812.44140625\n",
      "The representation loss after processing this batch is:  0.00010194722563028336\n",
      "The classification loss after processing this batch is:  22027.46484375\n",
      "The representation loss after processing this batch is:  0.00011274125427007675\n",
      "The classification loss after processing this batch is:  21619.732421875\n",
      "The representation loss after processing this batch is:  0.00010245107114315033\n",
      "The classification loss after processing this batch is:  21350.59375\n",
      "The representation loss after processing this batch is:  0.00011425185948610306\n",
      "The classification loss after processing this batch is:  22300.853515625\n",
      "The representation loss after processing this batch is:  0.00011176057159900665\n",
      "The classification loss after processing this batch is:  22945.21875\n",
      "The representation loss after processing this batch is:  0.00010594353079795837\n",
      "The classification loss after processing this batch is:  21029.38671875\n",
      "The representation loss after processing this batch is:  0.00011803396046161652\n",
      "The classification loss after processing this batch is:  21357.234375\n",
      "The representation loss after processing this batch is:  0.00011262111365795135\n",
      "The classification loss after processing this batch is:  21714.84375\n",
      "The representation loss after processing this batch is:  0.00010474491864442825\n",
      "The classification loss after processing this batch is:  21593.96484375\n",
      "The representation loss after processing this batch is:  0.00010817404836416245\n",
      "The classification loss after processing this batch is:  22485.466796875\n",
      "The representation loss after processing this batch is:  0.000108291395008564\n",
      "The classification loss after processing this batch is:  21377.3125\n",
      "The representation loss after processing this batch is:  9.760074317455292e-05\n",
      "The classification loss after processing this batch is:  21084.28125\n",
      "The representation loss after processing this batch is:  0.00010678824037313461\n",
      "The classification loss after processing this batch is:  22105.56640625\n",
      "The representation loss after processing this batch is:  0.0001079123467206955\n",
      "The classification loss after processing this batch is:  23945.76171875\n",
      "The representation loss after processing this batch is:  0.00012126751244068146\n",
      "The classification loss after processing this batch is:  21441.3828125\n",
      "The representation loss after processing this batch is:  0.00011294055730104446\n",
      "The classification loss after processing this batch is:  22513.91796875\n",
      "The representation loss after processing this batch is:  0.00011230167001485825\n",
      "The classification loss after processing this batch is:  24278.69921875\n",
      "The representation loss after processing this batch is:  0.0001063058152794838\n",
      "The classification loss after processing this batch is:  22143.591796875\n",
      "The representation loss after processing this batch is:  0.00011457223445177078\n",
      "The classification loss after processing this batch is:  21245.5390625\n",
      "The representation loss after processing this batch is:  0.00013008248060941696\n",
      "The classification loss after processing this batch is:  21537.09375\n",
      "The representation loss after processing this batch is:  0.00011405535042285919\n",
      "The classification loss after processing this batch is:  21534.015625\n",
      "The representation loss after processing this batch is:  0.00011592637747526169\n",
      "The classification loss after processing this batch is:  22138.2265625\n",
      "The representation loss after processing this batch is:  0.00011053308844566345\n",
      "The classification loss after processing this batch is:  21500.376953125\n",
      "The representation loss after processing this batch is:  0.00011604279279708862\n",
      "The classification loss after processing this batch is:  22004.29296875\n",
      "The representation loss after processing this batch is:  0.00010823924094438553\n",
      "The classification loss after processing this batch is:  24698.525390625\n",
      "The representation loss after processing this batch is:  0.0001694411039352417\n",
      "The classification loss after processing this batch is:  23312.568359375\n",
      "The representation loss after processing this batch is:  0.000102996826171875\n",
      "The classification loss after processing this batch is:  22403.115234375\n",
      "The representation loss after processing this batch is:  0.00011967215687036514\n",
      "The classification loss after processing this batch is:  21706.78515625\n",
      "The representation loss after processing this batch is:  0.00010735727846622467\n",
      "The classification loss after processing this batch is:  22132.3515625\n",
      "The representation loss after processing this batch is:  0.00013962015509605408\n",
      "The classification loss after processing this batch is:  22191.015625\n",
      "The representation loss after processing this batch is:  0.00014645792543888092\n",
      "The classification loss after processing this batch is:  21559.154296875\n",
      "The representation loss after processing this batch is:  0.00012712739408016205\n",
      "The classification loss after processing this batch is:  20984.18359375\n",
      "The representation loss after processing this batch is:  0.00011202134191989899\n",
      "The classification loss after processing this batch is:  21640.41015625\n",
      "The representation loss after processing this batch is:  0.00011199712753295898\n",
      "The classification loss after processing this batch is:  21608.349609375\n",
      "The representation loss after processing this batch is:  9.75700095295906e-05\n",
      "The classification loss after processing this batch is:  20629.10546875\n",
      "The representation loss after processing this batch is:  0.00010936520993709564\n",
      "The classification loss after processing this batch is:  21620.919921875\n",
      "The representation loss after processing this batch is:  0.00011053122580051422\n",
      "The classification loss after processing this batch is:  20753.984375\n",
      "The representation loss after processing this batch is:  0.00011222716420888901\n",
      "The classification loss after processing this batch is:  23012.931640625\n",
      "The representation loss after processing this batch is:  0.00012250803411006927\n",
      "The classification loss after processing this batch is:  22760.513671875\n",
      "The representation loss after processing this batch is:  0.00010489393025636673\n",
      "The classification loss after processing this batch is:  21582.875\n",
      "The representation loss after processing this batch is:  0.00010265875607728958\n",
      "The classification loss after processing this batch is:  21645.75390625\n",
      "The representation loss after processing this batch is:  0.00010933913290500641\n",
      "The classification loss after processing this batch is:  21813.35546875\n",
      "The representation loss after processing this batch is:  0.00010331440716981888\n",
      "The classification loss after processing this batch is:  23425.498046875\n",
      "The representation loss after processing this batch is:  0.00010873191058635712\n",
      "The classification loss after processing this batch is:  22582.22265625\n",
      "The representation loss after processing this batch is:  0.00012845546007156372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22073.45703125\n",
      "The representation loss after processing this batch is:  0.00011786818504333496\n",
      "The classification loss after processing this batch is:  22107.892578125\n",
      "The representation loss after processing this batch is:  9.986944496631622e-05\n",
      "The classification loss after processing this batch is:  23417.060546875\n",
      "The representation loss after processing this batch is:  0.00013774074614048004\n",
      "The classification loss after processing this batch is:  21102.65625\n",
      "The representation loss after processing this batch is:  0.00010431371629238129\n",
      "The classification loss after processing this batch is:  22252.625\n",
      "The representation loss after processing this batch is:  0.00010985974222421646\n",
      "The classification loss after processing this batch is:  22089.771484375\n",
      "The representation loss after processing this batch is:  0.00013025663793087006\n",
      "The classification loss after processing this batch is:  21950.90625\n",
      "The representation loss after processing this batch is:  0.00011559296399354935\n",
      "The classification loss after processing this batch is:  22791.39453125\n",
      "The representation loss after processing this batch is:  0.00013069342821836472\n",
      "The classification loss after processing this batch is:  23424.9609375\n",
      "The representation loss after processing this batch is:  0.00013865064829587936\n",
      "The classification loss after processing this batch is:  21857.28515625\n",
      "The representation loss after processing this batch is:  0.00012068171054124832\n",
      "The classification loss after processing this batch is:  22791.65234375\n",
      "The representation loss after processing this batch is:  0.00010967347770929337\n",
      "The classification loss after processing this batch is:  23159.734375\n",
      "The representation loss after processing this batch is:  0.00010316167026758194\n",
      "The classification loss after processing this batch is:  21375.017578125\n",
      "The representation loss after processing this batch is:  0.00011610984802246094\n",
      "The classification loss after processing this batch is:  22542.755859375\n",
      "The representation loss after processing this batch is:  0.00012099277228116989\n",
      "The classification loss after processing this batch is:  22320.6875\n",
      "The representation loss after processing this batch is:  0.000126764178276062\n",
      "The classification loss after processing this batch is:  21511.0\n",
      "The representation loss after processing this batch is:  0.00011762604117393494\n",
      "The classification loss after processing this batch is:  21707.9921875\n",
      "The representation loss after processing this batch is:  0.00012133456766605377\n",
      "The classification loss after processing this batch is:  21369.3515625\n",
      "The representation loss after processing this batch is:  0.00010796263813972473\n",
      "The classification loss after processing this batch is:  21251.642578125\n",
      "The representation loss after processing this batch is:  0.00011189468204975128\n",
      "The classification loss after processing this batch is:  23060.30859375\n",
      "The representation loss after processing this batch is:  0.0001068776473402977\n",
      "The classification loss after processing this batch is:  22713.447265625\n",
      "The representation loss after processing this batch is:  0.00010642409324645996\n",
      "The classification loss after processing this batch is:  23896.515625\n",
      "The representation loss after processing this batch is:  0.00012952834367752075\n",
      "The classification loss after processing this batch is:  21020.2890625\n",
      "The representation loss after processing this batch is:  0.00010778754949569702\n",
      "The classification loss after processing this batch is:  21284.630859375\n",
      "The representation loss after processing this batch is:  0.00012231990694999695\n",
      "The classification loss after processing this batch is:  21945.607421875\n",
      "The representation loss after processing this batch is:  0.0001378580927848816\n",
      "The classification loss after processing this batch is:  21740.607421875\n",
      "The representation loss after processing this batch is:  0.0001264680176973343\n",
      "The classification loss after processing this batch is:  23020.51171875\n",
      "The representation loss after processing this batch is:  0.00011914782226085663\n",
      "The classification loss after processing this batch is:  21751.90234375\n",
      "The representation loss after processing this batch is:  0.00010493490844964981\n",
      "The classification loss after processing this batch is:  22221.302734375\n",
      "The representation loss after processing this batch is:  0.00011311843991279602\n",
      "The classification loss after processing this batch is:  22386.609375\n",
      "The representation loss after processing this batch is:  0.00011921953409910202\n",
      "The classification loss after processing this batch is:  21541.65625\n",
      "The representation loss after processing this batch is:  0.00011180900037288666\n",
      "The classification loss after processing this batch is:  23681.0234375\n",
      "The representation loss after processing this batch is:  0.00012214761227369308\n",
      "The classification loss after processing this batch is:  23662.623046875\n",
      "The representation loss after processing this batch is:  0.00012070219963788986\n",
      "The classification loss after processing this batch is:  23016.74609375\n",
      "The representation loss after processing this batch is:  0.0001142425462603569\n",
      "The classification loss after processing this batch is:  21161.765625\n",
      "The representation loss after processing this batch is:  0.0001187790185213089\n",
      "The classification loss after processing this batch is:  23275.85546875\n",
      "The representation loss after processing this batch is:  0.0001248614862561226\n",
      "The classification loss after processing this batch is:  22783.072265625\n",
      "The representation loss after processing this batch is:  0.00011297222226858139\n",
      "The classification loss after processing this batch is:  21371.013671875\n",
      "The representation loss after processing this batch is:  0.00010629463940858841\n",
      "The classification loss after processing this batch is:  23857.00390625\n",
      "The representation loss after processing this batch is:  0.0001116609200835228\n",
      "The classification loss after processing this batch is:  23650.8671875\n",
      "The representation loss after processing this batch is:  0.00012522004544734955\n",
      "The classification loss after processing this batch is:  21220.10546875\n",
      "The representation loss after processing this batch is:  0.00012064725160598755\n",
      "The classification loss after processing this batch is:  21718.041015625\n",
      "The representation loss after processing this batch is:  0.00011045485734939575\n",
      "The classification loss after processing this batch is:  22410.302734375\n",
      "The representation loss after processing this batch is:  0.00012257229536771774\n",
      "The classification loss after processing this batch is:  21789.54296875\n",
      "The representation loss after processing this batch is:  0.00012093409895896912\n",
      "The classification loss after processing this batch is:  22683.55078125\n",
      "The representation loss after processing this batch is:  0.00012156181037425995\n",
      "The classification loss after processing this batch is:  23236.22265625\n",
      "The representation loss after processing this batch is:  0.00012616999447345734\n",
      "The classification loss after processing this batch is:  21300.3125\n",
      "The representation loss after processing this batch is:  0.00012833811342716217\n",
      "The classification loss after processing this batch is:  20788.361328125\n",
      "The representation loss after processing this batch is:  0.00012378767132759094\n",
      "The classification loss after processing this batch is:  22182.0\n",
      "The representation loss after processing this batch is:  0.00010831933468580246\n",
      "The classification loss after processing this batch is:  23211.173828125\n",
      "The representation loss after processing this batch is:  0.0001202896237373352\n",
      "The classification loss after processing this batch is:  21664.49609375\n",
      "The representation loss after processing this batch is:  0.0001005660742521286\n",
      "The classification loss after processing this batch is:  22304.119140625\n",
      "The representation loss after processing this batch is:  0.00012048706412315369\n",
      "The classification loss after processing this batch is:  22058.53125\n",
      "The representation loss after processing this batch is:  0.00010980386286973953\n",
      "The classification loss after processing this batch is:  22387.26953125\n",
      "The representation loss after processing this batch is:  0.00011208653450012207\n",
      "The classification loss after processing this batch is:  21617.1171875\n",
      "The representation loss after processing this batch is:  0.00012620072811841965\n",
      "The classification loss after processing this batch is:  22002.6953125\n",
      "The representation loss after processing this batch is:  0.00010958220809698105\n",
      "The classification loss after processing this batch is:  23245.24609375\n",
      "The representation loss after processing this batch is:  0.0001059751957654953\n",
      "The classification loss after processing this batch is:  21045.109375\n",
      "The representation loss after processing this batch is:  0.00011624116450548172\n",
      "The classification loss after processing this batch is:  20863.123046875\n",
      "The representation loss after processing this batch is:  0.00010517612099647522\n",
      "The classification loss after processing this batch is:  20688.525390625\n",
      "The representation loss after processing this batch is:  0.0001099342480301857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  20809.12890625\n",
      "The representation loss after processing this batch is:  0.00010696426033973694\n",
      "The classification loss after processing this batch is:  21114.478515625\n",
      "The representation loss after processing this batch is:  0.0001128343865275383\n",
      "The classification loss after processing this batch is:  22453.48828125\n",
      "The representation loss after processing this batch is:  0.00013976264744997025\n",
      "The classification loss after processing this batch is:  22726.8984375\n",
      "The representation loss after processing this batch is:  0.00010740850120782852\n",
      "The classification loss after processing this batch is:  21106.384765625\n",
      "The representation loss after processing this batch is:  0.00011615175753831863\n",
      "The classification loss after processing this batch is:  21048.736328125\n",
      "The representation loss after processing this batch is:  0.00011371076107025146\n",
      "The classification loss after processing this batch is:  21315.359375\n",
      "The representation loss after processing this batch is:  0.00010375864803791046\n",
      "The classification loss after processing this batch is:  21766.75\n",
      "The representation loss after processing this batch is:  0.00011435337364673615\n",
      "The classification loss after processing this batch is:  21935.244140625\n",
      "The representation loss after processing this batch is:  0.00011857692152261734\n",
      "The classification loss after processing this batch is:  21132.3203125\n",
      "The representation loss after processing this batch is:  0.00011976435780525208\n",
      "The classification loss after processing this batch is:  23770.76171875\n",
      "The representation loss after processing this batch is:  0.0001055542379617691\n",
      "The classification loss after processing this batch is:  21623.822265625\n",
      "The representation loss after processing this batch is:  9.413156658411026e-05\n",
      "The classification loss after processing this batch is:  21418.109375\n",
      "The representation loss after processing this batch is:  0.00011655408889055252\n",
      "The classification loss after processing this batch is:  21744.552734375\n",
      "The representation loss after processing this batch is:  0.00011732615530490875\n",
      "The classification loss after processing this batch is:  22108.05078125\n",
      "The representation loss after processing this batch is:  0.000125199556350708\n",
      "The classification loss after processing this batch is:  21698.3203125\n",
      "The representation loss after processing this batch is:  0.0001223227009177208\n",
      "The classification loss after processing this batch is:  21629.7890625\n",
      "The representation loss after processing this batch is:  0.00012070499360561371\n",
      "The classification loss after processing this batch is:  22250.478515625\n",
      "The representation loss after processing this batch is:  0.00011241529136896133\n",
      "The classification loss after processing this batch is:  23908.6953125\n",
      "The representation loss after processing this batch is:  0.00010807160288095474\n",
      "The classification loss after processing this batch is:  20946.009765625\n",
      "The representation loss after processing this batch is:  0.00011224020272493362\n",
      "The classification loss after processing this batch is:  21648.84765625\n",
      "The representation loss after processing this batch is:  0.00010866019874811172\n",
      "The classification loss after processing this batch is:  20519.037109375\n",
      "The representation loss after processing this batch is:  0.00010461173951625824\n",
      "The classification loss after processing this batch is:  21883.5\n",
      "The representation loss after processing this batch is:  9.785126894712448e-05\n",
      "The classification loss after processing this batch is:  22159.87890625\n",
      "The representation loss after processing this batch is:  0.00011011585593223572\n",
      "The classification loss after processing this batch is:  21480.94921875\n",
      "The representation loss after processing this batch is:  0.00011536106467247009\n",
      "The classification loss after processing this batch is:  21183.875\n",
      "The representation loss after processing this batch is:  0.00013240985572338104\n",
      "The classification loss after processing this batch is:  20811.896484375\n",
      "The representation loss after processing this batch is:  0.00010490696877241135\n",
      "The classification loss after processing this batch is:  21909.8515625\n",
      "The representation loss after processing this batch is:  0.00010246038436889648\n",
      "The classification loss after processing this batch is:  21558.001953125\n",
      "The representation loss after processing this batch is:  0.00011780112981796265\n",
      "The classification loss after processing this batch is:  20929.052734375\n",
      "The representation loss after processing this batch is:  0.00012191105633974075\n",
      "The classification loss after processing this batch is:  24890.126953125\n",
      "The representation loss after processing this batch is:  0.0001267334446310997\n",
      "The classification loss after processing this batch is:  23570.65234375\n",
      "The representation loss after processing this batch is:  0.0001118779182434082\n",
      "The classification loss after processing this batch is:  22517.47265625\n",
      "The representation loss after processing this batch is:  0.00011665932834148407\n",
      "The classification loss after processing this batch is:  21931.896484375\n",
      "The representation loss after processing this batch is:  0.0001207226887345314\n",
      "The classification loss after processing this batch is:  21295.97265625\n",
      "The representation loss after processing this batch is:  0.0001307232305407524\n",
      "The classification loss after processing this batch is:  21894.40625\n",
      "The representation loss after processing this batch is:  0.00011025834828615189\n",
      "The classification loss after processing this batch is:  22741.40625\n",
      "The representation loss after processing this batch is:  0.00011770986020565033\n",
      "The classification loss after processing this batch is:  21860.50390625\n",
      "The representation loss after processing this batch is:  0.00010036583989858627\n",
      "The classification loss after processing this batch is:  23968.8984375\n",
      "The representation loss after processing this batch is:  0.00010454654693603516\n",
      "The classification loss after processing this batch is:  22074.103515625\n",
      "The representation loss after processing this batch is:  0.00011848099529743195\n",
      "The classification loss after processing this batch is:  21069.2890625\n",
      "The representation loss after processing this batch is:  0.00013687554746866226\n",
      "The classification loss after processing this batch is:  23112.474609375\n",
      "The representation loss after processing this batch is:  0.00012434832751750946\n",
      "The classification loss after processing this batch is:  21364.9453125\n",
      "The representation loss after processing this batch is:  0.00011181551963090897\n",
      "The classification loss after processing this batch is:  21863.5390625\n",
      "The representation loss after processing this batch is:  0.00011558458209037781\n",
      "The classification loss after processing this batch is:  25253.59765625\n",
      "The representation loss after processing this batch is:  0.00014185719192028046\n",
      "The classification loss after processing this batch is:  22653.4921875\n",
      "The representation loss after processing this batch is:  0.00013258494436740875\n",
      "The classification loss after processing this batch is:  21475.6875\n",
      "The representation loss after processing this batch is:  0.00012070685625076294\n",
      "The classification loss after processing this batch is:  21794.255859375\n",
      "The representation loss after processing this batch is:  0.00017439760267734528\n",
      "The classification loss after processing this batch is:  23666.34765625\n",
      "The representation loss after processing this batch is:  0.0001210775226354599\n",
      "The classification loss after processing this batch is:  21063.07421875\n",
      "The representation loss after processing this batch is:  0.00013147667050361633\n",
      "The classification loss after processing this batch is:  21587.08984375\n",
      "The representation loss after processing this batch is:  0.0001409575343132019\n",
      "The classification loss after processing this batch is:  22341.892578125\n",
      "The representation loss after processing this batch is:  0.00013757869601249695\n",
      "The classification loss after processing this batch is:  27085.89453125\n",
      "The representation loss after processing this batch is:  0.00014216266572475433\n",
      "The classification loss after processing this batch is:  29557.28515625\n",
      "The representation loss after processing this batch is:  0.00012309476733207703\n",
      "The classification loss after processing this batch is:  20893.58203125\n",
      "The representation loss after processing this batch is:  0.00012118369340896606\n",
      "The classification loss after processing this batch is:  22344.009765625\n",
      "The representation loss after processing this batch is:  0.00012482330203056335\n",
      "The classification loss after processing this batch is:  22445.046875\n",
      "The representation loss after processing this batch is:  0.00013253279030323029\n",
      "The classification loss after processing this batch is:  20229.876953125\n",
      "The representation loss after processing this batch is:  0.0001013418659567833\n",
      "The classification loss after processing this batch is:  22115.73828125\n",
      "The representation loss after processing this batch is:  8.776597678661346e-05\n",
      "The classification loss after processing this batch is:  22596.16796875\n",
      "The representation loss after processing this batch is:  7.635261863470078e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21710.517578125\n",
      "The representation loss after processing this batch is:  8.156150579452515e-05\n",
      "The classification loss after processing this batch is:  22030.46484375\n",
      "The representation loss after processing this batch is:  7.461477071046829e-05\n",
      "The classification loss after processing this batch is:  21889.69921875\n",
      "The representation loss after processing this batch is:  7.883179932832718e-05\n",
      "The classification loss after processing this batch is:  21471.59375\n",
      "The representation loss after processing this batch is:  6.931927055120468e-05\n",
      "The classification loss after processing this batch is:  21576.6640625\n",
      "The representation loss after processing this batch is:  7.64988362789154e-05\n",
      "The classification loss after processing this batch is:  21647.310546875\n",
      "The representation loss after processing this batch is:  6.873812526464462e-05\n",
      "The classification loss after processing this batch is:  21823.04296875\n",
      "The representation loss after processing this batch is:  7.550697773694992e-05\n",
      "The classification loss after processing this batch is:  25029.16796875\n",
      "The representation loss after processing this batch is:  6.557349115610123e-05\n",
      "The classification loss after processing this batch is:  24239.37109375\n",
      "The representation loss after processing this batch is:  6.243772804737091e-05\n",
      "The classification loss after processing this batch is:  21518.62890625\n",
      "The representation loss after processing this batch is:  6.060488522052765e-05\n",
      "The classification loss after processing this batch is:  21448.6484375\n",
      "The representation loss after processing this batch is:  5.992967635393143e-05\n",
      "The classification loss after processing this batch is:  21170.517578125\n",
      "The representation loss after processing this batch is:  7.256586104631424e-05\n",
      "The classification loss after processing this batch is:  21431.37890625\n",
      "The representation loss after processing this batch is:  5.806330591440201e-05\n",
      "The classification loss after processing this batch is:  22553.8671875\n",
      "The representation loss after processing this batch is:  5.992036312818527e-05\n",
      "The classification loss after processing this batch is:  21702.015625\n",
      "The representation loss after processing this batch is:  6.152316927909851e-05\n",
      "The classification loss after processing this batch is:  23726.0625\n",
      "The representation loss after processing this batch is:  6.719771772623062e-05\n",
      "The classification loss after processing this batch is:  22056.49609375\n",
      "The representation loss after processing this batch is:  6.301794201135635e-05\n",
      "The classification loss after processing this batch is:  22311.943359375\n",
      "The representation loss after processing this batch is:  6.296206265687943e-05\n",
      "The classification loss after processing this batch is:  22255.994140625\n",
      "The representation loss after processing this batch is:  5.777459591627121e-05\n",
      "The classification loss after processing this batch is:  22202.072265625\n",
      "The representation loss after processing this batch is:  5.953758955001831e-05\n",
      "The classification loss after processing this batch is:  22465.474609375\n",
      "The representation loss after processing this batch is:  6.329827010631561e-05\n",
      "The classification loss after processing this batch is:  22164.2734375\n",
      "The representation loss after processing this batch is:  5.869567394256592e-05\n",
      "The classification loss after processing this batch is:  22381.05078125\n",
      "The representation loss after processing this batch is:  5.579367280006409e-05\n",
      "The classification loss after processing this batch is:  21438.44921875\n",
      "The representation loss after processing this batch is:  6.259884685277939e-05\n",
      "The classification loss after processing this batch is:  21794.0546875\n",
      "The representation loss after processing this batch is:  5.529727786779404e-05\n",
      "The classification loss after processing this batch is:  21886.8828125\n",
      "The representation loss after processing this batch is:  5.720183253288269e-05\n",
      "The classification loss after processing this batch is:  24040.900390625\n",
      "The representation loss after processing this batch is:  5.789846181869507e-05\n",
      "The classification loss after processing this batch is:  22741.046875\n",
      "The representation loss after processing this batch is:  5.628727376461029e-05\n",
      "The classification loss after processing this batch is:  21624.12890625\n",
      "The representation loss after processing this batch is:  5.672220140695572e-05\n",
      "The classification loss after processing this batch is:  21979.5546875\n",
      "The representation loss after processing this batch is:  5.417130887508392e-05\n",
      "The classification loss after processing this batch is:  21411.453125\n",
      "The representation loss after processing this batch is:  5.679856985807419e-05\n",
      "The classification loss after processing this batch is:  21846.900390625\n",
      "The representation loss after processing this batch is:  5.587376654148102e-05\n",
      "The classification loss after processing this batch is:  22102.71484375\n",
      "The representation loss after processing this batch is:  6.03552907705307e-05\n",
      "The classification loss after processing this batch is:  21943.408203125\n",
      "The representation loss after processing this batch is:  5.718506872653961e-05\n",
      "The classification loss after processing this batch is:  23399.5625\n",
      "The representation loss after processing this batch is:  5.592452362179756e-05\n",
      "The classification loss after processing this batch is:  27047.94921875\n",
      "The representation loss after processing this batch is:  6.320048123598099e-05\n",
      "The classification loss after processing this batch is:  22091.197265625\n",
      "The representation loss after processing this batch is:  5.81471249461174e-05\n",
      "The classification loss after processing this batch is:  22435.89453125\n",
      "The representation loss after processing this batch is:  5.5895186960697174e-05\n",
      "The classification loss after processing this batch is:  22372.888671875\n",
      "The representation loss after processing this batch is:  5.6522898375988007e-05\n",
      "The classification loss after processing this batch is:  22607.119140625\n",
      "The representation loss after processing this batch is:  5.7540833950042725e-05\n",
      "The classification loss after processing this batch is:  22064.33984375\n",
      "The representation loss after processing this batch is:  5.321484059095383e-05\n",
      "The classification loss after processing this batch is:  22468.05078125\n",
      "The representation loss after processing this batch is:  6.300676614046097e-05\n",
      "The classification loss after processing this batch is:  22029.18359375\n",
      "The representation loss after processing this batch is:  5.1487237215042114e-05\n",
      "The classification loss after processing this batch is:  22305.052734375\n",
      "The representation loss after processing this batch is:  5.8261677622795105e-05\n",
      "The classification loss after processing this batch is:  21814.140625\n",
      "The representation loss after processing this batch is:  5.351472645998001e-05\n",
      "The classification loss after processing this batch is:  21947.669921875\n",
      "The representation loss after processing this batch is:  5.830172449350357e-05\n",
      "The classification loss after processing this batch is:  21805.74609375\n",
      "The representation loss after processing this batch is:  5.3977593779563904e-05\n",
      "The classification loss after processing this batch is:  21471.333984375\n",
      "The representation loss after processing this batch is:  5.827657878398895e-05\n",
      "The classification loss after processing this batch is:  21384.923828125\n",
      "The representation loss after processing this batch is:  5.9126876294612885e-05\n",
      "The classification loss after processing this batch is:  20456.984375\n",
      "The representation loss after processing this batch is:  6.12335279583931e-05\n",
      "The classification loss after processing this batch is:  21380.111328125\n",
      "The representation loss after processing this batch is:  7.082056254148483e-05\n",
      "The classification loss after processing this batch is:  21771.21875\n",
      "The representation loss after processing this batch is:  5.298200994729996e-05\n",
      "The classification loss after processing this batch is:  21580.03515625\n",
      "The representation loss after processing this batch is:  5.253870040178299e-05\n",
      "The classification loss after processing this batch is:  21216.794921875\n",
      "The representation loss after processing this batch is:  5.983468145132065e-05\n",
      "The classification loss after processing this batch is:  22789.0390625\n",
      "The representation loss after processing this batch is:  5.5806711316108704e-05\n",
      "The classification loss after processing this batch is:  21594.22265625\n",
      "The representation loss after processing this batch is:  5.698995664715767e-05\n",
      "The classification loss after processing this batch is:  21325.736328125\n",
      "The representation loss after processing this batch is:  6.373785436153412e-05\n",
      "The classification loss after processing this batch is:  21772.80859375\n",
      "The representation loss after processing this batch is:  5.881115794181824e-05\n",
      "The classification loss after processing this batch is:  22864.1484375\n",
      "The representation loss after processing this batch is:  5.517899990081787e-05\n",
      "The classification loss after processing this batch is:  23962.8671875\n",
      "The representation loss after processing this batch is:  4.828255623579025e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  23467.86328125\n",
      "The representation loss after processing this batch is:  5.385652184486389e-05\n",
      "The classification loss after processing this batch is:  20609.9375\n",
      "The representation loss after processing this batch is:  5.412939935922623e-05\n",
      "The classification loss after processing this batch is:  22509.76953125\n",
      "The representation loss after processing this batch is:  5.672778934240341e-05\n",
      "The classification loss after processing this batch is:  21374.90625\n",
      "The representation loss after processing this batch is:  4.684366285800934e-05\n",
      "The classification loss after processing this batch is:  22781.294921875\n",
      "The representation loss after processing this batch is:  5.991104990243912e-05\n",
      "The classification loss after processing this batch is:  22819.291015625\n",
      "The representation loss after processing this batch is:  5.314359441399574e-05\n",
      "The classification loss after processing this batch is:  21318.88671875\n",
      "The representation loss after processing this batch is:  4.968605935573578e-05\n",
      "The classification loss after processing this batch is:  21709.591796875\n",
      "The representation loss after processing this batch is:  5.40073961019516e-05\n",
      "The classification loss after processing this batch is:  21813.111328125\n",
      "The representation loss after processing this batch is:  5.2908435463905334e-05\n",
      "The classification loss after processing this batch is:  22845.203125\n",
      "The representation loss after processing this batch is:  6.002560257911682e-05\n",
      "The classification loss after processing this batch is:  21845.63671875\n",
      "The representation loss after processing this batch is:  6.046611815690994e-05\n",
      "The classification loss after processing this batch is:  22477.85546875\n",
      "The representation loss after processing this batch is:  5.2519142627716064e-05\n",
      "The classification loss after processing this batch is:  23176.353515625\n",
      "The representation loss after processing this batch is:  5.674641579389572e-05\n",
      "The classification loss after processing this batch is:  23829.931640625\n",
      "The representation loss after processing this batch is:  6.21899962425232e-05\n",
      "The classification loss after processing this batch is:  21121.59765625\n",
      "The representation loss after processing this batch is:  5.186907947063446e-05\n",
      "The classification loss after processing this batch is:  21001.171875\n",
      "The representation loss after processing this batch is:  5.509518086910248e-05\n",
      "The classification loss after processing this batch is:  21207.35546875\n",
      "The representation loss after processing this batch is:  5.5264681577682495e-05\n",
      "The classification loss after processing this batch is:  22450.8046875\n",
      "The representation loss after processing this batch is:  4.86765056848526e-05\n",
      "The classification loss after processing this batch is:  23732.322265625\n",
      "The representation loss after processing this batch is:  5.168560892343521e-05\n",
      "The classification loss after processing this batch is:  21935.81640625\n",
      "The representation loss after processing this batch is:  5.940161645412445e-05\n",
      "The classification loss after processing this batch is:  20817.529296875\n",
      "The representation loss after processing this batch is:  5.24912029504776e-05\n",
      "The classification loss after processing this batch is:  21089.900390625\n",
      "The representation loss after processing this batch is:  6.133131682872772e-05\n",
      "The classification loss after processing this batch is:  20651.7890625\n",
      "The representation loss after processing this batch is:  5.5361539125442505e-05\n",
      "The classification loss after processing this batch is:  21073.6015625\n",
      "The representation loss after processing this batch is:  5.4418109357357025e-05\n",
      "The classification loss after processing this batch is:  20892.98828125\n",
      "The representation loss after processing this batch is:  5.750730633735657e-05\n",
      "The classification loss after processing this batch is:  20849.63671875\n",
      "The representation loss after processing this batch is:  5.5145472288131714e-05\n",
      "The classification loss after processing this batch is:  20541.033203125\n",
      "The representation loss after processing this batch is:  5.1684677600860596e-05\n",
      "The classification loss after processing this batch is:  20566.087890625\n",
      "The representation loss after processing this batch is:  5.313660949468613e-05\n",
      "The classification loss after processing this batch is:  21197.458984375\n",
      "The representation loss after processing this batch is:  5.0834380090236664e-05\n",
      "The classification loss after processing this batch is:  20712.29296875\n",
      "The representation loss after processing this batch is:  5.5097974836826324e-05\n",
      "The classification loss after processing this batch is:  20590.73828125\n",
      "The representation loss after processing this batch is:  5.195941776037216e-05\n",
      "The classification loss after processing this batch is:  20479.140625\n",
      "The representation loss after processing this batch is:  5.1587820053100586e-05\n",
      "The classification loss after processing this batch is:  20201.9453125\n",
      "The representation loss after processing this batch is:  5.212891846895218e-05\n",
      "The classification loss after processing this batch is:  21828.796875\n",
      "The representation loss after processing this batch is:  5.0298869609832764e-05\n",
      "The classification loss after processing this batch is:  21897.451171875\n",
      "The representation loss after processing this batch is:  5.171447992324829e-05\n",
      "The classification loss after processing this batch is:  22355.908203125\n",
      "The representation loss after processing this batch is:  4.815775901079178e-05\n",
      "The classification loss after processing this batch is:  23151.884765625\n",
      "The representation loss after processing this batch is:  5.8978796005249023e-05\n",
      "The classification loss after processing this batch is:  22645.5078125\n",
      "The representation loss after processing this batch is:  5.3307972848415375e-05\n",
      "The classification loss after processing this batch is:  21689.796875\n",
      "The representation loss after processing this batch is:  5.547422915697098e-05\n",
      "The classification loss after processing this batch is:  22087.4609375\n",
      "The representation loss after processing this batch is:  5.2488408982753754e-05\n",
      "The classification loss after processing this batch is:  21624.6640625\n",
      "The representation loss after processing this batch is:  5.274266004562378e-05\n",
      "The classification loss after processing this batch is:  21868.75\n",
      "The representation loss after processing this batch is:  5.279853940010071e-05\n",
      "The classification loss after processing this batch is:  20982.734375\n",
      "The representation loss after processing this batch is:  4.887208342552185e-05\n",
      "The classification loss after processing this batch is:  20908.28515625\n",
      "The representation loss after processing this batch is:  4.9773138016462326e-05\n",
      "The classification loss after processing this batch is:  21988.1875\n",
      "The representation loss after processing this batch is:  4.878360778093338e-05\n",
      "The classification loss after processing this batch is:  21838.513671875\n",
      "The representation loss after processing this batch is:  5.4142437875270844e-05\n",
      "The classification loss after processing this batch is:  21250.6328125\n",
      "The representation loss after processing this batch is:  5.217548459768295e-05\n",
      "The classification loss after processing this batch is:  22478.900390625\n",
      "The representation loss after processing this batch is:  4.923902451992035e-05\n",
      "The classification loss after processing this batch is:  24646.94140625\n",
      "The representation loss after processing this batch is:  6.0888007283210754e-05\n",
      "The classification loss after processing this batch is:  22931.8984375\n",
      "The representation loss after processing this batch is:  5.1633454859256744e-05\n",
      "The classification loss after processing this batch is:  21171.056640625\n",
      "The representation loss after processing this batch is:  4.742154851555824e-05\n",
      "The classification loss after processing this batch is:  21632.69921875\n",
      "The representation loss after processing this batch is:  5.4941512644290924e-05\n",
      "The classification loss after processing this batch is:  25761.12890625\n",
      "The representation loss after processing this batch is:  5.442369729280472e-05\n",
      "The classification loss after processing this batch is:  26047.619140625\n",
      "The representation loss after processing this batch is:  6.321817636489868e-05\n",
      "The classification loss after processing this batch is:  21146.26953125\n",
      "The representation loss after processing this batch is:  5.414150655269623e-05\n",
      "The classification loss after processing this batch is:  20721.3125\n",
      "The representation loss after processing this batch is:  5.195382982492447e-05\n",
      "The classification loss after processing this batch is:  21371.6484375\n",
      "The representation loss after processing this batch is:  5.307979881763458e-05\n",
      "The classification loss after processing this batch is:  21724.970703125\n",
      "The representation loss after processing this batch is:  5.223602056503296e-05\n",
      "The classification loss after processing this batch is:  21509.171875\n",
      "The representation loss after processing this batch is:  5.3199008107185364e-05\n",
      "The classification loss after processing this batch is:  21366.791015625\n",
      "The representation loss after processing this batch is:  5.672965198755264e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22483.111328125\n",
      "The representation loss after processing this batch is:  4.4972170144319534e-05\n",
      "The classification loss after processing this batch is:  23589.529296875\n",
      "The representation loss after processing this batch is:  5.6986697018146515e-05\n",
      "The classification loss after processing this batch is:  21371.958984375\n",
      "The representation loss after processing this batch is:  5.825608968734741e-05\n",
      "The classification loss after processing this batch is:  21914.7109375\n",
      "The representation loss after processing this batch is:  5.614152178168297e-05\n",
      "The classification loss after processing this batch is:  20655.82421875\n",
      "The representation loss after processing this batch is:  5.395989865064621e-05\n",
      "The classification loss after processing this batch is:  20653.71484375\n",
      "The representation loss after processing this batch is:  5.380343645811081e-05\n",
      "The classification loss after processing this batch is:  20196.7109375\n",
      "The representation loss after processing this batch is:  5.338154733181e-05\n",
      "The classification loss after processing this batch is:  21527.06640625\n",
      "The representation loss after processing this batch is:  5.866680294275284e-05\n",
      "The classification loss after processing this batch is:  21140.70703125\n",
      "The representation loss after processing this batch is:  5.2708201110363007e-05\n",
      "The classification loss after processing this batch is:  23486.306640625\n",
      "The representation loss after processing this batch is:  5.82551583647728e-05\n",
      "The classification loss after processing this batch is:  21184.556640625\n",
      "The representation loss after processing this batch is:  5.4084695875644684e-05\n",
      "The classification loss after processing this batch is:  21365.16796875\n",
      "The representation loss after processing this batch is:  4.828302189707756e-05\n",
      "The classification loss after processing this batch is:  22703.69921875\n",
      "The representation loss after processing this batch is:  5.5995769798755646e-05\n",
      "The classification loss after processing this batch is:  22331.73046875\n",
      "The representation loss after processing this batch is:  4.8897694796323776e-05\n",
      "The classification loss after processing this batch is:  21816.55859375\n",
      "The representation loss after processing this batch is:  5.1711685955524445e-05\n",
      "The classification loss after processing this batch is:  23029.75390625\n",
      "The representation loss after processing this batch is:  6.08544796705246e-05\n",
      "The classification loss after processing this batch is:  21312.291015625\n",
      "The representation loss after processing this batch is:  4.9979425966739655e-05\n",
      "The classification loss after processing this batch is:  21884.56640625\n",
      "The representation loss after processing this batch is:  5.20036555826664e-05\n",
      "The classification loss after processing this batch is:  20488.375\n",
      "The representation loss after processing this batch is:  4.573492333292961e-05\n",
      "The classification loss after processing this batch is:  20529.529296875\n",
      "The representation loss after processing this batch is:  5.331262946128845e-05\n",
      "The classification loss after processing this batch is:  20927.34375\n",
      "The representation loss after processing this batch is:  5.606561899185181e-05\n",
      "The classification loss after processing this batch is:  20952.24609375\n",
      "The representation loss after processing this batch is:  5.8681704103946686e-05\n",
      "The classification loss after processing this batch is:  20934.6953125\n",
      "The representation loss after processing this batch is:  5.647260695695877e-05\n",
      "The classification loss after processing this batch is:  23407.28125\n",
      "The representation loss after processing this batch is:  5.5888667702674866e-05\n",
      "The classification loss after processing this batch is:  20599.591796875\n",
      "The representation loss after processing this batch is:  5.118735134601593e-05\n",
      "The classification loss after processing this batch is:  20831.6015625\n",
      "The representation loss after processing this batch is:  5.231192335486412e-05\n",
      "The classification loss after processing this batch is:  21398.04296875\n",
      "The representation loss after processing this batch is:  5.138665437698364e-05\n",
      "The classification loss after processing this batch is:  21001.306640625\n",
      "The representation loss after processing this batch is:  5.315244197845459e-05\n",
      "The classification loss after processing this batch is:  21771.140625\n",
      "The representation loss after processing this batch is:  5.49880787730217e-05\n",
      "The classification loss after processing this batch is:  21720.37890625\n",
      "The representation loss after processing this batch is:  4.876777529716492e-05\n",
      "The classification loss after processing this batch is:  21513.5\n",
      "The representation loss after processing this batch is:  5.953945219516754e-05\n",
      "The classification loss after processing this batch is:  20137.8203125\n",
      "The representation loss after processing this batch is:  5.2031129598617554e-05\n",
      "The classification loss after processing this batch is:  21922.146484375\n",
      "The representation loss after processing this batch is:  5.372241139411926e-05\n",
      "The classification loss after processing this batch is:  24688.3828125\n",
      "The representation loss after processing this batch is:  5.248282104730606e-05\n",
      "The classification loss after processing this batch is:  25303.68359375\n",
      "The representation loss after processing this batch is:  5.9262849390506744e-05\n",
      "The classification loss after processing this batch is:  21740.787109375\n",
      "The representation loss after processing this batch is:  5.216337740421295e-05\n",
      "The classification loss after processing this batch is:  21693.55859375\n",
      "The representation loss after processing this batch is:  4.747183993458748e-05\n",
      "The classification loss after processing this batch is:  21293.96875\n",
      "The representation loss after processing this batch is:  4.9272552132606506e-05\n",
      "The classification loss after processing this batch is:  21997.6484375\n",
      "The representation loss after processing this batch is:  5.189329385757446e-05\n",
      "The classification loss after processing this batch is:  21271.3125\n",
      "The representation loss after processing this batch is:  5.845073610544205e-05\n",
      "The classification loss after processing this batch is:  21737.4296875\n",
      "The representation loss after processing this batch is:  5.1345210522413254e-05\n",
      "The classification loss after processing this batch is:  23035.185546875\n",
      "The representation loss after processing this batch is:  5.588214844465256e-05\n",
      "The classification loss after processing this batch is:  20568.90234375\n",
      "The representation loss after processing this batch is:  5.1009468734264374e-05\n",
      "The classification loss after processing this batch is:  21013.958984375\n",
      "The representation loss after processing this batch is:  5.507189780473709e-05\n",
      "The classification loss after processing this batch is:  22578.560546875\n",
      "The representation loss after processing this batch is:  5.815736949443817e-05\n",
      "The classification loss after processing this batch is:  21233.447265625\n",
      "The representation loss after processing this batch is:  5.828309804201126e-05\n",
      "The classification loss after processing this batch is:  21010.66796875\n",
      "The representation loss after processing this batch is:  5.357526242733002e-05\n",
      "The classification loss after processing this batch is:  20054.14453125\n",
      "The representation loss after processing this batch is:  5.2138231694698334e-05\n",
      "The classification loss after processing this batch is:  22921.59375\n",
      "The representation loss after processing this batch is:  5.59389591217041e-05\n",
      "The classification loss after processing this batch is:  22275.0859375\n",
      "The representation loss after processing this batch is:  6.216485053300858e-05\n",
      "The classification loss after processing this batch is:  26787.81640625\n",
      "The representation loss after processing this batch is:  5.6568533182144165e-05\n",
      "The classification loss after processing this batch is:  22668.80078125\n",
      "The representation loss after processing this batch is:  5.174148827791214e-05\n",
      "The classification loss after processing this batch is:  21194.576171875\n",
      "The representation loss after processing this batch is:  5.073286592960358e-05\n",
      "The classification loss after processing this batch is:  22444.396484375\n",
      "The representation loss after processing this batch is:  4.8930756747722626e-05\n",
      "The classification loss after processing this batch is:  23627.951171875\n",
      "The representation loss after processing this batch is:  4.9347057938575745e-05\n",
      "The classification loss after processing this batch is:  22703.787109375\n",
      "The representation loss after processing this batch is:  4.8558227717876434e-05\n",
      "The classification loss after processing this batch is:  21875.466796875\n",
      "The representation loss after processing this batch is:  5.278363823890686e-05\n",
      "The classification loss after processing this batch is:  22023.96484375\n",
      "The representation loss after processing this batch is:  4.918128252029419e-05\n",
      "The classification loss after processing this batch is:  21906.982421875\n",
      "The representation loss after processing this batch is:  5.092937499284744e-05\n",
      "The classification loss after processing this batch is:  20914.2890625\n",
      "The representation loss after processing this batch is:  4.9076974391937256e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22094.69140625\n",
      "The representation loss after processing this batch is:  5.667097866535187e-05\n",
      "The classification loss after processing this batch is:  21757.482421875\n",
      "The representation loss after processing this batch is:  5.1409006118774414e-05\n",
      "The classification loss after processing this batch is:  22291.701171875\n",
      "The representation loss after processing this batch is:  5.4790638387203217e-05\n",
      "The classification loss after processing this batch is:  22190.34765625\n",
      "The representation loss after processing this batch is:  5.3159892559051514e-05\n",
      "The classification loss after processing this batch is:  22224.609375\n",
      "The representation loss after processing this batch is:  5.858251824975014e-05\n",
      "The classification loss after processing this batch is:  21001.521484375\n",
      "The representation loss after processing this batch is:  4.7310721129179e-05\n",
      "The classification loss after processing this batch is:  20443.7734375\n",
      "The representation loss after processing this batch is:  6.214901804924011e-05\n",
      "The classification loss after processing this batch is:  20899.90234375\n",
      "The representation loss after processing this batch is:  5.083717405796051e-05\n",
      "The classification loss after processing this batch is:  20737.875\n",
      "The representation loss after processing this batch is:  5.144951865077019e-05\n",
      "The classification loss after processing this batch is:  21983.13671875\n",
      "The representation loss after processing this batch is:  5.6051649153232574e-05\n",
      "The classification loss after processing this batch is:  21627.525390625\n",
      "The representation loss after processing this batch is:  5.1690731197595596e-05\n",
      "The classification loss after processing this batch is:  21061.69921875\n",
      "The representation loss after processing this batch is:  5.8786943554878235e-05\n",
      "The classification loss after processing this batch is:  19744.87109375\n",
      "The representation loss after processing this batch is:  5.4486095905303955e-05\n",
      "The classification loss after processing this batch is:  19921.05859375\n",
      "The representation loss after processing this batch is:  5.522649735212326e-05\n",
      "The classification loss after processing this batch is:  21741.77734375\n",
      "The representation loss after processing this batch is:  5.380157381296158e-05\n",
      "The classification loss after processing this batch is:  22386.9609375\n",
      "The representation loss after processing this batch is:  4.961993545293808e-05\n",
      "The classification loss after processing this batch is:  22442.50390625\n",
      "The representation loss after processing this batch is:  6.0152262449264526e-05\n",
      "The classification loss after processing this batch is:  20533.5625\n",
      "The representation loss after processing this batch is:  5.5301934480667114e-05\n",
      "The classification loss after processing this batch is:  21683.65625\n",
      "The representation loss after processing this batch is:  5.3367577493190765e-05\n",
      "The classification loss after processing this batch is:  20672.74609375\n",
      "The representation loss after processing this batch is:  5.331449210643768e-05\n",
      "The classification loss after processing this batch is:  21481.7109375\n",
      "The representation loss after processing this batch is:  5.873851478099823e-05\n",
      "The classification loss after processing this batch is:  20703.93359375\n",
      "The representation loss after processing this batch is:  5.296943709254265e-05\n",
      "The classification loss after processing this batch is:  20152.35546875\n",
      "The representation loss after processing this batch is:  5.0561968237161636e-05\n",
      "The classification loss after processing this batch is:  19980.15234375\n",
      "The representation loss after processing this batch is:  5.1359646022319794e-05\n",
      "The classification loss after processing this batch is:  21014.310546875\n",
      "The representation loss after processing this batch is:  5.691312253475189e-05\n",
      "The classification loss after processing this batch is:  21241.6640625\n",
      "The representation loss after processing this batch is:  5.959067493677139e-05\n",
      "The classification loss after processing this batch is:  21350.0390625\n",
      "The representation loss after processing this batch is:  5.055312067270279e-05\n",
      "The classification loss after processing this batch is:  21393.171875\n",
      "The representation loss after processing this batch is:  5.36162406206131e-05\n",
      "The classification loss after processing this batch is:  20812.58203125\n",
      "The representation loss after processing this batch is:  4.942994564771652e-05\n",
      "The classification loss after processing this batch is:  22267.35546875\n",
      "The representation loss after processing this batch is:  5.070725455880165e-05\n",
      "The classification loss after processing this batch is:  23624.3515625\n",
      "The representation loss after processing this batch is:  5.9126876294612885e-05\n",
      "The classification loss after processing this batch is:  22910.85546875\n",
      "The representation loss after processing this batch is:  5.68656250834465e-05\n",
      "The classification loss after processing this batch is:  22610.314453125\n",
      "The representation loss after processing this batch is:  5.763070657849312e-05\n",
      "The classification loss after processing this batch is:  20855.1640625\n",
      "The representation loss after processing this batch is:  5.173264071345329e-05\n",
      "The classification loss after processing this batch is:  21059.80859375\n",
      "The representation loss after processing this batch is:  4.556635394692421e-05\n",
      "The classification loss after processing this batch is:  22250.150390625\n",
      "The representation loss after processing this batch is:  6.382633000612259e-05\n",
      "The classification loss after processing this batch is:  20608.7109375\n",
      "The representation loss after processing this batch is:  5.9475190937519073e-05\n",
      "The classification loss after processing this batch is:  20792.271484375\n",
      "The representation loss after processing this batch is:  5.238549783825874e-05\n",
      "The classification loss after processing this batch is:  21680.677734375\n",
      "The representation loss after processing this batch is:  5.2683521062135696e-05\n",
      "The classification loss after processing this batch is:  21592.62890625\n",
      "The representation loss after processing this batch is:  4.933401942253113e-05\n",
      "The classification loss after processing this batch is:  21344.974609375\n",
      "The representation loss after processing this batch is:  5.0853006541728973e-05\n",
      "The classification loss after processing this batch is:  21015.734375\n",
      "The representation loss after processing this batch is:  4.9688853323459625e-05\n",
      "The classification loss after processing this batch is:  22558.59765625\n",
      "The representation loss after processing this batch is:  5.77559694647789e-05\n",
      "The classification loss after processing this batch is:  22319.080078125\n",
      "The representation loss after processing this batch is:  5.470775067806244e-05\n",
      "The classification loss after processing this batch is:  22676.63671875\n",
      "The representation loss after processing this batch is:  4.460709169507027e-05\n",
      "The classification loss after processing this batch is:  23192.416015625\n",
      "The representation loss after processing this batch is:  5.1713548600673676e-05\n",
      "The classification loss after processing this batch is:  22007.0546875\n",
      "The representation loss after processing this batch is:  4.902016371488571e-05\n",
      "The classification loss after processing this batch is:  20964.5859375\n",
      "The representation loss after processing this batch is:  5.544256418943405e-05\n",
      "The classification loss after processing this batch is:  20647.51171875\n",
      "The representation loss after processing this batch is:  5.553103983402252e-05\n",
      "The classification loss after processing this batch is:  20824.3671875\n",
      "The representation loss after processing this batch is:  5.1137059926986694e-05\n",
      "The classification loss after processing this batch is:  21430.51953125\n",
      "The representation loss after processing this batch is:  5.15463761985302e-05\n",
      "The classification loss after processing this batch is:  20888.51953125\n",
      "The representation loss after processing this batch is:  4.737125709652901e-05\n",
      "The classification loss after processing this batch is:  21520.28125\n",
      "The representation loss after processing this batch is:  5.168141797184944e-05\n",
      "The classification loss after processing this batch is:  21163.8515625\n",
      "The representation loss after processing this batch is:  5.422346293926239e-05\n",
      "The classification loss after processing this batch is:  23895.1640625\n",
      "The representation loss after processing this batch is:  5.790870636701584e-05\n",
      "The classification loss after processing this batch is:  23298.455078125\n",
      "The representation loss after processing this batch is:  4.986859858036041e-05\n",
      "The classification loss after processing this batch is:  21203.56640625\n",
      "The representation loss after processing this batch is:  4.5457854866981506e-05\n",
      "The classification loss after processing this batch is:  20283.66015625\n",
      "The representation loss after processing this batch is:  5.54332509636879e-05\n",
      "The classification loss after processing this batch is:  20613.96875\n",
      "The representation loss after processing this batch is:  4.890980198979378e-05\n",
      "The classification loss after processing this batch is:  21552.431640625\n",
      "The representation loss after processing this batch is:  5.7942233979701996e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  20995.4609375\n",
      "The representation loss after processing this batch is:  5.553197115659714e-05\n",
      "The classification loss after processing this batch is:  21873.958984375\n",
      "The representation loss after processing this batch is:  5.3091906011104584e-05\n",
      "The classification loss after processing this batch is:  20938.23046875\n",
      "The representation loss after processing this batch is:  5.0166621804237366e-05\n",
      "The classification loss after processing this batch is:  20536.431640625\n",
      "The representation loss after processing this batch is:  4.6994537115097046e-05\n",
      "The classification loss after processing this batch is:  20309.650390625\n",
      "The representation loss after processing this batch is:  4.828348755836487e-05\n",
      "The classification loss after processing this batch is:  21942.34375\n",
      "The representation loss after processing this batch is:  5.242321640253067e-05\n",
      "The classification loss after processing this batch is:  23144.78515625\n",
      "The representation loss after processing this batch is:  5.948450416326523e-05\n",
      "The classification loss after processing this batch is:  21327.767578125\n",
      "The representation loss after processing this batch is:  5.391798913478851e-05\n",
      "The classification loss after processing this batch is:  21655.568359375\n",
      "The representation loss after processing this batch is:  5.2487943321466446e-05\n",
      "The classification loss after processing this batch is:  22918.125\n",
      "The representation loss after processing this batch is:  5.576014518737793e-05\n",
      "The classification loss after processing this batch is:  21914.3671875\n",
      "The representation loss after processing this batch is:  4.72203828394413e-05\n",
      "The classification loss after processing this batch is:  23239.35546875\n",
      "The representation loss after processing this batch is:  4.786951467394829e-05\n",
      "The classification loss after processing this batch is:  21074.4375\n",
      "The representation loss after processing this batch is:  4.92120161652565e-05\n",
      "The classification loss after processing this batch is:  22071.759765625\n",
      "The representation loss after processing this batch is:  6.742263212800026e-05\n",
      "The classification loss after processing this batch is:  21064.5625\n",
      "The representation loss after processing this batch is:  5.478784441947937e-05\n",
      "The classification loss after processing this batch is:  21656.978515625\n",
      "The representation loss after processing this batch is:  5.0848815590143204e-05\n",
      "The classification loss after processing this batch is:  21058.828125\n",
      "The representation loss after processing this batch is:  5.35864382982254e-05\n",
      "The classification loss after processing this batch is:  21105.8671875\n",
      "The representation loss after processing this batch is:  5.0088390707969666e-05\n",
      "The classification loss after processing this batch is:  21574.21484375\n",
      "The representation loss after processing this batch is:  4.733121022582054e-05\n",
      "The classification loss after processing this batch is:  20705.029296875\n",
      "The representation loss after processing this batch is:  5.1769427955150604e-05\n",
      "The classification loss after processing this batch is:  21005.66796875\n",
      "The representation loss after processing this batch is:  5.1709823310375214e-05\n",
      "The classification loss after processing this batch is:  20100.14453125\n",
      "The representation loss after processing this batch is:  5.0202012062072754e-05\n",
      "The classification loss after processing this batch is:  20270.28125\n",
      "The representation loss after processing this batch is:  5.808938294649124e-05\n",
      "The classification loss after processing this batch is:  20023.8046875\n",
      "The representation loss after processing this batch is:  5.0904229283332825e-05\n",
      "The classification loss after processing this batch is:  21728.138671875\n",
      "The representation loss after processing this batch is:  5.374010652303696e-05\n",
      "The classification loss after processing this batch is:  20866.82421875\n",
      "The representation loss after processing this batch is:  5.8026984333992004e-05\n",
      "The classification loss after processing this batch is:  21470.296875\n",
      "The representation loss after processing this batch is:  5.499552935361862e-05\n",
      "The classification loss after processing this batch is:  21642.8515625\n",
      "The representation loss after processing this batch is:  4.8807356506586075e-05\n",
      "The classification loss after processing this batch is:  20558.830078125\n",
      "The representation loss after processing this batch is:  4.693027585744858e-05\n",
      "The classification loss after processing this batch is:  21678.955078125\n",
      "The representation loss after processing this batch is:  5.122460424900055e-05\n",
      "The classification loss after processing this batch is:  21368.46484375\n",
      "The representation loss after processing this batch is:  5.7728029787540436e-05\n",
      "The classification loss after processing this batch is:  20460.0390625\n",
      "The representation loss after processing this batch is:  5.068443715572357e-05\n",
      "The classification loss after processing this batch is:  21187.75390625\n",
      "The representation loss after processing this batch is:  5.105417221784592e-05\n",
      "The classification loss after processing this batch is:  20875.3046875\n",
      "The representation loss after processing this batch is:  5.119107663631439e-05\n",
      "The classification loss after processing this batch is:  20534.072265625\n",
      "The representation loss after processing this batch is:  5.007116124033928e-05\n",
      "The classification loss after processing this batch is:  21244.990234375\n",
      "The representation loss after processing this batch is:  5.3374096751213074e-05\n",
      "The classification loss after processing this batch is:  20746.0078125\n",
      "The representation loss after processing this batch is:  5.5441632866859436e-05\n",
      "The classification loss after processing this batch is:  21661.2421875\n",
      "The representation loss after processing this batch is:  5.9081241488456726e-05\n",
      "The classification loss after processing this batch is:  22501.87890625\n",
      "The representation loss after processing this batch is:  6.734160706400871e-05\n",
      "The classification loss after processing this batch is:  21220.697265625\n",
      "The representation loss after processing this batch is:  6.103515625e-05\n",
      "The classification loss after processing this batch is:  23323.904296875\n",
      "The representation loss after processing this batch is:  4.969397559762001e-05\n",
      "The classification loss after processing this batch is:  23714.57421875\n",
      "The representation loss after processing this batch is:  5.3144991397857666e-05\n",
      "The classification loss after processing this batch is:  21094.201171875\n",
      "The representation loss after processing this batch is:  5.117710679769516e-05\n",
      "The classification loss after processing this batch is:  21604.53125\n",
      "The representation loss after processing this batch is:  4.934985190629959e-05\n",
      "The classification loss after processing this batch is:  22839.38671875\n",
      "The representation loss after processing this batch is:  5.9256795793771744e-05\n",
      "The classification loss after processing this batch is:  21385.4765625\n",
      "The representation loss after processing this batch is:  4.71360981464386e-05\n",
      "The classification loss after processing this batch is:  21275.865234375\n",
      "The representation loss after processing this batch is:  5.408190190792084e-05\n",
      "The classification loss after processing this batch is:  21104.88671875\n",
      "The representation loss after processing this batch is:  4.740757867693901e-05\n",
      "The classification loss after processing this batch is:  21412.26953125\n",
      "The representation loss after processing this batch is:  5.2111223340034485e-05\n",
      "The classification loss after processing this batch is:  22201.705078125\n",
      "The representation loss after processing this batch is:  4.962366074323654e-05\n",
      "The classification loss after processing this batch is:  21997.287109375\n",
      "The representation loss after processing this batch is:  5.0679780542850494e-05\n",
      "The classification loss after processing this batch is:  23921.412109375\n",
      "The representation loss after processing this batch is:  5.7714059948921204e-05\n",
      "The classification loss after processing this batch is:  22553.806640625\n",
      "The representation loss after processing this batch is:  4.8230867832899094e-05\n",
      "The classification loss after processing this batch is:  22025.640625\n",
      "The representation loss after processing this batch is:  5.194172263145447e-05\n",
      "The classification loss after processing this batch is:  20670.30859375\n",
      "The representation loss after processing this batch is:  4.7625042498111725e-05\n",
      "The classification loss after processing this batch is:  21054.90625\n",
      "The representation loss after processing this batch is:  4.9659982323646545e-05\n",
      "The classification loss after processing this batch is:  22047.595703125\n",
      "The representation loss after processing this batch is:  5.0445087254047394e-05\n",
      "The classification loss after processing this batch is:  20914.98046875\n",
      "The representation loss after processing this batch is:  4.648836329579353e-05\n",
      "The classification loss after processing this batch is:  19898.125\n",
      "The representation loss after processing this batch is:  5.593709647655487e-05\n",
      "The classification loss after processing this batch is:  22490.509765625\n",
      "The representation loss after processing this batch is:  5.051214247941971e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  20560.310546875\n",
      "The representation loss after processing this batch is:  5.0449278205633163e-05\n",
      "The classification loss after processing this batch is:  20662.5625\n",
      "The representation loss after processing this batch is:  5.149189382791519e-05\n",
      "The classification loss after processing this batch is:  19971.56640625\n",
      "The representation loss after processing this batch is:  5.0411559641361237e-05\n",
      "The classification loss after processing this batch is:  20660.8671875\n",
      "The representation loss after processing this batch is:  5.480460822582245e-05\n",
      "The classification loss after processing this batch is:  20166.828125\n",
      "The representation loss after processing this batch is:  4.963576793670654e-05\n",
      "The classification loss after processing this batch is:  21447.87890625\n",
      "The representation loss after processing this batch is:  4.5826658606529236e-05\n",
      "The classification loss after processing this batch is:  20914.353515625\n",
      "The representation loss after processing this batch is:  4.537729546427727e-05\n",
      "The classification loss after processing this batch is:  20461.5546875\n",
      "The representation loss after processing this batch is:  4.9118418246507645e-05\n",
      "The classification loss after processing this batch is:  21597.54296875\n",
      "The representation loss after processing this batch is:  4.868023097515106e-05\n",
      "The classification loss after processing this batch is:  22092.27734375\n",
      "The representation loss after processing this batch is:  5.077151581645012e-05\n",
      "The classification loss after processing this batch is:  20250.734375\n",
      "The representation loss after processing this batch is:  5.324278026819229e-05\n",
      "The classification loss after processing this batch is:  20510.03125\n",
      "The representation loss after processing this batch is:  5.087023600935936e-05\n",
      "The classification loss after processing this batch is:  20919.642578125\n",
      "The representation loss after processing this batch is:  4.746066406369209e-05\n",
      "The classification loss after processing this batch is:  20700.892578125\n",
      "The representation loss after processing this batch is:  5.100201815366745e-05\n",
      "The classification loss after processing this batch is:  21672.638671875\n",
      "The representation loss after processing this batch is:  5.1744282245635986e-05\n",
      "The classification loss after processing this batch is:  20422.6796875\n",
      "The representation loss after processing this batch is:  4.894193261861801e-05\n",
      "The classification loss after processing this batch is:  20049.6171875\n",
      "The representation loss after processing this batch is:  5.0858594477176666e-05\n",
      "The classification loss after processing this batch is:  21273.78515625\n",
      "The representation loss after processing this batch is:  5.3481198847293854e-05\n",
      "The classification loss after processing this batch is:  23042.8671875\n",
      "The representation loss after processing this batch is:  5.614571273326874e-05\n",
      "The classification loss after processing this batch is:  20522.826171875\n",
      "The representation loss after processing this batch is:  4.930654540657997e-05\n",
      "The classification loss after processing this batch is:  21521.21484375\n",
      "The representation loss after processing this batch is:  5.01447357237339e-05\n",
      "The classification loss after processing this batch is:  23336.482421875\n",
      "The representation loss after processing this batch is:  5.082134157419205e-05\n",
      "The classification loss after processing this batch is:  21051.765625\n",
      "The representation loss after processing this batch is:  4.930514842271805e-05\n",
      "The classification loss after processing this batch is:  20206.4921875\n",
      "The representation loss after processing this batch is:  5.168560892343521e-05\n",
      "The classification loss after processing this batch is:  20600.361328125\n",
      "The representation loss after processing this batch is:  4.955846816301346e-05\n",
      "The classification loss after processing this batch is:  20363.466796875\n",
      "The representation loss after processing this batch is:  4.7561246901750565e-05\n",
      "The classification loss after processing this batch is:  21213.533203125\n",
      "The representation loss after processing this batch is:  4.679849371314049e-05\n",
      "The classification loss after processing this batch is:  20382.765625\n",
      "The representation loss after processing this batch is:  5.582533776760101e-05\n",
      "The classification loss after processing this batch is:  21017.203125\n",
      "The representation loss after processing this batch is:  4.8976391553878784e-05\n",
      "The classification loss after processing this batch is:  24118.939453125\n",
      "The representation loss after processing this batch is:  5.715806037187576e-05\n",
      "The classification loss after processing this batch is:  22525.943359375\n",
      "The representation loss after processing this batch is:  4.8333313316106796e-05\n",
      "The classification loss after processing this batch is:  21646.48046875\n",
      "The representation loss after processing this batch is:  4.870397970080376e-05\n",
      "The classification loss after processing this batch is:  20552.99609375\n",
      "The representation loss after processing this batch is:  4.878547042608261e-05\n",
      "The classification loss after processing this batch is:  21283.875\n",
      "The representation loss after processing this batch is:  5.454476922750473e-05\n",
      "The classification loss after processing this batch is:  21385.220703125\n",
      "The representation loss after processing this batch is:  5.428120493888855e-05\n",
      "The classification loss after processing this batch is:  20622.544921875\n",
      "The representation loss after processing this batch is:  5.144905298948288e-05\n",
      "The classification loss after processing this batch is:  20043.0859375\n",
      "The representation loss after processing this batch is:  4.994124174118042e-05\n",
      "The classification loss after processing this batch is:  20722.97265625\n",
      "The representation loss after processing this batch is:  5.0337053835392e-05\n",
      "The classification loss after processing this batch is:  20715.583984375\n",
      "The representation loss after processing this batch is:  4.8193614929914474e-05\n",
      "The classification loss after processing this batch is:  20067.580078125\n",
      "The representation loss after processing this batch is:  5.158223211765289e-05\n",
      "The classification loss after processing this batch is:  21074.544921875\n",
      "The representation loss after processing this batch is:  4.9015041440725327e-05\n",
      "The classification loss after processing this batch is:  20238.03125\n",
      "The representation loss after processing this batch is:  5.4770614951848984e-05\n",
      "The classification loss after processing this batch is:  22452.578125\n",
      "The representation loss after processing this batch is:  5.4028816521167755e-05\n",
      "The classification loss after processing this batch is:  22117.35546875\n",
      "The representation loss after processing this batch is:  5.029281601309776e-05\n",
      "The classification loss after processing this batch is:  21047.541015625\n",
      "The representation loss after processing this batch is:  4.889024421572685e-05\n",
      "The classification loss after processing this batch is:  20875.91015625\n",
      "The representation loss after processing this batch is:  5.082134157419205e-05\n",
      "The classification loss after processing this batch is:  20676.896484375\n",
      "The representation loss after processing this batch is:  5.1845796406269073e-05\n",
      "The classification loss after processing this batch is:  22235.6171875\n",
      "The representation loss after processing this batch is:  5.136895924806595e-05\n",
      "The classification loss after processing this batch is:  21629.4296875\n",
      "The representation loss after processing this batch is:  4.9037858843803406e-05\n",
      "The classification loss after processing this batch is:  20890.91796875\n",
      "The representation loss after processing this batch is:  4.928559064865112e-05\n",
      "The classification loss after processing this batch is:  21342.939453125\n",
      "The representation loss after processing this batch is:  4.74732369184494e-05\n",
      "The classification loss after processing this batch is:  23020.611328125\n",
      "The representation loss after processing this batch is:  6.392877548933029e-05\n",
      "The classification loss after processing this batch is:  20569.833984375\n",
      "The representation loss after processing this batch is:  5.046650767326355e-05\n",
      "The classification loss after processing this batch is:  21539.791015625\n",
      "The representation loss after processing this batch is:  5.32432459294796e-05\n",
      "The classification loss after processing this batch is:  21706.177734375\n",
      "The representation loss after processing this batch is:  6.395392119884491e-05\n",
      "The classification loss after processing this batch is:  21143.34765625\n",
      "The representation loss after processing this batch is:  5.134847015142441e-05\n",
      "The classification loss after processing this batch is:  21830.015625\n",
      "The representation loss after processing this batch is:  5.117477849125862e-05\n",
      "The classification loss after processing this batch is:  22305.98046875\n",
      "The representation loss after processing this batch is:  4.858570173382759e-05\n",
      "The classification loss after processing this batch is:  20940.986328125\n",
      "The representation loss after processing this batch is:  5.1655806601047516e-05\n",
      "The classification loss after processing this batch is:  21737.474609375\n",
      "The representation loss after processing this batch is:  4.820851609110832e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22035.76953125\n",
      "The representation loss after processing this batch is:  4.9612484872341156e-05\n",
      "The classification loss after processing this batch is:  20853.5078125\n",
      "The representation loss after processing this batch is:  5.6121498346328735e-05\n",
      "The classification loss after processing this batch is:  21820.25\n",
      "The representation loss after processing this batch is:  4.6963803470134735e-05\n",
      "The classification loss after processing this batch is:  21535.30859375\n",
      "The representation loss after processing this batch is:  5.384627729654312e-05\n",
      "The classification loss after processing this batch is:  20459.849609375\n",
      "The representation loss after processing this batch is:  4.921248182654381e-05\n",
      "The classification loss after processing this batch is:  20621.83984375\n",
      "The representation loss after processing this batch is:  5.1802024245262146e-05\n",
      "The classification loss after processing this batch is:  20563.30078125\n",
      "The representation loss after processing this batch is:  4.861271008849144e-05\n",
      "The classification loss after processing this batch is:  20397.6875\n",
      "The representation loss after processing this batch is:  4.971399903297424e-05\n",
      "The classification loss after processing this batch is:  22381.5390625\n",
      "The representation loss after processing this batch is:  4.7851353883743286e-05\n",
      "The classification loss after processing this batch is:  21776.6953125\n",
      "The representation loss after processing this batch is:  4.510022699832916e-05\n",
      "The classification loss after processing this batch is:  22759.72265625\n",
      "The representation loss after processing this batch is:  5.552731454372406e-05\n",
      "The classification loss after processing this batch is:  20043.7578125\n",
      "The representation loss after processing this batch is:  4.9524009227752686e-05\n",
      "The classification loss after processing this batch is:  20510.154296875\n",
      "The representation loss after processing this batch is:  5.6916847825050354e-05\n",
      "The classification loss after processing this batch is:  20822.953125\n",
      "The representation loss after processing this batch is:  7.0223119109869e-05\n",
      "The classification loss after processing this batch is:  20632.478515625\n",
      "The representation loss after processing this batch is:  4.8298388719558716e-05\n",
      "The classification loss after processing this batch is:  21843.66015625\n",
      "The representation loss after processing this batch is:  5.4681673645973206e-05\n",
      "The classification loss after processing this batch is:  20803.50390625\n",
      "The representation loss after processing this batch is:  4.761712625622749e-05\n",
      "The classification loss after processing this batch is:  21155.984375\n",
      "The representation loss after processing this batch is:  4.546763375401497e-05\n",
      "The classification loss after processing this batch is:  21406.240234375\n",
      "The representation loss after processing this batch is:  5.137128755450249e-05\n",
      "The classification loss after processing this batch is:  20611.546875\n",
      "The representation loss after processing this batch is:  4.90252859890461e-05\n",
      "The classification loss after processing this batch is:  22838.77734375\n",
      "The representation loss after processing this batch is:  5.628913640975952e-05\n",
      "The classification loss after processing this batch is:  22751.67578125\n",
      "The representation loss after processing this batch is:  5.077291280031204e-05\n",
      "The classification loss after processing this batch is:  22023.49609375\n",
      "The representation loss after processing this batch is:  4.900200292468071e-05\n",
      "The classification loss after processing this batch is:  20392.1484375\n",
      "The representation loss after processing this batch is:  5.21000474691391e-05\n",
      "The classification loss after processing this batch is:  22495.869140625\n",
      "The representation loss after processing this batch is:  4.739686846733093e-05\n",
      "The classification loss after processing this batch is:  22154.90234375\n",
      "The representation loss after processing this batch is:  4.597986117005348e-05\n",
      "The classification loss after processing this batch is:  20656.9296875\n",
      "The representation loss after processing this batch is:  4.7262758016586304e-05\n",
      "The classification loss after processing this batch is:  23006.125\n",
      "The representation loss after processing this batch is:  5.268119275569916e-05\n",
      "The classification loss after processing this batch is:  22945.873046875\n",
      "The representation loss after processing this batch is:  5.304254591464996e-05\n",
      "The classification loss after processing this batch is:  20312.74609375\n",
      "The representation loss after processing this batch is:  4.837615415453911e-05\n",
      "The classification loss after processing this batch is:  21025.8828125\n",
      "The representation loss after processing this batch is:  5.223974585533142e-05\n",
      "The classification loss after processing this batch is:  21552.21484375\n",
      "The representation loss after processing this batch is:  6.150314584374428e-05\n",
      "The classification loss after processing this batch is:  21185.78515625\n",
      "The representation loss after processing this batch is:  5.2249524742364883e-05\n",
      "The classification loss after processing this batch is:  22229.57421875\n",
      "The representation loss after processing this batch is:  5.703512579202652e-05\n",
      "The classification loss after processing this batch is:  22775.1796875\n",
      "The representation loss after processing this batch is:  6.106123328208923e-05\n",
      "The classification loss after processing this batch is:  20579.26171875\n",
      "The representation loss after processing this batch is:  5.615968257188797e-05\n",
      "The classification loss after processing this batch is:  19933.462890625\n",
      "The representation loss after processing this batch is:  5.434919148683548e-05\n",
      "The classification loss after processing this batch is:  21350.45703125\n",
      "The representation loss after processing this batch is:  5.041761323809624e-05\n",
      "The classification loss after processing this batch is:  22226.1015625\n",
      "The representation loss after processing this batch is:  5.077477544546127e-05\n",
      "The classification loss after processing this batch is:  21006.12109375\n",
      "The representation loss after processing this batch is:  4.863925278186798e-05\n",
      "The classification loss after processing this batch is:  21841.2734375\n",
      "The representation loss after processing this batch is:  5.557015538215637e-05\n",
      "The classification loss after processing this batch is:  21336.529296875\n",
      "The representation loss after processing this batch is:  4.4504180550575256e-05\n",
      "The classification loss after processing this batch is:  21416.6171875\n",
      "The representation loss after processing this batch is:  4.8978254199028015e-05\n",
      "The classification loss after processing this batch is:  20895.796875\n",
      "The representation loss after processing this batch is:  5.390821024775505e-05\n",
      "The classification loss after processing this batch is:  21382.421875\n",
      "The representation loss after processing this batch is:  5.1383860409259796e-05\n",
      "The classification loss after processing this batch is:  22570.58203125\n",
      "The representation loss after processing this batch is:  5.243578925728798e-05\n",
      "The classification loss after processing this batch is:  20391.8359375\n",
      "The representation loss after processing this batch is:  4.425831139087677e-05\n",
      "The classification loss after processing this batch is:  20112.94921875\n",
      "The representation loss after processing this batch is:  4.931958392262459e-05\n",
      "The classification loss after processing this batch is:  19882.69140625\n",
      "The representation loss after processing this batch is:  5.2279792726039886e-05\n",
      "The classification loss after processing this batch is:  20093.4453125\n",
      "The representation loss after processing this batch is:  4.389230161905289e-05\n",
      "The classification loss after processing this batch is:  20507.765625\n",
      "The representation loss after processing this batch is:  5.2193645387887955e-05\n",
      "The classification loss after processing this batch is:  21668.787109375\n",
      "The representation loss after processing this batch is:  4.813028499484062e-05\n",
      "The classification loss after processing this batch is:  21884.890625\n",
      "The representation loss after processing this batch is:  5.037104710936546e-05\n",
      "The classification loss after processing this batch is:  20509.453125\n",
      "The representation loss after processing this batch is:  4.9987807869911194e-05\n",
      "The classification loss after processing this batch is:  20074.484375\n",
      "The representation loss after processing this batch is:  4.8173125833272934e-05\n",
      "The classification loss after processing this batch is:  20150.0625\n",
      "The representation loss after processing this batch is:  4.9493275582790375e-05\n",
      "The classification loss after processing this batch is:  20814.462890625\n",
      "The representation loss after processing this batch is:  5.207350477576256e-05\n",
      "The classification loss after processing this batch is:  20869.55078125\n",
      "The representation loss after processing this batch is:  5.016941577196121e-05\n",
      "The classification loss after processing this batch is:  20142.08203125\n",
      "The representation loss after processing this batch is:  5.201529711484909e-05\n",
      "The classification loss after processing this batch is:  22578.28125\n",
      "The representation loss after processing this batch is:  5.1633454859256744e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  20673.857421875\n",
      "The representation loss after processing this batch is:  4.4739339500665665e-05\n",
      "The classification loss after processing this batch is:  20448.94921875\n",
      "The representation loss after processing this batch is:  6.469152867794037e-05\n",
      "The classification loss after processing this batch is:  20860.24609375\n",
      "The representation loss after processing this batch is:  5.487259477376938e-05\n",
      "The classification loss after processing this batch is:  21312.9453125\n",
      "The representation loss after processing this batch is:  5.268445238471031e-05\n",
      "The classification loss after processing this batch is:  21009.59765625\n",
      "The representation loss after processing this batch is:  5.0412025302648544e-05\n",
      "The classification loss after processing this batch is:  20288.984375\n",
      "The representation loss after processing this batch is:  5.140341818332672e-05\n",
      "The classification loss after processing this batch is:  20954.072265625\n",
      "The representation loss after processing this batch is:  4.8801302909851074e-05\n",
      "The classification loss after processing this batch is:  22444.171875\n",
      "The representation loss after processing this batch is:  5.217641592025757e-05\n",
      "The classification loss after processing this batch is:  19745.486328125\n",
      "The representation loss after processing this batch is:  5.61014749109745e-05\n",
      "The classification loss after processing this batch is:  20473.24609375\n",
      "The representation loss after processing this batch is:  5.059642717242241e-05\n",
      "The classification loss after processing this batch is:  19471.1875\n",
      "The representation loss after processing this batch is:  5.204789340496063e-05\n",
      "The classification loss after processing this batch is:  20861.986328125\n",
      "The representation loss after processing this batch is:  4.768744111061096e-05\n",
      "The classification loss after processing this batch is:  21099.9921875\n",
      "The representation loss after processing this batch is:  5.047209560871124e-05\n",
      "The classification loss after processing this batch is:  20551.185546875\n",
      "The representation loss after processing this batch is:  5.190074443817139e-05\n",
      "The classification loss after processing this batch is:  20188.66015625\n",
      "The representation loss after processing this batch is:  5.526933819055557e-05\n",
      "The classification loss after processing this batch is:  19765.810546875\n",
      "The representation loss after processing this batch is:  5.0570815801620483e-05\n",
      "The classification loss after processing this batch is:  21030.88671875\n",
      "The representation loss after processing this batch is:  4.58667054772377e-05\n",
      "The classification loss after processing this batch is:  20506.529296875\n",
      "The representation loss after processing this batch is:  4.861317574977875e-05\n",
      "The classification loss after processing this batch is:  19994.998046875\n",
      "The representation loss after processing this batch is:  5.1637645810842514e-05\n",
      "The classification loss after processing this batch is:  23706.7890625\n",
      "The representation loss after processing this batch is:  5.769170820713043e-05\n",
      "The classification loss after processing this batch is:  22469.041015625\n",
      "The representation loss after processing this batch is:  5.1119364798069e-05\n",
      "The classification loss after processing this batch is:  21345.6796875\n",
      "The representation loss after processing this batch is:  5.408748984336853e-05\n",
      "The classification loss after processing this batch is:  20896.505859375\n",
      "The representation loss after processing this batch is:  5.800463259220123e-05\n",
      "The classification loss after processing this batch is:  20280.359375\n",
      "The representation loss after processing this batch is:  5.3340569138526917e-05\n",
      "The classification loss after processing this batch is:  20874.556640625\n",
      "The representation loss after processing this batch is:  5.236547440290451e-05\n",
      "The classification loss after processing this batch is:  21664.8984375\n",
      "The representation loss after processing this batch is:  5.246885120868683e-05\n",
      "The classification loss after processing this batch is:  20803.875\n",
      "The representation loss after processing this batch is:  4.5632943511009216e-05\n",
      "The classification loss after processing this batch is:  23139.955078125\n",
      "The representation loss after processing this batch is:  4.8968009650707245e-05\n",
      "The classification loss after processing this batch is:  21077.291015625\n",
      "The representation loss after processing this batch is:  5.082506686449051e-05\n",
      "The classification loss after processing this batch is:  20147.24609375\n",
      "The representation loss after processing this batch is:  5.108816549181938e-05\n",
      "The classification loss after processing this batch is:  22158.23046875\n",
      "The representation loss after processing this batch is:  5.205255001783371e-05\n",
      "The classification loss after processing this batch is:  20352.755859375\n",
      "The representation loss after processing this batch is:  4.782341420650482e-05\n",
      "The classification loss after processing this batch is:  20676.30859375\n",
      "The representation loss after processing this batch is:  5.63962385058403e-05\n",
      "The classification loss after processing this batch is:  24478.1484375\n",
      "The representation loss after processing this batch is:  5.901604890823364e-05\n",
      "The classification loss after processing this batch is:  21547.314453125\n",
      "The representation loss after processing this batch is:  6.417650729417801e-05\n",
      "The classification loss after processing this batch is:  20454.76953125\n",
      "The representation loss after processing this batch is:  6.176158785820007e-05\n",
      "The classification loss after processing this batch is:  20850.66796875\n",
      "The representation loss after processing this batch is:  7.940270006656647e-05\n",
      "The classification loss after processing this batch is:  22727.0859375\n",
      "The representation loss after processing this batch is:  5.833897739648819e-05\n",
      "The classification loss after processing this batch is:  19969.08984375\n",
      "The representation loss after processing this batch is:  6.796326488256454e-05\n",
      "The classification loss after processing this batch is:  20916.625\n",
      "The representation loss after processing this batch is:  6.588641554117203e-05\n",
      "The classification loss after processing this batch is:  21780.994140625\n",
      "The representation loss after processing this batch is:  6.632693111896515e-05\n",
      "The classification loss after processing this batch is:  25684.47265625\n",
      "The representation loss after processing this batch is:  6.492994725704193e-05\n",
      "The classification loss after processing this batch is:  27830.44140625\n",
      "The representation loss after processing this batch is:  5.4887495934963226e-05\n",
      "The classification loss after processing this batch is:  20136.078125\n",
      "The representation loss after processing this batch is:  6.0706399381160736e-05\n",
      "The classification loss after processing this batch is:  21335.66015625\n",
      "The representation loss after processing this batch is:  5.581974983215332e-05\n",
      "The classification loss after processing this batch is:  21504.55859375\n",
      "The representation loss after processing this batch is:  5.8300793170928955e-05\n",
      "The classification loss after processing this batch is:  19657.140625\n",
      "The representation loss after processing this batch is:  5.417782813310623e-05\n",
      "The classification loss after processing this batch is:  21115.841796875\n",
      "The representation loss after processing this batch is:  4.994962364435196e-05\n",
      "The classification loss after processing this batch is:  21816.03125\n",
      "The representation loss after processing this batch is:  4.3803825974464417e-05\n",
      "The classification loss after processing this batch is:  20931.4375\n",
      "The representation loss after processing this batch is:  4.4679269194602966e-05\n",
      "The classification loss after processing this batch is:  21137.572265625\n",
      "The representation loss after processing this batch is:  4.579080268740654e-05\n",
      "The classification loss after processing this batch is:  21063.453125\n",
      "The representation loss after processing this batch is:  4.4026877731084824e-05\n",
      "The classification loss after processing this batch is:  20677.18359375\n",
      "The representation loss after processing this batch is:  3.8010068237781525e-05\n",
      "The classification loss after processing this batch is:  20900.78515625\n",
      "The representation loss after processing this batch is:  5.0108879804611206e-05\n",
      "The classification loss after processing this batch is:  20946.330078125\n",
      "The representation loss after processing this batch is:  4.409346729516983e-05\n",
      "The classification loss after processing this batch is:  20989.455078125\n",
      "The representation loss after processing this batch is:  4.877569153904915e-05\n",
      "The classification loss after processing this batch is:  24116.671875\n",
      "The representation loss after processing this batch is:  4.535866901278496e-05\n",
      "The classification loss after processing this batch is:  23477.86328125\n",
      "The representation loss after processing this batch is:  3.9433594793081284e-05\n",
      "The classification loss after processing this batch is:  20652.634765625\n",
      "The representation loss after processing this batch is:  3.9672479033470154e-05\n",
      "The classification loss after processing this batch is:  20606.376953125\n",
      "The representation loss after processing this batch is:  3.767525777220726e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  20515.279296875\n",
      "The representation loss after processing this batch is:  4.104338586330414e-05\n",
      "The classification loss after processing this batch is:  20591.4140625\n",
      "The representation loss after processing this batch is:  3.674812614917755e-05\n",
      "The classification loss after processing this batch is:  21697.3671875\n",
      "The representation loss after processing this batch is:  4.0898099541664124e-05\n",
      "The classification loss after processing this batch is:  20806.552734375\n",
      "The representation loss after processing this batch is:  3.5906676203012466e-05\n",
      "The classification loss after processing this batch is:  23090.1953125\n",
      "The representation loss after processing this batch is:  4.620011895895004e-05\n",
      "The classification loss after processing this batch is:  20888.66015625\n",
      "The representation loss after processing this batch is:  4.147924482822418e-05\n",
      "The classification loss after processing this batch is:  20945.83203125\n",
      "The representation loss after processing this batch is:  4.491955041885376e-05\n",
      "The classification loss after processing this batch is:  20942.09375\n",
      "The representation loss after processing this batch is:  3.490131348371506e-05\n",
      "The classification loss after processing this batch is:  21048.69921875\n",
      "The representation loss after processing this batch is:  3.6990270018577576e-05\n",
      "The classification loss after processing this batch is:  21060.4921875\n",
      "The representation loss after processing this batch is:  4.3309759348630905e-05\n",
      "The classification loss after processing this batch is:  20658.34765625\n",
      "The representation loss after processing this batch is:  3.67211177945137e-05\n",
      "The classification loss after processing this batch is:  20883.015625\n",
      "The representation loss after processing this batch is:  3.659538924694061e-05\n",
      "The classification loss after processing this batch is:  20095.76171875\n",
      "The representation loss after processing this batch is:  4.161521792411804e-05\n",
      "The classification loss after processing this batch is:  20395.0625\n",
      "The representation loss after processing this batch is:  3.7692487239837646e-05\n",
      "The classification loss after processing this batch is:  20285.8359375\n",
      "The representation loss after processing this batch is:  4.063732922077179e-05\n",
      "The classification loss after processing this batch is:  22366.685546875\n",
      "The representation loss after processing this batch is:  3.728456795215607e-05\n",
      "The classification loss after processing this batch is:  21186.505859375\n",
      "The representation loss after processing this batch is:  3.689248114824295e-05\n",
      "The classification loss after processing this batch is:  20262.568359375\n",
      "The representation loss after processing this batch is:  3.830716013908386e-05\n",
      "The classification loss after processing this batch is:  20509.3828125\n",
      "The representation loss after processing this batch is:  3.50484624505043e-05\n",
      "The classification loss after processing this batch is:  19783.41796875\n",
      "The representation loss after processing this batch is:  3.7826597690582275e-05\n",
      "The classification loss after processing this batch is:  20375.83203125\n",
      "The representation loss after processing this batch is:  3.558257594704628e-05\n",
      "The classification loss after processing this batch is:  20638.935546875\n",
      "The representation loss after processing this batch is:  3.59569676220417e-05\n",
      "The classification loss after processing this batch is:  20338.8984375\n",
      "The representation loss after processing this batch is:  3.6010053008794785e-05\n",
      "The classification loss after processing this batch is:  21778.3203125\n",
      "The representation loss after processing this batch is:  3.460841253399849e-05\n",
      "The classification loss after processing this batch is:  25818.6171875\n",
      "The representation loss after processing this batch is:  4.334794357419014e-05\n",
      "The classification loss after processing this batch is:  20637.890625\n",
      "The representation loss after processing this batch is:  3.90494242310524e-05\n",
      "The classification loss after processing this batch is:  20833.78515625\n",
      "The representation loss after processing this batch is:  3.705918788909912e-05\n",
      "The classification loss after processing this batch is:  20790.5234375\n",
      "The representation loss after processing this batch is:  4.9334950745105743e-05\n",
      "The classification loss after processing this batch is:  21063.69140625\n",
      "The representation loss after processing this batch is:  3.592809662222862e-05\n",
      "The classification loss after processing this batch is:  20715.8984375\n",
      "The representation loss after processing this batch is:  3.6660581827163696e-05\n",
      "The classification loss after processing this batch is:  21092.19921875\n",
      "The representation loss after processing this batch is:  3.7779100239276886e-05\n",
      "The classification loss after processing this batch is:  20628.6328125\n",
      "The representation loss after processing this batch is:  3.765476867556572e-05\n",
      "The classification loss after processing this batch is:  21039.4296875\n",
      "The representation loss after processing this batch is:  4.169344902038574e-05\n",
      "The classification loss after processing this batch is:  20452.45703125\n",
      "The representation loss after processing this batch is:  3.7377700209617615e-05\n",
      "The classification loss after processing this batch is:  20627.966796875\n",
      "The representation loss after processing this batch is:  3.9492733776569366e-05\n",
      "The classification loss after processing this batch is:  20540.9296875\n",
      "The representation loss after processing this batch is:  3.434810787439346e-05\n",
      "The classification loss after processing this batch is:  20348.7734375\n",
      "The representation loss after processing this batch is:  3.71299684047699e-05\n",
      "The classification loss after processing this batch is:  20297.91796875\n",
      "The representation loss after processing this batch is:  3.643706440925598e-05\n",
      "The classification loss after processing this batch is:  19394.259765625\n",
      "The representation loss after processing this batch is:  3.752671182155609e-05\n",
      "The classification loss after processing this batch is:  20396.6015625\n",
      "The representation loss after processing this batch is:  4.194676876068115e-05\n",
      "The classification loss after processing this batch is:  20796.40234375\n",
      "The representation loss after processing this batch is:  3.800960257649422e-05\n",
      "The classification loss after processing this batch is:  20617.27734375\n",
      "The representation loss after processing this batch is:  4.064710810780525e-05\n",
      "The classification loss after processing this batch is:  20138.814453125\n",
      "The representation loss after processing this batch is:  3.776839002966881e-05\n",
      "The classification loss after processing this batch is:  21683.7578125\n",
      "The representation loss after processing this batch is:  3.7317629903554916e-05\n",
      "The classification loss after processing this batch is:  20700.4375\n",
      "The representation loss after processing this batch is:  3.925897181034088e-05\n",
      "The classification loss after processing this batch is:  20471.46484375\n",
      "The representation loss after processing this batch is:  4.08724881708622e-05\n",
      "The classification loss after processing this batch is:  20806.32421875\n",
      "The representation loss after processing this batch is:  3.701169043779373e-05\n",
      "The classification loss after processing this batch is:  21964.14453125\n",
      "The representation loss after processing this batch is:  3.64081934094429e-05\n",
      "The classification loss after processing this batch is:  23072.1640625\n",
      "The representation loss after processing this batch is:  3.3200252801179886e-05\n",
      "The classification loss after processing this batch is:  22669.673828125\n",
      "The representation loss after processing this batch is:  3.439001739025116e-05\n",
      "The classification loss after processing this batch is:  19879.234375\n",
      "The representation loss after processing this batch is:  3.8140919059515e-05\n",
      "The classification loss after processing this batch is:  21764.80078125\n",
      "The representation loss after processing this batch is:  3.494136035442352e-05\n",
      "The classification loss after processing this batch is:  20602.8046875\n",
      "The representation loss after processing this batch is:  3.554346039891243e-05\n",
      "The classification loss after processing this batch is:  21989.390625\n",
      "The representation loss after processing this batch is:  3.659771755337715e-05\n",
      "The classification loss after processing this batch is:  22082.4765625\n",
      "The representation loss after processing this batch is:  3.352714702486992e-05\n",
      "The classification loss after processing this batch is:  20685.689453125\n",
      "The representation loss after processing this batch is:  3.439886495471001e-05\n",
      "The classification loss after processing this batch is:  21018.498046875\n",
      "The representation loss after processing this batch is:  3.5047996789216995e-05\n",
      "The classification loss after processing this batch is:  21137.1171875\n",
      "The representation loss after processing this batch is:  3.6149751394987106e-05\n",
      "The classification loss after processing this batch is:  22345.28515625\n",
      "The representation loss after processing this batch is:  4.095491021871567e-05\n",
      "The classification loss after processing this batch is:  21368.5\n",
      "The representation loss after processing this batch is:  4.186946898698807e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  21899.30078125\n",
      "The representation loss after processing this batch is:  3.209756687283516e-05\n",
      "The classification loss after processing this batch is:  22801.55859375\n",
      "The representation loss after processing this batch is:  3.738328814506531e-05\n",
      "The classification loss after processing this batch is:  23319.82421875\n",
      "The representation loss after processing this batch is:  4.525156691670418e-05\n",
      "The classification loss after processing this batch is:  20513.54296875\n",
      "The representation loss after processing this batch is:  3.5210512578487396e-05\n",
      "The classification loss after processing this batch is:  20270.0703125\n",
      "The representation loss after processing this batch is:  3.457767888903618e-05\n",
      "The classification loss after processing this batch is:  20527.4609375\n",
      "The representation loss after processing this batch is:  3.39411199092865e-05\n",
      "The classification loss after processing this batch is:  21562.75\n",
      "The representation loss after processing this batch is:  3.348104655742645e-05\n",
      "The classification loss after processing this batch is:  22908.2265625\n",
      "The representation loss after processing this batch is:  3.43923456966877e-05\n",
      "The classification loss after processing this batch is:  21304.447265625\n",
      "The representation loss after processing this batch is:  3.665639087557793e-05\n",
      "The classification loss after processing this batch is:  20087.02734375\n",
      "The representation loss after processing this batch is:  3.315787762403488e-05\n",
      "The classification loss after processing this batch is:  20401.8984375\n",
      "The representation loss after processing this batch is:  3.714952617883682e-05\n",
      "The classification loss after processing this batch is:  19864.158203125\n",
      "The representation loss after processing this batch is:  3.531109541654587e-05\n",
      "The classification loss after processing this batch is:  20331.42578125\n",
      "The representation loss after processing this batch is:  3.5913195461034775e-05\n",
      "The classification loss after processing this batch is:  20213.3515625\n",
      "The representation loss after processing this batch is:  3.6541372537612915e-05\n",
      "The classification loss after processing this batch is:  20122.505859375\n",
      "The representation loss after processing this batch is:  3.615580499172211e-05\n",
      "The classification loss after processing this batch is:  19881.505859375\n",
      "The representation loss after processing this batch is:  3.377394750714302e-05\n",
      "The classification loss after processing this batch is:  19977.59765625\n",
      "The representation loss after processing this batch is:  3.554811701178551e-05\n",
      "The classification loss after processing this batch is:  20598.19921875\n",
      "The representation loss after processing this batch is:  3.603007644414902e-05\n",
      "The classification loss after processing this batch is:  20026.580078125\n",
      "The representation loss after processing this batch is:  3.5779550671577454e-05\n",
      "The classification loss after processing this batch is:  20014.7578125\n",
      "The representation loss after processing this batch is:  3.7418678402900696e-05\n",
      "The classification loss after processing this batch is:  19773.275390625\n",
      "The representation loss after processing this batch is:  3.385590389370918e-05\n",
      "The classification loss after processing this batch is:  19549.7578125\n",
      "The representation loss after processing this batch is:  3.485102206468582e-05\n",
      "The classification loss after processing this batch is:  21240.134765625\n",
      "The representation loss after processing this batch is:  3.06558795273304e-05\n",
      "The classification loss after processing this batch is:  21241.869140625\n",
      "The representation loss after processing this batch is:  3.352062776684761e-05\n",
      "The classification loss after processing this batch is:  21772.11328125\n",
      "The representation loss after processing this batch is:  3.3907126635313034e-05\n",
      "The classification loss after processing this batch is:  22523.0546875\n",
      "The representation loss after processing this batch is:  3.571854904294014e-05\n",
      "The classification loss after processing this batch is:  22020.34375\n",
      "The representation loss after processing this batch is:  3.445986658334732e-05\n",
      "The classification loss after processing this batch is:  21009.009765625\n",
      "The representation loss after processing this batch is:  3.542657941579819e-05\n",
      "The classification loss after processing this batch is:  21399.302734375\n",
      "The representation loss after processing this batch is:  3.381166607141495e-05\n",
      "The classification loss after processing this batch is:  20857.25390625\n",
      "The representation loss after processing this batch is:  3.579678013920784e-05\n",
      "The classification loss after processing this batch is:  21260.521484375\n",
      "The representation loss after processing this batch is:  3.618653863668442e-05\n",
      "The classification loss after processing this batch is:  20400.091796875\n",
      "The representation loss after processing this batch is:  3.31229530274868e-05\n",
      "The classification loss after processing this batch is:  20332.236328125\n",
      "The representation loss after processing this batch is:  3.4860800951719284e-05\n",
      "The classification loss after processing this batch is:  21403.12890625\n",
      "The representation loss after processing this batch is:  3.340933471918106e-05\n",
      "The classification loss after processing this batch is:  21382.4765625\n",
      "The representation loss after processing this batch is:  3.557419404387474e-05\n",
      "The classification loss after processing this batch is:  20650.732421875\n",
      "The representation loss after processing this batch is:  3.3727847039699554e-05\n",
      "The classification loss after processing this batch is:  21957.41015625\n",
      "The representation loss after processing this batch is:  3.218976780772209e-05\n",
      "The classification loss after processing this batch is:  24002.78515625\n",
      "The representation loss after processing this batch is:  3.986340016126633e-05\n",
      "The classification loss after processing this batch is:  22373.140625\n",
      "The representation loss after processing this batch is:  3.388989716768265e-05\n",
      "The classification loss after processing this batch is:  20612.41015625\n",
      "The representation loss after processing this batch is:  3.198860213160515e-05\n",
      "The classification loss after processing this batch is:  20865.4453125\n",
      "The representation loss after processing this batch is:  3.657769411802292e-05\n",
      "The classification loss after processing this batch is:  25260.291015625\n",
      "The representation loss after processing this batch is:  4.292326048016548e-05\n",
      "The classification loss after processing this batch is:  25484.583984375\n",
      "The representation loss after processing this batch is:  4.616100341081619e-05\n",
      "The classification loss after processing this batch is:  20517.34375\n",
      "The representation loss after processing this batch is:  3.825174644589424e-05\n",
      "The classification loss after processing this batch is:  20016.990234375\n",
      "The representation loss after processing this batch is:  3.730272874236107e-05\n",
      "The classification loss after processing this batch is:  20643.1796875\n",
      "The representation loss after processing this batch is:  3.622937947511673e-05\n",
      "The classification loss after processing this batch is:  21082.90625\n",
      "The representation loss after processing this batch is:  3.517325967550278e-05\n",
      "The classification loss after processing this batch is:  20791.41796875\n",
      "The representation loss after processing this batch is:  3.463542088866234e-05\n",
      "The classification loss after processing this batch is:  20563.22265625\n",
      "The representation loss after processing this batch is:  3.5493168979883194e-05\n",
      "The classification loss after processing this batch is:  21879.28125\n",
      "The representation loss after processing this batch is:  3.108801320195198e-05\n",
      "The classification loss after processing this batch is:  22840.517578125\n",
      "The representation loss after processing this batch is:  3.839004784822464e-05\n",
      "The classification loss after processing this batch is:  20646.8671875\n",
      "The representation loss after processing this batch is:  3.901775926351547e-05\n",
      "The classification loss after processing this batch is:  21284.45703125\n",
      "The representation loss after processing this batch is:  3.2191164791584015e-05\n",
      "The classification loss after processing this batch is:  19963.576171875\n",
      "The representation loss after processing this batch is:  3.302609547972679e-05\n",
      "The classification loss after processing this batch is:  19940.1015625\n",
      "The representation loss after processing this batch is:  3.657536581158638e-05\n",
      "The classification loss after processing this batch is:  19573.697265625\n",
      "The representation loss after processing this batch is:  3.2842159271240234e-05\n",
      "The classification loss after processing this batch is:  20923.88671875\n",
      "The representation loss after processing this batch is:  4.044594243168831e-05\n",
      "The classification loss after processing this batch is:  20558.853515625\n",
      "The representation loss after processing this batch is:  3.464287146925926e-05\n",
      "The classification loss after processing this batch is:  23097.240234375\n",
      "The representation loss after processing this batch is:  3.728363662958145e-05\n",
      "The classification loss after processing this batch is:  20514.00390625\n",
      "The representation loss after processing this batch is:  3.639562055468559e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  20829.85546875\n",
      "The representation loss after processing this batch is:  3.4234486520290375e-05\n",
      "The classification loss after processing this batch is:  22316.59375\n",
      "The representation loss after processing this batch is:  3.7353020161390305e-05\n",
      "The classification loss after processing this batch is:  21971.59375\n",
      "The representation loss after processing this batch is:  3.1124334782361984e-05\n",
      "The classification loss after processing this batch is:  21358.001953125\n",
      "The representation loss after processing this batch is:  3.364495933055878e-05\n",
      "The classification loss after processing this batch is:  22684.025390625\n",
      "The representation loss after processing this batch is:  3.930507227778435e-05\n",
      "The classification loss after processing this batch is:  20908.05859375\n",
      "The representation loss after processing this batch is:  3.4559983760118484e-05\n",
      "The classification loss after processing this batch is:  21344.93359375\n",
      "The representation loss after processing this batch is:  4.2275991290807724e-05\n",
      "The classification loss after processing this batch is:  20141.96484375\n",
      "The representation loss after processing this batch is:  3.2347626984119415e-05\n",
      "The classification loss after processing this batch is:  20188.0546875\n",
      "The representation loss after processing this batch is:  3.498885780572891e-05\n",
      "The classification loss after processing this batch is:  20470.453125\n",
      "The representation loss after processing this batch is:  3.595184534788132e-05\n",
      "The classification loss after processing this batch is:  20615.39453125\n",
      "The representation loss after processing this batch is:  3.659818321466446e-05\n",
      "The classification loss after processing this batch is:  20615.875\n",
      "The representation loss after processing this batch is:  3.78522090613842e-05\n",
      "The classification loss after processing this batch is:  23015.40625\n",
      "The representation loss after processing this batch is:  3.7140678614377975e-05\n",
      "The classification loss after processing this batch is:  20295.09375\n",
      "The representation loss after processing this batch is:  3.160117194056511e-05\n",
      "The classification loss after processing this batch is:  20403.22265625\n",
      "The representation loss after processing this batch is:  3.1775329262018204e-05\n",
      "The classification loss after processing this batch is:  21109.861328125\n",
      "The representation loss after processing this batch is:  3.394484519958496e-05\n",
      "The classification loss after processing this batch is:  20663.55078125\n",
      "The representation loss after processing this batch is:  3.1833071261644363e-05\n",
      "The classification loss after processing this batch is:  21459.7109375\n",
      "The representation loss after processing this batch is:  3.143679350614548e-05\n",
      "The classification loss after processing this batch is:  21363.203125\n",
      "The representation loss after processing this batch is:  3.216555342078209e-05\n",
      "The classification loss after processing this batch is:  21089.3671875\n",
      "The representation loss after processing this batch is:  3.694463521242142e-05\n",
      "The classification loss after processing this batch is:  19741.88671875\n",
      "The representation loss after processing this batch is:  3.322027623653412e-05\n",
      "The classification loss after processing this batch is:  21479.609375\n",
      "The representation loss after processing this batch is:  3.143865615129471e-05\n",
      "The classification loss after processing this batch is:  23953.33203125\n",
      "The representation loss after processing this batch is:  3.404403105378151e-05\n",
      "The classification loss after processing this batch is:  24696.23046875\n",
      "The representation loss after processing this batch is:  3.8945116102695465e-05\n",
      "The classification loss after processing this batch is:  21254.36328125\n",
      "The representation loss after processing this batch is:  3.358069807291031e-05\n",
      "The classification loss after processing this batch is:  21056.55078125\n",
      "The representation loss after processing this batch is:  3.2871030271053314e-05\n",
      "The classification loss after processing this batch is:  20662.453125\n",
      "The representation loss after processing this batch is:  3.330502659082413e-05\n",
      "The classification loss after processing this batch is:  21351.98828125\n",
      "The representation loss after processing this batch is:  3.314390778541565e-05\n",
      "The classification loss after processing this batch is:  20458.166015625\n",
      "The representation loss after processing this batch is:  3.3046118915081024e-05\n",
      "The classification loss after processing this batch is:  20946.12890625\n",
      "The representation loss after processing this batch is:  3.3268705010414124e-05\n",
      "The classification loss after processing this batch is:  22320.625\n",
      "The representation loss after processing this batch is:  3.579212352633476e-05\n",
      "The classification loss after processing this batch is:  19845.0234375\n",
      "The representation loss after processing this batch is:  3.390572965145111e-05\n",
      "The classification loss after processing this batch is:  20236.66015625\n",
      "The representation loss after processing this batch is:  3.4320168197155e-05\n",
      "The classification loss after processing this batch is:  21977.65234375\n",
      "The representation loss after processing this batch is:  3.7021003663539886e-05\n",
      "The classification loss after processing this batch is:  20647.7890625\n",
      "The representation loss after processing this batch is:  3.678351640701294e-05\n",
      "The classification loss after processing this batch is:  20483.3671875\n",
      "The representation loss after processing this batch is:  3.705127164721489e-05\n",
      "The classification loss after processing this batch is:  19456.615234375\n",
      "The representation loss after processing this batch is:  3.3488497138023376e-05\n",
      "The classification loss after processing this batch is:  22386.783203125\n",
      "The representation loss after processing this batch is:  3.676116466522217e-05\n",
      "The classification loss after processing this batch is:  21763.982421875\n",
      "The representation loss after processing this batch is:  3.9116013795137405e-05\n",
      "The classification loss after processing this batch is:  26103.916015625\n",
      "The representation loss after processing this batch is:  3.893580287694931e-05\n",
      "The classification loss after processing this batch is:  21987.728515625\n",
      "The representation loss after processing this batch is:  3.381306305527687e-05\n",
      "The classification loss after processing this batch is:  20729.55859375\n",
      "The representation loss after processing this batch is:  3.434112295508385e-05\n",
      "The classification loss after processing this batch is:  21819.232421875\n",
      "The representation loss after processing this batch is:  3.500981256365776e-05\n",
      "The classification loss after processing this batch is:  22966.23046875\n",
      "The representation loss after processing this batch is:  3.538280725479126e-05\n",
      "The classification loss after processing this batch is:  22153.724609375\n",
      "The representation loss after processing this batch is:  3.2891519367694855e-05\n",
      "The classification loss after processing this batch is:  21299.451171875\n",
      "The representation loss after processing this batch is:  3.5418663173913956e-05\n",
      "The classification loss after processing this batch is:  21378.8828125\n",
      "The representation loss after processing this batch is:  3.272201865911484e-05\n",
      "The classification loss after processing this batch is:  21238.96875\n",
      "The representation loss after processing this batch is:  3.082677721977234e-05\n",
      "The classification loss after processing this batch is:  20304.466796875\n",
      "The representation loss after processing this batch is:  3.4635886549949646e-05\n",
      "The classification loss after processing this batch is:  21433.28515625\n",
      "The representation loss after processing this batch is:  3.411620855331421e-05\n",
      "The classification loss after processing this batch is:  21151.994140625\n",
      "The representation loss after processing this batch is:  3.332272171974182e-05\n",
      "The classification loss after processing this batch is:  21744.478515625\n",
      "The representation loss after processing this batch is:  3.39532271027565e-05\n",
      "The classification loss after processing this batch is:  21578.76953125\n",
      "The representation loss after processing this batch is:  3.3431220799684525e-05\n",
      "The classification loss after processing this batch is:  21532.85546875\n",
      "The representation loss after processing this batch is:  3.7153251469135284e-05\n",
      "The classification loss after processing this batch is:  20490.25390625\n",
      "The representation loss after processing this batch is:  3.0496623367071152e-05\n",
      "The classification loss after processing this batch is:  20031.203125\n",
      "The representation loss after processing this batch is:  3.78158874809742e-05\n",
      "The classification loss after processing this batch is:  20424.96875\n",
      "The representation loss after processing this batch is:  3.112107515335083e-05\n",
      "The classification loss after processing this batch is:  20241.01171875\n",
      "The representation loss after processing this batch is:  3.253854811191559e-05\n",
      "The classification loss after processing this batch is:  21578.53125\n",
      "The representation loss after processing this batch is:  3.5585835576057434e-05\n",
      "The classification loss after processing this batch is:  21206.66015625\n",
      "The representation loss after processing this batch is:  3.09748575091362e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  20699.3515625\n",
      "The representation loss after processing this batch is:  3.7618447095155716e-05\n",
      "The classification loss after processing this batch is:  19387.40625\n",
      "The representation loss after processing this batch is:  3.8001686334609985e-05\n",
      "The classification loss after processing this batch is:  19522.44921875\n",
      "The representation loss after processing this batch is:  3.5054516047239304e-05\n",
      "The classification loss after processing this batch is:  21352.658203125\n",
      "The representation loss after processing this batch is:  3.224844112992287e-05\n",
      "The classification loss after processing this batch is:  21978.7890625\n",
      "The representation loss after processing this batch is:  3.30386683344841e-05\n",
      "The classification loss after processing this batch is:  22132.734375\n",
      "The representation loss after processing this batch is:  3.861403092741966e-05\n",
      "The classification loss after processing this batch is:  20118.87109375\n",
      "The representation loss after processing this batch is:  3.36766242980957e-05\n",
      "The classification loss after processing this batch is:  21374.056640625\n",
      "The representation loss after processing this batch is:  3.208359703421593e-05\n",
      "The classification loss after processing this batch is:  20378.224609375\n",
      "The representation loss after processing this batch is:  3.536371514201164e-05\n",
      "The classification loss after processing this batch is:  21305.96484375\n",
      "The representation loss after processing this batch is:  3.676256164908409e-05\n",
      "The classification loss after processing this batch is:  20284.921875\n",
      "The representation loss after processing this batch is:  3.2234471291303635e-05\n",
      "The classification loss after processing this batch is:  19753.07421875\n",
      "The representation loss after processing this batch is:  3.558816388249397e-05\n",
      "The classification loss after processing this batch is:  19480.59375\n",
      "The representation loss after processing this batch is:  3.590527921915054e-05\n",
      "The classification loss after processing this batch is:  20589.125\n",
      "The representation loss after processing this batch is:  4.162359982728958e-05\n",
      "The classification loss after processing this batch is:  20819.849609375\n",
      "The representation loss after processing this batch is:  3.9631035178899765e-05\n",
      "The classification loss after processing this batch is:  21054.87890625\n",
      "The representation loss after processing this batch is:  3.4782569855451584e-05\n",
      "The classification loss after processing this batch is:  21021.716796875\n",
      "The representation loss after processing this batch is:  3.713928163051605e-05\n",
      "The classification loss after processing this batch is:  20299.76171875\n",
      "The representation loss after processing this batch is:  3.262097015976906e-05\n",
      "The classification loss after processing this batch is:  21893.375\n",
      "The representation loss after processing this batch is:  3.509689122438431e-05\n",
      "The classification loss after processing this batch is:  23225.587890625\n",
      "The representation loss after processing this batch is:  3.823498263955116e-05\n",
      "The classification loss after processing this batch is:  22585.400390625\n",
      "The representation loss after processing this batch is:  3.8164202123880386e-05\n",
      "The classification loss after processing this batch is:  22336.123046875\n",
      "The representation loss after processing this batch is:  3.718538209795952e-05\n",
      "The classification loss after processing this batch is:  20397.453125\n",
      "The representation loss after processing this batch is:  3.273133188486099e-05\n",
      "The classification loss after processing this batch is:  20673.5078125\n",
      "The representation loss after processing this batch is:  3.2446347177028656e-05\n",
      "The classification loss after processing this batch is:  21873.07421875\n",
      "The representation loss after processing this batch is:  3.4749507904052734e-05\n",
      "The classification loss after processing this batch is:  20247.71484375\n",
      "The representation loss after processing this batch is:  3.932137042284012e-05\n",
      "The classification loss after processing this batch is:  20471.390625\n",
      "The representation loss after processing this batch is:  3.4586526453495026e-05\n",
      "The classification loss after processing this batch is:  21446.99609375\n",
      "The representation loss after processing this batch is:  3.153784200549126e-05\n",
      "The classification loss after processing this batch is:  21247.8125\n",
      "The representation loss after processing this batch is:  3.118766471743584e-05\n",
      "The classification loss after processing this batch is:  20985.8828125\n",
      "The representation loss after processing this batch is:  3.099720925092697e-05\n",
      "The classification loss after processing this batch is:  20730.896484375\n",
      "The representation loss after processing this batch is:  3.396207466721535e-05\n",
      "The classification loss after processing this batch is:  22325.04296875\n",
      "The representation loss after processing this batch is:  3.888830542564392e-05\n",
      "The classification loss after processing this batch is:  21899.65234375\n",
      "The representation loss after processing this batch is:  3.4607015550136566e-05\n",
      "The classification loss after processing this batch is:  22355.08203125\n",
      "The representation loss after processing this batch is:  3.2573938369750977e-05\n",
      "The classification loss after processing this batch is:  22924.1484375\n",
      "The representation loss after processing this batch is:  3.61311249434948e-05\n",
      "The classification loss after processing this batch is:  21729.90625\n",
      "The representation loss after processing this batch is:  3.147358074784279e-05\n",
      "The classification loss after processing this batch is:  20577.6640625\n",
      "The representation loss after processing this batch is:  3.327196463942528e-05\n",
      "The classification loss after processing this batch is:  20246.818359375\n",
      "The representation loss after processing this batch is:  3.518955782055855e-05\n",
      "The classification loss after processing this batch is:  20532.619140625\n",
      "The representation loss after processing this batch is:  3.30926850438118e-05\n",
      "The classification loss after processing this batch is:  21276.16015625\n",
      "The representation loss after processing this batch is:  3.448827192187309e-05\n",
      "The classification loss after processing this batch is:  20722.638671875\n",
      "The representation loss after processing this batch is:  3.476673737168312e-05\n",
      "The classification loss after processing this batch is:  21260.701171875\n",
      "The representation loss after processing this batch is:  3.2520387321710587e-05\n",
      "The classification loss after processing this batch is:  20941.169921875\n",
      "The representation loss after processing this batch is:  3.621866926550865e-05\n",
      "The classification loss after processing this batch is:  23600.203125\n",
      "The representation loss after processing this batch is:  3.8640107959508896e-05\n",
      "The classification loss after processing this batch is:  22866.4453125\n",
      "The representation loss after processing this batch is:  3.3711083233356476e-05\n",
      "The classification loss after processing this batch is:  20932.486328125\n",
      "The representation loss after processing this batch is:  3.3025629818439484e-05\n",
      "The classification loss after processing this batch is:  20038.0625\n",
      "The representation loss after processing this batch is:  3.566127270460129e-05\n",
      "The classification loss after processing this batch is:  20263.130859375\n",
      "The representation loss after processing this batch is:  3.4300144761800766e-05\n",
      "The classification loss after processing this batch is:  21191.814453125\n",
      "The representation loss after processing this batch is:  4.063360393047333e-05\n",
      "The classification loss after processing this batch is:  20744.763671875\n",
      "The representation loss after processing this batch is:  4.224525764584541e-05\n",
      "The classification loss after processing this batch is:  21453.375\n",
      "The representation loss after processing this batch is:  3.3476389944553375e-05\n",
      "The classification loss after processing this batch is:  20622.52734375\n",
      "The representation loss after processing this batch is:  3.298558294773102e-05\n",
      "The classification loss after processing this batch is:  20242.990234375\n",
      "The representation loss after processing this batch is:  2.9385089874267578e-05\n",
      "The classification loss after processing this batch is:  20017.8671875\n",
      "The representation loss after processing this batch is:  3.127194941043854e-05\n",
      "The classification loss after processing this batch is:  21668.08984375\n",
      "The representation loss after processing this batch is:  3.487337380647659e-05\n",
      "The classification loss after processing this batch is:  23054.30859375\n",
      "The representation loss after processing this batch is:  3.905920311808586e-05\n",
      "The classification loss after processing this batch is:  21115.37890625\n",
      "The representation loss after processing this batch is:  3.666756674647331e-05\n",
      "The classification loss after processing this batch is:  21282.59765625\n",
      "The representation loss after processing this batch is:  3.2953452318906784e-05\n",
      "The classification loss after processing this batch is:  22297.78515625\n",
      "The representation loss after processing this batch is:  3.741215914487839e-05\n",
      "The classification loss after processing this batch is:  21561.927734375\n",
      "The representation loss after processing this batch is:  3.2403040677309036e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  22828.3828125\n",
      "The representation loss after processing this batch is:  3.251293674111366e-05\n",
      "The classification loss after processing this batch is:  20879.310546875\n",
      "The representation loss after processing this batch is:  3.373436629772186e-05\n",
      "The classification loss after processing this batch is:  21813.44140625\n",
      "The representation loss after processing this batch is:  3.946758806705475e-05\n",
      "The classification loss after processing this batch is:  20835.884765625\n",
      "The representation loss after processing this batch is:  3.488361835479736e-05\n",
      "The classification loss after processing this batch is:  21372.92578125\n",
      "The representation loss after processing this batch is:  3.0053313821554184e-05\n",
      "The classification loss after processing this batch is:  20777.787109375\n",
      "The representation loss after processing this batch is:  3.424612805247307e-05\n",
      "The classification loss after processing this batch is:  20838.17578125\n",
      "The representation loss after processing this batch is:  3.252970054745674e-05\n",
      "The classification loss after processing this batch is:  21259.72265625\n",
      "The representation loss after processing this batch is:  3.0312221497297287e-05\n",
      "The classification loss after processing this batch is:  20426.80078125\n",
      "The representation loss after processing this batch is:  3.588711842894554e-05\n",
      "The classification loss after processing this batch is:  20807.857421875\n",
      "The representation loss after processing this batch is:  3.503914922475815e-05\n",
      "The classification loss after processing this batch is:  19834.0078125\n",
      "The representation loss after processing this batch is:  3.38749960064888e-05\n",
      "The classification loss after processing this batch is:  19925.955078125\n",
      "The representation loss after processing this batch is:  4.007341340184212e-05\n",
      "The classification loss after processing this batch is:  19783.0625\n",
      "The representation loss after processing this batch is:  3.2753217965364456e-05\n",
      "The classification loss after processing this batch is:  21394.2109375\n",
      "The representation loss after processing this batch is:  3.85320745408535e-05\n",
      "The classification loss after processing this batch is:  20448.837890625\n",
      "The representation loss after processing this batch is:  3.6946963518857956e-05\n",
      "The classification loss after processing this batch is:  21175.0546875\n",
      "The representation loss after processing this batch is:  3.542611375451088e-05\n",
      "The classification loss after processing this batch is:  21277.09375\n",
      "The representation loss after processing this batch is:  3.0753202736377716e-05\n",
      "The classification loss after processing this batch is:  20250.86328125\n",
      "The representation loss after processing this batch is:  3.010593354701996e-05\n",
      "The classification loss after processing this batch is:  21564.736328125\n",
      "The representation loss after processing this batch is:  3.392854705452919e-05\n",
      "The classification loss after processing this batch is:  21188.17578125\n",
      "The representation loss after processing this batch is:  3.8158614188432693e-05\n",
      "The classification loss after processing this batch is:  20217.515625\n",
      "The representation loss after processing this batch is:  3.398628905415535e-05\n",
      "The classification loss after processing this batch is:  21033.08984375\n",
      "The representation loss after processing this batch is:  3.169849514961243e-05\n",
      "The classification loss after processing this batch is:  20727.056640625\n",
      "The representation loss after processing this batch is:  3.372086212038994e-05\n",
      "The classification loss after processing this batch is:  20429.05078125\n",
      "The representation loss after processing this batch is:  3.087148070335388e-05\n",
      "The classification loss after processing this batch is:  21026.7890625\n",
      "The representation loss after processing this batch is:  3.269873559474945e-05\n",
      "The classification loss after processing this batch is:  20676.2421875\n",
      "The representation loss after processing this batch is:  3.631412982940674e-05\n",
      "The classification loss after processing this batch is:  21503.55078125\n",
      "The representation loss after processing this batch is:  3.7464313209056854e-05\n",
      "The classification loss after processing this batch is:  22264.603515625\n",
      "The representation loss after processing this batch is:  3.406219184398651e-05\n",
      "The classification loss after processing this batch is:  20963.2421875\n",
      "The representation loss after processing this batch is:  3.505684435367584e-05\n",
      "The classification loss after processing this batch is:  22755.912109375\n",
      "The representation loss after processing this batch is:  3.0972063541412354e-05\n",
      "The classification loss after processing this batch is:  23267.07421875\n",
      "The representation loss after processing this batch is:  3.186101093888283e-05\n",
      "The classification loss after processing this batch is:  20710.31640625\n",
      "The representation loss after processing this batch is:  3.290083259344101e-05\n",
      "The classification loss after processing this batch is:  21445.087890625\n",
      "The representation loss after processing this batch is:  3.084121271967888e-05\n",
      "The classification loss after processing this batch is:  22518.69140625\n",
      "The representation loss after processing this batch is:  3.651995211839676e-05\n",
      "The classification loss after processing this batch is:  21038.3828125\n",
      "The representation loss after processing this batch is:  3.16007062792778e-05\n",
      "The classification loss after processing this batch is:  21018.1640625\n",
      "The representation loss after processing this batch is:  3.4417957067489624e-05\n",
      "The classification loss after processing this batch is:  20651.06640625\n",
      "The representation loss after processing this batch is:  3.37664969265461e-05\n",
      "The classification loss after processing this batch is:  21006.828125\n",
      "The representation loss after processing this batch is:  3.302190452814102e-05\n",
      "The classification loss after processing this batch is:  21831.875\n",
      "The representation loss after processing this batch is:  2.9771588742733002e-05\n",
      "The classification loss after processing this batch is:  21672.46875\n",
      "The representation loss after processing this batch is:  3.467826172709465e-05\n",
      "The classification loss after processing this batch is:  23621.521484375\n",
      "The representation loss after processing this batch is:  4.067644476890564e-05\n",
      "The classification loss after processing this batch is:  22150.369140625\n",
      "The representation loss after processing this batch is:  3.216136246919632e-05\n",
      "The classification loss after processing this batch is:  21491.1015625\n",
      "The representation loss after processing this batch is:  3.1499192118644714e-05\n",
      "The classification loss after processing this batch is:  20345.591796875\n",
      "The representation loss after processing this batch is:  3.129756078124046e-05\n",
      "The classification loss after processing this batch is:  20485.470703125\n",
      "The representation loss after processing this batch is:  3.130175173282623e-05\n",
      "The classification loss after processing this batch is:  21456.5625\n",
      "The representation loss after processing this batch is:  3.1365081667900085e-05\n",
      "The classification loss after processing this batch is:  20492.701171875\n",
      "The representation loss after processing this batch is:  3.354903310537338e-05\n",
      "The classification loss after processing this batch is:  19580.255859375\n",
      "The representation loss after processing this batch is:  3.726966679096222e-05\n",
      "The classification loss after processing this batch is:  22024.416015625\n",
      "The representation loss after processing this batch is:  3.3867545425891876e-05\n",
      "The classification loss after processing this batch is:  20114.998046875\n",
      "The representation loss after processing this batch is:  3.0670780688524246e-05\n",
      "The classification loss after processing this batch is:  20335.4296875\n",
      "The representation loss after processing this batch is:  3.135623410344124e-05\n",
      "The classification loss after processing this batch is:  19560.40625\n",
      "The representation loss after processing this batch is:  3.384007140994072e-05\n",
      "The classification loss after processing this batch is:  20259.71484375\n",
      "The representation loss after processing this batch is:  3.401655703783035e-05\n",
      "The classification loss after processing this batch is:  19887.13671875\n",
      "The representation loss after processing this batch is:  3.196718171238899e-05\n",
      "The classification loss after processing this batch is:  21074.724609375\n",
      "The representation loss after processing this batch is:  3.2091978937387466e-05\n",
      "The classification loss after processing this batch is:  20536.08203125\n",
      "The representation loss after processing this batch is:  3.071688115596771e-05\n",
      "The classification loss after processing this batch is:  20162.37109375\n",
      "The representation loss after processing this batch is:  3.085285425186157e-05\n",
      "The classification loss after processing this batch is:  21328.48828125\n",
      "The representation loss after processing this batch is:  3.345031291246414e-05\n",
      "The classification loss after processing this batch is:  21840.5625\n",
      "The representation loss after processing this batch is:  3.370177000761032e-05\n",
      "The classification loss after processing this batch is:  20016.4140625\n",
      "The representation loss after processing this batch is:  3.3964868634939194e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  20289.85546875\n",
      "The representation loss after processing this batch is:  3.3562071621418e-05\n",
      "The classification loss after processing this batch is:  20831.22265625\n",
      "The representation loss after processing this batch is:  3.3593736588954926e-05\n",
      "The classification loss after processing this batch is:  20480.55859375\n",
      "The representation loss after processing this batch is:  3.158906474709511e-05\n",
      "The classification loss after processing this batch is:  21388.486328125\n",
      "The representation loss after processing this batch is:  3.2922253012657166e-05\n",
      "The classification loss after processing this batch is:  20172.72265625\n",
      "The representation loss after processing this batch is:  3.1286850571632385e-05\n",
      "The classification loss after processing this batch is:  19827.88671875\n",
      "The representation loss after processing this batch is:  3.431132063269615e-05\n",
      "The classification loss after processing this batch is:  20829.48046875\n",
      "The representation loss after processing this batch is:  3.4842174500226974e-05\n",
      "The classification loss after processing this batch is:  22740.294921875\n",
      "The representation loss after processing this batch is:  3.999611362814903e-05\n",
      "The classification loss after processing this batch is:  20298.71875\n",
      "The representation loss after processing this batch is:  3.0186958611011505e-05\n",
      "The classification loss after processing this batch is:  21330.4921875\n",
      "The representation loss after processing this batch is:  3.258604556322098e-05\n",
      "The classification loss after processing this batch is:  23152.458984375\n",
      "The representation loss after processing this batch is:  3.439607098698616e-05\n",
      "The classification loss after processing this batch is:  20834.16015625\n",
      "The representation loss after processing this batch is:  3.4147873520851135e-05\n",
      "The classification loss after processing this batch is:  19974.92578125\n",
      "The representation loss after processing this batch is:  3.4098513424396515e-05\n",
      "The classification loss after processing this batch is:  20275.5625\n",
      "The representation loss after processing this batch is:  3.283005207777023e-05\n",
      "The classification loss after processing this batch is:  20108.9765625\n",
      "The representation loss after processing this batch is:  3.144377842545509e-05\n",
      "The classification loss after processing this batch is:  20979.67578125\n",
      "The representation loss after processing this batch is:  3.056041896343231e-05\n",
      "The classification loss after processing this batch is:  20214.40234375\n",
      "The representation loss after processing this batch is:  3.718910738825798e-05\n",
      "The classification loss after processing this batch is:  20840.947265625\n",
      "The representation loss after processing this batch is:  3.271270543336868e-05\n",
      "The classification loss after processing this batch is:  23860.9765625\n",
      "The representation loss after processing this batch is:  3.580516204237938e-05\n",
      "The classification loss after processing this batch is:  22327.421875\n",
      "The representation loss after processing this batch is:  2.975156530737877e-05\n",
      "The classification loss after processing this batch is:  21438.384765625\n",
      "The representation loss after processing this batch is:  3.2574404031038284e-05\n",
      "The classification loss after processing this batch is:  20267.01171875\n",
      "The representation loss after processing this batch is:  3.101956099271774e-05\n",
      "The classification loss after processing this batch is:  21069.703125\n",
      "The representation loss after processing this batch is:  3.556162118911743e-05\n",
      "The classification loss after processing this batch is:  20990.12890625\n",
      "The representation loss after processing this batch is:  3.867829218506813e-05\n",
      "The classification loss after processing this batch is:  20318.845703125\n",
      "The representation loss after processing this batch is:  3.2813288271427155e-05\n",
      "The classification loss after processing this batch is:  19658.380859375\n",
      "The representation loss after processing this batch is:  3.437511622905731e-05\n",
      "The classification loss after processing this batch is:  20373.69140625\n",
      "The representation loss after processing this batch is:  3.298046067357063e-05\n",
      "The classification loss after processing this batch is:  20257.64453125\n",
      "The representation loss after processing this batch is:  3.0455179512500763e-05\n",
      "The classification loss after processing this batch is:  19655.306640625\n",
      "The representation loss after processing this batch is:  3.3845193684101105e-05\n",
      "The classification loss after processing this batch is:  20673.8125\n",
      "The representation loss after processing this batch is:  3.1564850360155106e-05\n",
      "The classification loss after processing this batch is:  19903.09765625\n",
      "The representation loss after processing this batch is:  3.298558294773102e-05\n",
      "The classification loss after processing this batch is:  22188.400390625\n",
      "The representation loss after processing this batch is:  3.5224948078393936e-05\n",
      "The classification loss after processing this batch is:  21864.89453125\n",
      "The representation loss after processing this batch is:  2.990197390317917e-05\n",
      "The classification loss after processing this batch is:  20969.654296875\n",
      "The representation loss after processing this batch is:  3.440165892243385e-05\n",
      "The classification loss after processing this batch is:  20664.45703125\n",
      "The representation loss after processing this batch is:  3.14079225063324e-05\n",
      "The classification loss after processing this batch is:  20371.259765625\n",
      "The representation loss after processing this batch is:  3.2257288694381714e-05\n",
      "The classification loss after processing this batch is:  21806.4375\n",
      "The representation loss after processing this batch is:  3.453763201832771e-05\n",
      "The classification loss after processing this batch is:  21332.83984375\n",
      "The representation loss after processing this batch is:  3.123050555586815e-05\n",
      "The classification loss after processing this batch is:  20558.4296875\n",
      "The representation loss after processing this batch is:  3.193644806742668e-05\n",
      "The classification loss after processing this batch is:  20967.5625\n",
      "The representation loss after processing this batch is:  3.203703090548515e-05\n",
      "The classification loss after processing this batch is:  22776.87890625\n",
      "The representation loss after processing this batch is:  3.933114930987358e-05\n",
      "The classification loss after processing this batch is:  20267.47265625\n",
      "The representation loss after processing this batch is:  3.2003968954086304e-05\n",
      "The classification loss after processing this batch is:  21322.958984375\n",
      "The representation loss after processing this batch is:  3.158301115036011e-05\n",
      "The classification loss after processing this batch is:  21369.591796875\n",
      "The representation loss after processing this batch is:  4.030764102935791e-05\n",
      "The classification loss after processing this batch is:  20926.232421875\n",
      "The representation loss after processing this batch is:  3.107590600848198e-05\n",
      "The classification loss after processing this batch is:  21539.71875\n",
      "The representation loss after processing this batch is:  3.253575414419174e-05\n",
      "The classification loss after processing this batch is:  22115.8046875\n",
      "The representation loss after processing this batch is:  3.4005846828222275e-05\n",
      "The classification loss after processing this batch is:  20758.064453125\n",
      "The representation loss after processing this batch is:  3.719888627529144e-05\n",
      "The classification loss after processing this batch is:  21547.919921875\n",
      "The representation loss after processing this batch is:  3.177206963300705e-05\n",
      "The classification loss after processing this batch is:  21660.263671875\n",
      "The representation loss after processing this batch is:  3.189966082572937e-05\n",
      "The classification loss after processing this batch is:  20804.728515625\n",
      "The representation loss after processing this batch is:  3.546895459294319e-05\n",
      "The classification loss after processing this batch is:  21708.052734375\n",
      "The representation loss after processing this batch is:  3.0193477869033813e-05\n",
      "The classification loss after processing this batch is:  21437.703125\n",
      "The representation loss after processing this batch is:  3.267871215939522e-05\n",
      "The classification loss after processing this batch is:  20334.484375\n",
      "The representation loss after processing this batch is:  3.392715007066727e-05\n",
      "The classification loss after processing this batch is:  20531.353515625\n",
      "The representation loss after processing this batch is:  3.2668933272361755e-05\n",
      "The classification loss after processing this batch is:  20345.859375\n",
      "The representation loss after processing this batch is:  3.411341458559036e-05\n",
      "The classification loss after processing this batch is:  20254.1796875\n",
      "The representation loss after processing this batch is:  3.337860107421875e-05\n",
      "The classification loss after processing this batch is:  22283.244140625\n",
      "The representation loss after processing this batch is:  3.2100360840559006e-05\n",
      "The classification loss after processing this batch is:  21658.23828125\n",
      "The representation loss after processing this batch is:  3.094179555773735e-05\n",
      "The classification loss after processing this batch is:  22597.958984375\n",
      "The representation loss after processing this batch is:  3.375345841050148e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  19878.31640625\n",
      "The representation loss after processing this batch is:  3.251619637012482e-05\n",
      "The classification loss after processing this batch is:  20330.283203125\n",
      "The representation loss after processing this batch is:  3.7528108805418015e-05\n",
      "The classification loss after processing this batch is:  20610.125\n",
      "The representation loss after processing this batch is:  3.4889206290245056e-05\n",
      "The classification loss after processing this batch is:  20343.1640625\n",
      "The representation loss after processing this batch is:  3.079930320382118e-05\n",
      "The classification loss after processing this batch is:  21514.40234375\n",
      "The representation loss after processing this batch is:  3.361795097589493e-05\n",
      "The classification loss after processing this batch is:  20376.30078125\n",
      "The representation loss after processing this batch is:  3.1439587473869324e-05\n",
      "The classification loss after processing this batch is:  20952.763671875\n",
      "The representation loss after processing this batch is:  3.2154377549886703e-05\n",
      "The classification loss after processing this batch is:  20979.564453125\n",
      "The representation loss after processing this batch is:  3.237603232264519e-05\n",
      "The classification loss after processing this batch is:  20243.21875\n",
      "The representation loss after processing this batch is:  3.32794152200222e-05\n",
      "The classification loss after processing this batch is:  22492.45703125\n",
      "The representation loss after processing this batch is:  3.580562770366669e-05\n",
      "The classification loss after processing this batch is:  22385.24609375\n",
      "The representation loss after processing this batch is:  3.2495707273483276e-05\n",
      "The classification loss after processing this batch is:  21557.544921875\n",
      "The representation loss after processing this batch is:  3.099581226706505e-05\n",
      "The classification loss after processing this batch is:  20014.96875\n",
      "The representation loss after processing this batch is:  3.316905349493027e-05\n",
      "The classification loss after processing this batch is:  22225.26171875\n",
      "The representation loss after processing this batch is:  3.2116658985614777e-05\n",
      "The classification loss after processing this batch is:  21798.6953125\n",
      "The representation loss after processing this batch is:  3.191642463207245e-05\n",
      "The classification loss after processing this batch is:  20192.1015625\n",
      "The representation loss after processing this batch is:  3.04272398352623e-05\n",
      "The classification loss after processing this batch is:  22421.40625\n",
      "The representation loss after processing this batch is:  3.803987056016922e-05\n",
      "The classification loss after processing this batch is:  22363.1640625\n",
      "The representation loss after processing this batch is:  3.700796514749527e-05\n",
      "The classification loss after processing this batch is:  19931.248046875\n",
      "The representation loss after processing this batch is:  3.1257979571819305e-05\n",
      "The classification loss after processing this batch is:  20612.21484375\n",
      "The representation loss after processing this batch is:  3.406498581171036e-05\n",
      "The classification loss after processing this batch is:  21154.890625\n",
      "The representation loss after processing this batch is:  3.46694141626358e-05\n",
      "The classification loss after processing this batch is:  20697.126953125\n",
      "The representation loss after processing this batch is:  3.407476469874382e-05\n",
      "The classification loss after processing this batch is:  21910.880859375\n",
      "The representation loss after processing this batch is:  3.950437530875206e-05\n",
      "The classification loss after processing this batch is:  22502.853515625\n",
      "The representation loss after processing this batch is:  3.434298560023308e-05\n",
      "The classification loss after processing this batch is:  20239.91015625\n",
      "The representation loss after processing this batch is:  3.517931327223778e-05\n",
      "The classification loss after processing this batch is:  19505.4765625\n",
      "The representation loss after processing this batch is:  3.374367952346802e-05\n",
      "The classification loss after processing this batch is:  20927.0\n",
      "The representation loss after processing this batch is:  3.1964853405952454e-05\n",
      "The classification loss after processing this batch is:  21759.51171875\n",
      "The representation loss after processing this batch is:  3.4174881875514984e-05\n",
      "The classification loss after processing this batch is:  20570.78515625\n",
      "The representation loss after processing this batch is:  3.259442746639252e-05\n",
      "The classification loss after processing this batch is:  21469.05859375\n",
      "The representation loss after processing this batch is:  3.484683111310005e-05\n",
      "The classification loss after processing this batch is:  20984.87890625\n",
      "The representation loss after processing this batch is:  2.947123721241951e-05\n",
      "The classification loss after processing this batch is:  20863.33984375\n",
      "The representation loss after processing this batch is:  3.271596506237984e-05\n",
      "The classification loss after processing this batch is:  20499.48046875\n",
      "The representation loss after processing this batch is:  3.140280023217201e-05\n",
      "The classification loss after processing this batch is:  20966.458984375\n",
      "The representation loss after processing this batch is:  3.577815368771553e-05\n",
      "The classification loss after processing this batch is:  22318.236328125\n",
      "The representation loss after processing this batch is:  3.344425931572914e-05\n",
      "The classification loss after processing this batch is:  20005.55859375\n",
      "The representation loss after processing this batch is:  3.188150003552437e-05\n",
      "The classification loss after processing this batch is:  19739.8671875\n",
      "The representation loss after processing this batch is:  3.200490027666092e-05\n",
      "The classification loss after processing this batch is:  19549.435546875\n",
      "The representation loss after processing this batch is:  3.25213186442852e-05\n",
      "The classification loss after processing this batch is:  19856.9765625\n",
      "The representation loss after processing this batch is:  3.0332710593938828e-05\n",
      "The classification loss after processing this batch is:  20201.927734375\n",
      "The representation loss after processing this batch is:  3.302795812487602e-05\n",
      "The classification loss after processing this batch is:  21292.400390625\n",
      "The representation loss after processing this batch is:  3.246404230594635e-05\n",
      "The classification loss after processing this batch is:  21474.322265625\n",
      "The representation loss after processing this batch is:  3.2417941838502884e-05\n",
      "The classification loss after processing this batch is:  20389.802734375\n",
      "The representation loss after processing this batch is:  3.1993724405765533e-05\n",
      "The classification loss after processing this batch is:  19604.23046875\n",
      "The representation loss after processing this batch is:  3.0887313187122345e-05\n",
      "The classification loss after processing this batch is:  19749.09375\n",
      "The representation loss after processing this batch is:  3.1274743378162384e-05\n",
      "The classification loss after processing this batch is:  20312.900390625\n",
      "The representation loss after processing this batch is:  3.140093758702278e-05\n",
      "The classification loss after processing this batch is:  20512.78125\n",
      "The representation loss after processing this batch is:  3.183819353580475e-05\n",
      "The classification loss after processing this batch is:  19716.83203125\n",
      "The representation loss after processing this batch is:  3.430526703596115e-05\n",
      "The classification loss after processing this batch is:  21970.7265625\n",
      "The representation loss after processing this batch is:  3.17390076816082e-05\n",
      "The classification loss after processing this batch is:  20340.26171875\n",
      "The representation loss after processing this batch is:  3.141164779663086e-05\n",
      "The classification loss after processing this batch is:  20131.0703125\n",
      "The representation loss after processing this batch is:  3.4440308809280396e-05\n",
      "The classification loss after processing this batch is:  20448.263671875\n",
      "The representation loss after processing this batch is:  3.456044942140579e-05\n",
      "The classification loss after processing this batch is:  21036.2578125\n",
      "The representation loss after processing this batch is:  3.4899450838565826e-05\n",
      "The classification loss after processing this batch is:  20891.2265625\n",
      "The representation loss after processing this batch is:  3.056740388274193e-05\n",
      "The classification loss after processing this batch is:  19882.560546875\n",
      "The representation loss after processing this batch is:  3.3580232411623e-05\n",
      "The classification loss after processing this batch is:  20430.732421875\n",
      "The representation loss after processing this batch is:  3.315042704343796e-05\n",
      "The classification loss after processing this batch is:  21858.5546875\n",
      "The representation loss after processing this batch is:  3.220420330762863e-05\n",
      "The classification loss after processing this batch is:  19355.171875\n",
      "The representation loss after processing this batch is:  3.45790758728981e-05\n",
      "The classification loss after processing this batch is:  19977.115234375\n",
      "The representation loss after processing this batch is:  3.229686990380287e-05\n",
      "The classification loss after processing this batch is:  18945.99609375\n",
      "The representation loss after processing this batch is:  3.343774005770683e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification loss after processing this batch is:  20435.306640625\n",
      "The representation loss after processing this batch is:  2.9585324227809906e-05\n",
      "The classification loss after processing this batch is:  20752.013671875\n",
      "The representation loss after processing this batch is:  3.1886622309684753e-05\n",
      "The classification loss after processing this batch is:  20200.486328125\n",
      "The representation loss after processing this batch is:  3.4137628972530365e-05\n",
      "The classification loss after processing this batch is:  19878.869140625\n",
      "The representation loss after processing this batch is:  3.4588854759931564e-05\n",
      "The classification loss after processing this batch is:  19412.33984375\n",
      "The representation loss after processing this batch is:  3.195693716406822e-05\n",
      "The classification loss after processing this batch is:  20587.791015625\n",
      "The representation loss after processing this batch is:  3.109592944383621e-05\n",
      "The classification loss after processing this batch is:  20287.81640625\n",
      "The representation loss after processing this batch is:  3.4176744520664215e-05\n",
      "The classification loss after processing this batch is:  19703.041015625\n",
      "The representation loss after processing this batch is:  3.3262185752391815e-05\n",
      "The classification loss after processing this batch is:  23373.123046875\n",
      "The representation loss after processing this batch is:  3.538839519023895e-05\n",
      "The classification loss after processing this batch is:  22012.6953125\n",
      "The representation loss after processing this batch is:  3.397325053811073e-05\n",
      "The classification loss after processing this batch is:  20981.791015625\n",
      "The representation loss after processing this batch is:  3.312667831778526e-05\n",
      "The classification loss after processing this batch is:  20628.486328125\n",
      "The representation loss after processing this batch is:  3.368593752384186e-05\n",
      "The classification loss after processing this batch is:  19900.296875\n",
      "The representation loss after processing this batch is:  3.3120159059762955e-05\n",
      "The classification loss after processing this batch is:  20434.802734375\n",
      "The representation loss after processing this batch is:  3.323610872030258e-05\n",
      "The classification loss after processing this batch is:  21219.884765625\n",
      "The representation loss after processing this batch is:  3.4924596548080444e-05\n",
      "The classification loss after processing this batch is:  20424.080078125\n",
      "The representation loss after processing this batch is:  3.216369077563286e-05\n",
      "The classification loss after processing this batch is:  22656.79296875\n",
      "The representation loss after processing this batch is:  3.177765756845474e-05\n",
      "The classification loss after processing this batch is:  20716.74609375\n",
      "The representation loss after processing this batch is:  3.41278500854969e-05\n",
      "The classification loss after processing this batch is:  19844.091796875\n",
      "The representation loss after processing this batch is:  3.403332084417343e-05\n",
      "The classification loss after processing this batch is:  21784.83984375\n",
      "The representation loss after processing this batch is:  3.495858982205391e-05\n",
      "The classification loss after processing this batch is:  20064.115234375\n",
      "The representation loss after processing this batch is:  3.216695040464401e-05\n",
      "The classification loss after processing this batch is:  20370.154296875\n",
      "The representation loss after processing this batch is:  3.717420622706413e-05\n",
      "The classification loss after processing this batch is:  24306.419921875\n",
      "The representation loss after processing this batch is:  3.8755591958761215e-05\n",
      "The classification loss after processing this batch is:  21330.50390625\n",
      "The representation loss after processing this batch is:  3.663729876279831e-05\n",
      "The classification loss after processing this batch is:  20170.478515625\n",
      "The representation loss after processing this batch is:  3.7671998143196106e-05\n",
      "The classification loss after processing this batch is:  20591.236328125\n",
      "The representation loss after processing this batch is:  4.607951268553734e-05\n",
      "The classification loss after processing this batch is:  22386.12109375\n",
      "The representation loss after processing this batch is:  3.764685243368149e-05\n",
      "The classification loss after processing this batch is:  19633.484375\n",
      "The representation loss after processing this batch is:  3.828899934887886e-05\n",
      "The classification loss after processing this batch is:  20770.34765625\n",
      "The representation loss after processing this batch is:  4.085572436451912e-05\n",
      "The classification loss after processing this batch is:  21684.64453125\n",
      "The representation loss after processing this batch is:  4.0646642446517944e-05\n",
      "The classification loss after processing this batch is:  25323.19921875\n",
      "The representation loss after processing this batch is:  4.00845892727375e-05\n",
      "The classification loss after processing this batch is:  27016.828125\n",
      "The representation loss after processing this batch is:  3.624334931373596e-05\n",
      "The classification loss after processing this batch is:  19858.8828125\n",
      "The representation loss after processing this batch is:  3.413856029510498e-05\n",
      "The classification loss after processing this batch is:  21323.92578125\n",
      "The representation loss after processing this batch is:  3.511738032102585e-05\n",
      "The classification loss after processing this batch is:  21383.40625\n",
      "The representation loss after processing this batch is:  3.92361544072628e-05\n",
      "The classification loss after processing this batch is:  19753.390625\n",
      "The representation loss after processing this batch is:  3.130827099084854e-05\n",
      "the loss after processing this epoch is:  0.1380014717578888\n",
      "the loss after processing this epoch is:  0.020916074514389038\n",
      "the loss after processing this epoch is:  0.002320935484021902\n",
      "the loss after processing this epoch is:  0.00046423572348430753\n",
      "the loss after processing this epoch is:  0.0011808326235041022\n",
      "the loss after processing this epoch is:  0.00020732483244501054\n",
      "the loss after processing this epoch is:  0.00017789006233215332\n",
      "the loss after processing this epoch is:  9.315212810179219e-05\n",
      "the loss after processing this epoch is:  0.00011453032493591309\n",
      "the loss after processing this epoch is:  1.754363256623037e-05\n"
     ]
    }
   ],
   "source": [
    "vafee = VFAE_CONV_NeuralModel().to(device)\n",
    "initial_classifier = VFAEEClassifier(beta=b, initial_VAE=vafee).to(device)\n",
    "\n",
    "for i in range(5):\n",
    "    training_examples = get_training_examples(model)\n",
    "    vafee = train_vae(vafee, training_examples, 1, 1, adv_examples= True)\n",
    "   \n",
    "    model =  VFAEEClassifier(beta=1, initial_VAE=vafee).to(device)\n",
    "\n",
    "    batch_size = 128\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "    model = train_classifier_adv(model, training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM Attack : \n",
      "0.8838\n",
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time_1 = time.time()\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=512)\n",
    "print(attack(model, device, test_loader, fgsm, 0.3)[0])\n",
    "print(\"=*\" * 20)\n",
    "time_2 = time.time()\n",
    "\n",
    "print(time_2-time_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projected Gradient Attack : \n",
      "0.5107\n",
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n"
     ]
    }
   ],
   "source": [
    "print(attack(model, device, test_loader, pgd, 0.3, 1e4, 40)[0])\n",
    "print(\"=*\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iFGSM Attack : \n",
      "0.065\n",
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n"
     ]
    }
   ],
   "source": [
    "print(attack(model, device, test_loader, pgd_linf, 0.3, 1e-2, 40)[0])\n",
    "print(\"=*\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Fool Attack : \n",
      "0.6917\n"
     ]
    }
   ],
   "source": [
    "print(attack(model, device, test_loader, pgd_l2,  1, 0.3, 40)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## modify multiplication factors\n",
    "## modify printed text \"classification loss to reconstruction loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM Attack : \n",
      "Projected Gradient Attack : \n",
      "iFGSM Attack : \n",
      "Deep Fool Attack : \n",
      "FGSM Attack : \n",
      "Projected Gradient Attack : \n",
      "iFGSM Attack : \n",
      "Deep Fool Attack : \n",
      "FGSM Attack : \n",
      "Projected Gradient Attack : \n",
      "iFGSM Attack : \n",
      "Deep Fool Attack : \n",
      "FGSM Attack : \n",
      "Projected Gradient Attack : \n",
      "iFGSM Attack : \n",
      "Deep Fool Attack : \n",
      "FGSM Attack : \n",
      "Projected Gradient Attack : \n",
      "iFGSM Attack : \n",
      "Deep Fool Attack : \n",
      "FGSM Attack : \n",
      "Projected Gradient Attack : \n",
      "iFGSM Attack : \n",
      "Deep Fool Attack : \n",
      "FGSM Attack : \n",
      "Projected Gradient Attack : \n",
      "iFGSM Attack : \n",
      "Deep Fool Attack : \n"
     ]
    }
   ],
   "source": [
    "fgsms = []\n",
    "pgds = []\n",
    "ifgsms=[]\n",
    "deepfools=[]\n",
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "for eps in epsilons :\n",
    "    fgsms.append(attack(model, device, test_loader, fgsm, eps)[0])\n",
    "\n",
    "    pgds.append(attack(model, device, test_loader, pgd, eps, 1e4, 40)[0])\n",
    "\n",
    "    ifgsms.append(attack(model, device, test_loader, pgd_linf, eps, 1e-2, 40)[0])\n",
    "\n",
    "    deepfools.append(attack(model, device, test_loader, pgd_l2, 1.3, eps, 40)[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epsilons, fgsms, label = 'fgsm')\n",
    "plt.plot(epsilons, pgds, label =\"pgd\")\n",
    "plt.plot(epsilons, ifgsms, label = 'ifgsm')\n",
    "plt.plot(epsilons, deepfools, label = 'deep fool L2')\n",
    "plt.legend() \n",
    "\n",
    "plt.xlabel('$\\epsilon$', size = 'xx-large', fontweight = 'demi')\n",
    "plt.ylabel('Accuracy', size = 'x-large')\n",
    "plt.ylim([0,1.0])\n",
    "plt.yticks(np.linspace(0,1,11))\n",
    "plt.savefig('figures/vafee4_1_classifier.pdf', format='pdf', bbox_inches='tight', quality = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
